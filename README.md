# MemorySplitAdvantage

Memory Split Advantage (MSA) describes a phenomenon: a single large network may perform worse than an ensemble of several smaller networks with the same total parameter count. This phenomenon has been empirically studied in [Lobacheva et al. (2020)](https://arxiv.org/pdf/2007.08483.pdf) and [Kondratyuk et al.(2020)](https://arxiv.org/pdf/2005.00570.pdf).

Our recent work *Ensembling With a Fixed Parameter Budget: When Does It Help and Why?* studied this phenomenon with both theoretical analysis and empirical experiments. In theoretical analysis, we used the Random Feature (RF) theory to explain the reason and the mechanism of MSA. In empirical experiments, we trained deep neural networks (ResNet and Vision Transformer) on real image datasets to study the existence of MSA.

This repository contains codes with random feature (RF) models.




