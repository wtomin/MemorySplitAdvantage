{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Feature Model on Synthetic Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "class RF_NonLinear_Model(nn.Module):\n",
    "    def __init__(self, p, d, o, coef):\n",
    "        \"\"\"RF_models\n",
    "        \n",
    "        Args:\n",
    "            p (int): the hidden size\n",
    "            d (int): the input feature dimension\n",
    "            o (int): the output dimension\n",
    "            coef (floatl): the ridge regression penalty coefficient\n",
    "        \"\"\"\n",
    "        super(RF_NonLinear_Model, self).__init__()\n",
    "\n",
    "        self.fc1 = nn.Linear(d, p, bias=False)\n",
    "        stdv = 1\n",
    "        self.fc1.weight.data.normal_(mean=0.0, std = stdv) # Gaussian initialization\n",
    "        self.fc2 = nn.Linear(p, o, bias=False)\n",
    "        self.p = p\n",
    "        self.d = d\n",
    "        self.o = o \n",
    "        self.coef = coef\n",
    "\n",
    "    def forward(self, x):\n",
    "        z = 1/np.sqrt(self.d) * F.relu(1/np.sqrt(self.d)* torch.mm(x, self.fc1.weight.data.t()))\n",
    "        out = np.sqrt(self.d) * torch.mm(self.fc2.weight.data, z.t())\n",
    "        return out.t()\n",
    "    def optimize_second_layer(self, x, y):\n",
    "        N = x.size(0)\n",
    "        z = 1/np.sqrt(self.d) * F.relu(1/np.sqrt(self.d)* torch.mm(x, self.fc1.weight.data.t()))\n",
    "        identity = torch.eye(self.p)\n",
    "        identity = identity.to(x.device)\n",
    "        beta = torch.mm(z.t(), z) + self.coef*self.p*N/(self.d**2) * identity\n",
    "        beta = torch.mm(z, torch.inverse(beta))\n",
    "        a = 1/np.sqrt(self.d) * torch.mm(y.t(), beta) \n",
    "        self.fc2.weight = torch.nn.Parameter(a)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import queue\n",
    "class Ensemble_Two_Layer_NN(object):\n",
    "    def __init__(self, n_classifiers, p, d=784, o=10, coef=1e-1):\n",
    "        \"\"\"Ensemble_Two_Layer_NN\n",
    "        \n",
    "        Args:\n",
    "            p (int): the hidden size\n",
    "            d (int, optional): the input feature dimension\n",
    "            o (int, optional): the output dimension\n",
    "            coef (float, optional): the ridge regression penalty coefficient\n",
    "        \"\"\"\n",
    "        self.n_classifiers = n_classifiers\n",
    "        self.p = p\n",
    "        self.d = d \n",
    "        self.o = o \n",
    "        self.coef = coef\n",
    "        self.learners = queue.LifoQueue(maxsize = self.n_classifiers)\n",
    "        self.MODEL_TYPE = RF_NonLinear_Model\n",
    "    def __len__(self):\n",
    "        return len(self.learners.queue)\n",
    "    \n",
    "    def train_one_classifier(self, x, y):\n",
    "        model = self.MODEL_TYPE(self.p, self.d, self.o, self.coef)\n",
    "        if x.is_cuda:\n",
    "            model.cuda()\n",
    "        rho = 1/self.n_classifiers\n",
    "        model.optimize_second_layer(x, y)\n",
    "        self.learners.put([model, rho])\n",
    "    def put_model_rho(self, model, rho):\n",
    "        self.learners.put([model, rho])\n",
    "    def get_init_model(self, cuda=True):\n",
    "        model = self.MODEL_TYPE(self.p, self.d, self.o, self.coef)\n",
    "        if cuda:\n",
    "            model.cuda()\n",
    "        return model\n",
    "    def cuda(self):\n",
    "        if len(self) == 0:\n",
    "            return \n",
    "        else:\n",
    "            for model, rho in self.learners.queue:\n",
    "                model.cuda()\n",
    "            return\n",
    "    def train(self):\n",
    "        if len(self)!=0:\n",
    "            for model, rho in self.learners.queue:\n",
    "                model.train()\n",
    "    def eval(self):\n",
    "        if len(self)!=0:\n",
    "            for model, rho in self.learners.queue:\n",
    "                model.eval()\n",
    "    def forward(self, x):\n",
    "        Bs = x.size(0)\n",
    "        if len(self) == 0:\n",
    "            zeros = torch.zeros(Bs, self.o)\n",
    "            zeros = zeros.to(x.device)\n",
    "            return zeros\n",
    "        else:\n",
    "            outputs = torch.zeros(Bs, self.o)\n",
    "            outputs = outputs.to(x.device) \n",
    "            for model, rho in self.learners.queue:\n",
    "                output = model(x)\n",
    "                outputs += rho*output\n",
    "            return outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import numpy as np\n",
    "from typing import Type, Any, Callable, Union, List, Optional\n",
    "\n",
    "def sample_true_distribution(feature_dim, output_dim, norm = 1):\n",
    "    beta = np.random.multivariate_normal(np.zeros([feature_dim]), np.eye(feature_dim)/feature_dim, \n",
    "        size=(output_dim)).T\n",
    "    beta = beta/np.linalg.norm(beta, ord=2) * norm # F norm = norm\n",
    "    beta = beta.astype('float32')\n",
    "    return beta\n",
    "def random_draw_samples(beta, feature_dim, output_dim, num_samples):\n",
    "    data = np.random.multivariate_normal(\n",
    "        np.zeros([feature_dim])  , \n",
    "        np.eye(feature_dim), \n",
    "        size=(num_samples)) #X ~ N(0,1)\n",
    "    data = data.astype('float32')\n",
    "    targets = np.matmul(data, beta)\n",
    "    targets = targets.astype('float32')\n",
    "    return data, targets\n",
    "\n",
    "def sample_nosie_to_data(data, targets, output_dim, variance):\n",
    "\n",
    "    noises = np.random.multivariate_normal(\n",
    "        np.zeros([output_dim]), \n",
    "        np.eye(output_dim)* (variance),\n",
    "        size = (len(targets)))\n",
    "    noises = noises.astype('float32')\n",
    "    return data, targets + noises\n",
    "def sample_dataset(feature_dim, output_dim, F_norm, SNR, num_samples, beta=None):\n",
    "\n",
    "    if beta is None:\n",
    "        beta = sample_true_distribution(feature_dim, output_dim, F_norm)\n",
    "    data, targets = random_draw_samples(beta, feature_dim, output_dim, num_samples)\n",
    "    if SNR !=0:\n",
    "        variance = F_norm * SNR\n",
    "        data, targets = sample_nosie_to_data(data, targets, output_dim, variance)\n",
    "    return torch.from_numpy(data), torch.from_numpy(targets)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "import copy \n",
    "\n",
    "# def get_subsample_dataset(trainset, subset):\n",
    "#     trainsubset = copy.deepcopy(trainset)\n",
    "#     trainsubset.data = [trainsubset.data[index] for index in subset]\n",
    "#     trainsubset.targets = [trainsubset.targets[index] for index in subset]\n",
    "#     return trainsubset\n",
    "def fix_width_number(width, n_classifiers):\n",
    "    return max(1, width//n_classifiers)\n",
    "\n",
    "# Training\n",
    "def train(net, train_beta, train_size, feature_dim, output_dim, F_norm, SNR):\n",
    "    net.train()\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    trainset = sample_dataset(feature_dim, output_dim, F_norm, SNR, train_size, beta = train_beta)\n",
    "    trainset = TensorDataset(*trainset)\n",
    "    trainloader = torch.utils.data.DataLoader(trainset, batch_size=len(trainset), shuffle=True)\n",
    "    trainloader = iter(trainloader)\n",
    "    with torch.no_grad():\n",
    "        inputs, targets = next(trainloader)\n",
    "        Bs = inputs.size(0)\n",
    "        inputs = inputs.reshape(Bs, -1)\n",
    "        inputs, targets = inputs.cuda(), targets.cuda()\n",
    "        for _ in range(net.n_classifiers):\n",
    "            net.train_one_classifier(inputs, targets)\n",
    "        outputs = net.forward(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        train_loss = loss.item() * outputs.numel()\n",
    "        total = targets.size(0)\n",
    "    return train_loss/ total\n",
    "\n",
    "# Test\n",
    "def test(net, testloader):\n",
    "    net.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs, targets) in enumerate(testloader):\n",
    "            inputs, targets = inputs.cuda(), targets.cuda()\n",
    "            Bs = inputs.size(0)\n",
    "            inputs = inputs.reshape(Bs, -1)\n",
    "            outputs = net.forward(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            test_loss += loss.item() * outputs.numel()\n",
    "            total += targets.size(0)\n",
    "    return test_loss / total\n",
    "\n",
    "def compute_bias_variance(net, testloader, trial, OUTPUST_SUM, OUTPUTS_SUMNORMSQUARED):\n",
    "    net.eval()\n",
    "    bias2 = 0\n",
    "    variance = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs, targets) in enumerate(testloader):\n",
    "            inputs, targets = inputs.cuda(), targets.cuda()\n",
    "            Bs = inputs.size(0)\n",
    "            inputs = inputs.reshape(Bs, -1)\n",
    "            outputs = net.forward(inputs)\n",
    "            OUTPUST_SUM[total:(total + targets.size(0)), :] += outputs\n",
    "            OUTPUTS_SUMNORMSQUARED[total:total + targets.size(0)] += outputs.norm(dim=1) ** 2.0\n",
    "\n",
    "            bias2 += (OUTPUST_SUM[total:total + targets.size(0), :] / (trial + 1) - targets).norm() ** 2.0\n",
    "            variance += OUTPUTS_SUMNORMSQUARED[total:total + targets.size(0)].sum()/(trial + 1) - (OUTPUST_SUM[total:total + targets.size(0), :]/(trial + 1)).norm() ** 2.0\n",
    "            total += targets.size(0)\n",
    "\n",
    "    return bias2 / total, variance / total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the synthetic dataset:\n",
    "$y=X\\beta + \\epsilon_\\mu, ||\\beta|| = F, \\epsilon_{mu} ~ \\mathcal{N}(0, 1), SNR = F/\\tau$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "feature_dim = 400\n",
    "num_classes = 1\n",
    "SNR = 1\n",
    "test_size = 10000\n",
    "beta = sample_true_distribution(feature_dim, num_classes, norm = 1)\n",
    "#trainset = Synthetic_Dataset(feature_dim=feature_dim, output_dim=1, num_samples=50000, seed=10, SNR = SNR)\n",
    "testset = sample_dataset(feature_dim, num_classes, F_norm = 1, SNR =0., num_samples=test_size, beta = beta)\n",
    "testset = TensorDataset(*testset)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=100, shuffle=False, num_workers=4)\n",
    "# loss definition\n",
    "criterion = nn.MSELoss(reduction='mean').cuda()\n",
    "\n",
    "num_trials = 50\n",
    "coef = 0.01\n",
    "N_Ds = [1]\n",
    "train_sizes = [int(np.around(x*feature_dim)) for x in N_Ds]\n",
    "P_Ns = 10** np.linspace(-2, 1, 50)\n",
    "\n",
    "outdir = 'synthetic_coef_{}'.format(coef)\n",
    "if not os.path.exists(outdir):\n",
    "    os.makedirs(outdir)\n",
    "\n",
    "def run_exps_ridge(train_sizes, N_Ds, P_Ns, train_beta, test_size, feature_dim, num_classes, num_trials, coef,\n",
    "             outdir, save_csv, SNR, K = 1, F_norm= 1):\n",
    "    df = pd.DataFrame()\n",
    "    # When training single NN\n",
    "    for train_size in train_sizes:\n",
    "        hidden_sizes = P_Ns * train_size\n",
    "        hidden_sizes = np.unique([int(np.around(x)) for x in hidden_sizes])\n",
    "        for hidden_size in hidden_sizes:\n",
    "            TRAIN_LOSS_SUM = 0.0\n",
    "            TEST_LOSS_SUM = 0.0\n",
    "            #permute_index = np.random.permutation(len(trainset))\n",
    "            OUTPUST_SUM = torch.Tensor(test_size, num_classes).zero_().cuda()\n",
    "            OUTPUTS_SUMNORMSQUARED = torch.Tensor(test_size).zero_().cuda()\n",
    "            for trial in range(num_trials):\n",
    "                net = Ensemble_Two_Layer_NN(n_classifiers = K, p = fix_width_number(hidden_size, K), d=feature_dim, o=num_classes, coef=coef)\n",
    "                net.cuda()\n",
    "                train_loss = train(net, train_beta, train_size, feature_dim, num_classes, F_norm, SNR)\n",
    "                test_loss = test(net, testloader)\n",
    "\n",
    "                TRAIN_LOSS_SUM += train_loss\n",
    "                TEST_LOSS_SUM += test_loss\n",
    "\n",
    "                # compute bias and variance\n",
    "                bias2, variance = compute_bias_variance(net, testloader, trial, OUTPUST_SUM, OUTPUTS_SUMNORMSQUARED)\n",
    "                variance_unbias = variance * num_trials / (num_trials - 1.0)\n",
    "                bias2_unbias = TEST_LOSS_SUM / (trial + 1) - variance_unbias\n",
    "                print('Train size: [{}] hidden size: [{}] trial: {}, train_loss: {:.6f}, test loss: {:.6f}, bias2: {}, variance: {}'.format(\n",
    "                    train_size, hidden_size,\n",
    "                    trial, TRAIN_LOSS_SUM / (trial + 1),  TEST_LOSS_SUM / (trial + 1),\n",
    "                    bias2_unbias, variance_unbias))\n",
    "                torch.cuda.empty_cache()\n",
    "            print('#'*50)\n",
    "            df = df.append({'train_size': train_size, 'hidden_size':hidden_size, \n",
    "                            'train_loss': TRAIN_LOSS_SUM / (trial + 1), \n",
    "                            'test_loss': TEST_LOSS_SUM / (trial + 1), \n",
    "                           'variance': variance_unbias.item(),\n",
    "                           'bias2': bias2_unbias.item()}, ignore_index=True)\n",
    "            df.to_csv(os.path.join(outdir, save_csv))\n",
    "    df.to_csv(os.path.join(outdir, save_csv))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [4] trial: 0, train_loss: 2.123276, test loss: 1.002749, bias2: 1.0027494430541992, variance: 0.0\n",
      "Train size: [400] hidden size: [4] trial: 1, train_loss: 2.111441, test loss: 0.995584, bias2: 0.9811515212059021, variance: 0.014432883821427822\n",
      "Train size: [400] hidden size: [4] trial: 2, train_loss: 2.072924, test loss: 0.999493, bias2: 0.9855545163154602, variance: 0.0139383003115654\n",
      "Train size: [400] hidden size: [4] trial: 3, train_loss: 2.124720, test loss: 1.006568, bias2: 0.9885440468788147, variance: 0.018023541197180748\n",
      "Train size: [400] hidden size: [4] trial: 4, train_loss: 2.115449, test loss: 1.009124, bias2: 0.9861704707145691, variance: 0.02295321598649025\n",
      "Train size: [400] hidden size: [4] trial: 5, train_loss: 2.050113, test loss: 1.009065, bias2: 0.9869535565376282, variance: 0.0221118051558733\n",
      "Train size: [400] hidden size: [4] trial: 6, train_loss: 2.027403, test loss: 1.009730, bias2: 0.9885431528091431, variance: 0.02118685655295849\n",
      "Train size: [400] hidden size: [4] trial: 7, train_loss: 2.004868, test loss: 1.008064, bias2: 0.9874477982521057, variance: 0.020616373047232628\n",
      "Train size: [400] hidden size: [4] trial: 8, train_loss: 2.008798, test loss: 1.010514, bias2: 0.9877377152442932, variance: 0.022776173427700996\n",
      "Train size: [400] hidden size: [4] trial: 9, train_loss: 2.009269, test loss: 1.010660, bias2: 0.9885662198066711, variance: 0.022093499079346657\n",
      "Train size: [400] hidden size: [4] trial: 10, train_loss: 1.996502, test loss: 1.010045, bias2: 0.9896499514579773, variance: 0.020395364612340927\n",
      "Train size: [400] hidden size: [4] trial: 11, train_loss: 1.995411, test loss: 1.008950, bias2: 0.988898515701294, variance: 0.020051240921020508\n",
      "Train size: [400] hidden size: [4] trial: 12, train_loss: 2.010771, test loss: 1.008806, bias2: 0.9899065494537354, variance: 0.018899109214544296\n",
      "Train size: [400] hidden size: [4] trial: 13, train_loss: 2.012792, test loss: 1.007870, bias2: 0.9889460206031799, variance: 0.018923839554190636\n",
      "Train size: [400] hidden size: [4] trial: 14, train_loss: 2.003580, test loss: 1.008538, bias2: 0.9897005558013916, variance: 0.01883697137236595\n",
      "Train size: [400] hidden size: [4] trial: 15, train_loss: 1.999865, test loss: 1.008159, bias2: 0.9888235926628113, variance: 0.019335420802235603\n",
      "Train size: [400] hidden size: [4] trial: 16, train_loss: 1.999765, test loss: 1.007858, bias2: 0.9885281324386597, variance: 0.019329523667693138\n",
      "Train size: [400] hidden size: [4] trial: 17, train_loss: 2.007020, test loss: 1.007657, bias2: 0.9890716075897217, variance: 0.01858559250831604\n",
      "Train size: [400] hidden size: [4] trial: 18, train_loss: 2.002476, test loss: 1.007549, bias2: 0.9889643788337708, variance: 0.01858428865671158\n",
      "Train size: [400] hidden size: [4] trial: 19, train_loss: 2.001274, test loss: 1.008325, bias2: 0.9881281852722168, variance: 0.020197253674268723\n",
      "Train size: [400] hidden size: [4] trial: 20, train_loss: 2.003137, test loss: 1.008859, bias2: 0.9880159497261047, variance: 0.020843198522925377\n",
      "Train size: [400] hidden size: [4] trial: 21, train_loss: 2.011267, test loss: 1.009903, bias2: 0.9881194829940796, variance: 0.02178345061838627\n",
      "Train size: [400] hidden size: [4] trial: 22, train_loss: 2.002484, test loss: 1.009992, bias2: 0.988200306892395, variance: 0.021791689097881317\n",
      "Train size: [400] hidden size: [4] trial: 23, train_loss: 1.988205, test loss: 1.011453, bias2: 0.9885603189468384, variance: 0.02289292961359024\n",
      "Train size: [400] hidden size: [4] trial: 24, train_loss: 1.980782, test loss: 1.012682, bias2: 0.9889190793037415, variance: 0.023762887343764305\n",
      "Train size: [400] hidden size: [4] trial: 25, train_loss: 1.968167, test loss: 1.012226, bias2: 0.9891220331192017, variance: 0.023104097694158554\n",
      "Train size: [400] hidden size: [4] trial: 26, train_loss: 1.975215, test loss: 1.012633, bias2: 0.9889017343521118, variance: 0.02373160980641842\n",
      "Train size: [400] hidden size: [4] trial: 27, train_loss: 1.975876, test loss: 1.012316, bias2: 0.989113986492157, variance: 0.023201750591397285\n",
      "Train size: [400] hidden size: [4] trial: 28, train_loss: 1.978299, test loss: 1.012530, bias2: 0.9894682168960571, variance: 0.02306200936436653\n",
      "Train size: [400] hidden size: [4] trial: 29, train_loss: 1.981800, test loss: 1.012552, bias2: 0.9895583987236023, variance: 0.02299361675977707\n",
      "Train size: [400] hidden size: [4] trial: 30, train_loss: 1.984262, test loss: 1.012853, bias2: 0.9899874329566956, variance: 0.02286592684686184\n",
      "Train size: [400] hidden size: [4] trial: 31, train_loss: 1.993958, test loss: 1.012788, bias2: 0.9903327226638794, variance: 0.022455589845776558\n",
      "Train size: [400] hidden size: [4] trial: 32, train_loss: 1.988586, test loss: 1.012965, bias2: 0.990402102470398, variance: 0.02256336249411106\n",
      "Train size: [400] hidden size: [4] trial: 33, train_loss: 1.988098, test loss: 1.012602, bias2: 0.989787220954895, variance: 0.02281496673822403\n",
      "Train size: [400] hidden size: [4] trial: 34, train_loss: 1.989647, test loss: 1.012331, bias2: 0.989675760269165, variance: 0.022655386477708817\n",
      "Train size: [400] hidden size: [4] trial: 35, train_loss: 1.985682, test loss: 1.013277, bias2: 0.9898661971092224, variance: 0.023411067202687263\n",
      "Train size: [400] hidden size: [4] trial: 36, train_loss: 1.982257, test loss: 1.012902, bias2: 0.9900885820388794, variance: 0.022813767194747925\n",
      "Train size: [400] hidden size: [4] trial: 37, train_loss: 1.977373, test loss: 1.012901, bias2: 0.9901191592216492, variance: 0.022781403735280037\n",
      "Train size: [400] hidden size: [4] trial: 38, train_loss: 1.974768, test loss: 1.013329, bias2: 0.9906416535377502, variance: 0.02268734760582447\n",
      "Train size: [400] hidden size: [4] trial: 39, train_loss: 1.977179, test loss: 1.012924, bias2: 0.9901905059814453, variance: 0.02273358777165413\n",
      "Train size: [400] hidden size: [4] trial: 40, train_loss: 1.979897, test loss: 1.012873, bias2: 0.9900084137916565, variance: 0.02286451868712902\n",
      "Train size: [400] hidden size: [4] trial: 41, train_loss: 1.983158, test loss: 1.012634, bias2: 0.9901415109634399, variance: 0.022492043673992157\n",
      "Train size: [400] hidden size: [4] trial: 42, train_loss: 1.987259, test loss: 1.012800, bias2: 0.9902333617210388, variance: 0.022566281259059906\n",
      "Train size: [400] hidden size: [4] trial: 43, train_loss: 1.982440, test loss: 1.013719, bias2: 0.9906740784645081, variance: 0.02304478920996189\n",
      "Train size: [400] hidden size: [4] trial: 44, train_loss: 1.983598, test loss: 1.013690, bias2: 0.9905873537063599, variance: 0.023102134466171265\n",
      "Train size: [400] hidden size: [4] trial: 45, train_loss: 1.987038, test loss: 1.014997, bias2: 0.9899706244468689, variance: 0.025025995448231697\n",
      "Train size: [400] hidden size: [4] trial: 46, train_loss: 1.981743, test loss: 1.015052, bias2: 0.989952564239502, variance: 0.025099176913499832\n",
      "Train size: [400] hidden size: [4] trial: 47, train_loss: 1.986006, test loss: 1.014770, bias2: 0.9898282885551453, variance: 0.024942122399806976\n",
      "Train size: [400] hidden size: [4] trial: 48, train_loss: 1.985855, test loss: 1.014879, bias2: 0.9893525242805481, variance: 0.02552645280957222\n",
      "Train size: [400] hidden size: [4] trial: 49, train_loss: 1.992400, test loss: 1.014593, bias2: 0.9895508289337158, variance: 0.025042172521352768\n",
      "##################################################\n",
      "Train size: [400] hidden size: [5] trial: 0, train_loss: 1.907261, test loss: 1.033051, bias2: 1.0330513715744019, variance: 0.0\n",
      "Train size: [400] hidden size: [5] trial: 1, train_loss: 1.903180, test loss: 1.025273, bias2: 1.0059880018234253, variance: 0.019284982234239578\n",
      "Train size: [400] hidden size: [5] trial: 2, train_loss: 1.922609, test loss: 1.018344, bias2: 0.9977004528045654, variance: 0.02064373530447483\n",
      "Train size: [400] hidden size: [5] trial: 3, train_loss: 1.928051, test loss: 1.017703, bias2: 0.996101975440979, variance: 0.02160106785595417\n",
      "Train size: [400] hidden size: [5] trial: 4, train_loss: 1.896311, test loss: 1.023963, bias2: 0.9933699369430542, variance: 0.03059282712638378\n",
      "Train size: [400] hidden size: [5] trial: 5, train_loss: 1.883368, test loss: 1.031941, bias2: 0.9989085793495178, variance: 0.0330323725938797\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [5] trial: 6, train_loss: 1.910596, test loss: 1.035590, bias2: 0.9988950490951538, variance: 0.03669526427984238\n",
      "Train size: [400] hidden size: [5] trial: 7, train_loss: 1.933857, test loss: 1.035917, bias2: 0.9970105886459351, variance: 0.03890598565340042\n",
      "Train size: [400] hidden size: [5] trial: 8, train_loss: 1.968013, test loss: 1.034248, bias2: 0.9961084127426147, variance: 0.03813984990119934\n",
      "Train size: [400] hidden size: [5] trial: 9, train_loss: 1.956436, test loss: 1.035287, bias2: 0.9966738224029541, variance: 0.03861329331994057\n",
      "Train size: [400] hidden size: [5] trial: 10, train_loss: 1.939420, test loss: 1.036898, bias2: 0.9971624612808228, variance: 0.03973570093512535\n",
      "Train size: [400] hidden size: [5] trial: 11, train_loss: 1.940461, test loss: 1.034283, bias2: 0.9964894652366638, variance: 0.037793103605508804\n",
      "Train size: [400] hidden size: [5] trial: 12, train_loss: 1.964419, test loss: 1.033358, bias2: 0.9960460662841797, variance: 0.037312041968107224\n",
      "Train size: [400] hidden size: [5] trial: 13, train_loss: 1.958470, test loss: 1.032176, bias2: 0.9961860179901123, variance: 0.03598952665925026\n",
      "Train size: [400] hidden size: [5] trial: 14, train_loss: 1.952481, test loss: 1.029673, bias2: 0.9947639107704163, variance: 0.03490858152508736\n",
      "Train size: [400] hidden size: [5] trial: 15, train_loss: 1.951066, test loss: 1.028544, bias2: 0.9942966103553772, variance: 0.03424708545207977\n",
      "Train size: [400] hidden size: [5] trial: 16, train_loss: 1.950393, test loss: 1.027271, bias2: 0.9924285411834717, variance: 0.03484251722693443\n",
      "Train size: [400] hidden size: [5] trial: 17, train_loss: 1.959478, test loss: 1.026499, bias2: 0.992655873298645, variance: 0.03384330868721008\n",
      "Train size: [400] hidden size: [5] trial: 18, train_loss: 1.965750, test loss: 1.025378, bias2: 0.9925469160079956, variance: 0.032831210643053055\n",
      "Train size: [400] hidden size: [5] trial: 19, train_loss: 1.984583, test loss: 1.026977, bias2: 0.9912402033805847, variance: 0.03573639318346977\n",
      "Train size: [400] hidden size: [5] trial: 20, train_loss: 1.995920, test loss: 1.026762, bias2: 0.9906163215637207, variance: 0.036146026104688644\n",
      "Train size: [400] hidden size: [5] trial: 21, train_loss: 1.989608, test loss: 1.026698, bias2: 0.990903913974762, variance: 0.03579441457986832\n",
      "Train size: [400] hidden size: [5] trial: 22, train_loss: 1.993225, test loss: 1.026333, bias2: 0.9909160137176514, variance: 0.035416632890701294\n",
      "Train size: [400] hidden size: [5] trial: 23, train_loss: 1.988974, test loss: 1.026300, bias2: 0.9902079105377197, variance: 0.03609213978052139\n",
      "Train size: [400] hidden size: [5] trial: 24, train_loss: 1.994885, test loss: 1.025784, bias2: 0.9907501339912415, variance: 0.03503400832414627\n",
      "Train size: [400] hidden size: [5] trial: 25, train_loss: 1.992757, test loss: 1.026475, bias2: 0.9911038875579834, variance: 0.035371411591768265\n",
      "Train size: [400] hidden size: [5] trial: 26, train_loss: 1.987661, test loss: 1.026645, bias2: 0.9919643402099609, variance: 0.034680817276239395\n",
      "Train size: [400] hidden size: [5] trial: 27, train_loss: 1.990219, test loss: 1.026609, bias2: 0.9911620616912842, variance: 0.0354471392929554\n",
      "Train size: [400] hidden size: [5] trial: 28, train_loss: 1.990309, test loss: 1.026742, bias2: 0.9918046593666077, variance: 0.03493743762373924\n",
      "Train size: [400] hidden size: [5] trial: 29, train_loss: 1.990390, test loss: 1.026047, bias2: 0.9908268451690674, variance: 0.03522005304694176\n",
      "Train size: [400] hidden size: [5] trial: 30, train_loss: 1.988445, test loss: 1.025582, bias2: 0.9907286763191223, variance: 0.03485315665602684\n",
      "Train size: [400] hidden size: [5] trial: 31, train_loss: 1.991985, test loss: 1.025317, bias2: 0.9912521839141846, variance: 0.03406502306461334\n",
      "Train size: [400] hidden size: [5] trial: 32, train_loss: 1.993468, test loss: 1.025195, bias2: 0.9908474087715149, variance: 0.03434758260846138\n",
      "Train size: [400] hidden size: [5] trial: 33, train_loss: 1.987427, test loss: 1.025009, bias2: 0.9908238649368286, variance: 0.034185271710157394\n",
      "Train size: [400] hidden size: [5] trial: 34, train_loss: 1.988066, test loss: 1.024710, bias2: 0.9908371567726135, variance: 0.03387315943837166\n",
      "Train size: [400] hidden size: [5] trial: 35, train_loss: 1.986675, test loss: 1.024600, bias2: 0.9904884099960327, variance: 0.03411150723695755\n",
      "Train size: [400] hidden size: [5] trial: 36, train_loss: 1.982265, test loss: 1.025111, bias2: 0.9906235337257385, variance: 0.03448757156729698\n",
      "Train size: [400] hidden size: [5] trial: 37, train_loss: 1.986945, test loss: 1.024447, bias2: 0.9907921552658081, variance: 0.033654578030109406\n",
      "Train size: [400] hidden size: [5] trial: 38, train_loss: 1.992311, test loss: 1.023908, bias2: 0.9906214475631714, variance: 0.0332864411175251\n",
      "Train size: [400] hidden size: [5] trial: 39, train_loss: 1.989447, test loss: 1.023614, bias2: 0.9901875257492065, variance: 0.033426377922296524\n",
      "Train size: [400] hidden size: [5] trial: 40, train_loss: 1.990285, test loss: 1.024528, bias2: 0.989905834197998, variance: 0.03462241217494011\n",
      "Train size: [400] hidden size: [5] trial: 41, train_loss: 1.988479, test loss: 1.024403, bias2: 0.9897863864898682, variance: 0.034616366028785706\n",
      "Train size: [400] hidden size: [5] trial: 42, train_loss: 1.985599, test loss: 1.024311, bias2: 0.9884257316589355, variance: 0.03588511794805527\n",
      "Train size: [400] hidden size: [5] trial: 43, train_loss: 1.981601, test loss: 1.024374, bias2: 0.9881136417388916, variance: 0.036260586231946945\n",
      "Train size: [400] hidden size: [5] trial: 44, train_loss: 1.987843, test loss: 1.024683, bias2: 0.9885252714157104, variance: 0.03615749254822731\n",
      "Train size: [400] hidden size: [5] trial: 45, train_loss: 1.987473, test loss: 1.025396, bias2: 0.9886898994445801, variance: 0.036706238985061646\n",
      "Train size: [400] hidden size: [5] trial: 46, train_loss: 1.987739, test loss: 1.025336, bias2: 0.9887937903404236, variance: 0.036542605608701706\n",
      "Train size: [400] hidden size: [5] trial: 47, train_loss: 1.988829, test loss: 1.024832, bias2: 0.9885124564170837, variance: 0.036319930106401443\n",
      "Train size: [400] hidden size: [5] trial: 48, train_loss: 1.989057, test loss: 1.024571, bias2: 0.988772988319397, variance: 0.035797614604234695\n",
      "Train size: [400] hidden size: [5] trial: 49, train_loss: 1.982857, test loss: 1.025289, bias2: 0.9885410070419312, variance: 0.03674837946891785\n",
      "##################################################\n",
      "Train size: [400] hidden size: [6] trial: 0, train_loss: 1.883444, test loss: 1.016893, bias2: 1.016892910003662, variance: -7.298527754384665e-11\n",
      "Train size: [400] hidden size: [6] trial: 1, train_loss: 1.939951, test loss: 1.040335, bias2: 1.0150634050369263, variance: 0.025271732360124588\n",
      "Train size: [400] hidden size: [6] trial: 2, train_loss: 1.894976, test loss: 1.030841, bias2: 0.9977424144744873, variance: 0.033098552376031876\n",
      "Train size: [400] hidden size: [6] trial: 3, train_loss: 1.970873, test loss: 1.026811, bias2: 0.9950063824653625, variance: 0.03180462121963501\n",
      "Train size: [400] hidden size: [6] trial: 4, train_loss: 2.002613, test loss: 1.020908, bias2: 0.9869265556335449, variance: 0.033981192857027054\n",
      "Train size: [400] hidden size: [6] trial: 5, train_loss: 2.006192, test loss: 1.020232, bias2: 0.986594557762146, variance: 0.033637870103120804\n",
      "Train size: [400] hidden size: [6] trial: 6, train_loss: 2.031675, test loss: 1.017388, bias2: 0.9859417080879211, variance: 0.03144677355885506\n",
      "Train size: [400] hidden size: [6] trial: 7, train_loss: 2.014494, test loss: 1.018117, bias2: 0.9881896376609802, variance: 0.029926955699920654\n",
      "Train size: [400] hidden size: [6] trial: 8, train_loss: 2.007878, test loss: 1.019897, bias2: 0.9890268445014954, variance: 0.030869677662849426\n",
      "Train size: [400] hidden size: [6] trial: 9, train_loss: 2.013726, test loss: 1.022010, bias2: 0.9890774488449097, variance: 0.03293249011039734\n",
      "Train size: [400] hidden size: [6] trial: 10, train_loss: 2.019578, test loss: 1.023052, bias2: 0.9890490770339966, variance: 0.034002915024757385\n",
      "Train size: [400] hidden size: [6] trial: 11, train_loss: 2.008436, test loss: 1.021384, bias2: 0.9889671206474304, variance: 0.032416507601737976\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [6] trial: 12, train_loss: 1.996232, test loss: 1.020433, bias2: 0.989016056060791, variance: 0.0314168855547905\n",
      "Train size: [400] hidden size: [6] trial: 13, train_loss: 1.988262, test loss: 1.020601, bias2: 0.9891741871833801, variance: 0.031426701694726944\n",
      "Train size: [400] hidden size: [6] trial: 14, train_loss: 1.989768, test loss: 1.022780, bias2: 0.9898362159729004, variance: 0.0329439602792263\n",
      "Train size: [400] hidden size: [6] trial: 15, train_loss: 1.998276, test loss: 1.024321, bias2: 0.989597737789154, variance: 0.03472370281815529\n",
      "Train size: [400] hidden size: [6] trial: 16, train_loss: 1.978723, test loss: 1.027201, bias2: 0.9897540211677551, variance: 0.037446655333042145\n",
      "Train size: [400] hidden size: [6] trial: 17, train_loss: 1.978566, test loss: 1.026097, bias2: 0.9903647899627686, variance: 0.03573225438594818\n",
      "Train size: [400] hidden size: [6] trial: 18, train_loss: 1.982897, test loss: 1.024806, bias2: 0.9887753129005432, variance: 0.03603106364607811\n",
      "Train size: [400] hidden size: [6] trial: 19, train_loss: 1.972337, test loss: 1.024201, bias2: 0.9885058403015137, variance: 0.03569508343935013\n",
      "Train size: [400] hidden size: [6] trial: 20, train_loss: 1.968415, test loss: 1.023776, bias2: 0.9879097938537598, variance: 0.035866767168045044\n",
      "Train size: [400] hidden size: [6] trial: 21, train_loss: 1.971856, test loss: 1.023656, bias2: 0.9870737791061401, variance: 0.03658248484134674\n",
      "Train size: [400] hidden size: [6] trial: 22, train_loss: 1.973563, test loss: 1.022284, bias2: 0.9863359928131104, variance: 0.03594818338751793\n",
      "Train size: [400] hidden size: [6] trial: 23, train_loss: 1.971323, test loss: 1.021521, bias2: 0.9852378368377686, variance: 0.03628351539373398\n",
      "Train size: [400] hidden size: [6] trial: 24, train_loss: 1.975737, test loss: 1.021291, bias2: 0.9855049848556519, variance: 0.03578627482056618\n",
      "Train size: [400] hidden size: [6] trial: 25, train_loss: 1.974251, test loss: 1.022065, bias2: 0.986533522605896, variance: 0.03553173318505287\n",
      "Train size: [400] hidden size: [6] trial: 26, train_loss: 1.974979, test loss: 1.021897, bias2: 0.9867226481437683, variance: 0.03517381474375725\n",
      "Train size: [400] hidden size: [6] trial: 27, train_loss: 1.973978, test loss: 1.020765, bias2: 0.9847931265830994, variance: 0.03597217798233032\n",
      "Train size: [400] hidden size: [6] trial: 28, train_loss: 1.975685, test loss: 1.020778, bias2: 0.9848787188529968, variance: 0.03589945659041405\n",
      "Train size: [400] hidden size: [6] trial: 29, train_loss: 1.977095, test loss: 1.022766, bias2: 0.9847669005393982, variance: 0.03799957036972046\n",
      "Train size: [400] hidden size: [6] trial: 30, train_loss: 1.985606, test loss: 1.023001, bias2: 0.985682487487793, variance: 0.03731837868690491\n",
      "Train size: [400] hidden size: [6] trial: 31, train_loss: 1.976850, test loss: 1.023148, bias2: 0.9852316975593567, variance: 0.037916235625743866\n",
      "Train size: [400] hidden size: [6] trial: 32, train_loss: 1.977207, test loss: 1.022451, bias2: 0.984821081161499, variance: 0.037630073726177216\n",
      "Train size: [400] hidden size: [6] trial: 33, train_loss: 1.979490, test loss: 1.021834, bias2: 0.9839391708374023, variance: 0.037895187735557556\n",
      "Train size: [400] hidden size: [6] trial: 34, train_loss: 1.979225, test loss: 1.022471, bias2: 0.9842936396598816, variance: 0.03817717358469963\n",
      "Train size: [400] hidden size: [6] trial: 35, train_loss: 1.976305, test loss: 1.022409, bias2: 0.9845675826072693, variance: 0.03784174844622612\n",
      "Train size: [400] hidden size: [6] trial: 36, train_loss: 1.972058, test loss: 1.022094, bias2: 0.9845737814903259, variance: 0.03752010315656662\n",
      "Train size: [400] hidden size: [6] trial: 37, train_loss: 1.966429, test loss: 1.021809, bias2: 0.9835088849067688, variance: 0.03829985111951828\n",
      "Train size: [400] hidden size: [6] trial: 38, train_loss: 1.966312, test loss: 1.021576, bias2: 0.9839121103286743, variance: 0.03766428306698799\n",
      "Train size: [400] hidden size: [6] trial: 39, train_loss: 1.971673, test loss: 1.021424, bias2: 0.9842135906219482, variance: 0.03721082955598831\n",
      "Train size: [400] hidden size: [6] trial: 40, train_loss: 1.972649, test loss: 1.021425, bias2: 0.9839668869972229, variance: 0.03745849058032036\n",
      "Train size: [400] hidden size: [6] trial: 41, train_loss: 1.968431, test loss: 1.022053, bias2: 0.9838479161262512, variance: 0.03820484131574631\n",
      "Train size: [400] hidden size: [6] trial: 42, train_loss: 1.966908, test loss: 1.022094, bias2: 0.9830947518348694, variance: 0.03899924457073212\n",
      "Train size: [400] hidden size: [6] trial: 43, train_loss: 1.966163, test loss: 1.021871, bias2: 0.9832956790924072, variance: 0.038575656712055206\n",
      "Train size: [400] hidden size: [6] trial: 44, train_loss: 1.966584, test loss: 1.021701, bias2: 0.9831634759902954, variance: 0.038537126034498215\n",
      "Train size: [400] hidden size: [6] trial: 45, train_loss: 1.972646, test loss: 1.020953, bias2: 0.9827037453651428, variance: 0.03824908658862114\n",
      "Train size: [400] hidden size: [6] trial: 46, train_loss: 1.972767, test loss: 1.021719, bias2: 0.9834674596786499, variance: 0.038251180201768875\n",
      "Train size: [400] hidden size: [6] trial: 47, train_loss: 1.967691, test loss: 1.021500, bias2: 0.9837773442268372, variance: 0.037723008543252945\n",
      "Train size: [400] hidden size: [6] trial: 48, train_loss: 1.965924, test loss: 1.022142, bias2: 0.9832484722137451, variance: 0.038893233984708786\n",
      "Train size: [400] hidden size: [6] trial: 49, train_loss: 1.966627, test loss: 1.021936, bias2: 0.983410656452179, variance: 0.03852563723921776\n",
      "##################################################\n",
      "Train size: [400] hidden size: [7] trial: 0, train_loss: 1.837111, test loss: 1.014696, bias2: 1.0146962404251099, variance: -1.459705550876933e-10\n",
      "Train size: [400] hidden size: [7] trial: 1, train_loss: 1.895008, test loss: 1.036619, bias2: 1.0182678699493408, variance: 0.018350867554545403\n",
      "Train size: [400] hidden size: [7] trial: 2, train_loss: 1.934501, test loss: 1.032989, bias2: 1.0049983263015747, variance: 0.02799096331000328\n",
      "Train size: [400] hidden size: [7] trial: 3, train_loss: 1.949968, test loss: 1.027687, bias2: 1.0000107288360596, variance: 0.02767683006823063\n",
      "Train size: [400] hidden size: [7] trial: 4, train_loss: 1.919057, test loss: 1.017490, bias2: 0.9798259139060974, variance: 0.037664007395505905\n",
      "Train size: [400] hidden size: [7] trial: 5, train_loss: 1.957259, test loss: 1.018234, bias2: 0.9822648763656616, variance: 0.035969510674476624\n",
      "Train size: [400] hidden size: [7] trial: 6, train_loss: 1.908377, test loss: 1.018520, bias2: 0.9807239174842834, variance: 0.037796441465616226\n",
      "Train size: [400] hidden size: [7] trial: 7, train_loss: 1.927443, test loss: 1.018588, bias2: 0.9795796871185303, variance: 0.0390084870159626\n",
      "Train size: [400] hidden size: [7] trial: 8, train_loss: 1.949494, test loss: 1.025769, bias2: 0.9827505350112915, variance: 0.04301845282316208\n",
      "Train size: [400] hidden size: [7] trial: 9, train_loss: 1.943102, test loss: 1.029153, bias2: 0.9830260872840881, variance: 0.04612667113542557\n",
      "Train size: [400] hidden size: [7] trial: 10, train_loss: 1.920251, test loss: 1.028109, bias2: 0.9820724129676819, variance: 0.04603644832968712\n",
      "Train size: [400] hidden size: [7] trial: 11, train_loss: 1.928298, test loss: 1.025640, bias2: 0.9817252159118652, variance: 0.0439150407910347\n",
      "Train size: [400] hidden size: [7] trial: 12, train_loss: 1.921549, test loss: 1.025586, bias2: 0.9828751683235168, variance: 0.04271048679947853\n",
      "Train size: [400] hidden size: [7] trial: 13, train_loss: 1.932882, test loss: 1.025657, bias2: 0.98061203956604, variance: 0.04504512995481491\n",
      "Train size: [400] hidden size: [7] trial: 14, train_loss: 1.943068, test loss: 1.024660, bias2: 0.9813656210899353, variance: 0.0432947501540184\n",
      "Train size: [400] hidden size: [7] trial: 15, train_loss: 1.939654, test loss: 1.024348, bias2: 0.9819567799568176, variance: 0.04239126667380333\n",
      "Train size: [400] hidden size: [7] trial: 16, train_loss: 1.946657, test loss: 1.023702, bias2: 0.9809005260467529, variance: 0.04280104488134384\n",
      "Train size: [400] hidden size: [7] trial: 17, train_loss: 1.941432, test loss: 1.022958, bias2: 0.9815890789031982, variance: 0.04136896878480911\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [7] trial: 18, train_loss: 1.956773, test loss: 1.024005, bias2: 0.9807645678520203, variance: 0.0432407446205616\n",
      "Train size: [400] hidden size: [7] trial: 19, train_loss: 1.939363, test loss: 1.024471, bias2: 0.9820237159729004, variance: 0.042447082698345184\n",
      "Train size: [400] hidden size: [7] trial: 20, train_loss: 1.942600, test loss: 1.024809, bias2: 0.9807628393173218, variance: 0.04404642432928085\n",
      "Train size: [400] hidden size: [7] trial: 21, train_loss: 1.945725, test loss: 1.024340, bias2: 0.9813212752342224, variance: 0.04301873594522476\n",
      "Train size: [400] hidden size: [7] trial: 22, train_loss: 1.950868, test loss: 1.022721, bias2: 0.9783960580825806, variance: 0.04432525858283043\n",
      "Train size: [400] hidden size: [7] trial: 23, train_loss: 1.957333, test loss: 1.023422, bias2: 0.9786838889122009, variance: 0.044737864285707474\n",
      "Train size: [400] hidden size: [7] trial: 24, train_loss: 1.958199, test loss: 1.022432, bias2: 0.9772244691848755, variance: 0.045207470655441284\n",
      "Train size: [400] hidden size: [7] trial: 25, train_loss: 1.956944, test loss: 1.022841, bias2: 0.9770689606666565, variance: 0.04577214643359184\n",
      "Train size: [400] hidden size: [7] trial: 26, train_loss: 1.961883, test loss: 1.022739, bias2: 0.9775810241699219, variance: 0.0451575331389904\n",
      "Train size: [400] hidden size: [7] trial: 27, train_loss: 1.970917, test loss: 1.025518, bias2: 0.9774617552757263, variance: 0.04805584251880646\n",
      "Train size: [400] hidden size: [7] trial: 28, train_loss: 1.978101, test loss: 1.026019, bias2: 0.9779139161109924, variance: 0.048105038702487946\n",
      "Train size: [400] hidden size: [7] trial: 29, train_loss: 1.974014, test loss: 1.024913, bias2: 0.9778687357902527, variance: 0.047043975442647934\n",
      "Train size: [400] hidden size: [7] trial: 30, train_loss: 1.976337, test loss: 1.024607, bias2: 0.9782164096832275, variance: 0.04639042541384697\n",
      "Train size: [400] hidden size: [7] trial: 31, train_loss: 1.973636, test loss: 1.026251, bias2: 0.9787662029266357, variance: 0.047484543174505234\n",
      "Train size: [400] hidden size: [7] trial: 32, train_loss: 1.975967, test loss: 1.025654, bias2: 0.979092001914978, variance: 0.04656221717596054\n",
      "Train size: [400] hidden size: [7] trial: 33, train_loss: 1.973140, test loss: 1.026369, bias2: 0.9787941575050354, variance: 0.047575078904628754\n",
      "Train size: [400] hidden size: [7] trial: 34, train_loss: 1.967958, test loss: 1.026194, bias2: 0.9793787002563477, variance: 0.0468156635761261\n",
      "Train size: [400] hidden size: [7] trial: 35, train_loss: 1.970020, test loss: 1.026018, bias2: 0.9786725640296936, variance: 0.04734567552804947\n",
      "Train size: [400] hidden size: [7] trial: 36, train_loss: 1.969874, test loss: 1.025602, bias2: 0.9788282513618469, variance: 0.0467732772231102\n",
      "Train size: [400] hidden size: [7] trial: 37, train_loss: 1.960064, test loss: 1.024943, bias2: 0.9780312180519104, variance: 0.04691164195537567\n",
      "Train size: [400] hidden size: [7] trial: 38, train_loss: 1.953755, test loss: 1.024635, bias2: 0.9751541614532471, variance: 0.04948091506958008\n",
      "Train size: [400] hidden size: [7] trial: 39, train_loss: 1.954646, test loss: 1.024470, bias2: 0.9751102924346924, variance: 0.049359798431396484\n",
      "Train size: [400] hidden size: [7] trial: 40, train_loss: 1.952986, test loss: 1.023829, bias2: 0.9753028154373169, variance: 0.048526518046855927\n",
      "Train size: [400] hidden size: [7] trial: 41, train_loss: 1.956048, test loss: 1.023234, bias2: 0.9749791026115417, variance: 0.048255156725645065\n",
      "Train size: [400] hidden size: [7] trial: 42, train_loss: 1.953199, test loss: 1.023481, bias2: 0.975843608379364, variance: 0.04763773828744888\n",
      "Train size: [400] hidden size: [7] trial: 43, train_loss: 1.956896, test loss: 1.023500, bias2: 0.9763167500495911, variance: 0.0471833162009716\n",
      "Train size: [400] hidden size: [7] trial: 44, train_loss: 1.958579, test loss: 1.023413, bias2: 0.9768050909042358, variance: 0.046607956290245056\n",
      "Train size: [400] hidden size: [7] trial: 45, train_loss: 1.963990, test loss: 1.023987, bias2: 0.9768102169036865, variance: 0.047176457941532135\n",
      "Train size: [400] hidden size: [7] trial: 46, train_loss: 1.966594, test loss: 1.023574, bias2: 0.9772000312805176, variance: 0.04637362062931061\n",
      "Train size: [400] hidden size: [7] trial: 47, train_loss: 1.962660, test loss: 1.024970, bias2: 0.9768139123916626, variance: 0.04815581440925598\n",
      "Train size: [400] hidden size: [7] trial: 48, train_loss: 1.957864, test loss: 1.025201, bias2: 0.9761926531791687, variance: 0.0490088053047657\n",
      "Train size: [400] hidden size: [7] trial: 49, train_loss: 1.957906, test loss: 1.025025, bias2: 0.9765558242797852, variance: 0.04846905171871185\n",
      "##################################################\n",
      "Train size: [400] hidden size: [8] trial: 0, train_loss: 1.926907, test loss: 1.023816, bias2: 1.0238157510757446, variance: -4.865684938293313e-11\n",
      "Train size: [400] hidden size: [8] trial: 1, train_loss: 2.009026, test loss: 1.023768, bias2: 1.0064617395401, variance: 0.017306450754404068\n",
      "Train size: [400] hidden size: [8] trial: 2, train_loss: 1.917243, test loss: 1.026603, bias2: 0.9875875115394592, variance: 0.03901522234082222\n",
      "Train size: [400] hidden size: [8] trial: 3, train_loss: 1.923076, test loss: 1.027630, bias2: 0.9865186810493469, variance: 0.04111139103770256\n",
      "Train size: [400] hidden size: [8] trial: 4, train_loss: 1.967844, test loss: 1.026986, bias2: 0.9866688847541809, variance: 0.040317602455616\n",
      "Train size: [400] hidden size: [8] trial: 5, train_loss: 1.956111, test loss: 1.022802, bias2: 0.9793021082878113, variance: 0.04350001737475395\n",
      "Train size: [400] hidden size: [8] trial: 6, train_loss: 1.909154, test loss: 1.026497, bias2: 0.9816303253173828, variance: 0.04486621543765068\n",
      "Train size: [400] hidden size: [8] trial: 7, train_loss: 1.923616, test loss: 1.026203, bias2: 0.9822718501091003, variance: 0.04393083602190018\n",
      "Train size: [400] hidden size: [8] trial: 8, train_loss: 1.914229, test loss: 1.026529, bias2: 0.9786766171455383, variance: 0.04785245656967163\n",
      "Train size: [400] hidden size: [8] trial: 9, train_loss: 1.915492, test loss: 1.028399, bias2: 0.9782168865203857, variance: 0.05018195882439613\n",
      "Train size: [400] hidden size: [8] trial: 10, train_loss: 1.933764, test loss: 1.029300, bias2: 0.9793499708175659, variance: 0.04995035007596016\n",
      "Train size: [400] hidden size: [8] trial: 11, train_loss: 1.956866, test loss: 1.029912, bias2: 0.9806873202323914, variance: 0.04922501742839813\n",
      "Train size: [400] hidden size: [8] trial: 12, train_loss: 1.965128, test loss: 1.030787, bias2: 0.9809046387672424, variance: 0.04988214001059532\n",
      "Train size: [400] hidden size: [8] trial: 13, train_loss: 1.962815, test loss: 1.028801, bias2: 0.9756921529769897, variance: 0.05310894548892975\n",
      "Train size: [400] hidden size: [8] trial: 14, train_loss: 1.959856, test loss: 1.030006, bias2: 0.9736870527267456, variance: 0.056318528950214386\n",
      "Train size: [400] hidden size: [8] trial: 15, train_loss: 1.960341, test loss: 1.030017, bias2: 0.9758648872375488, variance: 0.054151639342308044\n",
      "Train size: [400] hidden size: [8] trial: 16, train_loss: 1.954047, test loss: 1.030013, bias2: 0.9755696058273315, variance: 0.05444326624274254\n",
      "Train size: [400] hidden size: [8] trial: 17, train_loss: 1.949296, test loss: 1.029287, bias2: 0.9754523634910583, variance: 0.05383414402604103\n",
      "Train size: [400] hidden size: [8] trial: 18, train_loss: 1.950374, test loss: 1.029589, bias2: 0.9753344058990479, variance: 0.05425515025854111\n",
      "Train size: [400] hidden size: [8] trial: 19, train_loss: 1.941004, test loss: 1.028752, bias2: 0.9760491847991943, variance: 0.05270257592201233\n",
      "Train size: [400] hidden size: [8] trial: 20, train_loss: 1.947085, test loss: 1.028167, bias2: 0.976212739944458, variance: 0.051954127848148346\n",
      "Train size: [400] hidden size: [8] trial: 21, train_loss: 1.950560, test loss: 1.027098, bias2: 0.977053165435791, variance: 0.050045132637023926\n",
      "Train size: [400] hidden size: [8] trial: 22, train_loss: 1.945770, test loss: 1.027387, bias2: 0.9775811433792114, variance: 0.04980586841702461\n",
      "Train size: [400] hidden size: [8] trial: 23, train_loss: 1.939776, test loss: 1.026953, bias2: 0.9784216284751892, variance: 0.04853169247508049\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [8] trial: 24, train_loss: 1.946859, test loss: 1.026420, bias2: 0.9783458113670349, variance: 0.04807432368397713\n",
      "Train size: [400] hidden size: [8] trial: 25, train_loss: 1.941560, test loss: 1.025967, bias2: 0.9779288172721863, variance: 0.04803771153092384\n",
      "Train size: [400] hidden size: [8] trial: 26, train_loss: 1.939224, test loss: 1.025024, bias2: 0.9783523082733154, variance: 0.04667196422815323\n",
      "Train size: [400] hidden size: [8] trial: 27, train_loss: 1.933392, test loss: 1.025260, bias2: 0.9778096079826355, variance: 0.04744987562298775\n",
      "Train size: [400] hidden size: [8] trial: 28, train_loss: 1.928246, test loss: 1.025424, bias2: 0.9770829081535339, variance: 0.048341117799282074\n",
      "Train size: [400] hidden size: [8] trial: 29, train_loss: 1.938415, test loss: 1.025433, bias2: 0.9776405692100525, variance: 0.04779203608632088\n",
      "Train size: [400] hidden size: [8] trial: 30, train_loss: 1.934934, test loss: 1.025320, bias2: 0.9770796298980713, variance: 0.048240095376968384\n",
      "Train size: [400] hidden size: [8] trial: 31, train_loss: 1.933352, test loss: 1.024876, bias2: 0.9765372276306152, variance: 0.04833909869194031\n",
      "Train size: [400] hidden size: [8] trial: 32, train_loss: 1.930923, test loss: 1.027362, bias2: 0.9750549793243408, variance: 0.05230703204870224\n",
      "Train size: [400] hidden size: [8] trial: 33, train_loss: 1.931553, test loss: 1.026564, bias2: 0.9754073619842529, variance: 0.05115697160363197\n",
      "Train size: [400] hidden size: [8] trial: 34, train_loss: 1.928112, test loss: 1.026421, bias2: 0.9746551513671875, variance: 0.0517655685544014\n",
      "Train size: [400] hidden size: [8] trial: 35, train_loss: 1.929671, test loss: 1.026192, bias2: 0.9738886952400208, variance: 0.05230361595749855\n",
      "Train size: [400] hidden size: [8] trial: 36, train_loss: 1.929973, test loss: 1.026817, bias2: 0.97331702709198, variance: 0.053499672561883926\n",
      "Train size: [400] hidden size: [8] trial: 37, train_loss: 1.932792, test loss: 1.026872, bias2: 0.9721471667289734, variance: 0.054724518209695816\n",
      "Train size: [400] hidden size: [8] trial: 38, train_loss: 1.935946, test loss: 1.027778, bias2: 0.9724335074424744, variance: 0.055344972759485245\n",
      "Train size: [400] hidden size: [8] trial: 39, train_loss: 1.937635, test loss: 1.028954, bias2: 0.9727228283882141, variance: 0.05623069778084755\n",
      "Train size: [400] hidden size: [8] trial: 40, train_loss: 1.944588, test loss: 1.028512, bias2: 0.9725992679595947, variance: 0.05591307207942009\n",
      "Train size: [400] hidden size: [8] trial: 41, train_loss: 1.943358, test loss: 1.028607, bias2: 0.9734244346618652, variance: 0.055182792246341705\n",
      "Train size: [400] hidden size: [8] trial: 42, train_loss: 1.939737, test loss: 1.027989, bias2: 0.9733389616012573, variance: 0.05464969202876091\n",
      "Train size: [400] hidden size: [8] trial: 43, train_loss: 1.939126, test loss: 1.028585, bias2: 0.9739055037498474, variance: 0.05467924103140831\n",
      "Train size: [400] hidden size: [8] trial: 44, train_loss: 1.935707, test loss: 1.028398, bias2: 0.9742132425308228, variance: 0.05418514087796211\n",
      "Train size: [400] hidden size: [8] trial: 45, train_loss: 1.932892, test loss: 1.028800, bias2: 0.974036455154419, variance: 0.054763197898864746\n",
      "Train size: [400] hidden size: [8] trial: 46, train_loss: 1.934426, test loss: 1.028345, bias2: 0.9734575152397156, variance: 0.05488714203238487\n",
      "Train size: [400] hidden size: [8] trial: 47, train_loss: 1.933934, test loss: 1.028537, bias2: 0.9738888740539551, variance: 0.05464816838502884\n",
      "Train size: [400] hidden size: [8] trial: 48, train_loss: 1.935758, test loss: 1.028307, bias2: 0.974039614200592, variance: 0.05426725372672081\n",
      "Train size: [400] hidden size: [8] trial: 49, train_loss: 1.938493, test loss: 1.027944, bias2: 0.9742535352706909, variance: 0.053690105676651\n",
      "##################################################\n",
      "Train size: [400] hidden size: [9] trial: 0, train_loss: 2.231180, test loss: 1.041745, bias2: 1.0417450666427612, variance: -3.4059796649721363e-10\n",
      "Train size: [400] hidden size: [9] trial: 1, train_loss: 2.158013, test loss: 1.056267, bias2: 1.0167491436004639, variance: 0.03951749578118324\n",
      "Train size: [400] hidden size: [9] trial: 2, train_loss: 2.135784, test loss: 1.046750, bias2: 0.9930711984634399, variance: 0.05367875099182129\n",
      "Train size: [400] hidden size: [9] trial: 3, train_loss: 2.045239, test loss: 1.041594, bias2: 0.9878895878791809, variance: 0.05370453745126724\n",
      "Train size: [400] hidden size: [9] trial: 4, train_loss: 2.005748, test loss: 1.042602, bias2: 0.9809713363647461, variance: 0.06163036823272705\n",
      "Train size: [400] hidden size: [9] trial: 5, train_loss: 2.028558, test loss: 1.040652, bias2: 0.9722625017166138, variance: 0.06838943064212799\n",
      "Train size: [400] hidden size: [9] trial: 6, train_loss: 2.025181, test loss: 1.040729, bias2: 0.9714441299438477, variance: 0.06928525120019913\n",
      "Train size: [400] hidden size: [9] trial: 7, train_loss: 2.005722, test loss: 1.039549, bias2: 0.9731065630912781, variance: 0.06644264608621597\n",
      "Train size: [400] hidden size: [9] trial: 8, train_loss: 2.001600, test loss: 1.050407, bias2: 0.9699933528900146, variance: 0.08041343092918396\n",
      "Train size: [400] hidden size: [9] trial: 9, train_loss: 1.974187, test loss: 1.048140, bias2: 0.9698410034179688, variance: 0.07829856127500534\n",
      "Train size: [400] hidden size: [9] trial: 10, train_loss: 1.968146, test loss: 1.046189, bias2: 0.9686535000801086, variance: 0.07753534615039825\n",
      "Train size: [400] hidden size: [9] trial: 11, train_loss: 1.970775, test loss: 1.042956, bias2: 0.9676752686500549, variance: 0.0752805843949318\n",
      "Train size: [400] hidden size: [9] trial: 12, train_loss: 1.959864, test loss: 1.041501, bias2: 0.9704422354698181, variance: 0.07105930149555206\n",
      "Train size: [400] hidden size: [9] trial: 13, train_loss: 1.942940, test loss: 1.041962, bias2: 0.9728661179542542, variance: 0.0690959095954895\n",
      "Train size: [400] hidden size: [9] trial: 14, train_loss: 1.942755, test loss: 1.042249, bias2: 0.9707229733467102, variance: 0.07152561843395233\n",
      "Train size: [400] hidden size: [9] trial: 15, train_loss: 1.929585, test loss: 1.041865, bias2: 0.9720196723937988, variance: 0.06984543800354004\n",
      "Train size: [400] hidden size: [9] trial: 16, train_loss: 1.925009, test loss: 1.040559, bias2: 0.9720004796981812, variance: 0.06855854392051697\n",
      "Train size: [400] hidden size: [9] trial: 17, train_loss: 1.919297, test loss: 1.040862, bias2: 0.9734125137329102, variance: 0.06744923442602158\n",
      "Train size: [400] hidden size: [9] trial: 18, train_loss: 1.918914, test loss: 1.040421, bias2: 0.9725624322891235, variance: 0.06785856187343597\n",
      "Train size: [400] hidden size: [9] trial: 19, train_loss: 1.911666, test loss: 1.040693, bias2: 0.9738614559173584, variance: 0.06683158874511719\n",
      "Train size: [400] hidden size: [9] trial: 20, train_loss: 1.913758, test loss: 1.041254, bias2: 0.9747351408004761, variance: 0.06651915609836578\n",
      "Train size: [400] hidden size: [9] trial: 21, train_loss: 1.920494, test loss: 1.042124, bias2: 0.9751695990562439, variance: 0.06695419549942017\n",
      "Train size: [400] hidden size: [9] trial: 22, train_loss: 1.919091, test loss: 1.042688, bias2: 0.976107656955719, variance: 0.06658060848712921\n",
      "Train size: [400] hidden size: [9] trial: 23, train_loss: 1.925937, test loss: 1.043788, bias2: 0.9745380282402039, variance: 0.06925026327371597\n",
      "Train size: [400] hidden size: [9] trial: 24, train_loss: 1.927479, test loss: 1.043626, bias2: 0.9729687571525574, variance: 0.07065745443105698\n",
      "Train size: [400] hidden size: [9] trial: 25, train_loss: 1.924119, test loss: 1.041708, bias2: 0.9721369743347168, variance: 0.0695708692073822\n",
      "Train size: [400] hidden size: [9] trial: 26, train_loss: 1.923504, test loss: 1.041174, bias2: 0.9726865291595459, variance: 0.06848727911710739\n",
      "Train size: [400] hidden size: [9] trial: 27, train_loss: 1.916295, test loss: 1.040858, bias2: 0.9728363156318665, variance: 0.06802183389663696\n",
      "Train size: [400] hidden size: [9] trial: 28, train_loss: 1.924251, test loss: 1.040636, bias2: 0.9718113541603088, variance: 0.06882425397634506\n",
      "Train size: [400] hidden size: [9] trial: 29, train_loss: 1.931882, test loss: 1.041604, bias2: 0.9726167917251587, variance: 0.06898771971464157\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [9] trial: 30, train_loss: 1.929111, test loss: 1.040866, bias2: 0.9729461073875427, variance: 0.0679200291633606\n",
      "Train size: [400] hidden size: [9] trial: 31, train_loss: 1.922243, test loss: 1.040203, bias2: 0.973639965057373, variance: 0.06656338274478912\n",
      "Train size: [400] hidden size: [9] trial: 32, train_loss: 1.921280, test loss: 1.041185, bias2: 0.9734600782394409, variance: 0.0677245706319809\n",
      "Train size: [400] hidden size: [9] trial: 33, train_loss: 1.922467, test loss: 1.040520, bias2: 0.9742769002914429, variance: 0.06624268740415573\n",
      "Train size: [400] hidden size: [9] trial: 34, train_loss: 1.935058, test loss: 1.040940, bias2: 0.9740379452705383, variance: 0.06690186262130737\n",
      "Train size: [400] hidden size: [9] trial: 35, train_loss: 1.932220, test loss: 1.040651, bias2: 0.9735366702079773, variance: 0.06711454689502716\n",
      "Train size: [400] hidden size: [9] trial: 36, train_loss: 1.934427, test loss: 1.040314, bias2: 0.9723333716392517, variance: 0.06798107922077179\n",
      "Train size: [400] hidden size: [9] trial: 37, train_loss: 1.939688, test loss: 1.039503, bias2: 0.9704520106315613, variance: 0.06905118376016617\n",
      "Train size: [400] hidden size: [9] trial: 38, train_loss: 1.939937, test loss: 1.039606, bias2: 0.9706372022628784, variance: 0.06896927952766418\n",
      "Train size: [400] hidden size: [9] trial: 39, train_loss: 1.940345, test loss: 1.038954, bias2: 0.9704729914665222, variance: 0.06848077476024628\n",
      "Train size: [400] hidden size: [9] trial: 40, train_loss: 1.943104, test loss: 1.038280, bias2: 0.9693753123283386, variance: 0.06890424340963364\n",
      "Train size: [400] hidden size: [9] trial: 41, train_loss: 1.943369, test loss: 1.038461, bias2: 0.9694790840148926, variance: 0.06898177415132523\n",
      "Train size: [400] hidden size: [9] trial: 42, train_loss: 1.943126, test loss: 1.038138, bias2: 0.9700767993927002, variance: 0.06806111335754395\n",
      "Train size: [400] hidden size: [9] trial: 43, train_loss: 1.942583, test loss: 1.037909, bias2: 0.9699528813362122, variance: 0.06795625388622284\n",
      "Train size: [400] hidden size: [9] trial: 44, train_loss: 1.943862, test loss: 1.038139, bias2: 0.9698567986488342, variance: 0.06828255206346512\n",
      "Train size: [400] hidden size: [9] trial: 45, train_loss: 1.944586, test loss: 1.038359, bias2: 0.9694641828536987, variance: 0.06889477372169495\n",
      "Train size: [400] hidden size: [9] trial: 46, train_loss: 1.948014, test loss: 1.038355, bias2: 0.9700230956077576, variance: 0.06833187490701675\n",
      "Train size: [400] hidden size: [9] trial: 47, train_loss: 1.948626, test loss: 1.037802, bias2: 0.9695202708244324, variance: 0.06828134506940842\n",
      "Train size: [400] hidden size: [9] trial: 48, train_loss: 1.944946, test loss: 1.037509, bias2: 0.9702483415603638, variance: 0.0672604888677597\n",
      "Train size: [400] hidden size: [9] trial: 49, train_loss: 1.946529, test loss: 1.038254, bias2: 0.9708398580551147, variance: 0.06741437315940857\n",
      "##################################################\n",
      "Train size: [400] hidden size: [11] trial: 0, train_loss: 1.962497, test loss: 1.061430, bias2: 1.0614296197891235, variance: -1.459705550876933e-10\n",
      "Train size: [400] hidden size: [11] trial: 1, train_loss: 2.079090, test loss: 1.040331, bias2: 1.005400538444519, variance: 0.03493000194430351\n",
      "Train size: [400] hidden size: [11] trial: 2, train_loss: 1.955172, test loss: 1.039664, bias2: 0.992734432220459, variance: 0.04692935198545456\n",
      "Train size: [400] hidden size: [11] trial: 3, train_loss: 1.934803, test loss: 1.029144, bias2: 0.977632462978363, variance: 0.05151108279824257\n",
      "Train size: [400] hidden size: [11] trial: 4, train_loss: 1.912705, test loss: 1.024155, bias2: 0.9739205837249756, variance: 0.050234101712703705\n",
      "Train size: [400] hidden size: [11] trial: 5, train_loss: 1.894727, test loss: 1.038001, bias2: 0.9752484560012817, variance: 0.06275233626365662\n",
      "Train size: [400] hidden size: [11] trial: 6, train_loss: 1.919204, test loss: 1.036443, bias2: 0.9709015488624573, variance: 0.0655413493514061\n",
      "Train size: [400] hidden size: [11] trial: 7, train_loss: 1.922604, test loss: 1.035549, bias2: 0.9700180888175964, variance: 0.0655309334397316\n",
      "Train size: [400] hidden size: [11] trial: 8, train_loss: 1.935307, test loss: 1.035052, bias2: 0.9724851846694946, variance: 0.06256677210330963\n",
      "Train size: [400] hidden size: [11] trial: 9, train_loss: 1.929446, test loss: 1.033087, bias2: 0.9706465601921082, variance: 0.06244034692645073\n",
      "Train size: [400] hidden size: [11] trial: 10, train_loss: 1.924948, test loss: 1.037482, bias2: 0.9717770218849182, variance: 0.06570525467395782\n",
      "Train size: [400] hidden size: [11] trial: 11, train_loss: 1.917022, test loss: 1.040220, bias2: 0.9702637195587158, variance: 0.06995641440153122\n",
      "Train size: [400] hidden size: [11] trial: 12, train_loss: 1.921790, test loss: 1.040834, bias2: 0.968791663646698, variance: 0.07204239070415497\n",
      "Train size: [400] hidden size: [11] trial: 13, train_loss: 1.920118, test loss: 1.039625, bias2: 0.9690791964530945, variance: 0.07054609805345535\n",
      "Train size: [400] hidden size: [11] trial: 14, train_loss: 1.935202, test loss: 1.040139, bias2: 0.9682377576828003, variance: 0.07190141081809998\n",
      "Train size: [400] hidden size: [11] trial: 15, train_loss: 1.930206, test loss: 1.039796, bias2: 0.9688503742218018, variance: 0.07094548642635345\n",
      "Train size: [400] hidden size: [11] trial: 16, train_loss: 1.910774, test loss: 1.038335, bias2: 0.969890832901001, variance: 0.06844460964202881\n",
      "Train size: [400] hidden size: [11] trial: 17, train_loss: 1.919721, test loss: 1.036529, bias2: 0.969855546951294, variance: 0.06667313724756241\n",
      "Train size: [400] hidden size: [11] trial: 18, train_loss: 1.921467, test loss: 1.037305, bias2: 0.9713346362113953, variance: 0.06597010791301727\n",
      "Train size: [400] hidden size: [11] trial: 19, train_loss: 1.913345, test loss: 1.039848, bias2: 0.9707225561141968, variance: 0.06912554055452347\n",
      "Train size: [400] hidden size: [11] trial: 20, train_loss: 1.918942, test loss: 1.040048, bias2: 0.9703558683395386, variance: 0.06969249248504639\n",
      "Train size: [400] hidden size: [11] trial: 21, train_loss: 1.921814, test loss: 1.040554, bias2: 0.9707460999488831, variance: 0.06980840116739273\n",
      "Train size: [400] hidden size: [11] trial: 22, train_loss: 1.922355, test loss: 1.039563, bias2: 0.9713061451911926, variance: 0.06825724989175797\n",
      "Train size: [400] hidden size: [11] trial: 23, train_loss: 1.934163, test loss: 1.040548, bias2: 0.9725388288497925, variance: 0.06800911575555801\n",
      "Train size: [400] hidden size: [11] trial: 24, train_loss: 1.935922, test loss: 1.038727, bias2: 0.9704158306121826, variance: 0.06831095367670059\n",
      "Train size: [400] hidden size: [11] trial: 25, train_loss: 1.932189, test loss: 1.038111, bias2: 0.9705607891082764, variance: 0.06755019724369049\n",
      "Train size: [400] hidden size: [11] trial: 26, train_loss: 1.928486, test loss: 1.039679, bias2: 0.9676939845085144, variance: 0.07198494672775269\n",
      "Train size: [400] hidden size: [11] trial: 27, train_loss: 1.924342, test loss: 1.039449, bias2: 0.9672215580940247, variance: 0.07222779840230942\n",
      "Train size: [400] hidden size: [11] trial: 28, train_loss: 1.920923, test loss: 1.038897, bias2: 0.9672331809997559, variance: 0.07166337966918945\n",
      "Train size: [400] hidden size: [11] trial: 29, train_loss: 1.919524, test loss: 1.037997, bias2: 0.9680323004722595, variance: 0.0699651837348938\n",
      "Train size: [400] hidden size: [11] trial: 30, train_loss: 1.919172, test loss: 1.039521, bias2: 0.9685518145561218, variance: 0.07096866518259048\n",
      "Train size: [400] hidden size: [11] trial: 31, train_loss: 1.923680, test loss: 1.040784, bias2: 0.9678815603256226, variance: 0.07290279120206833\n",
      "Train size: [400] hidden size: [11] trial: 32, train_loss: 1.923001, test loss: 1.040109, bias2: 0.9671218991279602, variance: 0.07298702746629715\n",
      "Train size: [400] hidden size: [11] trial: 33, train_loss: 1.919068, test loss: 1.040389, bias2: 0.9670581221580505, variance: 0.0733308270573616\n",
      "Train size: [400] hidden size: [11] trial: 34, train_loss: 1.922322, test loss: 1.040419, bias2: 0.9681087136268616, variance: 0.07231041043996811\n",
      "Train size: [400] hidden size: [11] trial: 35, train_loss: 1.918864, test loss: 1.040095, bias2: 0.9672759771347046, variance: 0.07281921058893204\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [11] trial: 36, train_loss: 1.916033, test loss: 1.039667, bias2: 0.9670467376708984, variance: 0.07262053340673447\n",
      "Train size: [400] hidden size: [11] trial: 37, train_loss: 1.920278, test loss: 1.039753, bias2: 0.9666649103164673, variance: 0.07308843731880188\n",
      "Train size: [400] hidden size: [11] trial: 38, train_loss: 1.919658, test loss: 1.040022, bias2: 0.9670408964157104, variance: 0.07298064231872559\n",
      "Train size: [400] hidden size: [11] trial: 39, train_loss: 1.917819, test loss: 1.038929, bias2: 0.9669142961502075, variance: 0.07201468199491501\n",
      "Train size: [400] hidden size: [11] trial: 40, train_loss: 1.916435, test loss: 1.038188, bias2: 0.9662489891052246, variance: 0.07193896919488907\n",
      "Train size: [400] hidden size: [11] trial: 41, train_loss: 1.918171, test loss: 1.037459, bias2: 0.9654561281204224, variance: 0.07200325280427933\n",
      "Train size: [400] hidden size: [11] trial: 42, train_loss: 1.911768, test loss: 1.037908, bias2: 0.9657424688339233, variance: 0.07216548919677734\n",
      "Train size: [400] hidden size: [11] trial: 43, train_loss: 1.913828, test loss: 1.037627, bias2: 0.9656225442886353, variance: 0.07200455665588379\n",
      "Train size: [400] hidden size: [11] trial: 44, train_loss: 1.923098, test loss: 1.037593, bias2: 0.9646467566490173, variance: 0.07294603437185287\n",
      "Train size: [400] hidden size: [11] trial: 45, train_loss: 1.925035, test loss: 1.038301, bias2: 0.9640445709228516, variance: 0.07425665110349655\n",
      "Train size: [400] hidden size: [11] trial: 46, train_loss: 1.921100, test loss: 1.038116, bias2: 0.9645395278930664, variance: 0.07357695698738098\n",
      "Train size: [400] hidden size: [11] trial: 47, train_loss: 1.922644, test loss: 1.037550, bias2: 0.9641423225402832, variance: 0.07340788841247559\n",
      "Train size: [400] hidden size: [11] trial: 48, train_loss: 1.923834, test loss: 1.038292, bias2: 0.9645969867706299, variance: 0.07369480282068253\n",
      "Train size: [400] hidden size: [11] trial: 49, train_loss: 1.925286, test loss: 1.038726, bias2: 0.9653663635253906, variance: 0.07335983216762543\n",
      "##################################################\n",
      "Train size: [400] hidden size: [12] trial: 0, train_loss: 1.942652, test loss: 0.993764, bias2: 0.9937639236450195, variance: 9.731369876586626e-11\n",
      "Train size: [400] hidden size: [12] trial: 1, train_loss: 1.894254, test loss: 1.038102, bias2: 0.9957575798034668, variance: 0.042344555258750916\n",
      "Train size: [400] hidden size: [12] trial: 2, train_loss: 1.876229, test loss: 1.063540, bias2: 1.0004498958587646, variance: 0.06309016048908234\n",
      "Train size: [400] hidden size: [12] trial: 3, train_loss: 1.940660, test loss: 1.066495, bias2: 0.9924793839454651, variance: 0.07401508837938309\n",
      "Train size: [400] hidden size: [12] trial: 4, train_loss: 1.899448, test loss: 1.056829, bias2: 0.9806506037712097, variance: 0.07617887109518051\n",
      "Train size: [400] hidden size: [12] trial: 5, train_loss: 1.930312, test loss: 1.064017, bias2: 0.9830406904220581, variance: 0.08097651600837708\n",
      "Train size: [400] hidden size: [12] trial: 6, train_loss: 1.922283, test loss: 1.061956, bias2: 0.978496253490448, variance: 0.0834600105881691\n",
      "Train size: [400] hidden size: [12] trial: 7, train_loss: 1.911318, test loss: 1.057946, bias2: 0.9778528809547424, variance: 0.08009345084428787\n",
      "Train size: [400] hidden size: [12] trial: 8, train_loss: 1.905400, test loss: 1.055432, bias2: 0.9746809005737305, variance: 0.08075056970119476\n",
      "Train size: [400] hidden size: [12] trial: 9, train_loss: 1.922041, test loss: 1.057979, bias2: 0.9746627807617188, variance: 0.08331667631864548\n",
      "Train size: [400] hidden size: [12] trial: 10, train_loss: 1.914335, test loss: 1.056944, bias2: 0.9668452739715576, variance: 0.09009864181280136\n",
      "Train size: [400] hidden size: [12] trial: 11, train_loss: 1.906856, test loss: 1.053767, bias2: 0.9672233462333679, variance: 0.08654359728097916\n",
      "Train size: [400] hidden size: [12] trial: 12, train_loss: 1.898549, test loss: 1.057126, bias2: 0.9640187621116638, variance: 0.09310730546712875\n",
      "Train size: [400] hidden size: [12] trial: 13, train_loss: 1.906892, test loss: 1.057366, bias2: 0.963985800743103, variance: 0.09337975829839706\n",
      "Train size: [400] hidden size: [12] trial: 14, train_loss: 1.907488, test loss: 1.054771, bias2: 0.9641515612602234, variance: 0.09061995893716812\n",
      "Train size: [400] hidden size: [12] trial: 15, train_loss: 1.899788, test loss: 1.055372, bias2: 0.9627001285552979, variance: 0.09267139434814453\n",
      "Train size: [400] hidden size: [12] trial: 16, train_loss: 1.918275, test loss: 1.053789, bias2: 0.9633737802505493, variance: 0.090415358543396\n",
      "Train size: [400] hidden size: [12] trial: 17, train_loss: 1.935204, test loss: 1.051381, bias2: 0.9631563425064087, variance: 0.08822498470544815\n",
      "Train size: [400] hidden size: [12] trial: 18, train_loss: 1.941792, test loss: 1.052547, bias2: 0.9637578725814819, variance: 0.0887892097234726\n",
      "Train size: [400] hidden size: [12] trial: 19, train_loss: 1.954424, test loss: 1.051505, bias2: 0.9621427655220032, variance: 0.08936221152544022\n",
      "Train size: [400] hidden size: [12] trial: 20, train_loss: 1.956590, test loss: 1.050433, bias2: 0.9590821862220764, variance: 0.09135061502456665\n",
      "Train size: [400] hidden size: [12] trial: 21, train_loss: 1.953720, test loss: 1.049931, bias2: 0.9602330327033997, variance: 0.08969825506210327\n",
      "Train size: [400] hidden size: [12] trial: 22, train_loss: 1.943862, test loss: 1.049237, bias2: 0.9594697952270508, variance: 0.08976771682500839\n",
      "Train size: [400] hidden size: [12] trial: 23, train_loss: 1.934250, test loss: 1.048451, bias2: 0.9578249454498291, variance: 0.09062600135803223\n",
      "Train size: [400] hidden size: [12] trial: 24, train_loss: 1.935513, test loss: 1.049581, bias2: 0.9574415683746338, variance: 0.0921393558382988\n",
      "Train size: [400] hidden size: [12] trial: 25, train_loss: 1.937540, test loss: 1.048778, bias2: 0.9567191004753113, variance: 0.09205885976552963\n",
      "Train size: [400] hidden size: [12] trial: 26, train_loss: 1.941393, test loss: 1.048548, bias2: 0.9577198028564453, variance: 0.090828076004982\n",
      "Train size: [400] hidden size: [12] trial: 27, train_loss: 1.938081, test loss: 1.047238, bias2: 0.9580900073051453, variance: 0.08914824575185776\n",
      "Train size: [400] hidden size: [12] trial: 28, train_loss: 1.940861, test loss: 1.045788, bias2: 0.9578247666358948, variance: 0.08796291798353195\n",
      "Train size: [400] hidden size: [12] trial: 29, train_loss: 1.937659, test loss: 1.045878, bias2: 0.9579999446868896, variance: 0.08787811547517776\n",
      "Train size: [400] hidden size: [12] trial: 30, train_loss: 1.944646, test loss: 1.045277, bias2: 0.9576882123947144, variance: 0.08758902549743652\n",
      "Train size: [400] hidden size: [12] trial: 31, train_loss: 1.950400, test loss: 1.046321, bias2: 0.9579880237579346, variance: 0.08833274245262146\n",
      "Train size: [400] hidden size: [12] trial: 32, train_loss: 1.950102, test loss: 1.045782, bias2: 0.9589095115661621, variance: 0.08687198907136917\n",
      "Train size: [400] hidden size: [12] trial: 33, train_loss: 1.946361, test loss: 1.047391, bias2: 0.9580289721488953, variance: 0.08936185389757156\n",
      "Train size: [400] hidden size: [12] trial: 34, train_loss: 1.941326, test loss: 1.048905, bias2: 0.9591723084449768, variance: 0.08973308652639389\n",
      "Train size: [400] hidden size: [12] trial: 35, train_loss: 1.940460, test loss: 1.048632, bias2: 0.9596638083457947, variance: 0.08896776288747787\n",
      "Train size: [400] hidden size: [12] trial: 36, train_loss: 1.945395, test loss: 1.049860, bias2: 0.9609701633453369, variance: 0.0888897255063057\n",
      "Train size: [400] hidden size: [12] trial: 37, train_loss: 1.942234, test loss: 1.051367, bias2: 0.9608287215232849, variance: 0.09053822606801987\n",
      "Train size: [400] hidden size: [12] trial: 38, train_loss: 1.940477, test loss: 1.051534, bias2: 0.961442232131958, variance: 0.09009229391813278\n",
      "Train size: [400] hidden size: [12] trial: 39, train_loss: 1.937946, test loss: 1.052754, bias2: 0.9620435833930969, variance: 0.0907105877995491\n",
      "Train size: [400] hidden size: [12] trial: 40, train_loss: 1.932964, test loss: 1.052545, bias2: 0.9618957042694092, variance: 0.09064950793981552\n",
      "Train size: [400] hidden size: [12] trial: 41, train_loss: 1.931413, test loss: 1.052696, bias2: 0.9620688557624817, variance: 0.09062690287828445\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [12] trial: 42, train_loss: 1.931759, test loss: 1.051327, bias2: 0.9601800441741943, variance: 0.0911470502614975\n",
      "Train size: [400] hidden size: [12] trial: 43, train_loss: 1.935282, test loss: 1.051222, bias2: 0.9607346057891846, variance: 0.09048710018396378\n",
      "Train size: [400] hidden size: [12] trial: 44, train_loss: 1.931520, test loss: 1.050537, bias2: 0.9597750902175903, variance: 0.09076213836669922\n",
      "Train size: [400] hidden size: [12] trial: 45, train_loss: 1.932947, test loss: 1.050581, bias2: 0.9593248963356018, variance: 0.09125596284866333\n",
      "Train size: [400] hidden size: [12] trial: 46, train_loss: 1.934458, test loss: 1.051371, bias2: 0.9592214226722717, variance: 0.09214930236339569\n",
      "Train size: [400] hidden size: [12] trial: 47, train_loss: 1.932395, test loss: 1.050016, bias2: 0.9587795734405518, variance: 0.09123681485652924\n",
      "Train size: [400] hidden size: [12] trial: 48, train_loss: 1.935410, test loss: 1.050884, bias2: 0.9588868021965027, variance: 0.09199710935354233\n",
      "Train size: [400] hidden size: [12] trial: 49, train_loss: 1.933883, test loss: 1.050019, bias2: 0.9580814838409424, variance: 0.09193703532218933\n",
      "##################################################\n",
      "Train size: [400] hidden size: [14] trial: 0, train_loss: 1.904509, test loss: 0.999503, bias2: 0.9995031952857971, variance: 6.325390766726002e-10\n",
      "Train size: [400] hidden size: [14] trial: 1, train_loss: 1.824541, test loss: 1.017392, bias2: 0.9755641222000122, variance: 0.041827667504549026\n",
      "Train size: [400] hidden size: [14] trial: 2, train_loss: 1.810696, test loss: 1.022027, bias2: 0.9583280086517334, variance: 0.06369935721158981\n",
      "Train size: [400] hidden size: [14] trial: 3, train_loss: 1.844228, test loss: 1.027772, bias2: 0.9603840708732605, variance: 0.06738834083080292\n",
      "Train size: [400] hidden size: [14] trial: 4, train_loss: 1.825431, test loss: 1.034404, bias2: 0.9594053626060486, variance: 0.0749986544251442\n",
      "Train size: [400] hidden size: [14] trial: 5, train_loss: 1.864825, test loss: 1.041487, bias2: 0.9662070870399475, variance: 0.07527940720319748\n",
      "Train size: [400] hidden size: [14] trial: 6, train_loss: 1.881513, test loss: 1.044110, bias2: 0.9639552235603333, variance: 0.08015484362840652\n",
      "Train size: [400] hidden size: [14] trial: 7, train_loss: 1.882988, test loss: 1.047304, bias2: 0.9664232730865479, variance: 0.08088061213493347\n",
      "Train size: [400] hidden size: [14] trial: 8, train_loss: 1.882462, test loss: 1.048989, bias2: 0.9633545875549316, variance: 0.08563481271266937\n",
      "Train size: [400] hidden size: [14] trial: 9, train_loss: 1.886932, test loss: 1.047362, bias2: 0.9635645747184753, variance: 0.08379773795604706\n",
      "Train size: [400] hidden size: [14] trial: 10, train_loss: 1.878401, test loss: 1.046754, bias2: 0.9647427797317505, variance: 0.08201169967651367\n",
      "Train size: [400] hidden size: [14] trial: 11, train_loss: 1.882823, test loss: 1.045943, bias2: 0.9618968367576599, variance: 0.08404628187417984\n",
      "Train size: [400] hidden size: [14] trial: 12, train_loss: 1.883676, test loss: 1.045876, bias2: 0.9593899846076965, variance: 0.08648653328418732\n",
      "Train size: [400] hidden size: [14] trial: 13, train_loss: 1.877541, test loss: 1.047705, bias2: 0.9602159857749939, variance: 0.08748944103717804\n",
      "Train size: [400] hidden size: [14] trial: 14, train_loss: 1.873285, test loss: 1.048332, bias2: 0.957781970500946, variance: 0.09054967015981674\n",
      "Train size: [400] hidden size: [14] trial: 15, train_loss: 1.869353, test loss: 1.045861, bias2: 0.9555337429046631, variance: 0.09032704681158066\n",
      "Train size: [400] hidden size: [14] trial: 16, train_loss: 1.884777, test loss: 1.043443, bias2: 0.9550812244415283, variance: 0.08836184442043304\n",
      "Train size: [400] hidden size: [14] trial: 17, train_loss: 1.882787, test loss: 1.045162, bias2: 0.9519752860069275, variance: 0.09318646043539047\n",
      "Train size: [400] hidden size: [14] trial: 18, train_loss: 1.871053, test loss: 1.044837, bias2: 0.9492241740226746, variance: 0.09561282396316528\n",
      "Train size: [400] hidden size: [14] trial: 19, train_loss: 1.874921, test loss: 1.044989, bias2: 0.9495443105697632, variance: 0.09544465690851212\n",
      "Train size: [400] hidden size: [14] trial: 20, train_loss: 1.871618, test loss: 1.046735, bias2: 0.9508225321769714, variance: 0.09591276943683624\n",
      "Train size: [400] hidden size: [14] trial: 21, train_loss: 1.872938, test loss: 1.046033, bias2: 0.9505959749221802, variance: 0.09543707966804504\n",
      "Train size: [400] hidden size: [14] trial: 22, train_loss: 1.867794, test loss: 1.046369, bias2: 0.9512119889259338, variance: 0.095157191157341\n",
      "Train size: [400] hidden size: [14] trial: 23, train_loss: 1.870197, test loss: 1.047323, bias2: 0.9521965980529785, variance: 0.09512588381767273\n",
      "Train size: [400] hidden size: [14] trial: 24, train_loss: 1.873388, test loss: 1.048009, bias2: 0.9518861174583435, variance: 0.09612315893173218\n",
      "Train size: [400] hidden size: [14] trial: 25, train_loss: 1.880477, test loss: 1.047652, bias2: 0.9509585499763489, variance: 0.09669310599565506\n",
      "Train size: [400] hidden size: [14] trial: 26, train_loss: 1.882733, test loss: 1.049040, bias2: 0.9522179961204529, variance: 0.09682194143533707\n",
      "Train size: [400] hidden size: [14] trial: 27, train_loss: 1.890350, test loss: 1.049655, bias2: 0.9517063498497009, variance: 0.09794887155294418\n",
      "Train size: [400] hidden size: [14] trial: 28, train_loss: 1.890940, test loss: 1.049532, bias2: 0.952116072177887, variance: 0.0974157378077507\n",
      "Train size: [400] hidden size: [14] trial: 29, train_loss: 1.895830, test loss: 1.047451, bias2: 0.9515330195426941, variance: 0.09591789543628693\n",
      "Train size: [400] hidden size: [14] trial: 30, train_loss: 1.890657, test loss: 1.046620, bias2: 0.9514066576957703, variance: 0.09521347284317017\n",
      "Train size: [400] hidden size: [14] trial: 31, train_loss: 1.889096, test loss: 1.047620, bias2: 0.9515126347541809, variance: 0.09610777348279953\n",
      "Train size: [400] hidden size: [14] trial: 32, train_loss: 1.891182, test loss: 1.049248, bias2: 0.9518004059791565, variance: 0.0974474623799324\n",
      "Train size: [400] hidden size: [14] trial: 33, train_loss: 1.893094, test loss: 1.049073, bias2: 0.9513894319534302, variance: 0.09768403321504593\n",
      "Train size: [400] hidden size: [14] trial: 34, train_loss: 1.893270, test loss: 1.048770, bias2: 0.9517474174499512, variance: 0.0970228984951973\n",
      "Train size: [400] hidden size: [14] trial: 35, train_loss: 1.894195, test loss: 1.049890, bias2: 0.9521386623382568, variance: 0.09775139391422272\n",
      "Train size: [400] hidden size: [14] trial: 36, train_loss: 1.897016, test loss: 1.049752, bias2: 0.9529158473014832, variance: 0.09683603793382645\n",
      "Train size: [400] hidden size: [14] trial: 37, train_loss: 1.900159, test loss: 1.049758, bias2: 0.9529478549957275, variance: 0.0968099981546402\n",
      "Train size: [400] hidden size: [14] trial: 38, train_loss: 1.901210, test loss: 1.050306, bias2: 0.9529826641082764, variance: 0.0973229706287384\n",
      "Train size: [400] hidden size: [14] trial: 39, train_loss: 1.903575, test loss: 1.050357, bias2: 0.9531594514846802, variance: 0.09719756245613098\n",
      "Train size: [400] hidden size: [14] trial: 40, train_loss: 1.897757, test loss: 1.051230, bias2: 0.9538953900337219, variance: 0.0973343476653099\n",
      "Train size: [400] hidden size: [14] trial: 41, train_loss: 1.896220, test loss: 1.051338, bias2: 0.9542316198348999, variance: 0.0971066877245903\n",
      "Train size: [400] hidden size: [14] trial: 42, train_loss: 1.894353, test loss: 1.050619, bias2: 0.9546658396720886, variance: 0.09595318138599396\n",
      "Train size: [400] hidden size: [14] trial: 43, train_loss: 1.896503, test loss: 1.049908, bias2: 0.9530811309814453, variance: 0.0968269407749176\n",
      "Train size: [400] hidden size: [14] trial: 44, train_loss: 1.895889, test loss: 1.050528, bias2: 0.9521380066871643, variance: 0.09839002043008804\n",
      "Train size: [400] hidden size: [14] trial: 45, train_loss: 1.888946, test loss: 1.049430, bias2: 0.950980007648468, variance: 0.09844975173473358\n",
      "Train size: [400] hidden size: [14] trial: 46, train_loss: 1.887275, test loss: 1.051033, bias2: 0.9508766531944275, variance: 0.10015637427568436\n",
      "Train size: [400] hidden size: [14] trial: 47, train_loss: 1.885089, test loss: 1.050772, bias2: 0.9519829750061035, variance: 0.09878849238157272\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [14] trial: 48, train_loss: 1.884846, test loss: 1.049860, bias2: 0.9517560601234436, variance: 0.09810380637645721\n",
      "Train size: [400] hidden size: [14] trial: 49, train_loss: 1.882843, test loss: 1.049135, bias2: 0.9514169692993164, variance: 0.09771838039159775\n",
      "##################################################\n",
      "Train size: [400] hidden size: [16] trial: 0, train_loss: 1.952538, test loss: 1.013536, bias2: 1.013535976409912, variance: 3.8925479506346505e-10\n",
      "Train size: [400] hidden size: [16] trial: 1, train_loss: 1.958751, test loss: 1.026636, bias2: 0.9822883605957031, variance: 0.04434773325920105\n",
      "Train size: [400] hidden size: [16] trial: 2, train_loss: 1.957722, test loss: 1.049992, bias2: 0.9716265201568604, variance: 0.07836533337831497\n",
      "Train size: [400] hidden size: [16] trial: 3, train_loss: 1.966303, test loss: 1.045470, bias2: 0.9704707860946655, variance: 0.07499959319829941\n",
      "Train size: [400] hidden size: [16] trial: 4, train_loss: 1.978346, test loss: 1.047560, bias2: 0.9537832736968994, variance: 0.09377692639827728\n",
      "Train size: [400] hidden size: [16] trial: 5, train_loss: 1.954569, test loss: 1.053211, bias2: 0.9506800770759583, variance: 0.10253111273050308\n",
      "Train size: [400] hidden size: [16] trial: 6, train_loss: 1.954240, test loss: 1.055272, bias2: 0.9547924995422363, variance: 0.10047934949398041\n",
      "Train size: [400] hidden size: [16] trial: 7, train_loss: 1.936322, test loss: 1.062071, bias2: 0.9506529569625854, variance: 0.1114184707403183\n",
      "Train size: [400] hidden size: [16] trial: 8, train_loss: 1.914604, test loss: 1.057336, bias2: 0.944633424282074, variance: 0.11270205676555634\n",
      "Train size: [400] hidden size: [16] trial: 9, train_loss: 1.913258, test loss: 1.056879, bias2: 0.9428014755249023, variance: 0.11407770961523056\n",
      "Train size: [400] hidden size: [16] trial: 10, train_loss: 1.905271, test loss: 1.056621, bias2: 0.9416242837905884, variance: 0.11499644815921783\n",
      "Train size: [400] hidden size: [16] trial: 11, train_loss: 1.916149, test loss: 1.053279, bias2: 0.941801905632019, variance: 0.11147702485322952\n",
      "Train size: [400] hidden size: [16] trial: 12, train_loss: 1.919923, test loss: 1.051750, bias2: 0.9436525106430054, variance: 0.10809733718633652\n",
      "Train size: [400] hidden size: [16] trial: 13, train_loss: 1.919424, test loss: 1.056999, bias2: 0.9441927671432495, variance: 0.11280632019042969\n",
      "Train size: [400] hidden size: [16] trial: 14, train_loss: 1.929078, test loss: 1.058475, bias2: 0.9455651044845581, variance: 0.11291027814149857\n",
      "Train size: [400] hidden size: [16] trial: 15, train_loss: 1.930631, test loss: 1.056728, bias2: 0.9452278017997742, variance: 0.1115003228187561\n",
      "Train size: [400] hidden size: [16] trial: 16, train_loss: 1.931598, test loss: 1.055229, bias2: 0.9425105452537537, variance: 0.11271852254867554\n",
      "Train size: [400] hidden size: [16] trial: 17, train_loss: 1.938743, test loss: 1.056875, bias2: 0.9418908357620239, variance: 0.11498452723026276\n",
      "Train size: [400] hidden size: [16] trial: 18, train_loss: 1.929810, test loss: 1.058640, bias2: 0.942504346370697, variance: 0.11613554507493973\n",
      "Train size: [400] hidden size: [16] trial: 19, train_loss: 1.931524, test loss: 1.058175, bias2: 0.9419128894805908, variance: 0.11626183986663818\n",
      "Train size: [400] hidden size: [16] trial: 20, train_loss: 1.927336, test loss: 1.058276, bias2: 0.9428825378417969, variance: 0.11539329588413239\n",
      "Train size: [400] hidden size: [16] trial: 21, train_loss: 1.919829, test loss: 1.055899, bias2: 0.9431408047676086, variance: 0.11275798827409744\n",
      "Train size: [400] hidden size: [16] trial: 22, train_loss: 1.926842, test loss: 1.059594, bias2: 0.945527195930481, variance: 0.11406682431697845\n",
      "Train size: [400] hidden size: [16] trial: 23, train_loss: 1.925350, test loss: 1.057382, bias2: 0.9450429677963257, variance: 0.11233863979578018\n",
      "Train size: [400] hidden size: [16] trial: 24, train_loss: 1.921390, test loss: 1.057867, bias2: 0.9448325037956238, variance: 0.11303406208753586\n",
      "Train size: [400] hidden size: [16] trial: 25, train_loss: 1.921028, test loss: 1.056868, bias2: 0.945152223110199, variance: 0.11171560734510422\n",
      "Train size: [400] hidden size: [16] trial: 26, train_loss: 1.910475, test loss: 1.058692, bias2: 0.9445092678070068, variance: 0.11418260633945465\n",
      "Train size: [400] hidden size: [16] trial: 27, train_loss: 1.915925, test loss: 1.058553, bias2: 0.9462873935699463, variance: 0.1122659370303154\n",
      "Train size: [400] hidden size: [16] trial: 28, train_loss: 1.919355, test loss: 1.058605, bias2: 0.9475899338722229, variance: 0.11101479083299637\n",
      "Train size: [400] hidden size: [16] trial: 29, train_loss: 1.914643, test loss: 1.059166, bias2: 0.9482795000076294, variance: 0.1108866035938263\n",
      "Train size: [400] hidden size: [16] trial: 30, train_loss: 1.912882, test loss: 1.058137, bias2: 0.9475942254066467, variance: 0.11054293066263199\n",
      "Train size: [400] hidden size: [16] trial: 31, train_loss: 1.923961, test loss: 1.057679, bias2: 0.948162853717804, variance: 0.10951633751392365\n",
      "Train size: [400] hidden size: [16] trial: 32, train_loss: 1.919725, test loss: 1.056818, bias2: 0.9487144947052002, variance: 0.10810313373804092\n",
      "Train size: [400] hidden size: [16] trial: 33, train_loss: 1.929221, test loss: 1.056825, bias2: 0.950456440448761, variance: 0.10636861622333527\n",
      "Train size: [400] hidden size: [16] trial: 34, train_loss: 1.926352, test loss: 1.058521, bias2: 0.9493390321731567, variance: 0.10918166488409042\n",
      "Train size: [400] hidden size: [16] trial: 35, train_loss: 1.922674, test loss: 1.056967, bias2: 0.9480562806129456, variance: 0.10891038179397583\n",
      "Train size: [400] hidden size: [16] trial: 36, train_loss: 1.926005, test loss: 1.057438, bias2: 0.9482303261756897, variance: 0.10920806229114532\n",
      "Train size: [400] hidden size: [16] trial: 37, train_loss: 1.924246, test loss: 1.058115, bias2: 0.9482546448707581, variance: 0.10986072570085526\n",
      "Train size: [400] hidden size: [16] trial: 38, train_loss: 1.929004, test loss: 1.058135, bias2: 0.9492905139923096, variance: 0.10884425789117813\n",
      "Train size: [400] hidden size: [16] trial: 39, train_loss: 1.924724, test loss: 1.058130, bias2: 0.9500999450683594, variance: 0.10803008079528809\n",
      "Train size: [400] hidden size: [16] trial: 40, train_loss: 1.919436, test loss: 1.056591, bias2: 0.949059247970581, variance: 0.10753193497657776\n",
      "Train size: [400] hidden size: [16] trial: 41, train_loss: 1.917853, test loss: 1.057082, bias2: 0.9486445784568787, variance: 0.10843761265277863\n",
      "Train size: [400] hidden size: [16] trial: 42, train_loss: 1.917350, test loss: 1.058843, bias2: 0.949097216129303, variance: 0.10974592715501785\n",
      "Train size: [400] hidden size: [16] trial: 43, train_loss: 1.910845, test loss: 1.059001, bias2: 0.9488804340362549, variance: 0.11012078821659088\n",
      "Train size: [400] hidden size: [16] trial: 44, train_loss: 1.911834, test loss: 1.058693, bias2: 0.9499085545539856, variance: 0.10878484696149826\n",
      "Train size: [400] hidden size: [16] trial: 45, train_loss: 1.910539, test loss: 1.057972, bias2: 0.9489701390266418, variance: 0.10900230705738068\n",
      "Train size: [400] hidden size: [16] trial: 46, train_loss: 1.912125, test loss: 1.057607, bias2: 0.9490406513214111, variance: 0.10856619477272034\n",
      "Train size: [400] hidden size: [16] trial: 47, train_loss: 1.911648, test loss: 1.057128, bias2: 0.9494597911834717, variance: 0.10766793042421341\n",
      "Train size: [400] hidden size: [16] trial: 48, train_loss: 1.910739, test loss: 1.057156, bias2: 0.9492573142051697, variance: 0.1078987717628479\n",
      "Train size: [400] hidden size: [16] trial: 49, train_loss: 1.910909, test loss: 1.056129, bias2: 0.9481666684150696, variance: 0.1079622134566307\n",
      "##################################################\n",
      "Train size: [400] hidden size: [19] trial: 0, train_loss: 2.276740, test loss: 1.044439, bias2: 1.0444386005401611, variance: 7.785095901269301e-10\n",
      "Train size: [400] hidden size: [19] trial: 1, train_loss: 2.241639, test loss: 1.059247, bias2: 0.9771959185600281, variance: 0.0820508673787117\n",
      "Train size: [400] hidden size: [19] trial: 2, train_loss: 2.074904, test loss: 1.081396, bias2: 0.9768032431602478, variance: 0.10459286719560623\n",
      "Train size: [400] hidden size: [19] trial: 3, train_loss: 2.073854, test loss: 1.074009, bias2: 0.9549354314804077, variance: 0.1190732792019844\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [19] trial: 4, train_loss: 2.044917, test loss: 1.072772, bias2: 0.9570097923278809, variance: 0.11576201021671295\n",
      "Train size: [400] hidden size: [19] trial: 5, train_loss: 2.031657, test loss: 1.071643, bias2: 0.9443796873092651, variance: 0.12726333737373352\n",
      "Train size: [400] hidden size: [19] trial: 6, train_loss: 1.996367, test loss: 1.072050, bias2: 0.944625198841095, variance: 0.127424418926239\n",
      "Train size: [400] hidden size: [19] trial: 7, train_loss: 1.985337, test loss: 1.075367, bias2: 0.9440938234329224, variance: 0.13127294182777405\n",
      "Train size: [400] hidden size: [19] trial: 8, train_loss: 1.962478, test loss: 1.068419, bias2: 0.9420040845870972, variance: 0.12641537189483643\n",
      "Train size: [400] hidden size: [19] trial: 9, train_loss: 1.960027, test loss: 1.071357, bias2: 0.9434421062469482, variance: 0.1279146522283554\n",
      "Train size: [400] hidden size: [19] trial: 10, train_loss: 1.945716, test loss: 1.069408, bias2: 0.9392907619476318, variance: 0.13011744618415833\n",
      "Train size: [400] hidden size: [19] trial: 11, train_loss: 1.944995, test loss: 1.073274, bias2: 0.9434888958930969, variance: 0.12978486716747284\n",
      "Train size: [400] hidden size: [19] trial: 12, train_loss: 1.926935, test loss: 1.073991, bias2: 0.9439201354980469, variance: 0.13007114827632904\n",
      "Train size: [400] hidden size: [19] trial: 13, train_loss: 1.909655, test loss: 1.074431, bias2: 0.9420453310012817, variance: 0.13238537311553955\n",
      "Train size: [400] hidden size: [19] trial: 14, train_loss: 1.899184, test loss: 1.074579, bias2: 0.94069504737854, variance: 0.13388429582118988\n",
      "Train size: [400] hidden size: [19] trial: 15, train_loss: 1.899452, test loss: 1.074328, bias2: 0.942013680934906, variance: 0.1323147416114807\n",
      "Train size: [400] hidden size: [19] trial: 16, train_loss: 1.886720, test loss: 1.072476, bias2: 0.9412037134170532, variance: 0.131272554397583\n",
      "Train size: [400] hidden size: [19] trial: 17, train_loss: 1.884557, test loss: 1.069281, bias2: 0.940798282623291, variance: 0.12848293781280518\n",
      "Train size: [400] hidden size: [19] trial: 18, train_loss: 1.893799, test loss: 1.069071, bias2: 0.9410545229911804, variance: 0.1280169039964676\n",
      "Train size: [400] hidden size: [19] trial: 19, train_loss: 1.879660, test loss: 1.068511, bias2: 0.939804196357727, variance: 0.12870702147483826\n",
      "Train size: [400] hidden size: [19] trial: 20, train_loss: 1.881138, test loss: 1.068338, bias2: 0.941055953502655, variance: 0.12728255987167358\n",
      "Train size: [400] hidden size: [19] trial: 21, train_loss: 1.889160, test loss: 1.068455, bias2: 0.9392257928848267, variance: 0.12922896444797516\n",
      "Train size: [400] hidden size: [19] trial: 22, train_loss: 1.889239, test loss: 1.070467, bias2: 0.9390530586242676, variance: 0.13141383230686188\n",
      "Train size: [400] hidden size: [19] trial: 23, train_loss: 1.892309, test loss: 1.070578, bias2: 0.9389218688011169, variance: 0.13165612518787384\n",
      "Train size: [400] hidden size: [19] trial: 24, train_loss: 1.901316, test loss: 1.069932, bias2: 0.9396427869796753, variance: 0.1302887201309204\n",
      "Train size: [400] hidden size: [19] trial: 25, train_loss: 1.897785, test loss: 1.068404, bias2: 0.9370667934417725, variance: 0.13133667409420013\n",
      "Train size: [400] hidden size: [19] trial: 26, train_loss: 1.895557, test loss: 1.070141, bias2: 0.9379779100418091, variance: 0.1321628987789154\n",
      "Train size: [400] hidden size: [19] trial: 27, train_loss: 1.905444, test loss: 1.070567, bias2: 0.9389036893844604, variance: 0.13166369497776031\n",
      "Train size: [400] hidden size: [19] trial: 28, train_loss: 1.909161, test loss: 1.070340, bias2: 0.9375151991844177, variance: 0.1328248232603073\n",
      "Train size: [400] hidden size: [19] trial: 29, train_loss: 1.908997, test loss: 1.071063, bias2: 0.9381890296936035, variance: 0.1328735649585724\n",
      "Train size: [400] hidden size: [19] trial: 30, train_loss: 1.906838, test loss: 1.069640, bias2: 0.9369288682937622, variance: 0.13271071016788483\n",
      "Train size: [400] hidden size: [19] trial: 31, train_loss: 1.912158, test loss: 1.069614, bias2: 0.937263011932373, variance: 0.13235104084014893\n",
      "Train size: [400] hidden size: [19] trial: 32, train_loss: 1.912888, test loss: 1.070750, bias2: 0.9380555152893066, variance: 0.13269397616386414\n",
      "Train size: [400] hidden size: [19] trial: 33, train_loss: 1.907500, test loss: 1.069830, bias2: 0.9381220936775208, variance: 0.13170796632766724\n",
      "Train size: [400] hidden size: [19] trial: 34, train_loss: 1.909430, test loss: 1.069678, bias2: 0.9369977712631226, variance: 0.13268062472343445\n",
      "Train size: [400] hidden size: [19] trial: 35, train_loss: 1.906275, test loss: 1.069149, bias2: 0.9379957318305969, variance: 0.13115303218364716\n",
      "Train size: [400] hidden size: [19] trial: 36, train_loss: 1.898999, test loss: 1.068431, bias2: 0.9386941194534302, variance: 0.12973690032958984\n",
      "Train size: [400] hidden size: [19] trial: 37, train_loss: 1.895266, test loss: 1.068905, bias2: 0.9390347599983215, variance: 0.1298702210187912\n",
      "Train size: [400] hidden size: [19] trial: 38, train_loss: 1.897783, test loss: 1.067586, bias2: 0.9387282133102417, variance: 0.1288573443889618\n",
      "Train size: [400] hidden size: [19] trial: 39, train_loss: 1.899998, test loss: 1.066210, bias2: 0.9383373260498047, variance: 0.12787272036075592\n",
      "Train size: [400] hidden size: [19] trial: 40, train_loss: 1.896868, test loss: 1.066983, bias2: 0.9384401440620422, variance: 0.1285431832075119\n",
      "Train size: [400] hidden size: [19] trial: 41, train_loss: 1.901847, test loss: 1.066412, bias2: 0.9387989640235901, variance: 0.12761324644088745\n",
      "Train size: [400] hidden size: [19] trial: 42, train_loss: 1.894780, test loss: 1.066640, bias2: 0.9392827749252319, variance: 0.1273573935031891\n",
      "Train size: [400] hidden size: [19] trial: 43, train_loss: 1.896061, test loss: 1.066574, bias2: 0.9402480721473694, variance: 0.1263258010149002\n",
      "Train size: [400] hidden size: [19] trial: 44, train_loss: 1.892314, test loss: 1.066201, bias2: 0.9410530924797058, variance: 0.1251482367515564\n",
      "Train size: [400] hidden size: [19] trial: 45, train_loss: 1.891491, test loss: 1.066419, bias2: 0.9416041970252991, variance: 0.12481502443552017\n",
      "Train size: [400] hidden size: [19] trial: 46, train_loss: 1.890471, test loss: 1.065405, bias2: 0.9419416189193726, variance: 0.12346315383911133\n",
      "Train size: [400] hidden size: [19] trial: 47, train_loss: 1.891447, test loss: 1.066602, bias2: 0.9426078200340271, variance: 0.12399454414844513\n",
      "Train size: [400] hidden size: [19] trial: 48, train_loss: 1.890048, test loss: 1.067272, bias2: 0.9435828328132629, variance: 0.12368958443403244\n",
      "Train size: [400] hidden size: [19] trial: 49, train_loss: 1.889245, test loss: 1.067595, bias2: 0.9429333209991455, variance: 0.12466214597225189\n",
      "##################################################\n",
      "Train size: [400] hidden size: [22] trial: 0, train_loss: 1.798320, test loss: 1.071926, bias2: 1.0719263553619385, variance: -4.865685077071191e-10\n",
      "Train size: [400] hidden size: [22] trial: 1, train_loss: 1.878796, test loss: 1.033149, bias2: 0.9677306413650513, variance: 0.06541838496923447\n",
      "Train size: [400] hidden size: [22] trial: 2, train_loss: 1.869534, test loss: 1.040272, bias2: 0.9562066793441772, variance: 0.08406484872102737\n",
      "Train size: [400] hidden size: [22] trial: 3, train_loss: 1.815529, test loss: 1.034026, bias2: 0.9399977326393127, variance: 0.0940280631184578\n",
      "Train size: [400] hidden size: [22] trial: 4, train_loss: 1.813492, test loss: 1.036928, bias2: 0.944861888885498, variance: 0.09206584095954895\n",
      "Train size: [400] hidden size: [22] trial: 5, train_loss: 1.828393, test loss: 1.044544, bias2: 0.9450998902320862, variance: 0.0994442030787468\n",
      "Train size: [400] hidden size: [22] trial: 6, train_loss: 1.825908, test loss: 1.060891, bias2: 0.9424501061439514, variance: 0.11844068765640259\n",
      "Train size: [400] hidden size: [22] trial: 7, train_loss: 1.847700, test loss: 1.070002, bias2: 0.9345301985740662, variance: 0.13547129929065704\n",
      "Train size: [400] hidden size: [22] trial: 8, train_loss: 1.852989, test loss: 1.067492, bias2: 0.9334924221038818, variance: 0.13399991393089294\n",
      "Train size: [400] hidden size: [22] trial: 9, train_loss: 1.856985, test loss: 1.067130, bias2: 0.9269500970840454, variance: 0.14018025994300842\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [22] trial: 10, train_loss: 1.850543, test loss: 1.067524, bias2: 0.9263657331466675, variance: 0.14115847647190094\n",
      "Train size: [400] hidden size: [22] trial: 11, train_loss: 1.840175, test loss: 1.069882, bias2: 0.9260194897651672, variance: 0.1438625305891037\n",
      "Train size: [400] hidden size: [22] trial: 12, train_loss: 1.846291, test loss: 1.072447, bias2: 0.9242030382156372, variance: 0.1482439935207367\n",
      "Train size: [400] hidden size: [22] trial: 13, train_loss: 1.840611, test loss: 1.071270, bias2: 0.9206459522247314, variance: 0.15062390267848969\n",
      "Train size: [400] hidden size: [22] trial: 14, train_loss: 1.837814, test loss: 1.072708, bias2: 0.9148956537246704, variance: 0.1578127145767212\n",
      "Train size: [400] hidden size: [22] trial: 15, train_loss: 1.843554, test loss: 1.080498, bias2: 0.9131683111190796, variance: 0.16732928156852722\n",
      "Train size: [400] hidden size: [22] trial: 16, train_loss: 1.851859, test loss: 1.078191, bias2: 0.9138941764831543, variance: 0.16429641842842102\n",
      "Train size: [400] hidden size: [22] trial: 17, train_loss: 1.856070, test loss: 1.078439, bias2: 0.9158004522323608, variance: 0.1626383364200592\n",
      "Train size: [400] hidden size: [22] trial: 18, train_loss: 1.866176, test loss: 1.076670, bias2: 0.9180834889411926, variance: 0.15858690440654755\n",
      "Train size: [400] hidden size: [22] trial: 19, train_loss: 1.875435, test loss: 1.075587, bias2: 0.9202386736869812, variance: 0.15534837543964386\n",
      "Train size: [400] hidden size: [22] trial: 20, train_loss: 1.871659, test loss: 1.076218, bias2: 0.9220052361488342, variance: 0.15421265363693237\n",
      "Train size: [400] hidden size: [22] trial: 21, train_loss: 1.869867, test loss: 1.074976, bias2: 0.9239436984062195, variance: 0.15103214979171753\n",
      "Train size: [400] hidden size: [22] trial: 22, train_loss: 1.875028, test loss: 1.074230, bias2: 0.9248191118240356, variance: 0.14941097795963287\n",
      "Train size: [400] hidden size: [22] trial: 23, train_loss: 1.875862, test loss: 1.074330, bias2: 0.9260079860687256, variance: 0.14832232892513275\n",
      "Train size: [400] hidden size: [22] trial: 24, train_loss: 1.874138, test loss: 1.074100, bias2: 0.922261655330658, variance: 0.1518384963274002\n",
      "Train size: [400] hidden size: [22] trial: 25, train_loss: 1.871040, test loss: 1.073076, bias2: 0.9223061203956604, variance: 0.15076963603496552\n",
      "Train size: [400] hidden size: [22] trial: 26, train_loss: 1.871590, test loss: 1.076289, bias2: 0.9240889549255371, variance: 0.1521996408700943\n",
      "Train size: [400] hidden size: [22] trial: 27, train_loss: 1.868284, test loss: 1.076371, bias2: 0.9226002097129822, variance: 0.15377037227153778\n",
      "Train size: [400] hidden size: [22] trial: 28, train_loss: 1.862841, test loss: 1.078171, bias2: 0.922034740447998, variance: 0.15613581240177155\n",
      "Train size: [400] hidden size: [22] trial: 29, train_loss: 1.862785, test loss: 1.076331, bias2: 0.9192578196525574, variance: 0.1570732146501541\n",
      "Train size: [400] hidden size: [22] trial: 30, train_loss: 1.866014, test loss: 1.076318, bias2: 0.9194587469100952, variance: 0.1568596065044403\n",
      "Train size: [400] hidden size: [22] trial: 31, train_loss: 1.862521, test loss: 1.078186, bias2: 0.9193058609962463, variance: 0.1588805466890335\n",
      "Train size: [400] hidden size: [22] trial: 32, train_loss: 1.869249, test loss: 1.077096, bias2: 0.9187805652618408, variance: 0.15831518173217773\n",
      "Train size: [400] hidden size: [22] trial: 33, train_loss: 1.868349, test loss: 1.075528, bias2: 0.9194192886352539, variance: 0.15610864758491516\n",
      "Train size: [400] hidden size: [22] trial: 34, train_loss: 1.872907, test loss: 1.076221, bias2: 0.9195018410682678, variance: 0.15671904385089874\n",
      "Train size: [400] hidden size: [22] trial: 35, train_loss: 1.868594, test loss: 1.076664, bias2: 0.9172211289405823, variance: 0.1594424843788147\n",
      "Train size: [400] hidden size: [22] trial: 36, train_loss: 1.868446, test loss: 1.077273, bias2: 0.9176768660545349, variance: 0.15959639847278595\n",
      "Train size: [400] hidden size: [22] trial: 37, train_loss: 1.870535, test loss: 1.076870, bias2: 0.918450653553009, variance: 0.1584194153547287\n",
      "Train size: [400] hidden size: [22] trial: 38, train_loss: 1.871526, test loss: 1.076215, bias2: 0.9197463393211365, variance: 0.15646831691265106\n",
      "Train size: [400] hidden size: [22] trial: 39, train_loss: 1.867811, test loss: 1.076254, bias2: 0.9185835123062134, variance: 0.1576707512140274\n",
      "Train size: [400] hidden size: [22] trial: 40, train_loss: 1.867149, test loss: 1.076173, bias2: 0.918582558631897, variance: 0.1575908362865448\n",
      "Train size: [400] hidden size: [22] trial: 41, train_loss: 1.866329, test loss: 1.078339, bias2: 0.9182252883911133, variance: 0.16011394560337067\n",
      "Train size: [400] hidden size: [22] trial: 42, train_loss: 1.865530, test loss: 1.076965, bias2: 0.9168039560317993, variance: 0.16016127169132233\n",
      "Train size: [400] hidden size: [22] trial: 43, train_loss: 1.861136, test loss: 1.077701, bias2: 0.9172682762145996, variance: 0.16043248772621155\n",
      "Train size: [400] hidden size: [22] trial: 44, train_loss: 1.862716, test loss: 1.077127, bias2: 0.9164631366729736, variance: 0.16066370904445648\n",
      "Train size: [400] hidden size: [22] trial: 45, train_loss: 1.863042, test loss: 1.077175, bias2: 0.91584312915802, variance: 0.16133174300193787\n",
      "Train size: [400] hidden size: [22] trial: 46, train_loss: 1.862740, test loss: 1.076352, bias2: 0.9164924621582031, variance: 0.15985943377017975\n",
      "Train size: [400] hidden size: [22] trial: 47, train_loss: 1.861778, test loss: 1.079536, bias2: 0.9187024831771851, variance: 0.16083362698554993\n",
      "Train size: [400] hidden size: [22] trial: 48, train_loss: 1.863021, test loss: 1.078892, bias2: 0.9191561937332153, variance: 0.15973533689975739\n",
      "Train size: [400] hidden size: [22] trial: 49, train_loss: 1.861126, test loss: 1.079129, bias2: 0.9198076725006104, variance: 0.15932105481624603\n",
      "##################################################\n",
      "Train size: [400] hidden size: [25] trial: 0, train_loss: 1.673825, test loss: 1.097743, bias2: 1.097743034362793, variance: 7.785095901269301e-10\n",
      "Train size: [400] hidden size: [25] trial: 1, train_loss: 1.749715, test loss: 1.071779, bias2: 0.965998113155365, variance: 0.10578067600727081\n",
      "Train size: [400] hidden size: [25] trial: 2, train_loss: 1.730216, test loss: 1.060238, bias2: 0.9382171034812927, variance: 0.12202101200819016\n",
      "Train size: [400] hidden size: [25] trial: 3, train_loss: 1.849078, test loss: 1.079508, bias2: 0.9451950192451477, variance: 0.13431315124034882\n",
      "Train size: [400] hidden size: [25] trial: 4, train_loss: 1.887161, test loss: 1.082453, bias2: 0.9392926692962646, variance: 0.14316043257713318\n",
      "Train size: [400] hidden size: [25] trial: 5, train_loss: 1.904926, test loss: 1.086954, bias2: 0.9362197518348694, variance: 0.15073436498641968\n",
      "Train size: [400] hidden size: [25] trial: 6, train_loss: 1.907066, test loss: 1.082188, bias2: 0.9388250112533569, variance: 0.1433630883693695\n",
      "Train size: [400] hidden size: [25] trial: 7, train_loss: 1.888814, test loss: 1.076238, bias2: 0.9325666427612305, variance: 0.14367148280143738\n",
      "Train size: [400] hidden size: [25] trial: 8, train_loss: 1.891171, test loss: 1.076979, bias2: 0.9305738210678101, variance: 0.14640536904335022\n",
      "Train size: [400] hidden size: [25] trial: 9, train_loss: 1.890957, test loss: 1.073390, bias2: 0.9298908710479736, variance: 0.1434994637966156\n",
      "Train size: [400] hidden size: [25] trial: 10, train_loss: 1.880220, test loss: 1.075343, bias2: 0.9248955249786377, variance: 0.15044735372066498\n",
      "Train size: [400] hidden size: [25] trial: 11, train_loss: 1.873938, test loss: 1.072082, bias2: 0.9210750460624695, variance: 0.15100745856761932\n",
      "Train size: [400] hidden size: [25] trial: 12, train_loss: 1.883869, test loss: 1.076513, bias2: 0.9207543730735779, variance: 0.15575891733169556\n",
      "Train size: [400] hidden size: [25] trial: 13, train_loss: 1.889435, test loss: 1.080579, bias2: 0.924004852771759, variance: 0.15657395124435425\n",
      "Train size: [400] hidden size: [25] trial: 14, train_loss: 1.886976, test loss: 1.078053, bias2: 0.9232360124588013, variance: 0.15481719374656677\n",
      "Train size: [400] hidden size: [25] trial: 15, train_loss: 1.892417, test loss: 1.082682, bias2: 0.9244859218597412, variance: 0.1581956446170807\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [25] trial: 16, train_loss: 1.904795, test loss: 1.082646, bias2: 0.9241929650306702, variance: 0.1584525853395462\n",
      "Train size: [400] hidden size: [25] trial: 17, train_loss: 1.896581, test loss: 1.080188, bias2: 0.922661304473877, variance: 0.15752647817134857\n",
      "Train size: [400] hidden size: [25] trial: 18, train_loss: 1.904177, test loss: 1.081314, bias2: 0.9217374920845032, variance: 0.15957635641098022\n",
      "Train size: [400] hidden size: [25] trial: 19, train_loss: 1.896793, test loss: 1.080276, bias2: 0.919685423374176, variance: 0.16059021651744843\n",
      "Train size: [400] hidden size: [25] trial: 20, train_loss: 1.904889, test loss: 1.083720, bias2: 0.9182732105255127, variance: 0.16544723510742188\n",
      "Train size: [400] hidden size: [25] trial: 21, train_loss: 1.900744, test loss: 1.082474, bias2: 0.9175490140914917, variance: 0.16492484509944916\n",
      "Train size: [400] hidden size: [25] trial: 22, train_loss: 1.912241, test loss: 1.084109, bias2: 0.9150923490524292, variance: 0.16901670396327972\n",
      "Train size: [400] hidden size: [25] trial: 23, train_loss: 1.903579, test loss: 1.081468, bias2: 0.9144690036773682, variance: 0.1669989973306656\n",
      "Train size: [400] hidden size: [25] trial: 24, train_loss: 1.901182, test loss: 1.078409, bias2: 0.9117006063461304, variance: 0.16670814156532288\n",
      "Train size: [400] hidden size: [25] trial: 25, train_loss: 1.897835, test loss: 1.077373, bias2: 0.9135403037071228, variance: 0.16383258998394012\n",
      "Train size: [400] hidden size: [25] trial: 26, train_loss: 1.893098, test loss: 1.076756, bias2: 0.9124544858932495, variance: 0.16430149972438812\n",
      "Train size: [400] hidden size: [25] trial: 27, train_loss: 1.890973, test loss: 1.077061, bias2: 0.9111315608024597, variance: 0.16592949628829956\n",
      "Train size: [400] hidden size: [25] trial: 28, train_loss: 1.892368, test loss: 1.075157, bias2: 0.9092369079589844, variance: 0.16591981053352356\n",
      "Train size: [400] hidden size: [25] trial: 29, train_loss: 1.882028, test loss: 1.073315, bias2: 0.9097360968589783, variance: 0.16357938945293427\n",
      "Train size: [400] hidden size: [25] trial: 30, train_loss: 1.883704, test loss: 1.073899, bias2: 0.9095202088356018, variance: 0.16437895596027374\n",
      "Train size: [400] hidden size: [25] trial: 31, train_loss: 1.881592, test loss: 1.075601, bias2: 0.9098544716835022, variance: 0.16574686765670776\n",
      "Train size: [400] hidden size: [25] trial: 32, train_loss: 1.877975, test loss: 1.075904, bias2: 0.9094176888465881, variance: 0.1664864420890808\n",
      "Train size: [400] hidden size: [25] trial: 33, train_loss: 1.882151, test loss: 1.075301, bias2: 0.9106777906417847, variance: 0.16462339460849762\n",
      "Train size: [400] hidden size: [25] trial: 34, train_loss: 1.876130, test loss: 1.074191, bias2: 0.9109286665916443, variance: 0.16326220333576202\n",
      "Train size: [400] hidden size: [25] trial: 35, train_loss: 1.870205, test loss: 1.075308, bias2: 0.9113889932632446, variance: 0.16391919553279877\n",
      "Train size: [400] hidden size: [25] trial: 36, train_loss: 1.868374, test loss: 1.076226, bias2: 0.9115108251571655, variance: 0.16471529006958008\n",
      "Train size: [400] hidden size: [25] trial: 37, train_loss: 1.865357, test loss: 1.075847, bias2: 0.913055419921875, variance: 0.16279157996177673\n",
      "Train size: [400] hidden size: [25] trial: 38, train_loss: 1.866746, test loss: 1.076712, bias2: 0.9137450456619263, variance: 0.16296647489070892\n",
      "Train size: [400] hidden size: [25] trial: 39, train_loss: 1.860190, test loss: 1.077998, bias2: 0.9146063327789307, variance: 0.1633920669555664\n",
      "Train size: [400] hidden size: [25] trial: 40, train_loss: 1.862173, test loss: 1.079789, bias2: 0.915595293045044, variance: 0.164194256067276\n",
      "Train size: [400] hidden size: [25] trial: 41, train_loss: 1.857250, test loss: 1.078991, bias2: 0.915688157081604, variance: 0.16330279409885406\n",
      "Train size: [400] hidden size: [25] trial: 42, train_loss: 1.855088, test loss: 1.078807, bias2: 0.913199782371521, variance: 0.16560688614845276\n",
      "Train size: [400] hidden size: [25] trial: 43, train_loss: 1.855194, test loss: 1.078355, bias2: 0.9133356809616089, variance: 0.16501925885677338\n",
      "Train size: [400] hidden size: [25] trial: 44, train_loss: 1.855133, test loss: 1.078384, bias2: 0.914260745048523, variance: 0.16412284970283508\n",
      "Train size: [400] hidden size: [25] trial: 45, train_loss: 1.852789, test loss: 1.077963, bias2: 0.9149466753005981, variance: 0.16301611065864563\n",
      "Train size: [400] hidden size: [25] trial: 46, train_loss: 1.855092, test loss: 1.079227, bias2: 0.9147779941558838, variance: 0.16444921493530273\n",
      "Train size: [400] hidden size: [25] trial: 47, train_loss: 1.854561, test loss: 1.080550, bias2: 0.9146005511283875, variance: 0.1659497618675232\n",
      "Train size: [400] hidden size: [25] trial: 48, train_loss: 1.857752, test loss: 1.080640, bias2: 0.9150797128677368, variance: 0.16556058824062347\n",
      "Train size: [400] hidden size: [25] trial: 49, train_loss: 1.854013, test loss: 1.081157, bias2: 0.9151831269264221, variance: 0.1659739762544632\n",
      "##################################################\n",
      "Train size: [400] hidden size: [29] trial: 0, train_loss: 1.835726, test loss: 1.044201, bias2: 1.044201374053955, variance: 6.811959329944273e-10\n",
      "Train size: [400] hidden size: [29] trial: 1, train_loss: 1.767024, test loss: 1.055491, bias2: 0.9548752903938293, variance: 0.10061614215373993\n",
      "Train size: [400] hidden size: [29] trial: 2, train_loss: 1.777649, test loss: 1.048742, bias2: 0.9314784407615662, variance: 0.11726327240467072\n",
      "Train size: [400] hidden size: [29] trial: 3, train_loss: 1.753551, test loss: 1.058685, bias2: 0.9141496419906616, variance: 0.1445351541042328\n",
      "Train size: [400] hidden size: [29] trial: 4, train_loss: 1.768371, test loss: 1.063127, bias2: 0.9114639163017273, variance: 0.15166300535202026\n",
      "Train size: [400] hidden size: [29] trial: 5, train_loss: 1.786716, test loss: 1.063167, bias2: 0.9007528424263, variance: 0.16241376101970673\n",
      "Train size: [400] hidden size: [29] trial: 6, train_loss: 1.802135, test loss: 1.061869, bias2: 0.9058382511138916, variance: 0.15603111684322357\n",
      "Train size: [400] hidden size: [29] trial: 7, train_loss: 1.817812, test loss: 1.075114, bias2: 0.916857898235321, variance: 0.15825574100017548\n",
      "Train size: [400] hidden size: [29] trial: 8, train_loss: 1.801964, test loss: 1.073208, bias2: 0.9157339334487915, variance: 0.15747438371181488\n",
      "Train size: [400] hidden size: [29] trial: 9, train_loss: 1.805386, test loss: 1.076355, bias2: 0.9063670635223389, variance: 0.16998788714408875\n",
      "Train size: [400] hidden size: [29] trial: 10, train_loss: 1.820501, test loss: 1.086494, bias2: 0.9099749326705933, variance: 0.17651888728141785\n",
      "Train size: [400] hidden size: [29] trial: 11, train_loss: 1.829251, test loss: 1.090469, bias2: 0.911021888256073, variance: 0.1794472336769104\n",
      "Train size: [400] hidden size: [29] trial: 12, train_loss: 1.828289, test loss: 1.095215, bias2: 0.9110187292098999, variance: 0.18419668078422546\n",
      "Train size: [400] hidden size: [29] trial: 13, train_loss: 1.818977, test loss: 1.093501, bias2: 0.9066230654716492, variance: 0.1868782788515091\n",
      "Train size: [400] hidden size: [29] trial: 14, train_loss: 1.811158, test loss: 1.093854, bias2: 0.9058664441108704, variance: 0.18798761069774628\n",
      "Train size: [400] hidden size: [29] trial: 15, train_loss: 1.806899, test loss: 1.094917, bias2: 0.9062623977661133, variance: 0.18865439295768738\n",
      "Train size: [400] hidden size: [29] trial: 16, train_loss: 1.803232, test loss: 1.097819, bias2: 0.9063021540641785, variance: 0.1915164589881897\n",
      "Train size: [400] hidden size: [29] trial: 17, train_loss: 1.801803, test loss: 1.096067, bias2: 0.9022766947746277, variance: 0.19379059970378876\n",
      "Train size: [400] hidden size: [29] trial: 18, train_loss: 1.805746, test loss: 1.100106, bias2: 0.9049965143203735, variance: 0.19510969519615173\n",
      "Train size: [400] hidden size: [29] trial: 19, train_loss: 1.797114, test loss: 1.099682, bias2: 0.8986688852310181, variance: 0.20101331174373627\n",
      "Train size: [400] hidden size: [29] trial: 20, train_loss: 1.795337, test loss: 1.102609, bias2: 0.8982909917831421, variance: 0.20431813597679138\n",
      "Train size: [400] hidden size: [29] trial: 21, train_loss: 1.788218, test loss: 1.103025, bias2: 0.8952612280845642, variance: 0.20776374638080597\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [29] trial: 22, train_loss: 1.786591, test loss: 1.104613, bias2: 0.8942539095878601, variance: 0.21035951375961304\n",
      "Train size: [400] hidden size: [29] trial: 23, train_loss: 1.783497, test loss: 1.106808, bias2: 0.8915223479270935, variance: 0.21528582274913788\n",
      "Train size: [400] hidden size: [29] trial: 24, train_loss: 1.774092, test loss: 1.104835, bias2: 0.892920732498169, variance: 0.21191462874412537\n",
      "Train size: [400] hidden size: [29] trial: 25, train_loss: 1.783383, test loss: 1.105720, bias2: 0.8963922262191772, variance: 0.20932747423648834\n",
      "Train size: [400] hidden size: [29] trial: 26, train_loss: 1.778113, test loss: 1.104883, bias2: 0.8968732953071594, variance: 0.20801003277301788\n",
      "Train size: [400] hidden size: [29] trial: 27, train_loss: 1.770894, test loss: 1.104400, bias2: 0.8966562747955322, variance: 0.20774391293525696\n",
      "Train size: [400] hidden size: [29] trial: 28, train_loss: 1.778534, test loss: 1.103057, bias2: 0.8957309722900391, variance: 0.20732615888118744\n",
      "Train size: [400] hidden size: [29] trial: 29, train_loss: 1.777344, test loss: 1.103117, bias2: 0.8975532054901123, variance: 0.2055637687444687\n",
      "Train size: [400] hidden size: [29] trial: 30, train_loss: 1.782310, test loss: 1.102544, bias2: 0.8973311185836792, variance: 0.20521317422389984\n",
      "Train size: [400] hidden size: [29] trial: 31, train_loss: 1.786681, test loss: 1.102868, bias2: 0.8956950902938843, variance: 0.20717261731624603\n",
      "Train size: [400] hidden size: [29] trial: 32, train_loss: 1.784165, test loss: 1.101263, bias2: 0.8939211368560791, variance: 0.2073417603969574\n",
      "Train size: [400] hidden size: [29] trial: 33, train_loss: 1.783414, test loss: 1.101909, bias2: 0.8945635557174683, variance: 0.2073456346988678\n",
      "Train size: [400] hidden size: [29] trial: 34, train_loss: 1.782826, test loss: 1.101452, bias2: 0.89436936378479, variance: 0.20708218216896057\n",
      "Train size: [400] hidden size: [29] trial: 35, train_loss: 1.785770, test loss: 1.102201, bias2: 0.8958633542060852, variance: 0.20633749663829803\n",
      "Train size: [400] hidden size: [29] trial: 36, train_loss: 1.791269, test loss: 1.102132, bias2: 0.8974784016609192, variance: 0.20465344190597534\n",
      "Train size: [400] hidden size: [29] trial: 37, train_loss: 1.798559, test loss: 1.105180, bias2: 0.8962166905403137, variance: 0.2089635580778122\n",
      "Train size: [400] hidden size: [29] trial: 38, train_loss: 1.802821, test loss: 1.105637, bias2: 0.8970516920089722, variance: 0.2085857093334198\n",
      "Train size: [400] hidden size: [29] trial: 39, train_loss: 1.802125, test loss: 1.105124, bias2: 0.8962125182151794, variance: 0.20891159772872925\n",
      "Train size: [400] hidden size: [29] trial: 40, train_loss: 1.797235, test loss: 1.104831, bias2: 0.8966941833496094, variance: 0.2081366777420044\n",
      "Train size: [400] hidden size: [29] trial: 41, train_loss: 1.794083, test loss: 1.104540, bias2: 0.8964810371398926, variance: 0.2080589234828949\n",
      "Train size: [400] hidden size: [29] trial: 42, train_loss: 1.792747, test loss: 1.104991, bias2: 0.8957659006118774, variance: 0.20922504365444183\n",
      "Train size: [400] hidden size: [29] trial: 43, train_loss: 1.795320, test loss: 1.106016, bias2: 0.8950856328010559, variance: 0.21093039214611053\n",
      "Train size: [400] hidden size: [29] trial: 44, train_loss: 1.791259, test loss: 1.107544, bias2: 0.8959784507751465, variance: 0.2115652859210968\n",
      "Train size: [400] hidden size: [29] trial: 45, train_loss: 1.788169, test loss: 1.107082, bias2: 0.8962974548339844, variance: 0.21078452467918396\n",
      "Train size: [400] hidden size: [29] trial: 46, train_loss: 1.789249, test loss: 1.106316, bias2: 0.8961285352706909, variance: 0.2101874202489853\n",
      "Train size: [400] hidden size: [29] trial: 47, train_loss: 1.785513, test loss: 1.105415, bias2: 0.8959468603134155, variance: 0.20946861803531647\n",
      "Train size: [400] hidden size: [29] trial: 48, train_loss: 1.788630, test loss: 1.105599, bias2: 0.8958951830863953, variance: 0.2097042351961136\n",
      "Train size: [400] hidden size: [29] trial: 49, train_loss: 1.793498, test loss: 1.105070, bias2: 0.896800696849823, variance: 0.2082691788673401\n",
      "##################################################\n",
      "Train size: [400] hidden size: [33] trial: 0, train_loss: 1.749372, test loss: 1.080023, bias2: 1.0800235271453857, variance: 1.0704507280578923e-09\n",
      "Train size: [400] hidden size: [33] trial: 1, train_loss: 1.741477, test loss: 1.097134, bias2: 1.016933798789978, variance: 0.08020061999559402\n",
      "Train size: [400] hidden size: [33] trial: 2, train_loss: 1.784686, test loss: 1.112952, bias2: 0.9991204142570496, variance: 0.11383181810379028\n",
      "Train size: [400] hidden size: [33] trial: 3, train_loss: 1.768481, test loss: 1.108482, bias2: 0.9795309901237488, variance: 0.12895075976848602\n",
      "Train size: [400] hidden size: [33] trial: 4, train_loss: 1.761449, test loss: 1.107449, bias2: 0.9631592035293579, variance: 0.14428934454917908\n",
      "Train size: [400] hidden size: [33] trial: 5, train_loss: 1.774390, test loss: 1.109639, bias2: 0.9391207695007324, variance: 0.17051813006401062\n",
      "Train size: [400] hidden size: [33] trial: 6, train_loss: 1.747714, test loss: 1.107132, bias2: 0.9354590177536011, variance: 0.17167316377162933\n",
      "Train size: [400] hidden size: [33] trial: 7, train_loss: 1.756798, test loss: 1.103118, bias2: 0.9341952204704285, variance: 0.16892296075820923\n",
      "Train size: [400] hidden size: [33] trial: 8, train_loss: 1.753500, test loss: 1.097302, bias2: 0.9251117706298828, variance: 0.1721900999546051\n",
      "Train size: [400] hidden size: [33] trial: 9, train_loss: 1.742164, test loss: 1.098505, bias2: 0.9262927770614624, variance: 0.17221227288246155\n",
      "Train size: [400] hidden size: [33] trial: 10, train_loss: 1.754440, test loss: 1.093321, bias2: 0.9213299751281738, variance: 0.17199137806892395\n",
      "Train size: [400] hidden size: [33] trial: 11, train_loss: 1.727572, test loss: 1.092565, bias2: 0.9182116389274597, variance: 0.17435340583324432\n",
      "Train size: [400] hidden size: [33] trial: 12, train_loss: 1.742576, test loss: 1.091752, bias2: 0.9143487215042114, variance: 0.17740358412265778\n",
      "Train size: [400] hidden size: [33] trial: 13, train_loss: 1.727220, test loss: 1.093291, bias2: 0.9127123355865479, variance: 0.18057869374752045\n",
      "Train size: [400] hidden size: [33] trial: 14, train_loss: 1.739952, test loss: 1.094543, bias2: 0.9117532968521118, variance: 0.18278957903385162\n",
      "Train size: [400] hidden size: [33] trial: 15, train_loss: 1.748393, test loss: 1.098708, bias2: 0.9115868210792542, variance: 0.18712155520915985\n",
      "Train size: [400] hidden size: [33] trial: 16, train_loss: 1.750977, test loss: 1.099803, bias2: 0.9113792777061462, variance: 0.18842393159866333\n",
      "Train size: [400] hidden size: [33] trial: 17, train_loss: 1.764229, test loss: 1.098277, bias2: 0.9087177515029907, variance: 0.18955954909324646\n",
      "Train size: [400] hidden size: [33] trial: 18, train_loss: 1.760492, test loss: 1.100482, bias2: 0.9098430275917053, variance: 0.1906391978263855\n",
      "Train size: [400] hidden size: [33] trial: 19, train_loss: 1.764684, test loss: 1.103232, bias2: 0.9092322587966919, variance: 0.19399937987327576\n",
      "Train size: [400] hidden size: [33] trial: 20, train_loss: 1.765898, test loss: 1.103322, bias2: 0.9040231108665466, variance: 0.19929878413677216\n",
      "Train size: [400] hidden size: [33] trial: 21, train_loss: 1.760161, test loss: 1.105824, bias2: 0.9049493074417114, variance: 0.2008747160434723\n",
      "Train size: [400] hidden size: [33] trial: 22, train_loss: 1.768474, test loss: 1.108754, bias2: 0.9057737588882446, variance: 0.2029804289340973\n",
      "Train size: [400] hidden size: [33] trial: 23, train_loss: 1.772695, test loss: 1.106978, bias2: 0.9033781290054321, variance: 0.20360031723976135\n",
      "Train size: [400] hidden size: [33] trial: 24, train_loss: 1.768081, test loss: 1.107224, bias2: 0.902064323425293, variance: 0.2051597684621811\n",
      "Train size: [400] hidden size: [33] trial: 25, train_loss: 1.767948, test loss: 1.109240, bias2: 0.9020257592201233, variance: 0.20721392333507538\n",
      "Train size: [400] hidden size: [33] trial: 26, train_loss: 1.771546, test loss: 1.108329, bias2: 0.9024978280067444, variance: 0.20583146810531616\n",
      "Train size: [400] hidden size: [33] trial: 27, train_loss: 1.768344, test loss: 1.108968, bias2: 0.9018697738647461, variance: 0.20709797739982605\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [33] trial: 28, train_loss: 1.778631, test loss: 1.109477, bias2: 0.9017825126647949, variance: 0.2076941728591919\n",
      "Train size: [400] hidden size: [33] trial: 29, train_loss: 1.777427, test loss: 1.109449, bias2: 0.90220707654953, variance: 0.20724241435527802\n",
      "Train size: [400] hidden size: [33] trial: 30, train_loss: 1.772207, test loss: 1.109851, bias2: 0.9019090533256531, variance: 0.2079417109489441\n",
      "Train size: [400] hidden size: [33] trial: 31, train_loss: 1.779659, test loss: 1.109690, bias2: 0.9025506377220154, variance: 0.20713895559310913\n",
      "Train size: [400] hidden size: [33] trial: 32, train_loss: 1.777308, test loss: 1.107556, bias2: 0.8996281027793884, variance: 0.2079276591539383\n",
      "Train size: [400] hidden size: [33] trial: 33, train_loss: 1.776878, test loss: 1.105579, bias2: 0.8969696164131165, variance: 0.20860929787158966\n",
      "Train size: [400] hidden size: [33] trial: 34, train_loss: 1.776370, test loss: 1.106898, bias2: 0.898090660572052, variance: 0.2088070660829544\n",
      "Train size: [400] hidden size: [33] trial: 35, train_loss: 1.770247, test loss: 1.105741, bias2: 0.8988491892814636, variance: 0.20689146220684052\n",
      "Train size: [400] hidden size: [33] trial: 36, train_loss: 1.771943, test loss: 1.104815, bias2: 0.8977934122085571, variance: 0.207021102309227\n",
      "Train size: [400] hidden size: [33] trial: 37, train_loss: 1.778226, test loss: 1.105026, bias2: 0.8972101211547852, variance: 0.2078160047531128\n",
      "Train size: [400] hidden size: [33] trial: 38, train_loss: 1.777687, test loss: 1.104652, bias2: 0.8982105851173401, variance: 0.20644168555736542\n",
      "Train size: [400] hidden size: [33] trial: 39, train_loss: 1.778984, test loss: 1.104098, bias2: 0.897981584072113, variance: 0.20611639320850372\n",
      "Train size: [400] hidden size: [33] trial: 40, train_loss: 1.777153, test loss: 1.103988, bias2: 0.8938570022583008, variance: 0.21013151109218597\n",
      "Train size: [400] hidden size: [33] trial: 41, train_loss: 1.777473, test loss: 1.103641, bias2: 0.8949445486068726, variance: 0.20869648456573486\n",
      "Train size: [400] hidden size: [33] trial: 42, train_loss: 1.775728, test loss: 1.104300, bias2: 0.8940113186836243, variance: 0.21028868854045868\n",
      "Train size: [400] hidden size: [33] trial: 43, train_loss: 1.770518, test loss: 1.105784, bias2: 0.8950909376144409, variance: 0.21069350838661194\n",
      "Train size: [400] hidden size: [33] trial: 44, train_loss: 1.766755, test loss: 1.107575, bias2: 0.8936284780502319, variance: 0.21394693851470947\n",
      "Train size: [400] hidden size: [33] trial: 45, train_loss: 1.765936, test loss: 1.106309, bias2: 0.8902398347854614, variance: 0.21606937050819397\n",
      "Train size: [400] hidden size: [33] trial: 46, train_loss: 1.768465, test loss: 1.105707, bias2: 0.8901403546333313, variance: 0.21556705236434937\n",
      "Train size: [400] hidden size: [33] trial: 47, train_loss: 1.770105, test loss: 1.105710, bias2: 0.8904110193252563, variance: 0.21529936790466309\n",
      "Train size: [400] hidden size: [33] trial: 48, train_loss: 1.768608, test loss: 1.105601, bias2: 0.8905430436134338, variance: 0.21505765616893768\n",
      "Train size: [400] hidden size: [33] trial: 49, train_loss: 1.766858, test loss: 1.104745, bias2: 0.8903341293334961, variance: 0.21441124379634857\n",
      "##################################################\n",
      "Train size: [400] hidden size: [38] trial: 0, train_loss: 1.724370, test loss: 1.091017, bias2: 1.0910168886184692, variance: -2.0435877434721306e-09\n",
      "Train size: [400] hidden size: [38] trial: 1, train_loss: 1.651896, test loss: 1.108697, bias2: 0.9726192355155945, variance: 0.13607831299304962\n",
      "Train size: [400] hidden size: [38] trial: 2, train_loss: 1.686922, test loss: 1.109537, bias2: 0.9503951072692871, variance: 0.1591413915157318\n",
      "Train size: [400] hidden size: [38] trial: 3, train_loss: 1.682913, test loss: 1.101374, bias2: 0.9255064725875854, variance: 0.17586781084537506\n",
      "Train size: [400] hidden size: [38] trial: 4, train_loss: 1.673554, test loss: 1.110509, bias2: 0.9186480641365051, variance: 0.19186073541641235\n",
      "Train size: [400] hidden size: [38] trial: 5, train_loss: 1.645060, test loss: 1.112963, bias2: 0.9157719612121582, variance: 0.1971907615661621\n",
      "Train size: [400] hidden size: [38] trial: 6, train_loss: 1.634308, test loss: 1.103983, bias2: 0.9058051705360413, variance: 0.1981779783964157\n",
      "Train size: [400] hidden size: [38] trial: 7, train_loss: 1.633590, test loss: 1.101880, bias2: 0.8975312113761902, variance: 0.20434872806072235\n",
      "Train size: [400] hidden size: [38] trial: 8, train_loss: 1.630314, test loss: 1.103503, bias2: 0.8970962762832642, variance: 0.20640668272972107\n",
      "Train size: [400] hidden size: [38] trial: 9, train_loss: 1.640797, test loss: 1.110812, bias2: 0.8975433707237244, variance: 0.2132686823606491\n",
      "Train size: [400] hidden size: [38] trial: 10, train_loss: 1.647291, test loss: 1.115496, bias2: 0.8980299830436707, variance: 0.21746568381786346\n",
      "Train size: [400] hidden size: [38] trial: 11, train_loss: 1.652386, test loss: 1.113471, bias2: 0.8921734094619751, variance: 0.22129715979099274\n",
      "Train size: [400] hidden size: [38] trial: 12, train_loss: 1.653682, test loss: 1.119390, bias2: 0.8953133821487427, variance: 0.2240763008594513\n",
      "Train size: [400] hidden size: [38] trial: 13, train_loss: 1.658300, test loss: 1.127716, bias2: 0.8970086574554443, variance: 0.23070742189884186\n",
      "Train size: [400] hidden size: [38] trial: 14, train_loss: 1.670446, test loss: 1.127906, bias2: 0.8976002931594849, variance: 0.23030541837215424\n",
      "Train size: [400] hidden size: [38] trial: 15, train_loss: 1.673112, test loss: 1.133633, bias2: 0.8924921154975891, variance: 0.2411404252052307\n",
      "Train size: [400] hidden size: [38] trial: 16, train_loss: 1.671056, test loss: 1.132233, bias2: 0.8924674391746521, variance: 0.23976606130599976\n",
      "Train size: [400] hidden size: [38] trial: 17, train_loss: 1.659635, test loss: 1.130922, bias2: 0.8905298113822937, variance: 0.2403925061225891\n",
      "Train size: [400] hidden size: [38] trial: 18, train_loss: 1.656720, test loss: 1.127671, bias2: 0.891520082950592, variance: 0.23615069687366486\n",
      "Train size: [400] hidden size: [38] trial: 19, train_loss: 1.661262, test loss: 1.130258, bias2: 0.8930473327636719, variance: 0.23721112310886383\n",
      "Train size: [400] hidden size: [38] trial: 20, train_loss: 1.660681, test loss: 1.128108, bias2: 0.893651008605957, variance: 0.2344571053981781\n",
      "Train size: [400] hidden size: [38] trial: 21, train_loss: 1.654665, test loss: 1.126745, bias2: 0.8912969827651978, variance: 0.23544776439666748\n",
      "Train size: [400] hidden size: [38] trial: 22, train_loss: 1.661201, test loss: 1.127354, bias2: 0.8921549320220947, variance: 0.23519909381866455\n",
      "Train size: [400] hidden size: [38] trial: 23, train_loss: 1.664681, test loss: 1.127383, bias2: 0.8938174247741699, variance: 0.23356546461582184\n",
      "Train size: [400] hidden size: [38] trial: 24, train_loss: 1.674225, test loss: 1.126636, bias2: 0.8937541842460632, variance: 0.23288162052631378\n",
      "Train size: [400] hidden size: [38] trial: 25, train_loss: 1.678315, test loss: 1.125390, bias2: 0.8932875394821167, variance: 0.23210299015045166\n",
      "Train size: [400] hidden size: [38] trial: 26, train_loss: 1.674562, test loss: 1.124126, bias2: 0.891899824142456, variance: 0.2322261482477188\n",
      "Train size: [400] hidden size: [38] trial: 27, train_loss: 1.674634, test loss: 1.125930, bias2: 0.8906542062759399, variance: 0.23527559638023376\n",
      "Train size: [400] hidden size: [38] trial: 28, train_loss: 1.681821, test loss: 1.125588, bias2: 0.8900001049041748, variance: 0.23558829724788666\n",
      "Train size: [400] hidden size: [38] trial: 29, train_loss: 1.687984, test loss: 1.125466, bias2: 0.8893532752990723, variance: 0.23611317574977875\n",
      "Train size: [400] hidden size: [38] trial: 30, train_loss: 1.696371, test loss: 1.123557, bias2: 0.8881629705429077, variance: 0.23539450764656067\n",
      "Train size: [400] hidden size: [38] trial: 31, train_loss: 1.695718, test loss: 1.122049, bias2: 0.889022946357727, variance: 0.23302611708641052\n",
      "Train size: [400] hidden size: [38] trial: 32, train_loss: 1.702235, test loss: 1.123006, bias2: 0.8872776627540588, variance: 0.2357279509305954\n",
      "Train size: [400] hidden size: [38] trial: 33, train_loss: 1.703208, test loss: 1.122144, bias2: 0.8876767754554749, variance: 0.23446720838546753\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [38] trial: 34, train_loss: 1.707742, test loss: 1.121343, bias2: 0.8839413523674011, variance: 0.23740142583847046\n",
      "Train size: [400] hidden size: [38] trial: 35, train_loss: 1.715239, test loss: 1.122096, bias2: 0.8848575949668884, variance: 0.23723846673965454\n",
      "Train size: [400] hidden size: [38] trial: 36, train_loss: 1.711032, test loss: 1.120855, bias2: 0.8850791454315186, variance: 0.23577572405338287\n",
      "Train size: [400] hidden size: [38] trial: 37, train_loss: 1.712949, test loss: 1.119380, bias2: 0.8845939040184021, variance: 0.2347862273454666\n",
      "Train size: [400] hidden size: [38] trial: 38, train_loss: 1.718179, test loss: 1.118458, bias2: 0.8841208219528198, variance: 0.2343369871377945\n",
      "Train size: [400] hidden size: [38] trial: 39, train_loss: 1.716538, test loss: 1.119379, bias2: 0.8816168308258057, variance: 0.2377617508172989\n",
      "Train size: [400] hidden size: [38] trial: 40, train_loss: 1.714986, test loss: 1.120278, bias2: 0.8805490136146545, variance: 0.2397288829088211\n",
      "Train size: [400] hidden size: [38] trial: 41, train_loss: 1.712015, test loss: 1.120230, bias2: 0.8826767802238464, variance: 0.2375534176826477\n",
      "Train size: [400] hidden size: [38] trial: 42, train_loss: 1.713513, test loss: 1.119544, bias2: 0.8825421333312988, variance: 0.2370019257068634\n",
      "Train size: [400] hidden size: [38] trial: 43, train_loss: 1.712477, test loss: 1.119434, bias2: 0.8816084861755371, variance: 0.23782598972320557\n",
      "Train size: [400] hidden size: [38] trial: 44, train_loss: 1.714486, test loss: 1.119756, bias2: 0.8801131248474121, variance: 0.2396424114704132\n",
      "Train size: [400] hidden size: [38] trial: 45, train_loss: 1.713939, test loss: 1.120639, bias2: 0.8795046806335449, variance: 0.24113425612449646\n",
      "Train size: [400] hidden size: [38] trial: 46, train_loss: 1.712786, test loss: 1.123194, bias2: 0.8804155588150024, variance: 0.24277864396572113\n",
      "Train size: [400] hidden size: [38] trial: 47, train_loss: 1.711128, test loss: 1.123084, bias2: 0.8815491795539856, variance: 0.24153487384319305\n",
      "Train size: [400] hidden size: [38] trial: 48, train_loss: 1.708026, test loss: 1.125041, bias2: 0.8817771673202515, variance: 0.24326345324516296\n",
      "Train size: [400] hidden size: [38] trial: 49, train_loss: 1.705481, test loss: 1.126879, bias2: 0.8820285797119141, variance: 0.2448505461215973\n",
      "##################################################\n",
      "Train size: [400] hidden size: [44] trial: 0, train_loss: 1.670735, test loss: 1.156222, bias2: 1.156221866607666, variance: 1.9462739753173253e-10\n",
      "Train size: [400] hidden size: [44] trial: 1, train_loss: 1.701499, test loss: 1.192578, bias2: 1.0160993337631226, variance: 0.1764790266752243\n",
      "Train size: [400] hidden size: [44] trial: 2, train_loss: 1.644463, test loss: 1.153887, bias2: 0.9530676603317261, variance: 0.20081986486911774\n",
      "Train size: [400] hidden size: [44] trial: 3, train_loss: 1.662421, test loss: 1.153989, bias2: 0.9400193691253662, variance: 0.21396957337856293\n",
      "Train size: [400] hidden size: [44] trial: 4, train_loss: 1.721250, test loss: 1.150803, bias2: 0.9279782176017761, variance: 0.22282475233078003\n",
      "Train size: [400] hidden size: [44] trial: 5, train_loss: 1.675527, test loss: 1.172376, bias2: 0.8969900608062744, variance: 0.2753854990005493\n",
      "Train size: [400] hidden size: [44] trial: 6, train_loss: 1.691884, test loss: 1.182292, bias2: 0.898951530456543, variance: 0.2833402156829834\n",
      "Train size: [400] hidden size: [44] trial: 7, train_loss: 1.719884, test loss: 1.186400, bias2: 0.8919281363487244, variance: 0.2944720387458801\n",
      "Train size: [400] hidden size: [44] trial: 8, train_loss: 1.702033, test loss: 1.190888, bias2: 0.8885543942451477, variance: 0.3023340106010437\n",
      "Train size: [400] hidden size: [44] trial: 9, train_loss: 1.712451, test loss: 1.198304, bias2: 0.8916080594062805, variance: 0.306696355342865\n",
      "Train size: [400] hidden size: [44] trial: 10, train_loss: 1.720694, test loss: 1.194974, bias2: 0.8873093128204346, variance: 0.30766451358795166\n",
      "Train size: [400] hidden size: [44] trial: 11, train_loss: 1.720648, test loss: 1.186093, bias2: 0.887543797492981, variance: 0.2985488176345825\n",
      "Train size: [400] hidden size: [44] trial: 12, train_loss: 1.722788, test loss: 1.186956, bias2: 0.888055145740509, variance: 0.2989012598991394\n",
      "Train size: [400] hidden size: [44] trial: 13, train_loss: 1.734339, test loss: 1.191274, bias2: 0.8935023546218872, variance: 0.297772079706192\n",
      "Train size: [400] hidden size: [44] trial: 14, train_loss: 1.748595, test loss: 1.187065, bias2: 0.8926371335983276, variance: 0.29442811012268066\n",
      "Train size: [400] hidden size: [44] trial: 15, train_loss: 1.740479, test loss: 1.182505, bias2: 0.8892285823822021, variance: 0.29327645897865295\n",
      "Train size: [400] hidden size: [44] trial: 16, train_loss: 1.737788, test loss: 1.185395, bias2: 0.8879662752151489, variance: 0.2974291741847992\n",
      "Train size: [400] hidden size: [44] trial: 17, train_loss: 1.736667, test loss: 1.185748, bias2: 0.8871437311172485, variance: 0.2986047565937042\n",
      "Train size: [400] hidden size: [44] trial: 18, train_loss: 1.748438, test loss: 1.184110, bias2: 0.8828378915786743, variance: 0.3012716472148895\n",
      "Train size: [400] hidden size: [44] trial: 19, train_loss: 1.747987, test loss: 1.177728, bias2: 0.8772836923599243, variance: 0.30044445395469666\n",
      "Train size: [400] hidden size: [44] trial: 20, train_loss: 1.738739, test loss: 1.175736, bias2: 0.8750346302986145, variance: 0.3007015585899353\n",
      "Train size: [400] hidden size: [44] trial: 21, train_loss: 1.730361, test loss: 1.170309, bias2: 0.8708509802818298, variance: 0.299457848072052\n",
      "Train size: [400] hidden size: [44] trial: 22, train_loss: 1.737795, test loss: 1.168158, bias2: 0.8670641183853149, variance: 0.30109405517578125\n",
      "Train size: [400] hidden size: [44] trial: 23, train_loss: 1.736200, test loss: 1.166958, bias2: 0.8664729595184326, variance: 0.30048516392707825\n",
      "Train size: [400] hidden size: [44] trial: 24, train_loss: 1.730883, test loss: 1.168820, bias2: 0.8659871816635132, variance: 0.30283263325691223\n",
      "Train size: [400] hidden size: [44] trial: 25, train_loss: 1.730779, test loss: 1.171817, bias2: 0.865782618522644, variance: 0.3060343563556671\n",
      "Train size: [400] hidden size: [44] trial: 26, train_loss: 1.735226, test loss: 1.169080, bias2: 0.8625814914703369, variance: 0.3064989149570465\n",
      "Train size: [400] hidden size: [44] trial: 27, train_loss: 1.739708, test loss: 1.169038, bias2: 0.8634642958641052, variance: 0.3055735230445862\n",
      "Train size: [400] hidden size: [44] trial: 28, train_loss: 1.743853, test loss: 1.171654, bias2: 0.8610043525695801, variance: 0.3106495141983032\n",
      "Train size: [400] hidden size: [44] trial: 29, train_loss: 1.741567, test loss: 1.170488, bias2: 0.8609999418258667, variance: 0.30948758125305176\n",
      "Train size: [400] hidden size: [44] trial: 30, train_loss: 1.737317, test loss: 1.168993, bias2: 0.8613587617874146, variance: 0.30763423442840576\n",
      "Train size: [400] hidden size: [44] trial: 31, train_loss: 1.736456, test loss: 1.168306, bias2: 0.8612610101699829, variance: 0.3070450723171234\n",
      "Train size: [400] hidden size: [44] trial: 32, train_loss: 1.732305, test loss: 1.170943, bias2: 0.8629144430160522, variance: 0.30802813172340393\n",
      "Train size: [400] hidden size: [44] trial: 33, train_loss: 1.730527, test loss: 1.170198, bias2: 0.8628360629081726, variance: 0.30736225843429565\n",
      "Train size: [400] hidden size: [44] trial: 34, train_loss: 1.737670, test loss: 1.169335, bias2: 0.8630893230438232, variance: 0.3062460124492645\n",
      "Train size: [400] hidden size: [44] trial: 35, train_loss: 1.737497, test loss: 1.167925, bias2: 0.8620797395706177, variance: 0.305845707654953\n",
      "Train size: [400] hidden size: [44] trial: 36, train_loss: 1.731424, test loss: 1.165891, bias2: 0.8609216809272766, variance: 0.30496925115585327\n",
      "Train size: [400] hidden size: [44] trial: 37, train_loss: 1.739805, test loss: 1.168566, bias2: 0.8605890274047852, variance: 0.30797722935676575\n",
      "Train size: [400] hidden size: [44] trial: 38, train_loss: 1.738321, test loss: 1.168130, bias2: 0.8601964712142944, variance: 0.30793359875679016\n",
      "Train size: [400] hidden size: [44] trial: 39, train_loss: 1.735747, test loss: 1.168441, bias2: 0.8586729764938354, variance: 0.3097681701183319\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [44] trial: 40, train_loss: 1.736560, test loss: 1.167844, bias2: 0.8596116900444031, variance: 0.30823224782943726\n",
      "Train size: [400] hidden size: [44] trial: 41, train_loss: 1.734150, test loss: 1.169758, bias2: 0.8590302467346191, variance: 0.3107277452945709\n",
      "Train size: [400] hidden size: [44] trial: 42, train_loss: 1.731062, test loss: 1.167706, bias2: 0.8588885068893433, variance: 0.30881765484809875\n",
      "Train size: [400] hidden size: [44] trial: 43, train_loss: 1.736908, test loss: 1.167481, bias2: 0.8553873896598816, variance: 0.3120940327644348\n",
      "Train size: [400] hidden size: [44] trial: 44, train_loss: 1.730828, test loss: 1.167305, bias2: 0.8559997081756592, variance: 0.31130561232566833\n",
      "Train size: [400] hidden size: [44] trial: 45, train_loss: 1.728473, test loss: 1.166618, bias2: 0.8558740615844727, variance: 0.3107440173625946\n",
      "Train size: [400] hidden size: [44] trial: 46, train_loss: 1.726973, test loss: 1.166608, bias2: 0.8571232557296753, variance: 0.30948445200920105\n",
      "Train size: [400] hidden size: [44] trial: 47, train_loss: 1.725250, test loss: 1.166004, bias2: 0.8569808006286621, variance: 0.30902326107025146\n",
      "Train size: [400] hidden size: [44] trial: 48, train_loss: 1.725976, test loss: 1.165055, bias2: 0.8555147647857666, variance: 0.3095405399799347\n",
      "Train size: [400] hidden size: [44] trial: 49, train_loss: 1.729122, test loss: 1.164236, bias2: 0.855122983455658, variance: 0.3091124892234802\n",
      "##################################################\n",
      "Train size: [400] hidden size: [51] trial: 0, train_loss: 1.829012, test loss: 1.141022, bias2: 1.1410216093063354, variance: -3.3086655637504236e-09\n",
      "Train size: [400] hidden size: [51] trial: 1, train_loss: 1.859037, test loss: 1.195373, bias2: 1.0134391784667969, variance: 0.18193398416042328\n",
      "Train size: [400] hidden size: [51] trial: 2, train_loss: 1.834037, test loss: 1.182848, bias2: 0.9715642333030701, variance: 0.2112840861082077\n",
      "Train size: [400] hidden size: [51] trial: 3, train_loss: 1.824855, test loss: 1.167357, bias2: 0.9249861836433411, variance: 0.24237079918384552\n",
      "Train size: [400] hidden size: [51] trial: 4, train_loss: 1.787456, test loss: 1.161058, bias2: 0.9044876098632812, variance: 0.25657081604003906\n",
      "Train size: [400] hidden size: [51] trial: 5, train_loss: 1.786321, test loss: 1.154392, bias2: 0.8792299032211304, variance: 0.27516207098960876\n",
      "Train size: [400] hidden size: [51] trial: 6, train_loss: 1.774325, test loss: 1.174727, bias2: 0.8741333484649658, variance: 0.300593763589859\n",
      "Train size: [400] hidden size: [51] trial: 7, train_loss: 1.770392, test loss: 1.170894, bias2: 0.8624939918518066, variance: 0.308400422334671\n",
      "Train size: [400] hidden size: [51] trial: 8, train_loss: 1.755382, test loss: 1.184832, bias2: 0.8678431510925293, variance: 0.316988468170166\n",
      "Train size: [400] hidden size: [51] trial: 9, train_loss: 1.767770, test loss: 1.183266, bias2: 0.8662724494934082, variance: 0.3169933259487152\n",
      "Train size: [400] hidden size: [51] trial: 10, train_loss: 1.785106, test loss: 1.180457, bias2: 0.8628934621810913, variance: 0.31756356358528137\n",
      "Train size: [400] hidden size: [51] trial: 11, train_loss: 1.791512, test loss: 1.185865, bias2: 0.8479722738265991, variance: 0.33789265155792236\n",
      "Train size: [400] hidden size: [51] trial: 12, train_loss: 1.771574, test loss: 1.184215, bias2: 0.8481122255325317, variance: 0.336102694272995\n",
      "Train size: [400] hidden size: [51] trial: 13, train_loss: 1.771741, test loss: 1.182690, bias2: 0.8446433544158936, variance: 0.33804643154144287\n",
      "Train size: [400] hidden size: [51] trial: 14, train_loss: 1.766161, test loss: 1.188440, bias2: 0.8445462584495544, variance: 0.3438940644264221\n",
      "Train size: [400] hidden size: [51] trial: 15, train_loss: 1.766487, test loss: 1.191167, bias2: 0.8459720611572266, variance: 0.3451947867870331\n",
      "Train size: [400] hidden size: [51] trial: 16, train_loss: 1.747375, test loss: 1.188213, bias2: 0.8396281003952026, variance: 0.34858477115631104\n",
      "Train size: [400] hidden size: [51] trial: 17, train_loss: 1.746251, test loss: 1.188290, bias2: 0.838444709777832, variance: 0.3498455584049225\n",
      "Train size: [400] hidden size: [51] trial: 18, train_loss: 1.726588, test loss: 1.189003, bias2: 0.8333860635757446, variance: 0.3556164503097534\n",
      "Train size: [400] hidden size: [51] trial: 19, train_loss: 1.717477, test loss: 1.189871, bias2: 0.828899085521698, variance: 0.3609723448753357\n",
      "Train size: [400] hidden size: [51] trial: 20, train_loss: 1.710494, test loss: 1.184356, bias2: 0.8281863927841187, variance: 0.3561694324016571\n",
      "Train size: [400] hidden size: [51] trial: 21, train_loss: 1.717014, test loss: 1.183660, bias2: 0.830537736415863, variance: 0.3531220555305481\n",
      "Train size: [400] hidden size: [51] trial: 22, train_loss: 1.706774, test loss: 1.178982, bias2: 0.8264048099517822, variance: 0.3525773584842682\n",
      "Train size: [400] hidden size: [51] trial: 23, train_loss: 1.704791, test loss: 1.180828, bias2: 0.8307600021362305, variance: 0.35006821155548096\n",
      "Train size: [400] hidden size: [51] trial: 24, train_loss: 1.706608, test loss: 1.178544, bias2: 0.8278229832649231, variance: 0.3507212996482849\n",
      "Train size: [400] hidden size: [51] trial: 25, train_loss: 1.712347, test loss: 1.182094, bias2: 0.8278781175613403, variance: 0.35421624779701233\n",
      "Train size: [400] hidden size: [51] trial: 26, train_loss: 1.716380, test loss: 1.181497, bias2: 0.8271430730819702, variance: 0.35435423254966736\n",
      "Train size: [400] hidden size: [51] trial: 27, train_loss: 1.711079, test loss: 1.180208, bias2: 0.8271909952163696, variance: 0.3530174791812897\n",
      "Train size: [400] hidden size: [51] trial: 28, train_loss: 1.712588, test loss: 1.183645, bias2: 0.8249857425689697, variance: 0.3586593568325043\n",
      "Train size: [400] hidden size: [51] trial: 29, train_loss: 1.708957, test loss: 1.181091, bias2: 0.8242049813270569, variance: 0.35688644647598267\n",
      "Train size: [400] hidden size: [51] trial: 30, train_loss: 1.702292, test loss: 1.178214, bias2: 0.8223764896392822, variance: 0.3558374345302582\n",
      "Train size: [400] hidden size: [51] trial: 31, train_loss: 1.698116, test loss: 1.178229, bias2: 0.822624921798706, variance: 0.3556041717529297\n",
      "Train size: [400] hidden size: [51] trial: 32, train_loss: 1.708852, test loss: 1.178497, bias2: 0.8232346773147583, variance: 0.35526254773139954\n",
      "Train size: [400] hidden size: [51] trial: 33, train_loss: 1.707936, test loss: 1.178978, bias2: 0.8200105428695679, variance: 0.35896745324134827\n",
      "Train size: [400] hidden size: [51] trial: 34, train_loss: 1.702402, test loss: 1.177592, bias2: 0.8162055611610413, variance: 0.36138612031936646\n",
      "Train size: [400] hidden size: [51] trial: 35, train_loss: 1.696171, test loss: 1.180496, bias2: 0.8162959814071655, variance: 0.3641999661922455\n",
      "Train size: [400] hidden size: [51] trial: 36, train_loss: 1.692700, test loss: 1.179247, bias2: 0.8148913383483887, variance: 0.3643553555011749\n",
      "Train size: [400] hidden size: [51] trial: 37, train_loss: 1.691311, test loss: 1.178429, bias2: 0.8154612183570862, variance: 0.3629675507545471\n",
      "Train size: [400] hidden size: [51] trial: 38, train_loss: 1.689563, test loss: 1.179521, bias2: 0.8154784440994263, variance: 0.3640429675579071\n",
      "Train size: [400] hidden size: [51] trial: 39, train_loss: 1.688684, test loss: 1.178402, bias2: 0.8150070905685425, variance: 0.36339521408081055\n",
      "Train size: [400] hidden size: [51] trial: 40, train_loss: 1.689642, test loss: 1.178013, bias2: 0.8142364025115967, variance: 0.3637763261795044\n",
      "Train size: [400] hidden size: [51] trial: 41, train_loss: 1.690404, test loss: 1.179953, bias2: 0.8169611692428589, variance: 0.362991601228714\n",
      "Train size: [400] hidden size: [51] trial: 42, train_loss: 1.691521, test loss: 1.183971, bias2: 0.8163483738899231, variance: 0.367622435092926\n",
      "Train size: [400] hidden size: [51] trial: 43, train_loss: 1.692238, test loss: 1.182861, bias2: 0.815068244934082, variance: 0.36779236793518066\n",
      "Train size: [400] hidden size: [51] trial: 44, train_loss: 1.688476, test loss: 1.183405, bias2: 0.8164621591567993, variance: 0.36694321036338806\n",
      "Train size: [400] hidden size: [51] trial: 45, train_loss: 1.687018, test loss: 1.183670, bias2: 0.8157629370689392, variance: 0.3679066300392151\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [51] trial: 46, train_loss: 1.688581, test loss: 1.186375, bias2: 0.8162006139755249, variance: 0.3701740503311157\n",
      "Train size: [400] hidden size: [51] trial: 47, train_loss: 1.685442, test loss: 1.187426, bias2: 0.8169177770614624, variance: 0.3705086410045624\n",
      "Train size: [400] hidden size: [51] trial: 48, train_loss: 1.681360, test loss: 1.186898, bias2: 0.8160126209259033, variance: 0.3708849847316742\n",
      "Train size: [400] hidden size: [51] trial: 49, train_loss: 1.683411, test loss: 1.187354, bias2: 0.8172155618667603, variance: 0.3701383173465729\n",
      "##################################################\n",
      "Train size: [400] hidden size: [58] trial: 0, train_loss: 1.714040, test loss: 1.286266, bias2: 1.2862656116485596, variance: -1.5570191802538602e-09\n",
      "Train size: [400] hidden size: [58] trial: 1, train_loss: 1.670721, test loss: 1.311615, bias2: 1.0400817394256592, variance: 0.2715334892272949\n",
      "Train size: [400] hidden size: [58] trial: 2, train_loss: 1.625967, test loss: 1.259806, bias2: 0.9222818613052368, variance: 0.33752384781837463\n",
      "Train size: [400] hidden size: [58] trial: 3, train_loss: 1.624006, test loss: 1.257081, bias2: 0.9002910852432251, variance: 0.35679003596305847\n",
      "Train size: [400] hidden size: [58] trial: 4, train_loss: 1.606904, test loss: 1.259831, bias2: 0.8655321598052979, variance: 0.3942984342575073\n",
      "Train size: [400] hidden size: [58] trial: 5, train_loss: 1.617931, test loss: 1.269567, bias2: 0.8541190028190613, variance: 0.41544753313064575\n",
      "Train size: [400] hidden size: [58] trial: 6, train_loss: 1.619892, test loss: 1.276050, bias2: 0.8492212891578674, variance: 0.4268283247947693\n",
      "Train size: [400] hidden size: [58] trial: 7, train_loss: 1.624770, test loss: 1.258909, bias2: 0.8374057412147522, variance: 0.421503484249115\n",
      "Train size: [400] hidden size: [58] trial: 8, train_loss: 1.603188, test loss: 1.254285, bias2: 0.826160728931427, variance: 0.4281243681907654\n",
      "Train size: [400] hidden size: [58] trial: 9, train_loss: 1.612532, test loss: 1.251096, bias2: 0.8283661007881165, variance: 0.422730028629303\n",
      "Train size: [400] hidden size: [58] trial: 10, train_loss: 1.609689, test loss: 1.248913, bias2: 0.8314011096954346, variance: 0.41751226782798767\n",
      "Train size: [400] hidden size: [58] trial: 11, train_loss: 1.611174, test loss: 1.245905, bias2: 0.834088921546936, variance: 0.4118157625198364\n",
      "Train size: [400] hidden size: [58] trial: 12, train_loss: 1.615010, test loss: 1.243246, bias2: 0.8319364786148071, variance: 0.41130995750427246\n",
      "Train size: [400] hidden size: [58] trial: 13, train_loss: 1.613857, test loss: 1.241276, bias2: 0.8345525860786438, variance: 0.4067233204841614\n",
      "Train size: [400] hidden size: [58] trial: 14, train_loss: 1.613375, test loss: 1.231733, bias2: 0.8252152800559998, variance: 0.4065176844596863\n",
      "Train size: [400] hidden size: [58] trial: 15, train_loss: 1.615813, test loss: 1.231528, bias2: 0.8209275603294373, variance: 0.4106007218360901\n",
      "Train size: [400] hidden size: [58] trial: 16, train_loss: 1.609715, test loss: 1.227250, bias2: 0.8203167915344238, variance: 0.4069328308105469\n",
      "Train size: [400] hidden size: [58] trial: 17, train_loss: 1.603434, test loss: 1.226757, bias2: 0.8180844783782959, variance: 0.4086720645427704\n",
      "Train size: [400] hidden size: [58] trial: 18, train_loss: 1.600730, test loss: 1.224431, bias2: 0.8172852993011475, variance: 0.40714535117149353\n",
      "Train size: [400] hidden size: [58] trial: 19, train_loss: 1.602175, test loss: 1.225632, bias2: 0.8202487230300903, variance: 0.4053831994533539\n",
      "Train size: [400] hidden size: [58] trial: 20, train_loss: 1.603864, test loss: 1.227986, bias2: 0.820464015007019, variance: 0.4075222313404083\n",
      "Train size: [400] hidden size: [58] trial: 21, train_loss: 1.620427, test loss: 1.228452, bias2: 0.8187389373779297, variance: 0.40971338748931885\n",
      "Train size: [400] hidden size: [58] trial: 22, train_loss: 1.611588, test loss: 1.226694, bias2: 0.8165838718414307, variance: 0.41010990738868713\n",
      "Train size: [400] hidden size: [58] trial: 23, train_loss: 1.614976, test loss: 1.226649, bias2: 0.8121230602264404, variance: 0.41452547907829285\n",
      "Train size: [400] hidden size: [58] trial: 24, train_loss: 1.615562, test loss: 1.228757, bias2: 0.814826488494873, variance: 0.41393032670021057\n",
      "Train size: [400] hidden size: [58] trial: 25, train_loss: 1.610765, test loss: 1.227322, bias2: 0.8142921924591064, variance: 0.41302934288978577\n",
      "Train size: [400] hidden size: [58] trial: 26, train_loss: 1.614012, test loss: 1.225096, bias2: 0.8105831742286682, variance: 0.4145126938819885\n",
      "Train size: [400] hidden size: [58] trial: 27, train_loss: 1.624181, test loss: 1.222271, bias2: 0.8098663687705994, variance: 0.41240423917770386\n",
      "Train size: [400] hidden size: [58] trial: 28, train_loss: 1.622005, test loss: 1.225908, bias2: 0.809234082698822, variance: 0.4166739583015442\n",
      "Train size: [400] hidden size: [58] trial: 29, train_loss: 1.629105, test loss: 1.224927, bias2: 0.8103076219558716, variance: 0.4146190583705902\n",
      "Train size: [400] hidden size: [58] trial: 30, train_loss: 1.625323, test loss: 1.226009, bias2: 0.8107589483261108, variance: 0.41524970531463623\n",
      "Train size: [400] hidden size: [58] trial: 31, train_loss: 1.626047, test loss: 1.224986, bias2: 0.8097774982452393, variance: 0.4152083098888397\n",
      "Train size: [400] hidden size: [58] trial: 32, train_loss: 1.628356, test loss: 1.221429, bias2: 0.8088279962539673, variance: 0.4126012623310089\n",
      "Train size: [400] hidden size: [58] trial: 33, train_loss: 1.630296, test loss: 1.221880, bias2: 0.8110319375991821, variance: 0.41084837913513184\n",
      "Train size: [400] hidden size: [58] trial: 34, train_loss: 1.624737, test loss: 1.223347, bias2: 0.8133111000061035, variance: 0.4100360870361328\n",
      "Train size: [400] hidden size: [58] trial: 35, train_loss: 1.630347, test loss: 1.224871, bias2: 0.8139917850494385, variance: 0.41087958216667175\n",
      "Train size: [400] hidden size: [58] trial: 36, train_loss: 1.632629, test loss: 1.223529, bias2: 0.8149665594100952, variance: 0.40856215357780457\n",
      "Train size: [400] hidden size: [58] trial: 37, train_loss: 1.631866, test loss: 1.228045, bias2: 0.8159198760986328, variance: 0.4121250808238983\n",
      "Train size: [400] hidden size: [58] trial: 38, train_loss: 1.627902, test loss: 1.226654, bias2: 0.8133352994918823, variance: 0.4133186340332031\n",
      "Train size: [400] hidden size: [58] trial: 39, train_loss: 1.628162, test loss: 1.225918, bias2: 0.8137425780296326, variance: 0.4121749997138977\n",
      "Train size: [400] hidden size: [58] trial: 40, train_loss: 1.629379, test loss: 1.225406, bias2: 0.8139384984970093, variance: 0.41146767139434814\n",
      "Train size: [400] hidden size: [58] trial: 41, train_loss: 1.626475, test loss: 1.224913, bias2: 0.8133794665336609, variance: 0.41153401136398315\n",
      "Train size: [400] hidden size: [58] trial: 42, train_loss: 1.633723, test loss: 1.223902, bias2: 0.8116492033004761, variance: 0.4122523367404938\n",
      "Train size: [400] hidden size: [58] trial: 43, train_loss: 1.633052, test loss: 1.222322, bias2: 0.8104419708251953, variance: 0.41188013553619385\n",
      "Train size: [400] hidden size: [58] trial: 44, train_loss: 1.634407, test loss: 1.223662, bias2: 0.8096858263015747, variance: 0.41397640109062195\n",
      "Train size: [400] hidden size: [58] trial: 45, train_loss: 1.632090, test loss: 1.223361, bias2: 0.8094738721847534, variance: 0.4138871431350708\n",
      "Train size: [400] hidden size: [58] trial: 46, train_loss: 1.631259, test loss: 1.221596, bias2: 0.8067948222160339, variance: 0.41480153799057007\n",
      "Train size: [400] hidden size: [58] trial: 47, train_loss: 1.627073, test loss: 1.220869, bias2: 0.8042728304862976, variance: 0.41659611463546753\n",
      "Train size: [400] hidden size: [58] trial: 48, train_loss: 1.632031, test loss: 1.221328, bias2: 0.8066427111625671, variance: 0.41468530893325806\n",
      "Train size: [400] hidden size: [58] trial: 49, train_loss: 1.631138, test loss: 1.219471, bias2: 0.8061660528182983, variance: 0.41330471634864807\n",
      "##################################################\n",
      "Train size: [400] hidden size: [67] trial: 0, train_loss: 1.487052, test loss: 1.261602, bias2: 1.2616021633148193, variance: -3.8925479506346505e-10\n",
      "Train size: [400] hidden size: [67] trial: 1, train_loss: 1.505447, test loss: 1.225166, bias2: 1.01953125, variance: 0.2056344449520111\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [67] trial: 2, train_loss: 1.598203, test loss: 1.248173, bias2: 0.922634482383728, variance: 0.3255387544631958\n",
      "Train size: [400] hidden size: [67] trial: 3, train_loss: 1.582941, test loss: 1.217524, bias2: 0.8831616640090942, variance: 0.3343621492385864\n",
      "Train size: [400] hidden size: [67] trial: 4, train_loss: 1.601967, test loss: 1.206027, bias2: 0.866450309753418, variance: 0.3395765721797943\n",
      "Train size: [400] hidden size: [67] trial: 5, train_loss: 1.587493, test loss: 1.221796, bias2: 0.8500412702560425, variance: 0.37175452709198\n",
      "Train size: [400] hidden size: [67] trial: 6, train_loss: 1.577626, test loss: 1.239252, bias2: 0.8332859873771667, variance: 0.40596574544906616\n",
      "Train size: [400] hidden size: [67] trial: 7, train_loss: 1.562356, test loss: 1.224834, bias2: 0.8271572589874268, variance: 0.3976761996746063\n",
      "Train size: [400] hidden size: [67] trial: 8, train_loss: 1.560043, test loss: 1.222158, bias2: 0.8130727410316467, variance: 0.40908533334732056\n",
      "Train size: [400] hidden size: [67] trial: 9, train_loss: 1.549188, test loss: 1.225836, bias2: 0.8115512728691101, variance: 0.41428452730178833\n",
      "Train size: [400] hidden size: [67] trial: 10, train_loss: 1.541845, test loss: 1.223853, bias2: 0.8077564239501953, variance: 0.4160970449447632\n",
      "Train size: [400] hidden size: [67] trial: 11, train_loss: 1.562215, test loss: 1.237797, bias2: 0.8091696500778198, variance: 0.4286275804042816\n",
      "Train size: [400] hidden size: [67] trial: 12, train_loss: 1.565092, test loss: 1.240446, bias2: 0.810076117515564, variance: 0.43036994338035583\n",
      "Train size: [400] hidden size: [67] trial: 13, train_loss: 1.559291, test loss: 1.245117, bias2: 0.8126254677772522, variance: 0.4324917197227478\n",
      "Train size: [400] hidden size: [67] trial: 14, train_loss: 1.568426, test loss: 1.243240, bias2: 0.8095603585243225, variance: 0.43367987871170044\n",
      "Train size: [400] hidden size: [67] trial: 15, train_loss: 1.573782, test loss: 1.248458, bias2: 0.8073126077651978, variance: 0.44114577770233154\n",
      "Train size: [400] hidden size: [67] trial: 16, train_loss: 1.565076, test loss: 1.253140, bias2: 0.8098087310791016, variance: 0.4433315098285675\n",
      "Train size: [400] hidden size: [67] trial: 17, train_loss: 1.573516, test loss: 1.253272, bias2: 0.8020891547203064, variance: 0.4511825442314148\n",
      "Train size: [400] hidden size: [67] trial: 18, train_loss: 1.585625, test loss: 1.250081, bias2: 0.8031798601150513, variance: 0.44690069556236267\n",
      "Train size: [400] hidden size: [67] trial: 19, train_loss: 1.573320, test loss: 1.254540, bias2: 0.8021904230117798, variance: 0.4523492157459259\n",
      "Train size: [400] hidden size: [67] trial: 20, train_loss: 1.568769, test loss: 1.253928, bias2: 0.8023339509963989, variance: 0.45159444212913513\n",
      "Train size: [400] hidden size: [67] trial: 21, train_loss: 1.561906, test loss: 1.247531, bias2: 0.799706220626831, variance: 0.4478243589401245\n",
      "Train size: [400] hidden size: [67] trial: 22, train_loss: 1.561323, test loss: 1.253484, bias2: 0.796048104763031, variance: 0.4574354290962219\n",
      "Train size: [400] hidden size: [67] trial: 23, train_loss: 1.558619, test loss: 1.253615, bias2: 0.7957382202148438, variance: 0.45787689089775085\n",
      "Train size: [400] hidden size: [67] trial: 24, train_loss: 1.560766, test loss: 1.246759, bias2: 0.7931877374649048, variance: 0.4535713195800781\n",
      "Train size: [400] hidden size: [67] trial: 25, train_loss: 1.554545, test loss: 1.246149, bias2: 0.7938944101333618, variance: 0.45225441455841064\n",
      "Train size: [400] hidden size: [67] trial: 26, train_loss: 1.558504, test loss: 1.246434, bias2: 0.7967764139175415, variance: 0.44965723156929016\n",
      "Train size: [400] hidden size: [67] trial: 27, train_loss: 1.560406, test loss: 1.244609, bias2: 0.7976229786872864, variance: 0.44698566198349\n",
      "Train size: [400] hidden size: [67] trial: 28, train_loss: 1.563115, test loss: 1.243203, bias2: 0.7963870167732239, variance: 0.4468161463737488\n",
      "Train size: [400] hidden size: [67] trial: 29, train_loss: 1.566714, test loss: 1.244334, bias2: 0.7927814722061157, variance: 0.4515526294708252\n",
      "Train size: [400] hidden size: [67] trial: 30, train_loss: 1.566751, test loss: 1.242709, bias2: 0.7914329767227173, variance: 0.451276034116745\n",
      "Train size: [400] hidden size: [67] trial: 31, train_loss: 1.564284, test loss: 1.241759, bias2: 0.7906496524810791, variance: 0.4511089324951172\n",
      "Train size: [400] hidden size: [67] trial: 32, train_loss: 1.566418, test loss: 1.242164, bias2: 0.7925459146499634, variance: 0.44961801171302795\n",
      "Train size: [400] hidden size: [67] trial: 33, train_loss: 1.562210, test loss: 1.239360, bias2: 0.7901913523674011, variance: 0.44916898012161255\n",
      "Train size: [400] hidden size: [67] trial: 34, train_loss: 1.556368, test loss: 1.239354, bias2: 0.7889703512191772, variance: 0.45038318634033203\n",
      "Train size: [400] hidden size: [67] trial: 35, train_loss: 1.560918, test loss: 1.245444, bias2: 0.7882424592971802, variance: 0.4572012722492218\n",
      "Train size: [400] hidden size: [67] trial: 36, train_loss: 1.562778, test loss: 1.249778, bias2: 0.788253903388977, variance: 0.46152377128601074\n",
      "Train size: [400] hidden size: [67] trial: 37, train_loss: 1.563277, test loss: 1.249788, bias2: 0.7888137698173523, variance: 0.4609745144844055\n",
      "Train size: [400] hidden size: [67] trial: 38, train_loss: 1.563468, test loss: 1.249368, bias2: 0.7873579859733582, variance: 0.46201032400131226\n",
      "Train size: [400] hidden size: [67] trial: 39, train_loss: 1.562869, test loss: 1.246656, bias2: 0.7872856855392456, variance: 0.4593699872493744\n",
      "Train size: [400] hidden size: [67] trial: 40, train_loss: 1.563580, test loss: 1.250523, bias2: 0.785529375076294, variance: 0.4649932384490967\n",
      "Train size: [400] hidden size: [67] trial: 41, train_loss: 1.566470, test loss: 1.250504, bias2: 0.7831120491027832, variance: 0.46739235520362854\n",
      "Train size: [400] hidden size: [67] trial: 42, train_loss: 1.566894, test loss: 1.250726, bias2: 0.7840626239776611, variance: 0.46666327118873596\n",
      "Train size: [400] hidden size: [67] trial: 43, train_loss: 1.566292, test loss: 1.249975, bias2: 0.7817289233207703, variance: 0.4682464003562927\n",
      "Train size: [400] hidden size: [67] trial: 44, train_loss: 1.564740, test loss: 1.248945, bias2: 0.7823157906532288, variance: 0.4666288495063782\n",
      "Train size: [400] hidden size: [67] trial: 45, train_loss: 1.566135, test loss: 1.248096, bias2: 0.7833367586135864, variance: 0.46475911140441895\n",
      "Train size: [400] hidden size: [67] trial: 46, train_loss: 1.567619, test loss: 1.250316, bias2: 0.781653642654419, variance: 0.46866270899772644\n",
      "Train size: [400] hidden size: [67] trial: 47, train_loss: 1.567232, test loss: 1.249491, bias2: 0.7805088758468628, variance: 0.46898171305656433\n",
      "Train size: [400] hidden size: [67] trial: 48, train_loss: 1.565795, test loss: 1.253737, bias2: 0.7787581086158752, variance: 0.47497838735580444\n",
      "Train size: [400] hidden size: [67] trial: 49, train_loss: 1.566633, test loss: 1.254092, bias2: 0.778157114982605, variance: 0.4759352505207062\n",
      "##################################################\n",
      "Train size: [400] hidden size: [77] trial: 0, train_loss: 1.508463, test loss: 1.249741, bias2: 1.2497410774230957, variance: -2.724783731977709e-09\n",
      "Train size: [400] hidden size: [77] trial: 1, train_loss: 1.606327, test loss: 1.305964, bias2: 1.03741455078125, variance: 0.2685490846633911\n",
      "Train size: [400] hidden size: [77] trial: 2, train_loss: 1.539705, test loss: 1.309430, bias2: 0.9392739534378052, variance: 0.3701561391353607\n",
      "Train size: [400] hidden size: [77] trial: 3, train_loss: 1.493927, test loss: 1.294283, bias2: 0.8911876678466797, variance: 0.4030955135822296\n",
      "Train size: [400] hidden size: [77] trial: 4, train_loss: 1.527277, test loss: 1.313584, bias2: 0.8670669198036194, variance: 0.4465166926383972\n",
      "Train size: [400] hidden size: [77] trial: 5, train_loss: 1.549611, test loss: 1.308034, bias2: 0.8489855527877808, variance: 0.45904839038848877\n",
      "Train size: [400] hidden size: [77] trial: 6, train_loss: 1.506657, test loss: 1.285478, bias2: 0.830999493598938, variance: 0.4544788897037506\n",
      "Train size: [400] hidden size: [77] trial: 7, train_loss: 1.527855, test loss: 1.290058, bias2: 0.8119781017303467, variance: 0.4780801832675934\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [77] trial: 8, train_loss: 1.515726, test loss: 1.275817, bias2: 0.8057231307029724, variance: 0.47009390592575073\n",
      "Train size: [400] hidden size: [77] trial: 9, train_loss: 1.534975, test loss: 1.283290, bias2: 0.7993719577789307, variance: 0.483918160200119\n",
      "Train size: [400] hidden size: [77] trial: 10, train_loss: 1.549896, test loss: 1.294224, bias2: 0.7944775819778442, variance: 0.4997466504573822\n",
      "Train size: [400] hidden size: [77] trial: 11, train_loss: 1.555530, test loss: 1.281683, bias2: 0.7827614545822144, variance: 0.4989219903945923\n",
      "Train size: [400] hidden size: [77] trial: 12, train_loss: 1.563309, test loss: 1.280939, bias2: 0.7815530896186829, variance: 0.49938565492630005\n",
      "Train size: [400] hidden size: [77] trial: 13, train_loss: 1.553222, test loss: 1.276967, bias2: 0.7772270441055298, variance: 0.4997403621673584\n",
      "Train size: [400] hidden size: [77] trial: 14, train_loss: 1.551651, test loss: 1.276188, bias2: 0.7759291529655457, variance: 0.5002588629722595\n",
      "Train size: [400] hidden size: [77] trial: 15, train_loss: 1.559801, test loss: 1.272924, bias2: 0.7730943560600281, variance: 0.49982911348342896\n",
      "Train size: [400] hidden size: [77] trial: 16, train_loss: 1.551165, test loss: 1.268542, bias2: 0.7689294219017029, variance: 0.4996129870414734\n",
      "Train size: [400] hidden size: [77] trial: 17, train_loss: 1.549915, test loss: 1.269399, bias2: 0.7673465013504028, variance: 0.502052903175354\n",
      "Train size: [400] hidden size: [77] trial: 18, train_loss: 1.548441, test loss: 1.274519, bias2: 0.7711569666862488, variance: 0.5033624768257141\n",
      "Train size: [400] hidden size: [77] trial: 19, train_loss: 1.547490, test loss: 1.272979, bias2: 0.7725759148597717, variance: 0.5004034638404846\n",
      "Train size: [400] hidden size: [77] trial: 20, train_loss: 1.531446, test loss: 1.279477, bias2: 0.7698635458946228, variance: 0.5096132159233093\n",
      "Train size: [400] hidden size: [77] trial: 21, train_loss: 1.533316, test loss: 1.282300, bias2: 0.7660034894943237, variance: 0.5162968635559082\n",
      "Train size: [400] hidden size: [77] trial: 22, train_loss: 1.541985, test loss: 1.284551, bias2: 0.7634115219116211, variance: 0.5211397409439087\n",
      "Train size: [400] hidden size: [77] trial: 23, train_loss: 1.537464, test loss: 1.283618, bias2: 0.760235607624054, variance: 0.5233826041221619\n",
      "Train size: [400] hidden size: [77] trial: 24, train_loss: 1.544634, test loss: 1.287958, bias2: 0.7624177932739258, variance: 0.5255403518676758\n",
      "Train size: [400] hidden size: [77] trial: 25, train_loss: 1.546473, test loss: 1.285675, bias2: 0.7596256732940674, variance: 0.5260491371154785\n",
      "Train size: [400] hidden size: [77] trial: 26, train_loss: 1.544093, test loss: 1.281826, bias2: 0.7580372095108032, variance: 0.523788571357727\n",
      "Train size: [400] hidden size: [77] trial: 27, train_loss: 1.543483, test loss: 1.280084, bias2: 0.7544785737991333, variance: 0.5256050825119019\n",
      "Train size: [400] hidden size: [77] trial: 28, train_loss: 1.540329, test loss: 1.285774, bias2: 0.7532258629798889, variance: 0.5325486063957214\n",
      "Train size: [400] hidden size: [77] trial: 29, train_loss: 1.538957, test loss: 1.291052, bias2: 0.7546092867851257, variance: 0.5364424586296082\n",
      "Train size: [400] hidden size: [77] trial: 30, train_loss: 1.540473, test loss: 1.291445, bias2: 0.755344569683075, variance: 0.5361003279685974\n",
      "Train size: [400] hidden size: [77] trial: 31, train_loss: 1.539903, test loss: 1.290520, bias2: 0.7552880644798279, variance: 0.5352322459220886\n",
      "Train size: [400] hidden size: [77] trial: 32, train_loss: 1.540491, test loss: 1.292010, bias2: 0.7579227089881897, variance: 0.5340868830680847\n",
      "Train size: [400] hidden size: [77] trial: 33, train_loss: 1.535646, test loss: 1.287974, bias2: 0.7581017017364502, variance: 0.5298727750778198\n",
      "Train size: [400] hidden size: [77] trial: 34, train_loss: 1.537287, test loss: 1.289868, bias2: 0.7593485713005066, variance: 0.5305191874504089\n",
      "Train size: [400] hidden size: [77] trial: 35, train_loss: 1.542468, test loss: 1.289985, bias2: 0.7593171000480652, variance: 0.5306676030158997\n",
      "Train size: [400] hidden size: [77] trial: 36, train_loss: 1.541826, test loss: 1.291696, bias2: 0.758513331413269, variance: 0.5331826210021973\n",
      "Train size: [400] hidden size: [77] trial: 37, train_loss: 1.535171, test loss: 1.290672, bias2: 0.7591819763183594, variance: 0.5314904451370239\n",
      "Train size: [400] hidden size: [77] trial: 38, train_loss: 1.531071, test loss: 1.292523, bias2: 0.7580289244651794, variance: 0.5344939827919006\n",
      "Train size: [400] hidden size: [77] trial: 39, train_loss: 1.527555, test loss: 1.294798, bias2: 0.7577056884765625, variance: 0.5370924472808838\n",
      "Train size: [400] hidden size: [77] trial: 40, train_loss: 1.532944, test loss: 1.297304, bias2: 0.7592782974243164, variance: 0.5380253791809082\n",
      "Train size: [400] hidden size: [77] trial: 41, train_loss: 1.537816, test loss: 1.297745, bias2: 0.7602123618125916, variance: 0.5375327467918396\n",
      "Train size: [400] hidden size: [77] trial: 42, train_loss: 1.538766, test loss: 1.300288, bias2: 0.7571964263916016, variance: 0.5430910587310791\n",
      "Train size: [400] hidden size: [77] trial: 43, train_loss: 1.538482, test loss: 1.300379, bias2: 0.7591046690940857, variance: 0.5412744879722595\n",
      "Train size: [400] hidden size: [77] trial: 44, train_loss: 1.541178, test loss: 1.298949, bias2: 0.7581459879875183, variance: 0.5408033728599548\n",
      "Train size: [400] hidden size: [77] trial: 45, train_loss: 1.544816, test loss: 1.298858, bias2: 0.7551949620246887, variance: 0.5436633229255676\n",
      "Train size: [400] hidden size: [77] trial: 46, train_loss: 1.539889, test loss: 1.298091, bias2: 0.7518696784973145, variance: 0.5462214946746826\n",
      "Train size: [400] hidden size: [77] trial: 47, train_loss: 1.539168, test loss: 1.297898, bias2: 0.7525928616523743, variance: 0.5453054308891296\n",
      "Train size: [400] hidden size: [77] trial: 48, train_loss: 1.536868, test loss: 1.295673, bias2: 0.7510274648666382, variance: 0.5446460247039795\n",
      "Train size: [400] hidden size: [77] trial: 49, train_loss: 1.533180, test loss: 1.296323, bias2: 0.7504206299781799, variance: 0.5459023118019104\n",
      "##################################################\n",
      "Train size: [400] hidden size: [89] trial: 0, train_loss: 1.268861, test loss: 1.349533, bias2: 1.3495334386825562, variance: 1.9462740308284765e-09\n",
      "Train size: [400] hidden size: [89] trial: 1, train_loss: 1.374296, test loss: 1.304466, bias2: 1.0091485977172852, variance: 0.295317143201828\n",
      "Train size: [400] hidden size: [89] trial: 2, train_loss: 1.407699, test loss: 1.315174, bias2: 0.9026453495025635, variance: 0.41252851486206055\n",
      "Train size: [400] hidden size: [89] trial: 3, train_loss: 1.412487, test loss: 1.413402, bias2: 0.8635663986206055, variance: 0.5498360395431519\n",
      "Train size: [400] hidden size: [89] trial: 4, train_loss: 1.378602, test loss: 1.419474, bias2: 0.8362544775009155, variance: 0.5832195281982422\n",
      "Train size: [400] hidden size: [89] trial: 5, train_loss: 1.386608, test loss: 1.409284, bias2: 0.806795597076416, variance: 0.6024880409240723\n",
      "Train size: [400] hidden size: [89] trial: 6, train_loss: 1.376165, test loss: 1.390115, bias2: 0.7834929823875427, variance: 0.6066219210624695\n",
      "Train size: [400] hidden size: [89] trial: 7, train_loss: 1.387765, test loss: 1.397806, bias2: 0.7663569450378418, variance: 0.6314492225646973\n",
      "Train size: [400] hidden size: [89] trial: 8, train_loss: 1.400844, test loss: 1.405462, bias2: 0.7663214206695557, variance: 0.6391404867172241\n",
      "Train size: [400] hidden size: [89] trial: 9, train_loss: 1.412979, test loss: 1.399929, bias2: 0.7660653591156006, variance: 0.6338633298873901\n",
      "Train size: [400] hidden size: [89] trial: 10, train_loss: 1.400111, test loss: 1.397356, bias2: 0.7592920660972595, variance: 0.6380640864372253\n",
      "Train size: [400] hidden size: [89] trial: 11, train_loss: 1.393641, test loss: 1.386568, bias2: 0.7577274441719055, variance: 0.6288407444953918\n",
      "Train size: [400] hidden size: [89] trial: 12, train_loss: 1.390810, test loss: 1.378449, bias2: 0.7514591813087463, variance: 0.6269902586936951\n",
      "Train size: [400] hidden size: [89] trial: 13, train_loss: 1.382000, test loss: 1.370867, bias2: 0.7529286742210388, variance: 0.6179384589195251\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [89] trial: 14, train_loss: 1.386098, test loss: 1.374072, bias2: 0.7565780282020569, variance: 0.6174941658973694\n",
      "Train size: [400] hidden size: [89] trial: 15, train_loss: 1.390471, test loss: 1.381407, bias2: 0.7556238174438477, variance: 0.6257827281951904\n",
      "Train size: [400] hidden size: [89] trial: 16, train_loss: 1.396783, test loss: 1.383336, bias2: 0.7556243538856506, variance: 0.6277113556861877\n",
      "Train size: [400] hidden size: [89] trial: 17, train_loss: 1.404288, test loss: 1.376451, bias2: 0.7474954128265381, variance: 0.6289553642272949\n",
      "Train size: [400] hidden size: [89] trial: 18, train_loss: 1.405781, test loss: 1.385119, bias2: 0.7428678274154663, variance: 0.6422508955001831\n",
      "Train size: [400] hidden size: [89] trial: 19, train_loss: 1.403727, test loss: 1.385717, bias2: 0.7389131784439087, variance: 0.6468034982681274\n",
      "Train size: [400] hidden size: [89] trial: 20, train_loss: 1.407148, test loss: 1.387196, bias2: 0.7413883209228516, variance: 0.6458076238632202\n",
      "Train size: [400] hidden size: [89] trial: 21, train_loss: 1.407054, test loss: 1.381679, bias2: 0.7392416000366211, variance: 0.642437219619751\n",
      "Train size: [400] hidden size: [89] trial: 22, train_loss: 1.412380, test loss: 1.379691, bias2: 0.741473376750946, variance: 0.6382172703742981\n",
      "Train size: [400] hidden size: [89] trial: 23, train_loss: 1.409754, test loss: 1.373892, bias2: 0.7382761836051941, variance: 0.6356156468391418\n",
      "Train size: [400] hidden size: [89] trial: 24, train_loss: 1.409254, test loss: 1.368898, bias2: 0.7346844673156738, variance: 0.634213924407959\n",
      "Train size: [400] hidden size: [89] trial: 25, train_loss: 1.405517, test loss: 1.372186, bias2: 0.7320237755775452, variance: 0.6401622891426086\n",
      "Train size: [400] hidden size: [89] trial: 26, train_loss: 1.402211, test loss: 1.378055, bias2: 0.7313108444213867, variance: 0.6467446088790894\n",
      "Train size: [400] hidden size: [89] trial: 27, train_loss: 1.398669, test loss: 1.374971, bias2: 0.7307867407798767, variance: 0.644184410572052\n",
      "Train size: [400] hidden size: [89] trial: 28, train_loss: 1.395926, test loss: 1.376890, bias2: 0.7294511198997498, variance: 0.6474393010139465\n",
      "Train size: [400] hidden size: [89] trial: 29, train_loss: 1.400221, test loss: 1.373379, bias2: 0.725828230381012, variance: 0.6475502848625183\n",
      "Train size: [400] hidden size: [89] trial: 30, train_loss: 1.398136, test loss: 1.373574, bias2: 0.7281391024589539, variance: 0.6454346776008606\n",
      "Train size: [400] hidden size: [89] trial: 31, train_loss: 1.394466, test loss: 1.368922, bias2: 0.7272983193397522, variance: 0.641623318195343\n",
      "Train size: [400] hidden size: [89] trial: 32, train_loss: 1.399892, test loss: 1.371728, bias2: 0.7263292670249939, variance: 0.6453991532325745\n",
      "Train size: [400] hidden size: [89] trial: 33, train_loss: 1.403138, test loss: 1.368205, bias2: 0.7269245386123657, variance: 0.6412806510925293\n",
      "Train size: [400] hidden size: [89] trial: 34, train_loss: 1.405016, test loss: 1.369097, bias2: 0.7279412150382996, variance: 0.6411553025245667\n",
      "Train size: [400] hidden size: [89] trial: 35, train_loss: 1.409453, test loss: 1.369329, bias2: 0.7261742949485779, variance: 0.643155038356781\n",
      "Train size: [400] hidden size: [89] trial: 36, train_loss: 1.406318, test loss: 1.371994, bias2: 0.7261818647384644, variance: 0.645811915397644\n",
      "Train size: [400] hidden size: [89] trial: 37, train_loss: 1.407772, test loss: 1.372940, bias2: 0.725520670413971, variance: 0.6474197506904602\n",
      "Train size: [400] hidden size: [89] trial: 38, train_loss: 1.411287, test loss: 1.372300, bias2: 0.7230027318000793, variance: 0.6492974162101746\n",
      "Train size: [400] hidden size: [89] trial: 39, train_loss: 1.416901, test loss: 1.372952, bias2: 0.724317193031311, variance: 0.6486344337463379\n",
      "Train size: [400] hidden size: [89] trial: 40, train_loss: 1.419481, test loss: 1.372836, bias2: 0.7242391705513, variance: 0.6485969424247742\n",
      "Train size: [400] hidden size: [89] trial: 41, train_loss: 1.421135, test loss: 1.371628, bias2: 0.723573625087738, variance: 0.6480539441108704\n",
      "Train size: [400] hidden size: [89] trial: 42, train_loss: 1.426361, test loss: 1.373751, bias2: 0.7233886122703552, variance: 0.6503629088401794\n",
      "Train size: [400] hidden size: [89] trial: 43, train_loss: 1.425852, test loss: 1.372932, bias2: 0.7222480773925781, variance: 0.6506842374801636\n",
      "Train size: [400] hidden size: [89] trial: 44, train_loss: 1.428515, test loss: 1.374682, bias2: 0.7211157083511353, variance: 0.6535665988922119\n",
      "Train size: [400] hidden size: [89] trial: 45, train_loss: 1.429992, test loss: 1.374087, bias2: 0.722607433795929, variance: 0.6514797806739807\n",
      "Train size: [400] hidden size: [89] trial: 46, train_loss: 1.430160, test loss: 1.374148, bias2: 0.7232454419136047, variance: 0.6509026885032654\n",
      "Train size: [400] hidden size: [89] trial: 47, train_loss: 1.427871, test loss: 1.373065, bias2: 0.7248845100402832, variance: 0.6481802463531494\n",
      "Train size: [400] hidden size: [89] trial: 48, train_loss: 1.424951, test loss: 1.371948, bias2: 0.7223373055458069, variance: 0.6496104598045349\n",
      "Train size: [400] hidden size: [89] trial: 49, train_loss: 1.424659, test loss: 1.373418, bias2: 0.7217103838920593, variance: 0.6517074704170227\n",
      "##################################################\n",
      "Train size: [400] hidden size: [102] trial: 0, train_loss: 1.574433, test loss: 1.582790, bias2: 1.582789659500122, variance: -3.892548061656953e-09\n",
      "Train size: [400] hidden size: [102] trial: 1, train_loss: 1.413943, test loss: 1.512227, bias2: 1.0788204669952393, variance: 0.43340665102005005\n",
      "Train size: [400] hidden size: [102] trial: 2, train_loss: 1.362701, test loss: 1.500551, bias2: 0.8974996209144592, variance: 0.603051483631134\n",
      "Train size: [400] hidden size: [102] trial: 3, train_loss: 1.365492, test loss: 1.495118, bias2: 0.8543845415115356, variance: 0.640733003616333\n",
      "Train size: [400] hidden size: [102] trial: 4, train_loss: 1.367984, test loss: 1.502170, bias2: 0.8269256949424744, variance: 0.6752447485923767\n",
      "Train size: [400] hidden size: [102] trial: 5, train_loss: 1.336081, test loss: 1.492135, bias2: 0.7894459366798401, variance: 0.702688992023468\n",
      "Train size: [400] hidden size: [102] trial: 6, train_loss: 1.342308, test loss: 1.498842, bias2: 0.7618564963340759, variance: 0.7369857430458069\n",
      "Train size: [400] hidden size: [102] trial: 7, train_loss: 1.339027, test loss: 1.509906, bias2: 0.748161256313324, variance: 0.761745035648346\n",
      "Train size: [400] hidden size: [102] trial: 8, train_loss: 1.353445, test loss: 1.491960, bias2: 0.7360977530479431, variance: 0.7558627724647522\n",
      "Train size: [400] hidden size: [102] trial: 9, train_loss: 1.354837, test loss: 1.477045, bias2: 0.7238805294036865, variance: 0.7531648874282837\n",
      "Train size: [400] hidden size: [102] trial: 10, train_loss: 1.342670, test loss: 1.459355, bias2: 0.7170002460479736, variance: 0.7423548698425293\n",
      "Train size: [400] hidden size: [102] trial: 11, train_loss: 1.333806, test loss: 1.461786, bias2: 0.7172970175743103, variance: 0.7444887757301331\n",
      "Train size: [400] hidden size: [102] trial: 12, train_loss: 1.345062, test loss: 1.451140, bias2: 0.719190776348114, variance: 0.7319496273994446\n",
      "Train size: [400] hidden size: [102] trial: 13, train_loss: 1.350102, test loss: 1.445883, bias2: 0.7175897359848022, variance: 0.7282934188842773\n",
      "Train size: [400] hidden size: [102] trial: 14, train_loss: 1.347102, test loss: 1.449296, bias2: 0.7144984006881714, variance: 0.734797477722168\n",
      "Train size: [400] hidden size: [102] trial: 15, train_loss: 1.346512, test loss: 1.440880, bias2: 0.7045167684555054, variance: 0.7363630533218384\n",
      "Train size: [400] hidden size: [102] trial: 16, train_loss: 1.348978, test loss: 1.447295, bias2: 0.7064545750617981, variance: 0.740840494632721\n",
      "Train size: [400] hidden size: [102] trial: 17, train_loss: 1.361248, test loss: 1.438579, bias2: 0.7045456767082214, variance: 0.7340335249900818\n",
      "Train size: [400] hidden size: [102] trial: 18, train_loss: 1.357262, test loss: 1.446808, bias2: 0.7050809860229492, variance: 0.7417274713516235\n",
      "Train size: [400] hidden size: [102] trial: 19, train_loss: 1.360313, test loss: 1.447177, bias2: 0.7046807408332825, variance: 0.7424959540367126\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [102] trial: 20, train_loss: 1.375236, test loss: 1.450846, bias2: 0.702909529209137, variance: 0.7479363083839417\n",
      "Train size: [400] hidden size: [102] trial: 21, train_loss: 1.379934, test loss: 1.453807, bias2: 0.7055882215499878, variance: 0.7482188940048218\n",
      "Train size: [400] hidden size: [102] trial: 22, train_loss: 1.376418, test loss: 1.459921, bias2: 0.7092182636260986, variance: 0.7507032155990601\n",
      "Train size: [400] hidden size: [102] trial: 23, train_loss: 1.378648, test loss: 1.457776, bias2: 0.7104787230491638, variance: 0.747297465801239\n",
      "Train size: [400] hidden size: [102] trial: 24, train_loss: 1.378407, test loss: 1.453539, bias2: 0.7048174738883972, variance: 0.7487213015556335\n",
      "Train size: [400] hidden size: [102] trial: 25, train_loss: 1.373961, test loss: 1.459908, bias2: 0.7030725479125977, variance: 0.7568352222442627\n",
      "Train size: [400] hidden size: [102] trial: 26, train_loss: 1.368840, test loss: 1.464639, bias2: 0.7014890909194946, variance: 0.7631503343582153\n",
      "Train size: [400] hidden size: [102] trial: 27, train_loss: 1.362746, test loss: 1.466052, bias2: 0.6983092427253723, variance: 0.7677424550056458\n",
      "Train size: [400] hidden size: [102] trial: 28, train_loss: 1.359444, test loss: 1.462247, bias2: 0.6993755102157593, variance: 0.7628711462020874\n",
      "Train size: [400] hidden size: [102] trial: 29, train_loss: 1.362854, test loss: 1.462648, bias2: 0.6953955888748169, variance: 0.7672519683837891\n",
      "Train size: [400] hidden size: [102] trial: 30, train_loss: 1.358387, test loss: 1.462750, bias2: 0.6941692233085632, variance: 0.7685808539390564\n",
      "Train size: [400] hidden size: [102] trial: 31, train_loss: 1.361766, test loss: 1.463619, bias2: 0.6939018964767456, variance: 0.769716739654541\n",
      "Train size: [400] hidden size: [102] trial: 32, train_loss: 1.360814, test loss: 1.462804, bias2: 0.6921912431716919, variance: 0.7706124782562256\n",
      "Train size: [400] hidden size: [102] trial: 33, train_loss: 1.357027, test loss: 1.466223, bias2: 0.6926286220550537, variance: 0.7735947370529175\n",
      "Train size: [400] hidden size: [102] trial: 34, train_loss: 1.356523, test loss: 1.463683, bias2: 0.6915842890739441, variance: 0.7720988392829895\n",
      "Train size: [400] hidden size: [102] trial: 35, train_loss: 1.355721, test loss: 1.460805, bias2: 0.6878618001937866, variance: 0.7729432582855225\n",
      "Train size: [400] hidden size: [102] trial: 36, train_loss: 1.358124, test loss: 1.464779, bias2: 0.6886340379714966, variance: 0.7761446237564087\n",
      "Train size: [400] hidden size: [102] trial: 37, train_loss: 1.359339, test loss: 1.470459, bias2: 0.6869959235191345, variance: 0.783463180065155\n",
      "Train size: [400] hidden size: [102] trial: 38, train_loss: 1.361087, test loss: 1.472939, bias2: 0.6826997995376587, variance: 0.7902392148971558\n",
      "Train size: [400] hidden size: [102] trial: 39, train_loss: 1.361871, test loss: 1.471601, bias2: 0.6818475723266602, variance: 0.7897535562515259\n",
      "Train size: [400] hidden size: [102] trial: 40, train_loss: 1.364187, test loss: 1.467173, bias2: 0.6823191046714783, variance: 0.7848537564277649\n",
      "Train size: [400] hidden size: [102] trial: 41, train_loss: 1.366730, test loss: 1.466884, bias2: 0.6832596063613892, variance: 0.7836246490478516\n",
      "Train size: [400] hidden size: [102] trial: 42, train_loss: 1.364677, test loss: 1.464149, bias2: 0.683293342590332, variance: 0.7808552980422974\n",
      "Train size: [400] hidden size: [102] trial: 43, train_loss: 1.364123, test loss: 1.464930, bias2: 0.6839821338653564, variance: 0.7809476852416992\n",
      "Train size: [400] hidden size: [102] trial: 44, train_loss: 1.362595, test loss: 1.468552, bias2: 0.6856029629707336, variance: 0.7829485535621643\n",
      "Train size: [400] hidden size: [102] trial: 45, train_loss: 1.358560, test loss: 1.469056, bias2: 0.6867346167564392, variance: 0.7823211550712585\n",
      "Train size: [400] hidden size: [102] trial: 46, train_loss: 1.360214, test loss: 1.467931, bias2: 0.6858684420585632, variance: 0.782062828540802\n",
      "Train size: [400] hidden size: [102] trial: 47, train_loss: 1.358368, test loss: 1.466944, bias2: 0.6873502135276794, variance: 0.7795941233634949\n",
      "Train size: [400] hidden size: [102] trial: 48, train_loss: 1.356461, test loss: 1.465690, bias2: 0.6869766712188721, variance: 0.7787134647369385\n",
      "Train size: [400] hidden size: [102] trial: 49, train_loss: 1.356121, test loss: 1.470426, bias2: 0.6865083575248718, variance: 0.7839177250862122\n",
      "##################################################\n",
      "Train size: [400] hidden size: [118] trial: 0, train_loss: 1.171002, test loss: 1.502621, bias2: 1.5026212930679321, variance: 5.060312613380802e-09\n",
      "Train size: [400] hidden size: [118] trial: 1, train_loss: 1.213256, test loss: 1.550520, bias2: 1.099318027496338, variance: 0.45120200514793396\n",
      "Train size: [400] hidden size: [118] trial: 2, train_loss: 1.255246, test loss: 1.448258, bias2: 0.8747442960739136, variance: 0.5735141038894653\n",
      "Train size: [400] hidden size: [118] trial: 3, train_loss: 1.267689, test loss: 1.459088, bias2: 0.8334633708000183, variance: 0.6256247162818909\n",
      "Train size: [400] hidden size: [118] trial: 4, train_loss: 1.279694, test loss: 1.518091, bias2: 0.7874074578285217, variance: 0.7306831479072571\n",
      "Train size: [400] hidden size: [118] trial: 5, train_loss: 1.288706, test loss: 1.514870, bias2: 0.7598928809165955, variance: 0.754977285861969\n",
      "Train size: [400] hidden size: [118] trial: 6, train_loss: 1.293177, test loss: 1.552657, bias2: 0.7492891550064087, variance: 0.8033679723739624\n",
      "Train size: [400] hidden size: [118] trial: 7, train_loss: 1.286335, test loss: 1.557669, bias2: 0.7365310192108154, variance: 0.8211377859115601\n",
      "Train size: [400] hidden size: [118] trial: 8, train_loss: 1.281651, test loss: 1.569853, bias2: 0.734443724155426, variance: 0.8354088664054871\n",
      "Train size: [400] hidden size: [118] trial: 9, train_loss: 1.280809, test loss: 1.554728, bias2: 0.7093380689620972, variance: 0.8453896045684814\n",
      "Train size: [400] hidden size: [118] trial: 10, train_loss: 1.276679, test loss: 1.543293, bias2: 0.7000632286071777, variance: 0.8432294130325317\n",
      "Train size: [400] hidden size: [118] trial: 11, train_loss: 1.297397, test loss: 1.531321, bias2: 0.6886633634567261, variance: 0.8426578044891357\n",
      "Train size: [400] hidden size: [118] trial: 12, train_loss: 1.297827, test loss: 1.527768, bias2: 0.679375946521759, variance: 0.8483925461769104\n",
      "Train size: [400] hidden size: [118] trial: 13, train_loss: 1.304217, test loss: 1.513547, bias2: 0.6706522703170776, variance: 0.8428950309753418\n",
      "Train size: [400] hidden size: [118] trial: 14, train_loss: 1.296366, test loss: 1.502471, bias2: 0.6671062707901001, variance: 0.8353649377822876\n",
      "Train size: [400] hidden size: [118] trial: 15, train_loss: 1.299401, test loss: 1.504638, bias2: 0.6671339869499207, variance: 0.8375038504600525\n",
      "Train size: [400] hidden size: [118] trial: 16, train_loss: 1.294932, test loss: 1.504102, bias2: 0.6676098108291626, variance: 0.8364924192428589\n",
      "Train size: [400] hidden size: [118] trial: 17, train_loss: 1.282333, test loss: 1.513716, bias2: 0.6705508232116699, variance: 0.8431649208068848\n",
      "Train size: [400] hidden size: [118] trial: 18, train_loss: 1.282116, test loss: 1.508583, bias2: 0.6652864217758179, variance: 0.8432965278625488\n",
      "Train size: [400] hidden size: [118] trial: 19, train_loss: 1.280340, test loss: 1.509296, bias2: 0.6649301648139954, variance: 0.8443655371665955\n",
      "Train size: [400] hidden size: [118] trial: 20, train_loss: 1.281005, test loss: 1.514273, bias2: 0.6637742519378662, variance: 0.8504984378814697\n",
      "Train size: [400] hidden size: [118] trial: 21, train_loss: 1.280056, test loss: 1.515188, bias2: 0.664581298828125, variance: 0.8506067991256714\n",
      "Train size: [400] hidden size: [118] trial: 22, train_loss: 1.276021, test loss: 1.519381, bias2: 0.6618011593818665, variance: 0.8575798869132996\n",
      "Train size: [400] hidden size: [118] trial: 23, train_loss: 1.275834, test loss: 1.516052, bias2: 0.664513111114502, variance: 0.8515392541885376\n",
      "Train size: [400] hidden size: [118] trial: 24, train_loss: 1.274554, test loss: 1.518826, bias2: 0.6617943048477173, variance: 0.8570313453674316\n",
      "Train size: [400] hidden size: [118] trial: 25, train_loss: 1.273514, test loss: 1.512981, bias2: 0.6605002284049988, variance: 0.8524807095527649\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [118] trial: 26, train_loss: 1.272452, test loss: 1.517497, bias2: 0.6633008122444153, variance: 0.8541956543922424\n",
      "Train size: [400] hidden size: [118] trial: 27, train_loss: 1.270700, test loss: 1.512946, bias2: 0.6583154201507568, variance: 0.8546308279037476\n",
      "Train size: [400] hidden size: [118] trial: 28, train_loss: 1.266293, test loss: 1.513899, bias2: 0.6570478677749634, variance: 0.8568507432937622\n",
      "Train size: [400] hidden size: [118] trial: 29, train_loss: 1.276211, test loss: 1.516900, bias2: 0.653408944606781, variance: 0.863490879535675\n",
      "Train size: [400] hidden size: [118] trial: 30, train_loss: 1.279309, test loss: 1.516188, bias2: 0.6538226008415222, variance: 0.8623655438423157\n",
      "Train size: [400] hidden size: [118] trial: 31, train_loss: 1.277670, test loss: 1.510388, bias2: 0.651538610458374, variance: 0.858849048614502\n",
      "Train size: [400] hidden size: [118] trial: 32, train_loss: 1.275565, test loss: 1.512689, bias2: 0.6536585092544556, variance: 0.8590307235717773\n",
      "Train size: [400] hidden size: [118] trial: 33, train_loss: 1.273445, test loss: 1.512362, bias2: 0.650570273399353, variance: 0.861791729927063\n",
      "Train size: [400] hidden size: [118] trial: 34, train_loss: 1.275278, test loss: 1.516476, bias2: 0.6513773798942566, variance: 0.8650986552238464\n",
      "Train size: [400] hidden size: [118] trial: 35, train_loss: 1.273288, test loss: 1.519049, bias2: 0.6494522094726562, variance: 0.8695963621139526\n",
      "Train size: [400] hidden size: [118] trial: 36, train_loss: 1.274162, test loss: 1.524104, bias2: 0.6521880030632019, variance: 0.8719159960746765\n",
      "Train size: [400] hidden size: [118] trial: 37, train_loss: 1.274920, test loss: 1.519705, bias2: 0.6540554165840149, variance: 0.8656499981880188\n",
      "Train size: [400] hidden size: [118] trial: 38, train_loss: 1.277926, test loss: 1.517950, bias2: 0.6540393829345703, variance: 0.8639103174209595\n",
      "Train size: [400] hidden size: [118] trial: 39, train_loss: 1.279760, test loss: 1.518080, bias2: 0.6547303199768066, variance: 0.8633497953414917\n",
      "Train size: [400] hidden size: [118] trial: 40, train_loss: 1.277383, test loss: 1.518540, bias2: 0.6543179154396057, variance: 0.86422199010849\n",
      "Train size: [400] hidden size: [118] trial: 41, train_loss: 1.278345, test loss: 1.520256, bias2: 0.6504701375961304, variance: 0.8697855472564697\n",
      "Train size: [400] hidden size: [118] trial: 42, train_loss: 1.281522, test loss: 1.516487, bias2: 0.6528335213661194, variance: 0.8636536002159119\n",
      "Train size: [400] hidden size: [118] trial: 43, train_loss: 1.286233, test loss: 1.516919, bias2: 0.6487389206886292, variance: 0.8681796193122864\n",
      "Train size: [400] hidden size: [118] trial: 44, train_loss: 1.285867, test loss: 1.517961, bias2: 0.6499443054199219, variance: 0.8680169582366943\n",
      "Train size: [400] hidden size: [118] trial: 45, train_loss: 1.284793, test loss: 1.520082, bias2: 0.6467807292938232, variance: 0.8733012676239014\n",
      "Train size: [400] hidden size: [118] trial: 46, train_loss: 1.282844, test loss: 1.518422, bias2: 0.6462005972862244, variance: 0.8722216486930847\n",
      "Train size: [400] hidden size: [118] trial: 47, train_loss: 1.283455, test loss: 1.521768, bias2: 0.6494840979576111, variance: 0.8722837567329407\n",
      "Train size: [400] hidden size: [118] trial: 48, train_loss: 1.282036, test loss: 1.520276, bias2: 0.6503617763519287, variance: 0.8699138164520264\n",
      "Train size: [400] hidden size: [118] trial: 49, train_loss: 1.281184, test loss: 1.522542, bias2: 0.6504673957824707, variance: 0.8720749616622925\n",
      "##################################################\n",
      "Train size: [400] hidden size: [136] trial: 0, train_loss: 1.093923, test loss: 1.713745, bias2: 1.713744878768921, variance: 1.5570191802538602e-09\n",
      "Train size: [400] hidden size: [136] trial: 1, train_loss: 1.070389, test loss: 1.657826, bias2: 1.0693840980529785, variance: 0.5884421467781067\n",
      "Train size: [400] hidden size: [136] trial: 2, train_loss: 1.100948, test loss: 1.604762, bias2: 0.8917020559310913, variance: 0.7130601406097412\n",
      "Train size: [400] hidden size: [136] trial: 3, train_loss: 1.171630, test loss: 1.602573, bias2: 0.8323326110839844, variance: 0.770240068435669\n",
      "Train size: [400] hidden size: [136] trial: 4, train_loss: 1.152253, test loss: 1.567083, bias2: 0.7752559781074524, variance: 0.7918269038200378\n",
      "Train size: [400] hidden size: [136] trial: 5, train_loss: 1.144630, test loss: 1.591522, bias2: 0.758844256401062, variance: 0.8326780796051025\n",
      "Train size: [400] hidden size: [136] trial: 6, train_loss: 1.131299, test loss: 1.607243, bias2: 0.7376222610473633, variance: 0.8696203231811523\n",
      "Train size: [400] hidden size: [136] trial: 7, train_loss: 1.137576, test loss: 1.598466, bias2: 0.7154645919799805, variance: 0.8830016851425171\n",
      "Train size: [400] hidden size: [136] trial: 8, train_loss: 1.134286, test loss: 1.595616, bias2: 0.7063112258911133, variance: 0.8893049955368042\n",
      "Train size: [400] hidden size: [136] trial: 9, train_loss: 1.125883, test loss: 1.593215, bias2: 0.6990635395050049, variance: 0.8941518068313599\n",
      "Train size: [400] hidden size: [136] trial: 10, train_loss: 1.131547, test loss: 1.594130, bias2: 0.6964926719665527, variance: 0.8976374864578247\n",
      "Train size: [400] hidden size: [136] trial: 11, train_loss: 1.116230, test loss: 1.600494, bias2: 0.6829774379730225, variance: 0.9175164699554443\n",
      "Train size: [400] hidden size: [136] trial: 12, train_loss: 1.120450, test loss: 1.608836, bias2: 0.6740813255310059, variance: 0.9347547292709351\n",
      "Train size: [400] hidden size: [136] trial: 13, train_loss: 1.131149, test loss: 1.602316, bias2: 0.6688526272773743, variance: 0.9334635138511658\n",
      "Train size: [400] hidden size: [136] trial: 14, train_loss: 1.132659, test loss: 1.605572, bias2: 0.6606128215789795, variance: 0.944959282875061\n",
      "Train size: [400] hidden size: [136] trial: 15, train_loss: 1.128470, test loss: 1.617482, bias2: 0.6503497362136841, variance: 0.9671326875686646\n",
      "Train size: [400] hidden size: [136] trial: 16, train_loss: 1.127831, test loss: 1.613554, bias2: 0.6479476690292358, variance: 0.9656065702438354\n",
      "Train size: [400] hidden size: [136] trial: 17, train_loss: 1.126931, test loss: 1.610410, bias2: 0.6480950713157654, variance: 0.9623153805732727\n",
      "Train size: [400] hidden size: [136] trial: 18, train_loss: 1.125820, test loss: 1.624251, bias2: 0.6399831175804138, variance: 0.9842674136161804\n",
      "Train size: [400] hidden size: [136] trial: 19, train_loss: 1.122601, test loss: 1.629855, bias2: 0.6381605863571167, variance: 0.9916939735412598\n",
      "Train size: [400] hidden size: [136] trial: 20, train_loss: 1.132754, test loss: 1.627641, bias2: 0.6362227201461792, variance: 0.9914182424545288\n",
      "Train size: [400] hidden size: [136] trial: 21, train_loss: 1.129549, test loss: 1.617146, bias2: 0.6339996457099915, variance: 0.9831460118293762\n",
      "Train size: [400] hidden size: [136] trial: 22, train_loss: 1.130364, test loss: 1.609356, bias2: 0.6298189163208008, variance: 0.9795370101928711\n",
      "Train size: [400] hidden size: [136] trial: 23, train_loss: 1.133274, test loss: 1.609155, bias2: 0.6260858178138733, variance: 0.9830695986747742\n",
      "Train size: [400] hidden size: [136] trial: 24, train_loss: 1.128527, test loss: 1.601725, bias2: 0.620756208896637, variance: 0.980969250202179\n",
      "Train size: [400] hidden size: [136] trial: 25, train_loss: 1.134136, test loss: 1.608361, bias2: 0.6239693760871887, variance: 0.9843916296958923\n",
      "Train size: [400] hidden size: [136] trial: 26, train_loss: 1.134388, test loss: 1.606616, bias2: 0.6227438449859619, variance: 0.9838725328445435\n",
      "Train size: [400] hidden size: [136] trial: 27, train_loss: 1.128493, test loss: 1.605841, bias2: 0.6198318004608154, variance: 0.9860090017318726\n",
      "Train size: [400] hidden size: [136] trial: 28, train_loss: 1.121367, test loss: 1.607672, bias2: 0.6172498464584351, variance: 0.9904223680496216\n",
      "Train size: [400] hidden size: [136] trial: 29, train_loss: 1.116978, test loss: 1.603021, bias2: 0.6149031519889832, variance: 0.9881179928779602\n",
      "Train size: [400] hidden size: [136] trial: 30, train_loss: 1.118591, test loss: 1.603027, bias2: 0.61827152967453, variance: 0.9847555756568909\n",
      "Train size: [400] hidden size: [136] trial: 31, train_loss: 1.121466, test loss: 1.600046, bias2: 0.6130599975585938, variance: 0.9869862794876099\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [136] trial: 32, train_loss: 1.120533, test loss: 1.596169, bias2: 0.6121343970298767, variance: 0.9840349555015564\n",
      "Train size: [400] hidden size: [136] trial: 33, train_loss: 1.123070, test loss: 1.601888, bias2: 0.6134393215179443, variance: 0.9884486198425293\n",
      "Train size: [400] hidden size: [136] trial: 34, train_loss: 1.120634, test loss: 1.609433, bias2: 0.6112459897994995, variance: 0.998186469078064\n",
      "Train size: [400] hidden size: [136] trial: 35, train_loss: 1.124983, test loss: 1.611999, bias2: 0.6104903221130371, variance: 1.001508355140686\n",
      "Train size: [400] hidden size: [136] trial: 36, train_loss: 1.120161, test loss: 1.609710, bias2: 0.6062543392181396, variance: 1.0034552812576294\n",
      "Train size: [400] hidden size: [136] trial: 37, train_loss: 1.121080, test loss: 1.615613, bias2: 0.6046313047409058, variance: 1.0109813213348389\n",
      "Train size: [400] hidden size: [136] trial: 38, train_loss: 1.123493, test loss: 1.619286, bias2: 0.6009608507156372, variance: 1.0183252096176147\n",
      "Train size: [400] hidden size: [136] trial: 39, train_loss: 1.123949, test loss: 1.622205, bias2: 0.6003473997116089, variance: 1.0218573808670044\n",
      "Train size: [400] hidden size: [136] trial: 40, train_loss: 1.125896, test loss: 1.620793, bias2: 0.6004574298858643, variance: 1.0203359127044678\n",
      "Train size: [400] hidden size: [136] trial: 41, train_loss: 1.124780, test loss: 1.625482, bias2: 0.5998802185058594, variance: 1.0256022214889526\n",
      "Train size: [400] hidden size: [136] trial: 42, train_loss: 1.130222, test loss: 1.629532, bias2: 0.6005659103393555, variance: 1.028965711593628\n",
      "Train size: [400] hidden size: [136] trial: 43, train_loss: 1.131153, test loss: 1.635193, bias2: 0.6031455993652344, variance: 1.0320470333099365\n",
      "Train size: [400] hidden size: [136] trial: 44, train_loss: 1.130647, test loss: 1.628574, bias2: 0.6015784740447998, variance: 1.0269951820373535\n",
      "Train size: [400] hidden size: [136] trial: 45, train_loss: 1.133316, test loss: 1.629725, bias2: 0.6032819747924805, variance: 1.0264428853988647\n",
      "Train size: [400] hidden size: [136] trial: 46, train_loss: 1.135374, test loss: 1.629323, bias2: 0.602888822555542, variance: 1.0264338254928589\n",
      "Train size: [400] hidden size: [136] trial: 47, train_loss: 1.136464, test loss: 1.631105, bias2: 0.6022962331771851, variance: 1.0288084745407104\n",
      "Train size: [400] hidden size: [136] trial: 48, train_loss: 1.133760, test loss: 1.634167, bias2: 0.6032252311706543, variance: 1.0309414863586426\n",
      "Train size: [400] hidden size: [136] trial: 49, train_loss: 1.135939, test loss: 1.631749, bias2: 0.6029198169708252, variance: 1.0288292169570923\n",
      "##################################################\n",
      "Train size: [400] hidden size: [156] trial: 0, train_loss: 0.965906, test loss: 1.733657, bias2: 1.733656883239746, variance: 2.3355288814030928e-09\n",
      "Train size: [400] hidden size: [156] trial: 1, train_loss: 0.950054, test loss: 1.678160, bias2: 1.0513420104980469, variance: 0.6268182396888733\n",
      "Train size: [400] hidden size: [156] trial: 2, train_loss: 0.965909, test loss: 1.656426, bias2: 0.8792144060134888, variance: 0.7772120237350464\n",
      "Train size: [400] hidden size: [156] trial: 3, train_loss: 1.029893, test loss: 1.718362, bias2: 0.8323006629943848, variance: 0.8860611915588379\n",
      "Train size: [400] hidden size: [156] trial: 4, train_loss: 1.063865, test loss: 1.744757, bias2: 0.7731261849403381, variance: 0.9716307520866394\n",
      "Train size: [400] hidden size: [156] trial: 5, train_loss: 1.050574, test loss: 1.736385, bias2: 0.7305405139923096, variance: 1.0058449506759644\n",
      "Train size: [400] hidden size: [156] trial: 6, train_loss: 1.026696, test loss: 1.706630, bias2: 0.6979132890701294, variance: 1.0087171792984009\n",
      "Train size: [400] hidden size: [156] trial: 7, train_loss: 1.040772, test loss: 1.721317, bias2: 0.6869809627532959, variance: 1.0343363285064697\n",
      "Train size: [400] hidden size: [156] trial: 8, train_loss: 1.022152, test loss: 1.714836, bias2: 0.6843066215515137, variance: 1.0305297374725342\n",
      "Train size: [400] hidden size: [156] trial: 9, train_loss: 1.033776, test loss: 1.724346, bias2: 0.668020486831665, variance: 1.0563251972198486\n",
      "Train size: [400] hidden size: [156] trial: 10, train_loss: 1.053115, test loss: 1.727190, bias2: 0.6577945947647095, variance: 1.0693951845169067\n",
      "Train size: [400] hidden size: [156] trial: 11, train_loss: 1.051188, test loss: 1.718058, bias2: 0.6520545482635498, variance: 1.0660030841827393\n",
      "Train size: [400] hidden size: [156] trial: 12, train_loss: 1.050970, test loss: 1.712070, bias2: 0.6477998495101929, variance: 1.064270257949829\n",
      "Train size: [400] hidden size: [156] trial: 13, train_loss: 1.049905, test loss: 1.715794, bias2: 0.6365922689437866, variance: 1.0792014598846436\n",
      "Train size: [400] hidden size: [156] trial: 14, train_loss: 1.057572, test loss: 1.727761, bias2: 0.6293647289276123, variance: 1.0983966588974\n",
      "Train size: [400] hidden size: [156] trial: 15, train_loss: 1.059813, test loss: 1.744706, bias2: 0.6217125654220581, variance: 1.1229935884475708\n",
      "Train size: [400] hidden size: [156] trial: 16, train_loss: 1.052096, test loss: 1.756025, bias2: 0.6205621957778931, variance: 1.1354628801345825\n",
      "Train size: [400] hidden size: [156] trial: 17, train_loss: 1.056024, test loss: 1.761248, bias2: 0.6219948530197144, variance: 1.1392529010772705\n",
      "Train size: [400] hidden size: [156] trial: 18, train_loss: 1.063875, test loss: 1.755380, bias2: 0.61647629737854, variance: 1.1389037370681763\n",
      "Train size: [400] hidden size: [156] trial: 19, train_loss: 1.062074, test loss: 1.769885, bias2: 0.6100175380706787, variance: 1.1598671674728394\n",
      "Train size: [400] hidden size: [156] trial: 20, train_loss: 1.061996, test loss: 1.772017, bias2: 0.6125315427780151, variance: 1.1594858169555664\n",
      "Train size: [400] hidden size: [156] trial: 21, train_loss: 1.061563, test loss: 1.771649, bias2: 0.6084945201873779, variance: 1.163154125213623\n",
      "Train size: [400] hidden size: [156] trial: 22, train_loss: 1.064204, test loss: 1.768916, bias2: 0.6025960445404053, variance: 1.1663202047348022\n",
      "Train size: [400] hidden size: [156] trial: 23, train_loss: 1.061017, test loss: 1.779930, bias2: 0.5940548181533813, variance: 1.1858749389648438\n",
      "Train size: [400] hidden size: [156] trial: 24, train_loss: 1.064291, test loss: 1.782212, bias2: 0.5877770185470581, variance: 1.1944348812103271\n",
      "Train size: [400] hidden size: [156] trial: 25, train_loss: 1.061797, test loss: 1.786597, bias2: 0.5850702524185181, variance: 1.2015262842178345\n",
      "Train size: [400] hidden size: [156] trial: 26, train_loss: 1.058521, test loss: 1.787533, bias2: 0.5857754945755005, variance: 1.201757788658142\n",
      "Train size: [400] hidden size: [156] trial: 27, train_loss: 1.055123, test loss: 1.776894, bias2: 0.5836060047149658, variance: 1.1932878494262695\n",
      "Train size: [400] hidden size: [156] trial: 28, train_loss: 1.049113, test loss: 1.770195, bias2: 0.5818310976028442, variance: 1.1883636713027954\n",
      "Train size: [400] hidden size: [156] trial: 29, train_loss: 1.049295, test loss: 1.763993, bias2: 0.5783522129058838, variance: 1.1856409311294556\n",
      "Train size: [400] hidden size: [156] trial: 30, train_loss: 1.050885, test loss: 1.765364, bias2: 0.5794644355773926, variance: 1.1858998537063599\n",
      "Train size: [400] hidden size: [156] trial: 31, train_loss: 1.049392, test loss: 1.765145, bias2: 0.5757298469543457, variance: 1.1894149780273438\n",
      "Train size: [400] hidden size: [156] trial: 32, train_loss: 1.052614, test loss: 1.765728, bias2: 0.5754686594009399, variance: 1.1902588605880737\n",
      "Train size: [400] hidden size: [156] trial: 33, train_loss: 1.052148, test loss: 1.765724, bias2: 0.5755828619003296, variance: 1.190140962600708\n",
      "Train size: [400] hidden size: [156] trial: 34, train_loss: 1.048347, test loss: 1.776144, bias2: 0.5736821889877319, variance: 1.2024617195129395\n",
      "Train size: [400] hidden size: [156] trial: 35, train_loss: 1.044849, test loss: 1.780980, bias2: 0.5711871385574341, variance: 1.2097924947738647\n",
      "Train size: [400] hidden size: [156] trial: 36, train_loss: 1.046154, test loss: 1.786275, bias2: 0.5682299137115479, variance: 1.2180447578430176\n",
      "Train size: [400] hidden size: [156] trial: 37, train_loss: 1.050060, test loss: 1.796601, bias2: 0.5628013610839844, variance: 1.2337993383407593\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [156] trial: 38, train_loss: 1.051853, test loss: 1.794731, bias2: 0.5599488019943237, variance: 1.2347819805145264\n",
      "Train size: [400] hidden size: [156] trial: 39, train_loss: 1.054408, test loss: 1.796965, bias2: 0.5582143068313599, variance: 1.2387504577636719\n",
      "Train size: [400] hidden size: [156] trial: 40, train_loss: 1.053536, test loss: 1.797106, bias2: 0.5581027269363403, variance: 1.2390029430389404\n",
      "Train size: [400] hidden size: [156] trial: 41, train_loss: 1.052652, test loss: 1.803121, bias2: 0.5595406293869019, variance: 1.2435805797576904\n",
      "Train size: [400] hidden size: [156] trial: 42, train_loss: 1.052234, test loss: 1.800056, bias2: 0.5619940757751465, variance: 1.2380622625350952\n",
      "Train size: [400] hidden size: [156] trial: 43, train_loss: 1.049903, test loss: 1.792997, bias2: 0.5630819797515869, variance: 1.2299152612686157\n",
      "Train size: [400] hidden size: [156] trial: 44, train_loss: 1.048896, test loss: 1.791289, bias2: 0.5572280883789062, variance: 1.2340606451034546\n",
      "Train size: [400] hidden size: [156] trial: 45, train_loss: 1.046725, test loss: 1.792836, bias2: 0.5562433004379272, variance: 1.2365925312042236\n",
      "Train size: [400] hidden size: [156] trial: 46, train_loss: 1.046958, test loss: 1.797623, bias2: 0.5592348575592041, variance: 1.2383885383605957\n",
      "Train size: [400] hidden size: [156] trial: 47, train_loss: 1.045001, test loss: 1.794233, bias2: 0.5572844743728638, variance: 1.2369484901428223\n",
      "Train size: [400] hidden size: [156] trial: 48, train_loss: 1.044490, test loss: 1.793297, bias2: 0.5558120012283325, variance: 1.237485408782959\n",
      "Train size: [400] hidden size: [156] trial: 49, train_loss: 1.042122, test loss: 1.795393, bias2: 0.5552177429199219, variance: 1.2401751279830933\n",
      "##################################################\n",
      "Train size: [400] hidden size: [180] trial: 0, train_loss: 0.934996, test loss: 1.881470, bias2: 1.8814700841903687, variance: 1.479168254547858e-08\n",
      "Train size: [400] hidden size: [180] trial: 1, train_loss: 1.047454, test loss: 1.866054, bias2: 1.1469793319702148, variance: 0.719074547290802\n",
      "Train size: [400] hidden size: [180] trial: 2, train_loss: 1.027825, test loss: 1.878216, bias2: 0.9418148994445801, variance: 0.9364012479782104\n",
      "Train size: [400] hidden size: [180] trial: 3, train_loss: 0.962338, test loss: 1.848080, bias2: 0.7882555723190308, variance: 1.059824824333191\n",
      "Train size: [400] hidden size: [180] trial: 4, train_loss: 0.962826, test loss: 1.868744, bias2: 0.7175709009170532, variance: 1.1511733531951904\n",
      "Train size: [400] hidden size: [180] trial: 5, train_loss: 0.941203, test loss: 1.857890, bias2: 0.671958327293396, variance: 1.1859312057495117\n",
      "Train size: [400] hidden size: [180] trial: 6, train_loss: 0.947521, test loss: 1.867945, bias2: 0.6475553512573242, variance: 1.22038996219635\n",
      "Train size: [400] hidden size: [180] trial: 7, train_loss: 0.934770, test loss: 1.870906, bias2: 0.6158006191253662, variance: 1.2551058530807495\n",
      "Train size: [400] hidden size: [180] trial: 8, train_loss: 0.907671, test loss: 1.868795, bias2: 0.5946328639984131, variance: 1.2741624116897583\n",
      "Train size: [400] hidden size: [180] trial: 9, train_loss: 0.906439, test loss: 1.884315, bias2: 0.5770381689071655, variance: 1.3072768449783325\n",
      "Train size: [400] hidden size: [180] trial: 10, train_loss: 0.903811, test loss: 1.918721, bias2: 0.5747181177139282, variance: 1.3440032005310059\n",
      "Train size: [400] hidden size: [180] trial: 11, train_loss: 0.911337, test loss: 1.929205, bias2: 0.5685094594955444, variance: 1.360695481300354\n",
      "Train size: [400] hidden size: [180] trial: 12, train_loss: 0.905717, test loss: 1.956845, bias2: 0.5593934059143066, variance: 1.3974515199661255\n",
      "Train size: [400] hidden size: [180] trial: 13, train_loss: 0.912523, test loss: 1.939002, bias2: 0.5533616542816162, variance: 1.3856401443481445\n",
      "Train size: [400] hidden size: [180] trial: 14, train_loss: 0.909656, test loss: 1.949561, bias2: 0.5485067367553711, variance: 1.4010545015335083\n",
      "Train size: [400] hidden size: [180] trial: 15, train_loss: 0.920063, test loss: 1.945549, bias2: 0.5477796792984009, variance: 1.397769808769226\n",
      "Train size: [400] hidden size: [180] trial: 16, train_loss: 0.921025, test loss: 1.943384, bias2: 0.5372164249420166, variance: 1.40616774559021\n",
      "Train size: [400] hidden size: [180] trial: 17, train_loss: 0.922291, test loss: 1.939808, bias2: 0.5339241027832031, variance: 1.4058834314346313\n",
      "Train size: [400] hidden size: [180] trial: 18, train_loss: 0.920454, test loss: 1.942961, bias2: 0.5339779853820801, variance: 1.408982753753662\n",
      "Train size: [400] hidden size: [180] trial: 19, train_loss: 0.915399, test loss: 1.943006, bias2: 0.5230560302734375, variance: 1.4199497699737549\n",
      "Train size: [400] hidden size: [180] trial: 20, train_loss: 0.911186, test loss: 1.939526, bias2: 0.5162532329559326, variance: 1.423272728919983\n",
      "Train size: [400] hidden size: [180] trial: 21, train_loss: 0.916287, test loss: 1.944589, bias2: 0.5122324228286743, variance: 1.4323569536209106\n",
      "Train size: [400] hidden size: [180] trial: 22, train_loss: 0.911352, test loss: 1.952896, bias2: 0.5053091049194336, variance: 1.4475865364074707\n",
      "Train size: [400] hidden size: [180] trial: 23, train_loss: 0.905443, test loss: 1.950282, bias2: 0.5045422315597534, variance: 1.445739507675171\n",
      "Train size: [400] hidden size: [180] trial: 24, train_loss: 0.912188, test loss: 1.961773, bias2: 0.5032351016998291, variance: 1.4585379362106323\n",
      "Train size: [400] hidden size: [180] trial: 25, train_loss: 0.908575, test loss: 1.950093, bias2: 0.5051003694534302, variance: 1.4449923038482666\n",
      "Train size: [400] hidden size: [180] trial: 26, train_loss: 0.904923, test loss: 1.956970, bias2: 0.5008740425109863, variance: 1.4560961723327637\n",
      "Train size: [400] hidden size: [180] trial: 27, train_loss: 0.904147, test loss: 1.962353, bias2: 0.4985184669494629, variance: 1.4638347625732422\n",
      "Train size: [400] hidden size: [180] trial: 28, train_loss: 0.898946, test loss: 1.960244, bias2: 0.4976341724395752, variance: 1.462609887123108\n",
      "Train size: [400] hidden size: [180] trial: 29, train_loss: 0.903395, test loss: 1.967845, bias2: 0.4971482753753662, variance: 1.4706971645355225\n",
      "Train size: [400] hidden size: [180] trial: 30, train_loss: 0.907459, test loss: 1.966708, bias2: 0.49823272228240967, variance: 1.4684748649597168\n",
      "Train size: [400] hidden size: [180] trial: 31, train_loss: 0.906978, test loss: 1.964909, bias2: 0.4975472688674927, variance: 1.4673619270324707\n",
      "Train size: [400] hidden size: [180] trial: 32, train_loss: 0.908690, test loss: 1.963650, bias2: 0.4963124990463257, variance: 1.4673374891281128\n",
      "Train size: [400] hidden size: [180] trial: 33, train_loss: 0.911710, test loss: 1.961924, bias2: 0.4949817657470703, variance: 1.4669419527053833\n",
      "Train size: [400] hidden size: [180] trial: 34, train_loss: 0.912710, test loss: 1.964113, bias2: 0.4936481714248657, variance: 1.470464825630188\n",
      "Train size: [400] hidden size: [180] trial: 35, train_loss: 0.912794, test loss: 1.971313, bias2: 0.4945117235183716, variance: 1.476800799369812\n",
      "Train size: [400] hidden size: [180] trial: 36, train_loss: 0.912230, test loss: 1.966975, bias2: 0.4950673580169678, variance: 1.4719079732894897\n",
      "Train size: [400] hidden size: [180] trial: 37, train_loss: 0.911183, test loss: 1.969060, bias2: 0.4934781789779663, variance: 1.475581407546997\n",
      "Train size: [400] hidden size: [180] trial: 38, train_loss: 0.911577, test loss: 1.965372, bias2: 0.4899243116378784, variance: 1.475447654724121\n",
      "Train size: [400] hidden size: [180] trial: 39, train_loss: 0.911771, test loss: 1.966272, bias2: 0.4926776885986328, variance: 1.4735946655273438\n",
      "Train size: [400] hidden size: [180] trial: 40, train_loss: 0.909995, test loss: 1.967415, bias2: 0.49174511432647705, variance: 1.475670337677002\n",
      "Train size: [400] hidden size: [180] trial: 41, train_loss: 0.909421, test loss: 1.966066, bias2: 0.4909173250198364, variance: 1.475149154663086\n",
      "Train size: [400] hidden size: [180] trial: 42, train_loss: 0.908268, test loss: 1.971436, bias2: 0.4905240535736084, variance: 1.4809123277664185\n",
      "Train size: [400] hidden size: [180] trial: 43, train_loss: 0.906676, test loss: 1.979875, bias2: 0.4955275058746338, variance: 1.4843478202819824\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [180] trial: 44, train_loss: 0.905922, test loss: 1.981151, bias2: 0.49425506591796875, variance: 1.4868957996368408\n",
      "Train size: [400] hidden size: [180] trial: 45, train_loss: 0.908935, test loss: 1.981695, bias2: 0.49291813373565674, variance: 1.4887765645980835\n",
      "Train size: [400] hidden size: [180] trial: 46, train_loss: 0.907649, test loss: 1.981173, bias2: 0.4933347702026367, variance: 1.4878387451171875\n",
      "Train size: [400] hidden size: [180] trial: 47, train_loss: 0.908828, test loss: 1.972442, bias2: 0.4904528856277466, variance: 1.4819886684417725\n",
      "Train size: [400] hidden size: [180] trial: 48, train_loss: 0.909411, test loss: 1.972261, bias2: 0.490262508392334, variance: 1.4819982051849365\n",
      "Train size: [400] hidden size: [180] trial: 49, train_loss: 0.908437, test loss: 1.968420, bias2: 0.4873325824737549, variance: 1.4810878038406372\n",
      "##################################################\n",
      "Train size: [400] hidden size: [207] trial: 0, train_loss: 0.921783, test loss: 2.250923, bias2: 2.250922679901123, variance: -1.4013172844329347e-08\n",
      "Train size: [400] hidden size: [207] trial: 1, train_loss: 0.934146, test loss: 2.100625, bias2: 1.2401683330535889, variance: 0.8604562282562256\n",
      "Train size: [400] hidden size: [207] trial: 2, train_loss: 0.888407, test loss: 2.091687, bias2: 0.947510838508606, variance: 1.1441761255264282\n",
      "Train size: [400] hidden size: [207] trial: 3, train_loss: 0.858848, test loss: 2.169615, bias2: 0.8654569387435913, variance: 1.304158091545105\n",
      "Train size: [400] hidden size: [207] trial: 4, train_loss: 0.853581, test loss: 2.192357, bias2: 0.7685079574584961, variance: 1.423849105834961\n",
      "Train size: [400] hidden size: [207] trial: 5, train_loss: 0.855008, test loss: 2.255250, bias2: 0.7395981550216675, variance: 1.5156515836715698\n",
      "Train size: [400] hidden size: [207] trial: 6, train_loss: 0.848906, test loss: 2.216104, bias2: 0.6895098686218262, variance: 1.5265941619873047\n",
      "Train size: [400] hidden size: [207] trial: 7, train_loss: 0.843600, test loss: 2.187957, bias2: 0.6553738117218018, variance: 1.532583236694336\n",
      "Train size: [400] hidden size: [207] trial: 8, train_loss: 0.836079, test loss: 2.181480, bias2: 0.6195254325866699, variance: 1.5619549751281738\n",
      "Train size: [400] hidden size: [207] trial: 9, train_loss: 0.834223, test loss: 2.221590, bias2: 0.6208484172821045, variance: 1.6007421016693115\n",
      "Train size: [400] hidden size: [207] trial: 10, train_loss: 0.833830, test loss: 2.225466, bias2: 0.6072219610214233, variance: 1.6182440519332886\n",
      "Train size: [400] hidden size: [207] trial: 11, train_loss: 0.830423, test loss: 2.232370, bias2: 0.5927324295043945, variance: 1.6396374702453613\n",
      "Train size: [400] hidden size: [207] trial: 12, train_loss: 0.825910, test loss: 2.222606, bias2: 0.5847424268722534, variance: 1.6378637552261353\n",
      "Train size: [400] hidden size: [207] trial: 13, train_loss: 0.822574, test loss: 2.225740, bias2: 0.562591552734375, variance: 1.6631481647491455\n",
      "Train size: [400] hidden size: [207] trial: 14, train_loss: 0.818076, test loss: 2.213066, bias2: 0.5528544187545776, variance: 1.6602116823196411\n",
      "Train size: [400] hidden size: [207] trial: 15, train_loss: 0.819778, test loss: 2.203291, bias2: 0.5448650121688843, variance: 1.6584259271621704\n",
      "Train size: [400] hidden size: [207] trial: 16, train_loss: 0.815172, test loss: 2.198050, bias2: 0.5335310697555542, variance: 1.6645184755325317\n",
      "Train size: [400] hidden size: [207] trial: 17, train_loss: 0.813789, test loss: 2.196143, bias2: 0.5296516418457031, variance: 1.6664912700653076\n",
      "Train size: [400] hidden size: [207] trial: 18, train_loss: 0.809297, test loss: 2.196134, bias2: 0.5278606414794922, variance: 1.6682729721069336\n",
      "Train size: [400] hidden size: [207] trial: 19, train_loss: 0.808789, test loss: 2.180393, bias2: 0.5196564197540283, variance: 1.6607365608215332\n",
      "Train size: [400] hidden size: [207] trial: 20, train_loss: 0.806019, test loss: 2.174303, bias2: 0.5145095586776733, variance: 1.6597930192947388\n",
      "Train size: [400] hidden size: [207] trial: 21, train_loss: 0.806304, test loss: 2.160986, bias2: 0.5128129720687866, variance: 1.648173451423645\n",
      "Train size: [400] hidden size: [207] trial: 22, train_loss: 0.802229, test loss: 2.161915, bias2: 0.510887861251831, variance: 1.6510274410247803\n",
      "Train size: [400] hidden size: [207] trial: 23, train_loss: 0.801801, test loss: 2.175036, bias2: 0.5038411617279053, variance: 1.6711952686309814\n",
      "Train size: [400] hidden size: [207] trial: 24, train_loss: 0.803287, test loss: 2.159337, bias2: 0.49515604972839355, variance: 1.6641807556152344\n",
      "Train size: [400] hidden size: [207] trial: 25, train_loss: 0.803042, test loss: 2.157826, bias2: 0.49082815647125244, variance: 1.6669977903366089\n",
      "Train size: [400] hidden size: [207] trial: 26, train_loss: 0.801781, test loss: 2.153391, bias2: 0.4876900911331177, variance: 1.6657005548477173\n",
      "Train size: [400] hidden size: [207] trial: 27, train_loss: 0.795967, test loss: 2.143677, bias2: 0.48388874530792236, variance: 1.6597882509231567\n",
      "Train size: [400] hidden size: [207] trial: 28, train_loss: 0.800928, test loss: 2.144939, bias2: 0.4857213497161865, variance: 1.659217357635498\n",
      "Train size: [400] hidden size: [207] trial: 29, train_loss: 0.796818, test loss: 2.144539, bias2: 0.48649024963378906, variance: 1.6580491065979004\n",
      "Train size: [400] hidden size: [207] trial: 30, train_loss: 0.798379, test loss: 2.153060, bias2: 0.4841451644897461, variance: 1.668915033340454\n",
      "Train size: [400] hidden size: [207] trial: 31, train_loss: 0.796812, test loss: 2.157787, bias2: 0.4822866916656494, variance: 1.6754999160766602\n",
      "Train size: [400] hidden size: [207] trial: 32, train_loss: 0.792212, test loss: 2.147553, bias2: 0.48234105110168457, variance: 1.6652116775512695\n",
      "Train size: [400] hidden size: [207] trial: 33, train_loss: 0.790855, test loss: 2.142669, bias2: 0.47960567474365234, variance: 1.6630632877349854\n",
      "Train size: [400] hidden size: [207] trial: 34, train_loss: 0.789776, test loss: 2.151357, bias2: 0.4795414209365845, variance: 1.6718157529830933\n",
      "Train size: [400] hidden size: [207] trial: 35, train_loss: 0.789831, test loss: 2.152371, bias2: 0.4786015748977661, variance: 1.6737693548202515\n",
      "Train size: [400] hidden size: [207] trial: 36, train_loss: 0.790384, test loss: 2.158227, bias2: 0.4749706983566284, variance: 1.6832557916641235\n",
      "Train size: [400] hidden size: [207] trial: 37, train_loss: 0.791673, test loss: 2.159464, bias2: 0.47120440006256104, variance: 1.688259482383728\n",
      "Train size: [400] hidden size: [207] trial: 38, train_loss: 0.793892, test loss: 2.158015, bias2: 0.47214388847351074, variance: 1.6858716011047363\n",
      "Train size: [400] hidden size: [207] trial: 39, train_loss: 0.793089, test loss: 2.154827, bias2: 0.46987807750701904, variance: 1.684949517250061\n",
      "Train size: [400] hidden size: [207] trial: 40, train_loss: 0.790203, test loss: 2.153932, bias2: 0.468330979347229, variance: 1.6856008768081665\n",
      "Train size: [400] hidden size: [207] trial: 41, train_loss: 0.791397, test loss: 2.154667, bias2: 0.4642857313156128, variance: 1.690381407737732\n",
      "Train size: [400] hidden size: [207] trial: 42, train_loss: 0.791724, test loss: 2.155157, bias2: 0.4630359411239624, variance: 1.692121148109436\n",
      "Train size: [400] hidden size: [207] trial: 43, train_loss: 0.791769, test loss: 2.159638, bias2: 0.46499502658843994, variance: 1.6946433782577515\n",
      "Train size: [400] hidden size: [207] trial: 44, train_loss: 0.792637, test loss: 2.165026, bias2: 0.4673079252243042, variance: 1.6977177858352661\n",
      "Train size: [400] hidden size: [207] trial: 45, train_loss: 0.794490, test loss: 2.164962, bias2: 0.46676111221313477, variance: 1.6982004642486572\n",
      "Train size: [400] hidden size: [207] trial: 46, train_loss: 0.794575, test loss: 2.168747, bias2: 0.4635887145996094, variance: 1.705157995223999\n",
      "Train size: [400] hidden size: [207] trial: 47, train_loss: 0.794011, test loss: 2.174341, bias2: 0.4631924629211426, variance: 1.711148738861084\n",
      "Train size: [400] hidden size: [207] trial: 48, train_loss: 0.795356, test loss: 2.179315, bias2: 0.4618048667907715, variance: 1.7175102233886719\n",
      "Train size: [400] hidden size: [207] trial: 49, train_loss: 0.795576, test loss: 2.179920, bias2: 0.46024608612060547, variance: 1.7196736335754395\n",
      "##################################################\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [239] trial: 0, train_loss: 0.674584, test loss: 2.628671, bias2: 2.6286706924438477, variance: 1.4013172844329347e-08\n",
      "Train size: [400] hidden size: [239] trial: 1, train_loss: 0.659674, test loss: 2.501504, bias2: 1.4404399394989014, variance: 1.0610642433166504\n",
      "Train size: [400] hidden size: [239] trial: 2, train_loss: 0.669327, test loss: 2.521956, bias2: 1.0440280437469482, variance: 1.4779279232025146\n",
      "Train size: [400] hidden size: [239] trial: 3, train_loss: 0.664393, test loss: 2.462586, bias2: 0.8653690814971924, variance: 1.5972168445587158\n",
      "Train size: [400] hidden size: [239] trial: 4, train_loss: 0.661052, test loss: 2.475202, bias2: 0.7291388511657715, variance: 1.746063470840454\n",
      "Train size: [400] hidden size: [239] trial: 5, train_loss: 0.656788, test loss: 2.520031, bias2: 0.7094122171401978, variance: 1.81061851978302\n",
      "Train size: [400] hidden size: [239] trial: 6, train_loss: 0.664199, test loss: 2.492214, bias2: 0.6598927974700928, variance: 1.8323211669921875\n",
      "Train size: [400] hidden size: [239] trial: 7, train_loss: 0.672051, test loss: 2.461035, bias2: 0.6191432476043701, variance: 1.8418917655944824\n",
      "Train size: [400] hidden size: [239] trial: 8, train_loss: 0.671228, test loss: 2.519191, bias2: 0.5884172916412354, variance: 1.9307739734649658\n",
      "Train size: [400] hidden size: [239] trial: 9, train_loss: 0.657065, test loss: 2.519324, bias2: 0.5854876041412354, variance: 1.9338364601135254\n",
      "Train size: [400] hidden size: [239] trial: 10, train_loss: 0.673507, test loss: 2.556278, bias2: 0.5710258483886719, variance: 1.9852521419525146\n",
      "Train size: [400] hidden size: [239] trial: 11, train_loss: 0.662519, test loss: 2.565478, bias2: 0.5451602935791016, variance: 2.020317792892456\n",
      "Train size: [400] hidden size: [239] trial: 12, train_loss: 0.652512, test loss: 2.552625, bias2: 0.528350830078125, variance: 2.0242743492126465\n",
      "Train size: [400] hidden size: [239] trial: 13, train_loss: 0.646026, test loss: 2.582152, bias2: 0.529465913772583, variance: 2.052685499191284\n",
      "Train size: [400] hidden size: [239] trial: 14, train_loss: 0.641215, test loss: 2.571300, bias2: 0.5213799476623535, variance: 2.0499205589294434\n",
      "Train size: [400] hidden size: [239] trial: 15, train_loss: 0.644222, test loss: 2.562964, bias2: 0.5087363719940186, variance: 2.054227113723755\n",
      "Train size: [400] hidden size: [239] trial: 16, train_loss: 0.648312, test loss: 2.584296, bias2: 0.4983375072479248, variance: 2.08595871925354\n",
      "Train size: [400] hidden size: [239] trial: 17, train_loss: 0.650775, test loss: 2.595879, bias2: 0.49839210510253906, variance: 2.0974864959716797\n",
      "Train size: [400] hidden size: [239] trial: 18, train_loss: 0.644490, test loss: 2.603470, bias2: 0.4852299690246582, variance: 2.1182398796081543\n",
      "Train size: [400] hidden size: [239] trial: 19, train_loss: 0.648894, test loss: 2.617817, bias2: 0.4824032783508301, variance: 2.135413885116577\n",
      "Train size: [400] hidden size: [239] trial: 20, train_loss: 0.651873, test loss: 2.605991, bias2: 0.4767146110534668, variance: 2.1292765140533447\n",
      "Train size: [400] hidden size: [239] trial: 21, train_loss: 0.655557, test loss: 2.586742, bias2: 0.46786928176879883, variance: 2.11887264251709\n",
      "Train size: [400] hidden size: [239] trial: 22, train_loss: 0.662864, test loss: 2.588697, bias2: 0.46192049980163574, variance: 2.126776695251465\n",
      "Train size: [400] hidden size: [239] trial: 23, train_loss: 0.657840, test loss: 2.593197, bias2: 0.45246028900146484, variance: 2.1407365798950195\n",
      "Train size: [400] hidden size: [239] trial: 24, train_loss: 0.657010, test loss: 2.588784, bias2: 0.4443838596343994, variance: 2.144399642944336\n",
      "Train size: [400] hidden size: [239] trial: 25, train_loss: 0.652558, test loss: 2.576912, bias2: 0.4421861171722412, variance: 2.13472580909729\n",
      "Train size: [400] hidden size: [239] trial: 26, train_loss: 0.658315, test loss: 2.571510, bias2: 0.43720436096191406, variance: 2.134305715560913\n",
      "Train size: [400] hidden size: [239] trial: 27, train_loss: 0.659240, test loss: 2.570061, bias2: 0.4375131130218506, variance: 2.1325478553771973\n",
      "Train size: [400] hidden size: [239] trial: 28, train_loss: 0.663794, test loss: 2.571999, bias2: 0.43195152282714844, variance: 2.140047073364258\n",
      "Train size: [400] hidden size: [239] trial: 29, train_loss: 0.662053, test loss: 2.577163, bias2: 0.42866015434265137, variance: 2.1485025882720947\n",
      "Train size: [400] hidden size: [239] trial: 30, train_loss: 0.659126, test loss: 2.570989, bias2: 0.42600226402282715, variance: 2.144986391067505\n",
      "Train size: [400] hidden size: [239] trial: 31, train_loss: 0.659709, test loss: 2.567533, bias2: 0.4290769100189209, variance: 2.1384565830230713\n",
      "Train size: [400] hidden size: [239] trial: 32, train_loss: 0.659857, test loss: 2.552175, bias2: 0.4244375228881836, variance: 2.127737283706665\n",
      "Train size: [400] hidden size: [239] trial: 33, train_loss: 0.660193, test loss: 2.548271, bias2: 0.4186248779296875, variance: 2.1296463012695312\n",
      "Train size: [400] hidden size: [239] trial: 34, train_loss: 0.658985, test loss: 2.542901, bias2: 0.4178194999694824, variance: 2.1250813007354736\n",
      "Train size: [400] hidden size: [239] trial: 35, train_loss: 0.657870, test loss: 2.535432, bias2: 0.41412901878356934, variance: 2.121302604675293\n",
      "Train size: [400] hidden size: [239] trial: 36, train_loss: 0.657115, test loss: 2.528473, bias2: 0.40968775749206543, variance: 2.1187849044799805\n",
      "Train size: [400] hidden size: [239] trial: 37, train_loss: 0.658620, test loss: 2.528860, bias2: 0.4081449508666992, variance: 2.1207146644592285\n",
      "Train size: [400] hidden size: [239] trial: 38, train_loss: 0.658113, test loss: 2.525171, bias2: 0.4087643623352051, variance: 2.1164064407348633\n",
      "Train size: [400] hidden size: [239] trial: 39, train_loss: 0.656918, test loss: 2.524987, bias2: 0.4070706367492676, variance: 2.1179163455963135\n",
      "Train size: [400] hidden size: [239] trial: 40, train_loss: 0.658135, test loss: 2.532475, bias2: 0.4042322635650635, variance: 2.128242254257202\n",
      "Train size: [400] hidden size: [239] trial: 41, train_loss: 0.657986, test loss: 2.532433, bias2: 0.4050273895263672, variance: 2.1274056434631348\n",
      "Train size: [400] hidden size: [239] trial: 42, train_loss: 0.656478, test loss: 2.522501, bias2: 0.4060094356536865, variance: 2.1164915561676025\n",
      "Train size: [400] hidden size: [239] trial: 43, train_loss: 0.658242, test loss: 2.517617, bias2: 0.40532398223876953, variance: 2.112293004989624\n",
      "Train size: [400] hidden size: [239] trial: 44, train_loss: 0.659495, test loss: 2.509823, bias2: 0.40418338775634766, variance: 2.1056392192840576\n",
      "Train size: [400] hidden size: [239] trial: 45, train_loss: 0.656954, test loss: 2.509286, bias2: 0.40517735481262207, variance: 2.1041085720062256\n",
      "Train size: [400] hidden size: [239] trial: 46, train_loss: 0.658852, test loss: 2.503350, bias2: 0.4043548107147217, variance: 2.0989952087402344\n",
      "Train size: [400] hidden size: [239] trial: 47, train_loss: 0.657866, test loss: 2.498261, bias2: 0.4023568630218506, variance: 2.095904588699341\n",
      "Train size: [400] hidden size: [239] trial: 48, train_loss: 0.658066, test loss: 2.497097, bias2: 0.40097713470458984, variance: 2.0961198806762695\n",
      "Train size: [400] hidden size: [239] trial: 49, train_loss: 0.657372, test loss: 2.495416, bias2: 0.40028953552246094, variance: 2.0951268672943115\n",
      "##################################################\n",
      "Train size: [400] hidden size: [275] trial: 0, train_loss: 0.599972, test loss: 2.906953, bias2: 2.9069535732269287, variance: -1.5570191802538602e-09\n",
      "Train size: [400] hidden size: [275] trial: 1, train_loss: 0.518193, test loss: 3.002569, bias2: 1.57830810546875, variance: 1.4242606163024902\n",
      "Train size: [400] hidden size: [275] trial: 2, train_loss: 0.515317, test loss: 2.836730, bias2: 1.135693073272705, variance: 1.7010366916656494\n",
      "Train size: [400] hidden size: [275] trial: 3, train_loss: 0.487830, test loss: 2.845311, bias2: 0.904956579208374, variance: 1.940354347229004\n",
      "Train size: [400] hidden size: [275] trial: 4, train_loss: 0.495944, test loss: 2.782745, bias2: 0.7630770206451416, variance: 2.0196681022644043\n",
      "Train size: [400] hidden size: [275] trial: 5, train_loss: 0.484934, test loss: 2.777948, bias2: 0.7004706859588623, variance: 2.077477216720581\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [275] trial: 6, train_loss: 0.486066, test loss: 2.823229, bias2: 0.6420090198516846, variance: 2.1812195777893066\n",
      "Train size: [400] hidden size: [275] trial: 7, train_loss: 0.490064, test loss: 2.784040, bias2: 0.6069176197052002, variance: 2.1771225929260254\n",
      "Train size: [400] hidden size: [275] trial: 8, train_loss: 0.503939, test loss: 2.754412, bias2: 0.572758674621582, variance: 2.1816537380218506\n",
      "Train size: [400] hidden size: [275] trial: 9, train_loss: 0.508145, test loss: 2.804208, bias2: 0.5406782627105713, variance: 2.2635297775268555\n",
      "Train size: [400] hidden size: [275] trial: 10, train_loss: 0.498223, test loss: 2.793415, bias2: 0.5054733753204346, variance: 2.2879421710968018\n",
      "Train size: [400] hidden size: [275] trial: 11, train_loss: 0.495899, test loss: 2.785490, bias2: 0.48180150985717773, variance: 2.3036887645721436\n",
      "Train size: [400] hidden size: [275] trial: 12, train_loss: 0.490205, test loss: 2.775111, bias2: 0.46442747116088867, variance: 2.310683488845825\n",
      "Train size: [400] hidden size: [275] trial: 13, train_loss: 0.487258, test loss: 2.777740, bias2: 0.45088815689086914, variance: 2.3268516063690186\n",
      "Train size: [400] hidden size: [275] trial: 14, train_loss: 0.490534, test loss: 2.776202, bias2: 0.4348766803741455, variance: 2.3413257598876953\n",
      "Train size: [400] hidden size: [275] trial: 15, train_loss: 0.486887, test loss: 2.763117, bias2: 0.4225926399230957, variance: 2.3405239582061768\n",
      "Train size: [400] hidden size: [275] trial: 16, train_loss: 0.486975, test loss: 2.804536, bias2: 0.41554927825927734, variance: 2.388986587524414\n",
      "Train size: [400] hidden size: [275] trial: 17, train_loss: 0.486462, test loss: 2.820353, bias2: 0.4043574333190918, variance: 2.4159960746765137\n",
      "Train size: [400] hidden size: [275] trial: 18, train_loss: 0.487795, test loss: 2.824439, bias2: 0.3955223560333252, variance: 2.4289169311523438\n",
      "Train size: [400] hidden size: [275] trial: 19, train_loss: 0.487784, test loss: 2.839530, bias2: 0.3856055736541748, variance: 2.4539244174957275\n",
      "Train size: [400] hidden size: [275] trial: 20, train_loss: 0.487123, test loss: 2.847036, bias2: 0.38154077529907227, variance: 2.4654951095581055\n",
      "Train size: [400] hidden size: [275] trial: 21, train_loss: 0.486637, test loss: 2.864069, bias2: 0.3772749900817871, variance: 2.4867935180664062\n",
      "Train size: [400] hidden size: [275] trial: 22, train_loss: 0.487608, test loss: 2.870159, bias2: 0.364865779876709, variance: 2.5052928924560547\n",
      "Train size: [400] hidden size: [275] trial: 23, train_loss: 0.490384, test loss: 2.863571, bias2: 0.36399340629577637, variance: 2.499577760696411\n",
      "Train size: [400] hidden size: [275] trial: 24, train_loss: 0.489000, test loss: 2.873118, bias2: 0.3620917797088623, variance: 2.511026620864868\n",
      "Train size: [400] hidden size: [275] trial: 25, train_loss: 0.488741, test loss: 2.903124, bias2: 0.3647878170013428, variance: 2.5383360385894775\n",
      "Train size: [400] hidden size: [275] trial: 26, train_loss: 0.488505, test loss: 2.898306, bias2: 0.35862255096435547, variance: 2.5396833419799805\n",
      "Train size: [400] hidden size: [275] trial: 27, train_loss: 0.492234, test loss: 2.898285, bias2: 0.35938262939453125, variance: 2.538902521133423\n",
      "Train size: [400] hidden size: [275] trial: 28, train_loss: 0.491975, test loss: 2.882471, bias2: 0.3566908836364746, variance: 2.5257797241210938\n",
      "Train size: [400] hidden size: [275] trial: 29, train_loss: 0.491535, test loss: 2.885973, bias2: 0.3525547981262207, variance: 2.5334179401397705\n",
      "Train size: [400] hidden size: [275] trial: 30, train_loss: 0.492467, test loss: 2.890489, bias2: 0.3536336421966553, variance: 2.5368549823760986\n",
      "Train size: [400] hidden size: [275] trial: 31, train_loss: 0.493833, test loss: 2.908143, bias2: 0.3546562194824219, variance: 2.5534868240356445\n",
      "Train size: [400] hidden size: [275] trial: 32, train_loss: 0.492763, test loss: 2.917707, bias2: 0.35378432273864746, variance: 2.563922166824341\n",
      "Train size: [400] hidden size: [275] trial: 33, train_loss: 0.491547, test loss: 2.939880, bias2: 0.3512423038482666, variance: 2.5886378288269043\n",
      "Train size: [400] hidden size: [275] trial: 34, train_loss: 0.490168, test loss: 2.940155, bias2: 0.3519864082336426, variance: 2.5881683826446533\n",
      "Train size: [400] hidden size: [275] trial: 35, train_loss: 0.490219, test loss: 2.946338, bias2: 0.3498106002807617, variance: 2.596527338027954\n",
      "Train size: [400] hidden size: [275] trial: 36, train_loss: 0.489201, test loss: 2.949041, bias2: 0.3497326374053955, variance: 2.599308729171753\n",
      "Train size: [400] hidden size: [275] trial: 37, train_loss: 0.491466, test loss: 2.937159, bias2: 0.34819698333740234, variance: 2.5889623165130615\n",
      "Train size: [400] hidden size: [275] trial: 38, train_loss: 0.491398, test loss: 2.940127, bias2: 0.3487832546234131, variance: 2.591344118118286\n",
      "Train size: [400] hidden size: [275] trial: 39, train_loss: 0.492389, test loss: 2.947679, bias2: 0.34675145149230957, variance: 2.6009280681610107\n",
      "Train size: [400] hidden size: [275] trial: 40, train_loss: 0.493005, test loss: 2.947874, bias2: 0.3495011329650879, variance: 2.5983726978302\n",
      "Train size: [400] hidden size: [275] trial: 41, train_loss: 0.494498, test loss: 2.950177, bias2: 0.3478984832763672, variance: 2.6022789478302\n",
      "Train size: [400] hidden size: [275] trial: 42, train_loss: 0.493198, test loss: 2.930710, bias2: 0.3444085121154785, variance: 2.5863020420074463\n",
      "Train size: [400] hidden size: [275] trial: 43, train_loss: 0.494003, test loss: 2.932890, bias2: 0.34340476989746094, variance: 2.5894851684570312\n",
      "Train size: [400] hidden size: [275] trial: 44, train_loss: 0.494724, test loss: 2.928948, bias2: 0.34420084953308105, variance: 2.584746837615967\n",
      "Train size: [400] hidden size: [275] trial: 45, train_loss: 0.495203, test loss: 2.930748, bias2: 0.33996152877807617, variance: 2.590786933898926\n",
      "Train size: [400] hidden size: [275] trial: 46, train_loss: 0.495525, test loss: 2.938184, bias2: 0.3378441333770752, variance: 2.6003401279449463\n",
      "Train size: [400] hidden size: [275] trial: 47, train_loss: 0.498341, test loss: 2.951002, bias2: 0.3386557102203369, variance: 2.6123459339141846\n",
      "Train size: [400] hidden size: [275] trial: 48, train_loss: 0.496964, test loss: 2.941577, bias2: 0.3352391719818115, variance: 2.6063382625579834\n",
      "Train size: [400] hidden size: [275] trial: 49, train_loss: 0.495780, test loss: 2.939077, bias2: 0.3360934257507324, variance: 2.6029837131500244\n",
      "##################################################\n",
      "Train size: [400] hidden size: [316] trial: 0, train_loss: 0.334680, test loss: 2.810740, bias2: 2.810739517211914, variance: 1.5570191802538602e-09\n",
      "Train size: [400] hidden size: [316] trial: 1, train_loss: 0.335050, test loss: 2.953221, bias2: 1.5531352758407593, variance: 1.4000855684280396\n",
      "Train size: [400] hidden size: [316] trial: 2, train_loss: 0.345376, test loss: 3.461208, bias2: 1.2981231212615967, variance: 2.1630847454071045\n",
      "Train size: [400] hidden size: [316] trial: 3, train_loss: 0.344323, test loss: 3.370763, bias2: 1.0504724979400635, variance: 2.3202908039093018\n",
      "Train size: [400] hidden size: [316] trial: 4, train_loss: 0.360852, test loss: 3.366904, bias2: 0.9029757976531982, variance: 2.463927745819092\n",
      "Train size: [400] hidden size: [316] trial: 5, train_loss: 0.363154, test loss: 3.297936, bias2: 0.7773451805114746, variance: 2.520590305328369\n",
      "Train size: [400] hidden size: [316] trial: 6, train_loss: 0.374694, test loss: 3.182846, bias2: 0.6636795997619629, variance: 2.5191667079925537\n",
      "Train size: [400] hidden size: [316] trial: 7, train_loss: 0.371981, test loss: 3.147690, bias2: 0.6012392044067383, variance: 2.5464508533477783\n",
      "Train size: [400] hidden size: [316] trial: 8, train_loss: 0.363122, test loss: 3.121591, bias2: 0.556624174118042, variance: 2.5649664402008057\n",
      "Train size: [400] hidden size: [316] trial: 9, train_loss: 0.359141, test loss: 3.070761, bias2: 0.538649320602417, variance: 2.532111644744873\n",
      "Train size: [400] hidden size: [316] trial: 10, train_loss: 0.358046, test loss: 3.063072, bias2: 0.4990506172180176, variance: 2.564021348953247\n",
      "Train size: [400] hidden size: [316] trial: 11, train_loss: 0.363553, test loss: 3.129047, bias2: 0.48415207862854004, variance: 2.644895315170288\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [316] trial: 12, train_loss: 0.361443, test loss: 3.127636, bias2: 0.4718031883239746, variance: 2.6558330059051514\n",
      "Train size: [400] hidden size: [316] trial: 13, train_loss: 0.365468, test loss: 3.132292, bias2: 0.44612908363342285, variance: 2.6861634254455566\n",
      "Train size: [400] hidden size: [316] trial: 14, train_loss: 0.362110, test loss: 3.174862, bias2: 0.4348788261413574, variance: 2.739983558654785\n",
      "Train size: [400] hidden size: [316] trial: 15, train_loss: 0.362496, test loss: 3.184017, bias2: 0.4188704490661621, variance: 2.7651467323303223\n",
      "Train size: [400] hidden size: [316] trial: 16, train_loss: 0.359723, test loss: 3.147011, bias2: 0.40603184700012207, variance: 2.7409791946411133\n",
      "Train size: [400] hidden size: [316] trial: 17, train_loss: 0.362800, test loss: 3.188728, bias2: 0.39676904678344727, variance: 2.7919585704803467\n",
      "Train size: [400] hidden size: [316] trial: 18, train_loss: 0.362904, test loss: 3.219570, bias2: 0.39186596870422363, variance: 2.8277037143707275\n",
      "Train size: [400] hidden size: [316] trial: 19, train_loss: 0.361546, test loss: 3.224557, bias2: 0.38663625717163086, variance: 2.8379204273223877\n",
      "Train size: [400] hidden size: [316] trial: 20, train_loss: 0.358742, test loss: 3.220829, bias2: 0.3714561462402344, variance: 2.8493728637695312\n",
      "Train size: [400] hidden size: [316] trial: 21, train_loss: 0.361451, test loss: 3.261027, bias2: 0.35721564292907715, variance: 2.903811454772949\n",
      "Train size: [400] hidden size: [316] trial: 22, train_loss: 0.360157, test loss: 3.259188, bias2: 0.3543558120727539, variance: 2.904831886291504\n",
      "Train size: [400] hidden size: [316] trial: 23, train_loss: 0.362535, test loss: 3.258905, bias2: 0.3565361499786377, variance: 2.9023690223693848\n",
      "Train size: [400] hidden size: [316] trial: 24, train_loss: 0.364831, test loss: 3.276725, bias2: 0.3576469421386719, variance: 2.9190776348114014\n",
      "Train size: [400] hidden size: [316] trial: 25, train_loss: 0.364229, test loss: 3.286424, bias2: 0.35773682594299316, variance: 2.92868709564209\n",
      "Train size: [400] hidden size: [316] trial: 26, train_loss: 0.362904, test loss: 3.282384, bias2: 0.353377103805542, variance: 2.9290072917938232\n",
      "Train size: [400] hidden size: [316] trial: 27, train_loss: 0.362391, test loss: 3.293206, bias2: 0.3519914150238037, variance: 2.9412143230438232\n",
      "Train size: [400] hidden size: [316] trial: 28, train_loss: 0.361571, test loss: 3.286145, bias2: 0.3460578918457031, variance: 2.940086841583252\n",
      "Train size: [400] hidden size: [316] trial: 29, train_loss: 0.362139, test loss: 3.279464, bias2: 0.3491206169128418, variance: 2.9303436279296875\n",
      "Train size: [400] hidden size: [316] trial: 30, train_loss: 0.361094, test loss: 3.283078, bias2: 0.34631776809692383, variance: 2.9367599487304688\n",
      "Train size: [400] hidden size: [316] trial: 31, train_loss: 0.362738, test loss: 3.289547, bias2: 0.3445549011230469, variance: 2.9449925422668457\n",
      "Train size: [400] hidden size: [316] trial: 32, train_loss: 0.362238, test loss: 3.281902, bias2: 0.3447747230529785, variance: 2.937126874923706\n",
      "Train size: [400] hidden size: [316] trial: 33, train_loss: 0.363509, test loss: 3.276925, bias2: 0.3433566093444824, variance: 2.9335687160491943\n",
      "Train size: [400] hidden size: [316] trial: 34, train_loss: 0.364552, test loss: 3.263449, bias2: 0.33829617500305176, variance: 2.9251527786254883\n",
      "Train size: [400] hidden size: [316] trial: 35, train_loss: 0.364430, test loss: 3.267264, bias2: 0.3360755443572998, variance: 2.9311888217926025\n",
      "Train size: [400] hidden size: [316] trial: 36, train_loss: 0.363944, test loss: 3.270682, bias2: 0.33786582946777344, variance: 2.9328157901763916\n",
      "Train size: [400] hidden size: [316] trial: 37, train_loss: 0.364279, test loss: 3.278851, bias2: 0.33505988121032715, variance: 2.943791151046753\n",
      "Train size: [400] hidden size: [316] trial: 38, train_loss: 0.361468, test loss: 3.281043, bias2: 0.3340320587158203, variance: 2.9470105171203613\n",
      "Train size: [400] hidden size: [316] trial: 39, train_loss: 0.360663, test loss: 3.280538, bias2: 0.3331599235534668, variance: 2.947377920150757\n",
      "Train size: [400] hidden size: [316] trial: 40, train_loss: 0.361844, test loss: 3.280915, bias2: 0.33155345916748047, variance: 2.949361562728882\n",
      "Train size: [400] hidden size: [316] trial: 41, train_loss: 0.364530, test loss: 3.290159, bias2: 0.3297426700592041, variance: 2.960416793823242\n",
      "Train size: [400] hidden size: [316] trial: 42, train_loss: 0.365079, test loss: 3.287317, bias2: 0.32892656326293945, variance: 2.958390474319458\n",
      "Train size: [400] hidden size: [316] trial: 43, train_loss: 0.363658, test loss: 3.272425, bias2: 0.32425570487976074, variance: 2.948168992996216\n",
      "Train size: [400] hidden size: [316] trial: 44, train_loss: 0.365579, test loss: 3.279501, bias2: 0.3264038562774658, variance: 2.953096866607666\n",
      "Train size: [400] hidden size: [316] trial: 45, train_loss: 0.364144, test loss: 3.281128, bias2: 0.3219611644744873, variance: 2.9591667652130127\n",
      "Train size: [400] hidden size: [316] trial: 46, train_loss: 0.364286, test loss: 3.273872, bias2: 0.32088661193847656, variance: 2.9529855251312256\n",
      "Train size: [400] hidden size: [316] trial: 47, train_loss: 0.363515, test loss: 3.276853, bias2: 0.3204307556152344, variance: 2.9564220905303955\n",
      "Train size: [400] hidden size: [316] trial: 48, train_loss: 0.362478, test loss: 3.278834, bias2: 0.31567955017089844, variance: 2.9631540775299072\n",
      "Train size: [400] hidden size: [316] trial: 49, train_loss: 0.361521, test loss: 3.280741, bias2: 0.3171384334564209, variance: 2.9636030197143555\n",
      "##################################################\n",
      "Train size: [400] hidden size: [364] trial: 0, train_loss: 0.234680, test loss: 3.270271, bias2: 3.270270824432373, variance: -1.5570192246627812e-08\n",
      "Train size: [400] hidden size: [364] trial: 1, train_loss: 0.227863, test loss: 3.205853, bias2: 1.7371375560760498, variance: 1.4687154293060303\n",
      "Train size: [400] hidden size: [364] trial: 2, train_loss: 0.224720, test loss: 3.329269, bias2: 1.243685007095337, variance: 2.0855836868286133\n",
      "Train size: [400] hidden size: [364] trial: 3, train_loss: 0.206664, test loss: 3.305127, bias2: 0.9844584465026855, variance: 2.320668935775757\n",
      "Train size: [400] hidden size: [364] trial: 4, train_loss: 0.215634, test loss: 3.372072, bias2: 0.8341529369354248, variance: 2.537919521331787\n",
      "Train size: [400] hidden size: [364] trial: 5, train_loss: 0.213822, test loss: 3.354765, bias2: 0.7222428321838379, variance: 2.6325221061706543\n",
      "Train size: [400] hidden size: [364] trial: 6, train_loss: 0.214203, test loss: 3.355859, bias2: 0.6625511646270752, variance: 2.6933083534240723\n",
      "Train size: [400] hidden size: [364] trial: 7, train_loss: 0.215320, test loss: 3.428467, bias2: 0.62778639793396, variance: 2.800680637359619\n",
      "Train size: [400] hidden size: [364] trial: 8, train_loss: 0.224194, test loss: 3.431185, bias2: 0.5677351951599121, variance: 2.863450050354004\n",
      "Train size: [400] hidden size: [364] trial: 9, train_loss: 0.223692, test loss: 3.465889, bias2: 0.5402412414550781, variance: 2.925647258758545\n",
      "Train size: [400] hidden size: [364] trial: 10, train_loss: 0.224983, test loss: 3.472641, bias2: 0.5143835544586182, variance: 2.9582579135894775\n",
      "Train size: [400] hidden size: [364] trial: 11, train_loss: 0.223588, test loss: 3.437270, bias2: 0.4944801330566406, variance: 2.9427902698516846\n",
      "Train size: [400] hidden size: [364] trial: 12, train_loss: 0.223665, test loss: 3.433573, bias2: 0.4672837257385254, variance: 2.966289520263672\n",
      "Train size: [400] hidden size: [364] trial: 13, train_loss: 0.224249, test loss: 3.430971, bias2: 0.4544026851654053, variance: 2.9765679836273193\n",
      "Train size: [400] hidden size: [364] trial: 14, train_loss: 0.225782, test loss: 3.411987, bias2: 0.43862175941467285, variance: 2.973365306854248\n",
      "Train size: [400] hidden size: [364] trial: 15, train_loss: 0.226559, test loss: 3.426789, bias2: 0.42743921279907227, variance: 2.999350070953369\n",
      "Train size: [400] hidden size: [364] trial: 16, train_loss: 0.225475, test loss: 3.404806, bias2: 0.4172639846801758, variance: 2.987542152404785\n",
      "Train size: [400] hidden size: [364] trial: 17, train_loss: 0.226926, test loss: 3.381572, bias2: 0.4074983596801758, variance: 2.9740734100341797\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [364] trial: 18, train_loss: 0.226874, test loss: 3.365653, bias2: 0.3917396068572998, variance: 2.9739136695861816\n",
      "Train size: [400] hidden size: [364] trial: 19, train_loss: 0.224826, test loss: 3.370669, bias2: 0.3841986656188965, variance: 2.9864704608917236\n",
      "Train size: [400] hidden size: [364] trial: 20, train_loss: 0.224188, test loss: 3.397306, bias2: 0.38297414779663086, variance: 3.0143320560455322\n",
      "Train size: [400] hidden size: [364] trial: 21, train_loss: 0.225259, test loss: 3.410842, bias2: 0.373516321182251, variance: 3.037325620651245\n",
      "Train size: [400] hidden size: [364] trial: 22, train_loss: 0.226870, test loss: 3.430160, bias2: 0.36895203590393066, variance: 3.0612082481384277\n",
      "Train size: [400] hidden size: [364] trial: 23, train_loss: 0.225660, test loss: 3.443666, bias2: 0.3619098663330078, variance: 3.081756114959717\n",
      "Train size: [400] hidden size: [364] trial: 24, train_loss: 0.225114, test loss: 3.433495, bias2: 0.3597378730773926, variance: 3.0737571716308594\n",
      "Train size: [400] hidden size: [364] trial: 25, train_loss: 0.224455, test loss: 3.426183, bias2: 0.35031628608703613, variance: 3.075866222381592\n",
      "Train size: [400] hidden size: [364] trial: 26, train_loss: 0.223839, test loss: 3.416442, bias2: 0.346419095993042, variance: 3.0700225830078125\n",
      "Train size: [400] hidden size: [364] trial: 27, train_loss: 0.222093, test loss: 3.427415, bias2: 0.34215426445007324, variance: 3.0852603912353516\n",
      "Train size: [400] hidden size: [364] trial: 28, train_loss: 0.223176, test loss: 3.435305, bias2: 0.34290170669555664, variance: 3.0924031734466553\n",
      "Train size: [400] hidden size: [364] trial: 29, train_loss: 0.222511, test loss: 3.414124, bias2: 0.34026169776916504, variance: 3.0738625526428223\n",
      "Train size: [400] hidden size: [364] trial: 30, train_loss: 0.224190, test loss: 3.406429, bias2: 0.3350367546081543, variance: 3.071392297744751\n",
      "Train size: [400] hidden size: [364] trial: 31, train_loss: 0.223305, test loss: 3.398990, bias2: 0.33441686630249023, variance: 3.0645735263824463\n",
      "Train size: [400] hidden size: [364] trial: 32, train_loss: 0.223239, test loss: 3.406270, bias2: 0.32835841178894043, variance: 3.077911376953125\n",
      "Train size: [400] hidden size: [364] trial: 33, train_loss: 0.222148, test loss: 3.409391, bias2: 0.31704211235046387, variance: 3.092348575592041\n",
      "Train size: [400] hidden size: [364] trial: 34, train_loss: 0.222242, test loss: 3.415164, bias2: 0.3172757625579834, variance: 3.097888469696045\n",
      "Train size: [400] hidden size: [364] trial: 35, train_loss: 0.221880, test loss: 3.418062, bias2: 0.31475830078125, variance: 3.1033031940460205\n",
      "Train size: [400] hidden size: [364] trial: 36, train_loss: 0.221998, test loss: 3.414639, bias2: 0.3147578239440918, variance: 3.099881172180176\n",
      "Train size: [400] hidden size: [364] trial: 37, train_loss: 0.221442, test loss: 3.418700, bias2: 0.3147742748260498, variance: 3.1039254665374756\n",
      "Train size: [400] hidden size: [364] trial: 38, train_loss: 0.221562, test loss: 3.411853, bias2: 0.3107733726501465, variance: 3.101079225540161\n",
      "Train size: [400] hidden size: [364] trial: 39, train_loss: 0.222129, test loss: 3.419076, bias2: 0.3079347610473633, variance: 3.1111409664154053\n",
      "Train size: [400] hidden size: [364] trial: 40, train_loss: 0.222084, test loss: 3.430282, bias2: 0.30484938621520996, variance: 3.125432252883911\n",
      "Train size: [400] hidden size: [364] trial: 41, train_loss: 0.220402, test loss: 3.423269, bias2: 0.3013603687286377, variance: 3.121908664703369\n",
      "Train size: [400] hidden size: [364] trial: 42, train_loss: 0.220444, test loss: 3.434256, bias2: 0.29993367195129395, variance: 3.13432240486145\n",
      "Train size: [400] hidden size: [364] trial: 43, train_loss: 0.221423, test loss: 3.433415, bias2: 0.29939723014831543, variance: 3.1340179443359375\n",
      "Train size: [400] hidden size: [364] trial: 44, train_loss: 0.221830, test loss: 3.432259, bias2: 0.29598474502563477, variance: 3.1362743377685547\n",
      "Train size: [400] hidden size: [364] trial: 45, train_loss: 0.222151, test loss: 3.434291, bias2: 0.2936124801635742, variance: 3.1406784057617188\n",
      "Train size: [400] hidden size: [364] trial: 46, train_loss: 0.221575, test loss: 3.428988, bias2: 0.2920377254486084, variance: 3.1369502544403076\n",
      "Train size: [400] hidden size: [364] trial: 47, train_loss: 0.221585, test loss: 3.428469, bias2: 0.29152750968933105, variance: 3.136941432952881\n",
      "Train size: [400] hidden size: [364] trial: 48, train_loss: 0.221433, test loss: 3.422958, bias2: 0.2904677391052246, variance: 3.1324901580810547\n",
      "Train size: [400] hidden size: [364] trial: 49, train_loss: 0.220761, test loss: 3.412171, bias2: 0.28989291191101074, variance: 3.1222782135009766\n",
      "##################################################\n",
      "Train size: [400] hidden size: [419] trial: 0, train_loss: 0.154045, test loss: 2.974441, bias2: 2.974440813064575, variance: 3.1140383605077204e-09\n",
      "Train size: [400] hidden size: [419] trial: 1, train_loss: 0.131508, test loss: 2.936563, bias2: 1.5291749238967896, variance: 1.4073885679244995\n",
      "Train size: [400] hidden size: [419] trial: 2, train_loss: 0.130612, test loss: 2.917138, bias2: 1.1125929355621338, variance: 1.8045446872711182\n",
      "Train size: [400] hidden size: [419] trial: 3, train_loss: 0.129774, test loss: 2.985825, bias2: 0.8423726558685303, variance: 2.1434524059295654\n",
      "Train size: [400] hidden size: [419] trial: 4, train_loss: 0.129168, test loss: 3.118272, bias2: 0.7322192192077637, variance: 2.3860528469085693\n",
      "Train size: [400] hidden size: [419] trial: 5, train_loss: 0.133973, test loss: 3.273942, bias2: 0.663292407989502, variance: 2.610649347305298\n",
      "Train size: [400] hidden size: [419] trial: 6, train_loss: 0.126439, test loss: 3.207474, bias2: 0.5823047161102295, variance: 2.625169038772583\n",
      "Train size: [400] hidden size: [419] trial: 7, train_loss: 0.130072, test loss: 3.232953, bias2: 0.5229165554046631, variance: 2.7100367546081543\n",
      "Train size: [400] hidden size: [419] trial: 8, train_loss: 0.130268, test loss: 3.253272, bias2: 0.48670244216918945, variance: 2.7665698528289795\n",
      "Train size: [400] hidden size: [419] trial: 9, train_loss: 0.129760, test loss: 3.242463, bias2: 0.4588024616241455, variance: 2.783660888671875\n",
      "Train size: [400] hidden size: [419] trial: 10, train_loss: 0.132130, test loss: 3.266314, bias2: 0.4390442371368408, variance: 2.8272697925567627\n",
      "Train size: [400] hidden size: [419] trial: 11, train_loss: 0.131788, test loss: 3.244146, bias2: 0.400911808013916, variance: 2.8432345390319824\n",
      "Train size: [400] hidden size: [419] trial: 12, train_loss: 0.132061, test loss: 3.238937, bias2: 0.3841249942779541, variance: 2.854811906814575\n",
      "Train size: [400] hidden size: [419] trial: 13, train_loss: 0.132006, test loss: 3.265242, bias2: 0.3682880401611328, variance: 2.896954298019409\n",
      "Train size: [400] hidden size: [419] trial: 14, train_loss: 0.131269, test loss: 3.286112, bias2: 0.34973931312561035, variance: 2.936372756958008\n",
      "Train size: [400] hidden size: [419] trial: 15, train_loss: 0.134823, test loss: 3.296464, bias2: 0.353055477142334, variance: 2.943408727645874\n",
      "Train size: [400] hidden size: [419] trial: 16, train_loss: 0.133051, test loss: 3.291322, bias2: 0.3462865352630615, variance: 2.945034980773926\n",
      "Train size: [400] hidden size: [419] trial: 17, train_loss: 0.133424, test loss: 3.302813, bias2: 0.3332505226135254, variance: 2.96956205368042\n",
      "Train size: [400] hidden size: [419] trial: 18, train_loss: 0.132854, test loss: 3.285596, bias2: 0.32477355003356934, variance: 2.960822582244873\n",
      "Train size: [400] hidden size: [419] trial: 19, train_loss: 0.132135, test loss: 3.296030, bias2: 0.31929659843444824, variance: 2.976733684539795\n",
      "Train size: [400] hidden size: [419] trial: 20, train_loss: 0.132537, test loss: 3.316818, bias2: 0.31995177268981934, variance: 2.99686598777771\n",
      "Train size: [400] hidden size: [419] trial: 21, train_loss: 0.133897, test loss: 3.314894, bias2: 0.3147616386413574, variance: 3.0001320838928223\n",
      "Train size: [400] hidden size: [419] trial: 22, train_loss: 0.135498, test loss: 3.320833, bias2: 0.30801844596862793, variance: 3.01281476020813\n",
      "Train size: [400] hidden size: [419] trial: 23, train_loss: 0.135032, test loss: 3.324944, bias2: 0.3037233352661133, variance: 3.021221160888672\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [419] trial: 24, train_loss: 0.135627, test loss: 3.311428, bias2: 0.2915008068084717, variance: 3.0199272632598877\n",
      "Train size: [400] hidden size: [419] trial: 25, train_loss: 0.134083, test loss: 3.293689, bias2: 0.2872762680053711, variance: 3.0064122676849365\n",
      "Train size: [400] hidden size: [419] trial: 26, train_loss: 0.133568, test loss: 3.280797, bias2: 0.2888009548187256, variance: 2.9919962882995605\n",
      "Train size: [400] hidden size: [419] trial: 27, train_loss: 0.132975, test loss: 3.274678, bias2: 0.28044772148132324, variance: 2.994230270385742\n",
      "Train size: [400] hidden size: [419] trial: 28, train_loss: 0.132882, test loss: 3.272752, bias2: 0.27609753608703613, variance: 2.9966542720794678\n",
      "Train size: [400] hidden size: [419] trial: 29, train_loss: 0.132243, test loss: 3.257576, bias2: 0.27468037605285645, variance: 2.9828953742980957\n",
      "Train size: [400] hidden size: [419] trial: 30, train_loss: 0.132552, test loss: 3.265968, bias2: 0.26955461502075195, variance: 2.996412992477417\n",
      "Train size: [400] hidden size: [419] trial: 31, train_loss: 0.132520, test loss: 3.250491, bias2: 0.2612273693084717, variance: 2.9892640113830566\n",
      "Train size: [400] hidden size: [419] trial: 32, train_loss: 0.132672, test loss: 3.243798, bias2: 0.25879716873168945, variance: 2.9850006103515625\n",
      "Train size: [400] hidden size: [419] trial: 33, train_loss: 0.132895, test loss: 3.236892, bias2: 0.2575345039367676, variance: 2.979357957839966\n",
      "Train size: [400] hidden size: [419] trial: 34, train_loss: 0.132501, test loss: 3.236121, bias2: 0.2567744255065918, variance: 2.97934627532959\n",
      "Train size: [400] hidden size: [419] trial: 35, train_loss: 0.132519, test loss: 3.252989, bias2: 0.2510528564453125, variance: 3.001936674118042\n",
      "Train size: [400] hidden size: [419] trial: 36, train_loss: 0.132152, test loss: 3.241862, bias2: 0.24975824356079102, variance: 2.9921042919158936\n",
      "Train size: [400] hidden size: [419] trial: 37, train_loss: 0.131625, test loss: 3.239922, bias2: 0.25061464309692383, variance: 2.989307165145874\n",
      "Train size: [400] hidden size: [419] trial: 38, train_loss: 0.131332, test loss: 3.230315, bias2: 0.24787163734436035, variance: 2.9824438095092773\n",
      "Train size: [400] hidden size: [419] trial: 39, train_loss: 0.131103, test loss: 3.234888, bias2: 0.24721908569335938, variance: 2.9876692295074463\n",
      "Train size: [400] hidden size: [419] trial: 40, train_loss: 0.131394, test loss: 3.242025, bias2: 0.24437379837036133, variance: 2.9976513385772705\n",
      "Train size: [400] hidden size: [419] trial: 41, train_loss: 0.131321, test loss: 3.237216, bias2: 0.2416398525238037, variance: 2.9955759048461914\n",
      "Train size: [400] hidden size: [419] trial: 42, train_loss: 0.130128, test loss: 3.230968, bias2: 0.23676586151123047, variance: 2.994201898574829\n",
      "Train size: [400] hidden size: [419] trial: 43, train_loss: 0.129690, test loss: 3.234510, bias2: 0.23910069465637207, variance: 2.9954094886779785\n",
      "Train size: [400] hidden size: [419] trial: 44, train_loss: 0.129869, test loss: 3.243027, bias2: 0.2372446060180664, variance: 3.0057826042175293\n",
      "Train size: [400] hidden size: [419] trial: 45, train_loss: 0.129259, test loss: 3.232761, bias2: 0.2352757453918457, variance: 2.997485637664795\n",
      "Train size: [400] hidden size: [419] trial: 46, train_loss: 0.129005, test loss: 3.236232, bias2: 0.23628687858581543, variance: 2.9999449253082275\n",
      "Train size: [400] hidden size: [419] trial: 47, train_loss: 0.128855, test loss: 3.232612, bias2: 0.23656606674194336, variance: 2.9960460662841797\n",
      "Train size: [400] hidden size: [419] trial: 48, train_loss: 0.129184, test loss: 3.229867, bias2: 0.23688817024230957, variance: 2.992979049682617\n",
      "Train size: [400] hidden size: [419] trial: 49, train_loss: 0.129249, test loss: 3.227890, bias2: 0.23456692695617676, variance: 2.9933228492736816\n",
      "##################################################\n",
      "Train size: [400] hidden size: [483] trial: 0, train_loss: 0.055918, test loss: 2.791763, bias2: 2.7917628288269043, variance: 3.269740389555409e-08\n",
      "Train size: [400] hidden size: [483] trial: 1, train_loss: 0.062289, test loss: 2.806959, bias2: 1.6115374565124512, variance: 1.1954209804534912\n",
      "Train size: [400] hidden size: [483] trial: 2, train_loss: 0.071476, test loss: 3.037636, bias2: 1.2328314781188965, variance: 1.8048040866851807\n",
      "Train size: [400] hidden size: [483] trial: 3, train_loss: 0.071136, test loss: 2.900438, bias2: 0.9616444110870361, variance: 1.9387938976287842\n",
      "Train size: [400] hidden size: [483] trial: 4, train_loss: 0.075772, test loss: 2.929349, bias2: 0.7854347229003906, variance: 2.143913984298706\n",
      "Train size: [400] hidden size: [483] trial: 5, train_loss: 0.078599, test loss: 2.997911, bias2: 0.7317991256713867, variance: 2.2661116123199463\n",
      "Train size: [400] hidden size: [483] trial: 6, train_loss: 0.078612, test loss: 2.984682, bias2: 0.6396927833557129, variance: 2.344989061355591\n",
      "Train size: [400] hidden size: [483] trial: 7, train_loss: 0.079083, test loss: 3.011310, bias2: 0.5823025703430176, variance: 2.4290075302124023\n",
      "Train size: [400] hidden size: [483] trial: 8, train_loss: 0.077674, test loss: 2.966597, bias2: 0.5281188488006592, variance: 2.4384782314300537\n",
      "Train size: [400] hidden size: [483] trial: 9, train_loss: 0.076271, test loss: 2.971205, bias2: 0.47889280319213867, variance: 2.4923126697540283\n",
      "Train size: [400] hidden size: [483] trial: 10, train_loss: 0.077440, test loss: 2.987508, bias2: 0.4482142925262451, variance: 2.5392935276031494\n",
      "Train size: [400] hidden size: [483] trial: 11, train_loss: 0.079807, test loss: 2.986290, bias2: 0.41802382469177246, variance: 2.568265676498413\n",
      "Train size: [400] hidden size: [483] trial: 12, train_loss: 0.078995, test loss: 2.983856, bias2: 0.4043731689453125, variance: 2.579482316970825\n",
      "Train size: [400] hidden size: [483] trial: 13, train_loss: 0.078764, test loss: 3.016624, bias2: 0.39846038818359375, variance: 2.6181640625\n",
      "Train size: [400] hidden size: [483] trial: 14, train_loss: 0.080559, test loss: 3.034944, bias2: 0.3874702453613281, variance: 2.6474740505218506\n",
      "Train size: [400] hidden size: [483] trial: 15, train_loss: 0.080228, test loss: 3.035529, bias2: 0.37766432762145996, variance: 2.657864809036255\n",
      "Train size: [400] hidden size: [483] trial: 16, train_loss: 0.080915, test loss: 3.041456, bias2: 0.368849515914917, variance: 2.6726062297821045\n",
      "Train size: [400] hidden size: [483] trial: 17, train_loss: 0.080872, test loss: 3.049570, bias2: 0.35828137397766113, variance: 2.6912882328033447\n",
      "Train size: [400] hidden size: [483] trial: 18, train_loss: 0.081433, test loss: 3.047857, bias2: 0.3477144241333008, variance: 2.7001423835754395\n",
      "Train size: [400] hidden size: [483] trial: 19, train_loss: 0.080770, test loss: 3.043107, bias2: 0.3395528793334961, variance: 2.703554391860962\n",
      "Train size: [400] hidden size: [483] trial: 20, train_loss: 0.080988, test loss: 3.071207, bias2: 0.33866381645202637, variance: 2.7325427532196045\n",
      "Train size: [400] hidden size: [483] trial: 21, train_loss: 0.080161, test loss: 3.043542, bias2: 0.32895708084106445, variance: 2.714585304260254\n",
      "Train size: [400] hidden size: [483] trial: 22, train_loss: 0.080822, test loss: 3.066131, bias2: 0.31872129440307617, variance: 2.7474095821380615\n",
      "Train size: [400] hidden size: [483] trial: 23, train_loss: 0.080572, test loss: 3.054886, bias2: 0.31464624404907227, variance: 2.7402396202087402\n",
      "Train size: [400] hidden size: [483] trial: 24, train_loss: 0.080851, test loss: 3.042319, bias2: 0.31440258026123047, variance: 2.7279160022735596\n",
      "Train size: [400] hidden size: [483] trial: 25, train_loss: 0.080223, test loss: 3.027918, bias2: 0.30513954162597656, variance: 2.722778797149658\n",
      "Train size: [400] hidden size: [483] trial: 26, train_loss: 0.080469, test loss: 3.020399, bias2: 0.299774169921875, variance: 2.7206249237060547\n",
      "Train size: [400] hidden size: [483] trial: 27, train_loss: 0.080406, test loss: 3.025440, bias2: 0.296583890914917, variance: 2.728855848312378\n",
      "Train size: [400] hidden size: [483] trial: 28, train_loss: 0.079872, test loss: 3.019753, bias2: 0.29302096366882324, variance: 2.726731777191162\n",
      "Train size: [400] hidden size: [483] trial: 29, train_loss: 0.079810, test loss: 3.028253, bias2: 0.28952884674072266, variance: 2.7387242317199707\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [483] trial: 30, train_loss: 0.079413, test loss: 3.029775, bias2: 0.2867262363433838, variance: 2.743049144744873\n",
      "Train size: [400] hidden size: [483] trial: 31, train_loss: 0.079788, test loss: 3.024966, bias2: 0.2849605083465576, variance: 2.7400057315826416\n",
      "Train size: [400] hidden size: [483] trial: 32, train_loss: 0.080132, test loss: 3.022670, bias2: 0.28262925148010254, variance: 2.7400410175323486\n",
      "Train size: [400] hidden size: [483] trial: 33, train_loss: 0.080639, test loss: 3.011453, bias2: 0.280503511428833, variance: 2.730949878692627\n",
      "Train size: [400] hidden size: [483] trial: 34, train_loss: 0.081232, test loss: 2.998518, bias2: 0.27483105659484863, variance: 2.723686695098877\n",
      "Train size: [400] hidden size: [483] trial: 35, train_loss: 0.081497, test loss: 2.999240, bias2: 0.2703211307525635, variance: 2.728919267654419\n",
      "Train size: [400] hidden size: [483] trial: 36, train_loss: 0.081437, test loss: 2.995629, bias2: 0.2694542407989502, variance: 2.7261743545532227\n",
      "Train size: [400] hidden size: [483] trial: 37, train_loss: 0.081713, test loss: 2.987990, bias2: 0.2660067081451416, variance: 2.721982955932617\n",
      "Train size: [400] hidden size: [483] trial: 38, train_loss: 0.081620, test loss: 2.988215, bias2: 0.2653391361236572, variance: 2.7228758335113525\n",
      "Train size: [400] hidden size: [483] trial: 39, train_loss: 0.081738, test loss: 2.982559, bias2: 0.26708388328552246, variance: 2.715474843978882\n",
      "Train size: [400] hidden size: [483] trial: 40, train_loss: 0.081941, test loss: 2.983084, bias2: 0.26283955574035645, variance: 2.7202444076538086\n",
      "Train size: [400] hidden size: [483] trial: 41, train_loss: 0.081435, test loss: 2.976265, bias2: 0.2594292163848877, variance: 2.7168359756469727\n",
      "Train size: [400] hidden size: [483] trial: 42, train_loss: 0.081023, test loss: 2.964419, bias2: 0.2593421936035156, variance: 2.7050769329071045\n",
      "Train size: [400] hidden size: [483] trial: 43, train_loss: 0.081472, test loss: 2.965742, bias2: 0.2569711208343506, variance: 2.708771228790283\n",
      "Train size: [400] hidden size: [483] trial: 44, train_loss: 0.081105, test loss: 2.958370, bias2: 0.25565528869628906, variance: 2.7027151584625244\n",
      "Train size: [400] hidden size: [483] trial: 45, train_loss: 0.080902, test loss: 2.963637, bias2: 0.2549912929534912, variance: 2.708645820617676\n",
      "Train size: [400] hidden size: [483] trial: 46, train_loss: 0.080818, test loss: 2.957565, bias2: 0.25269150733947754, variance: 2.7048730850219727\n",
      "Train size: [400] hidden size: [483] trial: 47, train_loss: 0.080560, test loss: 2.957601, bias2: 0.25429558753967285, variance: 2.703305244445801\n",
      "Train size: [400] hidden size: [483] trial: 48, train_loss: 0.080289, test loss: 2.953630, bias2: 0.2510795593261719, variance: 2.702550172805786\n",
      "Train size: [400] hidden size: [483] trial: 49, train_loss: 0.080190, test loss: 2.951494, bias2: 0.2500631809234619, variance: 2.701430559158325\n",
      "##################################################\n",
      "Train size: [400] hidden size: [556] trial: 0, train_loss: 0.037377, test loss: 2.174029, bias2: 2.1740288734436035, variance: -2.1798269855821673e-08\n",
      "Train size: [400] hidden size: [556] trial: 1, train_loss: 0.043129, test loss: 2.362699, bias2: 1.2963488101959229, variance: 1.0663502216339111\n",
      "Train size: [400] hidden size: [556] trial: 2, train_loss: 0.043711, test loss: 2.410032, bias2: 0.9700278043746948, variance: 1.4400044679641724\n",
      "Train size: [400] hidden size: [556] trial: 3, train_loss: 0.043434, test loss: 2.443126, bias2: 0.7724016904830933, variance: 1.6707247495651245\n",
      "Train size: [400] hidden size: [556] trial: 4, train_loss: 0.042410, test loss: 2.416101, bias2: 0.655166745185852, variance: 1.7609342336654663\n",
      "Train size: [400] hidden size: [556] trial: 5, train_loss: 0.042647, test loss: 2.464239, bias2: 0.5837982892990112, variance: 1.880440354347229\n",
      "Train size: [400] hidden size: [556] trial: 6, train_loss: 0.042026, test loss: 2.427689, bias2: 0.5318852663040161, variance: 1.8958040475845337\n",
      "Train size: [400] hidden size: [556] trial: 7, train_loss: 0.041301, test loss: 2.410568, bias2: 0.4947260618209839, variance: 1.9158424139022827\n",
      "Train size: [400] hidden size: [556] trial: 8, train_loss: 0.043138, test loss: 2.462657, bias2: 0.4788990020751953, variance: 1.9837582111358643\n",
      "Train size: [400] hidden size: [556] trial: 9, train_loss: 0.043362, test loss: 2.463214, bias2: 0.45371246337890625, variance: 2.0095019340515137\n",
      "Train size: [400] hidden size: [556] trial: 10, train_loss: 0.043088, test loss: 2.446731, bias2: 0.4174320697784424, variance: 2.0292985439300537\n",
      "Train size: [400] hidden size: [556] trial: 11, train_loss: 0.043835, test loss: 2.459721, bias2: 0.40974903106689453, variance: 2.0499722957611084\n",
      "Train size: [400] hidden size: [556] trial: 12, train_loss: 0.043491, test loss: 2.437153, bias2: 0.38922572135925293, variance: 2.0479276180267334\n",
      "Train size: [400] hidden size: [556] trial: 13, train_loss: 0.043324, test loss: 2.430959, bias2: 0.37425827980041504, variance: 2.0567009449005127\n",
      "Train size: [400] hidden size: [556] trial: 14, train_loss: 0.042871, test loss: 2.443324, bias2: 0.37065553665161133, variance: 2.07266902923584\n",
      "Train size: [400] hidden size: [556] trial: 15, train_loss: 0.042845, test loss: 2.443004, bias2: 0.36072564125061035, variance: 2.0822787284851074\n",
      "Train size: [400] hidden size: [556] trial: 16, train_loss: 0.042477, test loss: 2.450479, bias2: 0.3558800220489502, variance: 2.0945987701416016\n",
      "Train size: [400] hidden size: [556] trial: 17, train_loss: 0.042175, test loss: 2.452978, bias2: 0.35152554512023926, variance: 2.101452589035034\n",
      "Train size: [400] hidden size: [556] trial: 18, train_loss: 0.043598, test loss: 2.489245, bias2: 0.34786105155944824, variance: 2.1413843631744385\n",
      "Train size: [400] hidden size: [556] trial: 19, train_loss: 0.044431, test loss: 2.490815, bias2: 0.340728759765625, variance: 2.1500866413116455\n",
      "Train size: [400] hidden size: [556] trial: 20, train_loss: 0.044730, test loss: 2.504664, bias2: 0.3327600955963135, variance: 2.171903610229492\n",
      "Train size: [400] hidden size: [556] trial: 21, train_loss: 0.044589, test loss: 2.488088, bias2: 0.3256874084472656, variance: 2.162400722503662\n",
      "Train size: [400] hidden size: [556] trial: 22, train_loss: 0.044783, test loss: 2.488136, bias2: 0.31896042823791504, variance: 2.169175624847412\n",
      "Train size: [400] hidden size: [556] trial: 23, train_loss: 0.044582, test loss: 2.487063, bias2: 0.3212876319885254, variance: 2.165775775909424\n",
      "Train size: [400] hidden size: [556] trial: 24, train_loss: 0.044664, test loss: 2.480704, bias2: 0.3179032802581787, variance: 2.1628010272979736\n",
      "Train size: [400] hidden size: [556] trial: 25, train_loss: 0.044754, test loss: 2.475852, bias2: 0.314359188079834, variance: 2.1614933013916016\n",
      "Train size: [400] hidden size: [556] trial: 26, train_loss: 0.044651, test loss: 2.473513, bias2: 0.31261372566223145, variance: 2.1608989238739014\n",
      "Train size: [400] hidden size: [556] trial: 27, train_loss: 0.044848, test loss: 2.473187, bias2: 0.31055688858032227, variance: 2.162630558013916\n",
      "Train size: [400] hidden size: [556] trial: 28, train_loss: 0.044783, test loss: 2.456654, bias2: 0.3011941909790039, variance: 2.155459403991699\n",
      "Train size: [400] hidden size: [556] trial: 29, train_loss: 0.045435, test loss: 2.480548, bias2: 0.2981295585632324, variance: 2.1824185848236084\n",
      "Train size: [400] hidden size: [556] trial: 30, train_loss: 0.045667, test loss: 2.488174, bias2: 0.2974224090576172, variance: 2.190751552581787\n",
      "Train size: [400] hidden size: [556] trial: 31, train_loss: 0.045529, test loss: 2.488232, bias2: 0.29718828201293945, variance: 2.1910438537597656\n",
      "Train size: [400] hidden size: [556] trial: 32, train_loss: 0.046019, test loss: 2.493340, bias2: 0.29320788383483887, variance: 2.200131893157959\n",
      "Train size: [400] hidden size: [556] trial: 33, train_loss: 0.046444, test loss: 2.492660, bias2: 0.2898581027984619, variance: 2.2028017044067383\n",
      "Train size: [400] hidden size: [556] trial: 34, train_loss: 0.046255, test loss: 2.491170, bias2: 0.2858569622039795, variance: 2.2053134441375732\n",
      "Train size: [400] hidden size: [556] trial: 35, train_loss: 0.046056, test loss: 2.492310, bias2: 0.2847721576690674, variance: 2.2075376510620117\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [556] trial: 36, train_loss: 0.046128, test loss: 2.495973, bias2: 0.28495311737060547, variance: 2.211019992828369\n",
      "Train size: [400] hidden size: [556] trial: 37, train_loss: 0.046094, test loss: 2.502640, bias2: 0.28263330459594727, variance: 2.2200067043304443\n",
      "Train size: [400] hidden size: [556] trial: 38, train_loss: 0.046080, test loss: 2.510942, bias2: 0.2807438373565674, variance: 2.2301976680755615\n",
      "Train size: [400] hidden size: [556] trial: 39, train_loss: 0.046222, test loss: 2.509574, bias2: 0.2748565673828125, variance: 2.234717845916748\n",
      "Train size: [400] hidden size: [556] trial: 40, train_loss: 0.046172, test loss: 2.509844, bias2: 0.2715301513671875, variance: 2.238313913345337\n",
      "Train size: [400] hidden size: [556] trial: 41, train_loss: 0.046115, test loss: 2.509515, bias2: 0.27002859115600586, variance: 2.2394866943359375\n",
      "Train size: [400] hidden size: [556] trial: 42, train_loss: 0.046018, test loss: 2.505065, bias2: 0.266157865524292, variance: 2.2389068603515625\n",
      "Train size: [400] hidden size: [556] trial: 43, train_loss: 0.045884, test loss: 2.500417, bias2: 0.2645297050476074, variance: 2.2358875274658203\n",
      "Train size: [400] hidden size: [556] trial: 44, train_loss: 0.045737, test loss: 2.494263, bias2: 0.2633192539215088, variance: 2.2309436798095703\n",
      "Train size: [400] hidden size: [556] trial: 45, train_loss: 0.046071, test loss: 2.496032, bias2: 0.26293110847473145, variance: 2.2331011295318604\n",
      "Train size: [400] hidden size: [556] trial: 46, train_loss: 0.046200, test loss: 2.494301, bias2: 0.25986623764038086, variance: 2.2344350814819336\n",
      "Train size: [400] hidden size: [556] trial: 47, train_loss: 0.046213, test loss: 2.497936, bias2: 0.26068687438964844, variance: 2.2372496128082275\n",
      "Train size: [400] hidden size: [556] trial: 48, train_loss: 0.045944, test loss: 2.492794, bias2: 0.2603917121887207, variance: 2.232402801513672\n",
      "Train size: [400] hidden size: [556] trial: 49, train_loss: 0.045932, test loss: 2.495007, bias2: 0.25864505767822266, variance: 2.2363619804382324\n",
      "##################################################\n",
      "Train size: [400] hidden size: [640] trial: 0, train_loss: 0.028320, test loss: 2.330005, bias2: 2.330005168914795, variance: 9.342115525612371e-09\n",
      "Train size: [400] hidden size: [640] trial: 1, train_loss: 0.034300, test loss: 2.300610, bias2: 1.2142252922058105, variance: 1.0863845348358154\n",
      "Train size: [400] hidden size: [640] trial: 2, train_loss: 0.031391, test loss: 2.164810, bias2: 0.8563413619995117, variance: 1.3084688186645508\n",
      "Train size: [400] hidden size: [640] trial: 3, train_loss: 0.033042, test loss: 2.240524, bias2: 0.7343865633010864, variance: 1.506137728691101\n",
      "Train size: [400] hidden size: [640] trial: 4, train_loss: 0.031604, test loss: 2.229975, bias2: 0.6267257928848267, variance: 1.6032496690750122\n",
      "Train size: [400] hidden size: [640] trial: 5, train_loss: 0.030496, test loss: 2.196830, bias2: 0.5515848398208618, variance: 1.6452454328536987\n",
      "Train size: [400] hidden size: [640] trial: 6, train_loss: 0.030908, test loss: 2.194836, bias2: 0.49387621879577637, variance: 1.7009599208831787\n",
      "Train size: [400] hidden size: [640] trial: 7, train_loss: 0.030901, test loss: 2.186968, bias2: 0.45005786418914795, variance: 1.7369102239608765\n",
      "Train size: [400] hidden size: [640] trial: 8, train_loss: 0.031911, test loss: 2.214116, bias2: 0.42126035690307617, variance: 1.7928555011749268\n",
      "Train size: [400] hidden size: [640] trial: 9, train_loss: 0.032336, test loss: 2.210323, bias2: 0.4033266305923462, variance: 1.80699622631073\n",
      "Train size: [400] hidden size: [640] trial: 10, train_loss: 0.032608, test loss: 2.204507, bias2: 0.3707641363143921, variance: 1.8337424993515015\n",
      "Train size: [400] hidden size: [640] trial: 11, train_loss: 0.032590, test loss: 2.186074, bias2: 0.3486684560775757, variance: 1.8374053239822388\n",
      "Train size: [400] hidden size: [640] trial: 12, train_loss: 0.032843, test loss: 2.177851, bias2: 0.32524824142456055, variance: 1.8526031970977783\n",
      "Train size: [400] hidden size: [640] trial: 13, train_loss: 0.032363, test loss: 2.147640, bias2: 0.31180882453918457, variance: 1.835831642150879\n",
      "Train size: [400] hidden size: [640] trial: 14, train_loss: 0.032239, test loss: 2.160362, bias2: 0.30325043201446533, variance: 1.8571110963821411\n",
      "Train size: [400] hidden size: [640] trial: 15, train_loss: 0.031689, test loss: 2.151913, bias2: 0.30324387550354004, variance: 1.8486685752868652\n",
      "Train size: [400] hidden size: [640] trial: 16, train_loss: 0.031965, test loss: 2.171902, bias2: 0.30193138122558594, variance: 1.8699703216552734\n",
      "Train size: [400] hidden size: [640] trial: 17, train_loss: 0.032043, test loss: 2.169030, bias2: 0.29289019107818604, variance: 1.876139521598816\n",
      "Train size: [400] hidden size: [640] trial: 18, train_loss: 0.032207, test loss: 2.177857, bias2: 0.2900606393814087, variance: 1.8877962827682495\n",
      "Train size: [400] hidden size: [640] trial: 19, train_loss: 0.032061, test loss: 2.173506, bias2: 0.2810060977935791, variance: 1.8924999237060547\n",
      "Train size: [400] hidden size: [640] trial: 20, train_loss: 0.032176, test loss: 2.170137, bias2: 0.2767984867095947, variance: 1.8933379650115967\n",
      "Train size: [400] hidden size: [640] trial: 21, train_loss: 0.032289, test loss: 2.174005, bias2: 0.2728691101074219, variance: 1.9011359214782715\n",
      "Train size: [400] hidden size: [640] trial: 22, train_loss: 0.032539, test loss: 2.168572, bias2: 0.2708367109298706, variance: 1.8977357149124146\n",
      "Train size: [400] hidden size: [640] trial: 23, train_loss: 0.032450, test loss: 2.163677, bias2: 0.26734089851379395, variance: 1.8963356018066406\n",
      "Train size: [400] hidden size: [640] trial: 24, train_loss: 0.032420, test loss: 2.164612, bias2: 0.266687273979187, variance: 1.8979250192642212\n",
      "Train size: [400] hidden size: [640] trial: 25, train_loss: 0.031989, test loss: 2.158599, bias2: 0.26451635360717773, variance: 1.89408278465271\n",
      "Train size: [400] hidden size: [640] trial: 26, train_loss: 0.031780, test loss: 2.151937, bias2: 0.25886690616607666, variance: 1.893070101737976\n",
      "Train size: [400] hidden size: [640] trial: 27, train_loss: 0.031481, test loss: 2.139281, bias2: 0.25860536098480225, variance: 1.880675196647644\n",
      "Train size: [400] hidden size: [640] trial: 28, train_loss: 0.031236, test loss: 2.132952, bias2: 0.2566453218460083, variance: 1.8763071298599243\n",
      "Train size: [400] hidden size: [640] trial: 29, train_loss: 0.031104, test loss: 2.126596, bias2: 0.2545452117919922, variance: 1.8720512390136719\n",
      "Train size: [400] hidden size: [640] trial: 30, train_loss: 0.031138, test loss: 2.122001, bias2: 0.24980521202087402, variance: 1.8721952438354492\n",
      "Train size: [400] hidden size: [640] trial: 31, train_loss: 0.030955, test loss: 2.122417, bias2: 0.24976372718811035, variance: 1.8726532459259033\n",
      "Train size: [400] hidden size: [640] trial: 32, train_loss: 0.030913, test loss: 2.119087, bias2: 0.24794459342956543, variance: 1.871142864227295\n",
      "Train size: [400] hidden size: [640] trial: 33, train_loss: 0.030999, test loss: 2.128610, bias2: 0.2479931116104126, variance: 1.8806167840957642\n",
      "Train size: [400] hidden size: [640] trial: 34, train_loss: 0.030903, test loss: 2.130157, bias2: 0.24954450130462646, variance: 1.8806124925613403\n",
      "Train size: [400] hidden size: [640] trial: 35, train_loss: 0.030892, test loss: 2.129806, bias2: 0.2479172945022583, variance: 1.88188898563385\n",
      "Train size: [400] hidden size: [640] trial: 36, train_loss: 0.030727, test loss: 2.121269, bias2: 0.24438929557800293, variance: 1.8768799304962158\n",
      "Train size: [400] hidden size: [640] trial: 37, train_loss: 0.030824, test loss: 2.125864, bias2: 0.24227523803710938, variance: 1.8835887908935547\n",
      "Train size: [400] hidden size: [640] trial: 38, train_loss: 0.030788, test loss: 2.133889, bias2: 0.2424170970916748, variance: 1.891472339630127\n",
      "Train size: [400] hidden size: [640] trial: 39, train_loss: 0.030745, test loss: 2.129954, bias2: 0.2414841651916504, variance: 1.8884696960449219\n",
      "Train size: [400] hidden size: [640] trial: 40, train_loss: 0.030928, test loss: 2.131555, bias2: 0.24176394939422607, variance: 1.8897916078567505\n",
      "Train size: [400] hidden size: [640] trial: 41, train_loss: 0.031014, test loss: 2.133278, bias2: 0.23931121826171875, variance: 1.8939669132232666\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [640] trial: 42, train_loss: 0.031089, test loss: 2.138956, bias2: 0.2384873628616333, variance: 1.9004682302474976\n",
      "Train size: [400] hidden size: [640] trial: 43, train_loss: 0.031322, test loss: 2.140838, bias2: 0.23867082595825195, variance: 1.9021673202514648\n",
      "Train size: [400] hidden size: [640] trial: 44, train_loss: 0.031441, test loss: 2.146764, bias2: 0.23768901824951172, variance: 1.9090745449066162\n",
      "Train size: [400] hidden size: [640] trial: 45, train_loss: 0.031492, test loss: 2.144517, bias2: 0.23689818382263184, variance: 1.907618522644043\n",
      "Train size: [400] hidden size: [640] trial: 46, train_loss: 0.031590, test loss: 2.149277, bias2: 0.23650288581848145, variance: 1.912773609161377\n",
      "Train size: [400] hidden size: [640] trial: 47, train_loss: 0.031446, test loss: 2.142260, bias2: 0.23754644393920898, variance: 1.9047141075134277\n",
      "Train size: [400] hidden size: [640] trial: 48, train_loss: 0.031456, test loss: 2.141542, bias2: 0.23532772064208984, variance: 1.9062139987945557\n",
      "Train size: [400] hidden size: [640] trial: 49, train_loss: 0.031453, test loss: 2.142813, bias2: 0.23632550239562988, variance: 1.9064877033233643\n",
      "##################################################\n",
      "Train size: [400] hidden size: [737] trial: 0, train_loss: 0.019451, test loss: 1.756522, bias2: 1.7565218210220337, variance: 3.1140383605077204e-09\n",
      "Train size: [400] hidden size: [737] trial: 1, train_loss: 0.023281, test loss: 1.910083, bias2: 1.0721478462219238, variance: 0.837935209274292\n",
      "Train size: [400] hidden size: [737] trial: 2, train_loss: 0.023468, test loss: 1.942956, bias2: 0.7802122831344604, variance: 1.1627435684204102\n",
      "Train size: [400] hidden size: [737] trial: 3, train_loss: 0.024948, test loss: 1.997823, bias2: 0.6539841890335083, variance: 1.3438384532928467\n",
      "Train size: [400] hidden size: [737] trial: 4, train_loss: 0.023809, test loss: 1.977603, bias2: 0.5583887100219727, variance: 1.4192140102386475\n",
      "Train size: [400] hidden size: [737] trial: 5, train_loss: 0.022940, test loss: 1.952079, bias2: 0.48700618743896484, variance: 1.465072751045227\n",
      "Train size: [400] hidden size: [737] trial: 6, train_loss: 0.023164, test loss: 1.949789, bias2: 0.45268702507019043, variance: 1.4971020221710205\n",
      "Train size: [400] hidden size: [737] trial: 7, train_loss: 0.023573, test loss: 1.914973, bias2: 0.40467369556427, variance: 1.5102996826171875\n",
      "Train size: [400] hidden size: [737] trial: 8, train_loss: 0.023685, test loss: 1.912121, bias2: 0.3873939514160156, variance: 1.5247269868850708\n",
      "Train size: [400] hidden size: [737] trial: 9, train_loss: 0.023847, test loss: 1.910450, bias2: 0.3657956123352051, variance: 1.5446548461914062\n",
      "Train size: [400] hidden size: [737] trial: 10, train_loss: 0.024270, test loss: 1.905715, bias2: 0.34934091567993164, variance: 1.5563745498657227\n",
      "Train size: [400] hidden size: [737] trial: 11, train_loss: 0.024089, test loss: 1.893975, bias2: 0.33152174949645996, variance: 1.5624536275863647\n",
      "Train size: [400] hidden size: [737] trial: 12, train_loss: 0.023815, test loss: 1.896784, bias2: 0.314835786819458, variance: 1.5819485187530518\n",
      "Train size: [400] hidden size: [737] trial: 13, train_loss: 0.023947, test loss: 1.907714, bias2: 0.3068394660949707, variance: 1.6008743047714233\n",
      "Train size: [400] hidden size: [737] trial: 14, train_loss: 0.023760, test loss: 1.914984, bias2: 0.3050868511199951, variance: 1.6098973751068115\n",
      "Train size: [400] hidden size: [737] trial: 15, train_loss: 0.023536, test loss: 1.914020, bias2: 0.2942509651184082, variance: 1.6197694540023804\n",
      "Train size: [400] hidden size: [737] trial: 16, train_loss: 0.023644, test loss: 1.917447, bias2: 0.2918311357498169, variance: 1.625616192817688\n",
      "Train size: [400] hidden size: [737] trial: 17, train_loss: 0.023621, test loss: 1.912862, bias2: 0.28656768798828125, variance: 1.6262946128845215\n",
      "Train size: [400] hidden size: [737] trial: 18, train_loss: 0.023497, test loss: 1.913118, bias2: 0.2797144651412964, variance: 1.6334033012390137\n",
      "Train size: [400] hidden size: [737] trial: 19, train_loss: 0.023409, test loss: 1.916524, bias2: 0.2791116237640381, variance: 1.6374127864837646\n",
      "Train size: [400] hidden size: [737] trial: 20, train_loss: 0.023214, test loss: 1.919903, bias2: 0.276043176651001, variance: 1.643860101699829\n",
      "Train size: [400] hidden size: [737] trial: 21, train_loss: 0.023419, test loss: 1.927982, bias2: 0.2731044292449951, variance: 1.6548773050308228\n",
      "Train size: [400] hidden size: [737] trial: 22, train_loss: 0.023139, test loss: 1.924898, bias2: 0.2723270654678345, variance: 1.6525707244873047\n",
      "Train size: [400] hidden size: [737] trial: 23, train_loss: 0.022954, test loss: 1.914564, bias2: 0.26938188076019287, variance: 1.645182490348816\n",
      "Train size: [400] hidden size: [737] trial: 24, train_loss: 0.022757, test loss: 1.912314, bias2: 0.2667742967605591, variance: 1.64553964138031\n",
      "Train size: [400] hidden size: [737] trial: 25, train_loss: 0.022724, test loss: 1.902851, bias2: 0.26108241081237793, variance: 1.6417685747146606\n",
      "Train size: [400] hidden size: [737] trial: 26, train_loss: 0.022682, test loss: 1.907376, bias2: 0.2582739591598511, variance: 1.6491024494171143\n",
      "Train size: [400] hidden size: [737] trial: 27, train_loss: 0.022761, test loss: 1.906071, bias2: 0.25608980655670166, variance: 1.6499813795089722\n",
      "Train size: [400] hidden size: [737] trial: 28, train_loss: 0.022602, test loss: 1.904753, bias2: 0.25273633003234863, variance: 1.6520167589187622\n",
      "Train size: [400] hidden size: [737] trial: 29, train_loss: 0.022460, test loss: 1.898286, bias2: 0.25122785568237305, variance: 1.6470586061477661\n",
      "Train size: [400] hidden size: [737] trial: 30, train_loss: 0.022508, test loss: 1.895533, bias2: 0.2487790584564209, variance: 1.6467543840408325\n",
      "Train size: [400] hidden size: [737] trial: 31, train_loss: 0.022454, test loss: 1.894583, bias2: 0.2470484972000122, variance: 1.6475343704223633\n",
      "Train size: [400] hidden size: [737] trial: 32, train_loss: 0.022306, test loss: 1.890777, bias2: 0.24375271797180176, variance: 1.6470240354537964\n",
      "Train size: [400] hidden size: [737] trial: 33, train_loss: 0.022210, test loss: 1.892526, bias2: 0.2444530725479126, variance: 1.6480728387832642\n",
      "Train size: [400] hidden size: [737] trial: 34, train_loss: 0.022277, test loss: 1.888606, bias2: 0.23963356018066406, variance: 1.648972511291504\n",
      "Train size: [400] hidden size: [737] trial: 35, train_loss: 0.022281, test loss: 1.882982, bias2: 0.2373892068862915, variance: 1.645592451095581\n",
      "Train size: [400] hidden size: [737] trial: 36, train_loss: 0.022496, test loss: 1.885956, bias2: 0.23517119884490967, variance: 1.6507850885391235\n",
      "Train size: [400] hidden size: [737] trial: 37, train_loss: 0.022405, test loss: 1.887303, bias2: 0.23279571533203125, variance: 1.6545069217681885\n",
      "Train size: [400] hidden size: [737] trial: 38, train_loss: 0.022554, test loss: 1.891119, bias2: 0.23083865642547607, variance: 1.660280466079712\n",
      "Train size: [400] hidden size: [737] trial: 39, train_loss: 0.022562, test loss: 1.887442, bias2: 0.2314159870147705, variance: 1.6560262441635132\n",
      "Train size: [400] hidden size: [737] trial: 40, train_loss: 0.022571, test loss: 1.889458, bias2: 0.23039841651916504, variance: 1.6590598821640015\n",
      "Train size: [400] hidden size: [737] trial: 41, train_loss: 0.022608, test loss: 1.887081, bias2: 0.2305670976638794, variance: 1.6565135717391968\n",
      "Train size: [400] hidden size: [737] trial: 42, train_loss: 0.022592, test loss: 1.883214, bias2: 0.2281665802001953, variance: 1.6550477743148804\n",
      "Train size: [400] hidden size: [737] trial: 43, train_loss: 0.022430, test loss: 1.884324, bias2: 0.22726917266845703, variance: 1.657055139541626\n",
      "Train size: [400] hidden size: [737] trial: 44, train_loss: 0.022318, test loss: 1.882105, bias2: 0.22645938396453857, variance: 1.6556452512741089\n",
      "Train size: [400] hidden size: [737] trial: 45, train_loss: 0.022299, test loss: 1.879707, bias2: 0.22484278678894043, variance: 1.6548641920089722\n",
      "Train size: [400] hidden size: [737] trial: 46, train_loss: 0.022266, test loss: 1.880483, bias2: 0.22408545017242432, variance: 1.6563977003097534\n",
      "Train size: [400] hidden size: [737] trial: 47, train_loss: 0.022340, test loss: 1.886760, bias2: 0.22316491603851318, variance: 1.6635955572128296\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [737] trial: 48, train_loss: 0.022323, test loss: 1.883984, bias2: 0.22293508052825928, variance: 1.6610490083694458\n",
      "Train size: [400] hidden size: [737] trial: 49, train_loss: 0.022317, test loss: 1.886735, bias2: 0.22298693656921387, variance: 1.6637476682662964\n",
      "##################################################\n",
      "Train size: [400] hidden size: [848] trial: 0, train_loss: 0.014668, test loss: 1.637885, bias2: 1.637884497642517, variance: -1.0120625226761604e-08\n",
      "Train size: [400] hidden size: [848] trial: 1, train_loss: 0.015242, test loss: 1.651772, bias2: 0.9054464101791382, variance: 0.7463254928588867\n",
      "Train size: [400] hidden size: [848] trial: 2, train_loss: 0.016033, test loss: 1.662469, bias2: 0.6604783535003662, variance: 1.0019904375076294\n",
      "Train size: [400] hidden size: [848] trial: 3, train_loss: 0.015429, test loss: 1.618262, bias2: 0.4953451156616211, variance: 1.1229172945022583\n",
      "Train size: [400] hidden size: [848] trial: 4, train_loss: 0.015929, test loss: 1.624043, bias2: 0.4365607500076294, variance: 1.1874821186065674\n",
      "Train size: [400] hidden size: [848] trial: 5, train_loss: 0.016482, test loss: 1.625383, bias2: 0.3972097635269165, variance: 1.2281728982925415\n",
      "Train size: [400] hidden size: [848] trial: 6, train_loss: 0.017200, test loss: 1.628493, bias2: 0.35424888134002686, variance: 1.2742438316345215\n",
      "Train size: [400] hidden size: [848] trial: 7, train_loss: 0.016735, test loss: 1.636843, bias2: 0.3399934768676758, variance: 1.2968493700027466\n",
      "Train size: [400] hidden size: [848] trial: 8, train_loss: 0.016699, test loss: 1.656057, bias2: 0.3106149435043335, variance: 1.3454418182373047\n",
      "Train size: [400] hidden size: [848] trial: 9, train_loss: 0.016425, test loss: 1.638110, bias2: 0.2901115417480469, variance: 1.3479986190795898\n",
      "Train size: [400] hidden size: [848] trial: 10, train_loss: 0.016379, test loss: 1.627782, bias2: 0.2747079133987427, variance: 1.3530737161636353\n",
      "Train size: [400] hidden size: [848] trial: 11, train_loss: 0.016358, test loss: 1.626910, bias2: 0.2539937496185303, variance: 1.3729161024093628\n",
      "Train size: [400] hidden size: [848] trial: 12, train_loss: 0.016161, test loss: 1.615524, bias2: 0.24473917484283447, variance: 1.3707852363586426\n",
      "Train size: [400] hidden size: [848] trial: 13, train_loss: 0.015984, test loss: 1.619267, bias2: 0.24919664859771729, variance: 1.370070457458496\n",
      "Train size: [400] hidden size: [848] trial: 14, train_loss: 0.015927, test loss: 1.628182, bias2: 0.25015413761138916, variance: 1.3780274391174316\n",
      "Train size: [400] hidden size: [848] trial: 15, train_loss: 0.015905, test loss: 1.625516, bias2: 0.24772882461547852, variance: 1.3777868747711182\n",
      "Train size: [400] hidden size: [848] trial: 16, train_loss: 0.015837, test loss: 1.621538, bias2: 0.24330377578735352, variance: 1.3782340288162231\n",
      "Train size: [400] hidden size: [848] trial: 17, train_loss: 0.016116, test loss: 1.631145, bias2: 0.24146342277526855, variance: 1.3896820545196533\n",
      "Train size: [400] hidden size: [848] trial: 18, train_loss: 0.016276, test loss: 1.638360, bias2: 0.23996222019195557, variance: 1.3983980417251587\n",
      "Train size: [400] hidden size: [848] trial: 19, train_loss: 0.016459, test loss: 1.646168, bias2: 0.23881125450134277, variance: 1.4073562622070312\n",
      "Train size: [400] hidden size: [848] trial: 20, train_loss: 0.016372, test loss: 1.643318, bias2: 0.23902451992034912, variance: 1.4042932987213135\n",
      "Train size: [400] hidden size: [848] trial: 21, train_loss: 0.016268, test loss: 1.639101, bias2: 0.23677754402160645, variance: 1.4023234844207764\n",
      "Train size: [400] hidden size: [848] trial: 22, train_loss: 0.016260, test loss: 1.638048, bias2: 0.23521292209625244, variance: 1.4028352499008179\n",
      "Train size: [400] hidden size: [848] trial: 23, train_loss: 0.016157, test loss: 1.643296, bias2: 0.2380843162536621, variance: 1.4052118062973022\n",
      "Train size: [400] hidden size: [848] trial: 24, train_loss: 0.016229, test loss: 1.641967, bias2: 0.2347623109817505, variance: 1.4072043895721436\n",
      "Train size: [400] hidden size: [848] trial: 25, train_loss: 0.016157, test loss: 1.643170, bias2: 0.2358475923538208, variance: 1.4073222875595093\n",
      "Train size: [400] hidden size: [848] trial: 26, train_loss: 0.016013, test loss: 1.638521, bias2: 0.23568546772003174, variance: 1.4028352499008179\n",
      "Train size: [400] hidden size: [848] trial: 27, train_loss: 0.016015, test loss: 1.637148, bias2: 0.236899733543396, variance: 1.4002482891082764\n",
      "Train size: [400] hidden size: [848] trial: 28, train_loss: 0.016107, test loss: 1.639358, bias2: 0.23402750492095947, variance: 1.4053301811218262\n",
      "Train size: [400] hidden size: [848] trial: 29, train_loss: 0.016195, test loss: 1.634666, bias2: 0.23164939880371094, variance: 1.403016209602356\n",
      "Train size: [400] hidden size: [848] trial: 30, train_loss: 0.016103, test loss: 1.633722, bias2: 0.2318563461303711, variance: 1.4018651247024536\n",
      "Train size: [400] hidden size: [848] trial: 31, train_loss: 0.016025, test loss: 1.630273, bias2: 0.23145294189453125, variance: 1.398820400238037\n",
      "Train size: [400] hidden size: [848] trial: 32, train_loss: 0.016089, test loss: 1.631375, bias2: 0.23139214515686035, variance: 1.3999829292297363\n",
      "Train size: [400] hidden size: [848] trial: 33, train_loss: 0.016089, test loss: 1.635123, bias2: 0.23186993598937988, variance: 1.403253436088562\n",
      "Train size: [400] hidden size: [848] trial: 34, train_loss: 0.016283, test loss: 1.641533, bias2: 0.2314082384109497, variance: 1.4101247787475586\n",
      "Train size: [400] hidden size: [848] trial: 35, train_loss: 0.016279, test loss: 1.638730, bias2: 0.2305612564086914, variance: 1.4081685543060303\n",
      "Train size: [400] hidden size: [848] trial: 36, train_loss: 0.016250, test loss: 1.635457, bias2: 0.23116981983184814, variance: 1.4042876958847046\n",
      "Train size: [400] hidden size: [848] trial: 37, train_loss: 0.016256, test loss: 1.635826, bias2: 0.2300732135772705, variance: 1.4057530164718628\n",
      "Train size: [400] hidden size: [848] trial: 38, train_loss: 0.016205, test loss: 1.636902, bias2: 0.23094439506530762, variance: 1.4059576988220215\n",
      "Train size: [400] hidden size: [848] trial: 39, train_loss: 0.016198, test loss: 1.640722, bias2: 0.23001456260681152, variance: 1.4107075929641724\n",
      "Train size: [400] hidden size: [848] trial: 40, train_loss: 0.016132, test loss: 1.636050, bias2: 0.22838211059570312, variance: 1.407668113708496\n",
      "Train size: [400] hidden size: [848] trial: 41, train_loss: 0.016080, test loss: 1.633037, bias2: 0.22849106788635254, variance: 1.4045456647872925\n",
      "Train size: [400] hidden size: [848] trial: 42, train_loss: 0.016052, test loss: 1.633428, bias2: 0.22936570644378662, variance: 1.4040623903274536\n",
      "Train size: [400] hidden size: [848] trial: 43, train_loss: 0.016031, test loss: 1.634603, bias2: 0.23076319694519043, variance: 1.403839349746704\n",
      "Train size: [400] hidden size: [848] trial: 44, train_loss: 0.015952, test loss: 1.636089, bias2: 0.23020195960998535, variance: 1.4058868885040283\n",
      "Train size: [400] hidden size: [848] trial: 45, train_loss: 0.015975, test loss: 1.639762, bias2: 0.23177695274353027, variance: 1.4079850912094116\n",
      "Train size: [400] hidden size: [848] trial: 46, train_loss: 0.016113, test loss: 1.643019, bias2: 0.23109900951385498, variance: 1.411920428276062\n",
      "Train size: [400] hidden size: [848] trial: 47, train_loss: 0.016251, test loss: 1.650140, bias2: 0.23227858543395996, variance: 1.417860984802246\n",
      "Train size: [400] hidden size: [848] trial: 48, train_loss: 0.016180, test loss: 1.647820, bias2: 0.2321939468383789, variance: 1.4156265258789062\n",
      "Train size: [400] hidden size: [848] trial: 49, train_loss: 0.016173, test loss: 1.649176, bias2: 0.23372113704681396, variance: 1.4154552221298218\n",
      "##################################################\n",
      "Train size: [400] hidden size: [977] trial: 0, train_loss: 0.011765, test loss: 1.355682, bias2: 1.3556816577911377, variance: 1.0120625226761604e-08\n",
      "Train size: [400] hidden size: [977] trial: 1, train_loss: 0.011690, test loss: 1.353725, bias2: 0.7492848038673401, variance: 0.6044405102729797\n",
      "Train size: [400] hidden size: [977] trial: 2, train_loss: 0.011865, test loss: 1.336099, bias2: 0.5633319616317749, variance: 0.772767186164856\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [977] trial: 3, train_loss: 0.012704, test loss: 1.433818, bias2: 0.500656247138977, variance: 0.9331622123718262\n",
      "Train size: [400] hidden size: [977] trial: 4, train_loss: 0.012662, test loss: 1.452800, bias2: 0.45771849155426025, variance: 0.9950814247131348\n",
      "Train size: [400] hidden size: [977] trial: 5, train_loss: 0.012605, test loss: 1.457065, bias2: 0.406246542930603, variance: 1.0508183240890503\n",
      "Train size: [400] hidden size: [977] trial: 6, train_loss: 0.012672, test loss: 1.456441, bias2: 0.38095736503601074, variance: 1.0754839181900024\n",
      "Train size: [400] hidden size: [977] trial: 7, train_loss: 0.012592, test loss: 1.427956, bias2: 0.35388386249542236, variance: 1.0740723609924316\n",
      "Train size: [400] hidden size: [977] trial: 8, train_loss: 0.012649, test loss: 1.435520, bias2: 0.3290456533432007, variance: 1.1064739227294922\n",
      "Train size: [400] hidden size: [977] trial: 9, train_loss: 0.012848, test loss: 1.451345, bias2: 0.3167814016342163, variance: 1.1345634460449219\n",
      "Train size: [400] hidden size: [977] trial: 10, train_loss: 0.013102, test loss: 1.459365, bias2: 0.31045782566070557, variance: 1.1489068269729614\n",
      "Train size: [400] hidden size: [977] trial: 11, train_loss: 0.013034, test loss: 1.457621, bias2: 0.29534244537353516, variance: 1.1622788906097412\n",
      "Train size: [400] hidden size: [977] trial: 12, train_loss: 0.013169, test loss: 1.461496, bias2: 0.27931416034698486, variance: 1.182181715965271\n",
      "Train size: [400] hidden size: [977] trial: 13, train_loss: 0.013174, test loss: 1.463798, bias2: 0.27854764461517334, variance: 1.1852500438690186\n",
      "Train size: [400] hidden size: [977] trial: 14, train_loss: 0.013175, test loss: 1.467152, bias2: 0.2715892791748047, variance: 1.1955622434616089\n",
      "Train size: [400] hidden size: [977] trial: 15, train_loss: 0.013040, test loss: 1.464762, bias2: 0.26990747451782227, variance: 1.194854974746704\n",
      "Train size: [400] hidden size: [977] trial: 16, train_loss: 0.013022, test loss: 1.471172, bias2: 0.26703941822052, variance: 1.2041326761245728\n",
      "Train size: [400] hidden size: [977] trial: 17, train_loss: 0.012920, test loss: 1.478023, bias2: 0.27011823654174805, variance: 1.2079048156738281\n",
      "Train size: [400] hidden size: [977] trial: 18, train_loss: 0.012825, test loss: 1.472315, bias2: 0.2679619789123535, variance: 1.2043535709381104\n",
      "Train size: [400] hidden size: [977] trial: 19, train_loss: 0.012773, test loss: 1.472511, bias2: 0.26142990589141846, variance: 1.2110811471939087\n",
      "Train size: [400] hidden size: [977] trial: 20, train_loss: 0.012757, test loss: 1.477822, bias2: 0.2589792013168335, variance: 1.2188431024551392\n",
      "Train size: [400] hidden size: [977] trial: 21, train_loss: 0.012625, test loss: 1.474530, bias2: 0.2572821378707886, variance: 1.2172480821609497\n",
      "Train size: [400] hidden size: [977] trial: 22, train_loss: 0.012642, test loss: 1.478587, bias2: 0.2563638687133789, variance: 1.2222235202789307\n",
      "Train size: [400] hidden size: [977] trial: 23, train_loss: 0.012702, test loss: 1.478311, bias2: 0.2534911632537842, variance: 1.2248198986053467\n",
      "Train size: [400] hidden size: [977] trial: 24, train_loss: 0.012810, test loss: 1.481052, bias2: 0.2518312931060791, variance: 1.2292208671569824\n",
      "Train size: [400] hidden size: [977] trial: 25, train_loss: 0.012742, test loss: 1.478949, bias2: 0.254550576210022, variance: 1.2243980169296265\n",
      "Train size: [400] hidden size: [977] trial: 26, train_loss: 0.012631, test loss: 1.475597, bias2: 0.2523108720779419, variance: 1.2232859134674072\n",
      "Train size: [400] hidden size: [977] trial: 27, train_loss: 0.012601, test loss: 1.477338, bias2: 0.25041842460632324, variance: 1.2269192934036255\n",
      "Train size: [400] hidden size: [977] trial: 28, train_loss: 0.012643, test loss: 1.476886, bias2: 0.24694645404815674, variance: 1.2299394607543945\n",
      "Train size: [400] hidden size: [977] trial: 29, train_loss: 0.012623, test loss: 1.477785, bias2: 0.24667763710021973, variance: 1.2311078310012817\n",
      "Train size: [400] hidden size: [977] trial: 30, train_loss: 0.012559, test loss: 1.473264, bias2: 0.24648332595825195, variance: 1.2267802953720093\n",
      "Train size: [400] hidden size: [977] trial: 31, train_loss: 0.012497, test loss: 1.468930, bias2: 0.24162518978118896, variance: 1.2273050546646118\n",
      "Train size: [400] hidden size: [977] trial: 32, train_loss: 0.012443, test loss: 1.471829, bias2: 0.24066424369812012, variance: 1.2311646938323975\n",
      "Train size: [400] hidden size: [977] trial: 33, train_loss: 0.012438, test loss: 1.470320, bias2: 0.23949134349822998, variance: 1.230829119682312\n",
      "Train size: [400] hidden size: [977] trial: 34, train_loss: 0.012506, test loss: 1.470919, bias2: 0.2373737096786499, variance: 1.233545184135437\n",
      "Train size: [400] hidden size: [977] trial: 35, train_loss: 0.012546, test loss: 1.474733, bias2: 0.23756027221679688, variance: 1.2371724843978882\n",
      "Train size: [400] hidden size: [977] trial: 36, train_loss: 0.012481, test loss: 1.471430, bias2: 0.23712027072906494, variance: 1.2343097925186157\n",
      "Train size: [400] hidden size: [977] trial: 37, train_loss: 0.012492, test loss: 1.471493, bias2: 0.2362358570098877, variance: 1.2352573871612549\n",
      "Train size: [400] hidden size: [977] trial: 38, train_loss: 0.012474, test loss: 1.469110, bias2: 0.23620367050170898, variance: 1.2329065799713135\n",
      "Train size: [400] hidden size: [977] trial: 39, train_loss: 0.012513, test loss: 1.472052, bias2: 0.23511004447937012, variance: 1.2369422912597656\n",
      "Train size: [400] hidden size: [977] trial: 40, train_loss: 0.012528, test loss: 1.469347, bias2: 0.23284077644348145, variance: 1.236506462097168\n",
      "Train size: [400] hidden size: [977] trial: 41, train_loss: 0.012478, test loss: 1.466981, bias2: 0.23182129859924316, variance: 1.2351595163345337\n",
      "Train size: [400] hidden size: [977] trial: 42, train_loss: 0.012527, test loss: 1.463061, bias2: 0.22929728031158447, variance: 1.2337638139724731\n",
      "Train size: [400] hidden size: [977] trial: 43, train_loss: 0.012557, test loss: 1.463539, bias2: 0.22668325901031494, variance: 1.2368561029434204\n",
      "Train size: [400] hidden size: [977] trial: 44, train_loss: 0.012581, test loss: 1.470020, bias2: 0.22746169567108154, variance: 1.2425580024719238\n",
      "Train size: [400] hidden size: [977] trial: 45, train_loss: 0.012664, test loss: 1.471555, bias2: 0.2246953248977661, variance: 1.2468595504760742\n",
      "Train size: [400] hidden size: [977] trial: 46, train_loss: 0.012615, test loss: 1.469092, bias2: 0.22288990020751953, variance: 1.2462022304534912\n",
      "Train size: [400] hidden size: [977] trial: 47, train_loss: 0.012627, test loss: 1.468210, bias2: 0.22212302684783936, variance: 1.246086835861206\n",
      "Train size: [400] hidden size: [977] trial: 48, train_loss: 0.012647, test loss: 1.469945, bias2: 0.22130084037780762, variance: 1.248644471168518\n",
      "Train size: [400] hidden size: [977] trial: 49, train_loss: 0.012638, test loss: 1.467729, bias2: 0.22038483619689941, variance: 1.2473443746566772\n",
      "##################################################\n",
      "Train size: [400] hidden size: [1125] trial: 0, train_loss: 0.010113, test loss: 1.334015, bias2: 1.334014654159546, variance: -6.228076721015441e-09\n",
      "Train size: [400] hidden size: [1125] trial: 1, train_loss: 0.009702, test loss: 1.338158, bias2: 0.7490911483764648, variance: 0.589066743850708\n",
      "Train size: [400] hidden size: [1125] trial: 2, train_loss: 0.009705, test loss: 1.364571, bias2: 0.5703372359275818, variance: 0.7942337393760681\n",
      "Train size: [400] hidden size: [1125] trial: 3, train_loss: 0.010225, test loss: 1.349089, bias2: 0.46548378467559814, variance: 0.8836047649383545\n",
      "Train size: [400] hidden size: [1125] trial: 4, train_loss: 0.010192, test loss: 1.329093, bias2: 0.4085065722465515, variance: 0.9205866456031799\n",
      "Train size: [400] hidden size: [1125] trial: 5, train_loss: 0.010106, test loss: 1.324802, bias2: 0.3748016953468323, variance: 0.9500005841255188\n",
      "Train size: [400] hidden size: [1125] trial: 6, train_loss: 0.010084, test loss: 1.335047, bias2: 0.34728294610977173, variance: 0.9877637028694153\n",
      "Train size: [400] hidden size: [1125] trial: 7, train_loss: 0.009994, test loss: 1.322142, bias2: 0.3224940299987793, variance: 0.9996480941772461\n",
      "Train size: [400] hidden size: [1125] trial: 8, train_loss: 0.010128, test loss: 1.317178, bias2: 0.3019897937774658, variance: 1.0151885747909546\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [1125] trial: 9, train_loss: 0.010036, test loss: 1.307300, bias2: 0.2981916666030884, variance: 1.009108066558838\n",
      "Train size: [400] hidden size: [1125] trial: 10, train_loss: 0.009971, test loss: 1.315258, bias2: 0.2941991090774536, variance: 1.0210585594177246\n",
      "Train size: [400] hidden size: [1125] trial: 11, train_loss: 0.010248, test loss: 1.319953, bias2: 0.28941822052001953, variance: 1.0305352210998535\n",
      "Train size: [400] hidden size: [1125] trial: 12, train_loss: 0.010403, test loss: 1.349765, bias2: 0.28955721855163574, variance: 1.0602076053619385\n",
      "Train size: [400] hidden size: [1125] trial: 13, train_loss: 0.010572, test loss: 1.352185, bias2: 0.2803546190261841, variance: 1.0718307495117188\n",
      "Train size: [400] hidden size: [1125] trial: 14, train_loss: 0.010527, test loss: 1.344011, bias2: 0.2747039794921875, variance: 1.0693069696426392\n",
      "Train size: [400] hidden size: [1125] trial: 15, train_loss: 0.010412, test loss: 1.338764, bias2: 0.26507997512817383, variance: 1.0736836194992065\n",
      "Train size: [400] hidden size: [1125] trial: 16, train_loss: 0.010454, test loss: 1.342306, bias2: 0.2611527442932129, variance: 1.0811529159545898\n",
      "Train size: [400] hidden size: [1125] trial: 17, train_loss: 0.010431, test loss: 1.336309, bias2: 0.25786590576171875, variance: 1.0784428119659424\n",
      "Train size: [400] hidden size: [1125] trial: 18, train_loss: 0.010441, test loss: 1.338354, bias2: 0.2566547393798828, variance: 1.0816997289657593\n",
      "Train size: [400] hidden size: [1125] trial: 19, train_loss: 0.010500, test loss: 1.348408, bias2: 0.2562445402145386, variance: 1.0921635627746582\n",
      "Train size: [400] hidden size: [1125] trial: 20, train_loss: 0.010550, test loss: 1.351489, bias2: 0.25677359104156494, variance: 1.0947151184082031\n",
      "Train size: [400] hidden size: [1125] trial: 21, train_loss: 0.010517, test loss: 1.355732, bias2: 0.2569618225097656, variance: 1.0987704992294312\n",
      "Train size: [400] hidden size: [1125] trial: 22, train_loss: 0.010501, test loss: 1.355800, bias2: 0.2571488618850708, variance: 1.098651647567749\n",
      "Train size: [400] hidden size: [1125] trial: 23, train_loss: 0.010502, test loss: 1.349908, bias2: 0.2522416114807129, variance: 1.0976661443710327\n",
      "Train size: [400] hidden size: [1125] trial: 24, train_loss: 0.010442, test loss: 1.348327, bias2: 0.25227153301239014, variance: 1.0960557460784912\n",
      "Train size: [400] hidden size: [1125] trial: 25, train_loss: 0.010407, test loss: 1.345353, bias2: 0.24893569946289062, variance: 1.0964170694351196\n",
      "Train size: [400] hidden size: [1125] trial: 26, train_loss: 0.010376, test loss: 1.343087, bias2: 0.24475359916687012, variance: 1.0983331203460693\n",
      "Train size: [400] hidden size: [1125] trial: 27, train_loss: 0.010376, test loss: 1.342752, bias2: 0.24451220035552979, variance: 1.098239779472351\n",
      "Train size: [400] hidden size: [1125] trial: 28, train_loss: 0.010399, test loss: 1.341132, bias2: 0.23989450931549072, variance: 1.1012377738952637\n",
      "Train size: [400] hidden size: [1125] trial: 29, train_loss: 0.010400, test loss: 1.337161, bias2: 0.23838460445404053, variance: 1.0987765789031982\n",
      "Train size: [400] hidden size: [1125] trial: 30, train_loss: 0.010442, test loss: 1.336674, bias2: 0.2380058765411377, variance: 1.0986679792404175\n",
      "Train size: [400] hidden size: [1125] trial: 31, train_loss: 0.010481, test loss: 1.338339, bias2: 0.23676586151123047, variance: 1.1015734672546387\n",
      "Train size: [400] hidden size: [1125] trial: 32, train_loss: 0.010472, test loss: 1.336837, bias2: 0.2350776195526123, variance: 1.1017590761184692\n",
      "Train size: [400] hidden size: [1125] trial: 33, train_loss: 0.010410, test loss: 1.336871, bias2: 0.23642313480377197, variance: 1.1004482507705688\n",
      "Train size: [400] hidden size: [1125] trial: 34, train_loss: 0.010432, test loss: 1.331458, bias2: 0.23222053050994873, variance: 1.0992377996444702\n",
      "Train size: [400] hidden size: [1125] trial: 35, train_loss: 0.010423, test loss: 1.332758, bias2: 0.23157966136932373, variance: 1.101178765296936\n",
      "Train size: [400] hidden size: [1125] trial: 36, train_loss: 0.010399, test loss: 1.331243, bias2: 0.23282968997955322, variance: 1.0984129905700684\n",
      "Train size: [400] hidden size: [1125] trial: 37, train_loss: 0.010373, test loss: 1.331861, bias2: 0.23372554779052734, variance: 1.098135232925415\n",
      "Train size: [400] hidden size: [1125] trial: 38, train_loss: 0.010454, test loss: 1.330702, bias2: 0.2305840253829956, variance: 1.100117802619934\n",
      "Train size: [400] hidden size: [1125] trial: 39, train_loss: 0.010478, test loss: 1.332606, bias2: 0.2295445203781128, variance: 1.1030614376068115\n",
      "Train size: [400] hidden size: [1125] trial: 40, train_loss: 0.010473, test loss: 1.329686, bias2: 0.22730541229248047, variance: 1.1023808717727661\n",
      "Train size: [400] hidden size: [1125] trial: 41, train_loss: 0.010446, test loss: 1.328154, bias2: 0.22775065898895264, variance: 1.1004033088684082\n",
      "Train size: [400] hidden size: [1125] trial: 42, train_loss: 0.010427, test loss: 1.328436, bias2: 0.22921574115753174, variance: 1.0992202758789062\n",
      "Train size: [400] hidden size: [1125] trial: 43, train_loss: 0.010426, test loss: 1.327746, bias2: 0.22912847995758057, variance: 1.0986171960830688\n",
      "Train size: [400] hidden size: [1125] trial: 44, train_loss: 0.010477, test loss: 1.328472, bias2: 0.2286931276321411, variance: 1.0997785329818726\n",
      "Train size: [400] hidden size: [1125] trial: 45, train_loss: 0.010482, test loss: 1.329195, bias2: 0.22860467433929443, variance: 1.1005899906158447\n",
      "Train size: [400] hidden size: [1125] trial: 46, train_loss: 0.010487, test loss: 1.328103, bias2: 0.22715866565704346, variance: 1.1009443998336792\n",
      "Train size: [400] hidden size: [1125] trial: 47, train_loss: 0.010488, test loss: 1.328823, bias2: 0.22584140300750732, variance: 1.1029812097549438\n",
      "Train size: [400] hidden size: [1125] trial: 48, train_loss: 0.010534, test loss: 1.328954, bias2: 0.22282648086547852, variance: 1.1061275005340576\n",
      "Train size: [400] hidden size: [1125] trial: 49, train_loss: 0.010551, test loss: 1.328828, bias2: 0.22217929363250732, variance: 1.1066490411758423\n",
      "##################################################\n",
      "Train size: [400] hidden size: [1295] trial: 0, train_loss: 0.009622, test loss: 1.180916, bias2: 1.180916428565979, variance: 1.0899134927910836e-08\n",
      "Train size: [400] hidden size: [1295] trial: 1, train_loss: 0.008784, test loss: 1.181581, bias2: 0.6771013140678406, variance: 0.504479706287384\n",
      "Train size: [400] hidden size: [1295] trial: 2, train_loss: 0.007944, test loss: 1.126963, bias2: 0.4954603910446167, variance: 0.631502628326416\n",
      "Train size: [400] hidden size: [1295] trial: 3, train_loss: 0.008096, test loss: 1.166132, bias2: 0.4232897162437439, variance: 0.742841899394989\n",
      "Train size: [400] hidden size: [1295] trial: 4, train_loss: 0.008034, test loss: 1.158956, bias2: 0.39265328645706177, variance: 0.7663025259971619\n",
      "Train size: [400] hidden size: [1295] trial: 5, train_loss: 0.008167, test loss: 1.164573, bias2: 0.366401731967926, variance: 0.7981714606285095\n",
      "Train size: [400] hidden size: [1295] trial: 6, train_loss: 0.008103, test loss: 1.161459, bias2: 0.3575018048286438, variance: 0.8039574027061462\n",
      "Train size: [400] hidden size: [1295] trial: 7, train_loss: 0.008205, test loss: 1.163555, bias2: 0.3448300361633301, variance: 0.8187252283096313\n",
      "Train size: [400] hidden size: [1295] trial: 8, train_loss: 0.008127, test loss: 1.152027, bias2: 0.3272252082824707, variance: 0.8248016834259033\n",
      "Train size: [400] hidden size: [1295] trial: 9, train_loss: 0.008246, test loss: 1.165677, bias2: 0.31583452224731445, variance: 0.8498421907424927\n",
      "Train size: [400] hidden size: [1295] trial: 10, train_loss: 0.008213, test loss: 1.165476, bias2: 0.30797213315963745, variance: 0.8575038313865662\n",
      "Train size: [400] hidden size: [1295] trial: 11, train_loss: 0.008199, test loss: 1.155163, bias2: 0.2898298501968384, variance: 0.8653334379196167\n",
      "Train size: [400] hidden size: [1295] trial: 12, train_loss: 0.008234, test loss: 1.168436, bias2: 0.2886098623275757, variance: 0.8798258304595947\n",
      "Train size: [400] hidden size: [1295] trial: 13, train_loss: 0.008196, test loss: 1.153592, bias2: 0.27838581800460815, variance: 0.8752065300941467\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [1295] trial: 14, train_loss: 0.008191, test loss: 1.154706, bias2: 0.2741273045539856, variance: 0.880578339099884\n",
      "Train size: [400] hidden size: [1295] trial: 15, train_loss: 0.008256, test loss: 1.160965, bias2: 0.2699459195137024, variance: 0.8910194039344788\n",
      "Train size: [400] hidden size: [1295] trial: 16, train_loss: 0.008230, test loss: 1.160538, bias2: 0.26296281814575195, variance: 0.8975750207901001\n",
      "Train size: [400] hidden size: [1295] trial: 17, train_loss: 0.008219, test loss: 1.161929, bias2: 0.25819993019104004, variance: 0.9037286043167114\n",
      "Train size: [400] hidden size: [1295] trial: 18, train_loss: 0.008279, test loss: 1.169143, bias2: 0.2556016445159912, variance: 0.9135417938232422\n",
      "Train size: [400] hidden size: [1295] trial: 19, train_loss: 0.008359, test loss: 1.172915, bias2: 0.25331586599349976, variance: 0.9195987582206726\n",
      "Train size: [400] hidden size: [1295] trial: 20, train_loss: 0.008394, test loss: 1.177519, bias2: 0.24843049049377441, variance: 0.9290889501571655\n",
      "Train size: [400] hidden size: [1295] trial: 21, train_loss: 0.008433, test loss: 1.178278, bias2: 0.24380218982696533, variance: 0.9344754219055176\n",
      "Train size: [400] hidden size: [1295] trial: 22, train_loss: 0.008494, test loss: 1.178574, bias2: 0.24153012037277222, variance: 0.9370434880256653\n",
      "Train size: [400] hidden size: [1295] trial: 23, train_loss: 0.008631, test loss: 1.185174, bias2: 0.24196749925613403, variance: 0.9432060122489929\n",
      "Train size: [400] hidden size: [1295] trial: 24, train_loss: 0.008711, test loss: 1.191871, bias2: 0.2415250539779663, variance: 0.9503459930419922\n",
      "Train size: [400] hidden size: [1295] trial: 25, train_loss: 0.008673, test loss: 1.195156, bias2: 0.24402683973312378, variance: 0.9511292576789856\n",
      "Train size: [400] hidden size: [1295] trial: 26, train_loss: 0.008663, test loss: 1.195849, bias2: 0.24285155534744263, variance: 0.952997624874115\n",
      "Train size: [400] hidden size: [1295] trial: 27, train_loss: 0.008655, test loss: 1.196701, bias2: 0.24220353364944458, variance: 0.9544975161552429\n",
      "Train size: [400] hidden size: [1295] trial: 28, train_loss: 0.008622, test loss: 1.197463, bias2: 0.24040913581848145, variance: 0.9570536613464355\n",
      "Train size: [400] hidden size: [1295] trial: 29, train_loss: 0.008654, test loss: 1.193850, bias2: 0.23670804500579834, variance: 0.957141637802124\n",
      "Train size: [400] hidden size: [1295] trial: 30, train_loss: 0.008645, test loss: 1.198029, bias2: 0.23718613386154175, variance: 0.9608431458473206\n",
      "Train size: [400] hidden size: [1295] trial: 31, train_loss: 0.008720, test loss: 1.199825, bias2: 0.23614978790283203, variance: 0.9636754989624023\n",
      "Train size: [400] hidden size: [1295] trial: 32, train_loss: 0.008727, test loss: 1.204498, bias2: 0.23693764209747314, variance: 0.9675600528717041\n",
      "Train size: [400] hidden size: [1295] trial: 33, train_loss: 0.008711, test loss: 1.205842, bias2: 0.23554229736328125, variance: 0.9703001976013184\n",
      "Train size: [400] hidden size: [1295] trial: 34, train_loss: 0.008707, test loss: 1.203659, bias2: 0.23414403200149536, variance: 0.969514787197113\n",
      "Train size: [400] hidden size: [1295] trial: 35, train_loss: 0.008693, test loss: 1.204260, bias2: 0.2329060435295105, variance: 0.971354067325592\n",
      "Train size: [400] hidden size: [1295] trial: 36, train_loss: 0.008685, test loss: 1.203994, bias2: 0.2307823896408081, variance: 0.9732111692428589\n",
      "Train size: [400] hidden size: [1295] trial: 37, train_loss: 0.008714, test loss: 1.211291, bias2: 0.23206168413162231, variance: 0.9792295098304749\n",
      "Train size: [400] hidden size: [1295] trial: 38, train_loss: 0.008735, test loss: 1.214878, bias2: 0.2325444221496582, variance: 0.9823340177536011\n",
      "Train size: [400] hidden size: [1295] trial: 39, train_loss: 0.008741, test loss: 1.218701, bias2: 0.23227930068969727, variance: 0.9864215850830078\n",
      "Train size: [400] hidden size: [1295] trial: 40, train_loss: 0.008716, test loss: 1.216550, bias2: 0.23180967569351196, variance: 0.984740674495697\n",
      "Train size: [400] hidden size: [1295] trial: 41, train_loss: 0.008740, test loss: 1.219989, bias2: 0.23202133178710938, variance: 0.9879672527313232\n",
      "Train size: [400] hidden size: [1295] trial: 42, train_loss: 0.008741, test loss: 1.222021, bias2: 0.23108422756195068, variance: 0.990936279296875\n",
      "Train size: [400] hidden size: [1295] trial: 43, train_loss: 0.008745, test loss: 1.220625, bias2: 0.23040348291397095, variance: 0.9902212023735046\n",
      "Train size: [400] hidden size: [1295] trial: 44, train_loss: 0.008715, test loss: 1.217579, bias2: 0.22943222522735596, variance: 0.9881467819213867\n",
      "Train size: [400] hidden size: [1295] trial: 45, train_loss: 0.008743, test loss: 1.223422, bias2: 0.22963809967041016, variance: 0.9937838315963745\n",
      "Train size: [400] hidden size: [1295] trial: 46, train_loss: 0.008699, test loss: 1.223437, bias2: 0.23051822185516357, variance: 0.9929189682006836\n",
      "Train size: [400] hidden size: [1295] trial: 47, train_loss: 0.008688, test loss: 1.222910, bias2: 0.23058229684829712, variance: 0.9923282265663147\n",
      "Train size: [400] hidden size: [1295] trial: 48, train_loss: 0.008657, test loss: 1.223178, bias2: 0.23153549432754517, variance: 0.9916426539421082\n",
      "Train size: [400] hidden size: [1295] trial: 49, train_loss: 0.008656, test loss: 1.222110, bias2: 0.22958147525787354, variance: 0.9925284385681152\n",
      "##################################################\n",
      "Train size: [400] hidden size: [1491] trial: 0, train_loss: 0.008994, test loss: 1.134097, bias2: 1.1340969800949097, variance: -1.3234662255001695e-08\n",
      "Train size: [400] hidden size: [1491] trial: 1, train_loss: 0.007779, test loss: 1.076603, bias2: 0.6390582323074341, variance: 0.43754419684410095\n",
      "Train size: [400] hidden size: [1491] trial: 2, train_loss: 0.008040, test loss: 1.081970, bias2: 0.4892939329147339, variance: 0.5926758050918579\n",
      "Train size: [400] hidden size: [1491] trial: 3, train_loss: 0.008230, test loss: 1.140368, bias2: 0.41641491651535034, variance: 0.7239527106285095\n",
      "Train size: [400] hidden size: [1491] trial: 4, train_loss: 0.008294, test loss: 1.150323, bias2: 0.37991780042648315, variance: 0.7704054713249207\n",
      "Train size: [400] hidden size: [1491] trial: 5, train_loss: 0.008293, test loss: 1.148332, bias2: 0.34945887327194214, variance: 0.7988731265068054\n",
      "Train size: [400] hidden size: [1491] trial: 6, train_loss: 0.008163, test loss: 1.145598, bias2: 0.3228036165237427, variance: 0.8227944374084473\n",
      "Train size: [400] hidden size: [1491] trial: 7, train_loss: 0.007943, test loss: 1.136238, bias2: 0.3118247389793396, variance: 0.8244133591651917\n",
      "Train size: [400] hidden size: [1491] trial: 8, train_loss: 0.007918, test loss: 1.137654, bias2: 0.3048083186149597, variance: 0.8328458666801453\n",
      "Train size: [400] hidden size: [1491] trial: 9, train_loss: 0.007897, test loss: 1.130640, bias2: 0.28972870111465454, variance: 0.8409114480018616\n",
      "Train size: [400] hidden size: [1491] trial: 10, train_loss: 0.008000, test loss: 1.141818, bias2: 0.27721142768859863, variance: 0.8646062612533569\n",
      "Train size: [400] hidden size: [1491] trial: 11, train_loss: 0.007937, test loss: 1.141454, bias2: 0.2715122103691101, variance: 0.869941771030426\n",
      "Train size: [400] hidden size: [1491] trial: 12, train_loss: 0.007805, test loss: 1.128963, bias2: 0.26544225215911865, variance: 0.8635203838348389\n",
      "Train size: [400] hidden size: [1491] trial: 13, train_loss: 0.007713, test loss: 1.127982, bias2: 0.2585151195526123, variance: 0.8694671392440796\n",
      "Train size: [400] hidden size: [1491] trial: 14, train_loss: 0.007689, test loss: 1.134481, bias2: 0.25625014305114746, variance: 0.8782310485839844\n",
      "Train size: [400] hidden size: [1491] trial: 15, train_loss: 0.007687, test loss: 1.132147, bias2: 0.250671923160553, variance: 0.8814751505851746\n",
      "Train size: [400] hidden size: [1491] trial: 16, train_loss: 0.007683, test loss: 1.136541, bias2: 0.24984604120254517, variance: 0.886694610118866\n",
      "Train size: [400] hidden size: [1491] trial: 17, train_loss: 0.007679, test loss: 1.137364, bias2: 0.2481892704963684, variance: 0.8891744017601013\n",
      "Train size: [400] hidden size: [1491] trial: 18, train_loss: 0.007653, test loss: 1.133933, bias2: 0.24267101287841797, variance: 0.8912615776062012\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [1491] trial: 19, train_loss: 0.007757, test loss: 1.134271, bias2: 0.2370966076850891, variance: 0.897174060344696\n",
      "Train size: [400] hidden size: [1491] trial: 20, train_loss: 0.007879, test loss: 1.133971, bias2: 0.23358750343322754, variance: 0.9003835916519165\n",
      "Train size: [400] hidden size: [1491] trial: 21, train_loss: 0.007948, test loss: 1.139033, bias2: 0.23422753810882568, variance: 0.9048055410385132\n",
      "Train size: [400] hidden size: [1491] trial: 22, train_loss: 0.007979, test loss: 1.136431, bias2: 0.23197221755981445, variance: 0.9044589996337891\n",
      "Train size: [400] hidden size: [1491] trial: 23, train_loss: 0.008028, test loss: 1.140826, bias2: 0.23182165622711182, variance: 0.9090044498443604\n",
      "Train size: [400] hidden size: [1491] trial: 24, train_loss: 0.008031, test loss: 1.141808, bias2: 0.22934645414352417, variance: 0.9124611020088196\n",
      "Train size: [400] hidden size: [1491] trial: 25, train_loss: 0.008006, test loss: 1.139292, bias2: 0.22372621297836304, variance: 0.915565550327301\n",
      "Train size: [400] hidden size: [1491] trial: 26, train_loss: 0.008056, test loss: 1.143016, bias2: 0.2233075499534607, variance: 0.9197083115577698\n",
      "Train size: [400] hidden size: [1491] trial: 27, train_loss: 0.008088, test loss: 1.143407, bias2: 0.2232809066772461, variance: 0.92012619972229\n",
      "Train size: [400] hidden size: [1491] trial: 28, train_loss: 0.008033, test loss: 1.141272, bias2: 0.2231188416481018, variance: 0.9181534647941589\n",
      "Train size: [400] hidden size: [1491] trial: 29, train_loss: 0.007978, test loss: 1.141483, bias2: 0.22193992137908936, variance: 0.919542670249939\n",
      "Train size: [400] hidden size: [1491] trial: 30, train_loss: 0.007969, test loss: 1.142922, bias2: 0.223280131816864, variance: 0.91964191198349\n",
      "Train size: [400] hidden size: [1491] trial: 31, train_loss: 0.007909, test loss: 1.141985, bias2: 0.22237080335617065, variance: 0.9196143746376038\n",
      "Train size: [400] hidden size: [1491] trial: 32, train_loss: 0.007913, test loss: 1.146518, bias2: 0.22293663024902344, variance: 0.9235818386077881\n",
      "Train size: [400] hidden size: [1491] trial: 33, train_loss: 0.007955, test loss: 1.149561, bias2: 0.22081804275512695, variance: 0.9287432432174683\n",
      "Train size: [400] hidden size: [1491] trial: 34, train_loss: 0.007950, test loss: 1.147101, bias2: 0.21804416179656982, variance: 0.9290566444396973\n",
      "Train size: [400] hidden size: [1491] trial: 35, train_loss: 0.007988, test loss: 1.145776, bias2: 0.21649301052093506, variance: 0.9292826652526855\n",
      "Train size: [400] hidden size: [1491] trial: 36, train_loss: 0.007993, test loss: 1.147316, bias2: 0.2181825041770935, variance: 0.9291333556175232\n",
      "Train size: [400] hidden size: [1491] trial: 37, train_loss: 0.007993, test loss: 1.147172, bias2: 0.21844011545181274, variance: 0.9287316203117371\n",
      "Train size: [400] hidden size: [1491] trial: 38, train_loss: 0.007960, test loss: 1.144957, bias2: 0.21877098083496094, variance: 0.9261859655380249\n",
      "Train size: [400] hidden size: [1491] trial: 39, train_loss: 0.007971, test loss: 1.142307, bias2: 0.2169169783592224, variance: 0.9253895878791809\n",
      "Train size: [400] hidden size: [1491] trial: 40, train_loss: 0.007942, test loss: 1.139258, bias2: 0.2157920002937317, variance: 0.9234657883644104\n",
      "Train size: [400] hidden size: [1491] trial: 41, train_loss: 0.007927, test loss: 1.138899, bias2: 0.21584153175354004, variance: 0.9230576753616333\n",
      "Train size: [400] hidden size: [1491] trial: 42, train_loss: 0.007915, test loss: 1.136236, bias2: 0.21448004245758057, variance: 0.9217557907104492\n",
      "Train size: [400] hidden size: [1491] trial: 43, train_loss: 0.007878, test loss: 1.134624, bias2: 0.21589744091033936, variance: 0.9187263250350952\n",
      "Train size: [400] hidden size: [1491] trial: 44, train_loss: 0.007847, test loss: 1.135483, bias2: 0.2159450650215149, variance: 0.9195376038551331\n",
      "Train size: [400] hidden size: [1491] trial: 45, train_loss: 0.007857, test loss: 1.136821, bias2: 0.21576547622680664, variance: 0.9210550785064697\n",
      "Train size: [400] hidden size: [1491] trial: 46, train_loss: 0.007878, test loss: 1.135828, bias2: 0.21441417932510376, variance: 0.9214140772819519\n",
      "Train size: [400] hidden size: [1491] trial: 47, train_loss: 0.007855, test loss: 1.136320, bias2: 0.2149428129196167, variance: 0.9213771820068359\n",
      "Train size: [400] hidden size: [1491] trial: 48, train_loss: 0.007816, test loss: 1.134254, bias2: 0.21453386545181274, variance: 0.919720470905304\n",
      "Train size: [400] hidden size: [1491] trial: 49, train_loss: 0.007827, test loss: 1.132772, bias2: 0.21371304988861084, variance: 0.9190585613250732\n",
      "##################################################\n",
      "Train size: [400] hidden size: [1717] trial: 0, train_loss: 0.007095, test loss: 1.022767, bias2: 1.0227673053741455, variance: -7.785095901269301e-10\n",
      "Train size: [400] hidden size: [1717] trial: 1, train_loss: 0.007024, test loss: 1.135299, bias2: 0.687952995300293, variance: 0.4473459720611572\n",
      "Train size: [400] hidden size: [1717] trial: 2, train_loss: 0.006762, test loss: 1.076648, bias2: 0.5122439861297607, variance: 0.564403772354126\n",
      "Train size: [400] hidden size: [1717] trial: 3, train_loss: 0.006671, test loss: 1.067069, bias2: 0.437807559967041, variance: 0.6292610168457031\n",
      "Train size: [400] hidden size: [1717] trial: 4, train_loss: 0.006657, test loss: 1.066506, bias2: 0.38812994956970215, variance: 0.6783759593963623\n",
      "Train size: [400] hidden size: [1717] trial: 5, train_loss: 0.006671, test loss: 1.081409, bias2: 0.3756747245788574, variance: 0.7057344913482666\n",
      "Train size: [400] hidden size: [1717] trial: 6, train_loss: 0.006870, test loss: 1.074587, bias2: 0.3492676615715027, variance: 0.7253198027610779\n",
      "Train size: [400] hidden size: [1717] trial: 7, train_loss: 0.006880, test loss: 1.064854, bias2: 0.3231431245803833, variance: 0.7417105436325073\n",
      "Train size: [400] hidden size: [1717] trial: 8, train_loss: 0.006785, test loss: 1.055724, bias2: 0.3100854158401489, variance: 0.7456381320953369\n",
      "Train size: [400] hidden size: [1717] trial: 9, train_loss: 0.006848, test loss: 1.063645, bias2: 0.2998082637786865, variance: 0.7638365030288696\n",
      "Train size: [400] hidden size: [1717] trial: 10, train_loss: 0.006766, test loss: 1.067441, bias2: 0.29184961318969727, variance: 0.7755918502807617\n",
      "Train size: [400] hidden size: [1717] trial: 11, train_loss: 0.006908, test loss: 1.072391, bias2: 0.2820255160331726, variance: 0.7903653979301453\n",
      "Train size: [400] hidden size: [1717] trial: 12, train_loss: 0.006962, test loss: 1.083737, bias2: 0.27175086736679077, variance: 0.8119860291481018\n",
      "Train size: [400] hidden size: [1717] trial: 13, train_loss: 0.007017, test loss: 1.089158, bias2: 0.27342450618743896, variance: 0.8157336711883545\n",
      "Train size: [400] hidden size: [1717] trial: 14, train_loss: 0.007078, test loss: 1.099734, bias2: 0.2703566551208496, variance: 0.8293770551681519\n",
      "Train size: [400] hidden size: [1717] trial: 15, train_loss: 0.007116, test loss: 1.095447, bias2: 0.263846755027771, variance: 0.8316007852554321\n",
      "Train size: [400] hidden size: [1717] trial: 16, train_loss: 0.007141, test loss: 1.094089, bias2: 0.26016390323638916, variance: 0.8339248895645142\n",
      "Train size: [400] hidden size: [1717] trial: 17, train_loss: 0.007192, test loss: 1.089776, bias2: 0.2559012770652771, variance: 0.8338747620582581\n",
      "Train size: [400] hidden size: [1717] trial: 18, train_loss: 0.007161, test loss: 1.086448, bias2: 0.25317734479904175, variance: 0.8332710862159729\n",
      "Train size: [400] hidden size: [1717] trial: 19, train_loss: 0.007180, test loss: 1.085950, bias2: 0.25248533487319946, variance: 0.833465039730072\n",
      "Train size: [400] hidden size: [1717] trial: 20, train_loss: 0.007202, test loss: 1.082765, bias2: 0.24764055013656616, variance: 0.8351245522499084\n",
      "Train size: [400] hidden size: [1717] trial: 21, train_loss: 0.007199, test loss: 1.082155, bias2: 0.24698489904403687, variance: 0.8351700901985168\n",
      "Train size: [400] hidden size: [1717] trial: 22, train_loss: 0.007217, test loss: 1.079503, bias2: 0.24463403224945068, variance: 0.8348692655563354\n",
      "Train size: [400] hidden size: [1717] trial: 23, train_loss: 0.007211, test loss: 1.080874, bias2: 0.24215257167816162, variance: 0.8387218713760376\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [1717] trial: 24, train_loss: 0.007222, test loss: 1.079662, bias2: 0.23913949728012085, variance: 0.840522825717926\n",
      "Train size: [400] hidden size: [1717] trial: 25, train_loss: 0.007209, test loss: 1.080636, bias2: 0.23865240812301636, variance: 0.8419831395149231\n",
      "Train size: [400] hidden size: [1717] trial: 26, train_loss: 0.007177, test loss: 1.078350, bias2: 0.2372397780418396, variance: 0.8411100506782532\n",
      "Train size: [400] hidden size: [1717] trial: 27, train_loss: 0.007131, test loss: 1.076004, bias2: 0.23637133836746216, variance: 0.8396326899528503\n",
      "Train size: [400] hidden size: [1717] trial: 28, train_loss: 0.007152, test loss: 1.076515, bias2: 0.235440194606781, variance: 0.8410748839378357\n",
      "Train size: [400] hidden size: [1717] trial: 29, train_loss: 0.007172, test loss: 1.075982, bias2: 0.23444992303848267, variance: 0.8415316939353943\n",
      "Train size: [400] hidden size: [1717] trial: 30, train_loss: 0.007145, test loss: 1.071804, bias2: 0.2295580506324768, variance: 0.8422457575798035\n",
      "Train size: [400] hidden size: [1717] trial: 31, train_loss: 0.007101, test loss: 1.070624, bias2: 0.2296147346496582, variance: 0.8410090208053589\n",
      "Train size: [400] hidden size: [1717] trial: 32, train_loss: 0.007112, test loss: 1.069500, bias2: 0.22855883836746216, variance: 0.8409413695335388\n",
      "Train size: [400] hidden size: [1717] trial: 33, train_loss: 0.007117, test loss: 1.066111, bias2: 0.2251935601234436, variance: 0.8409175276756287\n",
      "Train size: [400] hidden size: [1717] trial: 34, train_loss: 0.007125, test loss: 1.065525, bias2: 0.2231677770614624, variance: 0.8423572778701782\n",
      "Train size: [400] hidden size: [1717] trial: 35, train_loss: 0.007138, test loss: 1.066601, bias2: 0.22228938341140747, variance: 0.8443112969398499\n",
      "Train size: [400] hidden size: [1717] trial: 36, train_loss: 0.007138, test loss: 1.067581, bias2: 0.22201275825500488, variance: 0.8455678224563599\n",
      "Train size: [400] hidden size: [1717] trial: 37, train_loss: 0.007133, test loss: 1.068363, bias2: 0.22036266326904297, variance: 0.8480000495910645\n",
      "Train size: [400] hidden size: [1717] trial: 38, train_loss: 0.007123, test loss: 1.065530, bias2: 0.21862918138504028, variance: 0.846900999546051\n",
      "Train size: [400] hidden size: [1717] trial: 39, train_loss: 0.007101, test loss: 1.065668, bias2: 0.2179579734802246, variance: 0.847710132598877\n",
      "Train size: [400] hidden size: [1717] trial: 40, train_loss: 0.007106, test loss: 1.065761, bias2: 0.21748924255371094, variance: 0.8482714891433716\n",
      "Train size: [400] hidden size: [1717] trial: 41, train_loss: 0.007088, test loss: 1.063274, bias2: 0.21532350778579712, variance: 0.8479506373405457\n",
      "Train size: [400] hidden size: [1717] trial: 42, train_loss: 0.007104, test loss: 1.064794, bias2: 0.21549499034881592, variance: 0.8492988348007202\n",
      "Train size: [400] hidden size: [1717] trial: 43, train_loss: 0.007085, test loss: 1.065301, bias2: 0.216461181640625, variance: 0.8488401174545288\n",
      "Train size: [400] hidden size: [1717] trial: 44, train_loss: 0.007090, test loss: 1.063166, bias2: 0.21525192260742188, variance: 0.847914457321167\n",
      "Train size: [400] hidden size: [1717] trial: 45, train_loss: 0.007075, test loss: 1.063287, bias2: 0.2161928415298462, variance: 0.8470937013626099\n",
      "Train size: [400] hidden size: [1717] trial: 46, train_loss: 0.007067, test loss: 1.063739, bias2: 0.21583420038223267, variance: 0.8479049801826477\n",
      "Train size: [400] hidden size: [1717] trial: 47, train_loss: 0.007074, test loss: 1.063080, bias2: 0.2154889702796936, variance: 0.8475908637046814\n",
      "Train size: [400] hidden size: [1717] trial: 48, train_loss: 0.007101, test loss: 1.065773, bias2: 0.21515381336212158, variance: 0.8506190776824951\n",
      "Train size: [400] hidden size: [1717] trial: 49, train_loss: 0.007102, test loss: 1.063604, bias2: 0.2133069634437561, variance: 0.8502973914146423\n",
      "##################################################\n",
      "Train size: [400] hidden size: [1977] trial: 0, train_loss: 0.007864, test loss: 1.060777, bias2: 1.060776710510254, variance: -3.1140383605077204e-09\n",
      "Train size: [400] hidden size: [1977] trial: 1, train_loss: 0.006762, test loss: 1.012950, bias2: 0.6107915639877319, variance: 0.40215811133384705\n",
      "Train size: [400] hidden size: [1977] trial: 2, train_loss: 0.007117, test loss: 1.002344, bias2: 0.4735792279243469, variance: 0.5287646651268005\n",
      "Train size: [400] hidden size: [1977] trial: 3, train_loss: 0.006924, test loss: 1.018156, bias2: 0.4214646816253662, variance: 0.5966916084289551\n",
      "Train size: [400] hidden size: [1977] trial: 4, train_loss: 0.006813, test loss: 1.036690, bias2: 0.38847821950912476, variance: 0.648211658000946\n",
      "Train size: [400] hidden size: [1977] trial: 5, train_loss: 0.006644, test loss: 1.048597, bias2: 0.3642991781234741, variance: 0.6842974424362183\n",
      "Train size: [400] hidden size: [1977] trial: 6, train_loss: 0.006614, test loss: 1.046932, bias2: 0.33841919898986816, variance: 0.7085126638412476\n",
      "Train size: [400] hidden size: [1977] trial: 7, train_loss: 0.006539, test loss: 1.064927, bias2: 0.33101266622543335, variance: 0.7339141964912415\n",
      "Train size: [400] hidden size: [1977] trial: 8, train_loss: 0.006495, test loss: 1.073218, bias2: 0.3270719647407532, variance: 0.746146023273468\n",
      "Train size: [400] hidden size: [1977] trial: 9, train_loss: 0.006623, test loss: 1.069395, bias2: 0.31184375286102295, variance: 0.7575511932373047\n",
      "Train size: [400] hidden size: [1977] trial: 10, train_loss: 0.006509, test loss: 1.070590, bias2: 0.30280929803848267, variance: 0.7677810788154602\n",
      "Train size: [400] hidden size: [1977] trial: 11, train_loss: 0.006572, test loss: 1.066332, bias2: 0.29342812299728394, variance: 0.7729039788246155\n",
      "Train size: [400] hidden size: [1977] trial: 12, train_loss: 0.006569, test loss: 1.066613, bias2: 0.2888203263282776, variance: 0.7777929902076721\n",
      "Train size: [400] hidden size: [1977] trial: 13, train_loss: 0.006538, test loss: 1.060789, bias2: 0.2803363800048828, variance: 0.7804527282714844\n",
      "Train size: [400] hidden size: [1977] trial: 14, train_loss: 0.006445, test loss: 1.057235, bias2: 0.2745552659034729, variance: 0.7826797366142273\n",
      "Train size: [400] hidden size: [1977] trial: 15, train_loss: 0.006426, test loss: 1.059110, bias2: 0.269787073135376, variance: 0.7893229722976685\n",
      "Train size: [400] hidden size: [1977] trial: 16, train_loss: 0.006402, test loss: 1.060374, bias2: 0.26912057399749756, variance: 0.7912529706954956\n",
      "Train size: [400] hidden size: [1977] trial: 17, train_loss: 0.006408, test loss: 1.054625, bias2: 0.26530492305755615, variance: 0.7893204689025879\n",
      "Train size: [400] hidden size: [1977] trial: 18, train_loss: 0.006447, test loss: 1.053498, bias2: 0.26112037897109985, variance: 0.7923771739006042\n",
      "Train size: [400] hidden size: [1977] trial: 19, train_loss: 0.006433, test loss: 1.058104, bias2: 0.25832831859588623, variance: 0.7997760772705078\n",
      "Train size: [400] hidden size: [1977] trial: 20, train_loss: 0.006422, test loss: 1.057525, bias2: 0.25284916162490845, variance: 0.8046761155128479\n",
      "Train size: [400] hidden size: [1977] trial: 21, train_loss: 0.006430, test loss: 1.054338, bias2: 0.24678945541381836, variance: 0.807548999786377\n",
      "Train size: [400] hidden size: [1977] trial: 22, train_loss: 0.006397, test loss: 1.048945, bias2: 0.24228549003601074, variance: 0.8066599369049072\n",
      "Train size: [400] hidden size: [1977] trial: 23, train_loss: 0.006394, test loss: 1.046554, bias2: 0.23988181352615356, variance: 0.8066720366477966\n",
      "Train size: [400] hidden size: [1977] trial: 24, train_loss: 0.006378, test loss: 1.045042, bias2: 0.2376684546470642, variance: 0.807373583316803\n",
      "Train size: [400] hidden size: [1977] trial: 25, train_loss: 0.006386, test loss: 1.039170, bias2: 0.23435109853744507, variance: 0.8048185706138611\n",
      "Train size: [400] hidden size: [1977] trial: 26, train_loss: 0.006389, test loss: 1.038558, bias2: 0.23274338245391846, variance: 0.8058141469955444\n",
      "Train size: [400] hidden size: [1977] trial: 27, train_loss: 0.006350, test loss: 1.041473, bias2: 0.23279684782028198, variance: 0.8086764216423035\n",
      "Train size: [400] hidden size: [1977] trial: 28, train_loss: 0.006344, test loss: 1.037214, bias2: 0.2308977246284485, variance: 0.8063166737556458\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [1977] trial: 29, train_loss: 0.006352, test loss: 1.036147, bias2: 0.22932714223861694, variance: 0.8068193793296814\n",
      "Train size: [400] hidden size: [1977] trial: 30, train_loss: 0.006376, test loss: 1.037814, bias2: 0.22910046577453613, variance: 0.8087130784988403\n",
      "Train size: [400] hidden size: [1977] trial: 31, train_loss: 0.006387, test loss: 1.037429, bias2: 0.22887617349624634, variance: 0.8085532784461975\n",
      "Train size: [400] hidden size: [1977] trial: 32, train_loss: 0.006359, test loss: 1.036687, bias2: 0.22872471809387207, variance: 0.8079627752304077\n",
      "Train size: [400] hidden size: [1977] trial: 33, train_loss: 0.006348, test loss: 1.036952, bias2: 0.2264612317085266, variance: 0.8104907870292664\n",
      "Train size: [400] hidden size: [1977] trial: 34, train_loss: 0.006328, test loss: 1.038472, bias2: 0.22663038969039917, variance: 0.8118419051170349\n",
      "Train size: [400] hidden size: [1977] trial: 35, train_loss: 0.006334, test loss: 1.035674, bias2: 0.22519606351852417, variance: 0.8104775547981262\n",
      "Train size: [400] hidden size: [1977] trial: 36, train_loss: 0.006358, test loss: 1.035184, bias2: 0.22352474927902222, variance: 0.8116595149040222\n",
      "Train size: [400] hidden size: [1977] trial: 37, train_loss: 0.006375, test loss: 1.033641, bias2: 0.22172856330871582, variance: 0.8119122982025146\n",
      "Train size: [400] hidden size: [1977] trial: 38, train_loss: 0.006389, test loss: 1.032410, bias2: 0.22125029563903809, variance: 0.811159610748291\n",
      "Train size: [400] hidden size: [1977] trial: 39, train_loss: 0.006343, test loss: 1.029482, bias2: 0.21988511085510254, variance: 0.8095966577529907\n",
      "Train size: [400] hidden size: [1977] trial: 40, train_loss: 0.006341, test loss: 1.029047, bias2: 0.21819329261779785, variance: 0.8108537197113037\n",
      "Train size: [400] hidden size: [1977] trial: 41, train_loss: 0.006351, test loss: 1.026859, bias2: 0.21480494737625122, variance: 0.8120543360710144\n",
      "Train size: [400] hidden size: [1977] trial: 42, train_loss: 0.006351, test loss: 1.026252, bias2: 0.2139667272567749, variance: 0.8122854232788086\n",
      "Train size: [400] hidden size: [1977] trial: 43, train_loss: 0.006345, test loss: 1.026238, bias2: 0.2125682830810547, variance: 0.8136695623397827\n",
      "Train size: [400] hidden size: [1977] trial: 44, train_loss: 0.006377, test loss: 1.028877, bias2: 0.21387797594070435, variance: 0.8149986863136292\n",
      "Train size: [400] hidden size: [1977] trial: 45, train_loss: 0.006386, test loss: 1.027272, bias2: 0.21371740102767944, variance: 0.8135544657707214\n",
      "Train size: [400] hidden size: [1977] trial: 46, train_loss: 0.006385, test loss: 1.027284, bias2: 0.2147815227508545, variance: 0.8125028610229492\n",
      "Train size: [400] hidden size: [1977] trial: 47, train_loss: 0.006388, test loss: 1.027667, bias2: 0.21403831243515015, variance: 0.813628613948822\n",
      "Train size: [400] hidden size: [1977] trial: 48, train_loss: 0.006410, test loss: 1.027100, bias2: 0.21290266513824463, variance: 0.8141971826553345\n",
      "Train size: [400] hidden size: [1977] trial: 49, train_loss: 0.006399, test loss: 1.025241, bias2: 0.2128848433494568, variance: 0.8123565316200256\n",
      "##################################################\n",
      "Train size: [400] hidden size: [2276] trial: 0, train_loss: 0.006508, test loss: 0.917473, bias2: 0.9174726605415344, variance: 4.6710577628061856e-09\n",
      "Train size: [400] hidden size: [2276] trial: 1, train_loss: 0.006388, test loss: 0.882914, bias2: 0.5111309289932251, variance: 0.3717826008796692\n",
      "Train size: [400] hidden size: [2276] trial: 2, train_loss: 0.006395, test loss: 0.976242, bias2: 0.45388245582580566, variance: 0.5223598480224609\n",
      "Train size: [400] hidden size: [2276] trial: 3, train_loss: 0.006055, test loss: 0.959587, bias2: 0.38193076848983765, variance: 0.5776564478874207\n",
      "Train size: [400] hidden size: [2276] trial: 4, train_loss: 0.006263, test loss: 0.948121, bias2: 0.35540395975112915, variance: 0.5927172303199768\n",
      "Train size: [400] hidden size: [2276] trial: 5, train_loss: 0.006170, test loss: 0.947550, bias2: 0.32845956087112427, variance: 0.6190900206565857\n",
      "Train size: [400] hidden size: [2276] trial: 6, train_loss: 0.006084, test loss: 0.933384, bias2: 0.2990940809249878, variance: 0.6342900991439819\n",
      "Train size: [400] hidden size: [2276] trial: 7, train_loss: 0.005954, test loss: 0.924225, bias2: 0.2848835587501526, variance: 0.6393409967422485\n",
      "Train size: [400] hidden size: [2276] trial: 8, train_loss: 0.005862, test loss: 0.933434, bias2: 0.2747870683670044, variance: 0.6586474180221558\n",
      "Train size: [400] hidden size: [2276] trial: 9, train_loss: 0.005743, test loss: 0.928775, bias2: 0.26760387420654297, variance: 0.6611712574958801\n",
      "Train size: [400] hidden size: [2276] trial: 10, train_loss: 0.005792, test loss: 0.937196, bias2: 0.2660003900527954, variance: 0.6711961030960083\n",
      "Train size: [400] hidden size: [2276] trial: 11, train_loss: 0.005741, test loss: 0.944579, bias2: 0.2643952965736389, variance: 0.680183470249176\n",
      "Train size: [400] hidden size: [2276] trial: 12, train_loss: 0.005732, test loss: 0.951386, bias2: 0.25581157207489014, variance: 0.6955747008323669\n",
      "Train size: [400] hidden size: [2276] trial: 13, train_loss: 0.005811, test loss: 0.963174, bias2: 0.2579876184463501, variance: 0.7051864862442017\n",
      "Train size: [400] hidden size: [2276] trial: 14, train_loss: 0.005733, test loss: 0.960929, bias2: 0.25927305221557617, variance: 0.7016558051109314\n",
      "Train size: [400] hidden size: [2276] trial: 15, train_loss: 0.005741, test loss: 0.959034, bias2: 0.25356775522232056, variance: 0.7054663300514221\n",
      "Train size: [400] hidden size: [2276] trial: 16, train_loss: 0.005756, test loss: 0.961915, bias2: 0.25147587060928345, variance: 0.7104395627975464\n",
      "Train size: [400] hidden size: [2276] trial: 17, train_loss: 0.005790, test loss: 0.955769, bias2: 0.24692398309707642, variance: 0.7088453769683838\n",
      "Train size: [400] hidden size: [2276] trial: 18, train_loss: 0.005779, test loss: 0.956707, bias2: 0.24424004554748535, variance: 0.7124668955802917\n",
      "Train size: [400] hidden size: [2276] trial: 19, train_loss: 0.005760, test loss: 0.957785, bias2: 0.24104058742523193, variance: 0.7167440056800842\n",
      "Train size: [400] hidden size: [2276] trial: 20, train_loss: 0.005782, test loss: 0.958827, bias2: 0.23532402515411377, variance: 0.7235025763511658\n",
      "Train size: [400] hidden size: [2276] trial: 21, train_loss: 0.005762, test loss: 0.960542, bias2: 0.23586660623550415, variance: 0.7246749401092529\n",
      "Train size: [400] hidden size: [2276] trial: 22, train_loss: 0.005777, test loss: 0.962047, bias2: 0.23359394073486328, variance: 0.7284533381462097\n",
      "Train size: [400] hidden size: [2276] trial: 23, train_loss: 0.005779, test loss: 0.958275, bias2: 0.23139727115631104, variance: 0.7268779873847961\n",
      "Train size: [400] hidden size: [2276] trial: 24, train_loss: 0.005807, test loss: 0.959330, bias2: 0.22940248250961304, variance: 0.7299274206161499\n",
      "Train size: [400] hidden size: [2276] trial: 25, train_loss: 0.005827, test loss: 0.965736, bias2: 0.22715377807617188, variance: 0.7385823130607605\n",
      "Train size: [400] hidden size: [2276] trial: 26, train_loss: 0.005787, test loss: 0.965177, bias2: 0.22661644220352173, variance: 0.7385604381561279\n",
      "Train size: [400] hidden size: [2276] trial: 27, train_loss: 0.005828, test loss: 0.968177, bias2: 0.22858768701553345, variance: 0.7395892143249512\n",
      "Train size: [400] hidden size: [2276] trial: 28, train_loss: 0.005835, test loss: 0.973324, bias2: 0.22878164052963257, variance: 0.7445420026779175\n",
      "Train size: [400] hidden size: [2276] trial: 29, train_loss: 0.005824, test loss: 0.970310, bias2: 0.22838616371154785, variance: 0.741923987865448\n",
      "Train size: [400] hidden size: [2276] trial: 30, train_loss: 0.005795, test loss: 0.969965, bias2: 0.22779196500778198, variance: 0.7421730160713196\n",
      "Train size: [400] hidden size: [2276] trial: 31, train_loss: 0.005799, test loss: 0.968974, bias2: 0.22698014974594116, variance: 0.7419939637184143\n",
      "Train size: [400] hidden size: [2276] trial: 32, train_loss: 0.005797, test loss: 0.966961, bias2: 0.22619575262069702, variance: 0.7407654523849487\n",
      "Train size: [400] hidden size: [2276] trial: 33, train_loss: 0.005838, test loss: 0.965779, bias2: 0.2235339879989624, variance: 0.7422454953193665\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [2276] trial: 34, train_loss: 0.005829, test loss: 0.963979, bias2: 0.22325527667999268, variance: 0.7407239675521851\n",
      "Train size: [400] hidden size: [2276] trial: 35, train_loss: 0.005831, test loss: 0.965626, bias2: 0.222834050655365, variance: 0.7427922487258911\n",
      "Train size: [400] hidden size: [2276] trial: 36, train_loss: 0.005836, test loss: 0.967258, bias2: 0.22429031133651733, variance: 0.7429677248001099\n",
      "Train size: [400] hidden size: [2276] trial: 37, train_loss: 0.005873, test loss: 0.968136, bias2: 0.2240138053894043, variance: 0.7441226243972778\n",
      "Train size: [400] hidden size: [2276] trial: 38, train_loss: 0.005858, test loss: 0.967884, bias2: 0.22429251670837402, variance: 0.7435917854309082\n",
      "Train size: [400] hidden size: [2276] trial: 39, train_loss: 0.005840, test loss: 0.966619, bias2: 0.22336548566818237, variance: 0.7432532906532288\n",
      "Train size: [400] hidden size: [2276] trial: 40, train_loss: 0.005856, test loss: 0.967254, bias2: 0.22417181730270386, variance: 0.7430824637413025\n",
      "Train size: [400] hidden size: [2276] trial: 41, train_loss: 0.005854, test loss: 0.966105, bias2: 0.22331565618515015, variance: 0.7427898049354553\n",
      "Train size: [400] hidden size: [2276] trial: 42, train_loss: 0.005896, test loss: 0.966985, bias2: 0.22224318981170654, variance: 0.7447419166564941\n",
      "Train size: [400] hidden size: [2276] trial: 43, train_loss: 0.005914, test loss: 0.968048, bias2: 0.2225465178489685, variance: 0.7455011606216431\n",
      "Train size: [400] hidden size: [2276] trial: 44, train_loss: 0.005918, test loss: 0.966600, bias2: 0.22118037939071655, variance: 0.7454198002815247\n",
      "Train size: [400] hidden size: [2276] trial: 45, train_loss: 0.005914, test loss: 0.964810, bias2: 0.21965986490249634, variance: 0.7451499700546265\n",
      "Train size: [400] hidden size: [2276] trial: 46, train_loss: 0.005908, test loss: 0.963480, bias2: 0.2186659574508667, variance: 0.7448145151138306\n",
      "Train size: [400] hidden size: [2276] trial: 47, train_loss: 0.005920, test loss: 0.965929, bias2: 0.2190750241279602, variance: 0.7468544840812683\n",
      "Train size: [400] hidden size: [2276] trial: 48, train_loss: 0.005939, test loss: 0.966848, bias2: 0.21778464317321777, variance: 0.7490634322166443\n",
      "Train size: [400] hidden size: [2276] trial: 49, train_loss: 0.005940, test loss: 0.964842, bias2: 0.21701645851135254, variance: 0.7478253245353699\n",
      "##################################################\n",
      "Train size: [400] hidden size: [2621] trial: 0, train_loss: 0.004792, test loss: 0.892867, bias2: 0.8928669095039368, variance: -7.785095901269301e-10\n",
      "Train size: [400] hidden size: [2621] trial: 1, train_loss: 0.005185, test loss: 0.907967, bias2: 0.5891366004943848, variance: 0.31883034110069275\n",
      "Train size: [400] hidden size: [2621] trial: 2, train_loss: 0.005403, test loss: 0.884195, bias2: 0.43673044443130493, variance: 0.44746488332748413\n",
      "Train size: [400] hidden size: [2621] trial: 3, train_loss: 0.005487, test loss: 0.887098, bias2: 0.3810923099517822, variance: 0.5060060620307922\n",
      "Train size: [400] hidden size: [2621] trial: 4, train_loss: 0.005484, test loss: 0.886807, bias2: 0.3458479046821594, variance: 0.5409590005874634\n",
      "Train size: [400] hidden size: [2621] trial: 5, train_loss: 0.005699, test loss: 0.896267, bias2: 0.32242143154144287, variance: 0.5738450884819031\n",
      "Train size: [400] hidden size: [2621] trial: 6, train_loss: 0.005735, test loss: 0.902021, bias2: 0.3099885582923889, variance: 0.5920319557189941\n",
      "Train size: [400] hidden size: [2621] trial: 7, train_loss: 0.005648, test loss: 0.903983, bias2: 0.29272621870040894, variance: 0.6112563610076904\n",
      "Train size: [400] hidden size: [2621] trial: 8, train_loss: 0.005720, test loss: 0.911292, bias2: 0.2862577438354492, variance: 0.6250343322753906\n",
      "Train size: [400] hidden size: [2621] trial: 9, train_loss: 0.005699, test loss: 0.907773, bias2: 0.2754673957824707, variance: 0.6323057413101196\n",
      "Train size: [400] hidden size: [2621] trial: 10, train_loss: 0.005629, test loss: 0.899884, bias2: 0.26690417528152466, variance: 0.6329799294471741\n",
      "Train size: [400] hidden size: [2621] trial: 11, train_loss: 0.005662, test loss: 0.902352, bias2: 0.2632942795753479, variance: 0.6390580534934998\n",
      "Train size: [400] hidden size: [2621] trial: 12, train_loss: 0.005663, test loss: 0.904498, bias2: 0.259726881980896, variance: 0.6447710990905762\n",
      "Train size: [400] hidden size: [2621] trial: 13, train_loss: 0.005650, test loss: 0.901856, bias2: 0.25734788179397583, variance: 0.6445086002349854\n",
      "Train size: [400] hidden size: [2621] trial: 14, train_loss: 0.005682, test loss: 0.903864, bias2: 0.2505044937133789, variance: 0.653359591960907\n",
      "Train size: [400] hidden size: [2621] trial: 15, train_loss: 0.005665, test loss: 0.906015, bias2: 0.24808651208877563, variance: 0.6579288244247437\n",
      "Train size: [400] hidden size: [2621] trial: 16, train_loss: 0.005637, test loss: 0.908517, bias2: 0.2419884204864502, variance: 0.6665287017822266\n",
      "Train size: [400] hidden size: [2621] trial: 17, train_loss: 0.005656, test loss: 0.904681, bias2: 0.23721814155578613, variance: 0.667462944984436\n",
      "Train size: [400] hidden size: [2621] trial: 18, train_loss: 0.005616, test loss: 0.910438, bias2: 0.2389879822731018, variance: 0.6714503765106201\n",
      "Train size: [400] hidden size: [2621] trial: 19, train_loss: 0.005597, test loss: 0.910259, bias2: 0.23905980587005615, variance: 0.6711995005607605\n",
      "Train size: [400] hidden size: [2621] trial: 20, train_loss: 0.005572, test loss: 0.910729, bias2: 0.2367430329322815, variance: 0.6739863157272339\n",
      "Train size: [400] hidden size: [2621] trial: 21, train_loss: 0.005609, test loss: 0.911455, bias2: 0.2329694628715515, variance: 0.6784851551055908\n",
      "Train size: [400] hidden size: [2621] trial: 22, train_loss: 0.005640, test loss: 0.915129, bias2: 0.23112422227859497, variance: 0.6840046048164368\n",
      "Train size: [400] hidden size: [2621] trial: 23, train_loss: 0.005627, test loss: 0.912011, bias2: 0.22821086645126343, variance: 0.683800458908081\n",
      "Train size: [400] hidden size: [2621] trial: 24, train_loss: 0.005634, test loss: 0.910215, bias2: 0.22763538360595703, variance: 0.6825792789459229\n",
      "Train size: [400] hidden size: [2621] trial: 25, train_loss: 0.005619, test loss: 0.914064, bias2: 0.22646301984786987, variance: 0.6876009702682495\n",
      "Train size: [400] hidden size: [2621] trial: 26, train_loss: 0.005614, test loss: 0.916884, bias2: 0.2266574501991272, variance: 0.6902263760566711\n",
      "Train size: [400] hidden size: [2621] trial: 27, train_loss: 0.005579, test loss: 0.913900, bias2: 0.2258446216583252, variance: 0.6880549788475037\n",
      "Train size: [400] hidden size: [2621] trial: 28, train_loss: 0.005602, test loss: 0.909091, bias2: 0.22182339429855347, variance: 0.6872673034667969\n",
      "Train size: [400] hidden size: [2621] trial: 29, train_loss: 0.005590, test loss: 0.907562, bias2: 0.22132772207260132, variance: 0.6862341165542603\n",
      "Train size: [400] hidden size: [2621] trial: 30, train_loss: 0.005564, test loss: 0.910951, bias2: 0.22277748584747314, variance: 0.6881730556488037\n",
      "Train size: [400] hidden size: [2621] trial: 31, train_loss: 0.005568, test loss: 0.912994, bias2: 0.22231841087341309, variance: 0.690675675868988\n",
      "Train size: [400] hidden size: [2621] trial: 32, train_loss: 0.005574, test loss: 0.910881, bias2: 0.21994906663894653, variance: 0.6909319162368774\n",
      "Train size: [400] hidden size: [2621] trial: 33, train_loss: 0.005605, test loss: 0.917787, bias2: 0.22034329175949097, variance: 0.6974441409111023\n",
      "Train size: [400] hidden size: [2621] trial: 34, train_loss: 0.005585, test loss: 0.917292, bias2: 0.2197049856185913, variance: 0.6975873112678528\n",
      "Train size: [400] hidden size: [2621] trial: 35, train_loss: 0.005596, test loss: 0.915942, bias2: 0.21851998567581177, variance: 0.6974220871925354\n",
      "Train size: [400] hidden size: [2621] trial: 36, train_loss: 0.005583, test loss: 0.910093, bias2: 0.2151278257369995, variance: 0.6949649453163147\n",
      "Train size: [400] hidden size: [2621] trial: 37, train_loss: 0.005584, test loss: 0.911434, bias2: 0.21515798568725586, variance: 0.6962761282920837\n",
      "Train size: [400] hidden size: [2621] trial: 38, train_loss: 0.005590, test loss: 0.911466, bias2: 0.21393930912017822, variance: 0.6975268125534058\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [2621] trial: 39, train_loss: 0.005577, test loss: 0.911792, bias2: 0.2122032642364502, variance: 0.6995883584022522\n",
      "Train size: [400] hidden size: [2621] trial: 40, train_loss: 0.005597, test loss: 0.911634, bias2: 0.2108049988746643, variance: 0.700829029083252\n",
      "Train size: [400] hidden size: [2621] trial: 41, train_loss: 0.005585, test loss: 0.911689, bias2: 0.20977210998535156, variance: 0.7019168138504028\n",
      "Train size: [400] hidden size: [2621] trial: 42, train_loss: 0.005595, test loss: 0.913984, bias2: 0.20958423614501953, variance: 0.7043996453285217\n",
      "Train size: [400] hidden size: [2621] trial: 43, train_loss: 0.005597, test loss: 0.916324, bias2: 0.21027636528015137, variance: 0.7060472965240479\n",
      "Train size: [400] hidden size: [2621] trial: 44, train_loss: 0.005614, test loss: 0.915319, bias2: 0.20876240730285645, variance: 0.7065569758415222\n",
      "Train size: [400] hidden size: [2621] trial: 45, train_loss: 0.005597, test loss: 0.915797, bias2: 0.20988702774047852, variance: 0.705909788608551\n",
      "Train size: [400] hidden size: [2621] trial: 46, train_loss: 0.005593, test loss: 0.918259, bias2: 0.20989000797271729, variance: 0.7083694338798523\n",
      "Train size: [400] hidden size: [2621] trial: 47, train_loss: 0.005579, test loss: 0.920328, bias2: 0.2098039984703064, variance: 0.7105242013931274\n",
      "Train size: [400] hidden size: [2621] trial: 48, train_loss: 0.005586, test loss: 0.919047, bias2: 0.20899999141693115, variance: 0.7100465297698975\n",
      "Train size: [400] hidden size: [2621] trial: 49, train_loss: 0.005583, test loss: 0.919367, bias2: 0.20786690711975098, variance: 0.7115001082420349\n",
      "##################################################\n",
      "Train size: [400] hidden size: [3017] trial: 0, train_loss: 0.005400, test loss: 0.970473, bias2: 0.9704729914665222, variance: -4.6710577628061856e-09\n",
      "Train size: [400] hidden size: [3017] trial: 1, train_loss: 0.005118, test loss: 0.894445, bias2: 0.5631489753723145, variance: 0.33129581809043884\n",
      "Train size: [400] hidden size: [3017] trial: 2, train_loss: 0.005376, test loss: 0.877921, bias2: 0.42302507162094116, variance: 0.4548960328102112\n",
      "Train size: [400] hidden size: [3017] trial: 3, train_loss: 0.005489, test loss: 0.879618, bias2: 0.36144566535949707, variance: 0.518172025680542\n",
      "Train size: [400] hidden size: [3017] trial: 4, train_loss: 0.005531, test loss: 0.875752, bias2: 0.3285905718803406, variance: 0.5471615791320801\n",
      "Train size: [400] hidden size: [3017] trial: 5, train_loss: 0.005627, test loss: 0.886925, bias2: 0.3196481466293335, variance: 0.5672772526741028\n",
      "Train size: [400] hidden size: [3017] trial: 6, train_loss: 0.005508, test loss: 0.887087, bias2: 0.29447275400161743, variance: 0.5926139950752258\n",
      "Train size: [400] hidden size: [3017] trial: 7, train_loss: 0.005436, test loss: 0.889326, bias2: 0.2880607843399048, variance: 0.6012649536132812\n",
      "Train size: [400] hidden size: [3017] trial: 8, train_loss: 0.005404, test loss: 0.890783, bias2: 0.28293561935424805, variance: 0.6078475713729858\n",
      "Train size: [400] hidden size: [3017] trial: 9, train_loss: 0.005388, test loss: 0.899375, bias2: 0.2745787501335144, variance: 0.624796450138092\n",
      "Train size: [400] hidden size: [3017] trial: 10, train_loss: 0.005396, test loss: 0.900913, bias2: 0.2667953372001648, variance: 0.6341180205345154\n",
      "Train size: [400] hidden size: [3017] trial: 11, train_loss: 0.005363, test loss: 0.907465, bias2: 0.26653605699539185, variance: 0.6409292221069336\n",
      "Train size: [400] hidden size: [3017] trial: 12, train_loss: 0.005346, test loss: 0.910192, bias2: 0.2596778869628906, variance: 0.6505143046379089\n",
      "Train size: [400] hidden size: [3017] trial: 13, train_loss: 0.005346, test loss: 0.901913, bias2: 0.24964451789855957, variance: 0.6522679924964905\n",
      "Train size: [400] hidden size: [3017] trial: 14, train_loss: 0.005363, test loss: 0.907353, bias2: 0.2506616711616516, variance: 0.6566910743713379\n",
      "Train size: [400] hidden size: [3017] trial: 15, train_loss: 0.005362, test loss: 0.910957, bias2: 0.24949228763580322, variance: 0.6614647507667542\n",
      "Train size: [400] hidden size: [3017] trial: 16, train_loss: 0.005368, test loss: 0.913316, bias2: 0.2492406964302063, variance: 0.6640757918357849\n",
      "Train size: [400] hidden size: [3017] trial: 17, train_loss: 0.005303, test loss: 0.914201, bias2: 0.2484152913093567, variance: 0.665785551071167\n",
      "Train size: [400] hidden size: [3017] trial: 18, train_loss: 0.005328, test loss: 0.906815, bias2: 0.24322688579559326, variance: 0.6635883450508118\n",
      "Train size: [400] hidden size: [3017] trial: 19, train_loss: 0.005337, test loss: 0.904075, bias2: 0.24001222848892212, variance: 0.664063036441803\n",
      "Train size: [400] hidden size: [3017] trial: 20, train_loss: 0.005270, test loss: 0.902279, bias2: 0.23955881595611572, variance: 0.6627200841903687\n",
      "Train size: [400] hidden size: [3017] trial: 21, train_loss: 0.005291, test loss: 0.909106, bias2: 0.2406497597694397, variance: 0.6684558987617493\n",
      "Train size: [400] hidden size: [3017] trial: 22, train_loss: 0.005273, test loss: 0.911105, bias2: 0.23982375860214233, variance: 0.6712814569473267\n",
      "Train size: [400] hidden size: [3017] trial: 23, train_loss: 0.005258, test loss: 0.912368, bias2: 0.2385619878768921, variance: 0.6738055348396301\n",
      "Train size: [400] hidden size: [3017] trial: 24, train_loss: 0.005243, test loss: 0.910235, bias2: 0.23470497131347656, variance: 0.6755300760269165\n",
      "Train size: [400] hidden size: [3017] trial: 25, train_loss: 0.005250, test loss: 0.909173, bias2: 0.23323696851730347, variance: 0.6759359836578369\n",
      "Train size: [400] hidden size: [3017] trial: 26, train_loss: 0.005250, test loss: 0.905675, bias2: 0.22776877880096436, variance: 0.6779063940048218\n",
      "Train size: [400] hidden size: [3017] trial: 27, train_loss: 0.005242, test loss: 0.908596, bias2: 0.22881120443344116, variance: 0.6797847151756287\n",
      "Train size: [400] hidden size: [3017] trial: 28, train_loss: 0.005246, test loss: 0.910166, bias2: 0.22804635763168335, variance: 0.6821193695068359\n",
      "Train size: [400] hidden size: [3017] trial: 29, train_loss: 0.005260, test loss: 0.907740, bias2: 0.22501450777053833, variance: 0.6827255487442017\n",
      "Train size: [400] hidden size: [3017] trial: 30, train_loss: 0.005240, test loss: 0.905436, bias2: 0.22524809837341309, variance: 0.6801881194114685\n",
      "Train size: [400] hidden size: [3017] trial: 31, train_loss: 0.005236, test loss: 0.907654, bias2: 0.22472327947616577, variance: 0.6829308867454529\n",
      "Train size: [400] hidden size: [3017] trial: 32, train_loss: 0.005229, test loss: 0.910069, bias2: 0.2255581021308899, variance: 0.6845105886459351\n",
      "Train size: [400] hidden size: [3017] trial: 33, train_loss: 0.005235, test loss: 0.909881, bias2: 0.2244110107421875, variance: 0.6854696869850159\n",
      "Train size: [400] hidden size: [3017] trial: 34, train_loss: 0.005238, test loss: 0.907944, bias2: 0.22159099578857422, variance: 0.6863531470298767\n",
      "Train size: [400] hidden size: [3017] trial: 35, train_loss: 0.005241, test loss: 0.904121, bias2: 0.22025763988494873, variance: 0.6838630437850952\n",
      "Train size: [400] hidden size: [3017] trial: 36, train_loss: 0.005270, test loss: 0.904553, bias2: 0.21964561939239502, variance: 0.6849073171615601\n",
      "Train size: [400] hidden size: [3017] trial: 37, train_loss: 0.005293, test loss: 0.907282, bias2: 0.21887236833572388, variance: 0.6884100437164307\n",
      "Train size: [400] hidden size: [3017] trial: 38, train_loss: 0.005290, test loss: 0.907774, bias2: 0.21813702583312988, variance: 0.6896370649337769\n",
      "Train size: [400] hidden size: [3017] trial: 39, train_loss: 0.005273, test loss: 0.907246, bias2: 0.21643322706222534, variance: 0.6908125281333923\n",
      "Train size: [400] hidden size: [3017] trial: 40, train_loss: 0.005273, test loss: 0.906458, bias2: 0.21538329124450684, variance: 0.6910752058029175\n",
      "Train size: [400] hidden size: [3017] trial: 41, train_loss: 0.005257, test loss: 0.905114, bias2: 0.21379238367080688, variance: 0.6913219094276428\n",
      "Train size: [400] hidden size: [3017] trial: 42, train_loss: 0.005234, test loss: 0.905384, bias2: 0.21530598402023315, variance: 0.6900777816772461\n",
      "Train size: [400] hidden size: [3017] trial: 43, train_loss: 0.005239, test loss: 0.905385, bias2: 0.21448594331741333, variance: 0.6908986568450928\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [3017] trial: 44, train_loss: 0.005226, test loss: 0.903214, bias2: 0.21326476335525513, variance: 0.6899495720863342\n",
      "Train size: [400] hidden size: [3017] trial: 45, train_loss: 0.005241, test loss: 0.903429, bias2: 0.21209436655044556, variance: 0.6913344860076904\n",
      "Train size: [400] hidden size: [3017] trial: 46, train_loss: 0.005246, test loss: 0.902892, bias2: 0.21169716119766235, variance: 0.6911951899528503\n",
      "Train size: [400] hidden size: [3017] trial: 47, train_loss: 0.005267, test loss: 0.903297, bias2: 0.21263259649276733, variance: 0.6906641721725464\n",
      "Train size: [400] hidden size: [3017] trial: 48, train_loss: 0.005259, test loss: 0.903422, bias2: 0.21180015802383423, variance: 0.6916216611862183\n",
      "Train size: [400] hidden size: [3017] trial: 49, train_loss: 0.005258, test loss: 0.902392, bias2: 0.21074634790420532, variance: 0.6916453242301941\n",
      "##################################################\n",
      "Train size: [400] hidden size: [3474] trial: 0, train_loss: 0.005101, test loss: 0.874166, bias2: 0.8741658926010132, variance: 7.785095901269301e-10\n",
      "Train size: [400] hidden size: [3474] trial: 1, train_loss: 0.005032, test loss: 0.895974, bias2: 0.5737583041191101, variance: 0.32221537828445435\n",
      "Train size: [400] hidden size: [3474] trial: 2, train_loss: 0.005218, test loss: 0.877166, bias2: 0.42265933752059937, variance: 0.4545062184333801\n",
      "Train size: [400] hidden size: [3474] trial: 3, train_loss: 0.005338, test loss: 0.899081, bias2: 0.37310564517974854, variance: 0.52597576379776\n",
      "Train size: [400] hidden size: [3474] trial: 4, train_loss: 0.005328, test loss: 0.903380, bias2: 0.34440886974334717, variance: 0.5589715242385864\n",
      "Train size: [400] hidden size: [3474] trial: 5, train_loss: 0.005371, test loss: 0.912835, bias2: 0.3303720951080322, variance: 0.5824633240699768\n",
      "Train size: [400] hidden size: [3474] trial: 6, train_loss: 0.005290, test loss: 0.914200, bias2: 0.3096957206726074, variance: 0.604503870010376\n",
      "Train size: [400] hidden size: [3474] trial: 7, train_loss: 0.005276, test loss: 0.915562, bias2: 0.2987157106399536, variance: 0.6168459057807922\n",
      "Train size: [400] hidden size: [3474] trial: 8, train_loss: 0.005153, test loss: 0.899542, bias2: 0.28526771068573, variance: 0.6142740845680237\n",
      "Train size: [400] hidden size: [3474] trial: 9, train_loss: 0.005150, test loss: 0.897787, bias2: 0.27775096893310547, variance: 0.6200357675552368\n",
      "Train size: [400] hidden size: [3474] trial: 10, train_loss: 0.005075, test loss: 0.891639, bias2: 0.27331143617630005, variance: 0.6183273196220398\n",
      "Train size: [400] hidden size: [3474] trial: 11, train_loss: 0.005061, test loss: 0.887830, bias2: 0.2675648331642151, variance: 0.6202647686004639\n",
      "Train size: [400] hidden size: [3474] trial: 12, train_loss: 0.005093, test loss: 0.888671, bias2: 0.2603483200073242, variance: 0.6283226013183594\n",
      "Train size: [400] hidden size: [3474] trial: 13, train_loss: 0.005005, test loss: 0.883349, bias2: 0.2554936408996582, variance: 0.627855122089386\n",
      "Train size: [400] hidden size: [3474] trial: 14, train_loss: 0.005017, test loss: 0.886312, bias2: 0.2577750086784363, variance: 0.6285366415977478\n",
      "Train size: [400] hidden size: [3474] trial: 15, train_loss: 0.005018, test loss: 0.884255, bias2: 0.2551429867744446, variance: 0.6291124820709229\n",
      "Train size: [400] hidden size: [3474] trial: 16, train_loss: 0.004988, test loss: 0.888292, bias2: 0.2537275552749634, variance: 0.6345645785331726\n",
      "Train size: [400] hidden size: [3474] trial: 17, train_loss: 0.004938, test loss: 0.883203, bias2: 0.25301486253738403, variance: 0.6301882266998291\n",
      "Train size: [400] hidden size: [3474] trial: 18, train_loss: 0.004940, test loss: 0.878862, bias2: 0.24906998872756958, variance: 0.6297914981842041\n",
      "Train size: [400] hidden size: [3474] trial: 19, train_loss: 0.004960, test loss: 0.879543, bias2: 0.24712717533111572, variance: 0.6324154138565063\n",
      "Train size: [400] hidden size: [3474] trial: 20, train_loss: 0.004971, test loss: 0.884704, bias2: 0.24443680047988892, variance: 0.6402668952941895\n",
      "Train size: [400] hidden size: [3474] trial: 21, train_loss: 0.004989, test loss: 0.884312, bias2: 0.23952889442443848, variance: 0.6447829604148865\n",
      "Train size: [400] hidden size: [3474] trial: 22, train_loss: 0.004977, test loss: 0.882072, bias2: 0.23814737796783447, variance: 0.643924355506897\n",
      "Train size: [400] hidden size: [3474] trial: 23, train_loss: 0.004992, test loss: 0.879381, bias2: 0.23812270164489746, variance: 0.641258180141449\n",
      "Train size: [400] hidden size: [3474] trial: 24, train_loss: 0.005010, test loss: 0.880304, bias2: 0.23599594831466675, variance: 0.6443076729774475\n",
      "Train size: [400] hidden size: [3474] trial: 25, train_loss: 0.005004, test loss: 0.878785, bias2: 0.23339825868606567, variance: 0.6453870534896851\n",
      "Train size: [400] hidden size: [3474] trial: 26, train_loss: 0.004993, test loss: 0.883029, bias2: 0.23574453592300415, variance: 0.6472849249839783\n",
      "Train size: [400] hidden size: [3474] trial: 27, train_loss: 0.004994, test loss: 0.882604, bias2: 0.2367534041404724, variance: 0.6458503603935242\n",
      "Train size: [400] hidden size: [3474] trial: 28, train_loss: 0.005017, test loss: 0.883332, bias2: 0.23624205589294434, variance: 0.6470897197723389\n",
      "Train size: [400] hidden size: [3474] trial: 29, train_loss: 0.004999, test loss: 0.883702, bias2: 0.2369059920310974, variance: 0.6467962861061096\n",
      "Train size: [400] hidden size: [3474] trial: 30, train_loss: 0.004999, test loss: 0.883157, bias2: 0.2353840470314026, variance: 0.6477732062339783\n",
      "Train size: [400] hidden size: [3474] trial: 31, train_loss: 0.004999, test loss: 0.880985, bias2: 0.23379498720169067, variance: 0.6471899151802063\n",
      "Train size: [400] hidden size: [3474] trial: 32, train_loss: 0.005005, test loss: 0.886149, bias2: 0.23401492834091187, variance: 0.6521339416503906\n",
      "Train size: [400] hidden size: [3474] trial: 33, train_loss: 0.004992, test loss: 0.884870, bias2: 0.23346149921417236, variance: 0.6514085531234741\n",
      "Train size: [400] hidden size: [3474] trial: 34, train_loss: 0.005026, test loss: 0.882827, bias2: 0.2293599247932434, variance: 0.6534674167633057\n",
      "Train size: [400] hidden size: [3474] trial: 35, train_loss: 0.005035, test loss: 0.883323, bias2: 0.22957473993301392, variance: 0.6537482738494873\n",
      "Train size: [400] hidden size: [3474] trial: 36, train_loss: 0.005044, test loss: 0.884315, bias2: 0.22926318645477295, variance: 0.6550523042678833\n",
      "Train size: [400] hidden size: [3474] trial: 37, train_loss: 0.005050, test loss: 0.883695, bias2: 0.22842484712600708, variance: 0.6552699208259583\n",
      "Train size: [400] hidden size: [3474] trial: 38, train_loss: 0.005068, test loss: 0.886294, bias2: 0.229023277759552, variance: 0.6572710871696472\n",
      "Train size: [400] hidden size: [3474] trial: 39, train_loss: 0.005073, test loss: 0.884124, bias2: 0.226732075214386, variance: 0.6573914289474487\n",
      "Train size: [400] hidden size: [3474] trial: 40, train_loss: 0.005065, test loss: 0.887869, bias2: 0.22840005159378052, variance: 0.6594687104225159\n",
      "Train size: [400] hidden size: [3474] trial: 41, train_loss: 0.005051, test loss: 0.888161, bias2: 0.2290116548538208, variance: 0.6591492295265198\n",
      "Train size: [400] hidden size: [3474] trial: 42, train_loss: 0.005024, test loss: 0.887295, bias2: 0.22809112071990967, variance: 0.6592043042182922\n",
      "Train size: [400] hidden size: [3474] trial: 43, train_loss: 0.005035, test loss: 0.887549, bias2: 0.2275238037109375, variance: 0.6600250005722046\n",
      "Train size: [400] hidden size: [3474] trial: 44, train_loss: 0.005016, test loss: 0.889266, bias2: 0.2285061478614807, variance: 0.6607603430747986\n",
      "Train size: [400] hidden size: [3474] trial: 45, train_loss: 0.004998, test loss: 0.889295, bias2: 0.228412926197052, variance: 0.660882294178009\n",
      "Train size: [400] hidden size: [3474] trial: 46, train_loss: 0.004987, test loss: 0.890245, bias2: 0.22950559854507446, variance: 0.6607394218444824\n",
      "Train size: [400] hidden size: [3474] trial: 47, train_loss: 0.004979, test loss: 0.889739, bias2: 0.23054319620132446, variance: 0.6591957211494446\n",
      "Train size: [400] hidden size: [3474] trial: 48, train_loss: 0.004994, test loss: 0.888096, bias2: 0.2290899157524109, variance: 0.6590061187744141\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [3474] trial: 49, train_loss: 0.005003, test loss: 0.887982, bias2: 0.22787117958068848, variance: 0.6601109504699707\n",
      "##################################################\n",
      "Train size: [400] hidden size: [4000] trial: 0, train_loss: 0.004450, test loss: 0.787712, bias2: 0.7877119779586792, variance: -3.1140383605077204e-09\n",
      "Train size: [400] hidden size: [4000] trial: 1, train_loss: 0.004698, test loss: 0.795181, bias2: 0.46125170588493347, variance: 0.33392950892448425\n",
      "Train size: [400] hidden size: [4000] trial: 2, train_loss: 0.004729, test loss: 0.813605, bias2: 0.3848872482776642, variance: 0.4287179410457611\n",
      "Train size: [400] hidden size: [4000] trial: 3, train_loss: 0.004575, test loss: 0.815271, bias2: 0.34198665618896484, variance: 0.4732838273048401\n",
      "Train size: [400] hidden size: [4000] trial: 4, train_loss: 0.004561, test loss: 0.825349, bias2: 0.30843520164489746, variance: 0.5169133543968201\n",
      "Train size: [400] hidden size: [4000] trial: 5, train_loss: 0.004611, test loss: 0.834503, bias2: 0.29103022813796997, variance: 0.5434725284576416\n",
      "Train size: [400] hidden size: [4000] trial: 6, train_loss: 0.004639, test loss: 0.842412, bias2: 0.2845608592033386, variance: 0.5578510165214539\n",
      "Train size: [400] hidden size: [4000] trial: 7, train_loss: 0.004695, test loss: 0.841448, bias2: 0.27100861072540283, variance: 0.5704396367073059\n",
      "Train size: [400] hidden size: [4000] trial: 8, train_loss: 0.004681, test loss: 0.847222, bias2: 0.2713988423347473, variance: 0.5758228302001953\n",
      "Train size: [400] hidden size: [4000] trial: 9, train_loss: 0.004645, test loss: 0.838545, bias2: 0.26540595293045044, variance: 0.5731394290924072\n",
      "Train size: [400] hidden size: [4000] trial: 10, train_loss: 0.004694, test loss: 0.842715, bias2: 0.2635040879249573, variance: 0.5792108774185181\n",
      "Train size: [400] hidden size: [4000] trial: 11, train_loss: 0.004658, test loss: 0.844216, bias2: 0.257715106010437, variance: 0.5865007638931274\n",
      "Train size: [400] hidden size: [4000] trial: 12, train_loss: 0.004651, test loss: 0.840086, bias2: 0.25364965200424194, variance: 0.5864365696907043\n",
      "Train size: [400] hidden size: [4000] trial: 13, train_loss: 0.004699, test loss: 0.845786, bias2: 0.2504991888999939, variance: 0.5952868461608887\n",
      "Train size: [400] hidden size: [4000] trial: 14, train_loss: 0.004717, test loss: 0.840993, bias2: 0.24431979656219482, variance: 0.5966736674308777\n",
      "Train size: [400] hidden size: [4000] trial: 15, train_loss: 0.004707, test loss: 0.848934, bias2: 0.24704653024673462, variance: 0.6018877625465393\n",
      "Train size: [400] hidden size: [4000] trial: 16, train_loss: 0.004726, test loss: 0.849367, bias2: 0.24418336153030396, variance: 0.6051837205886841\n",
      "Train size: [400] hidden size: [4000] trial: 17, train_loss: 0.004730, test loss: 0.847342, bias2: 0.24081045389175415, variance: 0.6065319180488586\n",
      "Train size: [400] hidden size: [4000] trial: 18, train_loss: 0.004726, test loss: 0.847939, bias2: 0.2384629249572754, variance: 0.6094759106636047\n",
      "Train size: [400] hidden size: [4000] trial: 19, train_loss: 0.004727, test loss: 0.854608, bias2: 0.23911726474761963, variance: 0.6154903769493103\n",
      "Train size: [400] hidden size: [4000] trial: 20, train_loss: 0.004735, test loss: 0.852042, bias2: 0.2359752655029297, variance: 0.6160669922828674\n",
      "Train size: [400] hidden size: [4000] trial: 21, train_loss: 0.004709, test loss: 0.855737, bias2: 0.2356250286102295, variance: 0.6201123595237732\n",
      "Train size: [400] hidden size: [4000] trial: 22, train_loss: 0.004728, test loss: 0.855598, bias2: 0.23150205612182617, variance: 0.6240963935852051\n",
      "Train size: [400] hidden size: [4000] trial: 23, train_loss: 0.004757, test loss: 0.857526, bias2: 0.23094326257705688, variance: 0.626582682132721\n",
      "Train size: [400] hidden size: [4000] trial: 24, train_loss: 0.004765, test loss: 0.857905, bias2: 0.23152881860733032, variance: 0.6263765096664429\n",
      "Train size: [400] hidden size: [4000] trial: 25, train_loss: 0.004744, test loss: 0.852866, bias2: 0.2289147973060608, variance: 0.6239513754844666\n",
      "Train size: [400] hidden size: [4000] trial: 26, train_loss: 0.004722, test loss: 0.849716, bias2: 0.2275775671005249, variance: 0.6221387386322021\n",
      "Train size: [400] hidden size: [4000] trial: 27, train_loss: 0.004751, test loss: 0.849033, bias2: 0.228249192237854, variance: 0.6207841038703918\n",
      "Train size: [400] hidden size: [4000] trial: 28, train_loss: 0.004729, test loss: 0.850465, bias2: 0.22846698760986328, variance: 0.621997594833374\n",
      "Train size: [400] hidden size: [4000] trial: 29, train_loss: 0.004738, test loss: 0.848498, bias2: 0.22665351629257202, variance: 0.6218449473381042\n",
      "Train size: [400] hidden size: [4000] trial: 30, train_loss: 0.004751, test loss: 0.849590, bias2: 0.22391432523727417, variance: 0.6256758570671082\n",
      "Train size: [400] hidden size: [4000] trial: 31, train_loss: 0.004745, test loss: 0.847765, bias2: 0.2223091721534729, variance: 0.6254557967185974\n",
      "Train size: [400] hidden size: [4000] trial: 32, train_loss: 0.004748, test loss: 0.845999, bias2: 0.22079098224639893, variance: 0.6252080202102661\n",
      "Train size: [400] hidden size: [4000] trial: 33, train_loss: 0.004727, test loss: 0.847403, bias2: 0.22073513269424438, variance: 0.6266683340072632\n",
      "Train size: [400] hidden size: [4000] trial: 34, train_loss: 0.004733, test loss: 0.848982, bias2: 0.2215394377708435, variance: 0.6274421215057373\n",
      "Train size: [400] hidden size: [4000] trial: 35, train_loss: 0.004756, test loss: 0.847188, bias2: 0.21921533346176147, variance: 0.6279729008674622\n",
      "Train size: [400] hidden size: [4000] trial: 36, train_loss: 0.004756, test loss: 0.848638, bias2: 0.21961814165115356, variance: 0.6290197968482971\n",
      "Train size: [400] hidden size: [4000] trial: 37, train_loss: 0.004754, test loss: 0.848976, bias2: 0.21978068351745605, variance: 0.6291951537132263\n",
      "Train size: [400] hidden size: [4000] trial: 38, train_loss: 0.004760, test loss: 0.850125, bias2: 0.21951472759246826, variance: 0.6306101083755493\n",
      "Train size: [400] hidden size: [4000] trial: 39, train_loss: 0.004767, test loss: 0.851189, bias2: 0.21978706121444702, variance: 0.6314019560813904\n",
      "Train size: [400] hidden size: [4000] trial: 40, train_loss: 0.004760, test loss: 0.850657, bias2: 0.21963518857955933, variance: 0.6310217380523682\n",
      "Train size: [400] hidden size: [4000] trial: 41, train_loss: 0.004747, test loss: 0.851453, bias2: 0.2210599184036255, variance: 0.6303926706314087\n",
      "Train size: [400] hidden size: [4000] trial: 42, train_loss: 0.004753, test loss: 0.853266, bias2: 0.2215813398361206, variance: 0.631684422492981\n",
      "Train size: [400] hidden size: [4000] trial: 43, train_loss: 0.004758, test loss: 0.853637, bias2: 0.2208315134048462, variance: 0.6328052282333374\n",
      "Train size: [400] hidden size: [4000] trial: 44, train_loss: 0.004763, test loss: 0.853653, bias2: 0.22129684686660767, variance: 0.6323559880256653\n",
      "Train size: [400] hidden size: [4000] trial: 45, train_loss: 0.004791, test loss: 0.855734, bias2: 0.22160625457763672, variance: 0.634127676486969\n",
      "Train size: [400] hidden size: [4000] trial: 46, train_loss: 0.004797, test loss: 0.855892, bias2: 0.22084271907806396, variance: 0.6350493431091309\n",
      "Train size: [400] hidden size: [4000] trial: 47, train_loss: 0.004784, test loss: 0.856445, bias2: 0.22196131944656372, variance: 0.634484052658081\n",
      "Train size: [400] hidden size: [4000] trial: 48, train_loss: 0.004785, test loss: 0.856748, bias2: 0.22177571058273315, variance: 0.6349727511405945\n",
      "Train size: [400] hidden size: [4000] trial: 49, train_loss: 0.004787, test loss: 0.855756, bias2: 0.22120040655136108, variance: 0.6345560550689697\n",
      "##################################################\n"
     ]
    }
   ],
   "source": [
    "run_exps_ridge(train_sizes, N_Ds, P_Ns, beta, test_size, feature_dim, num_classes, num_trials, coef,\n",
    "             outdir, 'singleNN_output.csv', SNR= SNR, K = 1, F_norm = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [4] trial: 0, train_loss: 1.630600, test loss: 1.003226, bias2: 1.003225564956665, variance: -1.2164212345733283e-11\n",
      "Train size: [400] hidden size: [4] trial: 1, train_loss: 1.802394, test loss: 1.002005, bias2: 0.9923384189605713, variance: 0.009666301310062408\n",
      "Train size: [400] hidden size: [4] trial: 2, train_loss: 1.864563, test loss: 1.002583, bias2: 0.9936860203742981, variance: 0.008897243067622185\n",
      "Train size: [400] hidden size: [4] trial: 3, train_loss: 1.929349, test loss: 1.002395, bias2: 0.9946908950805664, variance: 0.007703782059252262\n",
      "Train size: [400] hidden size: [4] trial: 4, train_loss: 1.956210, test loss: 1.001866, bias2: 0.9935965538024902, variance: 0.00826981384307146\n",
      "Train size: [400] hidden size: [4] trial: 5, train_loss: 1.937442, test loss: 1.001937, bias2: 0.9946917295455933, variance: 0.0072456346824765205\n",
      "Train size: [400] hidden size: [4] trial: 6, train_loss: 1.932405, test loss: 1.001688, bias2: 0.9937775731086731, variance: 0.007910416461527348\n",
      "Train size: [400] hidden size: [4] trial: 7, train_loss: 1.953005, test loss: 1.000559, bias2: 0.9925609827041626, variance: 0.007998223416507244\n",
      "Train size: [400] hidden size: [4] trial: 8, train_loss: 1.988441, test loss: 1.001150, bias2: 0.9927954077720642, variance: 0.00835495162755251\n",
      "Train size: [400] hidden size: [4] trial: 9, train_loss: 1.982568, test loss: 1.001517, bias2: 0.9931858777999878, variance: 0.00833072792738676\n",
      "Train size: [400] hidden size: [4] trial: 10, train_loss: 2.003981, test loss: 1.001103, bias2: 0.9933428168296814, variance: 0.0077605596743524075\n",
      "Train size: [400] hidden size: [4] trial: 11, train_loss: 1.995602, test loss: 1.000848, bias2: 0.992505669593811, variance: 0.008341917768120766\n",
      "Train size: [400] hidden size: [4] trial: 12, train_loss: 2.013407, test loss: 1.001073, bias2: 0.9931083917617798, variance: 0.007964401505887508\n",
      "Train size: [400] hidden size: [4] trial: 13, train_loss: 2.003433, test loss: 1.001176, bias2: 0.993719220161438, variance: 0.0074571240693330765\n",
      "Train size: [400] hidden size: [4] trial: 14, train_loss: 2.023701, test loss: 1.000791, bias2: 0.9935612678527832, variance: 0.007230035960674286\n",
      "Train size: [400] hidden size: [4] trial: 15, train_loss: 2.023123, test loss: 1.000752, bias2: 0.9937622547149658, variance: 0.0069893584586679935\n",
      "Train size: [400] hidden size: [4] trial: 16, train_loss: 2.014191, test loss: 1.000687, bias2: 0.9939798712730408, variance: 0.006707397289574146\n",
      "Train size: [400] hidden size: [4] trial: 17, train_loss: 2.007410, test loss: 1.000779, bias2: 0.9932584762573242, variance: 0.007520781364291906\n",
      "Train size: [400] hidden size: [4] trial: 18, train_loss: 2.001503, test loss: 1.001069, bias2: 0.9933061003684998, variance: 0.007763473782688379\n",
      "Train size: [400] hidden size: [4] trial: 19, train_loss: 2.005297, test loss: 1.001212, bias2: 0.993667721748352, variance: 0.007544287014752626\n",
      "Train size: [400] hidden size: [4] trial: 20, train_loss: 2.016188, test loss: 1.001157, bias2: 0.9939016699790955, variance: 0.0072548845782876015\n",
      "Train size: [400] hidden size: [4] trial: 21, train_loss: 2.008228, test loss: 1.000758, bias2: 0.9935482740402222, variance: 0.0072096348740160465\n",
      "Train size: [400] hidden size: [4] trial: 22, train_loss: 2.009523, test loss: 1.000293, bias2: 0.9927835464477539, variance: 0.007508967071771622\n",
      "Train size: [400] hidden size: [4] trial: 23, train_loss: 2.010439, test loss: 1.000588, bias2: 0.9932757616043091, variance: 0.007312065456062555\n",
      "Train size: [400] hidden size: [4] trial: 24, train_loss: 2.005076, test loss: 1.000911, bias2: 0.993344247341156, variance: 0.007566400337964296\n",
      "Train size: [400] hidden size: [4] trial: 25, train_loss: 1.998181, test loss: 1.000968, bias2: 0.9930058121681213, variance: 0.007961822673678398\n",
      "Train size: [400] hidden size: [4] trial: 26, train_loss: 2.016778, test loss: 1.000896, bias2: 0.9931406378746033, variance: 0.007755352184176445\n",
      "Train size: [400] hidden size: [4] trial: 27, train_loss: 2.009770, test loss: 1.000852, bias2: 0.9931496381759644, variance: 0.00770233292132616\n",
      "Train size: [400] hidden size: [4] trial: 28, train_loss: 2.013673, test loss: 1.001083, bias2: 0.993522047996521, variance: 0.00756119703873992\n",
      "Train size: [400] hidden size: [4] trial: 29, train_loss: 2.011256, test loss: 1.000726, bias2: 0.9931373000144958, variance: 0.007588341366499662\n",
      "Train size: [400] hidden size: [4] trial: 30, train_loss: 2.015973, test loss: 1.000766, bias2: 0.9933626055717468, variance: 0.007403676863759756\n",
      "Train size: [400] hidden size: [4] trial: 31, train_loss: 2.014593, test loss: 1.001000, bias2: 0.9934859871864319, variance: 0.007514286320656538\n",
      "Train size: [400] hidden size: [4] trial: 32, train_loss: 2.016266, test loss: 1.000818, bias2: 0.9933814406394958, variance: 0.007436939049512148\n",
      "Train size: [400] hidden size: [4] trial: 33, train_loss: 2.015421, test loss: 1.000880, bias2: 0.9935179948806763, variance: 0.00736191077157855\n",
      "Train size: [400] hidden size: [4] trial: 34, train_loss: 2.022330, test loss: 1.000656, bias2: 0.9932040572166443, variance: 0.00745173217728734\n",
      "Train size: [400] hidden size: [4] trial: 35, train_loss: 2.013542, test loss: 1.000923, bias2: 0.99312824010849, variance: 0.00779479555785656\n",
      "Train size: [400] hidden size: [4] trial: 36, train_loss: 2.005854, test loss: 1.001008, bias2: 0.9930939078330994, variance: 0.007914360612630844\n",
      "Train size: [400] hidden size: [4] trial: 37, train_loss: 2.013062, test loss: 1.000495, bias2: 0.9922645092010498, variance: 0.008229967206716537\n",
      "Train size: [400] hidden size: [4] trial: 38, train_loss: 2.011603, test loss: 1.000425, bias2: 0.9922972917556763, variance: 0.008127948269248009\n",
      "Train size: [400] hidden size: [4] trial: 39, train_loss: 2.011120, test loss: 1.000532, bias2: 0.9922595620155334, variance: 0.008272617124021053\n",
      "Train size: [400] hidden size: [4] trial: 40, train_loss: 2.008846, test loss: 1.000322, bias2: 0.9921809434890747, variance: 0.008141010999679565\n",
      "Train size: [400] hidden size: [4] trial: 41, train_loss: 2.008084, test loss: 1.000276, bias2: 0.9922510981559753, variance: 0.00802501942962408\n",
      "Train size: [400] hidden size: [4] trial: 42, train_loss: 2.007846, test loss: 1.000234, bias2: 0.9923752546310425, variance: 0.00785889383405447\n",
      "Train size: [400] hidden size: [4] trial: 43, train_loss: 2.008045, test loss: 1.000214, bias2: 0.9921913146972656, variance: 0.008022284135222435\n",
      "Train size: [400] hidden size: [4] trial: 44, train_loss: 2.014638, test loss: 1.000146, bias2: 0.9921815991401672, variance: 0.0079640569165349\n",
      "Train size: [400] hidden size: [4] trial: 45, train_loss: 2.011724, test loss: 1.000259, bias2: 0.9923267364501953, variance: 0.007932555861771107\n",
      "Train size: [400] hidden size: [4] trial: 46, train_loss: 2.015682, test loss: 1.000356, bias2: 0.9925603866577148, variance: 0.007795587182044983\n",
      "Train size: [400] hidden size: [4] trial: 47, train_loss: 2.012767, test loss: 1.000095, bias2: 0.9922470450401306, variance: 0.007847841829061508\n",
      "Train size: [400] hidden size: [4] trial: 48, train_loss: 2.013906, test loss: 1.000189, bias2: 0.9922134280204773, variance: 0.00797576829791069\n",
      "Train size: [400] hidden size: [4] trial: 49, train_loss: 2.011820, test loss: 1.000267, bias2: 0.9923949241638184, variance: 0.0078724455088377\n",
      "##################################################\n",
      "Train size: [400] hidden size: [5] trial: 0, train_loss: 2.163015, test loss: 1.003107, bias2: 1.0031073093414307, variance: 1.900658233230934e-12\n",
      "Train size: [400] hidden size: [5] trial: 1, train_loss: 2.166764, test loss: 0.999252, bias2: 0.9970583915710449, variance: 0.0021937384735792875\n",
      "Train size: [400] hidden size: [5] trial: 2, train_loss: 2.088593, test loss: 0.998408, bias2: 0.995141863822937, variance: 0.0032659515272825956\n",
      "Train size: [400] hidden size: [5] trial: 3, train_loss: 2.044385, test loss: 0.999077, bias2: 0.9946557283401489, variance: 0.004421252757310867\n",
      "Train size: [400] hidden size: [5] trial: 4, train_loss: 2.013848, test loss: 0.998860, bias2: 0.9934501647949219, variance: 0.005409687757492065\n",
      "Train size: [400] hidden size: [5] trial: 5, train_loss: 2.007152, test loss: 0.999048, bias2: 0.9939702749252319, variance: 0.005077247973531485\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [5] trial: 6, train_loss: 1.961397, test loss: 0.999780, bias2: 0.9950499534606934, variance: 0.00473041133955121\n",
      "Train size: [400] hidden size: [5] trial: 7, train_loss: 1.928584, test loss: 0.999985, bias2: 0.9952476024627686, variance: 0.00473711546510458\n",
      "Train size: [400] hidden size: [5] trial: 8, train_loss: 1.968790, test loss: 1.000265, bias2: 0.995919942855835, variance: 0.004345285706222057\n",
      "Train size: [400] hidden size: [5] trial: 9, train_loss: 1.975982, test loss: 0.999712, bias2: 0.9953842163085938, variance: 0.004327499773353338\n",
      "Train size: [400] hidden size: [5] trial: 10, train_loss: 1.985179, test loss: 0.999632, bias2: 0.9952229857444763, variance: 0.004409066867083311\n",
      "Train size: [400] hidden size: [5] trial: 11, train_loss: 1.968622, test loss: 1.001883, bias2: 0.9960998892784119, variance: 0.005782905034720898\n",
      "Train size: [400] hidden size: [5] trial: 12, train_loss: 1.962255, test loss: 1.002312, bias2: 0.9964066743850708, variance: 0.0059056063182652\n",
      "Train size: [400] hidden size: [5] trial: 13, train_loss: 1.953939, test loss: 1.002247, bias2: 0.99663245677948, variance: 0.005614171270281076\n",
      "Train size: [400] hidden size: [5] trial: 14, train_loss: 1.973990, test loss: 1.002108, bias2: 0.9959083199501038, variance: 0.006199910771101713\n",
      "Train size: [400] hidden size: [5] trial: 15, train_loss: 1.978813, test loss: 1.002113, bias2: 0.9955669045448303, variance: 0.006546451710164547\n",
      "Train size: [400] hidden size: [5] trial: 16, train_loss: 1.993289, test loss: 1.001965, bias2: 0.9954971075057983, variance: 0.006467460189014673\n",
      "Train size: [400] hidden size: [5] trial: 17, train_loss: 1.988321, test loss: 1.001859, bias2: 0.9954512715339661, variance: 0.006407777313143015\n",
      "Train size: [400] hidden size: [5] trial: 18, train_loss: 1.982954, test loss: 1.001865, bias2: 0.9957203269004822, variance: 0.006144682411104441\n",
      "Train size: [400] hidden size: [5] trial: 19, train_loss: 1.996540, test loss: 1.001858, bias2: 0.9958097338676453, variance: 0.00604839576408267\n",
      "Train size: [400] hidden size: [5] trial: 20, train_loss: 1.993281, test loss: 1.001869, bias2: 0.9959594011306763, variance: 0.005909175146371126\n",
      "Train size: [400] hidden size: [5] trial: 21, train_loss: 1.998174, test loss: 1.001598, bias2: 0.9953967928886414, variance: 0.006201234180480242\n",
      "Train size: [400] hidden size: [5] trial: 22, train_loss: 1.993363, test loss: 1.001145, bias2: 0.9950834512710571, variance: 0.006061655469238758\n",
      "Train size: [400] hidden size: [5] trial: 23, train_loss: 1.994128, test loss: 1.002699, bias2: 0.9945571422576904, variance: 0.008141759783029556\n",
      "Train size: [400] hidden size: [5] trial: 24, train_loss: 1.997531, test loss: 1.002452, bias2: 0.9945924282073975, variance: 0.007859347388148308\n",
      "Train size: [400] hidden size: [5] trial: 25, train_loss: 1.991474, test loss: 1.002433, bias2: 0.9948188662528992, variance: 0.007614444009959698\n",
      "Train size: [400] hidden size: [5] trial: 26, train_loss: 1.994454, test loss: 1.002012, bias2: 0.9944713115692139, variance: 0.007540214341133833\n",
      "Train size: [400] hidden size: [5] trial: 27, train_loss: 1.995990, test loss: 1.001815, bias2: 0.9940832257270813, variance: 0.007732195779681206\n",
      "Train size: [400] hidden size: [5] trial: 28, train_loss: 1.989882, test loss: 1.002054, bias2: 0.9943581223487854, variance: 0.007695517968386412\n",
      "Train size: [400] hidden size: [5] trial: 29, train_loss: 1.994444, test loss: 1.002025, bias2: 0.9945477843284607, variance: 0.007477596402168274\n",
      "Train size: [400] hidden size: [5] trial: 30, train_loss: 1.992692, test loss: 1.001885, bias2: 0.9943476319313049, variance: 0.007537318393588066\n",
      "Train size: [400] hidden size: [5] trial: 31, train_loss: 1.993944, test loss: 1.002256, bias2: 0.9940009117126465, variance: 0.008255341090261936\n",
      "Train size: [400] hidden size: [5] trial: 32, train_loss: 1.994999, test loss: 1.002228, bias2: 0.994147002696991, variance: 0.008080903440713882\n",
      "Train size: [400] hidden size: [5] trial: 33, train_loss: 1.994695, test loss: 1.001906, bias2: 0.9936522841453552, variance: 0.008253528736531734\n",
      "Train size: [400] hidden size: [5] trial: 34, train_loss: 1.993038, test loss: 1.001785, bias2: 0.9936779141426086, variance: 0.008107366040349007\n",
      "Train size: [400] hidden size: [5] trial: 35, train_loss: 1.997882, test loss: 1.001932, bias2: 0.9938006401062012, variance: 0.008131127804517746\n",
      "Train size: [400] hidden size: [5] trial: 36, train_loss: 2.002709, test loss: 1.002016, bias2: 0.9940176010131836, variance: 0.007998465560376644\n",
      "Train size: [400] hidden size: [5] trial: 37, train_loss: 2.003296, test loss: 1.002208, bias2: 0.9942362904548645, variance: 0.007971955463290215\n",
      "Train size: [400] hidden size: [5] trial: 38, train_loss: 2.000175, test loss: 1.002119, bias2: 0.994224488735199, variance: 0.007894583977758884\n",
      "Train size: [400] hidden size: [5] trial: 39, train_loss: 1.999807, test loss: 1.002089, bias2: 0.9942358136177063, variance: 0.007853216491639614\n",
      "Train size: [400] hidden size: [5] trial: 40, train_loss: 1.999898, test loss: 1.002301, bias2: 0.9942964911460876, variance: 0.008004248142242432\n",
      "Train size: [400] hidden size: [5] trial: 41, train_loss: 2.000396, test loss: 1.002391, bias2: 0.9944213032722473, variance: 0.007969178259372711\n",
      "Train size: [400] hidden size: [5] trial: 42, train_loss: 2.002052, test loss: 1.002109, bias2: 0.9941793084144592, variance: 0.007929395884275436\n",
      "Train size: [400] hidden size: [5] trial: 43, train_loss: 2.004175, test loss: 1.002049, bias2: 0.9937704205513, variance: 0.008279015310108662\n",
      "Train size: [400] hidden size: [5] trial: 44, train_loss: 2.003978, test loss: 1.002125, bias2: 0.9935352802276611, variance: 0.008589988574385643\n",
      "Train size: [400] hidden size: [5] trial: 45, train_loss: 2.008763, test loss: 1.001999, bias2: 0.9935502409934998, variance: 0.008448915556073189\n",
      "Train size: [400] hidden size: [5] trial: 46, train_loss: 2.012340, test loss: 1.001835, bias2: 0.9933921694755554, variance: 0.008443070575594902\n",
      "Train size: [400] hidden size: [5] trial: 47, train_loss: 2.015599, test loss: 1.001837, bias2: 0.9935132265090942, variance: 0.00832340121269226\n",
      "Train size: [400] hidden size: [5] trial: 48, train_loss: 2.015022, test loss: 1.001621, bias2: 0.9933944344520569, variance: 0.008226076140999794\n",
      "Train size: [400] hidden size: [5] trial: 49, train_loss: 2.020930, test loss: 1.001378, bias2: 0.9931069612503052, variance: 0.008271354250609875\n",
      "##################################################\n",
      "Train size: [400] hidden size: [6] trial: 0, train_loss: 2.124730, test loss: 1.006689, bias2: 1.0066887140274048, variance: -3.6492638771923325e-11\n",
      "Train size: [400] hidden size: [6] trial: 1, train_loss: 2.279382, test loss: 1.005179, bias2: 0.9955686926841736, variance: 0.00961080938577652\n",
      "Train size: [400] hidden size: [6] trial: 2, train_loss: 2.185284, test loss: 1.010888, bias2: 0.9980158805847168, variance: 0.012871619313955307\n",
      "Train size: [400] hidden size: [6] trial: 3, train_loss: 2.071702, test loss: 1.008142, bias2: 0.9959980249404907, variance: 0.01214386336505413\n",
      "Train size: [400] hidden size: [6] trial: 4, train_loss: 2.068030, test loss: 1.006034, bias2: 0.9937730431556702, variance: 0.01226062886416912\n",
      "Train size: [400] hidden size: [6] trial: 5, train_loss: 2.034399, test loss: 1.006315, bias2: 0.9944823980331421, variance: 0.011832245625555515\n",
      "Train size: [400] hidden size: [6] trial: 6, train_loss: 2.014967, test loss: 1.005587, bias2: 0.9949307441711426, variance: 0.010656223632395267\n",
      "Train size: [400] hidden size: [6] trial: 7, train_loss: 1.990096, test loss: 1.003289, bias2: 0.9925612807273865, variance: 0.010727954097092152\n",
      "Train size: [400] hidden size: [6] trial: 8, train_loss: 1.968065, test loss: 1.002353, bias2: 0.9919620156288147, variance: 0.010391172021627426\n",
      "Train size: [400] hidden size: [6] trial: 9, train_loss: 1.983313, test loss: 1.002823, bias2: 0.992435872554779, variance: 0.01038733683526516\n",
      "Train size: [400] hidden size: [6] trial: 10, train_loss: 1.991888, test loss: 1.003221, bias2: 0.9909557104110718, variance: 0.012265540659427643\n",
      "Train size: [400] hidden size: [6] trial: 11, train_loss: 1.970125, test loss: 1.004196, bias2: 0.9917100667953491, variance: 0.012485994026064873\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [6] trial: 12, train_loss: 1.972718, test loss: 1.003848, bias2: 0.99164217710495, variance: 0.012205545790493488\n",
      "Train size: [400] hidden size: [6] trial: 13, train_loss: 1.979624, test loss: 1.004222, bias2: 0.9922192096710205, variance: 0.012002723291516304\n",
      "Train size: [400] hidden size: [6] trial: 14, train_loss: 1.982049, test loss: 1.004000, bias2: 0.9915580749511719, variance: 0.012441515922546387\n",
      "Train size: [400] hidden size: [6] trial: 15, train_loss: 1.992455, test loss: 1.004675, bias2: 0.9920348525047302, variance: 0.01264019962400198\n",
      "Train size: [400] hidden size: [6] trial: 16, train_loss: 1.997899, test loss: 1.004559, bias2: 0.9923057556152344, variance: 0.01225364301353693\n",
      "Train size: [400] hidden size: [6] trial: 17, train_loss: 1.987862, test loss: 1.004997, bias2: 0.9928908944129944, variance: 0.012106264941394329\n",
      "Train size: [400] hidden size: [6] trial: 18, train_loss: 2.000726, test loss: 1.004772, bias2: 0.9929245114326477, variance: 0.011847572401165962\n",
      "Train size: [400] hidden size: [6] trial: 19, train_loss: 2.000860, test loss: 1.004706, bias2: 0.992706298828125, variance: 0.011999855749309063\n",
      "Train size: [400] hidden size: [6] trial: 20, train_loss: 1.990522, test loss: 1.004523, bias2: 0.9929938316345215, variance: 0.011529209092259407\n",
      "Train size: [400] hidden size: [6] trial: 21, train_loss: 1.984489, test loss: 1.004131, bias2: 0.9928650259971619, variance: 0.011266060173511505\n",
      "Train size: [400] hidden size: [6] trial: 22, train_loss: 1.981215, test loss: 1.003824, bias2: 0.9927458763122559, variance: 0.011078588664531708\n",
      "Train size: [400] hidden size: [6] trial: 23, train_loss: 1.979090, test loss: 1.003965, bias2: 0.9931812286376953, variance: 0.010783438570797443\n",
      "Train size: [400] hidden size: [6] trial: 24, train_loss: 1.976155, test loss: 1.003615, bias2: 0.9931588768959045, variance: 0.010455812327563763\n",
      "Train size: [400] hidden size: [6] trial: 25, train_loss: 1.981783, test loss: 1.003737, bias2: 0.9930815696716309, variance: 0.01065588928759098\n",
      "Train size: [400] hidden size: [6] trial: 26, train_loss: 1.974880, test loss: 1.003534, bias2: 0.9931185245513916, variance: 0.010415822267532349\n",
      "Train size: [400] hidden size: [6] trial: 27, train_loss: 1.975879, test loss: 1.003444, bias2: 0.9929999113082886, variance: 0.010444494895637035\n",
      "Train size: [400] hidden size: [6] trial: 28, train_loss: 1.978779, test loss: 1.003714, bias2: 0.9930893182754517, variance: 0.010624174028635025\n",
      "Train size: [400] hidden size: [6] trial: 29, train_loss: 1.982972, test loss: 1.003793, bias2: 0.9932147264480591, variance: 0.010578490793704987\n",
      "Train size: [400] hidden size: [6] trial: 30, train_loss: 1.982715, test loss: 1.003582, bias2: 0.9927473664283752, variance: 0.010834518820047379\n",
      "Train size: [400] hidden size: [6] trial: 31, train_loss: 1.987497, test loss: 1.002907, bias2: 0.9919314384460449, variance: 0.01097595039755106\n",
      "Train size: [400] hidden size: [6] trial: 32, train_loss: 1.984228, test loss: 1.002815, bias2: 0.992007851600647, variance: 0.010807403363287449\n",
      "Train size: [400] hidden size: [6] trial: 33, train_loss: 1.982835, test loss: 1.002672, bias2: 0.9919667840003967, variance: 0.010705634951591492\n",
      "Train size: [400] hidden size: [6] trial: 34, train_loss: 1.977610, test loss: 1.002412, bias2: 0.9917498230934143, variance: 0.010661790147423744\n",
      "Train size: [400] hidden size: [6] trial: 35, train_loss: 1.979157, test loss: 1.002263, bias2: 0.9917641878128052, variance: 0.010498770512640476\n",
      "Train size: [400] hidden size: [6] trial: 36, train_loss: 1.977799, test loss: 1.001979, bias2: 0.991479218006134, variance: 0.010499874129891396\n",
      "Train size: [400] hidden size: [6] trial: 37, train_loss: 1.976769, test loss: 1.001914, bias2: 0.991645097732544, variance: 0.010268928483128548\n",
      "Train size: [400] hidden size: [6] trial: 38, train_loss: 1.979548, test loss: 1.002231, bias2: 0.991690456867218, variance: 0.010540091432631016\n",
      "Train size: [400] hidden size: [6] trial: 39, train_loss: 1.985803, test loss: 1.002168, bias2: 0.991629958152771, variance: 0.010537964291870594\n",
      "Train size: [400] hidden size: [6] trial: 40, train_loss: 1.982470, test loss: 1.002241, bias2: 0.9914656281471252, variance: 0.010775288566946983\n",
      "Train size: [400] hidden size: [6] trial: 41, train_loss: 1.977821, test loss: 1.001994, bias2: 0.9911692142486572, variance: 0.010825265198946\n",
      "Train size: [400] hidden size: [6] trial: 42, train_loss: 1.975808, test loss: 1.001994, bias2: 0.9910473227500916, variance: 0.010946915484964848\n",
      "Train size: [400] hidden size: [6] trial: 43, train_loss: 1.979984, test loss: 1.001825, bias2: 0.9906396865844727, variance: 0.011185022071003914\n",
      "Train size: [400] hidden size: [6] trial: 44, train_loss: 1.978497, test loss: 1.001849, bias2: 0.9905027151107788, variance: 0.011345974169671535\n",
      "Train size: [400] hidden size: [6] trial: 45, train_loss: 1.971645, test loss: 1.002061, bias2: 0.9905716180801392, variance: 0.011489623226225376\n",
      "Train size: [400] hidden size: [6] trial: 46, train_loss: 1.972604, test loss: 1.002076, bias2: 0.9907004237174988, variance: 0.011375579051673412\n",
      "Train size: [400] hidden size: [6] trial: 47, train_loss: 1.972138, test loss: 1.002103, bias2: 0.9906273484230042, variance: 0.011475886218249798\n",
      "Train size: [400] hidden size: [6] trial: 48, train_loss: 1.975269, test loss: 1.002037, bias2: 0.9906930923461914, variance: 0.011344294995069504\n",
      "Train size: [400] hidden size: [6] trial: 49, train_loss: 1.976601, test loss: 1.002044, bias2: 0.9906657934188843, variance: 0.011377958580851555\n",
      "##################################################\n",
      "Train size: [400] hidden size: [7] trial: 0, train_loss: 2.059670, test loss: 0.994175, bias2: 0.9941745400428772, variance: -1.6725792625904568e-11\n",
      "Train size: [400] hidden size: [7] trial: 1, train_loss: 1.986670, test loss: 1.003198, bias2: 0.9978131651878357, variance: 0.00538486847653985\n",
      "Train size: [400] hidden size: [7] trial: 2, train_loss: 1.994462, test loss: 1.002556, bias2: 0.9957497715950012, variance: 0.006806173361837864\n",
      "Train size: [400] hidden size: [7] trial: 3, train_loss: 1.993387, test loss: 1.003237, bias2: 0.9953194260597229, variance: 0.007917564362287521\n",
      "Train size: [400] hidden size: [7] trial: 4, train_loss: 1.990087, test loss: 1.001573, bias2: 0.9918276071548462, variance: 0.00974514614790678\n",
      "Train size: [400] hidden size: [7] trial: 5, train_loss: 1.976696, test loss: 0.999951, bias2: 0.9895616769790649, variance: 0.01038941740989685\n",
      "Train size: [400] hidden size: [7] trial: 6, train_loss: 2.002833, test loss: 1.001229, bias2: 0.9913733601570129, variance: 0.009855584241449833\n",
      "Train size: [400] hidden size: [7] trial: 7, train_loss: 1.989371, test loss: 1.001494, bias2: 0.9922831654548645, variance: 0.009210536256432533\n",
      "Train size: [400] hidden size: [7] trial: 8, train_loss: 1.970300, test loss: 1.002058, bias2: 0.9922784566879272, variance: 0.009779796935617924\n",
      "Train size: [400] hidden size: [7] trial: 9, train_loss: 1.971561, test loss: 1.002559, bias2: 0.9930763840675354, variance: 0.009483027271926403\n",
      "Train size: [400] hidden size: [7] trial: 10, train_loss: 1.989256, test loss: 1.002447, bias2: 0.9931246042251587, variance: 0.00932253710925579\n",
      "Train size: [400] hidden size: [7] trial: 11, train_loss: 1.999852, test loss: 1.002138, bias2: 0.9933961033821106, variance: 0.008741676807403564\n",
      "Train size: [400] hidden size: [7] trial: 12, train_loss: 2.007685, test loss: 1.002195, bias2: 0.9938200116157532, variance: 0.008374961093068123\n",
      "Train size: [400] hidden size: [7] trial: 13, train_loss: 2.003618, test loss: 1.001535, bias2: 0.9925671219825745, variance: 0.008967440575361252\n",
      "Train size: [400] hidden size: [7] trial: 14, train_loss: 1.994590, test loss: 1.001929, bias2: 0.9932140111923218, variance: 0.008714884519577026\n",
      "Train size: [400] hidden size: [7] trial: 15, train_loss: 2.002137, test loss: 1.001833, bias2: 0.9929821491241455, variance: 0.008850600570440292\n",
      "Train size: [400] hidden size: [7] trial: 16, train_loss: 2.012597, test loss: 1.002993, bias2: 0.9931515455245972, variance: 0.00984153337776661\n",
      "Train size: [400] hidden size: [7] trial: 17, train_loss: 2.005417, test loss: 1.003488, bias2: 0.9935525059700012, variance: 0.009935656562447548\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [7] trial: 18, train_loss: 2.011599, test loss: 1.003699, bias2: 0.9938560724258423, variance: 0.009842989034950733\n",
      "Train size: [400] hidden size: [7] trial: 19, train_loss: 2.019025, test loss: 1.004427, bias2: 0.9942507743835449, variance: 0.01017654687166214\n",
      "Train size: [400] hidden size: [7] trial: 20, train_loss: 2.016847, test loss: 1.004282, bias2: 0.9944074153900146, variance: 0.009874848648905754\n",
      "Train size: [400] hidden size: [7] trial: 21, train_loss: 2.014639, test loss: 1.004122, bias2: 0.9946012496948242, variance: 0.009520742110908031\n",
      "Train size: [400] hidden size: [7] trial: 22, train_loss: 2.025556, test loss: 1.004564, bias2: 0.9948703646659851, variance: 0.009693784639239311\n",
      "Train size: [400] hidden size: [7] trial: 23, train_loss: 2.021129, test loss: 1.004872, bias2: 0.9946792125701904, variance: 0.010192885994911194\n",
      "Train size: [400] hidden size: [7] trial: 24, train_loss: 2.019397, test loss: 1.005100, bias2: 0.9951005578041077, variance: 0.00999956764280796\n",
      "Train size: [400] hidden size: [7] trial: 25, train_loss: 2.026442, test loss: 1.004928, bias2: 0.9947667717933655, variance: 0.010161450132727623\n",
      "Train size: [400] hidden size: [7] trial: 26, train_loss: 2.025068, test loss: 1.004597, bias2: 0.9943826794624329, variance: 0.010214509442448616\n",
      "Train size: [400] hidden size: [7] trial: 27, train_loss: 2.024453, test loss: 1.004293, bias2: 0.9940637350082397, variance: 0.010229479521512985\n",
      "Train size: [400] hidden size: [7] trial: 28, train_loss: 2.017521, test loss: 1.004481, bias2: 0.9942041635513306, variance: 0.010276791639626026\n",
      "Train size: [400] hidden size: [7] trial: 29, train_loss: 2.021135, test loss: 1.004912, bias2: 0.9944344162940979, variance: 0.010477357544004917\n",
      "Train size: [400] hidden size: [7] trial: 30, train_loss: 2.020027, test loss: 1.004665, bias2: 0.9940438866615295, variance: 0.01062090415507555\n",
      "Train size: [400] hidden size: [7] trial: 31, train_loss: 2.014737, test loss: 1.004654, bias2: 0.9939990043640137, variance: 0.01065506599843502\n",
      "Train size: [400] hidden size: [7] trial: 32, train_loss: 2.016032, test loss: 1.004367, bias2: 0.9933800101280212, variance: 0.01098698005080223\n",
      "Train size: [400] hidden size: [7] trial: 33, train_loss: 2.008881, test loss: 1.004440, bias2: 0.9936177134513855, variance: 0.010821890085935593\n",
      "Train size: [400] hidden size: [7] trial: 34, train_loss: 2.013559, test loss: 1.004220, bias2: 0.993497908115387, variance: 0.010721985250711441\n",
      "Train size: [400] hidden size: [7] trial: 35, train_loss: 2.015651, test loss: 1.004347, bias2: 0.9936133027076721, variance: 0.010733540169894695\n",
      "Train size: [400] hidden size: [7] trial: 36, train_loss: 2.015164, test loss: 1.004393, bias2: 0.9936227202415466, variance: 0.010769768618047237\n",
      "Train size: [400] hidden size: [7] trial: 37, train_loss: 2.017258, test loss: 1.004366, bias2: 0.9936602711677551, variance: 0.010706255212426186\n",
      "Train size: [400] hidden size: [7] trial: 38, train_loss: 2.017100, test loss: 1.004244, bias2: 0.9937598705291748, variance: 0.010483957827091217\n",
      "Train size: [400] hidden size: [7] trial: 39, train_loss: 2.017628, test loss: 1.004143, bias2: 0.9938766360282898, variance: 0.010266242548823357\n",
      "Train size: [400] hidden size: [7] trial: 40, train_loss: 2.019259, test loss: 1.004087, bias2: 0.9937148690223694, variance: 0.010372358374297619\n",
      "Train size: [400] hidden size: [7] trial: 41, train_loss: 2.014351, test loss: 1.004180, bias2: 0.9939835071563721, variance: 0.010196703486144543\n",
      "Train size: [400] hidden size: [7] trial: 42, train_loss: 2.011617, test loss: 1.004093, bias2: 0.9940676093101501, variance: 0.010025441646575928\n",
      "Train size: [400] hidden size: [7] trial: 43, train_loss: 2.006994, test loss: 1.003986, bias2: 0.9940258860588074, variance: 0.009960608556866646\n",
      "Train size: [400] hidden size: [7] trial: 44, train_loss: 2.002488, test loss: 1.003941, bias2: 0.994147777557373, variance: 0.009792659431695938\n",
      "Train size: [400] hidden size: [7] trial: 45, train_loss: 2.001196, test loss: 1.003978, bias2: 0.9940844178199768, variance: 0.009894070215523243\n",
      "Train size: [400] hidden size: [7] trial: 46, train_loss: 2.001978, test loss: 1.004048, bias2: 0.9939645528793335, variance: 0.010083526372909546\n",
      "Train size: [400] hidden size: [7] trial: 47, train_loss: 2.002726, test loss: 1.004281, bias2: 0.9940086603164673, variance: 0.010272027924656868\n",
      "Train size: [400] hidden size: [7] trial: 48, train_loss: 1.999079, test loss: 1.004155, bias2: 0.9935605525970459, variance: 0.010594156570732594\n",
      "Train size: [400] hidden size: [7] trial: 49, train_loss: 1.997337, test loss: 1.004295, bias2: 0.9937334060668945, variance: 0.0105620501562953\n",
      "##################################################\n",
      "Train size: [400] hidden size: [8] trial: 0, train_loss: 2.173604, test loss: 1.010880, bias2: 1.0108795166015625, variance: 0.0\n",
      "Train size: [400] hidden size: [8] trial: 1, train_loss: 2.035195, test loss: 1.007213, bias2: 1.0033833980560303, variance: 0.0038299367297440767\n",
      "Train size: [400] hidden size: [8] trial: 2, train_loss: 2.020667, test loss: 1.006716, bias2: 1.0005282163619995, variance: 0.00618809275329113\n",
      "Train size: [400] hidden size: [8] trial: 3, train_loss: 2.060509, test loss: 1.007027, bias2: 1.0010488033294678, variance: 0.005978368688374758\n",
      "Train size: [400] hidden size: [8] trial: 4, train_loss: 2.033855, test loss: 1.004744, bias2: 0.997918963432312, variance: 0.0068251085467636585\n",
      "Train size: [400] hidden size: [8] trial: 5, train_loss: 2.014596, test loss: 1.004018, bias2: 0.996944010257721, variance: 0.007073941640555859\n",
      "Train size: [400] hidden size: [8] trial: 6, train_loss: 2.037406, test loss: 1.004716, bias2: 0.9962555170059204, variance: 0.008460300974547863\n",
      "Train size: [400] hidden size: [8] trial: 7, train_loss: 2.007013, test loss: 1.004436, bias2: 0.9958267211914062, variance: 0.008609074167907238\n",
      "Train size: [400] hidden size: [8] trial: 8, train_loss: 1.982320, test loss: 1.003237, bias2: 0.9944470524787903, variance: 0.008789616636931896\n",
      "Train size: [400] hidden size: [8] trial: 9, train_loss: 1.981875, test loss: 1.003157, bias2: 0.993738055229187, variance: 0.009419436566531658\n",
      "Train size: [400] hidden size: [8] trial: 10, train_loss: 1.958478, test loss: 1.002047, bias2: 0.9921184182167053, variance: 0.009928376413881779\n",
      "Train size: [400] hidden size: [8] trial: 11, train_loss: 1.953602, test loss: 1.002677, bias2: 0.9920669794082642, variance: 0.010610463097691536\n",
      "Train size: [400] hidden size: [8] trial: 12, train_loss: 1.940190, test loss: 1.004372, bias2: 0.9931094646453857, variance: 0.011262436397373676\n",
      "Train size: [400] hidden size: [8] trial: 13, train_loss: 1.953175, test loss: 1.004650, bias2: 0.9932872653007507, variance: 0.011362478137016296\n",
      "Train size: [400] hidden size: [8] trial: 14, train_loss: 1.948291, test loss: 1.004667, bias2: 0.9935191869735718, variance: 0.011147369630634785\n",
      "Train size: [400] hidden size: [8] trial: 15, train_loss: 1.953747, test loss: 1.005596, bias2: 0.9938834309577942, variance: 0.011712583713233471\n",
      "Train size: [400] hidden size: [8] trial: 16, train_loss: 1.951706, test loss: 1.005499, bias2: 0.9939902424812317, variance: 0.011508985422551632\n",
      "Train size: [400] hidden size: [8] trial: 17, train_loss: 1.954455, test loss: 1.005408, bias2: 0.9936838746070862, variance: 0.011723955161869526\n",
      "Train size: [400] hidden size: [8] trial: 18, train_loss: 1.954933, test loss: 1.005781, bias2: 0.9940820336341858, variance: 0.011698778718709946\n",
      "Train size: [400] hidden size: [8] trial: 19, train_loss: 1.957634, test loss: 1.006337, bias2: 0.9936995506286621, variance: 0.012637883424758911\n",
      "Train size: [400] hidden size: [8] trial: 20, train_loss: 1.952884, test loss: 1.006065, bias2: 0.9930937886238098, variance: 0.012971603311598301\n",
      "Train size: [400] hidden size: [8] trial: 21, train_loss: 1.955378, test loss: 1.006050, bias2: 0.9933363795280457, variance: 0.0127132348716259\n",
      "Train size: [400] hidden size: [8] trial: 22, train_loss: 1.944430, test loss: 1.005081, bias2: 0.9916433095932007, variance: 0.013438005931675434\n",
      "Train size: [400] hidden size: [8] trial: 23, train_loss: 1.950536, test loss: 1.004820, bias2: 0.9917646050453186, variance: 0.013055479153990746\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [8] trial: 24, train_loss: 1.941244, test loss: 1.004582, bias2: 0.9911850094795227, variance: 0.013397029601037502\n",
      "Train size: [400] hidden size: [8] trial: 25, train_loss: 1.938768, test loss: 1.004209, bias2: 0.9909595251083374, variance: 0.01324914488941431\n",
      "Train size: [400] hidden size: [8] trial: 26, train_loss: 1.941535, test loss: 1.004189, bias2: 0.9911859035491943, variance: 0.013002898544073105\n",
      "Train size: [400] hidden size: [8] trial: 27, train_loss: 1.933518, test loss: 1.004577, bias2: 0.9915222525596619, variance: 0.013054415583610535\n",
      "Train size: [400] hidden size: [8] trial: 28, train_loss: 1.937892, test loss: 1.004676, bias2: 0.9915332198143005, variance: 0.013142435811460018\n",
      "Train size: [400] hidden size: [8] trial: 29, train_loss: 1.937095, test loss: 1.004463, bias2: 0.9911823272705078, variance: 0.013281128369271755\n",
      "Train size: [400] hidden size: [8] trial: 30, train_loss: 1.937145, test loss: 1.005277, bias2: 0.9912704825401306, variance: 0.014006802812218666\n",
      "Train size: [400] hidden size: [8] trial: 31, train_loss: 1.941272, test loss: 1.004741, bias2: 0.9909436702728271, variance: 0.013797665014863014\n",
      "Train size: [400] hidden size: [8] trial: 32, train_loss: 1.944838, test loss: 1.004917, bias2: 0.9912293553352356, variance: 0.013687309809029102\n",
      "Train size: [400] hidden size: [8] trial: 33, train_loss: 1.953011, test loss: 1.004580, bias2: 0.9910936951637268, variance: 0.013486224226653576\n",
      "Train size: [400] hidden size: [8] trial: 34, train_loss: 1.953893, test loss: 1.004405, bias2: 0.9911694526672363, variance: 0.013235348276793957\n",
      "Train size: [400] hidden size: [8] trial: 35, train_loss: 1.954038, test loss: 1.004424, bias2: 0.9913925528526306, variance: 0.013031319715082645\n",
      "Train size: [400] hidden size: [8] trial: 36, train_loss: 1.949261, test loss: 1.004551, bias2: 0.9915282726287842, variance: 0.013022671453654766\n",
      "Train size: [400] hidden size: [8] trial: 37, train_loss: 1.953848, test loss: 1.004422, bias2: 0.9908111095428467, variance: 0.01361062191426754\n",
      "Train size: [400] hidden size: [8] trial: 38, train_loss: 1.948151, test loss: 1.004361, bias2: 0.9906377196311951, variance: 0.013723695650696754\n",
      "Train size: [400] hidden size: [8] trial: 39, train_loss: 1.945219, test loss: 1.003942, bias2: 0.9902492761611938, variance: 0.013692869804799557\n",
      "Train size: [400] hidden size: [8] trial: 40, train_loss: 1.948710, test loss: 1.004037, bias2: 0.9905318021774292, variance: 0.013504879549145699\n",
      "Train size: [400] hidden size: [8] trial: 41, train_loss: 1.939760, test loss: 1.003648, bias2: 0.9900727272033691, variance: 0.013574969954788685\n",
      "Train size: [400] hidden size: [8] trial: 42, train_loss: 1.943803, test loss: 1.003517, bias2: 0.989499568939209, variance: 0.014017698355019093\n",
      "Train size: [400] hidden size: [8] trial: 43, train_loss: 1.940324, test loss: 1.003671, bias2: 0.9898708462715149, variance: 0.013800092972815037\n",
      "Train size: [400] hidden size: [8] trial: 44, train_loss: 1.944207, test loss: 1.003637, bias2: 0.9894248247146606, variance: 0.014212262816727161\n",
      "Train size: [400] hidden size: [8] trial: 45, train_loss: 1.942716, test loss: 1.003524, bias2: 0.9890305995941162, variance: 0.014493606053292751\n",
      "Train size: [400] hidden size: [8] trial: 46, train_loss: 1.944238, test loss: 1.003639, bias2: 0.9892017841339111, variance: 0.014436944387853146\n",
      "Train size: [400] hidden size: [8] trial: 47, train_loss: 1.945035, test loss: 1.003486, bias2: 0.9892560243606567, variance: 0.014229681342840195\n",
      "Train size: [400] hidden size: [8] trial: 48, train_loss: 1.943789, test loss: 1.003465, bias2: 0.9893358945846558, variance: 0.014128943905234337\n",
      "Train size: [400] hidden size: [8] trial: 49, train_loss: 1.949324, test loss: 1.003590, bias2: 0.9895728230476379, variance: 0.014017659239470959\n",
      "##################################################\n",
      "Train size: [400] hidden size: [9] trial: 0, train_loss: 2.215886, test loss: 0.992616, bias2: 0.9926155805587769, variance: 2.311200397731028e-10\n",
      "Train size: [400] hidden size: [9] trial: 1, train_loss: 2.227572, test loss: 0.988367, bias2: 0.9802885055541992, variance: 0.00807883869856596\n",
      "Train size: [400] hidden size: [9] trial: 2, train_loss: 2.086935, test loss: 0.992779, bias2: 0.9852522611618042, variance: 0.007526929955929518\n",
      "Train size: [400] hidden size: [9] trial: 3, train_loss: 2.049722, test loss: 0.997630, bias2: 0.989307701587677, variance: 0.008321856148540974\n",
      "Train size: [400] hidden size: [9] trial: 4, train_loss: 2.030742, test loss: 0.997691, bias2: 0.9875338077545166, variance: 0.010157049633562565\n",
      "Train size: [400] hidden size: [9] trial: 5, train_loss: 2.011785, test loss: 0.996585, bias2: 0.9861181378364563, variance: 0.010466407984495163\n",
      "Train size: [400] hidden size: [9] trial: 6, train_loss: 1.983160, test loss: 0.997803, bias2: 0.9872693419456482, variance: 0.010533662512898445\n",
      "Train size: [400] hidden size: [9] trial: 7, train_loss: 1.978159, test loss: 1.000383, bias2: 0.9889928102493286, variance: 0.011390328407287598\n",
      "Train size: [400] hidden size: [9] trial: 8, train_loss: 1.970866, test loss: 0.999895, bias2: 0.9880449175834656, variance: 0.011850501410663128\n",
      "Train size: [400] hidden size: [9] trial: 9, train_loss: 1.975212, test loss: 1.000320, bias2: 0.9885165095329285, variance: 0.01180332899093628\n",
      "Train size: [400] hidden size: [9] trial: 10, train_loss: 1.977466, test loss: 1.001599, bias2: 0.9892153739929199, variance: 0.012384029105305672\n",
      "Train size: [400] hidden size: [9] trial: 11, train_loss: 1.976476, test loss: 1.000066, bias2: 0.9862599968910217, variance: 0.013805581256747246\n",
      "Train size: [400] hidden size: [9] trial: 12, train_loss: 1.979472, test loss: 1.000355, bias2: 0.9854745864868164, variance: 0.014880307018756866\n",
      "Train size: [400] hidden size: [9] trial: 13, train_loss: 1.965653, test loss: 1.000377, bias2: 0.9856287240982056, variance: 0.014748671092092991\n",
      "Train size: [400] hidden size: [9] trial: 14, train_loss: 1.965048, test loss: 1.000666, bias2: 0.9861319661140442, variance: 0.014534316025674343\n",
      "Train size: [400] hidden size: [9] trial: 15, train_loss: 1.970269, test loss: 1.000848, bias2: 0.9858559966087341, variance: 0.014992290176451206\n",
      "Train size: [400] hidden size: [9] trial: 16, train_loss: 1.956632, test loss: 1.001033, bias2: 0.9860037565231323, variance: 0.015029314905405045\n",
      "Train size: [400] hidden size: [9] trial: 17, train_loss: 1.960037, test loss: 1.001972, bias2: 0.9872608184814453, variance: 0.014710875228047371\n",
      "Train size: [400] hidden size: [9] trial: 18, train_loss: 1.971661, test loss: 1.002686, bias2: 0.9874362349510193, variance: 0.015249436721205711\n",
      "Train size: [400] hidden size: [9] trial: 19, train_loss: 1.973351, test loss: 1.002946, bias2: 0.9878690242767334, variance: 0.015077105723321438\n",
      "Train size: [400] hidden size: [9] trial: 20, train_loss: 1.970538, test loss: 1.002602, bias2: 0.987605631351471, variance: 0.014996577054262161\n",
      "Train size: [400] hidden size: [9] trial: 21, train_loss: 1.977497, test loss: 1.003186, bias2: 0.9874899387359619, variance: 0.015696261078119278\n",
      "Train size: [400] hidden size: [9] trial: 22, train_loss: 1.968646, test loss: 1.003808, bias2: 0.9872550368309021, variance: 0.016552718356251717\n",
      "Train size: [400] hidden size: [9] trial: 23, train_loss: 1.961738, test loss: 1.003897, bias2: 0.9875218272209167, variance: 0.016375252977013588\n",
      "Train size: [400] hidden size: [9] trial: 24, train_loss: 1.960302, test loss: 1.003565, bias2: 0.9872795343399048, variance: 0.016285061836242676\n",
      "Train size: [400] hidden size: [9] trial: 25, train_loss: 1.953516, test loss: 1.003225, bias2: 0.9869616627693176, variance: 0.016263173893094063\n",
      "Train size: [400] hidden size: [9] trial: 26, train_loss: 1.954562, test loss: 1.003243, bias2: 0.9865111708641052, variance: 0.01673181727528572\n",
      "Train size: [400] hidden size: [9] trial: 27, train_loss: 1.956082, test loss: 1.003374, bias2: 0.9868110418319702, variance: 0.01656304858624935\n",
      "Train size: [400] hidden size: [9] trial: 28, train_loss: 1.949938, test loss: 1.002969, bias2: 0.9864475131034851, variance: 0.016521286219358444\n",
      "Train size: [400] hidden size: [9] trial: 29, train_loss: 1.956434, test loss: 1.002228, bias2: 0.9853898286819458, variance: 0.016838403418660164\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [9] trial: 30, train_loss: 1.964627, test loss: 1.002071, bias2: 0.9855307340621948, variance: 0.016540033742785454\n",
      "Train size: [400] hidden size: [9] trial: 31, train_loss: 1.962665, test loss: 1.002055, bias2: 0.9856809973716736, variance: 0.016374317929148674\n",
      "Train size: [400] hidden size: [9] trial: 32, train_loss: 1.961020, test loss: 1.001323, bias2: 0.9849812388420105, variance: 0.01634165085852146\n",
      "Train size: [400] hidden size: [9] trial: 33, train_loss: 1.964775, test loss: 1.001231, bias2: 0.9850894212722778, variance: 0.016141626983880997\n",
      "Train size: [400] hidden size: [9] trial: 34, train_loss: 1.960447, test loss: 1.001252, bias2: 0.985197901725769, variance: 0.016054362058639526\n",
      "Train size: [400] hidden size: [9] trial: 35, train_loss: 1.954682, test loss: 1.001279, bias2: 0.985316276550293, variance: 0.015962453559041023\n",
      "Train size: [400] hidden size: [9] trial: 36, train_loss: 1.950833, test loss: 1.001139, bias2: 0.9846246838569641, variance: 0.01651390641927719\n",
      "Train size: [400] hidden size: [9] trial: 37, train_loss: 1.950054, test loss: 1.001141, bias2: 0.9843806624412537, variance: 0.016760049387812614\n",
      "Train size: [400] hidden size: [9] trial: 38, train_loss: 1.945993, test loss: 1.001099, bias2: 0.9845227599143982, variance: 0.01657596416771412\n",
      "Train size: [400] hidden size: [9] trial: 39, train_loss: 1.947933, test loss: 1.001735, bias2: 0.9851377010345459, variance: 0.016597656533122063\n",
      "Train size: [400] hidden size: [9] trial: 40, train_loss: 1.948085, test loss: 1.001437, bias2: 0.9850330352783203, variance: 0.01640401966869831\n",
      "Train size: [400] hidden size: [9] trial: 41, train_loss: 1.946470, test loss: 1.001242, bias2: 0.9849565029144287, variance: 0.016285529360175133\n",
      "Train size: [400] hidden size: [9] trial: 42, train_loss: 1.954964, test loss: 1.001434, bias2: 0.985309898853302, variance: 0.016124168410897255\n",
      "Train size: [400] hidden size: [9] trial: 43, train_loss: 1.955460, test loss: 1.001308, bias2: 0.985227644443512, variance: 0.016080429777503014\n",
      "Train size: [400] hidden size: [9] trial: 44, train_loss: 1.951434, test loss: 1.001215, bias2: 0.9853590726852417, variance: 0.015856396406888962\n",
      "Train size: [400] hidden size: [9] trial: 45, train_loss: 1.948372, test loss: 1.001288, bias2: 0.9855204224586487, variance: 0.015767136588692665\n",
      "Train size: [400] hidden size: [9] trial: 46, train_loss: 1.947744, test loss: 1.001109, bias2: 0.9854370355606079, variance: 0.015671709552407265\n",
      "Train size: [400] hidden size: [9] trial: 47, train_loss: 1.952610, test loss: 1.001073, bias2: 0.9855960607528687, variance: 0.015477164648473263\n",
      "Train size: [400] hidden size: [9] trial: 48, train_loss: 1.955684, test loss: 1.000934, bias2: 0.9853240847587585, variance: 0.015609431080520153\n",
      "Train size: [400] hidden size: [9] trial: 49, train_loss: 1.953752, test loss: 1.001128, bias2: 0.9853165745735168, variance: 0.015811879187822342\n",
      "##################################################\n",
      "Train size: [400] hidden size: [11] trial: 0, train_loss: 1.936051, test loss: 1.009104, bias2: 1.0091042518615723, variance: 2.4328424691466566e-11\n",
      "Train size: [400] hidden size: [11] trial: 1, train_loss: 1.920000, test loss: 1.009579, bias2: 0.9951937198638916, variance: 0.014384989626705647\n",
      "Train size: [400] hidden size: [11] trial: 2, train_loss: 2.061494, test loss: 1.010217, bias2: 0.9959890842437744, variance: 0.014227733016014099\n",
      "Train size: [400] hidden size: [11] trial: 3, train_loss: 1.978550, test loss: 1.009398, bias2: 0.9920520186424255, variance: 0.017346089705824852\n",
      "Train size: [400] hidden size: [11] trial: 4, train_loss: 1.978826, test loss: 1.008477, bias2: 0.990726888179779, variance: 0.0177505724132061\n",
      "Train size: [400] hidden size: [11] trial: 5, train_loss: 1.959529, test loss: 1.012332, bias2: 0.989896297454834, variance: 0.02243543602526188\n",
      "Train size: [400] hidden size: [11] trial: 6, train_loss: 1.943423, test loss: 1.011551, bias2: 0.990635871887207, variance: 0.020914819091558456\n",
      "Train size: [400] hidden size: [11] trial: 7, train_loss: 1.978318, test loss: 1.010893, bias2: 0.9910089373588562, variance: 0.01988368295133114\n",
      "Train size: [400] hidden size: [11] trial: 8, train_loss: 1.953326, test loss: 1.011352, bias2: 0.9922274947166443, variance: 0.019124457612633705\n",
      "Train size: [400] hidden size: [11] trial: 9, train_loss: 1.971074, test loss: 1.010234, bias2: 0.990510106086731, variance: 0.019724005833268166\n",
      "Train size: [400] hidden size: [11] trial: 10, train_loss: 1.962326, test loss: 1.009407, bias2: 0.9889745712280273, variance: 0.02043258771300316\n",
      "Train size: [400] hidden size: [11] trial: 11, train_loss: 1.962208, test loss: 1.008695, bias2: 0.9895477294921875, variance: 0.019147178158164024\n",
      "Train size: [400] hidden size: [11] trial: 12, train_loss: 1.952042, test loss: 1.007569, bias2: 0.988539457321167, variance: 0.019029859453439713\n",
      "Train size: [400] hidden size: [11] trial: 13, train_loss: 1.966084, test loss: 1.006435, bias2: 0.9881069660186768, variance: 0.018328407779335976\n",
      "Train size: [400] hidden size: [11] trial: 14, train_loss: 1.966210, test loss: 1.006121, bias2: 0.9860518574714661, variance: 0.020069289952516556\n",
      "Train size: [400] hidden size: [11] trial: 15, train_loss: 1.977587, test loss: 1.005745, bias2: 0.9861158132553101, variance: 0.019629212096333504\n",
      "Train size: [400] hidden size: [11] trial: 16, train_loss: 1.976991, test loss: 1.005010, bias2: 0.9854967594146729, variance: 0.01951298490166664\n",
      "Train size: [400] hidden size: [11] trial: 17, train_loss: 1.980000, test loss: 1.005109, bias2: 0.9858695268630981, variance: 0.019239196553826332\n",
      "Train size: [400] hidden size: [11] trial: 18, train_loss: 1.980419, test loss: 1.004442, bias2: 0.9848173260688782, variance: 0.01962491124868393\n",
      "Train size: [400] hidden size: [11] trial: 19, train_loss: 1.974666, test loss: 1.003473, bias2: 0.983877956867218, variance: 0.019594604149460793\n",
      "Train size: [400] hidden size: [11] trial: 20, train_loss: 1.982718, test loss: 1.003639, bias2: 0.9836496114730835, variance: 0.019989360123872757\n",
      "Train size: [400] hidden size: [11] trial: 21, train_loss: 1.980377, test loss: 1.003575, bias2: 0.9837234616279602, variance: 0.019851163029670715\n",
      "Train size: [400] hidden size: [11] trial: 22, train_loss: 1.982506, test loss: 1.003225, bias2: 0.9833176136016846, variance: 0.019906992092728615\n",
      "Train size: [400] hidden size: [11] trial: 23, train_loss: 1.976712, test loss: 1.003642, bias2: 0.9841818809509277, variance: 0.019460106268525124\n",
      "Train size: [400] hidden size: [11] trial: 24, train_loss: 1.971812, test loss: 1.003331, bias2: 0.9842950105667114, variance: 0.019036278128623962\n",
      "Train size: [400] hidden size: [11] trial: 25, train_loss: 1.977569, test loss: 1.003533, bias2: 0.9840265512466431, variance: 0.019506586715579033\n",
      "Train size: [400] hidden size: [11] trial: 26, train_loss: 1.971399, test loss: 1.003541, bias2: 0.9843165874481201, variance: 0.019223909825086594\n",
      "Train size: [400] hidden size: [11] trial: 27, train_loss: 1.968752, test loss: 1.003649, bias2: 0.9845106601715088, variance: 0.01913822814822197\n",
      "Train size: [400] hidden size: [11] trial: 28, train_loss: 1.972808, test loss: 1.003498, bias2: 0.984645426273346, variance: 0.018852559849619865\n",
      "Train size: [400] hidden size: [11] trial: 29, train_loss: 1.961124, test loss: 1.003401, bias2: 0.9849408864974976, variance: 0.018459780141711235\n",
      "Train size: [400] hidden size: [11] trial: 30, train_loss: 1.957247, test loss: 1.003495, bias2: 0.984906017780304, variance: 0.018589293584227562\n",
      "Train size: [400] hidden size: [11] trial: 31, train_loss: 1.962912, test loss: 1.003993, bias2: 0.9850565195083618, variance: 0.018936656415462494\n",
      "Train size: [400] hidden size: [11] trial: 32, train_loss: 1.968075, test loss: 1.003614, bias2: 0.9848310947418213, variance: 0.018782727420330048\n",
      "Train size: [400] hidden size: [11] trial: 33, train_loss: 1.965486, test loss: 1.003758, bias2: 0.9849998950958252, variance: 0.018757717683911324\n",
      "Train size: [400] hidden size: [11] trial: 34, train_loss: 1.965263, test loss: 1.003661, bias2: 0.9849385023117065, variance: 0.018722055479884148\n",
      "Train size: [400] hidden size: [11] trial: 35, train_loss: 1.969265, test loss: 1.003567, bias2: 0.9850771427154541, variance: 0.018489357084035873\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [11] trial: 36, train_loss: 1.972887, test loss: 1.003664, bias2: 0.9851214289665222, variance: 0.01854260265827179\n",
      "Train size: [400] hidden size: [11] trial: 37, train_loss: 1.975040, test loss: 1.003804, bias2: 0.9854618310928345, variance: 0.018342237919569016\n",
      "Train size: [400] hidden size: [11] trial: 38, train_loss: 1.974107, test loss: 1.003973, bias2: 0.9856290221214294, variance: 0.018344322219491005\n",
      "Train size: [400] hidden size: [11] trial: 39, train_loss: 1.969169, test loss: 1.004312, bias2: 0.9858449697494507, variance: 0.018466858193278313\n",
      "Train size: [400] hidden size: [11] trial: 40, train_loss: 1.973783, test loss: 1.003804, bias2: 0.9853408932685852, variance: 0.018462693318724632\n",
      "Train size: [400] hidden size: [11] trial: 41, train_loss: 1.968856, test loss: 1.003912, bias2: 0.9854386448860168, variance: 0.018473561853170395\n",
      "Train size: [400] hidden size: [11] trial: 42, train_loss: 1.963983, test loss: 1.003904, bias2: 0.9856031537055969, variance: 0.0183006152510643\n",
      "Train size: [400] hidden size: [11] trial: 43, train_loss: 1.964340, test loss: 1.003716, bias2: 0.9856275916099548, variance: 0.018088260665535927\n",
      "Train size: [400] hidden size: [11] trial: 44, train_loss: 1.971440, test loss: 1.003396, bias2: 0.9852413535118103, variance: 0.018155138939619064\n",
      "Train size: [400] hidden size: [11] trial: 45, train_loss: 1.972796, test loss: 1.003682, bias2: 0.9852093458175659, variance: 0.018472442403435707\n",
      "Train size: [400] hidden size: [11] trial: 46, train_loss: 1.973197, test loss: 1.003642, bias2: 0.9853305816650391, variance: 0.018311882391572\n",
      "Train size: [400] hidden size: [11] trial: 47, train_loss: 1.972160, test loss: 1.003369, bias2: 0.9848248362541199, variance: 0.018543776124715805\n",
      "Train size: [400] hidden size: [11] trial: 48, train_loss: 1.974625, test loss: 1.003122, bias2: 0.9844326376914978, variance: 0.018689434975385666\n",
      "Train size: [400] hidden size: [11] trial: 49, train_loss: 1.976903, test loss: 1.002904, bias2: 0.9842543601989746, variance: 0.018649812787771225\n",
      "##################################################\n",
      "Train size: [400] hidden size: [12] trial: 0, train_loss: 1.923670, test loss: 0.974691, bias2: 0.9746914505958557, variance: 3.4059796649721363e-10\n",
      "Train size: [400] hidden size: [12] trial: 1, train_loss: 1.947313, test loss: 0.986757, bias2: 0.974270224571228, variance: 0.012487083673477173\n",
      "Train size: [400] hidden size: [12] trial: 2, train_loss: 2.018728, test loss: 0.999811, bias2: 0.9818529486656189, variance: 0.01795833371579647\n",
      "Train size: [400] hidden size: [12] trial: 3, train_loss: 1.910461, test loss: 0.999383, bias2: 0.9807387590408325, variance: 0.018643818795681\n",
      "Train size: [400] hidden size: [12] trial: 4, train_loss: 1.914422, test loss: 0.999505, bias2: 0.9799267649650574, variance: 0.01957830972969532\n",
      "Train size: [400] hidden size: [12] trial: 5, train_loss: 1.897680, test loss: 1.000894, bias2: 0.9818985462188721, variance: 0.0189954936504364\n",
      "Train size: [400] hidden size: [12] trial: 6, train_loss: 1.906131, test loss: 1.001125, bias2: 0.9835389256477356, variance: 0.017586035653948784\n",
      "Train size: [400] hidden size: [12] trial: 7, train_loss: 1.910062, test loss: 1.001640, bias2: 0.9839321970939636, variance: 0.017707984894514084\n",
      "Train size: [400] hidden size: [12] trial: 8, train_loss: 1.901989, test loss: 1.001736, bias2: 0.9844172596931458, variance: 0.017318302765488625\n",
      "Train size: [400] hidden size: [12] trial: 9, train_loss: 1.877485, test loss: 1.003147, bias2: 0.9852390885353088, variance: 0.01790780946612358\n",
      "Train size: [400] hidden size: [12] trial: 10, train_loss: 1.896331, test loss: 1.002770, bias2: 0.9843589067459106, variance: 0.018410827964544296\n",
      "Train size: [400] hidden size: [12] trial: 11, train_loss: 1.888877, test loss: 1.002530, bias2: 0.9835633039474487, variance: 0.018967123702168465\n",
      "Train size: [400] hidden size: [12] trial: 12, train_loss: 1.920967, test loss: 1.003127, bias2: 0.98387610912323, variance: 0.019250642508268356\n",
      "Train size: [400] hidden size: [12] trial: 13, train_loss: 1.914813, test loss: 1.002700, bias2: 0.9839986562728882, variance: 0.018701797351241112\n",
      "Train size: [400] hidden size: [12] trial: 14, train_loss: 1.902224, test loss: 1.003503, bias2: 0.9850499033927917, variance: 0.018453184515237808\n",
      "Train size: [400] hidden size: [12] trial: 15, train_loss: 1.901528, test loss: 1.003099, bias2: 0.9844056963920593, variance: 0.018693361431360245\n",
      "Train size: [400] hidden size: [12] trial: 16, train_loss: 1.909878, test loss: 1.002583, bias2: 0.984286367893219, variance: 0.018296750262379646\n",
      "Train size: [400] hidden size: [12] trial: 17, train_loss: 1.909909, test loss: 1.002013, bias2: 0.9841288328170776, variance: 0.01788375712931156\n",
      "Train size: [400] hidden size: [12] trial: 18, train_loss: 1.923087, test loss: 1.001938, bias2: 0.9843618273735046, variance: 0.017575791105628014\n",
      "Train size: [400] hidden size: [12] trial: 19, train_loss: 1.923210, test loss: 1.003142, bias2: 0.9855390191078186, variance: 0.017602844163775444\n",
      "Train size: [400] hidden size: [12] trial: 20, train_loss: 1.923922, test loss: 1.003271, bias2: 0.9859104156494141, variance: 0.017360586673021317\n",
      "Train size: [400] hidden size: [12] trial: 21, train_loss: 1.932815, test loss: 1.002735, bias2: 0.985458493232727, variance: 0.017276888713240623\n",
      "Train size: [400] hidden size: [12] trial: 22, train_loss: 1.936188, test loss: 1.003234, bias2: 0.9852370619773865, variance: 0.017997315153479576\n",
      "Train size: [400] hidden size: [12] trial: 23, train_loss: 1.929892, test loss: 1.003274, bias2: 0.9848278760910034, variance: 0.01844598352909088\n",
      "Train size: [400] hidden size: [12] trial: 24, train_loss: 1.932109, test loss: 1.003817, bias2: 0.9851604104042053, variance: 0.018656689673662186\n",
      "Train size: [400] hidden size: [12] trial: 25, train_loss: 1.933568, test loss: 1.004338, bias2: 0.9855145215988159, variance: 0.018824011087417603\n",
      "Train size: [400] hidden size: [12] trial: 26, train_loss: 1.927173, test loss: 1.003656, bias2: 0.9841221570968628, variance: 0.019533976912498474\n",
      "Train size: [400] hidden size: [12] trial: 27, train_loss: 1.924297, test loss: 1.004329, bias2: 0.9840943217277527, variance: 0.02023501694202423\n",
      "Train size: [400] hidden size: [12] trial: 28, train_loss: 1.927144, test loss: 1.004956, bias2: 0.9845423698425293, variance: 0.02041364461183548\n",
      "Train size: [400] hidden size: [12] trial: 29, train_loss: 1.928169, test loss: 1.004648, bias2: 0.9842913150787354, variance: 0.020356521010398865\n",
      "Train size: [400] hidden size: [12] trial: 30, train_loss: 1.924773, test loss: 1.005473, bias2: 0.9844673275947571, variance: 0.021005447953939438\n",
      "Train size: [400] hidden size: [12] trial: 31, train_loss: 1.924836, test loss: 1.005148, bias2: 0.9845504760742188, variance: 0.020597562193870544\n",
      "Train size: [400] hidden size: [12] trial: 32, train_loss: 1.923674, test loss: 1.004903, bias2: 0.9838202595710754, variance: 0.021082792431116104\n",
      "Train size: [400] hidden size: [12] trial: 33, train_loss: 1.920283, test loss: 1.004458, bias2: 0.9836394190788269, variance: 0.020818181335926056\n",
      "Train size: [400] hidden size: [12] trial: 34, train_loss: 1.923539, test loss: 1.004410, bias2: 0.984011709690094, variance: 0.020398663356900215\n",
      "Train size: [400] hidden size: [12] trial: 35, train_loss: 1.927774, test loss: 1.004409, bias2: 0.9838286638259888, variance: 0.020580558106303215\n",
      "Train size: [400] hidden size: [12] trial: 36, train_loss: 1.926738, test loss: 1.004058, bias2: 0.983697235584259, variance: 0.020361101254820824\n",
      "Train size: [400] hidden size: [12] trial: 37, train_loss: 1.928269, test loss: 1.003758, bias2: 0.9834330081939697, variance: 0.02032528631389141\n",
      "Train size: [400] hidden size: [12] trial: 38, train_loss: 1.939085, test loss: 1.003983, bias2: 0.9838261604309082, variance: 0.0201566219329834\n",
      "Train size: [400] hidden size: [12] trial: 39, train_loss: 1.939314, test loss: 1.003959, bias2: 0.9838064312934875, variance: 0.020152505487203598\n",
      "Train size: [400] hidden size: [12] trial: 40, train_loss: 1.941719, test loss: 1.003546, bias2: 0.983575165271759, variance: 0.01997038535773754\n",
      "Train size: [400] hidden size: [12] trial: 41, train_loss: 1.947896, test loss: 1.003371, bias2: 0.9837660789489746, variance: 0.01960480585694313\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [12] trial: 42, train_loss: 1.940694, test loss: 1.003256, bias2: 0.9837545156478882, variance: 0.0195018220692873\n",
      "Train size: [400] hidden size: [12] trial: 43, train_loss: 1.940088, test loss: 1.003189, bias2: 0.9835307598114014, variance: 0.019658692181110382\n",
      "Train size: [400] hidden size: [12] trial: 44, train_loss: 1.937576, test loss: 1.003629, bias2: 0.9835708737373352, variance: 0.020057836547493935\n",
      "Train size: [400] hidden size: [12] trial: 45, train_loss: 1.932505, test loss: 1.003382, bias2: 0.9832435250282288, variance: 0.020138222724199295\n",
      "Train size: [400] hidden size: [12] trial: 46, train_loss: 1.941233, test loss: 1.003692, bias2: 0.9832593202590942, variance: 0.020432839170098305\n",
      "Train size: [400] hidden size: [12] trial: 47, train_loss: 1.943698, test loss: 1.004073, bias2: 0.9835964441299438, variance: 0.02047705091536045\n",
      "Train size: [400] hidden size: [12] trial: 48, train_loss: 1.945671, test loss: 1.003978, bias2: 0.9837749004364014, variance: 0.020202970132231712\n",
      "Train size: [400] hidden size: [12] trial: 49, train_loss: 1.948830, test loss: 1.004153, bias2: 0.9837628602981567, variance: 0.02039039507508278\n",
      "##################################################\n",
      "Train size: [400] hidden size: [14] trial: 0, train_loss: 1.992201, test loss: 0.997937, bias2: 0.9979366660118103, variance: -1.2164212692677978e-10\n",
      "Train size: [400] hidden size: [14] trial: 1, train_loss: 1.835910, test loss: 0.993311, bias2: 0.9823794364929199, variance: 0.010931845754384995\n",
      "Train size: [400] hidden size: [14] trial: 2, train_loss: 1.847216, test loss: 0.993306, bias2: 0.9793224930763245, variance: 0.01398347970098257\n",
      "Train size: [400] hidden size: [14] trial: 3, train_loss: 1.877075, test loss: 0.993819, bias2: 0.9734513759613037, variance: 0.020367763936519623\n",
      "Train size: [400] hidden size: [14] trial: 4, train_loss: 1.887801, test loss: 0.994478, bias2: 0.9738380312919617, variance: 0.020640486851334572\n",
      "Train size: [400] hidden size: [14] trial: 5, train_loss: 1.893644, test loss: 0.996588, bias2: 0.9770434498786926, variance: 0.0195444505661726\n",
      "Train size: [400] hidden size: [14] trial: 6, train_loss: 1.855337, test loss: 0.996038, bias2: 0.9775705337524414, variance: 0.018467562273144722\n",
      "Train size: [400] hidden size: [14] trial: 7, train_loss: 1.877938, test loss: 0.996679, bias2: 0.9768235087394714, variance: 0.019855326041579247\n",
      "Train size: [400] hidden size: [14] trial: 8, train_loss: 1.875763, test loss: 0.997741, bias2: 0.9775504469871521, variance: 0.020191075280308723\n",
      "Train size: [400] hidden size: [14] trial: 9, train_loss: 1.881123, test loss: 0.999123, bias2: 0.9791269898414612, variance: 0.01999557390809059\n",
      "Train size: [400] hidden size: [14] trial: 10, train_loss: 1.874658, test loss: 1.000148, bias2: 0.980358898639679, variance: 0.019788706675171852\n",
      "Train size: [400] hidden size: [14] trial: 11, train_loss: 1.872710, test loss: 0.999886, bias2: 0.9799546599388123, variance: 0.019931182265281677\n",
      "Train size: [400] hidden size: [14] trial: 12, train_loss: 1.874089, test loss: 1.001779, bias2: 0.9803116321563721, variance: 0.021466948091983795\n",
      "Train size: [400] hidden size: [14] trial: 13, train_loss: 1.876973, test loss: 1.002706, bias2: 0.9814620018005371, variance: 0.02124403603374958\n",
      "Train size: [400] hidden size: [14] trial: 14, train_loss: 1.866994, test loss: 1.002495, bias2: 0.9805054068565369, variance: 0.02198942005634308\n",
      "Train size: [400] hidden size: [14] trial: 15, train_loss: 1.876594, test loss: 1.002240, bias2: 0.9793915152549744, variance: 0.022848328575491905\n",
      "Train size: [400] hidden size: [14] trial: 16, train_loss: 1.887615, test loss: 1.001951, bias2: 0.9798620939254761, variance: 0.02208925038576126\n",
      "Train size: [400] hidden size: [14] trial: 17, train_loss: 1.891652, test loss: 1.002821, bias2: 0.9803196787834167, variance: 0.022500956431031227\n",
      "Train size: [400] hidden size: [14] trial: 18, train_loss: 1.901129, test loss: 1.003530, bias2: 0.9807326197624207, variance: 0.022796912118792534\n",
      "Train size: [400] hidden size: [14] trial: 19, train_loss: 1.898881, test loss: 1.003285, bias2: 0.9803129434585571, variance: 0.022971631959080696\n",
      "Train size: [400] hidden size: [14] trial: 20, train_loss: 1.903226, test loss: 1.003006, bias2: 0.9794465899467468, variance: 0.023559389635920525\n",
      "Train size: [400] hidden size: [14] trial: 21, train_loss: 1.904622, test loss: 1.002758, bias2: 0.9792604446411133, variance: 0.023497719317674637\n",
      "Train size: [400] hidden size: [14] trial: 22, train_loss: 1.909245, test loss: 1.002937, bias2: 0.9783645272254944, variance: 0.024572692811489105\n",
      "Train size: [400] hidden size: [14] trial: 23, train_loss: 1.910629, test loss: 1.003220, bias2: 0.9786589741706848, variance: 0.024561110883951187\n",
      "Train size: [400] hidden size: [14] trial: 24, train_loss: 1.913749, test loss: 1.003896, bias2: 0.9793267250061035, variance: 0.024569639936089516\n",
      "Train size: [400] hidden size: [14] trial: 25, train_loss: 1.913589, test loss: 1.002992, bias2: 0.9785268902778625, variance: 0.024464918300509453\n",
      "Train size: [400] hidden size: [14] trial: 26, train_loss: 1.913332, test loss: 1.002743, bias2: 0.9782848358154297, variance: 0.02445780485868454\n",
      "Train size: [400] hidden size: [14] trial: 27, train_loss: 1.910367, test loss: 1.003614, bias2: 0.9783288836479187, variance: 0.02528507634997368\n",
      "Train size: [400] hidden size: [14] trial: 28, train_loss: 1.915802, test loss: 1.003322, bias2: 0.978514552116394, variance: 0.02480742335319519\n",
      "Train size: [400] hidden size: [14] trial: 29, train_loss: 1.922582, test loss: 1.003736, bias2: 0.9791916012763977, variance: 0.024544795975089073\n",
      "Train size: [400] hidden size: [14] trial: 30, train_loss: 1.921632, test loss: 1.003417, bias2: 0.9789783954620361, variance: 0.024438371881842613\n",
      "Train size: [400] hidden size: [14] trial: 31, train_loss: 1.920729, test loss: 1.003233, bias2: 0.9791476726531982, variance: 0.024085262790322304\n",
      "Train size: [400] hidden size: [14] trial: 32, train_loss: 1.921733, test loss: 1.003522, bias2: 0.9792042374610901, variance: 0.024317791685461998\n",
      "Train size: [400] hidden size: [14] trial: 33, train_loss: 1.921969, test loss: 1.003576, bias2: 0.9793180227279663, variance: 0.024258367717266083\n",
      "Train size: [400] hidden size: [14] trial: 34, train_loss: 1.922411, test loss: 1.003877, bias2: 0.9797513484954834, variance: 0.024125313386321068\n",
      "Train size: [400] hidden size: [14] trial: 35, train_loss: 1.926018, test loss: 1.003924, bias2: 0.9796335101127625, variance: 0.024290475994348526\n",
      "Train size: [400] hidden size: [14] trial: 36, train_loss: 1.926477, test loss: 1.003567, bias2: 0.9791598320007324, variance: 0.024407532066106796\n",
      "Train size: [400] hidden size: [14] trial: 37, train_loss: 1.924533, test loss: 1.003974, bias2: 0.97939532995224, variance: 0.024578630924224854\n",
      "Train size: [400] hidden size: [14] trial: 38, train_loss: 1.922668, test loss: 1.003683, bias2: 0.9793274402618408, variance: 0.024355778470635414\n",
      "Train size: [400] hidden size: [14] trial: 39, train_loss: 1.927044, test loss: 1.003337, bias2: 0.9791180491447449, variance: 0.024218766018748283\n",
      "Train size: [400] hidden size: [14] trial: 40, train_loss: 1.925912, test loss: 1.002968, bias2: 0.978635311126709, variance: 0.02433238923549652\n",
      "Train size: [400] hidden size: [14] trial: 41, train_loss: 1.929133, test loss: 1.003548, bias2: 0.9786606431007385, variance: 0.024886902421712875\n",
      "Train size: [400] hidden size: [14] trial: 42, train_loss: 1.925465, test loss: 1.003205, bias2: 0.9784386157989502, variance: 0.024766217917203903\n",
      "Train size: [400] hidden size: [14] trial: 43, train_loss: 1.927141, test loss: 1.003021, bias2: 0.9784524440765381, variance: 0.0245682206004858\n",
      "Train size: [400] hidden size: [14] trial: 44, train_loss: 1.927811, test loss: 1.003081, bias2: 0.9786590337753296, variance: 0.0244224164634943\n",
      "Train size: [400] hidden size: [14] trial: 45, train_loss: 1.929758, test loss: 1.003185, bias2: 0.9785736203193665, variance: 0.024611778557300568\n",
      "Train size: [400] hidden size: [14] trial: 46, train_loss: 1.928928, test loss: 1.003313, bias2: 0.9784029722213745, variance: 0.024909626692533493\n",
      "Train size: [400] hidden size: [14] trial: 47, train_loss: 1.927736, test loss: 1.003508, bias2: 0.9780367016792297, variance: 0.025471005588769913\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [14] trial: 48, train_loss: 1.927772, test loss: 1.003135, bias2: 0.9776371121406555, variance: 0.025497734546661377\n",
      "Train size: [400] hidden size: [14] trial: 49, train_loss: 1.922438, test loss: 1.002972, bias2: 0.9776861667633057, variance: 0.02528560534119606\n",
      "##################################################\n",
      "Train size: [400] hidden size: [16] trial: 0, train_loss: 1.784898, test loss: 1.002777, bias2: 1.0027774572372437, variance: 2.4328424691466566e-11\n",
      "Train size: [400] hidden size: [16] trial: 1, train_loss: 1.756770, test loss: 1.000416, bias2: 0.9893403053283691, variance: 0.011075874790549278\n",
      "Train size: [400] hidden size: [16] trial: 2, train_loss: 1.792415, test loss: 1.000633, bias2: 0.9845549464225769, variance: 0.016077807173132896\n",
      "Train size: [400] hidden size: [16] trial: 3, train_loss: 1.843956, test loss: 0.997970, bias2: 0.9778861999511719, variance: 0.02008412964642048\n",
      "Train size: [400] hidden size: [16] trial: 4, train_loss: 1.849540, test loss: 0.999854, bias2: 0.9772602915763855, variance: 0.022593315690755844\n",
      "Train size: [400] hidden size: [16] trial: 5, train_loss: 1.851010, test loss: 1.000223, bias2: 0.9710699319839478, variance: 0.02915349043905735\n",
      "Train size: [400] hidden size: [16] trial: 6, train_loss: 1.898325, test loss: 0.998113, bias2: 0.9684113264083862, variance: 0.029701748862862587\n",
      "Train size: [400] hidden size: [16] trial: 7, train_loss: 1.907626, test loss: 0.999353, bias2: 0.9677470922470093, variance: 0.031606290489435196\n",
      "Train size: [400] hidden size: [16] trial: 8, train_loss: 1.911318, test loss: 0.999383, bias2: 0.9689324498176575, variance: 0.03045075200498104\n",
      "Train size: [400] hidden size: [16] trial: 9, train_loss: 1.911531, test loss: 0.999158, bias2: 0.9693596363067627, variance: 0.029798686504364014\n",
      "Train size: [400] hidden size: [16] trial: 10, train_loss: 1.909371, test loss: 1.000031, bias2: 0.9702352285385132, variance: 0.029796231538057327\n",
      "Train size: [400] hidden size: [16] trial: 11, train_loss: 1.903637, test loss: 0.999638, bias2: 0.9692627787590027, variance: 0.030375532805919647\n",
      "Train size: [400] hidden size: [16] trial: 12, train_loss: 1.903918, test loss: 0.998549, bias2: 0.9676144123077393, variance: 0.030935073271393776\n",
      "Train size: [400] hidden size: [16] trial: 13, train_loss: 1.908698, test loss: 0.998794, bias2: 0.965907096862793, variance: 0.03288652375340462\n",
      "Train size: [400] hidden size: [16] trial: 14, train_loss: 1.916433, test loss: 0.998466, bias2: 0.9650445580482483, variance: 0.0334213525056839\n",
      "Train size: [400] hidden size: [16] trial: 15, train_loss: 1.912369, test loss: 1.000744, bias2: 0.9662690758705139, variance: 0.03447513282299042\n",
      "Train size: [400] hidden size: [16] trial: 16, train_loss: 1.911987, test loss: 0.999960, bias2: 0.9659390449523926, variance: 0.03402060642838478\n",
      "Train size: [400] hidden size: [16] trial: 17, train_loss: 1.908107, test loss: 0.999890, bias2: 0.9660959839820862, variance: 0.033794011920690536\n",
      "Train size: [400] hidden size: [16] trial: 18, train_loss: 1.898065, test loss: 0.999784, bias2: 0.966285228729248, variance: 0.033498410135507584\n",
      "Train size: [400] hidden size: [16] trial: 19, train_loss: 1.899162, test loss: 0.999708, bias2: 0.9667133092880249, variance: 0.032994382083415985\n",
      "Train size: [400] hidden size: [16] trial: 20, train_loss: 1.915005, test loss: 1.000053, bias2: 0.9672868251800537, variance: 0.03276659548282623\n",
      "Train size: [400] hidden size: [16] trial: 21, train_loss: 1.904985, test loss: 1.000496, bias2: 0.9679552912712097, variance: 0.032540999352931976\n",
      "Train size: [400] hidden size: [16] trial: 22, train_loss: 1.906336, test loss: 1.000399, bias2: 0.9685580134391785, variance: 0.03184050694108009\n",
      "Train size: [400] hidden size: [16] trial: 23, train_loss: 1.904692, test loss: 1.000889, bias2: 0.9696046710014343, variance: 0.031284648925065994\n",
      "Train size: [400] hidden size: [16] trial: 24, train_loss: 1.910760, test loss: 1.000519, bias2: 0.9696736335754395, variance: 0.030845778062939644\n",
      "Train size: [400] hidden size: [16] trial: 25, train_loss: 1.906533, test loss: 1.000272, bias2: 0.9698291420936584, variance: 0.030442629009485245\n",
      "Train size: [400] hidden size: [16] trial: 26, train_loss: 1.909721, test loss: 1.000235, bias2: 0.9696241021156311, variance: 0.03061096929013729\n",
      "Train size: [400] hidden size: [16] trial: 27, train_loss: 1.912665, test loss: 1.000431, bias2: 0.969731867313385, variance: 0.03069930337369442\n",
      "Train size: [400] hidden size: [16] trial: 28, train_loss: 1.917191, test loss: 1.000797, bias2: 0.9694095849990845, variance: 0.031387463212013245\n",
      "Train size: [400] hidden size: [16] trial: 29, train_loss: 1.921284, test loss: 1.001217, bias2: 0.9697314500808716, variance: 0.0314859114587307\n",
      "Train size: [400] hidden size: [16] trial: 30, train_loss: 1.922600, test loss: 1.001179, bias2: 0.9696541428565979, variance: 0.03152438625693321\n",
      "Train size: [400] hidden size: [16] trial: 31, train_loss: 1.922145, test loss: 1.001037, bias2: 0.9696860909461975, variance: 0.03135065361857414\n",
      "Train size: [400] hidden size: [16] trial: 32, train_loss: 1.926835, test loss: 1.001528, bias2: 0.9696066379547119, variance: 0.031921759247779846\n",
      "Train size: [400] hidden size: [16] trial: 33, train_loss: 1.922240, test loss: 1.001643, bias2: 0.970319926738739, variance: 0.031322527676820755\n",
      "Train size: [400] hidden size: [16] trial: 34, train_loss: 1.928092, test loss: 1.001727, bias2: 0.9703478813171387, variance: 0.03137886896729469\n",
      "Train size: [400] hidden size: [16] trial: 35, train_loss: 1.925243, test loss: 1.001745, bias2: 0.9708348512649536, variance: 0.03090999275445938\n",
      "Train size: [400] hidden size: [16] trial: 36, train_loss: 1.928615, test loss: 1.001142, bias2: 0.9700092673301697, variance: 0.031132904812693596\n",
      "Train size: [400] hidden size: [16] trial: 37, train_loss: 1.928602, test loss: 1.000898, bias2: 0.9698823690414429, variance: 0.031016003340482712\n",
      "Train size: [400] hidden size: [16] trial: 38, train_loss: 1.924763, test loss: 1.001255, bias2: 0.9701810479164124, variance: 0.031073614954948425\n",
      "Train size: [400] hidden size: [16] trial: 39, train_loss: 1.921039, test loss: 1.001331, bias2: 0.9701674580574036, variance: 0.031163010746240616\n",
      "Train size: [400] hidden size: [16] trial: 40, train_loss: 1.919593, test loss: 1.001177, bias2: 0.9700337052345276, variance: 0.031143002212047577\n",
      "Train size: [400] hidden size: [16] trial: 41, train_loss: 1.917436, test loss: 1.000770, bias2: 0.9696348309516907, variance: 0.03113492764532566\n",
      "Train size: [400] hidden size: [16] trial: 42, train_loss: 1.917707, test loss: 1.000135, bias2: 0.9686478972434998, variance: 0.03148682788014412\n",
      "Train size: [400] hidden size: [16] trial: 43, train_loss: 1.916359, test loss: 1.000172, bias2: 0.9690408706665039, variance: 0.031131405383348465\n",
      "Train size: [400] hidden size: [16] trial: 44, train_loss: 1.920272, test loss: 1.000569, bias2: 0.9692884683609009, variance: 0.03128017112612724\n",
      "Train size: [400] hidden size: [16] trial: 45, train_loss: 1.921269, test loss: 1.000678, bias2: 0.9696044325828552, variance: 0.031073173508048058\n",
      "Train size: [400] hidden size: [16] trial: 46, train_loss: 1.919315, test loss: 1.000561, bias2: 0.9696290493011475, variance: 0.030931945890188217\n",
      "Train size: [400] hidden size: [16] trial: 47, train_loss: 1.921232, test loss: 1.000320, bias2: 0.9691325426101685, variance: 0.0311875119805336\n",
      "Train size: [400] hidden size: [16] trial: 48, train_loss: 1.923773, test loss: 1.000253, bias2: 0.968904435634613, variance: 0.031348418444395065\n",
      "Train size: [400] hidden size: [16] trial: 49, train_loss: 1.927549, test loss: 1.000318, bias2: 0.9688676595687866, variance: 0.03145039454102516\n",
      "##################################################\n",
      "Train size: [400] hidden size: [19] trial: 0, train_loss: 1.760501, test loss: 1.000960, bias2: 1.0009599924087524, variance: 0.0\n",
      "Train size: [400] hidden size: [19] trial: 1, train_loss: 1.846899, test loss: 1.010979, bias2: 0.984950065612793, variance: 0.02602861262857914\n",
      "Train size: [400] hidden size: [19] trial: 2, train_loss: 1.858541, test loss: 1.007843, bias2: 0.978915274143219, variance: 0.028927527368068695\n",
      "Train size: [400] hidden size: [19] trial: 3, train_loss: 1.873291, test loss: 1.009974, bias2: 0.9795250296592712, variance: 0.030448714271187782\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [19] trial: 4, train_loss: 1.906319, test loss: 1.009274, bias2: 0.9811251163482666, variance: 0.028148798272013664\n",
      "Train size: [400] hidden size: [19] trial: 5, train_loss: 1.879416, test loss: 1.007746, bias2: 0.9792395234107971, variance: 0.0285062026232481\n",
      "Train size: [400] hidden size: [19] trial: 6, train_loss: 1.900467, test loss: 1.004698, bias2: 0.974820613861084, variance: 0.02987741120159626\n",
      "Train size: [400] hidden size: [19] trial: 7, train_loss: 1.881960, test loss: 1.003859, bias2: 0.9719251394271851, variance: 0.03193413466215134\n",
      "Train size: [400] hidden size: [19] trial: 8, train_loss: 1.926198, test loss: 1.005708, bias2: 0.9699720144271851, variance: 0.03573574125766754\n",
      "Train size: [400] hidden size: [19] trial: 9, train_loss: 1.912059, test loss: 1.004082, bias2: 0.9701544642448425, variance: 0.03392786905169487\n",
      "Train size: [400] hidden size: [19] trial: 10, train_loss: 1.900532, test loss: 1.002799, bias2: 0.9687809944152832, variance: 0.03401791304349899\n",
      "Train size: [400] hidden size: [19] trial: 11, train_loss: 1.906010, test loss: 1.003030, bias2: 0.9695717692375183, variance: 0.03345828130841255\n",
      "Train size: [400] hidden size: [19] trial: 12, train_loss: 1.905478, test loss: 1.002307, bias2: 0.9681927561759949, variance: 0.0341138131916523\n",
      "Train size: [400] hidden size: [19] trial: 13, train_loss: 1.895288, test loss: 1.002213, bias2: 0.9679303765296936, variance: 0.03428298979997635\n",
      "Train size: [400] hidden size: [19] trial: 14, train_loss: 1.904567, test loss: 1.002018, bias2: 0.9680979251861572, variance: 0.033919792622327805\n",
      "Train size: [400] hidden size: [19] trial: 15, train_loss: 1.910227, test loss: 1.002366, bias2: 0.9692136645317078, variance: 0.033152271062135696\n",
      "Train size: [400] hidden size: [19] trial: 16, train_loss: 1.919298, test loss: 1.003277, bias2: 0.9701734185218811, variance: 0.03310353308916092\n",
      "Train size: [400] hidden size: [19] trial: 17, train_loss: 1.919610, test loss: 1.003813, bias2: 0.971518874168396, variance: 0.032294247299432755\n",
      "Train size: [400] hidden size: [19] trial: 18, train_loss: 1.916711, test loss: 1.002666, bias2: 0.9702154994010925, variance: 0.03245050832629204\n",
      "Train size: [400] hidden size: [19] trial: 19, train_loss: 1.916030, test loss: 1.002316, bias2: 0.9691476225852966, variance: 0.03316836804151535\n",
      "Train size: [400] hidden size: [19] trial: 20, train_loss: 1.915519, test loss: 1.002198, bias2: 0.9697858691215515, variance: 0.03241237625479698\n",
      "Train size: [400] hidden size: [19] trial: 21, train_loss: 1.905860, test loss: 1.001942, bias2: 0.9696293473243713, variance: 0.03231256455183029\n",
      "Train size: [400] hidden size: [19] trial: 22, train_loss: 1.904491, test loss: 1.002498, bias2: 0.9701970815658569, variance: 0.032301194965839386\n",
      "Train size: [400] hidden size: [19] trial: 23, train_loss: 1.902578, test loss: 1.002326, bias2: 0.9692519307136536, variance: 0.03307373821735382\n",
      "Train size: [400] hidden size: [19] trial: 24, train_loss: 1.906294, test loss: 1.001689, bias2: 0.969048261642456, variance: 0.03264021873474121\n",
      "Train size: [400] hidden size: [19] trial: 25, train_loss: 1.911506, test loss: 1.001524, bias2: 0.9679231643676758, variance: 0.033600542694330215\n",
      "Train size: [400] hidden size: [19] trial: 26, train_loss: 1.906112, test loss: 1.003188, bias2: 0.9684316515922546, variance: 0.03475622087717056\n",
      "Train size: [400] hidden size: [19] trial: 27, train_loss: 1.912045, test loss: 1.003062, bias2: 0.968601405620575, variance: 0.03446037694811821\n",
      "Train size: [400] hidden size: [19] trial: 28, train_loss: 1.914061, test loss: 1.003445, bias2: 0.9689226746559143, variance: 0.03452247753739357\n",
      "Train size: [400] hidden size: [19] trial: 29, train_loss: 1.914870, test loss: 1.004261, bias2: 0.9702067375183105, variance: 0.03405463322997093\n",
      "Train size: [400] hidden size: [19] trial: 30, train_loss: 1.909078, test loss: 1.003754, bias2: 0.9696035981178284, variance: 0.03415040671825409\n",
      "Train size: [400] hidden size: [19] trial: 31, train_loss: 1.909804, test loss: 1.003319, bias2: 0.969170093536377, variance: 0.034148477017879486\n",
      "Train size: [400] hidden size: [19] trial: 32, train_loss: 1.912163, test loss: 1.003569, bias2: 0.9699707627296448, variance: 0.033598724752664566\n",
      "Train size: [400] hidden size: [19] trial: 33, train_loss: 1.917045, test loss: 1.003378, bias2: 0.969549834728241, variance: 0.033828090876340866\n",
      "Train size: [400] hidden size: [19] trial: 34, train_loss: 1.917897, test loss: 1.003379, bias2: 0.9699444770812988, variance: 0.033434126526117325\n",
      "Train size: [400] hidden size: [19] trial: 35, train_loss: 1.916862, test loss: 1.002835, bias2: 0.9693058133125305, variance: 0.03352959081530571\n",
      "Train size: [400] hidden size: [19] trial: 36, train_loss: 1.917002, test loss: 1.002605, bias2: 0.9691847562789917, variance: 0.03342021256685257\n",
      "Train size: [400] hidden size: [19] trial: 37, train_loss: 1.911893, test loss: 1.002243, bias2: 0.9683271646499634, variance: 0.03391597419977188\n",
      "Train size: [400] hidden size: [19] trial: 38, train_loss: 1.914193, test loss: 1.001417, bias2: 0.9676657915115356, variance: 0.03375101462006569\n",
      "Train size: [400] hidden size: [19] trial: 39, train_loss: 1.917583, test loss: 1.001366, bias2: 0.9679296016693115, variance: 0.033436037600040436\n",
      "Train size: [400] hidden size: [19] trial: 40, train_loss: 1.912844, test loss: 1.001391, bias2: 0.9672837853431702, variance: 0.034107618033885956\n",
      "Train size: [400] hidden size: [19] trial: 41, train_loss: 1.912459, test loss: 1.001219, bias2: 0.9672124981880188, variance: 0.03400630131363869\n",
      "Train size: [400] hidden size: [19] trial: 42, train_loss: 1.907481, test loss: 1.001179, bias2: 0.9668391942977905, variance: 0.034339539706707\n",
      "Train size: [400] hidden size: [19] trial: 43, train_loss: 1.906987, test loss: 1.001103, bias2: 0.9668556451797485, variance: 0.034247610718011856\n",
      "Train size: [400] hidden size: [19] trial: 44, train_loss: 1.905929, test loss: 1.001302, bias2: 0.9671026468276978, variance: 0.03419945016503334\n",
      "Train size: [400] hidden size: [19] trial: 45, train_loss: 1.899901, test loss: 1.001641, bias2: 0.9674696326255798, variance: 0.03417185693979263\n",
      "Train size: [400] hidden size: [19] trial: 46, train_loss: 1.902667, test loss: 1.001877, bias2: 0.9678214192390442, variance: 0.03405575454235077\n",
      "Train size: [400] hidden size: [19] trial: 47, train_loss: 1.898204, test loss: 1.002119, bias2: 0.9681355357170105, variance: 0.033983539789915085\n",
      "Train size: [400] hidden size: [19] trial: 48, train_loss: 1.900170, test loss: 1.002052, bias2: 0.9682552218437195, variance: 0.03379734233021736\n",
      "Train size: [400] hidden size: [19] trial: 49, train_loss: 1.902640, test loss: 1.002355, bias2: 0.968127965927124, variance: 0.03422723338007927\n",
      "##################################################\n",
      "Train size: [400] hidden size: [22] trial: 0, train_loss: 1.715072, test loss: 0.985428, bias2: 0.9854283928871155, variance: -6.082106346338989e-11\n",
      "Train size: [400] hidden size: [22] trial: 1, train_loss: 1.766029, test loss: 0.990246, bias2: 0.9748144149780273, variance: 0.01543203741312027\n",
      "Train size: [400] hidden size: [22] trial: 2, train_loss: 1.683320, test loss: 0.991800, bias2: 0.9694997668266296, variance: 0.022300079464912415\n",
      "Train size: [400] hidden size: [22] trial: 3, train_loss: 1.727575, test loss: 0.993473, bias2: 0.9686570763587952, variance: 0.024815758690238\n",
      "Train size: [400] hidden size: [22] trial: 4, train_loss: 1.734981, test loss: 0.992582, bias2: 0.9694942831993103, variance: 0.023088060319423676\n",
      "Train size: [400] hidden size: [22] trial: 5, train_loss: 1.756184, test loss: 0.995114, bias2: 0.9697788953781128, variance: 0.025334736332297325\n",
      "Train size: [400] hidden size: [22] trial: 6, train_loss: 1.802425, test loss: 0.996538, bias2: 0.9681187868118286, variance: 0.028418969362974167\n",
      "Train size: [400] hidden size: [22] trial: 7, train_loss: 1.786271, test loss: 0.999876, bias2: 0.9712925553321838, variance: 0.02858361043035984\n",
      "Train size: [400] hidden size: [22] trial: 8, train_loss: 1.798475, test loss: 1.001212, bias2: 0.9723591208457947, variance: 0.02885241061449051\n",
      "Train size: [400] hidden size: [22] trial: 9, train_loss: 1.789742, test loss: 1.005156, bias2: 0.9739522933959961, variance: 0.031203845515847206\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [22] trial: 10, train_loss: 1.790686, test loss: 1.006412, bias2: 0.9757694602012634, variance: 0.03064212016761303\n",
      "Train size: [400] hidden size: [22] trial: 11, train_loss: 1.796662, test loss: 1.004803, bias2: 0.9727247357368469, variance: 0.032078422605991364\n",
      "Train size: [400] hidden size: [22] trial: 12, train_loss: 1.811759, test loss: 1.002833, bias2: 0.9699105620384216, variance: 0.03292243182659149\n",
      "Train size: [400] hidden size: [22] trial: 13, train_loss: 1.813897, test loss: 1.004804, bias2: 0.9711741209030151, variance: 0.03362944722175598\n",
      "Train size: [400] hidden size: [22] trial: 14, train_loss: 1.833001, test loss: 1.006375, bias2: 0.9733156561851501, variance: 0.03305891901254654\n",
      "Train size: [400] hidden size: [22] trial: 15, train_loss: 1.842327, test loss: 1.004828, bias2: 0.971177875995636, variance: 0.033649999648332596\n",
      "Train size: [400] hidden size: [22] trial: 16, train_loss: 1.837590, test loss: 1.002642, bias2: 0.9689017534255981, variance: 0.033740416169166565\n",
      "Train size: [400] hidden size: [22] trial: 17, train_loss: 1.851929, test loss: 1.002332, bias2: 0.9695427417755127, variance: 0.03278885409235954\n",
      "Train size: [400] hidden size: [22] trial: 18, train_loss: 1.856182, test loss: 1.004798, bias2: 0.9703058004379272, variance: 0.03449248895049095\n",
      "Train size: [400] hidden size: [22] trial: 19, train_loss: 1.861526, test loss: 1.003772, bias2: 0.9686790108680725, variance: 0.03509299084544182\n",
      "Train size: [400] hidden size: [22] trial: 20, train_loss: 1.868758, test loss: 1.003647, bias2: 0.9678810238838196, variance: 0.03576591983437538\n",
      "Train size: [400] hidden size: [22] trial: 21, train_loss: 1.862030, test loss: 1.002970, bias2: 0.9673484563827515, variance: 0.03562190383672714\n",
      "Train size: [400] hidden size: [22] trial: 22, train_loss: 1.860821, test loss: 1.002053, bias2: 0.9657697677612305, variance: 0.03628350794315338\n",
      "Train size: [400] hidden size: [22] trial: 23, train_loss: 1.861917, test loss: 1.000996, bias2: 0.964697539806366, variance: 0.03629820793867111\n",
      "Train size: [400] hidden size: [22] trial: 24, train_loss: 1.858975, test loss: 1.001180, bias2: 0.964283287525177, variance: 0.03689674660563469\n",
      "Train size: [400] hidden size: [22] trial: 25, train_loss: 1.860802, test loss: 1.001094, bias2: 0.9616370797157288, variance: 0.0394568108022213\n",
      "Train size: [400] hidden size: [22] trial: 26, train_loss: 1.857256, test loss: 1.000429, bias2: 0.9612800478935242, variance: 0.03914923593401909\n",
      "Train size: [400] hidden size: [22] trial: 27, train_loss: 1.856180, test loss: 1.000534, bias2: 0.9620490670204163, variance: 0.038485001772642136\n",
      "Train size: [400] hidden size: [22] trial: 28, train_loss: 1.854858, test loss: 1.000268, bias2: 0.9618950486183167, variance: 0.03837328776717186\n",
      "Train size: [400] hidden size: [22] trial: 29, train_loss: 1.861291, test loss: 1.000537, bias2: 0.9614976644515991, variance: 0.03903950750827789\n",
      "Train size: [400] hidden size: [22] trial: 30, train_loss: 1.860348, test loss: 1.001375, bias2: 0.9621755480766296, variance: 0.03919975087046623\n",
      "Train size: [400] hidden size: [22] trial: 31, train_loss: 1.865160, test loss: 1.001102, bias2: 0.9613264799118042, variance: 0.039775244891643524\n",
      "Train size: [400] hidden size: [22] trial: 32, train_loss: 1.869668, test loss: 1.001647, bias2: 0.9617044925689697, variance: 0.039942532777786255\n",
      "Train size: [400] hidden size: [22] trial: 33, train_loss: 1.879055, test loss: 1.001455, bias2: 0.9617270231246948, variance: 0.03972792625427246\n",
      "Train size: [400] hidden size: [22] trial: 34, train_loss: 1.878478, test loss: 1.001379, bias2: 0.9618661403656006, variance: 0.039513226598501205\n",
      "Train size: [400] hidden size: [22] trial: 35, train_loss: 1.877846, test loss: 1.002685, bias2: 0.9628231525421143, variance: 0.03986131399869919\n",
      "Train size: [400] hidden size: [22] trial: 36, train_loss: 1.875754, test loss: 1.002770, bias2: 0.9631235003471375, variance: 0.0396466888487339\n",
      "Train size: [400] hidden size: [22] trial: 37, train_loss: 1.873230, test loss: 1.002882, bias2: 0.9634063839912415, variance: 0.039475392550230026\n",
      "Train size: [400] hidden size: [22] trial: 38, train_loss: 1.871668, test loss: 1.002947, bias2: 0.9635611772537231, variance: 0.039385586977005005\n",
      "Train size: [400] hidden size: [22] trial: 39, train_loss: 1.870629, test loss: 1.003225, bias2: 0.9639371633529663, variance: 0.039287835359573364\n",
      "Train size: [400] hidden size: [22] trial: 40, train_loss: 1.873653, test loss: 1.003021, bias2: 0.9640253782272339, variance: 0.03899600729346275\n",
      "Train size: [400] hidden size: [22] trial: 41, train_loss: 1.875961, test loss: 1.002555, bias2: 0.9635159373283386, variance: 0.039039332419633865\n",
      "Train size: [400] hidden size: [22] trial: 42, train_loss: 1.877208, test loss: 1.002796, bias2: 0.9642814993858337, variance: 0.03851441293954849\n",
      "Train size: [400] hidden size: [22] trial: 43, train_loss: 1.877766, test loss: 1.002767, bias2: 0.9643042683601379, variance: 0.03846316039562225\n",
      "Train size: [400] hidden size: [22] trial: 44, train_loss: 1.879936, test loss: 1.002615, bias2: 0.9642276167869568, variance: 0.03838711604475975\n",
      "Train size: [400] hidden size: [22] trial: 45, train_loss: 1.882730, test loss: 1.002983, bias2: 0.9648464918136597, variance: 0.03813695162534714\n",
      "Train size: [400] hidden size: [22] trial: 46, train_loss: 1.878563, test loss: 1.002829, bias2: 0.9646921157836914, variance: 0.038136985152959824\n",
      "Train size: [400] hidden size: [22] trial: 47, train_loss: 1.879180, test loss: 1.003321, bias2: 0.964843213558197, variance: 0.03847821429371834\n",
      "Train size: [400] hidden size: [22] trial: 48, train_loss: 1.883764, test loss: 1.003740, bias2: 0.9647501111030579, variance: 0.03898993879556656\n",
      "Train size: [400] hidden size: [22] trial: 49, train_loss: 1.880669, test loss: 1.003667, bias2: 0.9651576280593872, variance: 0.03850949928164482\n",
      "##################################################\n",
      "Train size: [400] hidden size: [25] trial: 0, train_loss: 1.908818, test loss: 0.988056, bias2: 0.9880557656288147, variance: 0.0\n",
      "Train size: [400] hidden size: [25] trial: 1, train_loss: 1.742960, test loss: 0.994532, bias2: 0.9760134220123291, variance: 0.018518783152103424\n",
      "Train size: [400] hidden size: [25] trial: 2, train_loss: 1.752354, test loss: 0.992356, bias2: 0.9595571160316467, variance: 0.03279917687177658\n",
      "Train size: [400] hidden size: [25] trial: 3, train_loss: 1.816962, test loss: 0.991842, bias2: 0.9532519578933716, variance: 0.03858986496925354\n",
      "Train size: [400] hidden size: [25] trial: 4, train_loss: 1.839383, test loss: 0.991520, bias2: 0.9501805305480957, variance: 0.04133960232138634\n",
      "Train size: [400] hidden size: [25] trial: 5, train_loss: 1.835327, test loss: 0.990135, bias2: 0.9495862722396851, variance: 0.04054884612560272\n",
      "Train size: [400] hidden size: [25] trial: 6, train_loss: 1.840188, test loss: 0.994075, bias2: 0.9477266073226929, variance: 0.04634794220328331\n",
      "Train size: [400] hidden size: [25] trial: 7, train_loss: 1.892065, test loss: 0.994979, bias2: 0.9484815001487732, variance: 0.046497032046318054\n",
      "Train size: [400] hidden size: [25] trial: 8, train_loss: 1.884253, test loss: 0.997903, bias2: 0.9528775215148926, variance: 0.0450252927839756\n",
      "Train size: [400] hidden size: [25] trial: 9, train_loss: 1.873470, test loss: 0.998485, bias2: 0.9532119631767273, variance: 0.04527268558740616\n",
      "Train size: [400] hidden size: [25] trial: 10, train_loss: 1.848338, test loss: 0.999069, bias2: 0.9550959467887878, variance: 0.04397322237491608\n",
      "Train size: [400] hidden size: [25] trial: 11, train_loss: 1.833290, test loss: 0.998508, bias2: 0.955009937286377, variance: 0.04349798336625099\n",
      "Train size: [400] hidden size: [25] trial: 12, train_loss: 1.836199, test loss: 0.997131, bias2: 0.9542731642723083, variance: 0.04285812750458717\n",
      "Train size: [400] hidden size: [25] trial: 13, train_loss: 1.825611, test loss: 1.001167, bias2: 0.9570406079292297, variance: 0.044126320630311966\n",
      "Train size: [400] hidden size: [25] trial: 14, train_loss: 1.817617, test loss: 1.000515, bias2: 0.9564884901046753, variance: 0.04402659833431244\n",
      "Train size: [400] hidden size: [25] trial: 15, train_loss: 1.821039, test loss: 0.999569, bias2: 0.9550825953483582, variance: 0.04448652267456055\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [25] trial: 16, train_loss: 1.833535, test loss: 0.999054, bias2: 0.9553883671760559, variance: 0.043665457516908646\n",
      "Train size: [400] hidden size: [25] trial: 17, train_loss: 1.829714, test loss: 0.999253, bias2: 0.9551118612289429, variance: 0.0441410057246685\n",
      "Train size: [400] hidden size: [25] trial: 18, train_loss: 1.825124, test loss: 1.000383, bias2: 0.9553561210632324, variance: 0.04502679780125618\n",
      "Train size: [400] hidden size: [25] trial: 19, train_loss: 1.820045, test loss: 0.999856, bias2: 0.9553794264793396, variance: 0.044476769864559174\n",
      "Train size: [400] hidden size: [25] trial: 20, train_loss: 1.824661, test loss: 0.999939, bias2: 0.955829381942749, variance: 0.044109392911195755\n",
      "Train size: [400] hidden size: [25] trial: 21, train_loss: 1.827271, test loss: 1.001085, bias2: 0.9565914273262024, variance: 0.044493164867162704\n",
      "Train size: [400] hidden size: [25] trial: 22, train_loss: 1.830944, test loss: 1.000709, bias2: 0.9565669894218445, variance: 0.044141825288534164\n",
      "Train size: [400] hidden size: [25] trial: 23, train_loss: 1.829766, test loss: 1.001256, bias2: 0.9570291638374329, variance: 0.04422647878527641\n",
      "Train size: [400] hidden size: [25] trial: 24, train_loss: 1.837630, test loss: 1.001861, bias2: 0.9579477310180664, variance: 0.0439131073653698\n",
      "Train size: [400] hidden size: [25] trial: 25, train_loss: 1.844989, test loss: 1.002830, bias2: 0.9586449861526489, variance: 0.04418538510799408\n",
      "Train size: [400] hidden size: [25] trial: 26, train_loss: 1.840774, test loss: 1.002050, bias2: 0.9581073522567749, variance: 0.043942444026470184\n",
      "Train size: [400] hidden size: [25] trial: 27, train_loss: 1.843985, test loss: 1.002113, bias2: 0.9579052925109863, variance: 0.044207554310560226\n",
      "Train size: [400] hidden size: [25] trial: 28, train_loss: 1.843270, test loss: 1.002062, bias2: 0.9581374526023865, variance: 0.0439249649643898\n",
      "Train size: [400] hidden size: [25] trial: 29, train_loss: 1.841234, test loss: 1.002003, bias2: 0.9580707550048828, variance: 0.04393266886472702\n",
      "Train size: [400] hidden size: [25] trial: 30, train_loss: 1.847284, test loss: 1.003669, bias2: 0.9593004584312439, variance: 0.04436834901571274\n",
      "Train size: [400] hidden size: [25] trial: 31, train_loss: 1.854645, test loss: 1.003975, bias2: 0.9587999582290649, variance: 0.045174598693847656\n",
      "Train size: [400] hidden size: [25] trial: 32, train_loss: 1.856048, test loss: 1.003994, bias2: 0.9592069387435913, variance: 0.04478738084435463\n",
      "Train size: [400] hidden size: [25] trial: 33, train_loss: 1.855458, test loss: 1.003748, bias2: 0.9588658213615417, variance: 0.044881779700517654\n",
      "Train size: [400] hidden size: [25] trial: 34, train_loss: 1.858161, test loss: 1.004111, bias2: 0.9588237404823303, variance: 0.04528716579079628\n",
      "Train size: [400] hidden size: [25] trial: 35, train_loss: 1.862079, test loss: 1.004258, bias2: 0.9594371318817139, variance: 0.04482056945562363\n",
      "Train size: [400] hidden size: [25] trial: 36, train_loss: 1.865844, test loss: 1.004008, bias2: 0.9597051739692688, variance: 0.04430250823497772\n",
      "Train size: [400] hidden size: [25] trial: 37, train_loss: 1.864676, test loss: 1.003554, bias2: 0.9594184756278992, variance: 0.044135499745607376\n",
      "Train size: [400] hidden size: [25] trial: 38, train_loss: 1.864228, test loss: 1.002829, bias2: 0.9580970406532288, variance: 0.04473217576742172\n",
      "Train size: [400] hidden size: [25] trial: 39, train_loss: 1.862188, test loss: 1.003065, bias2: 0.95750492811203, variance: 0.04556017369031906\n",
      "Train size: [400] hidden size: [25] trial: 40, train_loss: 1.862689, test loss: 1.002527, bias2: 0.9566055536270142, variance: 0.04592132940888405\n",
      "Train size: [400] hidden size: [25] trial: 41, train_loss: 1.864095, test loss: 1.002715, bias2: 0.9568181037902832, variance: 0.04589679837226868\n",
      "Train size: [400] hidden size: [25] trial: 42, train_loss: 1.862024, test loss: 1.002426, bias2: 0.9564569592475891, variance: 0.04596921429038048\n",
      "Train size: [400] hidden size: [25] trial: 43, train_loss: 1.860980, test loss: 1.002343, bias2: 0.9566507339477539, variance: 0.04569194093346596\n",
      "Train size: [400] hidden size: [25] trial: 44, train_loss: 1.861188, test loss: 1.002174, bias2: 0.9568639993667603, variance: 0.045310117304325104\n",
      "Train size: [400] hidden size: [25] trial: 45, train_loss: 1.858227, test loss: 1.002741, bias2: 0.9570167064666748, variance: 0.04572463408112526\n",
      "Train size: [400] hidden size: [25] trial: 46, train_loss: 1.854551, test loss: 1.002656, bias2: 0.9569249749183655, variance: 0.04573052003979683\n",
      "Train size: [400] hidden size: [25] trial: 47, train_loss: 1.857628, test loss: 1.002456, bias2: 0.9566107988357544, variance: 0.045844919979572296\n",
      "Train size: [400] hidden size: [25] trial: 48, train_loss: 1.860344, test loss: 1.002361, bias2: 0.9568272233009338, variance: 0.0455341674387455\n",
      "Train size: [400] hidden size: [25] trial: 49, train_loss: 1.861136, test loss: 1.002347, bias2: 0.9565892219543457, variance: 0.04575797915458679\n",
      "##################################################\n",
      "Train size: [400] hidden size: [29] trial: 0, train_loss: 1.859241, test loss: 1.022927, bias2: 1.0229274034500122, variance: -7.298527754384665e-11\n",
      "Train size: [400] hidden size: [29] trial: 1, train_loss: 1.815852, test loss: 1.005817, bias2: 0.9854196906089783, variance: 0.02039703167974949\n",
      "Train size: [400] hidden size: [29] trial: 2, train_loss: 1.814448, test loss: 1.001995, bias2: 0.974727988243103, variance: 0.027266517281532288\n",
      "Train size: [400] hidden size: [29] trial: 3, train_loss: 1.817894, test loss: 1.003083, bias2: 0.971446692943573, variance: 0.031636301428079605\n",
      "Train size: [400] hidden size: [29] trial: 4, train_loss: 1.865037, test loss: 1.005030, bias2: 0.9637258052825928, variance: 0.041304588317871094\n",
      "Train size: [400] hidden size: [29] trial: 5, train_loss: 1.867187, test loss: 1.003481, bias2: 0.9613305926322937, variance: 0.04215032607316971\n",
      "Train size: [400] hidden size: [29] trial: 6, train_loss: 1.868387, test loss: 1.000433, bias2: 0.9594857096672058, variance: 0.04094763472676277\n",
      "Train size: [400] hidden size: [29] trial: 7, train_loss: 1.855007, test loss: 0.998203, bias2: 0.9559948444366455, variance: 0.04220809042453766\n",
      "Train size: [400] hidden size: [29] trial: 8, train_loss: 1.872458, test loss: 1.001514, bias2: 0.9582607746124268, variance: 0.043253567069768906\n",
      "Train size: [400] hidden size: [29] trial: 9, train_loss: 1.868407, test loss: 1.002979, bias2: 0.9590007066726685, variance: 0.043978121131658554\n",
      "Train size: [400] hidden size: [29] trial: 10, train_loss: 1.867391, test loss: 1.005024, bias2: 0.9579976201057434, variance: 0.04702679067850113\n",
      "Train size: [400] hidden size: [29] trial: 11, train_loss: 1.880327, test loss: 1.003400, bias2: 0.9561629891395569, variance: 0.047236859798431396\n",
      "Train size: [400] hidden size: [29] trial: 12, train_loss: 1.881032, test loss: 1.000885, bias2: 0.9548358917236328, variance: 0.04604946821928024\n",
      "Train size: [400] hidden size: [29] trial: 13, train_loss: 1.870457, test loss: 0.999908, bias2: 0.9520693421363831, variance: 0.04783852770924568\n",
      "Train size: [400] hidden size: [29] trial: 14, train_loss: 1.854652, test loss: 1.001499, bias2: 0.9501581192016602, variance: 0.051341041922569275\n",
      "Train size: [400] hidden size: [29] trial: 15, train_loss: 1.852774, test loss: 1.002848, bias2: 0.9498220086097717, variance: 0.053025756031274796\n",
      "Train size: [400] hidden size: [29] trial: 16, train_loss: 1.874013, test loss: 1.003679, bias2: 0.9510462880134583, variance: 0.052633099257946014\n",
      "Train size: [400] hidden size: [29] trial: 17, train_loss: 1.874553, test loss: 1.003867, bias2: 0.9525288343429565, variance: 0.05133857950568199\n",
      "Train size: [400] hidden size: [29] trial: 18, train_loss: 1.872209, test loss: 1.005485, bias2: 0.9533774256706238, variance: 0.05210787430405617\n",
      "Train size: [400] hidden size: [29] trial: 19, train_loss: 1.873422, test loss: 1.005179, bias2: 0.9529203772544861, variance: 0.05225877836346626\n",
      "Train size: [400] hidden size: [29] trial: 20, train_loss: 1.889386, test loss: 1.005188, bias2: 0.9536358118057251, variance: 0.05155196040868759\n",
      "Train size: [400] hidden size: [29] trial: 21, train_loss: 1.885471, test loss: 1.005883, bias2: 0.9532706141471863, variance: 0.052612122148275375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [29] trial: 22, train_loss: 1.887983, test loss: 1.005964, bias2: 0.9527578353881836, variance: 0.053206220269203186\n",
      "Train size: [400] hidden size: [29] trial: 23, train_loss: 1.901045, test loss: 1.005163, bias2: 0.9516729116439819, variance: 0.05348970741033554\n",
      "Train size: [400] hidden size: [29] trial: 24, train_loss: 1.903851, test loss: 1.005578, bias2: 0.9519001841545105, variance: 0.05367739126086235\n",
      "Train size: [400] hidden size: [29] trial: 25, train_loss: 1.892046, test loss: 1.006675, bias2: 0.9537655711174011, variance: 0.05290932580828667\n",
      "Train size: [400] hidden size: [29] trial: 26, train_loss: 1.899113, test loss: 1.007010, bias2: 0.9536944627761841, variance: 0.05331538990139961\n",
      "Train size: [400] hidden size: [29] trial: 27, train_loss: 1.906269, test loss: 1.007057, bias2: 0.9531762003898621, variance: 0.053880419582128525\n",
      "Train size: [400] hidden size: [29] trial: 28, train_loss: 1.911009, test loss: 1.007480, bias2: 0.953787088394165, variance: 0.05369318649172783\n",
      "Train size: [400] hidden size: [29] trial: 29, train_loss: 1.912669, test loss: 1.006998, bias2: 0.9538214802742004, variance: 0.05317608267068863\n",
      "Train size: [400] hidden size: [29] trial: 30, train_loss: 1.911969, test loss: 1.006357, bias2: 0.9525898098945618, variance: 0.053767379373311996\n",
      "Train size: [400] hidden size: [29] trial: 31, train_loss: 1.911472, test loss: 1.008117, bias2: 0.9527729153633118, variance: 0.05534441024065018\n",
      "Train size: [400] hidden size: [29] trial: 32, train_loss: 1.908594, test loss: 1.007938, bias2: 0.9531010389328003, variance: 0.05483735352754593\n",
      "Train size: [400] hidden size: [29] trial: 33, train_loss: 1.902654, test loss: 1.008122, bias2: 0.9537213444709778, variance: 0.05440063402056694\n",
      "Train size: [400] hidden size: [29] trial: 34, train_loss: 1.899189, test loss: 1.007916, bias2: 0.9539747834205627, variance: 0.053941402584314346\n",
      "Train size: [400] hidden size: [29] trial: 35, train_loss: 1.904164, test loss: 1.008278, bias2: 0.9543666839599609, variance: 0.05391084775328636\n",
      "Train size: [400] hidden size: [29] trial: 36, train_loss: 1.903326, test loss: 1.007634, bias2: 0.9538550972938538, variance: 0.05377895012497902\n",
      "Train size: [400] hidden size: [29] trial: 37, train_loss: 1.897779, test loss: 1.006959, bias2: 0.9537122249603271, variance: 0.053246863186359406\n",
      "Train size: [400] hidden size: [29] trial: 38, train_loss: 1.892097, test loss: 1.007394, bias2: 0.9539484977722168, variance: 0.053445231169462204\n",
      "Train size: [400] hidden size: [29] trial: 39, train_loss: 1.895912, test loss: 1.007139, bias2: 0.9540032744407654, variance: 0.053135599941015244\n",
      "Train size: [400] hidden size: [29] trial: 40, train_loss: 1.897265, test loss: 1.007447, bias2: 0.954906702041626, variance: 0.05253984406590462\n",
      "Train size: [400] hidden size: [29] trial: 41, train_loss: 1.889046, test loss: 1.007498, bias2: 0.9550473690032959, variance: 0.0524505153298378\n",
      "Train size: [400] hidden size: [29] trial: 42, train_loss: 1.890726, test loss: 1.007152, bias2: 0.9548577070236206, variance: 0.052294258028268814\n",
      "Train size: [400] hidden size: [29] trial: 43, train_loss: 1.890084, test loss: 1.006698, bias2: 0.9543451070785522, variance: 0.052353017032146454\n",
      "Train size: [400] hidden size: [29] trial: 44, train_loss: 1.883977, test loss: 1.006193, bias2: 0.9543421864509583, variance: 0.05185134336352348\n",
      "Train size: [400] hidden size: [29] trial: 45, train_loss: 1.883281, test loss: 1.006513, bias2: 0.9544366002082825, variance: 0.05207637697458267\n",
      "Train size: [400] hidden size: [29] trial: 46, train_loss: 1.878023, test loss: 1.006420, bias2: 0.9544733762741089, variance: 0.051946185529232025\n",
      "Train size: [400] hidden size: [29] trial: 47, train_loss: 1.872145, test loss: 1.006618, bias2: 0.9540457129478455, variance: 0.0525718592107296\n",
      "Train size: [400] hidden size: [29] trial: 48, train_loss: 1.874097, test loss: 1.006879, bias2: 0.9543460607528687, variance: 0.05253242701292038\n",
      "Train size: [400] hidden size: [29] trial: 49, train_loss: 1.874810, test loss: 1.006614, bias2: 0.9540489315986633, variance: 0.05256470665335655\n",
      "##################################################\n",
      "Train size: [400] hidden size: [33] trial: 0, train_loss: 1.917335, test loss: 0.986369, bias2: 0.9863688349723816, variance: 5.352253640289462e-10\n",
      "Train size: [400] hidden size: [33] trial: 1, train_loss: 1.803411, test loss: 0.991348, bias2: 0.9639808535575867, variance: 0.027367185801267624\n",
      "Train size: [400] hidden size: [33] trial: 2, train_loss: 1.832731, test loss: 1.003988, bias2: 0.9627370238304138, variance: 0.041251134127378464\n",
      "Train size: [400] hidden size: [33] trial: 3, train_loss: 1.809755, test loss: 1.006349, bias2: 0.9627657532691956, variance: 0.04358285292983055\n",
      "Train size: [400] hidden size: [33] trial: 4, train_loss: 1.880730, test loss: 1.000629, bias2: 0.95458984375, variance: 0.04603935778141022\n",
      "Train size: [400] hidden size: [33] trial: 5, train_loss: 1.884196, test loss: 1.002628, bias2: 0.9559774398803711, variance: 0.04665031284093857\n",
      "Train size: [400] hidden size: [33] trial: 6, train_loss: 1.885715, test loss: 1.007358, bias2: 0.9587136507034302, variance: 0.04864475131034851\n",
      "Train size: [400] hidden size: [33] trial: 7, train_loss: 1.885387, test loss: 1.005280, bias2: 0.9571836590766907, variance: 0.04809637740254402\n",
      "Train size: [400] hidden size: [33] trial: 8, train_loss: 1.875134, test loss: 1.003703, bias2: 0.9549075961112976, variance: 0.04879515990614891\n",
      "Train size: [400] hidden size: [33] trial: 9, train_loss: 1.855272, test loss: 1.000753, bias2: 0.9515461921691895, variance: 0.04920640215277672\n",
      "Train size: [400] hidden size: [33] trial: 10, train_loss: 1.843020, test loss: 1.002544, bias2: 0.9505272507667542, variance: 0.052016790956258774\n",
      "Train size: [400] hidden size: [33] trial: 11, train_loss: 1.832218, test loss: 1.001623, bias2: 0.9496862292289734, variance: 0.051936712116003036\n",
      "Train size: [400] hidden size: [33] trial: 12, train_loss: 1.819151, test loss: 1.004400, bias2: 0.9506021738052368, variance: 0.053798168897628784\n",
      "Train size: [400] hidden size: [33] trial: 13, train_loss: 1.838910, test loss: 1.005056, bias2: 0.9507468342781067, variance: 0.0543087013065815\n",
      "Train size: [400] hidden size: [33] trial: 14, train_loss: 1.840716, test loss: 1.002775, bias2: 0.9482787251472473, variance: 0.05449577793478966\n",
      "Train size: [400] hidden size: [33] trial: 15, train_loss: 1.836470, test loss: 1.004417, bias2: 0.9506487250328064, variance: 0.05376807972788811\n",
      "Train size: [400] hidden size: [33] trial: 16, train_loss: 1.824124, test loss: 1.004378, bias2: 0.9510968327522278, variance: 0.05328157916665077\n",
      "Train size: [400] hidden size: [33] trial: 17, train_loss: 1.825663, test loss: 1.003125, bias2: 0.9502261877059937, variance: 0.052898745983839035\n",
      "Train size: [400] hidden size: [33] trial: 18, train_loss: 1.827248, test loss: 1.003530, bias2: 0.9500854015350342, variance: 0.05344412103295326\n",
      "Train size: [400] hidden size: [33] trial: 19, train_loss: 1.832636, test loss: 1.003622, bias2: 0.950103759765625, variance: 0.05351778864860535\n",
      "Train size: [400] hidden size: [33] trial: 20, train_loss: 1.838574, test loss: 1.003314, bias2: 0.9496909379959106, variance: 0.05362331494688988\n",
      "Train size: [400] hidden size: [33] trial: 21, train_loss: 1.846298, test loss: 1.004352, bias2: 0.9497345089912415, variance: 0.05461745709180832\n",
      "Train size: [400] hidden size: [33] trial: 22, train_loss: 1.850766, test loss: 1.003518, bias2: 0.9491443037986755, variance: 0.054374031722545624\n",
      "Train size: [400] hidden size: [33] trial: 23, train_loss: 1.843755, test loss: 1.004781, bias2: 0.9495497345924377, variance: 0.055230800062417984\n",
      "Train size: [400] hidden size: [33] trial: 24, train_loss: 1.850999, test loss: 1.006215, bias2: 0.9487934708595276, variance: 0.05742187798023224\n",
      "Train size: [400] hidden size: [33] trial: 25, train_loss: 1.854640, test loss: 1.006802, bias2: 0.9496280550956726, variance: 0.05717439576983452\n",
      "Train size: [400] hidden size: [33] trial: 26, train_loss: 1.856524, test loss: 1.006488, bias2: 0.9487535953521729, variance: 0.05773446336388588\n",
      "Train size: [400] hidden size: [33] trial: 27, train_loss: 1.858278, test loss: 1.006592, bias2: 0.9486148953437805, variance: 0.05797702819108963\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [33] trial: 28, train_loss: 1.855273, test loss: 1.006658, bias2: 0.9490256309509277, variance: 0.057632774114608765\n",
      "Train size: [400] hidden size: [33] trial: 29, train_loss: 1.860308, test loss: 1.005997, bias2: 0.9482861161231995, variance: 0.0577109195291996\n",
      "Train size: [400] hidden size: [33] trial: 30, train_loss: 1.867565, test loss: 1.006571, bias2: 0.948899507522583, variance: 0.05767204612493515\n",
      "Train size: [400] hidden size: [33] trial: 31, train_loss: 1.865506, test loss: 1.006279, bias2: 0.9487295150756836, variance: 0.057549700140953064\n",
      "Train size: [400] hidden size: [33] trial: 32, train_loss: 1.866404, test loss: 1.005913, bias2: 0.9485718607902527, variance: 0.05734141543507576\n",
      "Train size: [400] hidden size: [33] trial: 33, train_loss: 1.868833, test loss: 1.005997, bias2: 0.9481810927391052, variance: 0.057816196233034134\n",
      "Train size: [400] hidden size: [33] trial: 34, train_loss: 1.862618, test loss: 1.005130, bias2: 0.9469966292381287, variance: 0.05813368782401085\n",
      "Train size: [400] hidden size: [33] trial: 35, train_loss: 1.858505, test loss: 1.004757, bias2: 0.9466397762298584, variance: 0.05811738222837448\n",
      "Train size: [400] hidden size: [33] trial: 36, train_loss: 1.853722, test loss: 1.004684, bias2: 0.9473740458488464, variance: 0.05731029808521271\n",
      "Train size: [400] hidden size: [33] trial: 37, train_loss: 1.852461, test loss: 1.004585, bias2: 0.9474912881851196, variance: 0.05709328502416611\n",
      "Train size: [400] hidden size: [33] trial: 38, train_loss: 1.850362, test loss: 1.004529, bias2: 0.9470489025115967, variance: 0.05747976899147034\n",
      "Train size: [400] hidden size: [33] trial: 39, train_loss: 1.855963, test loss: 1.004565, bias2: 0.9471780061721802, variance: 0.05738673731684685\n",
      "Train size: [400] hidden size: [33] trial: 40, train_loss: 1.851517, test loss: 1.003910, bias2: 0.9466004967689514, variance: 0.057309333235025406\n",
      "Train size: [400] hidden size: [33] trial: 41, train_loss: 1.856394, test loss: 1.004581, bias2: 0.947211503982544, variance: 0.05736997723579407\n",
      "Train size: [400] hidden size: [33] trial: 42, train_loss: 1.855662, test loss: 1.004317, bias2: 0.9473004937171936, variance: 0.05701669305562973\n",
      "Train size: [400] hidden size: [33] trial: 43, train_loss: 1.858024, test loss: 1.004337, bias2: 0.9472343921661377, variance: 0.05710294097661972\n",
      "Train size: [400] hidden size: [33] trial: 44, train_loss: 1.855697, test loss: 1.003988, bias2: 0.9472306370735168, variance: 0.05675724893808365\n",
      "Train size: [400] hidden size: [33] trial: 45, train_loss: 1.855674, test loss: 1.004107, bias2: 0.9476634860038757, variance: 0.056443169713020325\n",
      "Train size: [400] hidden size: [33] trial: 46, train_loss: 1.858315, test loss: 1.003711, bias2: 0.9472730159759521, variance: 0.05643821135163307\n",
      "Train size: [400] hidden size: [33] trial: 47, train_loss: 1.857735, test loss: 1.003477, bias2: 0.9473049640655518, variance: 0.056171759963035583\n",
      "Train size: [400] hidden size: [33] trial: 48, train_loss: 1.860946, test loss: 1.003830, bias2: 0.9474843144416809, variance: 0.05634588375687599\n",
      "Train size: [400] hidden size: [33] trial: 49, train_loss: 1.855418, test loss: 1.004081, bias2: 0.9469754099845886, variance: 0.05710521712899208\n",
      "##################################################\n",
      "Train size: [400] hidden size: [38] trial: 0, train_loss: 1.977680, test loss: 1.030706, bias2: 1.0307059288024902, variance: -5.352253640289462e-10\n",
      "Train size: [400] hidden size: [38] trial: 1, train_loss: 1.892671, test loss: 1.025980, bias2: 0.9887450337409973, variance: 0.03723450377583504\n",
      "Train size: [400] hidden size: [38] trial: 2, train_loss: 1.831354, test loss: 1.009251, bias2: 0.965571939945221, variance: 0.04367867857217789\n",
      "Train size: [400] hidden size: [38] trial: 3, train_loss: 1.800942, test loss: 1.015662, bias2: 0.9641878008842468, variance: 0.05147414654493332\n",
      "Train size: [400] hidden size: [38] trial: 4, train_loss: 1.797725, test loss: 1.016431, bias2: 0.9626507759094238, variance: 0.05377984419465065\n",
      "Train size: [400] hidden size: [38] trial: 5, train_loss: 1.796904, test loss: 1.016787, bias2: 0.9617081880569458, variance: 0.055078838020563126\n",
      "Train size: [400] hidden size: [38] trial: 6, train_loss: 1.805714, test loss: 1.007397, bias2: 0.9475454688072205, variance: 0.05985146015882492\n",
      "Train size: [400] hidden size: [38] trial: 7, train_loss: 1.807992, test loss: 1.009909, bias2: 0.9479983448982239, variance: 0.06191046163439751\n",
      "Train size: [400] hidden size: [38] trial: 8, train_loss: 1.819944, test loss: 1.008535, bias2: 0.9458363652229309, variance: 0.06269856542348862\n",
      "Train size: [400] hidden size: [38] trial: 9, train_loss: 1.816089, test loss: 1.006876, bias2: 0.9451859593391418, variance: 0.06168956682085991\n",
      "Train size: [400] hidden size: [38] trial: 10, train_loss: 1.819371, test loss: 1.006865, bias2: 0.9447651505470276, variance: 0.06209985539317131\n",
      "Train size: [400] hidden size: [38] trial: 11, train_loss: 1.819291, test loss: 1.005726, bias2: 0.9401711821556091, variance: 0.06555517017841339\n",
      "Train size: [400] hidden size: [38] trial: 12, train_loss: 1.826530, test loss: 1.003943, bias2: 0.9396331310272217, variance: 0.06430986523628235\n",
      "Train size: [400] hidden size: [38] trial: 13, train_loss: 1.830164, test loss: 1.003283, bias2: 0.94071364402771, variance: 0.06256914138793945\n",
      "Train size: [400] hidden size: [38] trial: 14, train_loss: 1.823340, test loss: 1.002761, bias2: 0.9401687979698181, variance: 0.06259209662675858\n",
      "Train size: [400] hidden size: [38] trial: 15, train_loss: 1.813235, test loss: 1.002803, bias2: 0.9401437640190125, variance: 0.06265933066606522\n",
      "Train size: [400] hidden size: [38] trial: 16, train_loss: 1.824549, test loss: 1.001848, bias2: 0.9385548233985901, variance: 0.06329306215047836\n",
      "Train size: [400] hidden size: [38] trial: 17, train_loss: 1.818734, test loss: 1.002780, bias2: 0.9388458132743835, variance: 0.06393426656723022\n",
      "Train size: [400] hidden size: [38] trial: 18, train_loss: 1.822182, test loss: 1.004833, bias2: 0.941252589225769, variance: 0.06358013302087784\n",
      "Train size: [400] hidden size: [38] trial: 19, train_loss: 1.819013, test loss: 1.004605, bias2: 0.9404457807540894, variance: 0.06415942311286926\n",
      "Train size: [400] hidden size: [38] trial: 20, train_loss: 1.823129, test loss: 1.004827, bias2: 0.940923273563385, variance: 0.06390386819839478\n",
      "Train size: [400] hidden size: [38] trial: 21, train_loss: 1.814675, test loss: 1.003742, bias2: 0.9410594701766968, variance: 0.06268252432346344\n",
      "Train size: [400] hidden size: [38] trial: 22, train_loss: 1.827887, test loss: 1.004388, bias2: 0.9418250918388367, variance: 0.06256251037120819\n",
      "Train size: [400] hidden size: [38] trial: 23, train_loss: 1.819521, test loss: 1.003856, bias2: 0.9404631853103638, variance: 0.0633925125002861\n",
      "Train size: [400] hidden size: [38] trial: 24, train_loss: 1.817031, test loss: 1.002873, bias2: 0.9397310614585876, variance: 0.06314177811145782\n",
      "Train size: [400] hidden size: [38] trial: 25, train_loss: 1.815119, test loss: 1.003081, bias2: 0.9396538734436035, variance: 0.06342741847038269\n",
      "Train size: [400] hidden size: [38] trial: 26, train_loss: 1.810732, test loss: 1.004209, bias2: 0.9415091276168823, variance: 0.06270024925470352\n",
      "Train size: [400] hidden size: [38] trial: 27, train_loss: 1.809095, test loss: 1.004982, bias2: 0.9424248337745667, variance: 0.06255742162466049\n",
      "Train size: [400] hidden size: [38] trial: 28, train_loss: 1.810217, test loss: 1.003998, bias2: 0.9404578804969788, variance: 0.06354053318500519\n",
      "Train size: [400] hidden size: [38] trial: 29, train_loss: 1.805379, test loss: 1.003036, bias2: 0.9383711814880371, variance: 0.06466519087553024\n",
      "Train size: [400] hidden size: [38] trial: 30, train_loss: 1.801974, test loss: 1.004100, bias2: 0.9393997192382812, variance: 0.06470069289207458\n",
      "Train size: [400] hidden size: [38] trial: 31, train_loss: 1.799383, test loss: 1.004668, bias2: 0.9399058818817139, variance: 0.06476225703954697\n",
      "Train size: [400] hidden size: [38] trial: 32, train_loss: 1.798911, test loss: 1.003564, bias2: 0.9386103749275208, variance: 0.06495408713817596\n",
      "Train size: [400] hidden size: [38] trial: 33, train_loss: 1.799856, test loss: 1.003860, bias2: 0.9383682012557983, variance: 0.06549213826656342\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [38] trial: 34, train_loss: 1.794195, test loss: 1.003632, bias2: 0.9369714260101318, variance: 0.06666019558906555\n",
      "Train size: [400] hidden size: [38] trial: 35, train_loss: 1.799217, test loss: 1.003442, bias2: 0.936888575553894, variance: 0.06655324995517731\n",
      "Train size: [400] hidden size: [38] trial: 36, train_loss: 1.803942, test loss: 1.003406, bias2: 0.9365412592887878, variance: 0.06686440855264664\n",
      "Train size: [400] hidden size: [38] trial: 37, train_loss: 1.804220, test loss: 1.002502, bias2: 0.9348964095115662, variance: 0.0676058903336525\n",
      "Train size: [400] hidden size: [38] trial: 38, train_loss: 1.800108, test loss: 1.002126, bias2: 0.9341027736663818, variance: 0.068023182451725\n",
      "Train size: [400] hidden size: [38] trial: 39, train_loss: 1.802337, test loss: 1.001983, bias2: 0.9337629079818726, variance: 0.06821969151496887\n",
      "Train size: [400] hidden size: [38] trial: 40, train_loss: 1.808605, test loss: 1.002403, bias2: 0.933193564414978, variance: 0.06920931488275528\n",
      "Train size: [400] hidden size: [38] trial: 41, train_loss: 1.807190, test loss: 1.002414, bias2: 0.9331049919128418, variance: 0.06930937618017197\n",
      "Train size: [400] hidden size: [38] trial: 42, train_loss: 1.803685, test loss: 1.002505, bias2: 0.9323869347572327, variance: 0.0701182410120964\n",
      "Train size: [400] hidden size: [38] trial: 43, train_loss: 1.806538, test loss: 1.001779, bias2: 0.9314520359039307, variance: 0.07032737135887146\n",
      "Train size: [400] hidden size: [38] trial: 44, train_loss: 1.806322, test loss: 1.002848, bias2: 0.9328193068504333, variance: 0.07002872228622437\n",
      "Train size: [400] hidden size: [38] trial: 45, train_loss: 1.809161, test loss: 1.002589, bias2: 0.9322786331176758, variance: 0.07031060755252838\n",
      "Train size: [400] hidden size: [38] trial: 46, train_loss: 1.809948, test loss: 1.003106, bias2: 0.9325895309448242, variance: 0.07051633298397064\n",
      "Train size: [400] hidden size: [38] trial: 47, train_loss: 1.807201, test loss: 1.002336, bias2: 0.93180251121521, variance: 0.07053329795598984\n",
      "Train size: [400] hidden size: [38] trial: 48, train_loss: 1.808028, test loss: 1.002324, bias2: 0.9321247339248657, variance: 0.07019913196563721\n",
      "Train size: [400] hidden size: [38] trial: 49, train_loss: 1.809519, test loss: 1.002252, bias2: 0.9320416450500488, variance: 0.07021080702543259\n",
      "##################################################\n",
      "Train size: [400] hidden size: [44] trial: 0, train_loss: 1.968540, test loss: 0.974270, bias2: 0.9742703437805176, variance: -7.785095901269301e-10\n",
      "Train size: [400] hidden size: [44] trial: 1, train_loss: 1.848113, test loss: 0.973307, bias2: 0.9256857633590698, variance: 0.047621238976716995\n",
      "Train size: [400] hidden size: [44] trial: 2, train_loss: 1.793010, test loss: 0.991171, bias2: 0.9265791177749634, variance: 0.0645919144153595\n",
      "Train size: [400] hidden size: [44] trial: 3, train_loss: 1.785764, test loss: 0.990549, bias2: 0.9209375381469727, variance: 0.0696113333106041\n",
      "Train size: [400] hidden size: [44] trial: 4, train_loss: 1.777563, test loss: 0.993821, bias2: 0.9249222874641418, variance: 0.06889849156141281\n",
      "Train size: [400] hidden size: [44] trial: 5, train_loss: 1.813129, test loss: 0.999043, bias2: 0.9292078018188477, variance: 0.06983499228954315\n",
      "Train size: [400] hidden size: [44] trial: 6, train_loss: 1.797238, test loss: 1.003618, bias2: 0.9330954551696777, variance: 0.07052253931760788\n",
      "Train size: [400] hidden size: [44] trial: 7, train_loss: 1.812958, test loss: 1.003973, bias2: 0.9281893372535706, variance: 0.07578401267528534\n",
      "Train size: [400] hidden size: [44] trial: 8, train_loss: 1.799929, test loss: 1.005334, bias2: 0.9293417930603027, variance: 0.07599247246980667\n",
      "Train size: [400] hidden size: [44] trial: 9, train_loss: 1.786766, test loss: 1.006803, bias2: 0.9300291538238525, variance: 0.07677386701107025\n",
      "Train size: [400] hidden size: [44] trial: 10, train_loss: 1.790276, test loss: 1.007410, bias2: 0.9297782778739929, variance: 0.0776316449046135\n",
      "Train size: [400] hidden size: [44] trial: 11, train_loss: 1.785777, test loss: 1.006933, bias2: 0.9264950156211853, variance: 0.08043842017650604\n",
      "Train size: [400] hidden size: [44] trial: 12, train_loss: 1.795767, test loss: 1.007500, bias2: 0.9257696270942688, variance: 0.08173077553510666\n",
      "Train size: [400] hidden size: [44] trial: 13, train_loss: 1.793515, test loss: 1.008773, bias2: 0.9266201853752136, variance: 0.08215326070785522\n",
      "Train size: [400] hidden size: [44] trial: 14, train_loss: 1.809661, test loss: 1.009441, bias2: 0.9275749325752258, variance: 0.08186597377061844\n",
      "Train size: [400] hidden size: [44] trial: 15, train_loss: 1.800087, test loss: 1.008765, bias2: 0.9289954900741577, variance: 0.07976923137903214\n",
      "Train size: [400] hidden size: [44] trial: 16, train_loss: 1.801066, test loss: 1.010077, bias2: 0.9269548058509827, variance: 0.08312241733074188\n",
      "Train size: [400] hidden size: [44] trial: 17, train_loss: 1.793218, test loss: 1.011483, bias2: 0.9285978078842163, variance: 0.08288514614105225\n",
      "Train size: [400] hidden size: [44] trial: 18, train_loss: 1.801015, test loss: 1.010017, bias2: 0.9259235262870789, variance: 0.08409341424703598\n",
      "Train size: [400] hidden size: [44] trial: 19, train_loss: 1.799355, test loss: 1.009532, bias2: 0.9263216257095337, variance: 0.08321056514978409\n",
      "Train size: [400] hidden size: [44] trial: 20, train_loss: 1.806438, test loss: 1.009695, bias2: 0.9265381097793579, variance: 0.08315692096948624\n",
      "Train size: [400] hidden size: [44] trial: 21, train_loss: 1.808582, test loss: 1.009096, bias2: 0.9262133836746216, variance: 0.08288264274597168\n",
      "Train size: [400] hidden size: [44] trial: 22, train_loss: 1.800239, test loss: 1.010194, bias2: 0.9272515773773193, variance: 0.08294223248958588\n",
      "Train size: [400] hidden size: [44] trial: 23, train_loss: 1.796440, test loss: 1.010176, bias2: 0.9278251528739929, variance: 0.08235125243663788\n",
      "Train size: [400] hidden size: [44] trial: 24, train_loss: 1.800302, test loss: 1.009526, bias2: 0.9274262189865112, variance: 0.0821000263094902\n",
      "Train size: [400] hidden size: [44] trial: 25, train_loss: 1.808504, test loss: 1.009787, bias2: 0.9266844987869263, variance: 0.08310267329216003\n",
      "Train size: [400] hidden size: [44] trial: 26, train_loss: 1.816100, test loss: 1.008943, bias2: 0.9249747395515442, variance: 0.08396860212087631\n",
      "Train size: [400] hidden size: [44] trial: 27, train_loss: 1.826304, test loss: 1.008411, bias2: 0.9241586923599243, variance: 0.08425262570381165\n",
      "Train size: [400] hidden size: [44] trial: 28, train_loss: 1.829663, test loss: 1.007829, bias2: 0.9233266711235046, variance: 0.08450265973806381\n",
      "Train size: [400] hidden size: [44] trial: 29, train_loss: 1.818979, test loss: 1.007632, bias2: 0.9237041473388672, variance: 0.08392799645662308\n",
      "Train size: [400] hidden size: [44] trial: 30, train_loss: 1.815831, test loss: 1.007993, bias2: 0.9252497553825378, variance: 0.08274348080158234\n",
      "Train size: [400] hidden size: [44] trial: 31, train_loss: 1.814125, test loss: 1.007935, bias2: 0.9253594875335693, variance: 0.08257588744163513\n",
      "Train size: [400] hidden size: [44] trial: 32, train_loss: 1.811684, test loss: 1.007708, bias2: 0.9251528978347778, variance: 0.08255539834499359\n",
      "Train size: [400] hidden size: [44] trial: 33, train_loss: 1.814566, test loss: 1.007771, bias2: 0.9250741004943848, variance: 0.08269669860601425\n",
      "Train size: [400] hidden size: [44] trial: 34, train_loss: 1.811735, test loss: 1.007624, bias2: 0.9250409007072449, variance: 0.08258301764726639\n",
      "Train size: [400] hidden size: [44] trial: 35, train_loss: 1.812313, test loss: 1.007705, bias2: 0.9250106811523438, variance: 0.08269454538822174\n",
      "Train size: [400] hidden size: [44] trial: 36, train_loss: 1.815778, test loss: 1.007379, bias2: 0.9248647689819336, variance: 0.08251452445983887\n",
      "Train size: [400] hidden size: [44] trial: 37, train_loss: 1.816034, test loss: 1.007770, bias2: 0.9261703491210938, variance: 0.08159910887479782\n",
      "Train size: [400] hidden size: [44] trial: 38, train_loss: 1.811372, test loss: 1.006657, bias2: 0.926166832447052, variance: 0.08048991113901138\n",
      "Train size: [400] hidden size: [44] trial: 39, train_loss: 1.809621, test loss: 1.006628, bias2: 0.9258965253829956, variance: 0.08073105663061142\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [44] trial: 40, train_loss: 1.804540, test loss: 1.006130, bias2: 0.9253275394439697, variance: 0.0808028057217598\n",
      "Train size: [400] hidden size: [44] trial: 41, train_loss: 1.804232, test loss: 1.005829, bias2: 0.9256734251976013, variance: 0.08015590906143188\n",
      "Train size: [400] hidden size: [44] trial: 42, train_loss: 1.799283, test loss: 1.005985, bias2: 0.9256265163421631, variance: 0.08035837858915329\n",
      "Train size: [400] hidden size: [44] trial: 43, train_loss: 1.805481, test loss: 1.007185, bias2: 0.9266301989555359, variance: 0.0805547833442688\n",
      "Train size: [400] hidden size: [44] trial: 44, train_loss: 1.805561, test loss: 1.007298, bias2: 0.9269667863845825, variance: 0.08033143728971481\n",
      "Train size: [400] hidden size: [44] trial: 45, train_loss: 1.808607, test loss: 1.007353, bias2: 0.9273619651794434, variance: 0.07999051362276077\n",
      "Train size: [400] hidden size: [44] trial: 46, train_loss: 1.807260, test loss: 1.006771, bias2: 0.9265809059143066, variance: 0.08019004762172699\n",
      "Train size: [400] hidden size: [44] trial: 47, train_loss: 1.809693, test loss: 1.006404, bias2: 0.9260838627815247, variance: 0.08031995594501495\n",
      "Train size: [400] hidden size: [44] trial: 48, train_loss: 1.809877, test loss: 1.006653, bias2: 0.9267951250076294, variance: 0.0798574909567833\n",
      "Train size: [400] hidden size: [44] trial: 49, train_loss: 1.804413, test loss: 1.006142, bias2: 0.9261237382888794, variance: 0.08001794666051865\n",
      "##################################################\n",
      "Train size: [400] hidden size: [51] trial: 0, train_loss: 1.808226, test loss: 1.027384, bias2: 1.0273841619491577, variance: 4.865684938293313e-11\n",
      "Train size: [400] hidden size: [51] trial: 1, train_loss: 1.822236, test loss: 1.013481, bias2: 0.9701704978942871, variance: 0.04331042245030403\n",
      "Train size: [400] hidden size: [51] trial: 2, train_loss: 1.824792, test loss: 1.004538, bias2: 0.9550950527191162, variance: 0.04944334551692009\n",
      "Train size: [400] hidden size: [51] trial: 3, train_loss: 1.840304, test loss: 0.999866, bias2: 0.9430647492408752, variance: 0.056801002472639084\n",
      "Train size: [400] hidden size: [51] trial: 4, train_loss: 1.813616, test loss: 0.997340, bias2: 0.9335044622421265, variance: 0.0638354942202568\n",
      "Train size: [400] hidden size: [51] trial: 5, train_loss: 1.807760, test loss: 0.994027, bias2: 0.9303133487701416, variance: 0.0637131854891777\n",
      "Train size: [400] hidden size: [51] trial: 6, train_loss: 1.808295, test loss: 0.997570, bias2: 0.9264782667160034, variance: 0.07109197974205017\n",
      "Train size: [400] hidden size: [51] trial: 7, train_loss: 1.811830, test loss: 1.000776, bias2: 0.9260033965110779, variance: 0.07477252930402756\n",
      "Train size: [400] hidden size: [51] trial: 8, train_loss: 1.795389, test loss: 0.998387, bias2: 0.9229321479797363, variance: 0.07545477151870728\n",
      "Train size: [400] hidden size: [51] trial: 9, train_loss: 1.807285, test loss: 0.998066, bias2: 0.9198418259620667, variance: 0.07822395861148834\n",
      "Train size: [400] hidden size: [51] trial: 10, train_loss: 1.804225, test loss: 0.997262, bias2: 0.9189283847808838, variance: 0.07833395153284073\n",
      "Train size: [400] hidden size: [51] trial: 11, train_loss: 1.815944, test loss: 0.993652, bias2: 0.9127620458602905, variance: 0.0808897316455841\n",
      "Train size: [400] hidden size: [51] trial: 12, train_loss: 1.797653, test loss: 0.994475, bias2: 0.9127694368362427, variance: 0.08170551806688309\n",
      "Train size: [400] hidden size: [51] trial: 13, train_loss: 1.797941, test loss: 0.995880, bias2: 0.9149711728096008, variance: 0.08090905845165253\n",
      "Train size: [400] hidden size: [51] trial: 14, train_loss: 1.797468, test loss: 0.996171, bias2: 0.909893274307251, variance: 0.08627733588218689\n",
      "Train size: [400] hidden size: [51] trial: 15, train_loss: 1.779245, test loss: 0.995809, bias2: 0.9084147810935974, variance: 0.0873943343758583\n",
      "Train size: [400] hidden size: [51] trial: 16, train_loss: 1.784759, test loss: 0.996485, bias2: 0.9107397198677063, variance: 0.08574515581130981\n",
      "Train size: [400] hidden size: [51] trial: 17, train_loss: 1.772206, test loss: 0.996623, bias2: 0.9113446474075317, variance: 0.0852784514427185\n",
      "Train size: [400] hidden size: [51] trial: 18, train_loss: 1.756553, test loss: 0.996431, bias2: 0.9106053709983826, variance: 0.08582528680562973\n",
      "Train size: [400] hidden size: [51] trial: 19, train_loss: 1.747945, test loss: 0.996893, bias2: 0.9104453921318054, variance: 0.08644763380289078\n",
      "Train size: [400] hidden size: [51] trial: 20, train_loss: 1.754815, test loss: 0.998675, bias2: 0.9115043878555298, variance: 0.08717091381549835\n",
      "Train size: [400] hidden size: [51] trial: 21, train_loss: 1.755254, test loss: 1.000012, bias2: 0.9120194315910339, variance: 0.0879926010966301\n",
      "Train size: [400] hidden size: [51] trial: 22, train_loss: 1.744630, test loss: 1.001924, bias2: 0.9136570692062378, variance: 0.08826663345098495\n",
      "Train size: [400] hidden size: [51] trial: 23, train_loss: 1.741843, test loss: 1.002996, bias2: 0.9140718579292297, variance: 0.08892413228750229\n",
      "Train size: [400] hidden size: [51] trial: 24, train_loss: 1.740724, test loss: 1.003828, bias2: 0.916051983833313, variance: 0.08777569234371185\n",
      "Train size: [400] hidden size: [51] trial: 25, train_loss: 1.737080, test loss: 1.005236, bias2: 0.9167525768280029, variance: 0.08848369866609573\n",
      "Train size: [400] hidden size: [51] trial: 26, train_loss: 1.736068, test loss: 1.006789, bias2: 0.9192124605178833, variance: 0.0875767171382904\n",
      "Train size: [400] hidden size: [51] trial: 27, train_loss: 1.733315, test loss: 1.006979, bias2: 0.9201021194458008, variance: 0.08687710016965866\n",
      "Train size: [400] hidden size: [51] trial: 28, train_loss: 1.735950, test loss: 1.007078, bias2: 0.9194631576538086, variance: 0.0876147449016571\n",
      "Train size: [400] hidden size: [51] trial: 29, train_loss: 1.732482, test loss: 1.007698, bias2: 0.9196339845657349, variance: 0.08806394785642624\n",
      "Train size: [400] hidden size: [51] trial: 30, train_loss: 1.740623, test loss: 1.008527, bias2: 0.9201415777206421, variance: 0.08838571608066559\n",
      "Train size: [400] hidden size: [51] trial: 31, train_loss: 1.745727, test loss: 1.008833, bias2: 0.9204429388046265, variance: 0.08839011192321777\n",
      "Train size: [400] hidden size: [51] trial: 32, train_loss: 1.755357, test loss: 1.008485, bias2: 0.9195567965507507, variance: 0.08892837911844254\n",
      "Train size: [400] hidden size: [51] trial: 33, train_loss: 1.748842, test loss: 1.007323, bias2: 0.9186686873435974, variance: 0.08865436166524887\n",
      "Train size: [400] hidden size: [51] trial: 34, train_loss: 1.753348, test loss: 1.007596, bias2: 0.9192790985107422, variance: 0.08831656724214554\n",
      "Train size: [400] hidden size: [51] trial: 35, train_loss: 1.749739, test loss: 1.007113, bias2: 0.9197674989700317, variance: 0.08734525740146637\n",
      "Train size: [400] hidden size: [51] trial: 36, train_loss: 1.751394, test loss: 1.006746, bias2: 0.9198174476623535, variance: 0.08692847192287445\n",
      "Train size: [400] hidden size: [51] trial: 37, train_loss: 1.750538, test loss: 1.006297, bias2: 0.9191792607307434, variance: 0.08711785823106766\n",
      "Train size: [400] hidden size: [51] trial: 38, train_loss: 1.748478, test loss: 1.006875, bias2: 0.9200496077537537, variance: 0.0868256613612175\n",
      "Train size: [400] hidden size: [51] trial: 39, train_loss: 1.751468, test loss: 1.006747, bias2: 0.9201908111572266, variance: 0.08655597269535065\n",
      "Train size: [400] hidden size: [51] trial: 40, train_loss: 1.747225, test loss: 1.006442, bias2: 0.9198473691940308, variance: 0.08659449219703674\n",
      "Train size: [400] hidden size: [51] trial: 41, train_loss: 1.748316, test loss: 1.006027, bias2: 0.9193851351737976, variance: 0.0866415947675705\n",
      "Train size: [400] hidden size: [51] trial: 42, train_loss: 1.751868, test loss: 1.006325, bias2: 0.919982373714447, variance: 0.08634249120950699\n",
      "Train size: [400] hidden size: [51] trial: 43, train_loss: 1.755089, test loss: 1.006163, bias2: 0.9190981388092041, variance: 0.08706460148096085\n",
      "Train size: [400] hidden size: [51] trial: 44, train_loss: 1.749225, test loss: 1.006124, bias2: 0.9191413521766663, variance: 0.08698264509439468\n",
      "Train size: [400] hidden size: [51] trial: 45, train_loss: 1.747657, test loss: 1.006205, bias2: 0.9194219708442688, variance: 0.08678286522626877\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [51] trial: 46, train_loss: 1.748973, test loss: 1.005922, bias2: 0.919258177280426, variance: 0.08666341751813889\n",
      "Train size: [400] hidden size: [51] trial: 47, train_loss: 1.747578, test loss: 1.005672, bias2: 0.9185672998428345, variance: 0.08710493892431259\n",
      "Train size: [400] hidden size: [51] trial: 48, train_loss: 1.753495, test loss: 1.005902, bias2: 0.9191025495529175, variance: 0.08679937571287155\n",
      "Train size: [400] hidden size: [51] trial: 49, train_loss: 1.755193, test loss: 1.005064, bias2: 0.9176762700080872, variance: 0.08738724142313004\n",
      "##################################################\n",
      "Train size: [400] hidden size: [58] trial: 0, train_loss: 1.573905, test loss: 0.991380, bias2: 0.9913794994354248, variance: 1.0217938717360653e-09\n",
      "Train size: [400] hidden size: [58] trial: 1, train_loss: 1.608403, test loss: 0.995485, bias2: 0.9277633428573608, variance: 0.06772121787071228\n",
      "Train size: [400] hidden size: [58] trial: 2, train_loss: 1.639577, test loss: 0.996201, bias2: 0.9132356643676758, variance: 0.08296506106853485\n",
      "Train size: [400] hidden size: [58] trial: 3, train_loss: 1.634542, test loss: 1.010645, bias2: 0.9048525094985962, variance: 0.10579300671815872\n",
      "Train size: [400] hidden size: [58] trial: 4, train_loss: 1.633458, test loss: 1.013902, bias2: 0.9057232737541199, variance: 0.1081792563199997\n",
      "Train size: [400] hidden size: [58] trial: 5, train_loss: 1.636039, test loss: 1.019990, bias2: 0.9127388596534729, variance: 0.10725087672472\n",
      "Train size: [400] hidden size: [58] trial: 6, train_loss: 1.636170, test loss: 1.016184, bias2: 0.9046173691749573, variance: 0.11156638711690903\n",
      "Train size: [400] hidden size: [58] trial: 7, train_loss: 1.662704, test loss: 1.014197, bias2: 0.904034435749054, variance: 0.11016254872083664\n",
      "Train size: [400] hidden size: [58] trial: 8, train_loss: 1.700434, test loss: 1.010295, bias2: 0.898510754108429, variance: 0.11178427189588547\n",
      "Train size: [400] hidden size: [58] trial: 9, train_loss: 1.721505, test loss: 1.012369, bias2: 0.9004040360450745, variance: 0.11196534335613251\n",
      "Train size: [400] hidden size: [58] trial: 10, train_loss: 1.711486, test loss: 1.013938, bias2: 0.9033303260803223, variance: 0.11060737073421478\n",
      "Train size: [400] hidden size: [58] trial: 11, train_loss: 1.723298, test loss: 1.011211, bias2: 0.901747465133667, variance: 0.10946321487426758\n",
      "Train size: [400] hidden size: [58] trial: 12, train_loss: 1.739278, test loss: 1.009630, bias2: 0.9002416729927063, variance: 0.10938794165849686\n",
      "Train size: [400] hidden size: [58] trial: 13, train_loss: 1.737816, test loss: 1.010289, bias2: 0.9025691747665405, variance: 0.1077202782034874\n",
      "Train size: [400] hidden size: [58] trial: 14, train_loss: 1.741341, test loss: 1.012048, bias2: 0.9038468599319458, variance: 0.1082010418176651\n",
      "Train size: [400] hidden size: [58] trial: 15, train_loss: 1.756281, test loss: 1.009700, bias2: 0.9003934860229492, variance: 0.1093069463968277\n",
      "Train size: [400] hidden size: [58] trial: 16, train_loss: 1.769562, test loss: 1.008641, bias2: 0.9004909992218018, variance: 0.10815035551786423\n",
      "Train size: [400] hidden size: [58] trial: 17, train_loss: 1.761840, test loss: 1.007877, bias2: 0.9000025391578674, variance: 0.10787399113178253\n",
      "Train size: [400] hidden size: [58] trial: 18, train_loss: 1.755256, test loss: 1.007379, bias2: 0.8989508152008057, variance: 0.10842811316251755\n",
      "Train size: [400] hidden size: [58] trial: 19, train_loss: 1.749988, test loss: 1.006293, bias2: 0.8984400033950806, variance: 0.10785332322120667\n",
      "Train size: [400] hidden size: [58] trial: 20, train_loss: 1.752802, test loss: 1.006844, bias2: 0.9004217386245728, variance: 0.1064218282699585\n",
      "Train size: [400] hidden size: [58] trial: 21, train_loss: 1.745946, test loss: 1.005708, bias2: 0.8997637033462524, variance: 0.10594439506530762\n",
      "Train size: [400] hidden size: [58] trial: 22, train_loss: 1.749047, test loss: 1.006494, bias2: 0.8985342383384705, variance: 0.1079593300819397\n",
      "Train size: [400] hidden size: [58] trial: 23, train_loss: 1.738980, test loss: 1.006069, bias2: 0.897968590259552, variance: 0.10810035467147827\n",
      "Train size: [400] hidden size: [58] trial: 24, train_loss: 1.743665, test loss: 1.005568, bias2: 0.8972824215888977, variance: 0.10828562825918198\n",
      "Train size: [400] hidden size: [58] trial: 25, train_loss: 1.747603, test loss: 1.006185, bias2: 0.8967512249946594, variance: 0.10943383723497391\n",
      "Train size: [400] hidden size: [58] trial: 26, train_loss: 1.755014, test loss: 1.006289, bias2: 0.8974450826644897, variance: 0.10884394496679306\n",
      "Train size: [400] hidden size: [58] trial: 27, train_loss: 1.762810, test loss: 1.005407, bias2: 0.8956553936004639, variance: 0.10975206643342972\n",
      "Train size: [400] hidden size: [58] trial: 28, train_loss: 1.759911, test loss: 1.005179, bias2: 0.8958675265312195, variance: 0.10931175202131271\n",
      "Train size: [400] hidden size: [58] trial: 29, train_loss: 1.755443, test loss: 1.004869, bias2: 0.8956304788589478, variance: 0.10923872143030167\n",
      "Train size: [400] hidden size: [58] trial: 30, train_loss: 1.750173, test loss: 1.005474, bias2: 0.8967647552490234, variance: 0.10870956629514694\n",
      "Train size: [400] hidden size: [58] trial: 31, train_loss: 1.751438, test loss: 1.006000, bias2: 0.8979395627975464, variance: 0.10806073993444443\n",
      "Train size: [400] hidden size: [58] trial: 32, train_loss: 1.756058, test loss: 1.007622, bias2: 0.8987067937850952, variance: 0.10891510546207428\n",
      "Train size: [400] hidden size: [58] trial: 33, train_loss: 1.748899, test loss: 1.007066, bias2: 0.8986887335777283, variance: 0.10837765783071518\n",
      "Train size: [400] hidden size: [58] trial: 34, train_loss: 1.753418, test loss: 1.008291, bias2: 0.8999060392379761, variance: 0.108384869992733\n",
      "Train size: [400] hidden size: [58] trial: 35, train_loss: 1.752297, test loss: 1.008698, bias2: 0.8999858498573303, variance: 0.10871180146932602\n",
      "Train size: [400] hidden size: [58] trial: 36, train_loss: 1.761607, test loss: 1.008551, bias2: 0.899280309677124, variance: 0.10927044600248337\n",
      "Train size: [400] hidden size: [58] trial: 37, train_loss: 1.764424, test loss: 1.009603, bias2: 0.9002816677093506, variance: 0.10932180285453796\n",
      "Train size: [400] hidden size: [58] trial: 38, train_loss: 1.768624, test loss: 1.009782, bias2: 0.9003929495811462, variance: 0.10938887298107147\n",
      "Train size: [400] hidden size: [58] trial: 39, train_loss: 1.767169, test loss: 1.010381, bias2: 0.9014954566955566, variance: 0.1088857501745224\n",
      "Train size: [400] hidden size: [58] trial: 40, train_loss: 1.764559, test loss: 1.010236, bias2: 0.9017630815505981, variance: 0.1084727942943573\n",
      "Train size: [400] hidden size: [58] trial: 41, train_loss: 1.764823, test loss: 1.010500, bias2: 0.9024178981781006, variance: 0.10808172821998596\n",
      "Train size: [400] hidden size: [58] trial: 42, train_loss: 1.762810, test loss: 1.010582, bias2: 0.9030151963233948, variance: 0.10756703466176987\n",
      "Train size: [400] hidden size: [58] trial: 43, train_loss: 1.761803, test loss: 1.009962, bias2: 0.902324378490448, variance: 0.10763782262802124\n",
      "Train size: [400] hidden size: [58] trial: 44, train_loss: 1.760934, test loss: 1.009799, bias2: 0.9018121957778931, variance: 0.10798703134059906\n",
      "Train size: [400] hidden size: [58] trial: 45, train_loss: 1.758047, test loss: 1.009723, bias2: 0.9015832543373108, variance: 0.10813983529806137\n",
      "Train size: [400] hidden size: [58] trial: 46, train_loss: 1.759016, test loss: 1.009065, bias2: 0.9002371430397034, variance: 0.10882779210805893\n",
      "Train size: [400] hidden size: [58] trial: 47, train_loss: 1.761113, test loss: 1.008684, bias2: 0.8998990654945374, variance: 0.10878486186265945\n",
      "Train size: [400] hidden size: [58] trial: 48, train_loss: 1.761181, test loss: 1.008809, bias2: 0.9001474976539612, variance: 0.10866134613752365\n",
      "Train size: [400] hidden size: [58] trial: 49, train_loss: 1.757051, test loss: 1.008674, bias2: 0.8996974229812622, variance: 0.1089768186211586\n",
      "##################################################\n",
      "Train size: [400] hidden size: [67] trial: 0, train_loss: 1.661388, test loss: 0.997824, bias2: 0.9978243708610535, variance: -1.1677644407015464e-09\n",
      "Train size: [400] hidden size: [67] trial: 1, train_loss: 1.584051, test loss: 0.986626, bias2: 0.9099817872047424, variance: 0.0766439214348793\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [67] trial: 2, train_loss: 1.658724, test loss: 0.977480, bias2: 0.885469913482666, variance: 0.09201047569513321\n",
      "Train size: [400] hidden size: [67] trial: 3, train_loss: 1.740979, test loss: 0.993005, bias2: 0.8870108723640442, variance: 0.10599441081285477\n",
      "Train size: [400] hidden size: [67] trial: 4, train_loss: 1.760123, test loss: 0.989784, bias2: 0.8837658166885376, variance: 0.10601793974637985\n",
      "Train size: [400] hidden size: [67] trial: 5, train_loss: 1.733319, test loss: 0.995757, bias2: 0.8862202763557434, variance: 0.10953699797391891\n",
      "Train size: [400] hidden size: [67] trial: 6, train_loss: 1.724755, test loss: 1.001550, bias2: 0.8947732448577881, variance: 0.10677634179592133\n",
      "Train size: [400] hidden size: [67] trial: 7, train_loss: 1.714960, test loss: 1.000459, bias2: 0.894261360168457, variance: 0.10619726032018661\n",
      "Train size: [400] hidden size: [67] trial: 8, train_loss: 1.710581, test loss: 1.004118, bias2: 0.8970381617546082, variance: 0.10708005726337433\n",
      "Train size: [400] hidden size: [67] trial: 9, train_loss: 1.721895, test loss: 1.008270, bias2: 0.9000242352485657, variance: 0.10824605077505112\n",
      "Train size: [400] hidden size: [67] trial: 10, train_loss: 1.731872, test loss: 1.014194, bias2: 0.9041213393211365, variance: 0.11007219552993774\n",
      "Train size: [400] hidden size: [67] trial: 11, train_loss: 1.754551, test loss: 1.014418, bias2: 0.9016776084899902, variance: 0.11274084448814392\n",
      "Train size: [400] hidden size: [67] trial: 12, train_loss: 1.751691, test loss: 1.015136, bias2: 0.9004089832305908, variance: 0.11472687870264053\n",
      "Train size: [400] hidden size: [67] trial: 13, train_loss: 1.735356, test loss: 1.016838, bias2: 0.9026931524276733, variance: 0.11414456367492676\n",
      "Train size: [400] hidden size: [67] trial: 14, train_loss: 1.743652, test loss: 1.014182, bias2: 0.8994112014770508, variance: 0.11477085947990417\n",
      "Train size: [400] hidden size: [67] trial: 15, train_loss: 1.761871, test loss: 1.014371, bias2: 0.898080587387085, variance: 0.11629022657871246\n",
      "Train size: [400] hidden size: [67] trial: 16, train_loss: 1.754597, test loss: 1.010897, bias2: 0.894245982170105, variance: 0.11665139347314835\n",
      "Train size: [400] hidden size: [67] trial: 17, train_loss: 1.754106, test loss: 1.009343, bias2: 0.8904822468757629, variance: 0.11886115372180939\n",
      "Train size: [400] hidden size: [67] trial: 18, train_loss: 1.751252, test loss: 1.010585, bias2: 0.8917624354362488, variance: 0.11882277578115463\n",
      "Train size: [400] hidden size: [67] trial: 19, train_loss: 1.745326, test loss: 1.011070, bias2: 0.8933173418045044, variance: 0.11775252223014832\n",
      "Train size: [400] hidden size: [67] trial: 20, train_loss: 1.743015, test loss: 1.008483, bias2: 0.8900349736213684, variance: 0.11844833195209503\n",
      "Train size: [400] hidden size: [67] trial: 21, train_loss: 1.738720, test loss: 1.007960, bias2: 0.8886263370513916, variance: 0.11933315545320511\n",
      "Train size: [400] hidden size: [67] trial: 22, train_loss: 1.734335, test loss: 1.007010, bias2: 0.8869613409042358, variance: 0.12004831433296204\n",
      "Train size: [400] hidden size: [67] trial: 23, train_loss: 1.733675, test loss: 1.005086, bias2: 0.8861270546913147, variance: 0.11895899474620819\n",
      "Train size: [400] hidden size: [67] trial: 24, train_loss: 1.737907, test loss: 1.005068, bias2: 0.8857808113098145, variance: 0.11928687244653702\n",
      "Train size: [400] hidden size: [67] trial: 25, train_loss: 1.733162, test loss: 1.003926, bias2: 0.8834630250930786, variance: 0.12046337872743607\n",
      "Train size: [400] hidden size: [67] trial: 26, train_loss: 1.732281, test loss: 1.002786, bias2: 0.8813927173614502, variance: 0.12139285355806351\n",
      "Train size: [400] hidden size: [67] trial: 27, train_loss: 1.740648, test loss: 1.002479, bias2: 0.881650447845459, variance: 0.12082912027835846\n",
      "Train size: [400] hidden size: [67] trial: 28, train_loss: 1.742928, test loss: 1.003482, bias2: 0.8824227452278137, variance: 0.12105971574783325\n",
      "Train size: [400] hidden size: [67] trial: 29, train_loss: 1.744746, test loss: 1.001169, bias2: 0.8806955814361572, variance: 0.12047387659549713\n",
      "Train size: [400] hidden size: [67] trial: 30, train_loss: 1.746060, test loss: 1.001029, bias2: 0.8786937594413757, variance: 0.1223350241780281\n",
      "Train size: [400] hidden size: [67] trial: 31, train_loss: 1.739364, test loss: 1.001589, bias2: 0.8790854811668396, variance: 0.12250382453203201\n",
      "Train size: [400] hidden size: [67] trial: 32, train_loss: 1.746933, test loss: 1.002670, bias2: 0.8787215352058411, variance: 0.12394826859235764\n",
      "Train size: [400] hidden size: [67] trial: 33, train_loss: 1.741084, test loss: 1.003972, bias2: 0.8792849779129028, variance: 0.1246868222951889\n",
      "Train size: [400] hidden size: [67] trial: 34, train_loss: 1.739039, test loss: 1.004725, bias2: 0.8802981972694397, variance: 0.12442654371261597\n",
      "Train size: [400] hidden size: [67] trial: 35, train_loss: 1.732882, test loss: 1.003573, bias2: 0.8794763684272766, variance: 0.1240963339805603\n",
      "Train size: [400] hidden size: [67] trial: 36, train_loss: 1.728385, test loss: 1.004057, bias2: 0.8807590007781982, variance: 0.12329819798469543\n",
      "Train size: [400] hidden size: [67] trial: 37, train_loss: 1.731165, test loss: 1.004957, bias2: 0.8823318481445312, variance: 0.12262512743473053\n",
      "Train size: [400] hidden size: [67] trial: 38, train_loss: 1.730755, test loss: 1.005989, bias2: 0.8840207457542419, variance: 0.12196830660104752\n",
      "Train size: [400] hidden size: [67] trial: 39, train_loss: 1.727408, test loss: 1.005630, bias2: 0.8836244940757751, variance: 0.12200561910867691\n",
      "Train size: [400] hidden size: [67] trial: 40, train_loss: 1.725709, test loss: 1.005598, bias2: 0.8839208483695984, variance: 0.12167685478925705\n",
      "Train size: [400] hidden size: [67] trial: 41, train_loss: 1.725787, test loss: 1.006320, bias2: 0.8846945762634277, variance: 0.12162505090236664\n",
      "Train size: [400] hidden size: [67] trial: 42, train_loss: 1.721639, test loss: 1.006601, bias2: 0.8852508664131165, variance: 0.1213502362370491\n",
      "Train size: [400] hidden size: [67] trial: 43, train_loss: 1.723342, test loss: 1.006623, bias2: 0.8845006227493286, variance: 0.12212229520082474\n",
      "Train size: [400] hidden size: [67] trial: 44, train_loss: 1.723987, test loss: 1.006829, bias2: 0.884823203086853, variance: 0.12200606614351273\n",
      "Train size: [400] hidden size: [67] trial: 45, train_loss: 1.719634, test loss: 1.007097, bias2: 0.8855069279670715, variance: 0.12158998101949692\n",
      "Train size: [400] hidden size: [67] trial: 46, train_loss: 1.718773, test loss: 1.006758, bias2: 0.885674238204956, variance: 0.12108387798070908\n",
      "Train size: [400] hidden size: [67] trial: 47, train_loss: 1.720065, test loss: 1.006621, bias2: 0.8858714699745178, variance: 0.12074953317642212\n",
      "Train size: [400] hidden size: [67] trial: 48, train_loss: 1.718360, test loss: 1.006677, bias2: 0.8863365650177002, variance: 0.12034022808074951\n",
      "Train size: [400] hidden size: [67] trial: 49, train_loss: 1.719051, test loss: 1.006235, bias2: 0.886006772518158, variance: 0.1202285885810852\n",
      "##################################################\n",
      "Train size: [400] hidden size: [77] trial: 0, train_loss: 1.574040, test loss: 0.995303, bias2: 0.9953025579452515, variance: 7.785095901269301e-10\n",
      "Train size: [400] hidden size: [77] trial: 1, train_loss: 1.661863, test loss: 1.019003, bias2: 0.9694130420684814, variance: 0.04958975315093994\n",
      "Train size: [400] hidden size: [77] trial: 2, train_loss: 1.704892, test loss: 1.016747, bias2: 0.9278299808502197, variance: 0.08891728520393372\n",
      "Train size: [400] hidden size: [77] trial: 3, train_loss: 1.664678, test loss: 1.012184, bias2: 0.9040250778198242, variance: 0.10815892368555069\n",
      "Train size: [400] hidden size: [77] trial: 4, train_loss: 1.651540, test loss: 1.005229, bias2: 0.8936372995376587, variance: 0.11159159243106842\n",
      "Train size: [400] hidden size: [77] trial: 5, train_loss: 1.647573, test loss: 1.005450, bias2: 0.8872990012168884, variance: 0.11815138906240463\n",
      "Train size: [400] hidden size: [77] trial: 6, train_loss: 1.701717, test loss: 1.009038, bias2: 0.8891425728797913, variance: 0.11989574134349823\n",
      "Train size: [400] hidden size: [77] trial: 7, train_loss: 1.693274, test loss: 1.006272, bias2: 0.8871066570281982, variance: 0.11916553229093552\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [77] trial: 8, train_loss: 1.677728, test loss: 1.007257, bias2: 0.8836112022399902, variance: 0.12364541739225388\n",
      "Train size: [400] hidden size: [77] trial: 9, train_loss: 1.688703, test loss: 1.003132, bias2: 0.8782709836959839, variance: 0.12486086040735245\n",
      "Train size: [400] hidden size: [77] trial: 10, train_loss: 1.694873, test loss: 1.003453, bias2: 0.8767141699790955, variance: 0.12673895061016083\n",
      "Train size: [400] hidden size: [77] trial: 11, train_loss: 1.690215, test loss: 1.004727, bias2: 0.8766267895698547, variance: 0.12810008227825165\n",
      "Train size: [400] hidden size: [77] trial: 12, train_loss: 1.691071, test loss: 1.005803, bias2: 0.8796331882476807, variance: 0.12617026269435883\n",
      "Train size: [400] hidden size: [77] trial: 13, train_loss: 1.691655, test loss: 1.006325, bias2: 0.879768967628479, variance: 0.1265563815832138\n",
      "Train size: [400] hidden size: [77] trial: 14, train_loss: 1.687926, test loss: 1.004692, bias2: 0.877994179725647, variance: 0.12669776380062103\n",
      "Train size: [400] hidden size: [77] trial: 15, train_loss: 1.686777, test loss: 1.005147, bias2: 0.8784953355789185, variance: 0.12665210664272308\n",
      "Train size: [400] hidden size: [77] trial: 16, train_loss: 1.674696, test loss: 1.004230, bias2: 0.8793928027153015, variance: 0.12483768910169601\n",
      "Train size: [400] hidden size: [77] trial: 17, train_loss: 1.678558, test loss: 1.003114, bias2: 0.8794481754302979, variance: 0.1236661896109581\n",
      "Train size: [400] hidden size: [77] trial: 18, train_loss: 1.683371, test loss: 1.003612, bias2: 0.8806749582290649, variance: 0.12293693423271179\n",
      "Train size: [400] hidden size: [77] trial: 19, train_loss: 1.673039, test loss: 0.999222, bias2: 0.8769748210906982, variance: 0.1222475990653038\n",
      "Train size: [400] hidden size: [77] trial: 20, train_loss: 1.668772, test loss: 1.000509, bias2: 0.8782458901405334, variance: 0.12226276099681854\n",
      "Train size: [400] hidden size: [77] trial: 21, train_loss: 1.656671, test loss: 1.001419, bias2: 0.8783414363861084, variance: 0.12307798117399216\n",
      "Train size: [400] hidden size: [77] trial: 22, train_loss: 1.648063, test loss: 1.001868, bias2: 0.8791555166244507, variance: 0.12271223962306976\n",
      "Train size: [400] hidden size: [77] trial: 23, train_loss: 1.647299, test loss: 1.002314, bias2: 0.8810798525810242, variance: 0.1212337464094162\n",
      "Train size: [400] hidden size: [77] trial: 24, train_loss: 1.649549, test loss: 1.002192, bias2: 0.8799012899398804, variance: 0.12229087203741074\n",
      "Train size: [400] hidden size: [77] trial: 25, train_loss: 1.646207, test loss: 1.000936, bias2: 0.87831711769104, variance: 0.1226189136505127\n",
      "Train size: [400] hidden size: [77] trial: 26, train_loss: 1.647757, test loss: 1.000061, bias2: 0.8759803175926208, variance: 0.1240806132555008\n",
      "Train size: [400] hidden size: [77] trial: 27, train_loss: 1.644206, test loss: 1.001626, bias2: 0.8768748044967651, variance: 0.12475145608186722\n",
      "Train size: [400] hidden size: [77] trial: 28, train_loss: 1.647748, test loss: 1.000717, bias2: 0.8760039806365967, variance: 0.12471281737089157\n",
      "Train size: [400] hidden size: [77] trial: 29, train_loss: 1.650058, test loss: 1.001931, bias2: 0.8759837746620178, variance: 0.12594681978225708\n",
      "Train size: [400] hidden size: [77] trial: 30, train_loss: 1.649839, test loss: 1.003256, bias2: 0.8778367638587952, variance: 0.12541931867599487\n",
      "Train size: [400] hidden size: [77] trial: 31, train_loss: 1.652413, test loss: 1.002819, bias2: 0.8775432109832764, variance: 0.12527570128440857\n",
      "Train size: [400] hidden size: [77] trial: 32, train_loss: 1.647910, test loss: 1.003285, bias2: 0.8771251440048218, variance: 0.1261599361896515\n",
      "Train size: [400] hidden size: [77] trial: 33, train_loss: 1.650118, test loss: 1.003629, bias2: 0.8766571879386902, variance: 0.1269715577363968\n",
      "Train size: [400] hidden size: [77] trial: 34, train_loss: 1.645557, test loss: 1.004985, bias2: 0.8772612810134888, variance: 0.12772391736507416\n",
      "Train size: [400] hidden size: [77] trial: 35, train_loss: 1.644970, test loss: 1.006581, bias2: 0.8790183067321777, variance: 0.12756289541721344\n",
      "Train size: [400] hidden size: [77] trial: 36, train_loss: 1.654863, test loss: 1.006352, bias2: 0.8774628043174744, variance: 0.12888924777507782\n",
      "Train size: [400] hidden size: [77] trial: 37, train_loss: 1.657709, test loss: 1.007278, bias2: 0.8774071931838989, variance: 0.12987056374549866\n",
      "Train size: [400] hidden size: [77] trial: 38, train_loss: 1.663657, test loss: 1.006950, bias2: 0.8776199817657471, variance: 0.12933006882667542\n",
      "Train size: [400] hidden size: [77] trial: 39, train_loss: 1.662635, test loss: 1.006021, bias2: 0.8761407136917114, variance: 0.12987981736660004\n",
      "Train size: [400] hidden size: [77] trial: 40, train_loss: 1.664827, test loss: 1.005745, bias2: 0.8750807642936707, variance: 0.13066430389881134\n",
      "Train size: [400] hidden size: [77] trial: 41, train_loss: 1.666123, test loss: 1.006091, bias2: 0.875586986541748, variance: 0.13050447404384613\n",
      "Train size: [400] hidden size: [77] trial: 42, train_loss: 1.668634, test loss: 1.005684, bias2: 0.8747987151145935, variance: 0.13088518381118774\n",
      "Train size: [400] hidden size: [77] trial: 43, train_loss: 1.662858, test loss: 1.003816, bias2: 0.8726629018783569, variance: 0.13115260004997253\n",
      "Train size: [400] hidden size: [77] trial: 44, train_loss: 1.663475, test loss: 1.004162, bias2: 0.8716896176338196, variance: 0.13247211277484894\n",
      "Train size: [400] hidden size: [77] trial: 45, train_loss: 1.660879, test loss: 1.005374, bias2: 0.8719173669815063, variance: 0.13345696032047272\n",
      "Train size: [400] hidden size: [77] trial: 46, train_loss: 1.660297, test loss: 1.005148, bias2: 0.8720463514328003, variance: 0.133102148771286\n",
      "Train size: [400] hidden size: [77] trial: 47, train_loss: 1.662524, test loss: 1.004954, bias2: 0.8717561960220337, variance: 0.13319790363311768\n",
      "Train size: [400] hidden size: [77] trial: 48, train_loss: 1.658421, test loss: 1.005775, bias2: 0.8718830347061157, variance: 0.1338914930820465\n",
      "Train size: [400] hidden size: [77] trial: 49, train_loss: 1.658970, test loss: 1.004948, bias2: 0.871503472328186, variance: 0.13344453275203705\n",
      "##################################################\n",
      "Train size: [400] hidden size: [89] trial: 0, train_loss: 1.578405, test loss: 1.027667, bias2: 1.027666687965393, variance: -1.3623918659888545e-09\n",
      "Train size: [400] hidden size: [89] trial: 1, train_loss: 1.572692, test loss: 1.013250, bias2: 0.9340748190879822, variance: 0.07917565852403641\n",
      "Train size: [400] hidden size: [89] trial: 2, train_loss: 1.592893, test loss: 1.014466, bias2: 0.9044490456581116, variance: 0.11001698672771454\n",
      "Train size: [400] hidden size: [89] trial: 3, train_loss: 1.661004, test loss: 1.018560, bias2: 0.8976979851722717, variance: 0.1208619624376297\n",
      "Train size: [400] hidden size: [89] trial: 4, train_loss: 1.642780, test loss: 1.006141, bias2: 0.8790086507797241, variance: 0.12713278830051422\n",
      "Train size: [400] hidden size: [89] trial: 5, train_loss: 1.611426, test loss: 0.996827, bias2: 0.8647539615631104, variance: 0.13207277655601501\n",
      "Train size: [400] hidden size: [89] trial: 6, train_loss: 1.632156, test loss: 0.998370, bias2: 0.8599433898925781, variance: 0.13842633366584778\n",
      "Train size: [400] hidden size: [89] trial: 7, train_loss: 1.636361, test loss: 0.997296, bias2: 0.857224702835083, variance: 0.14007148146629333\n",
      "Train size: [400] hidden size: [89] trial: 8, train_loss: 1.629828, test loss: 0.999590, bias2: 0.8567839860916138, variance: 0.14280609786510468\n",
      "Train size: [400] hidden size: [89] trial: 9, train_loss: 1.620940, test loss: 0.998354, bias2: 0.8510838150978088, variance: 0.1472705751657486\n",
      "Train size: [400] hidden size: [89] trial: 10, train_loss: 1.647286, test loss: 1.002314, bias2: 0.8560119271278381, variance: 0.14630194008350372\n",
      "Train size: [400] hidden size: [89] trial: 11, train_loss: 1.639281, test loss: 1.002495, bias2: 0.8533973097801208, variance: 0.1490979790687561\n",
      "Train size: [400] hidden size: [89] trial: 12, train_loss: 1.632897, test loss: 1.007661, bias2: 0.8575290441513062, variance: 0.15013214945793152\n",
      "Train size: [400] hidden size: [89] trial: 13, train_loss: 1.615926, test loss: 1.011683, bias2: 0.8604706525802612, variance: 0.1512119621038437\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [89] trial: 14, train_loss: 1.614162, test loss: 1.010757, bias2: 0.8600704669952393, variance: 0.15068671107292175\n",
      "Train size: [400] hidden size: [89] trial: 15, train_loss: 1.612253, test loss: 1.009840, bias2: 0.861451268196106, variance: 0.14838896691799164\n",
      "Train size: [400] hidden size: [89] trial: 16, train_loss: 1.601999, test loss: 1.010318, bias2: 0.8618403673171997, variance: 0.14847803115844727\n",
      "Train size: [400] hidden size: [89] trial: 17, train_loss: 1.602103, test loss: 1.011607, bias2: 0.8603823184967041, variance: 0.15122458338737488\n",
      "Train size: [400] hidden size: [89] trial: 18, train_loss: 1.612802, test loss: 1.013832, bias2: 0.8619749546051025, variance: 0.15185652673244476\n",
      "Train size: [400] hidden size: [89] trial: 19, train_loss: 1.610209, test loss: 1.013765, bias2: 0.862402081489563, variance: 0.151363343000412\n",
      "Train size: [400] hidden size: [89] trial: 20, train_loss: 1.612912, test loss: 1.012890, bias2: 0.8610765337944031, variance: 0.1518133133649826\n",
      "Train size: [400] hidden size: [89] trial: 21, train_loss: 1.610337, test loss: 1.012551, bias2: 0.8611007332801819, variance: 0.15145045518875122\n",
      "Train size: [400] hidden size: [89] trial: 22, train_loss: 1.615107, test loss: 1.013722, bias2: 0.8610129356384277, variance: 0.1527092605829239\n",
      "Train size: [400] hidden size: [89] trial: 23, train_loss: 1.616506, test loss: 1.013905, bias2: 0.8616947531700134, variance: 0.15221016108989716\n",
      "Train size: [400] hidden size: [89] trial: 24, train_loss: 1.612568, test loss: 1.014129, bias2: 0.8623379468917847, variance: 0.15179148316383362\n",
      "Train size: [400] hidden size: [89] trial: 25, train_loss: 1.610379, test loss: 1.014942, bias2: 0.8620458841323853, variance: 0.1528964340686798\n",
      "Train size: [400] hidden size: [89] trial: 26, train_loss: 1.607256, test loss: 1.014173, bias2: 0.8611658215522766, variance: 0.15300732851028442\n",
      "Train size: [400] hidden size: [89] trial: 27, train_loss: 1.610193, test loss: 1.015218, bias2: 0.8629699945449829, variance: 0.15224841237068176\n",
      "Train size: [400] hidden size: [89] trial: 28, train_loss: 1.605195, test loss: 1.015373, bias2: 0.8623812794685364, variance: 0.15299217402935028\n",
      "Train size: [400] hidden size: [89] trial: 29, train_loss: 1.606606, test loss: 1.016539, bias2: 0.8632485866546631, variance: 0.15329036116600037\n",
      "Train size: [400] hidden size: [89] trial: 30, train_loss: 1.608266, test loss: 1.016059, bias2: 0.8617486953735352, variance: 0.15431059896945953\n",
      "Train size: [400] hidden size: [89] trial: 31, train_loss: 1.605624, test loss: 1.017137, bias2: 0.8614649772644043, variance: 0.1556723266839981\n",
      "Train size: [400] hidden size: [89] trial: 32, train_loss: 1.606480, test loss: 1.017116, bias2: 0.8612600564956665, variance: 0.15585578978061676\n",
      "Train size: [400] hidden size: [89] trial: 33, train_loss: 1.602782, test loss: 1.017184, bias2: 0.8609510064125061, variance: 0.15623290836811066\n",
      "Train size: [400] hidden size: [89] trial: 34, train_loss: 1.598474, test loss: 1.015728, bias2: 0.8593401312828064, variance: 0.15638811886310577\n",
      "Train size: [400] hidden size: [89] trial: 35, train_loss: 1.595849, test loss: 1.016415, bias2: 0.8604416847229004, variance: 0.1559734046459198\n",
      "Train size: [400] hidden size: [89] trial: 36, train_loss: 1.593137, test loss: 1.016183, bias2: 0.858722984790802, variance: 0.1574597954750061\n",
      "Train size: [400] hidden size: [89] trial: 37, train_loss: 1.590122, test loss: 1.015105, bias2: 0.858891487121582, variance: 0.15621314942836761\n",
      "Train size: [400] hidden size: [89] trial: 38, train_loss: 1.587622, test loss: 1.016219, bias2: 0.8591917753219604, variance: 0.1570274531841278\n",
      "Train size: [400] hidden size: [89] trial: 39, train_loss: 1.582737, test loss: 1.015995, bias2: 0.8583991527557373, variance: 0.15759584307670593\n",
      "Train size: [400] hidden size: [89] trial: 40, train_loss: 1.579740, test loss: 1.016188, bias2: 0.8583906292915344, variance: 0.15779787302017212\n",
      "Train size: [400] hidden size: [89] trial: 41, train_loss: 1.578623, test loss: 1.016784, bias2: 0.8594210147857666, variance: 0.15736326575279236\n",
      "Train size: [400] hidden size: [89] trial: 42, train_loss: 1.576635, test loss: 1.016873, bias2: 0.8590390682220459, variance: 0.15783439576625824\n",
      "Train size: [400] hidden size: [89] trial: 43, train_loss: 1.577097, test loss: 1.016257, bias2: 0.8592555522918701, variance: 0.15700146555900574\n",
      "Train size: [400] hidden size: [89] trial: 44, train_loss: 1.571026, test loss: 1.016710, bias2: 0.8598726391792297, variance: 0.15683752298355103\n",
      "Train size: [400] hidden size: [89] trial: 45, train_loss: 1.574850, test loss: 1.017553, bias2: 0.8594237565994263, variance: 0.15812955796718597\n",
      "Train size: [400] hidden size: [89] trial: 46, train_loss: 1.578158, test loss: 1.017564, bias2: 0.8583739399909973, variance: 0.15918999910354614\n",
      "Train size: [400] hidden size: [89] trial: 47, train_loss: 1.580263, test loss: 1.019209, bias2: 0.8588309288024902, variance: 0.16037771105766296\n",
      "Train size: [400] hidden size: [89] trial: 48, train_loss: 1.583188, test loss: 1.018763, bias2: 0.8588682413101196, variance: 0.15989483892917633\n",
      "Train size: [400] hidden size: [89] trial: 49, train_loss: 1.585122, test loss: 1.017472, bias2: 0.8571903109550476, variance: 0.1602817177772522\n",
      "##################################################\n",
      "Train size: [400] hidden size: [102] trial: 0, train_loss: 1.577583, test loss: 0.955689, bias2: 0.9556894302368164, variance: -2.530156306690401e-09\n",
      "Train size: [400] hidden size: [102] trial: 1, train_loss: 1.458280, test loss: 0.979198, bias2: 0.8896807432174683, variance: 0.08951752632856369\n",
      "Train size: [400] hidden size: [102] trial: 2, train_loss: 1.468074, test loss: 1.001623, bias2: 0.8782511353492737, variance: 0.12337154150009155\n",
      "Train size: [400] hidden size: [102] trial: 3, train_loss: 1.516004, test loss: 1.016980, bias2: 0.8733686804771423, variance: 0.14361147582530975\n",
      "Train size: [400] hidden size: [102] trial: 4, train_loss: 1.519375, test loss: 1.023874, bias2: 0.868510901927948, variance: 0.15536290407180786\n",
      "Train size: [400] hidden size: [102] trial: 5, train_loss: 1.520433, test loss: 1.018216, bias2: 0.858701229095459, variance: 0.15951427817344666\n",
      "Train size: [400] hidden size: [102] trial: 6, train_loss: 1.516990, test loss: 1.021468, bias2: 0.8616052269935608, variance: 0.1598626971244812\n",
      "Train size: [400] hidden size: [102] trial: 7, train_loss: 1.526913, test loss: 1.022108, bias2: 0.8572415709495544, variance: 0.16486616432666779\n",
      "Train size: [400] hidden size: [102] trial: 8, train_loss: 1.532527, test loss: 1.023512, bias2: 0.8498435020446777, variance: 0.17366835474967957\n",
      "Train size: [400] hidden size: [102] trial: 9, train_loss: 1.565069, test loss: 1.020238, bias2: 0.8465578556060791, variance: 0.17368006706237793\n",
      "Train size: [400] hidden size: [102] trial: 10, train_loss: 1.544174, test loss: 1.018499, bias2: 0.840228796005249, variance: 0.17826998233795166\n",
      "Train size: [400] hidden size: [102] trial: 11, train_loss: 1.536674, test loss: 1.023335, bias2: 0.8432133793830872, variance: 0.18012209236621857\n",
      "Train size: [400] hidden size: [102] trial: 12, train_loss: 1.553938, test loss: 1.021779, bias2: 0.8414275050163269, variance: 0.18035131692886353\n",
      "Train size: [400] hidden size: [102] trial: 13, train_loss: 1.560913, test loss: 1.023489, bias2: 0.8413740396499634, variance: 0.1821153163909912\n",
      "Train size: [400] hidden size: [102] trial: 14, train_loss: 1.563965, test loss: 1.024451, bias2: 0.8403238654136658, variance: 0.1841270476579666\n",
      "Train size: [400] hidden size: [102] trial: 15, train_loss: 1.549894, test loss: 1.027004, bias2: 0.8435673713684082, variance: 0.18343666195869446\n",
      "Train size: [400] hidden size: [102] trial: 16, train_loss: 1.552138, test loss: 1.027856, bias2: 0.8444494605064392, variance: 0.1834070086479187\n",
      "Train size: [400] hidden size: [102] trial: 17, train_loss: 1.556330, test loss: 1.026782, bias2: 0.8435596227645874, variance: 0.18322207033634186\n",
      "Train size: [400] hidden size: [102] trial: 18, train_loss: 1.553537, test loss: 1.026629, bias2: 0.8431805372238159, variance: 0.1834482103586197\n",
      "Train size: [400] hidden size: [102] trial: 19, train_loss: 1.554971, test loss: 1.025752, bias2: 0.842998743057251, variance: 0.18275365233421326\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [102] trial: 20, train_loss: 1.559325, test loss: 1.029220, bias2: 0.8466965556144714, variance: 0.18252317607402802\n",
      "Train size: [400] hidden size: [102] trial: 21, train_loss: 1.556778, test loss: 1.029514, bias2: 0.8469147086143494, variance: 0.1825989931821823\n",
      "Train size: [400] hidden size: [102] trial: 22, train_loss: 1.561760, test loss: 1.031634, bias2: 0.8479726314544678, variance: 0.18366095423698425\n",
      "Train size: [400] hidden size: [102] trial: 23, train_loss: 1.562361, test loss: 1.029838, bias2: 0.8483895063400269, variance: 0.18144860863685608\n",
      "Train size: [400] hidden size: [102] trial: 24, train_loss: 1.557882, test loss: 1.030322, bias2: 0.8479422330856323, variance: 0.18237972259521484\n",
      "Train size: [400] hidden size: [102] trial: 25, train_loss: 1.557011, test loss: 1.031988, bias2: 0.8469865918159485, variance: 0.1850016564130783\n",
      "Train size: [400] hidden size: [102] trial: 26, train_loss: 1.550834, test loss: 1.031379, bias2: 0.8452867269515991, variance: 0.186091810464859\n",
      "Train size: [400] hidden size: [102] trial: 27, train_loss: 1.554301, test loss: 1.031159, bias2: 0.8448473811149597, variance: 0.1863117814064026\n",
      "Train size: [400] hidden size: [102] trial: 28, train_loss: 1.551064, test loss: 1.031253, bias2: 0.8453903198242188, variance: 0.18586257100105286\n",
      "Train size: [400] hidden size: [102] trial: 29, train_loss: 1.559328, test loss: 1.032021, bias2: 0.8460017442703247, variance: 0.186019167304039\n",
      "Train size: [400] hidden size: [102] trial: 30, train_loss: 1.559259, test loss: 1.029212, bias2: 0.8444744944572449, variance: 0.18473726511001587\n",
      "Train size: [400] hidden size: [102] trial: 31, train_loss: 1.557227, test loss: 1.028217, bias2: 0.8434743881225586, variance: 0.18474255502223969\n",
      "Train size: [400] hidden size: [102] trial: 32, train_loss: 1.553565, test loss: 1.028166, bias2: 0.8435336351394653, variance: 0.18463218212127686\n",
      "Train size: [400] hidden size: [102] trial: 33, train_loss: 1.550144, test loss: 1.029287, bias2: 0.8451967239379883, variance: 0.1840900033712387\n",
      "Train size: [400] hidden size: [102] trial: 34, train_loss: 1.550088, test loss: 1.029113, bias2: 0.8446735739707947, variance: 0.18443961441516876\n",
      "Train size: [400] hidden size: [102] trial: 35, train_loss: 1.548785, test loss: 1.029301, bias2: 0.843052089214325, variance: 0.18624846637248993\n",
      "Train size: [400] hidden size: [102] trial: 36, train_loss: 1.550759, test loss: 1.030186, bias2: 0.8441497087478638, variance: 0.18603631854057312\n",
      "Train size: [400] hidden size: [102] trial: 37, train_loss: 1.551159, test loss: 1.030035, bias2: 0.8441601991653442, variance: 0.1858748346567154\n",
      "Train size: [400] hidden size: [102] trial: 38, train_loss: 1.551434, test loss: 1.029577, bias2: 0.8420809507369995, variance: 0.1874963343143463\n",
      "Train size: [400] hidden size: [102] trial: 39, train_loss: 1.549945, test loss: 1.029443, bias2: 0.8414368629455566, variance: 0.18800565600395203\n",
      "Train size: [400] hidden size: [102] trial: 40, train_loss: 1.549860, test loss: 1.029894, bias2: 0.841886043548584, variance: 0.18800793588161469\n",
      "Train size: [400] hidden size: [102] trial: 41, train_loss: 1.550987, test loss: 1.029589, bias2: 0.8413804173469543, variance: 0.18820863962173462\n",
      "Train size: [400] hidden size: [102] trial: 42, train_loss: 1.556848, test loss: 1.029192, bias2: 0.8389785289764404, variance: 0.19021354615688324\n",
      "Train size: [400] hidden size: [102] trial: 43, train_loss: 1.557188, test loss: 1.029747, bias2: 0.8391132950782776, variance: 0.1906335949897766\n",
      "Train size: [400] hidden size: [102] trial: 44, train_loss: 1.553538, test loss: 1.029904, bias2: 0.8379548788070679, variance: 0.19194892048835754\n",
      "Train size: [400] hidden size: [102] trial: 45, train_loss: 1.550276, test loss: 1.028280, bias2: 0.8359726667404175, variance: 0.1923069953918457\n",
      "Train size: [400] hidden size: [102] trial: 46, train_loss: 1.546884, test loss: 1.027508, bias2: 0.8350910544395447, variance: 0.19241659343242645\n",
      "Train size: [400] hidden size: [102] trial: 47, train_loss: 1.549534, test loss: 1.028564, bias2: 0.8364434242248535, variance: 0.19212031364440918\n",
      "Train size: [400] hidden size: [102] trial: 48, train_loss: 1.546582, test loss: 1.027604, bias2: 0.8358567953109741, variance: 0.1917472928762436\n",
      "Train size: [400] hidden size: [102] trial: 49, train_loss: 1.548417, test loss: 1.026806, bias2: 0.8350874185562134, variance: 0.1917189359664917\n",
      "##################################################\n",
      "Train size: [400] hidden size: [118] trial: 0, train_loss: 1.461344, test loss: 0.995614, bias2: 0.9956138134002686, variance: -1.5570191802538602e-09\n",
      "Train size: [400] hidden size: [118] trial: 1, train_loss: 1.409040, test loss: 0.983766, bias2: 0.8816319704055786, variance: 0.1021336019039154\n",
      "Train size: [400] hidden size: [118] trial: 2, train_loss: 1.458060, test loss: 0.990922, bias2: 0.856201171875, variance: 0.1347208321094513\n",
      "Train size: [400] hidden size: [118] trial: 3, train_loss: 1.463249, test loss: 1.003112, bias2: 0.8533041477203369, variance: 0.14980755746364594\n",
      "Train size: [400] hidden size: [118] trial: 4, train_loss: 1.485738, test loss: 1.004885, bias2: 0.8421230316162109, variance: 0.1627618968486786\n",
      "Train size: [400] hidden size: [118] trial: 5, train_loss: 1.484207, test loss: 1.018810, bias2: 0.8406310081481934, variance: 0.1781785637140274\n",
      "Train size: [400] hidden size: [118] trial: 6, train_loss: 1.503891, test loss: 1.022293, bias2: 0.8371985554695129, variance: 0.18509453535079956\n",
      "Train size: [400] hidden size: [118] trial: 7, train_loss: 1.540934, test loss: 1.029442, bias2: 0.8345195651054382, variance: 0.19492202997207642\n",
      "Train size: [400] hidden size: [118] trial: 8, train_loss: 1.541711, test loss: 1.026660, bias2: 0.8199813365936279, variance: 0.20667830109596252\n",
      "Train size: [400] hidden size: [118] trial: 9, train_loss: 1.511371, test loss: 1.024936, bias2: 0.818314254283905, variance: 0.2066216915845871\n",
      "Train size: [400] hidden size: [118] trial: 10, train_loss: 1.515712, test loss: 1.020220, bias2: 0.8120356202125549, variance: 0.20818394422531128\n",
      "Train size: [400] hidden size: [118] trial: 11, train_loss: 1.501828, test loss: 1.019427, bias2: 0.8074888586997986, variance: 0.21193857491016388\n",
      "Train size: [400] hidden size: [118] trial: 12, train_loss: 1.496767, test loss: 1.020216, bias2: 0.8055400252342224, variance: 0.21467570960521698\n",
      "Train size: [400] hidden size: [118] trial: 13, train_loss: 1.494967, test loss: 1.018612, bias2: 0.8038411140441895, variance: 0.21477103233337402\n",
      "Train size: [400] hidden size: [118] trial: 14, train_loss: 1.496417, test loss: 1.021818, bias2: 0.8057172298431396, variance: 0.2161010205745697\n",
      "Train size: [400] hidden size: [118] trial: 15, train_loss: 1.487710, test loss: 1.023255, bias2: 0.805536687374115, variance: 0.21771854162216187\n",
      "Train size: [400] hidden size: [118] trial: 16, train_loss: 1.471914, test loss: 1.023823, bias2: 0.8077791333198547, variance: 0.21604354679584503\n",
      "Train size: [400] hidden size: [118] trial: 17, train_loss: 1.469784, test loss: 1.023764, bias2: 0.8057948350906372, variance: 0.21796903014183044\n",
      "Train size: [400] hidden size: [118] trial: 18, train_loss: 1.464865, test loss: 1.024358, bias2: 0.8037074208259583, variance: 0.22065086662769318\n",
      "Train size: [400] hidden size: [118] trial: 19, train_loss: 1.461782, test loss: 1.021162, bias2: 0.8026759624481201, variance: 0.21848571300506592\n",
      "Train size: [400] hidden size: [118] trial: 20, train_loss: 1.471417, test loss: 1.017880, bias2: 0.798377275466919, variance: 0.2195030152797699\n",
      "Train size: [400] hidden size: [118] trial: 21, train_loss: 1.479518, test loss: 1.017524, bias2: 0.7964668869972229, variance: 0.2210572212934494\n",
      "Train size: [400] hidden size: [118] trial: 22, train_loss: 1.479563, test loss: 1.018354, bias2: 0.795657753944397, variance: 0.22269652783870697\n",
      "Train size: [400] hidden size: [118] trial: 23, train_loss: 1.480440, test loss: 1.021206, bias2: 0.7961916923522949, variance: 0.2250145524740219\n",
      "Train size: [400] hidden size: [118] trial: 24, train_loss: 1.484258, test loss: 1.022951, bias2: 0.796168327331543, variance: 0.22678306698799133\n",
      "Train size: [400] hidden size: [118] trial: 25, train_loss: 1.481573, test loss: 1.023187, bias2: 0.7974440455436707, variance: 0.22574298083782196\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [118] trial: 26, train_loss: 1.478709, test loss: 1.022754, bias2: 0.795242190361023, variance: 0.22751152515411377\n",
      "Train size: [400] hidden size: [118] trial: 27, train_loss: 1.472765, test loss: 1.023086, bias2: 0.794230043888092, variance: 0.22885553538799286\n",
      "Train size: [400] hidden size: [118] trial: 28, train_loss: 1.470559, test loss: 1.023698, bias2: 0.7941018342971802, variance: 0.22959628701210022\n",
      "Train size: [400] hidden size: [118] trial: 29, train_loss: 1.470029, test loss: 1.023648, bias2: 0.7914060354232788, variance: 0.23224210739135742\n",
      "Train size: [400] hidden size: [118] trial: 30, train_loss: 1.472154, test loss: 1.024304, bias2: 0.7901743650436401, variance: 0.23413005471229553\n",
      "Train size: [400] hidden size: [118] trial: 31, train_loss: 1.467721, test loss: 1.022267, bias2: 0.7879577875137329, variance: 0.23430907726287842\n",
      "Train size: [400] hidden size: [118] trial: 32, train_loss: 1.467549, test loss: 1.023338, bias2: 0.7892770171165466, variance: 0.23406140506267548\n",
      "Train size: [400] hidden size: [118] trial: 33, train_loss: 1.466883, test loss: 1.022699, bias2: 0.7879401445388794, variance: 0.23475921154022217\n",
      "Train size: [400] hidden size: [118] trial: 34, train_loss: 1.465273, test loss: 1.023169, bias2: 0.7890864610671997, variance: 0.23408211767673492\n",
      "Train size: [400] hidden size: [118] trial: 35, train_loss: 1.461731, test loss: 1.023397, bias2: 0.7891314029693604, variance: 0.23426534235477448\n",
      "Train size: [400] hidden size: [118] trial: 36, train_loss: 1.468202, test loss: 1.023344, bias2: 0.7902114987373352, variance: 0.2331325262784958\n",
      "Train size: [400] hidden size: [118] trial: 37, train_loss: 1.468587, test loss: 1.021910, bias2: 0.7889056205749512, variance: 0.2330041229724884\n",
      "Train size: [400] hidden size: [118] trial: 38, train_loss: 1.473409, test loss: 1.021721, bias2: 0.7889387607574463, variance: 0.23278239369392395\n",
      "Train size: [400] hidden size: [118] trial: 39, train_loss: 1.470643, test loss: 1.023690, bias2: 0.7913933396339417, variance: 0.2322961837053299\n",
      "Train size: [400] hidden size: [118] trial: 40, train_loss: 1.471336, test loss: 1.022837, bias2: 0.7908890247344971, variance: 0.2319478690624237\n",
      "Train size: [400] hidden size: [118] trial: 41, train_loss: 1.471515, test loss: 1.022620, bias2: 0.7911472320556641, variance: 0.23147283494472504\n",
      "Train size: [400] hidden size: [118] trial: 42, train_loss: 1.468430, test loss: 1.020752, bias2: 0.7899157404899597, variance: 0.23083585500717163\n",
      "Train size: [400] hidden size: [118] trial: 43, train_loss: 1.466729, test loss: 1.020771, bias2: 0.7902507781982422, variance: 0.23051980137825012\n",
      "Train size: [400] hidden size: [118] trial: 44, train_loss: 1.467308, test loss: 1.020918, bias2: 0.7902959585189819, variance: 0.2306220680475235\n",
      "Train size: [400] hidden size: [118] trial: 45, train_loss: 1.466631, test loss: 1.020899, bias2: 0.7905586957931519, variance: 0.2303403913974762\n",
      "Train size: [400] hidden size: [118] trial: 46, train_loss: 1.469198, test loss: 1.021670, bias2: 0.7913489937782288, variance: 0.2303207665681839\n",
      "Train size: [400] hidden size: [118] trial: 47, train_loss: 1.472855, test loss: 1.021389, bias2: 0.7925657629966736, variance: 0.22882334887981415\n",
      "Train size: [400] hidden size: [118] trial: 48, train_loss: 1.470511, test loss: 1.021018, bias2: 0.7932775020599365, variance: 0.22774061560630798\n",
      "Train size: [400] hidden size: [118] trial: 49, train_loss: 1.469351, test loss: 1.020611, bias2: 0.7937615513801575, variance: 0.22684986889362335\n",
      "##################################################\n",
      "Train size: [400] hidden size: [136] trial: 0, train_loss: 1.437337, test loss: 0.999299, bias2: 0.9992994666099548, variance: -7.785095901269301e-10\n",
      "Train size: [400] hidden size: [136] trial: 1, train_loss: 1.401172, test loss: 1.008099, bias2: 0.8733866214752197, variance: 0.13471221923828125\n",
      "Train size: [400] hidden size: [136] trial: 2, train_loss: 1.397460, test loss: 1.033518, bias2: 0.8709524869918823, variance: 0.162565678358078\n",
      "Train size: [400] hidden size: [136] trial: 3, train_loss: 1.360697, test loss: 1.031099, bias2: 0.8409192562103271, variance: 0.19018007814884186\n",
      "Train size: [400] hidden size: [136] trial: 4, train_loss: 1.383180, test loss: 1.024845, bias2: 0.827527642250061, variance: 0.19731734693050385\n",
      "Train size: [400] hidden size: [136] trial: 5, train_loss: 1.418941, test loss: 1.031691, bias2: 0.8125702142715454, variance: 0.21912120282649994\n",
      "Train size: [400] hidden size: [136] trial: 6, train_loss: 1.414497, test loss: 1.027556, bias2: 0.8102974891662598, variance: 0.21725834906101227\n",
      "Train size: [400] hidden size: [136] trial: 7, train_loss: 1.397845, test loss: 1.024492, bias2: 0.8018900752067566, variance: 0.22260241210460663\n",
      "Train size: [400] hidden size: [136] trial: 8, train_loss: 1.381760, test loss: 1.025564, bias2: 0.7981958389282227, variance: 0.22736822068691254\n",
      "Train size: [400] hidden size: [136] trial: 9, train_loss: 1.385764, test loss: 1.024713, bias2: 0.7989184260368347, variance: 0.22579486668109894\n",
      "Train size: [400] hidden size: [136] trial: 10, train_loss: 1.401037, test loss: 1.027579, bias2: 0.7943545579910278, variance: 0.23322463035583496\n",
      "Train size: [400] hidden size: [136] trial: 11, train_loss: 1.423827, test loss: 1.027219, bias2: 0.7919466495513916, variance: 0.23527202010154724\n",
      "Train size: [400] hidden size: [136] trial: 12, train_loss: 1.432379, test loss: 1.024756, bias2: 0.7888898253440857, variance: 0.23586565256118774\n",
      "Train size: [400] hidden size: [136] trial: 13, train_loss: 1.442201, test loss: 1.024228, bias2: 0.7864949703216553, variance: 0.23773303627967834\n",
      "Train size: [400] hidden size: [136] trial: 14, train_loss: 1.457735, test loss: 1.026972, bias2: 0.7882277965545654, variance: 0.23874403536319733\n",
      "Train size: [400] hidden size: [136] trial: 15, train_loss: 1.464980, test loss: 1.029743, bias2: 0.7893270254135132, variance: 0.2404160350561142\n",
      "Train size: [400] hidden size: [136] trial: 16, train_loss: 1.469196, test loss: 1.030394, bias2: 0.7902373671531677, variance: 0.24015681445598602\n",
      "Train size: [400] hidden size: [136] trial: 17, train_loss: 1.468653, test loss: 1.030786, bias2: 0.790844202041626, variance: 0.23994186520576477\n",
      "Train size: [400] hidden size: [136] trial: 18, train_loss: 1.470378, test loss: 1.030460, bias2: 0.7889704704284668, variance: 0.24148917198181152\n",
      "Train size: [400] hidden size: [136] trial: 19, train_loss: 1.462826, test loss: 1.029163, bias2: 0.7858127355575562, variance: 0.24335063993930817\n",
      "Train size: [400] hidden size: [136] trial: 20, train_loss: 1.466711, test loss: 1.031026, bias2: 0.7861305475234985, variance: 0.2448953092098236\n",
      "Train size: [400] hidden size: [136] trial: 21, train_loss: 1.458615, test loss: 1.032129, bias2: 0.7881606221199036, variance: 0.2439684122800827\n",
      "Train size: [400] hidden size: [136] trial: 22, train_loss: 1.453056, test loss: 1.031734, bias2: 0.7859727144241333, variance: 0.24576163291931152\n",
      "Train size: [400] hidden size: [136] trial: 23, train_loss: 1.449028, test loss: 1.032324, bias2: 0.7853373885154724, variance: 0.24698634445667267\n",
      "Train size: [400] hidden size: [136] trial: 24, train_loss: 1.444823, test loss: 1.029950, bias2: 0.7814090251922607, variance: 0.24854113161563873\n",
      "Train size: [400] hidden size: [136] trial: 25, train_loss: 1.440382, test loss: 1.029932, bias2: 0.780158281326294, variance: 0.2497739940881729\n",
      "Train size: [400] hidden size: [136] trial: 26, train_loss: 1.442806, test loss: 1.028579, bias2: 0.7769045829772949, variance: 0.25167417526245117\n",
      "Train size: [400] hidden size: [136] trial: 27, train_loss: 1.437982, test loss: 1.026598, bias2: 0.7757729291915894, variance: 0.25082555413246155\n",
      "Train size: [400] hidden size: [136] trial: 28, train_loss: 1.431874, test loss: 1.025476, bias2: 0.7730786800384521, variance: 0.25239765644073486\n",
      "Train size: [400] hidden size: [136] trial: 29, train_loss: 1.430071, test loss: 1.026672, bias2: 0.7745729684829712, variance: 0.2520988881587982\n",
      "Train size: [400] hidden size: [136] trial: 30, train_loss: 1.422046, test loss: 1.024823, bias2: 0.7723067998886108, variance: 0.25251615047454834\n",
      "Train size: [400] hidden size: [136] trial: 31, train_loss: 1.427142, test loss: 1.023632, bias2: 0.7708555459976196, variance: 0.2527768313884735\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [136] trial: 32, train_loss: 1.428591, test loss: 1.023355, bias2: 0.7710673809051514, variance: 0.2522871494293213\n",
      "Train size: [400] hidden size: [136] trial: 33, train_loss: 1.427247, test loss: 1.025192, bias2: 0.7723231315612793, variance: 0.25286877155303955\n",
      "Train size: [400] hidden size: [136] trial: 34, train_loss: 1.430367, test loss: 1.024638, bias2: 0.7720898389816284, variance: 0.2525482177734375\n",
      "Train size: [400] hidden size: [136] trial: 35, train_loss: 1.432197, test loss: 1.024090, bias2: 0.7704788446426392, variance: 0.25361141562461853\n",
      "Train size: [400] hidden size: [136] trial: 36, train_loss: 1.431638, test loss: 1.025086, bias2: 0.7715933918952942, variance: 0.2534927725791931\n",
      "Train size: [400] hidden size: [136] trial: 37, train_loss: 1.430202, test loss: 1.024509, bias2: 0.7724176645278931, variance: 0.25209176540374756\n",
      "Train size: [400] hidden size: [136] trial: 38, train_loss: 1.427566, test loss: 1.026150, bias2: 0.7732506990432739, variance: 0.25289902091026306\n",
      "Train size: [400] hidden size: [136] trial: 39, train_loss: 1.429792, test loss: 1.027542, bias2: 0.7746617197990417, variance: 0.2528800368309021\n",
      "Train size: [400] hidden size: [136] trial: 40, train_loss: 1.427653, test loss: 1.028042, bias2: 0.7757842540740967, variance: 0.2522578239440918\n",
      "Train size: [400] hidden size: [136] trial: 41, train_loss: 1.425125, test loss: 1.027057, bias2: 0.7744855880737305, variance: 0.25257155299186707\n",
      "Train size: [400] hidden size: [136] trial: 42, train_loss: 1.422403, test loss: 1.027845, bias2: 0.7758403420448303, variance: 0.2520042061805725\n",
      "Train size: [400] hidden size: [136] trial: 43, train_loss: 1.420937, test loss: 1.028556, bias2: 0.7757899761199951, variance: 0.25276637077331543\n",
      "Train size: [400] hidden size: [136] trial: 44, train_loss: 1.418462, test loss: 1.030747, bias2: 0.7757577896118164, variance: 0.2549891769886017\n",
      "Train size: [400] hidden size: [136] trial: 45, train_loss: 1.414584, test loss: 1.030629, bias2: 0.7766318321228027, variance: 0.2539968490600586\n",
      "Train size: [400] hidden size: [136] trial: 46, train_loss: 1.414939, test loss: 1.031062, bias2: 0.7757282853126526, variance: 0.25533348321914673\n",
      "Train size: [400] hidden size: [136] trial: 47, train_loss: 1.416509, test loss: 1.030862, bias2: 0.7758200168609619, variance: 0.2550424337387085\n",
      "Train size: [400] hidden size: [136] trial: 48, train_loss: 1.415584, test loss: 1.031512, bias2: 0.7756803035736084, variance: 0.2558320462703705\n",
      "Train size: [400] hidden size: [136] trial: 49, train_loss: 1.415637, test loss: 1.031559, bias2: 0.7755118012428284, variance: 0.2560473084449768\n",
      "##################################################\n",
      "Train size: [400] hidden size: [156] trial: 0, train_loss: 1.377089, test loss: 1.054027, bias2: 1.0540266036987305, variance: -4.087175486944261e-09\n",
      "Train size: [400] hidden size: [156] trial: 1, train_loss: 1.369941, test loss: 1.044664, bias2: 0.871694028377533, variance: 0.17297033965587616\n",
      "Train size: [400] hidden size: [156] trial: 2, train_loss: 1.331588, test loss: 1.046836, bias2: 0.8244758248329163, variance: 0.22236043214797974\n",
      "Train size: [400] hidden size: [156] trial: 3, train_loss: 1.370699, test loss: 1.032834, bias2: 0.8154700994491577, variance: 0.21736356616020203\n",
      "Train size: [400] hidden size: [156] trial: 4, train_loss: 1.360330, test loss: 1.042447, bias2: 0.8132297396659851, variance: 0.22921685874462128\n",
      "Train size: [400] hidden size: [156] trial: 5, train_loss: 1.377943, test loss: 1.043489, bias2: 0.8013497591018677, variance: 0.24213875830173492\n",
      "Train size: [400] hidden size: [156] trial: 6, train_loss: 1.390690, test loss: 1.047440, bias2: 0.801972508430481, variance: 0.24546752870082855\n",
      "Train size: [400] hidden size: [156] trial: 7, train_loss: 1.384865, test loss: 1.047515, bias2: 0.7948899269104004, variance: 0.25262531638145447\n",
      "Train size: [400] hidden size: [156] trial: 8, train_loss: 1.376573, test loss: 1.034182, bias2: 0.7870145440101624, variance: 0.24716787040233612\n",
      "Train size: [400] hidden size: [156] trial: 9, train_loss: 1.387436, test loss: 1.035775, bias2: 0.7830517292022705, variance: 0.25272366404533386\n",
      "Train size: [400] hidden size: [156] trial: 10, train_loss: 1.379870, test loss: 1.029760, bias2: 0.7742961645126343, variance: 0.25546371936798096\n",
      "Train size: [400] hidden size: [156] trial: 11, train_loss: 1.365776, test loss: 1.028557, bias2: 0.7704711556434631, variance: 0.25808578729629517\n",
      "Train size: [400] hidden size: [156] trial: 12, train_loss: 1.352617, test loss: 1.036428, bias2: 0.7712270021438599, variance: 0.2652013599872589\n",
      "Train size: [400] hidden size: [156] trial: 13, train_loss: 1.358626, test loss: 1.039312, bias2: 0.7682047486305237, variance: 0.27110737562179565\n",
      "Train size: [400] hidden size: [156] trial: 14, train_loss: 1.357136, test loss: 1.039517, bias2: 0.7667020559310913, variance: 0.2728153169155121\n",
      "Train size: [400] hidden size: [156] trial: 15, train_loss: 1.365063, test loss: 1.039350, bias2: 0.7679224610328674, variance: 0.27142733335494995\n",
      "Train size: [400] hidden size: [156] trial: 16, train_loss: 1.355228, test loss: 1.042224, bias2: 0.767117440700531, variance: 0.2751064896583557\n",
      "Train size: [400] hidden size: [156] trial: 17, train_loss: 1.351260, test loss: 1.042882, bias2: 0.7677910327911377, variance: 0.27509140968322754\n",
      "Train size: [400] hidden size: [156] trial: 18, train_loss: 1.347379, test loss: 1.040293, bias2: 0.7642269134521484, variance: 0.27606645226478577\n",
      "Train size: [400] hidden size: [156] trial: 19, train_loss: 1.356258, test loss: 1.041530, bias2: 0.7638376355171204, variance: 0.27769213914871216\n",
      "Train size: [400] hidden size: [156] trial: 20, train_loss: 1.360661, test loss: 1.041252, bias2: 0.7615536451339722, variance: 0.2796988785266876\n",
      "Train size: [400] hidden size: [156] trial: 21, train_loss: 1.364584, test loss: 1.046321, bias2: 0.7630010843276978, variance: 0.2833200991153717\n",
      "Train size: [400] hidden size: [156] trial: 22, train_loss: 1.363039, test loss: 1.046413, bias2: 0.760875940322876, variance: 0.2855372130870819\n",
      "Train size: [400] hidden size: [156] trial: 23, train_loss: 1.356722, test loss: 1.044248, bias2: 0.7598106861114502, variance: 0.2844375669956207\n",
      "Train size: [400] hidden size: [156] trial: 24, train_loss: 1.352106, test loss: 1.042076, bias2: 0.7587002515792847, variance: 0.283376008272171\n",
      "Train size: [400] hidden size: [156] trial: 25, train_loss: 1.345488, test loss: 1.043665, bias2: 0.7577382326126099, variance: 0.2859269082546234\n",
      "Train size: [400] hidden size: [156] trial: 26, train_loss: 1.347886, test loss: 1.044469, bias2: 0.756751298904419, variance: 0.28771793842315674\n",
      "Train size: [400] hidden size: [156] trial: 27, train_loss: 1.347374, test loss: 1.042470, bias2: 0.7537490129470825, variance: 0.28872087597846985\n",
      "Train size: [400] hidden size: [156] trial: 28, train_loss: 1.344596, test loss: 1.043110, bias2: 0.754903256893158, variance: 0.28820639848709106\n",
      "Train size: [400] hidden size: [156] trial: 29, train_loss: 1.345413, test loss: 1.043783, bias2: 0.7560475468635559, variance: 0.2877352833747864\n",
      "Train size: [400] hidden size: [156] trial: 30, train_loss: 1.346824, test loss: 1.043585, bias2: 0.7542622685432434, variance: 0.2893231511116028\n",
      "Train size: [400] hidden size: [156] trial: 31, train_loss: 1.347321, test loss: 1.044811, bias2: 0.7524678707122803, variance: 0.29234278202056885\n",
      "Train size: [400] hidden size: [156] trial: 32, train_loss: 1.338022, test loss: 1.044992, bias2: 0.7516657710075378, variance: 0.29332631826400757\n",
      "Train size: [400] hidden size: [156] trial: 33, train_loss: 1.332433, test loss: 1.044893, bias2: 0.751356840133667, variance: 0.2935360372066498\n",
      "Train size: [400] hidden size: [156] trial: 34, train_loss: 1.336321, test loss: 1.046088, bias2: 0.7524223923683167, variance: 0.29366534948349\n",
      "Train size: [400] hidden size: [156] trial: 35, train_loss: 1.335429, test loss: 1.045862, bias2: 0.7514764666557312, variance: 0.29438596963882446\n",
      "Train size: [400] hidden size: [156] trial: 36, train_loss: 1.331928, test loss: 1.047931, bias2: 0.7531555891036987, variance: 0.29477569460868835\n",
      "Train size: [400] hidden size: [156] trial: 37, train_loss: 1.333005, test loss: 1.048148, bias2: 0.752989649772644, variance: 0.2951584756374359\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [156] trial: 38, train_loss: 1.333603, test loss: 1.049255, bias2: 0.753204345703125, variance: 0.2960505187511444\n",
      "Train size: [400] hidden size: [156] trial: 39, train_loss: 1.336399, test loss: 1.052239, bias2: 0.7552604675292969, variance: 0.296978622674942\n",
      "Train size: [400] hidden size: [156] trial: 40, train_loss: 1.335150, test loss: 1.051373, bias2: 0.7540494203567505, variance: 0.29732343554496765\n",
      "Train size: [400] hidden size: [156] trial: 41, train_loss: 1.334497, test loss: 1.049457, bias2: 0.7527050971984863, variance: 0.2967517673969269\n",
      "Train size: [400] hidden size: [156] trial: 42, train_loss: 1.334636, test loss: 1.048645, bias2: 0.7520835399627686, variance: 0.2965615689754486\n",
      "Train size: [400] hidden size: [156] trial: 43, train_loss: 1.333505, test loss: 1.048867, bias2: 0.751559853553772, variance: 0.2973073720932007\n",
      "Train size: [400] hidden size: [156] trial: 44, train_loss: 1.337362, test loss: 1.048488, bias2: 0.7509657144546509, variance: 0.2975222170352936\n",
      "Train size: [400] hidden size: [156] trial: 45, train_loss: 1.338871, test loss: 1.047971, bias2: 0.752517819404602, variance: 0.295452743768692\n",
      "Train size: [400] hidden size: [156] trial: 46, train_loss: 1.335984, test loss: 1.049984, bias2: 0.7544747591018677, variance: 0.29550933837890625\n",
      "Train size: [400] hidden size: [156] trial: 47, train_loss: 1.336627, test loss: 1.049998, bias2: 0.7542409896850586, variance: 0.2957572937011719\n",
      "Train size: [400] hidden size: [156] trial: 48, train_loss: 1.335728, test loss: 1.049833, bias2: 0.7532682418823242, variance: 0.29656457901000977\n",
      "Train size: [400] hidden size: [156] trial: 49, train_loss: 1.339702, test loss: 1.050592, bias2: 0.752586841583252, variance: 0.2980055809020996\n",
      "##################################################\n",
      "Train size: [400] hidden size: [180] trial: 0, train_loss: 1.324023, test loss: 1.030380, bias2: 1.030380368232727, variance: 3.8925479506346505e-10\n",
      "Train size: [400] hidden size: [180] trial: 1, train_loss: 1.282279, test loss: 1.036932, bias2: 0.8763858079910278, variance: 0.16054609417915344\n",
      "Train size: [400] hidden size: [180] trial: 2, train_loss: 1.256988, test loss: 1.029503, bias2: 0.818899393081665, variance: 0.210603266954422\n",
      "Train size: [400] hidden size: [180] trial: 3, train_loss: 1.241022, test loss: 1.057501, bias2: 0.7970037460327148, variance: 0.26049765944480896\n",
      "Train size: [400] hidden size: [180] trial: 4, train_loss: 1.261834, test loss: 1.066076, bias2: 0.802329421043396, variance: 0.2637467086315155\n",
      "Train size: [400] hidden size: [180] trial: 5, train_loss: 1.267780, test loss: 1.064584, bias2: 0.7934525609016418, variance: 0.27113133668899536\n",
      "Train size: [400] hidden size: [180] trial: 6, train_loss: 1.246292, test loss: 1.071909, bias2: 0.7841298580169678, variance: 0.2877785861492157\n",
      "Train size: [400] hidden size: [180] trial: 7, train_loss: 1.238621, test loss: 1.068585, bias2: 0.7774519920349121, variance: 0.2911332845687866\n",
      "Train size: [400] hidden size: [180] trial: 8, train_loss: 1.245726, test loss: 1.068787, bias2: 0.7700233459472656, variance: 0.29876402020454407\n",
      "Train size: [400] hidden size: [180] trial: 9, train_loss: 1.241997, test loss: 1.071903, bias2: 0.7726837396621704, variance: 0.2992190420627594\n",
      "Train size: [400] hidden size: [180] trial: 10, train_loss: 1.246237, test loss: 1.081128, bias2: 0.7779903411865234, variance: 0.3031373918056488\n",
      "Train size: [400] hidden size: [180] trial: 11, train_loss: 1.233664, test loss: 1.082291, bias2: 0.7688398957252502, variance: 0.31345099210739136\n",
      "Train size: [400] hidden size: [180] trial: 12, train_loss: 1.231312, test loss: 1.076422, bias2: 0.7617042064666748, variance: 0.31471768021583557\n",
      "Train size: [400] hidden size: [180] trial: 13, train_loss: 1.227404, test loss: 1.074736, bias2: 0.7564531564712524, variance: 0.3182826340198517\n",
      "Train size: [400] hidden size: [180] trial: 14, train_loss: 1.231271, test loss: 1.072285, bias2: 0.7535076141357422, variance: 0.3187769949436188\n",
      "Train size: [400] hidden size: [180] trial: 15, train_loss: 1.229548, test loss: 1.076456, bias2: 0.752009928226471, variance: 0.324445903301239\n",
      "Train size: [400] hidden size: [180] trial: 16, train_loss: 1.226835, test loss: 1.075101, bias2: 0.7450368404388428, variance: 0.33006367087364197\n",
      "Train size: [400] hidden size: [180] trial: 17, train_loss: 1.226920, test loss: 1.076288, bias2: 0.7438088655471802, variance: 0.33247900009155273\n",
      "Train size: [400] hidden size: [180] trial: 18, train_loss: 1.239692, test loss: 1.077781, bias2: 0.7416881918907166, variance: 0.33609241247177124\n",
      "Train size: [400] hidden size: [180] trial: 19, train_loss: 1.240237, test loss: 1.072089, bias2: 0.7366148233413696, variance: 0.3354738652706146\n",
      "Train size: [400] hidden size: [180] trial: 20, train_loss: 1.237859, test loss: 1.067720, bias2: 0.7295724153518677, variance: 0.3381478786468506\n",
      "Train size: [400] hidden size: [180] trial: 21, train_loss: 1.232617, test loss: 1.066375, bias2: 0.730104923248291, variance: 0.3362705707550049\n",
      "Train size: [400] hidden size: [180] trial: 22, train_loss: 1.239196, test loss: 1.068267, bias2: 0.728814959526062, variance: 0.3394519090652466\n",
      "Train size: [400] hidden size: [180] trial: 23, train_loss: 1.237580, test loss: 1.068549, bias2: 0.7297405004501343, variance: 0.33880817890167236\n",
      "Train size: [400] hidden size: [180] trial: 24, train_loss: 1.245738, test loss: 1.067606, bias2: 0.7293112874031067, variance: 0.33829420804977417\n",
      "Train size: [400] hidden size: [180] trial: 25, train_loss: 1.245012, test loss: 1.066523, bias2: 0.7279032468795776, variance: 0.3386192321777344\n",
      "Train size: [400] hidden size: [180] trial: 26, train_loss: 1.241276, test loss: 1.068787, bias2: 0.727461040019989, variance: 0.34132593870162964\n",
      "Train size: [400] hidden size: [180] trial: 27, train_loss: 1.240180, test loss: 1.068016, bias2: 0.7266486883163452, variance: 0.3413677215576172\n",
      "Train size: [400] hidden size: [180] trial: 28, train_loss: 1.242274, test loss: 1.070558, bias2: 0.7273398637771606, variance: 0.34321799874305725\n",
      "Train size: [400] hidden size: [180] trial: 29, train_loss: 1.241403, test loss: 1.069013, bias2: 0.7253358364105225, variance: 0.3436773717403412\n",
      "Train size: [400] hidden size: [180] trial: 30, train_loss: 1.240796, test loss: 1.069781, bias2: 0.7243428230285645, variance: 0.3454376757144928\n",
      "Train size: [400] hidden size: [180] trial: 31, train_loss: 1.243422, test loss: 1.069640, bias2: 0.7238907814025879, variance: 0.3457491397857666\n",
      "Train size: [400] hidden size: [180] trial: 32, train_loss: 1.242510, test loss: 1.069753, bias2: 0.7229762077331543, variance: 0.3467765748500824\n",
      "Train size: [400] hidden size: [180] trial: 33, train_loss: 1.240440, test loss: 1.069122, bias2: 0.7229149341583252, variance: 0.34620681405067444\n",
      "Train size: [400] hidden size: [180] trial: 34, train_loss: 1.237676, test loss: 1.067307, bias2: 0.7221355438232422, variance: 0.3451717793941498\n",
      "Train size: [400] hidden size: [180] trial: 35, train_loss: 1.237748, test loss: 1.066138, bias2: 0.7211093902587891, variance: 0.3450288474559784\n",
      "Train size: [400] hidden size: [180] trial: 36, train_loss: 1.234221, test loss: 1.067754, bias2: 0.7224593162536621, variance: 0.3452945947647095\n",
      "Train size: [400] hidden size: [180] trial: 37, train_loss: 1.234131, test loss: 1.072031, bias2: 0.7235583066940308, variance: 0.3484722077846527\n",
      "Train size: [400] hidden size: [180] trial: 38, train_loss: 1.233490, test loss: 1.072549, bias2: 0.7230114936828613, variance: 0.34953784942626953\n",
      "Train size: [400] hidden size: [180] trial: 39, train_loss: 1.231694, test loss: 1.072705, bias2: 0.7223116159439087, variance: 0.35039374232292175\n",
      "Train size: [400] hidden size: [180] trial: 40, train_loss: 1.228949, test loss: 1.074376, bias2: 0.7215584516525269, variance: 0.3528172969818115\n",
      "Train size: [400] hidden size: [180] trial: 41, train_loss: 1.229971, test loss: 1.074047, bias2: 0.7198828458786011, variance: 0.35416385531425476\n",
      "Train size: [400] hidden size: [180] trial: 42, train_loss: 1.225737, test loss: 1.075920, bias2: 0.7208610773086548, variance: 0.3550589382648468\n",
      "Train size: [400] hidden size: [180] trial: 43, train_loss: 1.226330, test loss: 1.074283, bias2: 0.7199652194976807, variance: 0.35431814193725586\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [180] trial: 44, train_loss: 1.223485, test loss: 1.074343, bias2: 0.7211036682128906, variance: 0.3532398045063019\n",
      "Train size: [400] hidden size: [180] trial: 45, train_loss: 1.223953, test loss: 1.076731, bias2: 0.7224620580673218, variance: 0.354269415140152\n",
      "Train size: [400] hidden size: [180] trial: 46, train_loss: 1.220055, test loss: 1.075896, bias2: 0.7210518717765808, variance: 0.3548441529273987\n",
      "Train size: [400] hidden size: [180] trial: 47, train_loss: 1.221459, test loss: 1.075071, bias2: 0.7212346196174622, variance: 0.3538364768028259\n",
      "Train size: [400] hidden size: [180] trial: 48, train_loss: 1.222892, test loss: 1.076145, bias2: 0.7199973464012146, variance: 0.3561480641365051\n",
      "Train size: [400] hidden size: [180] trial: 49, train_loss: 1.221638, test loss: 1.075646, bias2: 0.7198727130889893, variance: 0.35577306151390076\n",
      "##################################################\n",
      "Train size: [400] hidden size: [207] trial: 0, train_loss: 1.138781, test loss: 1.139929, bias2: 1.1399286985397339, variance: 2.530156306690401e-09\n",
      "Train size: [400] hidden size: [207] trial: 1, train_loss: 1.199808, test loss: 1.114199, bias2: 0.8990897536277771, variance: 0.2151096612215042\n",
      "Train size: [400] hidden size: [207] trial: 2, train_loss: 1.221908, test loss: 1.108631, bias2: 0.8131035566329956, variance: 0.29552772641181946\n",
      "Train size: [400] hidden size: [207] trial: 3, train_loss: 1.229354, test loss: 1.091188, bias2: 0.7709498405456543, variance: 0.3202378749847412\n",
      "Train size: [400] hidden size: [207] trial: 4, train_loss: 1.171608, test loss: 1.082455, bias2: 0.7604094743728638, variance: 0.3220452070236206\n",
      "Train size: [400] hidden size: [207] trial: 5, train_loss: 1.143770, test loss: 1.108930, bias2: 0.7451304197311401, variance: 0.36379989981651306\n",
      "Train size: [400] hidden size: [207] trial: 6, train_loss: 1.141055, test loss: 1.117768, bias2: 0.7362709045410156, variance: 0.38149675726890564\n",
      "Train size: [400] hidden size: [207] trial: 7, train_loss: 1.160983, test loss: 1.126865, bias2: 0.7294955253601074, variance: 0.3973694145679474\n",
      "Train size: [400] hidden size: [207] trial: 8, train_loss: 1.166350, test loss: 1.121397, bias2: 0.7242944240570068, variance: 0.39710211753845215\n",
      "Train size: [400] hidden size: [207] trial: 9, train_loss: 1.159071, test loss: 1.121373, bias2: 0.7153307199478149, variance: 0.40604186058044434\n",
      "Train size: [400] hidden size: [207] trial: 10, train_loss: 1.155665, test loss: 1.117351, bias2: 0.7095886468887329, variance: 0.40776196122169495\n",
      "Train size: [400] hidden size: [207] trial: 11, train_loss: 1.144862, test loss: 1.121071, bias2: 0.7099959850311279, variance: 0.4110753834247589\n",
      "Train size: [400] hidden size: [207] trial: 12, train_loss: 1.145909, test loss: 1.106983, bias2: 0.6977700591087341, variance: 0.4092124104499817\n",
      "Train size: [400] hidden size: [207] trial: 13, train_loss: 1.154708, test loss: 1.103606, bias2: 0.6904373168945312, variance: 0.41316846013069153\n",
      "Train size: [400] hidden size: [207] trial: 14, train_loss: 1.153923, test loss: 1.103058, bias2: 0.6866948008537292, variance: 0.41636329889297485\n",
      "Train size: [400] hidden size: [207] trial: 15, train_loss: 1.159074, test loss: 1.098329, bias2: 0.6832811832427979, variance: 0.41504743695259094\n",
      "Train size: [400] hidden size: [207] trial: 16, train_loss: 1.170066, test loss: 1.094543, bias2: 0.680382251739502, variance: 0.4141608476638794\n",
      "Train size: [400] hidden size: [207] trial: 17, train_loss: 1.178065, test loss: 1.094868, bias2: 0.6783757209777832, variance: 0.4164921045303345\n",
      "Train size: [400] hidden size: [207] trial: 18, train_loss: 1.180537, test loss: 1.096391, bias2: 0.6775262355804443, variance: 0.418864369392395\n",
      "Train size: [400] hidden size: [207] trial: 19, train_loss: 1.171599, test loss: 1.097225, bias2: 0.675363302230835, variance: 0.4218619167804718\n",
      "Train size: [400] hidden size: [207] trial: 20, train_loss: 1.174492, test loss: 1.090473, bias2: 0.6733721494674683, variance: 0.4171006679534912\n",
      "Train size: [400] hidden size: [207] trial: 21, train_loss: 1.176885, test loss: 1.087527, bias2: 0.6700671315193176, variance: 0.4174594283103943\n",
      "Train size: [400] hidden size: [207] trial: 22, train_loss: 1.171648, test loss: 1.088474, bias2: 0.6735966205596924, variance: 0.41487744450569153\n",
      "Train size: [400] hidden size: [207] trial: 23, train_loss: 1.168398, test loss: 1.086621, bias2: 0.6728585958480835, variance: 0.4137624502182007\n",
      "Train size: [400] hidden size: [207] trial: 24, train_loss: 1.169289, test loss: 1.088579, bias2: 0.6743806600570679, variance: 0.41419804096221924\n",
      "Train size: [400] hidden size: [207] trial: 25, train_loss: 1.166005, test loss: 1.087756, bias2: 0.672046422958374, variance: 0.41570982336997986\n",
      "Train size: [400] hidden size: [207] trial: 26, train_loss: 1.164094, test loss: 1.086734, bias2: 0.6692434549331665, variance: 0.4174906313419342\n",
      "Train size: [400] hidden size: [207] trial: 27, train_loss: 1.166968, test loss: 1.089213, bias2: 0.6728717088699341, variance: 0.41634130477905273\n",
      "Train size: [400] hidden size: [207] trial: 28, train_loss: 1.167477, test loss: 1.089457, bias2: 0.6752631664276123, variance: 0.4141937494277954\n",
      "Train size: [400] hidden size: [207] trial: 29, train_loss: 1.174096, test loss: 1.089602, bias2: 0.675044059753418, variance: 0.41455841064453125\n",
      "Train size: [400] hidden size: [207] trial: 30, train_loss: 1.167857, test loss: 1.088471, bias2: 0.6748697757720947, variance: 0.41360124945640564\n",
      "Train size: [400] hidden size: [207] trial: 31, train_loss: 1.169934, test loss: 1.090182, bias2: 0.6766958236694336, variance: 0.413486123085022\n",
      "Train size: [400] hidden size: [207] trial: 32, train_loss: 1.172965, test loss: 1.088021, bias2: 0.6742357015609741, variance: 0.41378533840179443\n",
      "Train size: [400] hidden size: [207] trial: 33, train_loss: 1.171950, test loss: 1.089914, bias2: 0.6754763722419739, variance: 0.414437472820282\n",
      "Train size: [400] hidden size: [207] trial: 34, train_loss: 1.167148, test loss: 1.089702, bias2: 0.6768786311149597, variance: 0.4128229022026062\n",
      "Train size: [400] hidden size: [207] trial: 35, train_loss: 1.166554, test loss: 1.091114, bias2: 0.677993655204773, variance: 0.4131205081939697\n",
      "Train size: [400] hidden size: [207] trial: 36, train_loss: 1.163977, test loss: 1.090323, bias2: 0.6797512769699097, variance: 0.41057130694389343\n",
      "Train size: [400] hidden size: [207] trial: 37, train_loss: 1.160376, test loss: 1.092038, bias2: 0.6808552742004395, variance: 0.4111827313899994\n",
      "Train size: [400] hidden size: [207] trial: 38, train_loss: 1.158694, test loss: 1.091990, bias2: 0.6819486618041992, variance: 0.4100412130355835\n",
      "Train size: [400] hidden size: [207] trial: 39, train_loss: 1.161284, test loss: 1.093507, bias2: 0.6818785667419434, variance: 0.4116280972957611\n",
      "Train size: [400] hidden size: [207] trial: 40, train_loss: 1.160967, test loss: 1.093150, bias2: 0.6829873919487, variance: 0.41016286611557007\n",
      "Train size: [400] hidden size: [207] trial: 41, train_loss: 1.162386, test loss: 1.092492, bias2: 0.6816787719726562, variance: 0.41081368923187256\n",
      "Train size: [400] hidden size: [207] trial: 42, train_loss: 1.159133, test loss: 1.093383, bias2: 0.6818675994873047, variance: 0.4115152060985565\n",
      "Train size: [400] hidden size: [207] trial: 43, train_loss: 1.157117, test loss: 1.093938, bias2: 0.6838449239730835, variance: 0.41009321808815\n",
      "Train size: [400] hidden size: [207] trial: 44, train_loss: 1.157107, test loss: 1.093547, bias2: 0.6844310760498047, variance: 0.4091161787509918\n",
      "Train size: [400] hidden size: [207] trial: 45, train_loss: 1.159703, test loss: 1.092443, bias2: 0.6827476024627686, variance: 0.40969574451446533\n",
      "Train size: [400] hidden size: [207] trial: 46, train_loss: 1.160193, test loss: 1.089768, bias2: 0.6808725595474243, variance: 0.40889573097229004\n",
      "Train size: [400] hidden size: [207] trial: 47, train_loss: 1.161810, test loss: 1.089733, bias2: 0.6816123127937317, variance: 0.40812045335769653\n",
      "Train size: [400] hidden size: [207] trial: 48, train_loss: 1.159473, test loss: 1.090203, bias2: 0.6826207041740417, variance: 0.4075821042060852\n",
      "Train size: [400] hidden size: [207] trial: 49, train_loss: 1.158877, test loss: 1.088853, bias2: 0.6809861660003662, variance: 0.4078671634197235\n",
      "##################################################\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [239] trial: 0, train_loss: 1.116425, test loss: 1.184036, bias2: 1.1840358972549438, variance: 3.1140383605077204e-09\n",
      "Train size: [400] hidden size: [239] trial: 1, train_loss: 1.071642, test loss: 1.114072, bias2: 0.887412428855896, variance: 0.22665955126285553\n",
      "Train size: [400] hidden size: [239] trial: 2, train_loss: 1.020622, test loss: 1.130998, bias2: 0.8185461759567261, variance: 0.31245148181915283\n",
      "Train size: [400] hidden size: [239] trial: 3, train_loss: 1.013288, test loss: 1.119221, bias2: 0.7666454315185547, variance: 0.3525758683681488\n",
      "Train size: [400] hidden size: [239] trial: 4, train_loss: 0.996129, test loss: 1.107009, bias2: 0.735222578048706, variance: 0.37178662419319153\n",
      "Train size: [400] hidden size: [239] trial: 5, train_loss: 1.012671, test loss: 1.123330, bias2: 0.7153681516647339, variance: 0.40796196460723877\n",
      "Train size: [400] hidden size: [239] trial: 6, train_loss: 1.024369, test loss: 1.135838, bias2: 0.7023773193359375, variance: 0.43346062302589417\n",
      "Train size: [400] hidden size: [239] trial: 7, train_loss: 1.031850, test loss: 1.148016, bias2: 0.7033805251121521, variance: 0.44463545083999634\n",
      "Train size: [400] hidden size: [239] trial: 8, train_loss: 1.040738, test loss: 1.148415, bias2: 0.696164608001709, variance: 0.45225074887275696\n",
      "Train size: [400] hidden size: [239] trial: 9, train_loss: 1.047343, test loss: 1.136856, bias2: 0.67674720287323, variance: 0.46010830998420715\n",
      "Train size: [400] hidden size: [239] trial: 10, train_loss: 1.039083, test loss: 1.137001, bias2: 0.6747291088104248, variance: 0.4622722864151001\n",
      "Train size: [400] hidden size: [239] trial: 11, train_loss: 1.042991, test loss: 1.132423, bias2: 0.665673017501831, variance: 0.4667498767375946\n",
      "Train size: [400] hidden size: [239] trial: 12, train_loss: 1.042171, test loss: 1.131701, bias2: 0.6625964641571045, variance: 0.46910417079925537\n",
      "Train size: [400] hidden size: [239] trial: 13, train_loss: 1.045531, test loss: 1.129942, bias2: 0.6583875417709351, variance: 0.4715547561645508\n",
      "Train size: [400] hidden size: [239] trial: 14, train_loss: 1.043683, test loss: 1.133140, bias2: 0.6601709127426147, variance: 0.4729691743850708\n",
      "Train size: [400] hidden size: [239] trial: 15, train_loss: 1.030402, test loss: 1.131769, bias2: 0.6601656675338745, variance: 0.47160303592681885\n",
      "Train size: [400] hidden size: [239] trial: 16, train_loss: 1.039512, test loss: 1.135257, bias2: 0.6585017442703247, variance: 0.4767555892467499\n",
      "Train size: [400] hidden size: [239] trial: 17, train_loss: 1.044307, test loss: 1.139223, bias2: 0.6604802012443542, variance: 0.4787430167198181\n",
      "Train size: [400] hidden size: [239] trial: 18, train_loss: 1.040448, test loss: 1.139873, bias2: 0.6598741412162781, variance: 0.47999852895736694\n",
      "Train size: [400] hidden size: [239] trial: 19, train_loss: 1.044650, test loss: 1.141466, bias2: 0.658867597579956, variance: 0.4825986623764038\n",
      "Train size: [400] hidden size: [239] trial: 20, train_loss: 1.044671, test loss: 1.142445, bias2: 0.6581791639328003, variance: 0.48426559567451477\n",
      "Train size: [400] hidden size: [239] trial: 21, train_loss: 1.041456, test loss: 1.137406, bias2: 0.652583122253418, variance: 0.4848233461380005\n",
      "Train size: [400] hidden size: [239] trial: 22, train_loss: 1.048388, test loss: 1.139240, bias2: 0.6541593074798584, variance: 0.4850812256336212\n",
      "Train size: [400] hidden size: [239] trial: 23, train_loss: 1.052037, test loss: 1.138531, bias2: 0.6533608436584473, variance: 0.4851696789264679\n",
      "Train size: [400] hidden size: [239] trial: 24, train_loss: 1.049405, test loss: 1.138409, bias2: 0.6534926891326904, variance: 0.48491647839546204\n",
      "Train size: [400] hidden size: [239] trial: 25, train_loss: 1.048906, test loss: 1.136963, bias2: 0.6529595255851746, variance: 0.48400384187698364\n",
      "Train size: [400] hidden size: [239] trial: 26, train_loss: 1.048906, test loss: 1.135590, bias2: 0.6495780348777771, variance: 0.48601192235946655\n",
      "Train size: [400] hidden size: [239] trial: 27, train_loss: 1.057101, test loss: 1.134980, bias2: 0.6484626531600952, variance: 0.4865175783634186\n",
      "Train size: [400] hidden size: [239] trial: 28, train_loss: 1.059777, test loss: 1.132552, bias2: 0.6475121378898621, variance: 0.4850396513938904\n",
      "Train size: [400] hidden size: [239] trial: 29, train_loss: 1.053690, test loss: 1.140314, bias2: 0.6507406234741211, variance: 0.489573210477829\n",
      "Train size: [400] hidden size: [239] trial: 30, train_loss: 1.054028, test loss: 1.139890, bias2: 0.6528128385543823, variance: 0.4870772361755371\n",
      "Train size: [400] hidden size: [239] trial: 31, train_loss: 1.053869, test loss: 1.145556, bias2: 0.6567356586456299, variance: 0.4888208210468292\n",
      "Train size: [400] hidden size: [239] trial: 32, train_loss: 1.052152, test loss: 1.146360, bias2: 0.6577596068382263, variance: 0.48860007524490356\n",
      "Train size: [400] hidden size: [239] trial: 33, train_loss: 1.055723, test loss: 1.147422, bias2: 0.6579991579055786, variance: 0.48942306637763977\n",
      "Train size: [400] hidden size: [239] trial: 34, train_loss: 1.053941, test loss: 1.149955, bias2: 0.6591403484344482, variance: 0.4908147156238556\n",
      "Train size: [400] hidden size: [239] trial: 35, train_loss: 1.053961, test loss: 1.148107, bias2: 0.6558807492256165, variance: 0.49222666025161743\n",
      "Train size: [400] hidden size: [239] trial: 36, train_loss: 1.056846, test loss: 1.147227, bias2: 0.6547298431396484, variance: 0.492497056722641\n",
      "Train size: [400] hidden size: [239] trial: 37, train_loss: 1.053435, test loss: 1.146483, bias2: 0.6543980836868286, variance: 0.49208521842956543\n",
      "Train size: [400] hidden size: [239] trial: 38, train_loss: 1.055027, test loss: 1.148190, bias2: 0.6543508768081665, variance: 0.493838906288147\n",
      "Train size: [400] hidden size: [239] trial: 39, train_loss: 1.052627, test loss: 1.146565, bias2: 0.6544343829154968, variance: 0.4921305775642395\n",
      "Train size: [400] hidden size: [239] trial: 40, train_loss: 1.056643, test loss: 1.144952, bias2: 0.6524652242660522, variance: 0.49248647689819336\n",
      "Train size: [400] hidden size: [239] trial: 41, train_loss: 1.056340, test loss: 1.146715, bias2: 0.6524189710617065, variance: 0.49429628252983093\n",
      "Train size: [400] hidden size: [239] trial: 42, train_loss: 1.058861, test loss: 1.147301, bias2: 0.6508991122245789, variance: 0.49640172719955444\n",
      "Train size: [400] hidden size: [239] trial: 43, train_loss: 1.054427, test loss: 1.146343, bias2: 0.6523362398147583, variance: 0.4940063953399658\n",
      "Train size: [400] hidden size: [239] trial: 44, train_loss: 1.054317, test loss: 1.146872, bias2: 0.6503461599349976, variance: 0.49652573466300964\n",
      "Train size: [400] hidden size: [239] trial: 45, train_loss: 1.052167, test loss: 1.147453, bias2: 0.6506866216659546, variance: 0.496766597032547\n",
      "Train size: [400] hidden size: [239] trial: 46, train_loss: 1.049132, test loss: 1.145495, bias2: 0.6517199873924255, variance: 0.4937748312950134\n",
      "Train size: [400] hidden size: [239] trial: 47, train_loss: 1.048961, test loss: 1.144576, bias2: 0.6492701768875122, variance: 0.4953056573867798\n",
      "Train size: [400] hidden size: [239] trial: 48, train_loss: 1.048159, test loss: 1.143027, bias2: 0.6484019756317139, variance: 0.4946252405643463\n",
      "Train size: [400] hidden size: [239] trial: 49, train_loss: 1.048487, test loss: 1.143491, bias2: 0.6480599641799927, variance: 0.4954312741756439\n",
      "##################################################\n",
      "Train size: [400] hidden size: [275] trial: 0, train_loss: 0.994297, test loss: 1.153422, bias2: 1.1534216403961182, variance: -2.3355288814030928e-09\n",
      "Train size: [400] hidden size: [275] trial: 1, train_loss: 0.933395, test loss: 1.138308, bias2: 0.8115483522415161, variance: 0.3267599642276764\n",
      "Train size: [400] hidden size: [275] trial: 2, train_loss: 0.949800, test loss: 1.140133, bias2: 0.7037825584411621, variance: 0.436350554227829\n",
      "Train size: [400] hidden size: [275] trial: 3, train_loss: 0.940335, test loss: 1.123210, bias2: 0.6573052406311035, variance: 0.4659050703048706\n",
      "Train size: [400] hidden size: [275] trial: 4, train_loss: 0.937486, test loss: 1.125181, bias2: 0.6236175894737244, variance: 0.5015634894371033\n",
      "Train size: [400] hidden size: [275] trial: 5, train_loss: 0.921836, test loss: 1.146208, bias2: 0.6217101812362671, variance: 0.5244978666305542\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [275] trial: 6, train_loss: 0.931753, test loss: 1.174574, bias2: 0.613198459148407, variance: 0.5613759160041809\n",
      "Train size: [400] hidden size: [275] trial: 7, train_loss: 0.921962, test loss: 1.166568, bias2: 0.6104997992515564, variance: 0.5560683608055115\n",
      "Train size: [400] hidden size: [275] trial: 8, train_loss: 0.913392, test loss: 1.161618, bias2: 0.603884756565094, variance: 0.557732880115509\n",
      "Train size: [400] hidden size: [275] trial: 9, train_loss: 0.908599, test loss: 1.152620, bias2: 0.6008170247077942, variance: 0.5518031716346741\n",
      "Train size: [400] hidden size: [275] trial: 10, train_loss: 0.910068, test loss: 1.161663, bias2: 0.6095470190048218, variance: 0.5521160364151001\n",
      "Train size: [400] hidden size: [275] trial: 11, train_loss: 0.905771, test loss: 1.163791, bias2: 0.6116991639137268, variance: 0.5520914196968079\n",
      "Train size: [400] hidden size: [275] trial: 12, train_loss: 0.919109, test loss: 1.156988, bias2: 0.6067597270011902, variance: 0.55022794008255\n",
      "Train size: [400] hidden size: [275] trial: 13, train_loss: 0.925226, test loss: 1.154210, bias2: 0.5980988144874573, variance: 0.5561112761497498\n",
      "Train size: [400] hidden size: [275] trial: 14, train_loss: 0.926567, test loss: 1.154231, bias2: 0.5953934192657471, variance: 0.5588380098342896\n",
      "Train size: [400] hidden size: [275] trial: 15, train_loss: 0.922326, test loss: 1.159906, bias2: 0.6028107404708862, variance: 0.5570956468582153\n",
      "Train size: [400] hidden size: [275] trial: 16, train_loss: 0.919764, test loss: 1.153143, bias2: 0.5992645621299744, variance: 0.5538784861564636\n",
      "Train size: [400] hidden size: [275] trial: 17, train_loss: 0.933021, test loss: 1.152158, bias2: 0.5952293276786804, variance: 0.5569284558296204\n",
      "Train size: [400] hidden size: [275] trial: 18, train_loss: 0.932660, test loss: 1.150214, bias2: 0.5925838351249695, variance: 0.5576301217079163\n",
      "Train size: [400] hidden size: [275] trial: 19, train_loss: 0.931750, test loss: 1.150327, bias2: 0.593292772769928, variance: 0.5570337176322937\n",
      "Train size: [400] hidden size: [275] trial: 20, train_loss: 0.927058, test loss: 1.150027, bias2: 0.5942564606666565, variance: 0.5557708144187927\n",
      "Train size: [400] hidden size: [275] trial: 21, train_loss: 0.921457, test loss: 1.147816, bias2: 0.5957393646240234, variance: 0.5520764589309692\n",
      "Train size: [400] hidden size: [275] trial: 22, train_loss: 0.920544, test loss: 1.153143, bias2: 0.5952666401863098, variance: 0.5578766465187073\n",
      "Train size: [400] hidden size: [275] trial: 23, train_loss: 0.929903, test loss: 1.152542, bias2: 0.5879875421524048, variance: 0.5645546913146973\n",
      "Train size: [400] hidden size: [275] trial: 24, train_loss: 0.931027, test loss: 1.149229, bias2: 0.5871782898902893, variance: 0.5620506405830383\n",
      "Train size: [400] hidden size: [275] trial: 25, train_loss: 0.927972, test loss: 1.152159, bias2: 0.5888283848762512, variance: 0.5633304715156555\n",
      "Train size: [400] hidden size: [275] trial: 26, train_loss: 0.923368, test loss: 1.153826, bias2: 0.5895131826400757, variance: 0.5643131732940674\n",
      "Train size: [400] hidden size: [275] trial: 27, train_loss: 0.927582, test loss: 1.150924, bias2: 0.5869495868682861, variance: 0.5639743804931641\n",
      "Train size: [400] hidden size: [275] trial: 28, train_loss: 0.930078, test loss: 1.150605, bias2: 0.5876214504241943, variance: 0.5629832744598389\n",
      "Train size: [400] hidden size: [275] trial: 29, train_loss: 0.931660, test loss: 1.152543, bias2: 0.5877271890640259, variance: 0.564815878868103\n",
      "Train size: [400] hidden size: [275] trial: 30, train_loss: 0.933904, test loss: 1.151126, bias2: 0.5884996652603149, variance: 0.5626266002655029\n",
      "Train size: [400] hidden size: [275] trial: 31, train_loss: 0.932041, test loss: 1.151982, bias2: 0.589577317237854, variance: 0.5624046325683594\n",
      "Train size: [400] hidden size: [275] trial: 32, train_loss: 0.931800, test loss: 1.155879, bias2: 0.5899254083633423, variance: 0.5659531354904175\n",
      "Train size: [400] hidden size: [275] trial: 33, train_loss: 0.934305, test loss: 1.155171, bias2: 0.5878838896751404, variance: 0.5672875046730042\n",
      "Train size: [400] hidden size: [275] trial: 34, train_loss: 0.936503, test loss: 1.157190, bias2: 0.5866037607192993, variance: 0.5705859661102295\n",
      "Train size: [400] hidden size: [275] trial: 35, train_loss: 0.939805, test loss: 1.159737, bias2: 0.5880079865455627, variance: 0.5717291235923767\n",
      "Train size: [400] hidden size: [275] trial: 36, train_loss: 0.939453, test loss: 1.157045, bias2: 0.5890583395957947, variance: 0.5679866671562195\n",
      "Train size: [400] hidden size: [275] trial: 37, train_loss: 0.942683, test loss: 1.157465, bias2: 0.5869957208633423, variance: 0.5704696178436279\n",
      "Train size: [400] hidden size: [275] trial: 38, train_loss: 0.943821, test loss: 1.154914, bias2: 0.586589515209198, variance: 0.5683249831199646\n",
      "Train size: [400] hidden size: [275] trial: 39, train_loss: 0.946223, test loss: 1.155138, bias2: 0.5872992277145386, variance: 0.5678390264511108\n",
      "Train size: [400] hidden size: [275] trial: 40, train_loss: 0.947565, test loss: 1.154952, bias2: 0.5864363312721252, variance: 0.5685158371925354\n",
      "Train size: [400] hidden size: [275] trial: 41, train_loss: 0.947450, test loss: 1.156816, bias2: 0.5882033705711365, variance: 0.5686121582984924\n",
      "Train size: [400] hidden size: [275] trial: 42, train_loss: 0.945821, test loss: 1.157278, bias2: 0.5894045233726501, variance: 0.5678730607032776\n",
      "Train size: [400] hidden size: [275] trial: 43, train_loss: 0.947333, test loss: 1.158119, bias2: 0.5889759063720703, variance: 0.5691431760787964\n",
      "Train size: [400] hidden size: [275] trial: 44, train_loss: 0.946490, test loss: 1.159851, bias2: 0.5903720259666443, variance: 0.5694791674613953\n",
      "Train size: [400] hidden size: [275] trial: 45, train_loss: 0.944349, test loss: 1.159626, bias2: 0.5883634686470032, variance: 0.5712621808052063\n",
      "Train size: [400] hidden size: [275] trial: 46, train_loss: 0.942118, test loss: 1.159724, bias2: 0.5873009562492371, variance: 0.57242351770401\n",
      "Train size: [400] hidden size: [275] trial: 47, train_loss: 0.942009, test loss: 1.156088, bias2: 0.5845018029212952, variance: 0.5715859532356262\n",
      "Train size: [400] hidden size: [275] trial: 48, train_loss: 0.943137, test loss: 1.156198, bias2: 0.5843473672866821, variance: 0.5718508958816528\n",
      "Train size: [400] hidden size: [275] trial: 49, train_loss: 0.944271, test loss: 1.155039, bias2: 0.5837656855583191, variance: 0.5712729096412659\n",
      "##################################################\n",
      "Train size: [400] hidden size: [316] trial: 0, train_loss: 0.767897, test loss: 1.123944, bias2: 1.1239441633224487, variance: 7.0065864221646734e-09\n",
      "Train size: [400] hidden size: [316] trial: 1, train_loss: 0.840086, test loss: 1.239374, bias2: 0.8737950921058655, variance: 0.3655785918235779\n",
      "Train size: [400] hidden size: [316] trial: 2, train_loss: 0.854853, test loss: 1.244051, bias2: 0.7763344645500183, variance: 0.46771687269210815\n",
      "Train size: [400] hidden size: [316] trial: 3, train_loss: 0.828785, test loss: 1.221727, bias2: 0.7102216482162476, variance: 0.511505126953125\n",
      "Train size: [400] hidden size: [316] trial: 4, train_loss: 0.824090, test loss: 1.225190, bias2: 0.673628568649292, variance: 0.551561713218689\n",
      "Train size: [400] hidden size: [316] trial: 5, train_loss: 0.825220, test loss: 1.225825, bias2: 0.6462613940238953, variance: 0.5795634388923645\n",
      "Train size: [400] hidden size: [316] trial: 6, train_loss: 0.823500, test loss: 1.198675, bias2: 0.6037093997001648, variance: 0.5949651598930359\n",
      "Train size: [400] hidden size: [316] trial: 7, train_loss: 0.845425, test loss: 1.216754, bias2: 0.5974726676940918, variance: 0.6192817687988281\n",
      "Train size: [400] hidden size: [316] trial: 8, train_loss: 0.854343, test loss: 1.223052, bias2: 0.5845670700073242, variance: 0.6384847164154053\n",
      "Train size: [400] hidden size: [316] trial: 9, train_loss: 0.859604, test loss: 1.231523, bias2: 0.5834144353866577, variance: 0.648108720779419\n",
      "Train size: [400] hidden size: [316] trial: 10, train_loss: 0.868685, test loss: 1.227726, bias2: 0.5769603848457336, variance: 0.6507660746574402\n",
      "Train size: [400] hidden size: [316] trial: 11, train_loss: 0.860586, test loss: 1.226292, bias2: 0.5749711394309998, variance: 0.6513211131095886\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [316] trial: 12, train_loss: 0.857541, test loss: 1.225045, bias2: 0.5720476508140564, variance: 0.6529971957206726\n",
      "Train size: [400] hidden size: [316] trial: 13, train_loss: 0.864536, test loss: 1.233359, bias2: 0.5735402703285217, variance: 0.6598188281059265\n",
      "Train size: [400] hidden size: [316] trial: 14, train_loss: 0.858055, test loss: 1.225917, bias2: 0.5720736980438232, variance: 0.6538434028625488\n",
      "Train size: [400] hidden size: [316] trial: 15, train_loss: 0.864077, test loss: 1.245210, bias2: 0.5760887265205383, variance: 0.6691208481788635\n",
      "Train size: [400] hidden size: [316] trial: 16, train_loss: 0.863124, test loss: 1.237613, bias2: 0.5723592638969421, variance: 0.6652534604072571\n",
      "Train size: [400] hidden size: [316] trial: 17, train_loss: 0.864215, test loss: 1.234743, bias2: 0.5734425187110901, variance: 0.661300003528595\n",
      "Train size: [400] hidden size: [316] trial: 18, train_loss: 0.864072, test loss: 1.231639, bias2: 0.5697260499000549, variance: 0.6619126200675964\n",
      "Train size: [400] hidden size: [316] trial: 19, train_loss: 0.858520, test loss: 1.229701, bias2: 0.5603407025337219, variance: 0.6693598628044128\n",
      "Train size: [400] hidden size: [316] trial: 20, train_loss: 0.856515, test loss: 1.236855, bias2: 0.5609761476516724, variance: 0.6758788824081421\n",
      "Train size: [400] hidden size: [316] trial: 21, train_loss: 0.852412, test loss: 1.234551, bias2: 0.5599446892738342, variance: 0.6746063828468323\n",
      "Train size: [400] hidden size: [316] trial: 22, train_loss: 0.851459, test loss: 1.231341, bias2: 0.5623835325241089, variance: 0.6689573526382446\n",
      "Train size: [400] hidden size: [316] trial: 23, train_loss: 0.850341, test loss: 1.227678, bias2: 0.560258686542511, variance: 0.6674194931983948\n",
      "Train size: [400] hidden size: [316] trial: 24, train_loss: 0.848199, test loss: 1.229970, bias2: 0.5594140887260437, variance: 0.6705562472343445\n",
      "Train size: [400] hidden size: [316] trial: 25, train_loss: 0.848041, test loss: 1.229923, bias2: 0.5572797060012817, variance: 0.6726433038711548\n",
      "Train size: [400] hidden size: [316] trial: 26, train_loss: 0.844937, test loss: 1.231918, bias2: 0.5584683418273926, variance: 0.6734497547149658\n",
      "Train size: [400] hidden size: [316] trial: 27, train_loss: 0.846760, test loss: 1.234116, bias2: 0.5549812912940979, variance: 0.6791344285011292\n",
      "Train size: [400] hidden size: [316] trial: 28, train_loss: 0.847510, test loss: 1.233322, bias2: 0.5506265759468079, variance: 0.6826949715614319\n",
      "Train size: [400] hidden size: [316] trial: 29, train_loss: 0.849175, test loss: 1.236176, bias2: 0.549872875213623, variance: 0.6863027811050415\n",
      "Train size: [400] hidden size: [316] trial: 30, train_loss: 0.847567, test loss: 1.236685, bias2: 0.5509179830551147, variance: 0.6857668161392212\n",
      "Train size: [400] hidden size: [316] trial: 31, train_loss: 0.847087, test loss: 1.236348, bias2: 0.5474571585655212, variance: 0.6888912320137024\n",
      "Train size: [400] hidden size: [316] trial: 32, train_loss: 0.844283, test loss: 1.237308, bias2: 0.5487546324729919, variance: 0.6885533928871155\n",
      "Train size: [400] hidden size: [316] trial: 33, train_loss: 0.842744, test loss: 1.234970, bias2: 0.545720636844635, variance: 0.6892498135566711\n",
      "Train size: [400] hidden size: [316] trial: 34, train_loss: 0.845675, test loss: 1.236341, bias2: 0.5452494621276855, variance: 0.6910911798477173\n",
      "Train size: [400] hidden size: [316] trial: 35, train_loss: 0.845406, test loss: 1.238876, bias2: 0.5462331771850586, variance: 0.692642331123352\n",
      "Train size: [400] hidden size: [316] trial: 36, train_loss: 0.846458, test loss: 1.237639, bias2: 0.5452271699905396, variance: 0.6924120187759399\n",
      "Train size: [400] hidden size: [316] trial: 37, train_loss: 0.847300, test loss: 1.238276, bias2: 0.5466517210006714, variance: 0.6916241645812988\n",
      "Train size: [400] hidden size: [316] trial: 38, train_loss: 0.848086, test loss: 1.236932, bias2: 0.5468112826347351, variance: 0.6901212334632874\n",
      "Train size: [400] hidden size: [316] trial: 39, train_loss: 0.845388, test loss: 1.236061, bias2: 0.5465856790542603, variance: 0.6894757747650146\n",
      "Train size: [400] hidden size: [316] trial: 40, train_loss: 0.846895, test loss: 1.237689, bias2: 0.5469228029251099, variance: 0.6907662153244019\n",
      "Train size: [400] hidden size: [316] trial: 41, train_loss: 0.846754, test loss: 1.237615, bias2: 0.5457302927970886, variance: 0.6918842196464539\n",
      "Train size: [400] hidden size: [316] trial: 42, train_loss: 0.846936, test loss: 1.237080, bias2: 0.5470355749130249, variance: 0.6900447607040405\n",
      "Train size: [400] hidden size: [316] trial: 43, train_loss: 0.847480, test loss: 1.236146, bias2: 0.5479980111122131, variance: 0.6881478428840637\n",
      "Train size: [400] hidden size: [316] trial: 44, train_loss: 0.847166, test loss: 1.236243, bias2: 0.5506675243377686, variance: 0.6855759620666504\n",
      "Train size: [400] hidden size: [316] trial: 45, train_loss: 0.845519, test loss: 1.233870, bias2: 0.5491177439689636, variance: 0.6847525238990784\n",
      "Train size: [400] hidden size: [316] trial: 46, train_loss: 0.844384, test loss: 1.231641, bias2: 0.5485661029815674, variance: 0.6830750703811646\n",
      "Train size: [400] hidden size: [316] trial: 47, train_loss: 0.845068, test loss: 1.230720, bias2: 0.5480479001998901, variance: 0.6826719045639038\n",
      "Train size: [400] hidden size: [316] trial: 48, train_loss: 0.843581, test loss: 1.230836, bias2: 0.5484660863876343, variance: 0.6823699474334717\n",
      "Train size: [400] hidden size: [316] trial: 49, train_loss: 0.842668, test loss: 1.230584, bias2: 0.5480414032936096, variance: 0.6825421452522278\n",
      "##################################################\n",
      "Train size: [400] hidden size: [364] trial: 0, train_loss: 0.868194, test loss: 1.190773, bias2: 1.1907734870910645, variance: 7.39584127273929e-09\n",
      "Train size: [400] hidden size: [364] trial: 1, train_loss: 0.886011, test loss: 1.261182, bias2: 0.8388651609420776, variance: 0.42231711745262146\n",
      "Train size: [400] hidden size: [364] trial: 2, train_loss: 0.825625, test loss: 1.303495, bias2: 0.7089431881904602, variance: 0.5945515036582947\n",
      "Train size: [400] hidden size: [364] trial: 3, train_loss: 0.802812, test loss: 1.308876, bias2: 0.6544826626777649, variance: 0.65439373254776\n",
      "Train size: [400] hidden size: [364] trial: 4, train_loss: 0.791885, test loss: 1.318712, bias2: 0.6241379380226135, variance: 0.6945740580558777\n",
      "Train size: [400] hidden size: [364] trial: 5, train_loss: 0.795816, test loss: 1.334345, bias2: 0.6019843220710754, variance: 0.7323608994483948\n",
      "Train size: [400] hidden size: [364] trial: 6, train_loss: 0.786728, test loss: 1.327156, bias2: 0.584891140460968, variance: 0.7422648072242737\n",
      "Train size: [400] hidden size: [364] trial: 7, train_loss: 0.765460, test loss: 1.316239, bias2: 0.5792800188064575, variance: 0.7369593381881714\n",
      "Train size: [400] hidden size: [364] trial: 8, train_loss: 0.756236, test loss: 1.319455, bias2: 0.5662174224853516, variance: 0.7532377243041992\n",
      "Train size: [400] hidden size: [364] trial: 9, train_loss: 0.746644, test loss: 1.313978, bias2: 0.562698483467102, variance: 0.7512794733047485\n",
      "Train size: [400] hidden size: [364] trial: 10, train_loss: 0.743034, test loss: 1.318301, bias2: 0.5620428919792175, variance: 0.7562584280967712\n",
      "Train size: [400] hidden size: [364] trial: 11, train_loss: 0.747811, test loss: 1.304091, bias2: 0.5493119955062866, variance: 0.7547791004180908\n",
      "Train size: [400] hidden size: [364] trial: 12, train_loss: 0.740706, test loss: 1.291933, bias2: 0.5444464087486267, variance: 0.7474861741065979\n",
      "Train size: [400] hidden size: [364] trial: 13, train_loss: 0.733690, test loss: 1.313694, bias2: 0.5404881238937378, variance: 0.7732058763504028\n",
      "Train size: [400] hidden size: [364] trial: 14, train_loss: 0.726784, test loss: 1.313584, bias2: 0.5420106649398804, variance: 0.7715734243392944\n",
      "Train size: [400] hidden size: [364] trial: 15, train_loss: 0.722697, test loss: 1.319526, bias2: 0.5454925298690796, variance: 0.7740330696105957\n",
      "Train size: [400] hidden size: [364] trial: 16, train_loss: 0.728546, test loss: 1.320701, bias2: 0.542869508266449, variance: 0.7778316140174866\n",
      "Train size: [400] hidden size: [364] trial: 17, train_loss: 0.725292, test loss: 1.323975, bias2: 0.5380973219871521, variance: 0.7858772873878479\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [364] trial: 18, train_loss: 0.723692, test loss: 1.322782, bias2: 0.537907600402832, variance: 0.7848740816116333\n",
      "Train size: [400] hidden size: [364] trial: 19, train_loss: 0.724244, test loss: 1.318216, bias2: 0.5335890650749207, variance: 0.7846272587776184\n",
      "Train size: [400] hidden size: [364] trial: 20, train_loss: 0.724757, test loss: 1.317091, bias2: 0.5343388319015503, variance: 0.782752275466919\n",
      "Train size: [400] hidden size: [364] trial: 21, train_loss: 0.724179, test loss: 1.313467, bias2: 0.5344153046607971, variance: 0.7790517210960388\n",
      "Train size: [400] hidden size: [364] trial: 22, train_loss: 0.724226, test loss: 1.326206, bias2: 0.538685142993927, variance: 0.7875208258628845\n",
      "Train size: [400] hidden size: [364] trial: 23, train_loss: 0.724157, test loss: 1.326212, bias2: 0.5388895869255066, variance: 0.7873223423957825\n",
      "Train size: [400] hidden size: [364] trial: 24, train_loss: 0.720373, test loss: 1.325712, bias2: 0.5362161993980408, variance: 0.7894962430000305\n",
      "Train size: [400] hidden size: [364] trial: 25, train_loss: 0.724960, test loss: 1.326449, bias2: 0.5355886220932007, variance: 0.7908605337142944\n",
      "Train size: [400] hidden size: [364] trial: 26, train_loss: 0.724176, test loss: 1.331445, bias2: 0.5346627235412598, variance: 0.7967818975448608\n",
      "Train size: [400] hidden size: [364] trial: 27, train_loss: 0.719842, test loss: 1.332801, bias2: 0.5352016091346741, variance: 0.7975996136665344\n",
      "Train size: [400] hidden size: [364] trial: 28, train_loss: 0.719625, test loss: 1.329952, bias2: 0.5350243449211121, variance: 0.7949277758598328\n",
      "Train size: [400] hidden size: [364] trial: 29, train_loss: 0.718249, test loss: 1.326077, bias2: 0.5352776646614075, variance: 0.790799081325531\n",
      "Train size: [400] hidden size: [364] trial: 30, train_loss: 0.717142, test loss: 1.323049, bias2: 0.5331853032112122, variance: 0.7898632884025574\n",
      "Train size: [400] hidden size: [364] trial: 31, train_loss: 0.717469, test loss: 1.325459, bias2: 0.5341871380805969, variance: 0.791271984577179\n",
      "Train size: [400] hidden size: [364] trial: 32, train_loss: 0.720639, test loss: 1.321403, bias2: 0.5311009287834167, variance: 0.7903019785881042\n",
      "Train size: [400] hidden size: [364] trial: 33, train_loss: 0.721409, test loss: 1.319748, bias2: 0.5265824794769287, variance: 0.7931654453277588\n",
      "Train size: [400] hidden size: [364] trial: 34, train_loss: 0.723852, test loss: 1.316734, bias2: 0.5249254107475281, variance: 0.7918086647987366\n",
      "Train size: [400] hidden size: [364] trial: 35, train_loss: 0.725308, test loss: 1.315826, bias2: 0.5248356461524963, variance: 0.7909905314445496\n",
      "Train size: [400] hidden size: [364] trial: 36, train_loss: 0.724018, test loss: 1.315427, bias2: 0.5248159766197205, variance: 0.7906108498573303\n",
      "Train size: [400] hidden size: [364] trial: 37, train_loss: 0.724212, test loss: 1.314225, bias2: 0.5222214460372925, variance: 0.7920036315917969\n",
      "Train size: [400] hidden size: [364] trial: 38, train_loss: 0.721422, test loss: 1.313403, bias2: 0.5212307572364807, variance: 0.7921721339225769\n",
      "Train size: [400] hidden size: [364] trial: 39, train_loss: 0.721032, test loss: 1.312334, bias2: 0.5238410830497742, variance: 0.7884933352470398\n",
      "Train size: [400] hidden size: [364] trial: 40, train_loss: 0.721860, test loss: 1.312224, bias2: 0.5241568088531494, variance: 0.7880673408508301\n",
      "Train size: [400] hidden size: [364] trial: 41, train_loss: 0.721127, test loss: 1.313345, bias2: 0.5261124968528748, variance: 0.7872328162193298\n",
      "Train size: [400] hidden size: [364] trial: 42, train_loss: 0.718220, test loss: 1.313997, bias2: 0.5262282490730286, variance: 0.7877684235572815\n",
      "Train size: [400] hidden size: [364] trial: 43, train_loss: 0.719045, test loss: 1.313394, bias2: 0.526212751865387, variance: 0.7871808409690857\n",
      "Train size: [400] hidden size: [364] trial: 44, train_loss: 0.719574, test loss: 1.311171, bias2: 0.5241640210151672, variance: 0.7870072722434998\n",
      "Train size: [400] hidden size: [364] trial: 45, train_loss: 0.717688, test loss: 1.311428, bias2: 0.5220350623130798, variance: 0.7893931269645691\n",
      "Train size: [400] hidden size: [364] trial: 46, train_loss: 0.719045, test loss: 1.314041, bias2: 0.5196179747581482, variance: 0.7944226861000061\n",
      "Train size: [400] hidden size: [364] trial: 47, train_loss: 0.720220, test loss: 1.314675, bias2: 0.5164719223976135, variance: 0.7982032895088196\n",
      "Train size: [400] hidden size: [364] trial: 48, train_loss: 0.718881, test loss: 1.315403, bias2: 0.5176467895507812, variance: 0.7977563142776489\n",
      "Train size: [400] hidden size: [364] trial: 49, train_loss: 0.720816, test loss: 1.319796, bias2: 0.5194249153137207, variance: 0.8003712892532349\n",
      "##################################################\n",
      "Train size: [400] hidden size: [419] trial: 0, train_loss: 0.510385, test loss: 1.509890, bias2: 1.5098903179168701, variance: 7.785096123313906e-09\n",
      "Train size: [400] hidden size: [419] trial: 1, train_loss: 0.531180, test loss: 1.493060, bias2: 1.0222954750061035, variance: 0.4707648456096649\n",
      "Train size: [400] hidden size: [419] trial: 2, train_loss: 0.534794, test loss: 1.472880, bias2: 0.8207864761352539, variance: 0.6520936489105225\n",
      "Train size: [400] hidden size: [419] trial: 3, train_loss: 0.563573, test loss: 1.432031, bias2: 0.6961654424667358, variance: 0.7358652353286743\n",
      "Train size: [400] hidden size: [419] trial: 4, train_loss: 0.566219, test loss: 1.399830, bias2: 0.6509482860565186, variance: 0.7488821744918823\n",
      "Train size: [400] hidden size: [419] trial: 5, train_loss: 0.572142, test loss: 1.423318, bias2: 0.6402193903923035, variance: 0.7830988764762878\n",
      "Train size: [400] hidden size: [419] trial: 6, train_loss: 0.574559, test loss: 1.430148, bias2: 0.6247796416282654, variance: 0.8053686022758484\n",
      "Train size: [400] hidden size: [419] trial: 7, train_loss: 0.573996, test loss: 1.428533, bias2: 0.5916462540626526, variance: 0.8368867039680481\n",
      "Train size: [400] hidden size: [419] trial: 8, train_loss: 0.571889, test loss: 1.405008, bias2: 0.5667872428894043, variance: 0.8382208347320557\n",
      "Train size: [400] hidden size: [419] trial: 9, train_loss: 0.569135, test loss: 1.404348, bias2: 0.5531638860702515, variance: 0.851184606552124\n",
      "Train size: [400] hidden size: [419] trial: 10, train_loss: 0.575948, test loss: 1.417647, bias2: 0.5340442061424255, variance: 0.8836029171943665\n",
      "Train size: [400] hidden size: [419] trial: 11, train_loss: 0.579611, test loss: 1.430850, bias2: 0.5189075469970703, variance: 0.9119421243667603\n",
      "Train size: [400] hidden size: [419] trial: 12, train_loss: 0.588378, test loss: 1.422637, bias2: 0.5102708339691162, variance: 0.912366509437561\n",
      "Train size: [400] hidden size: [419] trial: 13, train_loss: 0.587338, test loss: 1.414034, bias2: 0.5012109875679016, variance: 0.9128227829933167\n",
      "Train size: [400] hidden size: [419] trial: 14, train_loss: 0.592828, test loss: 1.414617, bias2: 0.49929237365722656, variance: 0.9153244495391846\n",
      "Train size: [400] hidden size: [419] trial: 15, train_loss: 0.596341, test loss: 1.405813, bias2: 0.4956458806991577, variance: 0.9101673364639282\n",
      "Train size: [400] hidden size: [419] trial: 16, train_loss: 0.597335, test loss: 1.417013, bias2: 0.4966772794723511, variance: 0.9203358888626099\n",
      "Train size: [400] hidden size: [419] trial: 17, train_loss: 0.599632, test loss: 1.432624, bias2: 0.4983149766921997, variance: 0.9343087673187256\n",
      "Train size: [400] hidden size: [419] trial: 18, train_loss: 0.606127, test loss: 1.434954, bias2: 0.4964052438735962, variance: 0.9385491609573364\n",
      "Train size: [400] hidden size: [419] trial: 19, train_loss: 0.606161, test loss: 1.431064, bias2: 0.4941083788871765, variance: 0.9369556307792664\n",
      "Train size: [400] hidden size: [419] trial: 20, train_loss: 0.602344, test loss: 1.436004, bias2: 0.48661887645721436, variance: 0.949385404586792\n",
      "Train size: [400] hidden size: [419] trial: 21, train_loss: 0.601860, test loss: 1.434505, bias2: 0.4810771346092224, variance: 0.9534273743629456\n",
      "Train size: [400] hidden size: [419] trial: 22, train_loss: 0.599587, test loss: 1.434016, bias2: 0.4794456958770752, variance: 0.9545705318450928\n",
      "Train size: [400] hidden size: [419] trial: 23, train_loss: 0.598934, test loss: 1.433855, bias2: 0.47818487882614136, variance: 0.9556704163551331\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [419] trial: 24, train_loss: 0.598541, test loss: 1.441333, bias2: 0.4779983162879944, variance: 0.9633345007896423\n",
      "Train size: [400] hidden size: [419] trial: 25, train_loss: 0.601432, test loss: 1.442756, bias2: 0.4750749468803406, variance: 0.967681348323822\n",
      "Train size: [400] hidden size: [419] trial: 26, train_loss: 0.603709, test loss: 1.441857, bias2: 0.4752945899963379, variance: 0.9665621519088745\n",
      "Train size: [400] hidden size: [419] trial: 27, train_loss: 0.604565, test loss: 1.440031, bias2: 0.47054582834243774, variance: 0.9694849848747253\n",
      "Train size: [400] hidden size: [419] trial: 28, train_loss: 0.608035, test loss: 1.438052, bias2: 0.4689972400665283, variance: 0.9690549373626709\n",
      "Train size: [400] hidden size: [419] trial: 29, train_loss: 0.605982, test loss: 1.433640, bias2: 0.4694574475288391, variance: 0.9641829133033752\n",
      "Train size: [400] hidden size: [419] trial: 30, train_loss: 0.605896, test loss: 1.434108, bias2: 0.46639662981033325, variance: 0.9677109122276306\n",
      "Train size: [400] hidden size: [419] trial: 31, train_loss: 0.604568, test loss: 1.436004, bias2: 0.46790266036987305, variance: 0.9681016206741333\n",
      "Train size: [400] hidden size: [419] trial: 32, train_loss: 0.604015, test loss: 1.436983, bias2: 0.467708945274353, variance: 0.9692740440368652\n",
      "Train size: [400] hidden size: [419] trial: 33, train_loss: 0.604583, test loss: 1.435921, bias2: 0.46660691499710083, variance: 0.96931391954422\n",
      "Train size: [400] hidden size: [419] trial: 34, train_loss: 0.604214, test loss: 1.433916, bias2: 0.4638060927391052, variance: 0.9701096415519714\n",
      "Train size: [400] hidden size: [419] trial: 35, train_loss: 0.604269, test loss: 1.436515, bias2: 0.4632098078727722, variance: 0.9733056426048279\n",
      "Train size: [400] hidden size: [419] trial: 36, train_loss: 0.604777, test loss: 1.433200, bias2: 0.4625115394592285, variance: 0.970687985420227\n",
      "Train size: [400] hidden size: [419] trial: 37, train_loss: 0.602404, test loss: 1.433271, bias2: 0.46168285608291626, variance: 0.9715879559516907\n",
      "Train size: [400] hidden size: [419] trial: 38, train_loss: 0.602941, test loss: 1.435466, bias2: 0.4605485796928406, variance: 0.9749175906181335\n",
      "Train size: [400] hidden size: [419] trial: 39, train_loss: 0.604293, test loss: 1.436332, bias2: 0.4598691463470459, variance: 0.9764629602432251\n",
      "Train size: [400] hidden size: [419] trial: 40, train_loss: 0.605524, test loss: 1.435090, bias2: 0.4612664580345154, variance: 0.9738233685493469\n",
      "Train size: [400] hidden size: [419] trial: 41, train_loss: 0.603813, test loss: 1.433981, bias2: 0.45912134647369385, variance: 0.9748592376708984\n",
      "Train size: [400] hidden size: [419] trial: 42, train_loss: 0.604933, test loss: 1.434166, bias2: 0.45849597454071045, variance: 0.975670337677002\n",
      "Train size: [400] hidden size: [419] trial: 43, train_loss: 0.604317, test loss: 1.434908, bias2: 0.45943427085876465, variance: 0.9754734039306641\n",
      "Train size: [400] hidden size: [419] trial: 44, train_loss: 0.602717, test loss: 1.436159, bias2: 0.45855265855789185, variance: 0.9776065945625305\n",
      "Train size: [400] hidden size: [419] trial: 45, train_loss: 0.601434, test loss: 1.438618, bias2: 0.45853346586227417, variance: 0.9800844788551331\n",
      "Train size: [400] hidden size: [419] trial: 46, train_loss: 0.600319, test loss: 1.439130, bias2: 0.4577966332435608, variance: 0.9813337922096252\n",
      "Train size: [400] hidden size: [419] trial: 47, train_loss: 0.600449, test loss: 1.440102, bias2: 0.4593963027000427, variance: 0.9807055592536926\n",
      "Train size: [400] hidden size: [419] trial: 48, train_loss: 0.601827, test loss: 1.439006, bias2: 0.45647621154785156, variance: 0.9825301170349121\n",
      "Train size: [400] hidden size: [419] trial: 49, train_loss: 0.603378, test loss: 1.442477, bias2: 0.4567088484764099, variance: 0.9857680201530457\n",
      "##################################################\n",
      "Train size: [400] hidden size: [483] trial: 0, train_loss: 0.482638, test loss: 1.710053, bias2: 1.7100526094436646, variance: 0.0\n",
      "Train size: [400] hidden size: [483] trial: 1, train_loss: 0.455905, test loss: 1.545781, bias2: 0.9357711672782898, variance: 0.6100097298622131\n",
      "Train size: [400] hidden size: [483] trial: 2, train_loss: 0.439268, test loss: 1.557571, bias2: 0.7299998998641968, variance: 0.8275711536407471\n",
      "Train size: [400] hidden size: [483] trial: 3, train_loss: 0.459828, test loss: 1.594805, bias2: 0.6375365257263184, variance: 0.9572685956954956\n",
      "Train size: [400] hidden size: [483] trial: 4, train_loss: 0.457579, test loss: 1.640418, bias2: 0.5990337133407593, variance: 1.0413843393325806\n",
      "Train size: [400] hidden size: [483] trial: 5, train_loss: 0.450843, test loss: 1.598749, bias2: 0.5573103427886963, variance: 1.0414386987686157\n",
      "Train size: [400] hidden size: [483] trial: 6, train_loss: 0.453771, test loss: 1.577542, bias2: 0.5248403549194336, variance: 1.0527020692825317\n",
      "Train size: [400] hidden size: [483] trial: 7, train_loss: 0.464114, test loss: 1.585004, bias2: 0.5140362977981567, variance: 1.0709675550460815\n",
      "Train size: [400] hidden size: [483] trial: 8, train_loss: 0.468518, test loss: 1.575822, bias2: 0.5018428564071655, variance: 1.0739786624908447\n",
      "Train size: [400] hidden size: [483] trial: 9, train_loss: 0.458182, test loss: 1.568620, bias2: 0.49394237995147705, variance: 1.0746774673461914\n",
      "Train size: [400] hidden size: [483] trial: 10, train_loss: 0.457192, test loss: 1.558542, bias2: 0.48052942752838135, variance: 1.078012466430664\n",
      "Train size: [400] hidden size: [483] trial: 11, train_loss: 0.456191, test loss: 1.571222, bias2: 0.47900390625, variance: 1.0922185182571411\n",
      "Train size: [400] hidden size: [483] trial: 12, train_loss: 0.453301, test loss: 1.567945, bias2: 0.4750324487686157, variance: 1.0929124355316162\n",
      "Train size: [400] hidden size: [483] trial: 13, train_loss: 0.451163, test loss: 1.562188, bias2: 0.467714786529541, variance: 1.0944737195968628\n",
      "Train size: [400] hidden size: [483] trial: 14, train_loss: 0.449477, test loss: 1.581475, bias2: 0.4647578001022339, variance: 1.1167173385620117\n",
      "Train size: [400] hidden size: [483] trial: 15, train_loss: 0.448570, test loss: 1.571448, bias2: 0.46352601051330566, variance: 1.1079223155975342\n",
      "Train size: [400] hidden size: [483] trial: 16, train_loss: 0.456509, test loss: 1.577665, bias2: 0.458345890045166, variance: 1.1193193197250366\n",
      "Train size: [400] hidden size: [483] trial: 17, train_loss: 0.456320, test loss: 1.576663, bias2: 0.45671045780181885, variance: 1.119952917098999\n",
      "Train size: [400] hidden size: [483] trial: 18, train_loss: 0.454755, test loss: 1.573339, bias2: 0.4529188871383667, variance: 1.1204203367233276\n",
      "Train size: [400] hidden size: [483] trial: 19, train_loss: 0.458931, test loss: 1.579409, bias2: 0.44688236713409424, variance: 1.1325271129608154\n",
      "Train size: [400] hidden size: [483] trial: 20, train_loss: 0.459784, test loss: 1.576090, bias2: 0.44726669788360596, variance: 1.128823161125183\n",
      "Train size: [400] hidden size: [483] trial: 21, train_loss: 0.461429, test loss: 1.584432, bias2: 0.4448741674423218, variance: 1.1395574808120728\n",
      "Train size: [400] hidden size: [483] trial: 22, train_loss: 0.459642, test loss: 1.576430, bias2: 0.4429246187210083, variance: 1.1335052251815796\n",
      "Train size: [400] hidden size: [483] trial: 23, train_loss: 0.459981, test loss: 1.574837, bias2: 0.43512964248657227, variance: 1.1397074460983276\n",
      "Train size: [400] hidden size: [483] trial: 24, train_loss: 0.461918, test loss: 1.574804, bias2: 0.4339609146118164, variance: 1.140843391418457\n",
      "Train size: [400] hidden size: [483] trial: 25, train_loss: 0.462255, test loss: 1.572969, bias2: 0.43104875087738037, variance: 1.1419204473495483\n",
      "Train size: [400] hidden size: [483] trial: 26, train_loss: 0.463044, test loss: 1.572762, bias2: 0.4311262369155884, variance: 1.1416358947753906\n",
      "Train size: [400] hidden size: [483] trial: 27, train_loss: 0.462039, test loss: 1.570962, bias2: 0.42581331729888916, variance: 1.1451482772827148\n",
      "Train size: [400] hidden size: [483] trial: 28, train_loss: 0.462124, test loss: 1.566221, bias2: 0.42235350608825684, variance: 1.1438676118850708\n",
      "Train size: [400] hidden size: [483] trial: 29, train_loss: 0.466132, test loss: 1.566285, bias2: 0.4206368923187256, variance: 1.1456483602523804\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [483] trial: 30, train_loss: 0.465195, test loss: 1.566282, bias2: 0.42022716999053955, variance: 1.1460545063018799\n",
      "Train size: [400] hidden size: [483] trial: 31, train_loss: 0.466451, test loss: 1.568278, bias2: 0.4191465377807617, variance: 1.1491318941116333\n",
      "Train size: [400] hidden size: [483] trial: 32, train_loss: 0.465424, test loss: 1.572896, bias2: 0.41744256019592285, variance: 1.1554536819458008\n",
      "Train size: [400] hidden size: [483] trial: 33, train_loss: 0.467910, test loss: 1.575166, bias2: 0.41697144508361816, variance: 1.1581947803497314\n",
      "Train size: [400] hidden size: [483] trial: 34, train_loss: 0.466100, test loss: 1.581789, bias2: 0.416792631149292, variance: 1.1649962663650513\n",
      "Train size: [400] hidden size: [483] trial: 35, train_loss: 0.467599, test loss: 1.583843, bias2: 0.4180516004562378, variance: 1.165791392326355\n",
      "Train size: [400] hidden size: [483] trial: 36, train_loss: 0.470586, test loss: 1.587617, bias2: 0.4169422388076782, variance: 1.1706743240356445\n",
      "Train size: [400] hidden size: [483] trial: 37, train_loss: 0.469265, test loss: 1.589131, bias2: 0.4181724786758423, variance: 1.170958161354065\n",
      "Train size: [400] hidden size: [483] trial: 38, train_loss: 0.468769, test loss: 1.591188, bias2: 0.4193507432937622, variance: 1.1718368530273438\n",
      "Train size: [400] hidden size: [483] trial: 39, train_loss: 0.467329, test loss: 1.586300, bias2: 0.41705989837646484, variance: 1.1692399978637695\n",
      "Train size: [400] hidden size: [483] trial: 40, train_loss: 0.467262, test loss: 1.585261, bias2: 0.4164007902145386, variance: 1.1688601970672607\n",
      "Train size: [400] hidden size: [483] trial: 41, train_loss: 0.466780, test loss: 1.583299, bias2: 0.4154174327850342, variance: 1.1678820848464966\n",
      "Train size: [400] hidden size: [483] trial: 42, train_loss: 0.467050, test loss: 1.583650, bias2: 0.4133816957473755, variance: 1.170267939567566\n",
      "Train size: [400] hidden size: [483] trial: 43, train_loss: 0.466642, test loss: 1.584304, bias2: 0.41094934940338135, variance: 1.173354983329773\n",
      "Train size: [400] hidden size: [483] trial: 44, train_loss: 0.465611, test loss: 1.582726, bias2: 0.40969550609588623, variance: 1.1730303764343262\n",
      "Train size: [400] hidden size: [483] trial: 45, train_loss: 0.465064, test loss: 1.581562, bias2: 0.4102039337158203, variance: 1.1713579893112183\n",
      "Train size: [400] hidden size: [483] trial: 46, train_loss: 0.465634, test loss: 1.578063, bias2: 0.4068024158477783, variance: 1.1712605953216553\n",
      "Train size: [400] hidden size: [483] trial: 47, train_loss: 0.464944, test loss: 1.579452, bias2: 0.40572547912597656, variance: 1.1737267971038818\n",
      "Train size: [400] hidden size: [483] trial: 48, train_loss: 0.465064, test loss: 1.583399, bias2: 0.40719521045684814, variance: 1.1762042045593262\n",
      "Train size: [400] hidden size: [483] trial: 49, train_loss: 0.466085, test loss: 1.580502, bias2: 0.4070051908493042, variance: 1.173497200012207\n",
      "##################################################\n",
      "Train size: [400] hidden size: [556] trial: 0, train_loss: 0.370297, test loss: 1.756473, bias2: 1.7564729452133179, variance: -3.1140383605077204e-09\n",
      "Train size: [400] hidden size: [556] trial: 1, train_loss: 0.368943, test loss: 1.855496, bias2: 1.1203436851501465, variance: 0.7351522445678711\n",
      "Train size: [400] hidden size: [556] trial: 2, train_loss: 0.343430, test loss: 1.760057, bias2: 0.8278258442878723, variance: 0.9322306513786316\n",
      "Train size: [400] hidden size: [556] trial: 3, train_loss: 0.338957, test loss: 1.798573, bias2: 0.6805107593536377, variance: 1.1180620193481445\n",
      "Train size: [400] hidden size: [556] trial: 4, train_loss: 0.341067, test loss: 1.812371, bias2: 0.5969533920288086, variance: 1.2154181003570557\n",
      "Train size: [400] hidden size: [556] trial: 5, train_loss: 0.356904, test loss: 1.823140, bias2: 0.5551321506500244, variance: 1.2680083513259888\n",
      "Train size: [400] hidden size: [556] trial: 6, train_loss: 0.362450, test loss: 1.810485, bias2: 0.5209563970565796, variance: 1.2895289659500122\n",
      "Train size: [400] hidden size: [556] trial: 7, train_loss: 0.369633, test loss: 1.827105, bias2: 0.5029288530349731, variance: 1.3241760730743408\n",
      "Train size: [400] hidden size: [556] trial: 8, train_loss: 0.363452, test loss: 1.810248, bias2: 0.48008501529693604, variance: 1.3301630020141602\n",
      "Train size: [400] hidden size: [556] trial: 9, train_loss: 0.361270, test loss: 1.788771, bias2: 0.4593600034713745, variance: 1.3294105529785156\n",
      "Train size: [400] hidden size: [556] trial: 10, train_loss: 0.357676, test loss: 1.787716, bias2: 0.4536839723587036, variance: 1.3340319395065308\n",
      "Train size: [400] hidden size: [556] trial: 11, train_loss: 0.352309, test loss: 1.794634, bias2: 0.4472494125366211, variance: 1.3473842144012451\n",
      "Train size: [400] hidden size: [556] trial: 12, train_loss: 0.355251, test loss: 1.790234, bias2: 0.4394245147705078, variance: 1.3508094549179077\n",
      "Train size: [400] hidden size: [556] trial: 13, train_loss: 0.357094, test loss: 1.788598, bias2: 0.4351309537887573, variance: 1.3534667491912842\n",
      "Train size: [400] hidden size: [556] trial: 14, train_loss: 0.356110, test loss: 1.777400, bias2: 0.42327797412872314, variance: 1.3541224002838135\n",
      "Train size: [400] hidden size: [556] trial: 15, train_loss: 0.353830, test loss: 1.777560, bias2: 0.41583406925201416, variance: 1.3617255687713623\n",
      "Train size: [400] hidden size: [556] trial: 16, train_loss: 0.351533, test loss: 1.776128, bias2: 0.41137921810150146, variance: 1.3647483587265015\n",
      "Train size: [400] hidden size: [556] trial: 17, train_loss: 0.350715, test loss: 1.778534, bias2: 0.4076763391494751, variance: 1.370857834815979\n",
      "Train size: [400] hidden size: [556] trial: 18, train_loss: 0.350810, test loss: 1.782347, bias2: 0.40411460399627686, variance: 1.3782328367233276\n",
      "Train size: [400] hidden size: [556] trial: 19, train_loss: 0.348282, test loss: 1.775897, bias2: 0.39922237396240234, variance: 1.3766741752624512\n",
      "Train size: [400] hidden size: [556] trial: 20, train_loss: 0.348406, test loss: 1.795567, bias2: 0.4012702703475952, variance: 1.3942970037460327\n",
      "Train size: [400] hidden size: [556] trial: 21, train_loss: 0.348623, test loss: 1.785268, bias2: 0.3984801769256592, variance: 1.386788010597229\n",
      "Train size: [400] hidden size: [556] trial: 22, train_loss: 0.351294, test loss: 1.793823, bias2: 0.3991546630859375, variance: 1.3946682214736938\n",
      "Train size: [400] hidden size: [556] trial: 23, train_loss: 0.352177, test loss: 1.794665, bias2: 0.39516687393188477, variance: 1.3994985818862915\n",
      "Train size: [400] hidden size: [556] trial: 24, train_loss: 0.353581, test loss: 1.792070, bias2: 0.3933316469192505, variance: 1.3987383842468262\n",
      "Train size: [400] hidden size: [556] trial: 25, train_loss: 0.354108, test loss: 1.791429, bias2: 0.38972342014312744, variance: 1.4017055034637451\n",
      "Train size: [400] hidden size: [556] trial: 26, train_loss: 0.356695, test loss: 1.792282, bias2: 0.38540351390838623, variance: 1.4068783521652222\n",
      "Train size: [400] hidden size: [556] trial: 27, train_loss: 0.358284, test loss: 1.799334, bias2: 0.38159799575805664, variance: 1.4177360534667969\n",
      "Train size: [400] hidden size: [556] trial: 28, train_loss: 0.358355, test loss: 1.797380, bias2: 0.3812577724456787, variance: 1.416122555732727\n",
      "Train size: [400] hidden size: [556] trial: 29, train_loss: 0.357473, test loss: 1.794256, bias2: 0.38019657135009766, variance: 1.4140595197677612\n",
      "Train size: [400] hidden size: [556] trial: 30, train_loss: 0.357322, test loss: 1.789761, bias2: 0.3762916326522827, variance: 1.413469672203064\n",
      "Train size: [400] hidden size: [556] trial: 31, train_loss: 0.356305, test loss: 1.795890, bias2: 0.3715137243270874, variance: 1.424376130104065\n",
      "Train size: [400] hidden size: [556] trial: 32, train_loss: 0.355805, test loss: 1.795027, bias2: 0.37021660804748535, variance: 1.424810528755188\n",
      "Train size: [400] hidden size: [556] trial: 33, train_loss: 0.354097, test loss: 1.795856, bias2: 0.3703383207321167, variance: 1.4255175590515137\n",
      "Train size: [400] hidden size: [556] trial: 34, train_loss: 0.353211, test loss: 1.788301, bias2: 0.36816442012786865, variance: 1.4201360940933228\n",
      "Train size: [400] hidden size: [556] trial: 35, train_loss: 0.353591, test loss: 1.790721, bias2: 0.36663269996643066, variance: 1.424088478088379\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [556] trial: 36, train_loss: 0.354788, test loss: 1.790136, bias2: 0.3648339509963989, variance: 1.4253023862838745\n",
      "Train size: [400] hidden size: [556] trial: 37, train_loss: 0.352924, test loss: 1.782297, bias2: 0.3616828918457031, variance: 1.4206143617630005\n",
      "Train size: [400] hidden size: [556] trial: 38, train_loss: 0.352091, test loss: 1.793373, bias2: 0.3625112771987915, variance: 1.4308621883392334\n",
      "Train size: [400] hidden size: [556] trial: 39, train_loss: 0.352444, test loss: 1.796654, bias2: 0.36406683921813965, variance: 1.4325876235961914\n",
      "Train size: [400] hidden size: [556] trial: 40, train_loss: 0.353019, test loss: 1.798330, bias2: 0.36539316177368164, variance: 1.4329367876052856\n",
      "Train size: [400] hidden size: [556] trial: 41, train_loss: 0.351598, test loss: 1.797110, bias2: 0.3653545379638672, variance: 1.4317550659179688\n",
      "Train size: [400] hidden size: [556] trial: 42, train_loss: 0.352100, test loss: 1.804043, bias2: 0.3664809465408325, variance: 1.4375624656677246\n",
      "Train size: [400] hidden size: [556] trial: 43, train_loss: 0.352333, test loss: 1.800895, bias2: 0.3649423122406006, variance: 1.4359527826309204\n",
      "Train size: [400] hidden size: [556] trial: 44, train_loss: 0.351659, test loss: 1.798452, bias2: 0.363922119140625, variance: 1.4345303773880005\n",
      "Train size: [400] hidden size: [556] trial: 45, train_loss: 0.349631, test loss: 1.796445, bias2: 0.3643028736114502, variance: 1.432141661643982\n",
      "Train size: [400] hidden size: [556] trial: 46, train_loss: 0.349941, test loss: 1.797775, bias2: 0.3623110055923462, variance: 1.4354643821716309\n",
      "Train size: [400] hidden size: [556] trial: 47, train_loss: 0.350531, test loss: 1.798189, bias2: 0.35790741443634033, variance: 1.4402813911437988\n",
      "Train size: [400] hidden size: [556] trial: 48, train_loss: 0.350884, test loss: 1.800517, bias2: 0.35567212104797363, variance: 1.4448453187942505\n",
      "Train size: [400] hidden size: [556] trial: 49, train_loss: 0.350307, test loss: 1.800746, bias2: 0.3574024438858032, variance: 1.443343162536621\n",
      "##################################################\n",
      "Train size: [400] hidden size: [640] trial: 0, train_loss: 0.218197, test loss: 2.142710, bias2: 2.142709732055664, variance: -4.6710577628061856e-09\n",
      "Train size: [400] hidden size: [640] trial: 1, train_loss: 0.201968, test loss: 1.985882, bias2: 1.126495599746704, variance: 0.8593860864639282\n",
      "Train size: [400] hidden size: [640] trial: 2, train_loss: 0.215073, test loss: 1.916194, bias2: 0.8296006917953491, variance: 1.086593747138977\n",
      "Train size: [400] hidden size: [640] trial: 3, train_loss: 0.215383, test loss: 1.871737, bias2: 0.651275634765625, variance: 1.220461130142212\n",
      "Train size: [400] hidden size: [640] trial: 4, train_loss: 0.226642, test loss: 1.899263, bias2: 0.5875158309936523, variance: 1.3117473125457764\n",
      "Train size: [400] hidden size: [640] trial: 5, train_loss: 0.234627, test loss: 1.918928, bias2: 0.5442054271697998, variance: 1.3747230768203735\n",
      "Train size: [400] hidden size: [640] trial: 6, train_loss: 0.238101, test loss: 1.929910, bias2: 0.5118088722229004, variance: 1.41810142993927\n",
      "Train size: [400] hidden size: [640] trial: 7, train_loss: 0.241634, test loss: 1.921910, bias2: 0.4809986352920532, variance: 1.4409115314483643\n",
      "Train size: [400] hidden size: [640] trial: 8, train_loss: 0.235826, test loss: 1.916958, bias2: 0.45140540599823, variance: 1.4655523300170898\n",
      "Train size: [400] hidden size: [640] trial: 9, train_loss: 0.234304, test loss: 1.917053, bias2: 0.4293707609176636, variance: 1.4876821041107178\n",
      "Train size: [400] hidden size: [640] trial: 10, train_loss: 0.231841, test loss: 1.905783, bias2: 0.4097384214401245, variance: 1.4960445165634155\n",
      "Train size: [400] hidden size: [640] trial: 11, train_loss: 0.234665, test loss: 1.918984, bias2: 0.39644503593444824, variance: 1.5225393772125244\n",
      "Train size: [400] hidden size: [640] trial: 12, train_loss: 0.239158, test loss: 1.901720, bias2: 0.38133513927459717, variance: 1.520384430885315\n",
      "Train size: [400] hidden size: [640] trial: 13, train_loss: 0.241615, test loss: 1.900565, bias2: 0.3775831460952759, variance: 1.5229817628860474\n",
      "Train size: [400] hidden size: [640] trial: 14, train_loss: 0.241999, test loss: 1.892049, bias2: 0.35963666439056396, variance: 1.5324124097824097\n",
      "Train size: [400] hidden size: [640] trial: 15, train_loss: 0.242294, test loss: 1.883879, bias2: 0.35757434368133545, variance: 1.526305079460144\n",
      "Train size: [400] hidden size: [640] trial: 16, train_loss: 0.244327, test loss: 1.895887, bias2: 0.34793972969055176, variance: 1.5479469299316406\n",
      "Train size: [400] hidden size: [640] trial: 17, train_loss: 0.242776, test loss: 1.910503, bias2: 0.3484901189804077, variance: 1.5620133876800537\n",
      "Train size: [400] hidden size: [640] trial: 18, train_loss: 0.243222, test loss: 1.907387, bias2: 0.34275877475738525, variance: 1.564627766609192\n",
      "Train size: [400] hidden size: [640] trial: 19, train_loss: 0.242346, test loss: 1.899136, bias2: 0.34302830696105957, variance: 1.5561072826385498\n",
      "Train size: [400] hidden size: [640] trial: 20, train_loss: 0.240178, test loss: 1.888958, bias2: 0.337782621383667, variance: 1.5511751174926758\n",
      "Train size: [400] hidden size: [640] trial: 21, train_loss: 0.241917, test loss: 1.901382, bias2: 0.3362109661102295, variance: 1.5651708841323853\n",
      "Train size: [400] hidden size: [640] trial: 22, train_loss: 0.240731, test loss: 1.898501, bias2: 0.3343777656555176, variance: 1.5641237497329712\n",
      "Train size: [400] hidden size: [640] trial: 23, train_loss: 0.240395, test loss: 1.902386, bias2: 0.3367809057235718, variance: 1.5656052827835083\n",
      "Train size: [400] hidden size: [640] trial: 24, train_loss: 0.239021, test loss: 1.899146, bias2: 0.3331233263015747, variance: 1.5660223960876465\n",
      "Train size: [400] hidden size: [640] trial: 25, train_loss: 0.241207, test loss: 1.898600, bias2: 0.3295034170150757, variance: 1.5690969228744507\n",
      "Train size: [400] hidden size: [640] trial: 26, train_loss: 0.240572, test loss: 1.908853, bias2: 0.3277132511138916, variance: 1.5811399221420288\n",
      "Train size: [400] hidden size: [640] trial: 27, train_loss: 0.239231, test loss: 1.905500, bias2: 0.3231610059738159, variance: 1.582338571548462\n",
      "Train size: [400] hidden size: [640] trial: 28, train_loss: 0.238827, test loss: 1.902535, bias2: 0.31991803646087646, variance: 1.5826166868209839\n",
      "Train size: [400] hidden size: [640] trial: 29, train_loss: 0.238530, test loss: 1.904313, bias2: 0.31881868839263916, variance: 1.5854946374893188\n",
      "Train size: [400] hidden size: [640] trial: 30, train_loss: 0.236741, test loss: 1.901182, bias2: 0.3172980546951294, variance: 1.5838842391967773\n",
      "Train size: [400] hidden size: [640] trial: 31, train_loss: 0.236357, test loss: 1.907244, bias2: 0.3215641975402832, variance: 1.585679292678833\n",
      "Train size: [400] hidden size: [640] trial: 32, train_loss: 0.237821, test loss: 1.909735, bias2: 0.32124412059783936, variance: 1.5884913206100464\n",
      "Train size: [400] hidden size: [640] trial: 33, train_loss: 0.237442, test loss: 1.906360, bias2: 0.3202322721481323, variance: 1.586127758026123\n",
      "Train size: [400] hidden size: [640] trial: 34, train_loss: 0.236785, test loss: 1.905080, bias2: 0.31700026988983154, variance: 1.5880793333053589\n",
      "Train size: [400] hidden size: [640] trial: 35, train_loss: 0.236582, test loss: 1.900636, bias2: 0.31857597827911377, variance: 1.5820599794387817\n",
      "Train size: [400] hidden size: [640] trial: 36, train_loss: 0.235722, test loss: 1.906470, bias2: 0.3194756507873535, variance: 1.5869945287704468\n",
      "Train size: [400] hidden size: [640] trial: 37, train_loss: 0.235882, test loss: 1.908292, bias2: 0.3184562921524048, variance: 1.5898357629776\n",
      "Train size: [400] hidden size: [640] trial: 38, train_loss: 0.236579, test loss: 1.907837, bias2: 0.31783974170684814, variance: 1.5899969339370728\n",
      "Train size: [400] hidden size: [640] trial: 39, train_loss: 0.237037, test loss: 1.906084, bias2: 0.3178819417953491, variance: 1.588201642036438\n",
      "Train size: [400] hidden size: [640] trial: 40, train_loss: 0.237256, test loss: 1.909683, bias2: 0.31777918338775635, variance: 1.5919039249420166\n",
      "Train size: [400] hidden size: [640] trial: 41, train_loss: 0.237749, test loss: 1.914374, bias2: 0.32024645805358887, variance: 1.5941271781921387\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [640] trial: 42, train_loss: 0.238406, test loss: 1.909528, bias2: 0.3181651830673218, variance: 1.5913631916046143\n",
      "Train size: [400] hidden size: [640] trial: 43, train_loss: 0.237894, test loss: 1.909571, bias2: 0.31638455390930176, variance: 1.5931867361068726\n",
      "Train size: [400] hidden size: [640] trial: 44, train_loss: 0.238751, test loss: 1.905996, bias2: 0.31626737117767334, variance: 1.5897284746170044\n",
      "Train size: [400] hidden size: [640] trial: 45, train_loss: 0.238323, test loss: 1.905674, bias2: 0.3157910108566284, variance: 1.5898832082748413\n",
      "Train size: [400] hidden size: [640] trial: 46, train_loss: 0.238664, test loss: 1.903599, bias2: 0.3141913414001465, variance: 1.5894079208374023\n",
      "Train size: [400] hidden size: [640] trial: 47, train_loss: 0.238389, test loss: 1.911625, bias2: 0.3120361566543579, variance: 1.5995885133743286\n",
      "Train size: [400] hidden size: [640] trial: 48, train_loss: 0.237421, test loss: 1.911510, bias2: 0.3114206790924072, variance: 1.6000895500183105\n",
      "Train size: [400] hidden size: [640] trial: 49, train_loss: 0.236809, test loss: 1.913501, bias2: 0.3097195625305176, variance: 1.6037812232971191\n",
      "##################################################\n",
      "Train size: [400] hidden size: [737] trial: 0, train_loss: 0.181866, test loss: 1.901852, bias2: 1.901851773262024, variance: -1.2456153442030882e-08\n",
      "Train size: [400] hidden size: [737] trial: 1, train_loss: 0.177014, test loss: 1.815426, bias2: 1.014920711517334, variance: 0.8005050420761108\n",
      "Train size: [400] hidden size: [737] trial: 2, train_loss: 0.167665, test loss: 1.918671, bias2: 0.7753201723098755, variance: 1.1433510780334473\n",
      "Train size: [400] hidden size: [737] trial: 3, train_loss: 0.166939, test loss: 1.974209, bias2: 0.6649112701416016, variance: 1.309297800064087\n",
      "Train size: [400] hidden size: [737] trial: 4, train_loss: 0.166464, test loss: 1.959012, bias2: 0.5595579147338867, variance: 1.3994542360305786\n",
      "Train size: [400] hidden size: [737] trial: 5, train_loss: 0.161107, test loss: 1.955080, bias2: 0.5023409128189087, variance: 1.452738881111145\n",
      "Train size: [400] hidden size: [737] trial: 6, train_loss: 0.154847, test loss: 1.947084, bias2: 0.46208810806274414, variance: 1.4849961996078491\n",
      "Train size: [400] hidden size: [737] trial: 7, train_loss: 0.155431, test loss: 1.959568, bias2: 0.4435300827026367, variance: 1.5160374641418457\n",
      "Train size: [400] hidden size: [737] trial: 8, train_loss: 0.154429, test loss: 1.944063, bias2: 0.4096022844314575, variance: 1.5344611406326294\n",
      "Train size: [400] hidden size: [737] trial: 9, train_loss: 0.156704, test loss: 1.938206, bias2: 0.390544056892395, variance: 1.547662377357483\n",
      "Train size: [400] hidden size: [737] trial: 10, train_loss: 0.153655, test loss: 1.949084, bias2: 0.37402188777923584, variance: 1.5750620365142822\n",
      "Train size: [400] hidden size: [737] trial: 11, train_loss: 0.151985, test loss: 1.969655, bias2: 0.362418532371521, variance: 1.6072367429733276\n",
      "Train size: [400] hidden size: [737] trial: 12, train_loss: 0.154583, test loss: 1.980685, bias2: 0.3599364757537842, variance: 1.6207486391067505\n",
      "Train size: [400] hidden size: [737] trial: 13, train_loss: 0.152166, test loss: 1.980685, bias2: 0.35493552684783936, variance: 1.6257489919662476\n",
      "Train size: [400] hidden size: [737] trial: 14, train_loss: 0.151681, test loss: 1.964435, bias2: 0.34654200077056885, variance: 1.6178932189941406\n",
      "Train size: [400] hidden size: [737] trial: 15, train_loss: 0.151566, test loss: 1.957692, bias2: 0.34044063091278076, variance: 1.6172510385513306\n",
      "Train size: [400] hidden size: [737] trial: 16, train_loss: 0.150865, test loss: 1.959103, bias2: 0.33166635036468506, variance: 1.6274369955062866\n",
      "Train size: [400] hidden size: [737] trial: 17, train_loss: 0.151997, test loss: 1.962542, bias2: 0.32847046852111816, variance: 1.6340715885162354\n",
      "Train size: [400] hidden size: [737] trial: 18, train_loss: 0.151498, test loss: 1.967595, bias2: 0.3206954002380371, variance: 1.646899938583374\n",
      "Train size: [400] hidden size: [737] trial: 19, train_loss: 0.152562, test loss: 1.958204, bias2: 0.3152278661727905, variance: 1.6429764032363892\n",
      "Train size: [400] hidden size: [737] trial: 20, train_loss: 0.153158, test loss: 1.964236, bias2: 0.30933594703674316, variance: 1.6548998355865479\n",
      "Train size: [400] hidden size: [737] trial: 21, train_loss: 0.153645, test loss: 1.977967, bias2: 0.30482280254364014, variance: 1.6731441020965576\n",
      "Train size: [400] hidden size: [737] trial: 22, train_loss: 0.151983, test loss: 1.976767, bias2: 0.3034665584564209, variance: 1.6733002662658691\n",
      "Train size: [400] hidden size: [737] trial: 23, train_loss: 0.152527, test loss: 1.974144, bias2: 0.30268585681915283, variance: 1.6714576482772827\n",
      "Train size: [400] hidden size: [737] trial: 24, train_loss: 0.153448, test loss: 1.973782, bias2: 0.299896240234375, variance: 1.6738860607147217\n",
      "Train size: [400] hidden size: [737] trial: 25, train_loss: 0.153199, test loss: 1.976389, bias2: 0.2973440885543823, variance: 1.6790447235107422\n",
      "Train size: [400] hidden size: [737] trial: 26, train_loss: 0.152773, test loss: 1.980171, bias2: 0.29833006858825684, variance: 1.681841254234314\n",
      "Train size: [400] hidden size: [737] trial: 27, train_loss: 0.152875, test loss: 1.979153, bias2: 0.2996382713317871, variance: 1.6795145273208618\n",
      "Train size: [400] hidden size: [737] trial: 28, train_loss: 0.151908, test loss: 1.978672, bias2: 0.2977921962738037, variance: 1.6808797121047974\n",
      "Train size: [400] hidden size: [737] trial: 29, train_loss: 0.151057, test loss: 1.973708, bias2: 0.2939363718032837, variance: 1.6797715425491333\n",
      "Train size: [400] hidden size: [737] trial: 30, train_loss: 0.150478, test loss: 1.979416, bias2: 0.29132235050201416, variance: 1.6880933046340942\n",
      "Train size: [400] hidden size: [737] trial: 31, train_loss: 0.151042, test loss: 1.984687, bias2: 0.28885340690612793, variance: 1.6958333253860474\n",
      "Train size: [400] hidden size: [737] trial: 32, train_loss: 0.150213, test loss: 1.983414, bias2: 0.28756844997406006, variance: 1.6958458423614502\n",
      "Train size: [400] hidden size: [737] trial: 33, train_loss: 0.150683, test loss: 1.995061, bias2: 0.28779757022857666, variance: 1.707263708114624\n",
      "Train size: [400] hidden size: [737] trial: 34, train_loss: 0.150815, test loss: 1.995172, bias2: 0.28523433208465576, variance: 1.7099372148513794\n",
      "Train size: [400] hidden size: [737] trial: 35, train_loss: 0.150625, test loss: 1.995320, bias2: 0.2850358486175537, variance: 1.7102843523025513\n",
      "Train size: [400] hidden size: [737] trial: 36, train_loss: 0.150727, test loss: 1.998145, bias2: 0.28453826904296875, variance: 1.7136067152023315\n",
      "Train size: [400] hidden size: [737] trial: 37, train_loss: 0.150138, test loss: 1.994299, bias2: 0.285510778427124, variance: 1.7087886333465576\n",
      "Train size: [400] hidden size: [737] trial: 38, train_loss: 0.149937, test loss: 1.996174, bias2: 0.28568732738494873, variance: 1.7104862928390503\n",
      "Train size: [400] hidden size: [737] trial: 39, train_loss: 0.150854, test loss: 1.998272, bias2: 0.2849252223968506, variance: 1.71334707736969\n",
      "Train size: [400] hidden size: [737] trial: 40, train_loss: 0.151335, test loss: 2.001126, bias2: 0.2823747396469116, variance: 1.7187515497207642\n",
      "Train size: [400] hidden size: [737] trial: 41, train_loss: 0.151060, test loss: 2.001883, bias2: 0.2822352647781372, variance: 1.719647765159607\n",
      "Train size: [400] hidden size: [737] trial: 42, train_loss: 0.150703, test loss: 2.010765, bias2: 0.28280699253082275, variance: 1.72795832157135\n",
      "Train size: [400] hidden size: [737] trial: 43, train_loss: 0.149931, test loss: 2.008394, bias2: 0.2837522029876709, variance: 1.724642038345337\n",
      "Train size: [400] hidden size: [737] trial: 44, train_loss: 0.150372, test loss: 2.012199, bias2: 0.2856099605560303, variance: 1.726588487625122\n",
      "Train size: [400] hidden size: [737] trial: 45, train_loss: 0.150857, test loss: 2.012841, bias2: 0.28439581394195557, variance: 1.7284454107284546\n",
      "Train size: [400] hidden size: [737] trial: 46, train_loss: 0.150893, test loss: 2.010223, bias2: 0.286989688873291, variance: 1.7232329845428467\n",
      "Train size: [400] hidden size: [737] trial: 47, train_loss: 0.150796, test loss: 2.012399, bias2: 0.2859983444213867, variance: 1.7264008522033691\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [737] trial: 48, train_loss: 0.152186, test loss: 2.020522, bias2: 0.2873225212097168, variance: 1.7331995964050293\n",
      "Train size: [400] hidden size: [737] trial: 49, train_loss: 0.152072, test loss: 2.021099, bias2: 0.28644728660583496, variance: 1.7346513271331787\n",
      "##################################################\n",
      "Train size: [400] hidden size: [848] trial: 0, train_loss: 0.096331, test loss: 2.003871, bias2: 2.003871440887451, variance: -2.8026345688658694e-08\n",
      "Train size: [400] hidden size: [848] trial: 1, train_loss: 0.083958, test loss: 1.781118, bias2: 0.9874386787414551, variance: 0.7936795949935913\n",
      "Train size: [400] hidden size: [848] trial: 2, train_loss: 0.082497, test loss: 1.813183, bias2: 0.739728569984436, variance: 1.0734540224075317\n",
      "Train size: [400] hidden size: [848] trial: 3, train_loss: 0.085642, test loss: 1.836366, bias2: 0.6338683366775513, variance: 1.2024974822998047\n",
      "Train size: [400] hidden size: [848] trial: 4, train_loss: 0.084644, test loss: 1.852845, bias2: 0.5516868829727173, variance: 1.3011583089828491\n",
      "Train size: [400] hidden size: [848] trial: 5, train_loss: 0.086546, test loss: 1.903189, bias2: 0.5138853788375854, variance: 1.3893035650253296\n",
      "Train size: [400] hidden size: [848] trial: 6, train_loss: 0.086805, test loss: 1.941543, bias2: 0.48186683654785156, variance: 1.4596760272979736\n",
      "Train size: [400] hidden size: [848] trial: 7, train_loss: 0.085539, test loss: 1.932807, bias2: 0.4584505558013916, variance: 1.4743565320968628\n",
      "Train size: [400] hidden size: [848] trial: 8, train_loss: 0.087247, test loss: 1.959823, bias2: 0.4333212375640869, variance: 1.5265014171600342\n",
      "Train size: [400] hidden size: [848] trial: 9, train_loss: 0.087215, test loss: 1.970832, bias2: 0.4155625104904175, variance: 1.5552698373794556\n",
      "Train size: [400] hidden size: [848] trial: 10, train_loss: 0.087394, test loss: 1.964468, bias2: 0.40907227993011475, variance: 1.5553957223892212\n",
      "Train size: [400] hidden size: [848] trial: 11, train_loss: 0.088433, test loss: 1.956447, bias2: 0.39473605155944824, variance: 1.5617107152938843\n",
      "Train size: [400] hidden size: [848] trial: 12, train_loss: 0.088956, test loss: 1.963452, bias2: 0.3837488889694214, variance: 1.5797032117843628\n",
      "Train size: [400] hidden size: [848] trial: 13, train_loss: 0.089453, test loss: 1.970137, bias2: 0.37619590759277344, variance: 1.5939412117004395\n",
      "Train size: [400] hidden size: [848] trial: 14, train_loss: 0.089209, test loss: 1.977429, bias2: 0.36755919456481934, variance: 1.609870195388794\n",
      "Train size: [400] hidden size: [848] trial: 15, train_loss: 0.089262, test loss: 1.980123, bias2: 0.35403144359588623, variance: 1.6260912418365479\n",
      "Train size: [400] hidden size: [848] trial: 16, train_loss: 0.088901, test loss: 1.965790, bias2: 0.3417097330093384, variance: 1.6240804195404053\n",
      "Train size: [400] hidden size: [848] trial: 17, train_loss: 0.088135, test loss: 1.957501, bias2: 0.3371325731277466, variance: 1.620368480682373\n",
      "Train size: [400] hidden size: [848] trial: 18, train_loss: 0.088053, test loss: 1.969370, bias2: 0.33719348907470703, variance: 1.6321762800216675\n",
      "Train size: [400] hidden size: [848] trial: 19, train_loss: 0.087476, test loss: 1.968711, bias2: 0.3315286636352539, variance: 1.6371827125549316\n",
      "Train size: [400] hidden size: [848] trial: 20, train_loss: 0.088546, test loss: 1.978919, bias2: 0.32519638538360596, variance: 1.6537221670150757\n",
      "Train size: [400] hidden size: [848] trial: 21, train_loss: 0.088373, test loss: 1.978758, bias2: 0.3178536891937256, variance: 1.660904049873352\n",
      "Train size: [400] hidden size: [848] trial: 22, train_loss: 0.088237, test loss: 1.979299, bias2: 0.3122497797012329, variance: 1.6670492887496948\n",
      "Train size: [400] hidden size: [848] trial: 23, train_loss: 0.088169, test loss: 1.970412, bias2: 0.3075575828552246, variance: 1.6628540754318237\n",
      "Train size: [400] hidden size: [848] trial: 24, train_loss: 0.088190, test loss: 1.968641, bias2: 0.30122053623199463, variance: 1.6674203872680664\n",
      "Train size: [400] hidden size: [848] trial: 25, train_loss: 0.088829, test loss: 1.974062, bias2: 0.2965642213821411, variance: 1.6774975061416626\n",
      "Train size: [400] hidden size: [848] trial: 26, train_loss: 0.088518, test loss: 1.979574, bias2: 0.3001028299331665, variance: 1.6794713735580444\n",
      "Train size: [400] hidden size: [848] trial: 27, train_loss: 0.088353, test loss: 1.976067, bias2: 0.29893314838409424, variance: 1.6771334409713745\n",
      "Train size: [400] hidden size: [848] trial: 28, train_loss: 0.088373, test loss: 1.973420, bias2: 0.29616010189056396, variance: 1.677259922027588\n",
      "Train size: [400] hidden size: [848] trial: 29, train_loss: 0.088518, test loss: 1.974382, bias2: 0.2933398485183716, variance: 1.681042194366455\n",
      "Train size: [400] hidden size: [848] trial: 30, train_loss: 0.088674, test loss: 1.979183, bias2: 0.2937568426132202, variance: 1.6854263544082642\n",
      "Train size: [400] hidden size: [848] trial: 31, train_loss: 0.088253, test loss: 1.977455, bias2: 0.2913320064544678, variance: 1.6861231327056885\n",
      "Train size: [400] hidden size: [848] trial: 32, train_loss: 0.087909, test loss: 1.969778, bias2: 0.2857539653778076, variance: 1.6840236186981201\n",
      "Train size: [400] hidden size: [848] trial: 33, train_loss: 0.087940, test loss: 1.971196, bias2: 0.28376340866088867, variance: 1.6874324083328247\n",
      "Train size: [400] hidden size: [848] trial: 34, train_loss: 0.088376, test loss: 1.970034, bias2: 0.2833191156387329, variance: 1.686714768409729\n",
      "Train size: [400] hidden size: [848] trial: 35, train_loss: 0.088307, test loss: 1.967017, bias2: 0.2800687551498413, variance: 1.6869478225708008\n",
      "Train size: [400] hidden size: [848] trial: 36, train_loss: 0.088051, test loss: 1.970758, bias2: 0.2797640562057495, variance: 1.6909937858581543\n",
      "Train size: [400] hidden size: [848] trial: 37, train_loss: 0.088228, test loss: 1.974520, bias2: 0.2776738405227661, variance: 1.6968464851379395\n",
      "Train size: [400] hidden size: [848] trial: 38, train_loss: 0.088330, test loss: 1.975099, bias2: 0.2764824628829956, variance: 1.6986165046691895\n",
      "Train size: [400] hidden size: [848] trial: 39, train_loss: 0.088664, test loss: 1.978965, bias2: 0.27584707736968994, variance: 1.703118085861206\n",
      "Train size: [400] hidden size: [848] trial: 40, train_loss: 0.089151, test loss: 1.979836, bias2: 0.27261245250701904, variance: 1.7072232961654663\n",
      "Train size: [400] hidden size: [848] trial: 41, train_loss: 0.088840, test loss: 1.977280, bias2: 0.27075231075286865, variance: 1.7065273523330688\n",
      "Train size: [400] hidden size: [848] trial: 42, train_loss: 0.089069, test loss: 1.978348, bias2: 0.27000927925109863, variance: 1.7083388566970825\n",
      "Train size: [400] hidden size: [848] trial: 43, train_loss: 0.088957, test loss: 1.973344, bias2: 0.2685509920120239, variance: 1.7047934532165527\n",
      "Train size: [400] hidden size: [848] trial: 44, train_loss: 0.089303, test loss: 1.978907, bias2: 0.2666177749633789, variance: 1.7122888565063477\n",
      "Train size: [400] hidden size: [848] trial: 45, train_loss: 0.089709, test loss: 1.982334, bias2: 0.26717519760131836, variance: 1.7151583433151245\n",
      "Train size: [400] hidden size: [848] trial: 46, train_loss: 0.089138, test loss: 1.978142, bias2: 0.2662034034729004, variance: 1.7119382619857788\n",
      "Train size: [400] hidden size: [848] trial: 47, train_loss: 0.089115, test loss: 1.976326, bias2: 0.263797402381897, variance: 1.7125285863876343\n",
      "Train size: [400] hidden size: [848] trial: 48, train_loss: 0.089714, test loss: 1.979476, bias2: 0.26320576667785645, variance: 1.7162706851959229\n",
      "Train size: [400] hidden size: [848] trial: 49, train_loss: 0.089630, test loss: 1.978744, bias2: 0.26381874084472656, variance: 1.7149250507354736\n",
      "##################################################\n",
      "Train size: [400] hidden size: [977] trial: 0, train_loss: 0.047405, test loss: 1.707342, bias2: 1.7073421478271484, variance: 7.0065864221646734e-09\n",
      "Train size: [400] hidden size: [977] trial: 1, train_loss: 0.048225, test loss: 1.831107, bias2: 1.04024338722229, variance: 0.7908638715744019\n",
      "Train size: [400] hidden size: [977] trial: 2, train_loss: 0.050348, test loss: 1.841774, bias2: 0.771753191947937, variance: 1.0700207948684692\n",
      "Train size: [400] hidden size: [977] trial: 3, train_loss: 0.050881, test loss: 1.788118, bias2: 0.6197906732559204, variance: 1.1683270931243896\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [977] trial: 4, train_loss: 0.049768, test loss: 1.772879, bias2: 0.526474118232727, variance: 1.246404767036438\n",
      "Train size: [400] hidden size: [977] trial: 5, train_loss: 0.050309, test loss: 1.800841, bias2: 0.47873783111572266, variance: 1.3221030235290527\n",
      "Train size: [400] hidden size: [977] trial: 6, train_loss: 0.050966, test loss: 1.763808, bias2: 0.4245809316635132, variance: 1.3392269611358643\n",
      "Train size: [400] hidden size: [977] trial: 7, train_loss: 0.051853, test loss: 1.778418, bias2: 0.39107561111450195, variance: 1.3873428106307983\n",
      "Train size: [400] hidden size: [977] trial: 8, train_loss: 0.050908, test loss: 1.781893, bias2: 0.38841068744659424, variance: 1.3934826850891113\n",
      "Train size: [400] hidden size: [977] trial: 9, train_loss: 0.052613, test loss: 1.806305, bias2: 0.37682461738586426, variance: 1.4294800758361816\n",
      "Train size: [400] hidden size: [977] trial: 10, train_loss: 0.053494, test loss: 1.831460, bias2: 0.3662487268447876, variance: 1.4652109146118164\n",
      "Train size: [400] hidden size: [977] trial: 11, train_loss: 0.053487, test loss: 1.840882, bias2: 0.35472333431243896, variance: 1.4861583709716797\n",
      "Train size: [400] hidden size: [977] trial: 12, train_loss: 0.053269, test loss: 1.827437, bias2: 0.3465622663497925, variance: 1.4808746576309204\n",
      "Train size: [400] hidden size: [977] trial: 13, train_loss: 0.053853, test loss: 1.829262, bias2: 0.336612343788147, variance: 1.4926499128341675\n",
      "Train size: [400] hidden size: [977] trial: 14, train_loss: 0.053382, test loss: 1.831515, bias2: 0.32618558406829834, variance: 1.5053291320800781\n",
      "Train size: [400] hidden size: [977] trial: 15, train_loss: 0.054379, test loss: 1.822131, bias2: 0.3171581029891968, variance: 1.5049729347229004\n",
      "Train size: [400] hidden size: [977] trial: 16, train_loss: 0.054974, test loss: 1.824610, bias2: 0.3135024309158325, variance: 1.5111078023910522\n",
      "Train size: [400] hidden size: [977] trial: 17, train_loss: 0.054365, test loss: 1.819208, bias2: 0.3107597827911377, variance: 1.5084480047225952\n",
      "Train size: [400] hidden size: [977] trial: 18, train_loss: 0.054512, test loss: 1.822646, bias2: 0.30388104915618896, variance: 1.5187654495239258\n",
      "Train size: [400] hidden size: [977] trial: 19, train_loss: 0.054410, test loss: 1.830462, bias2: 0.299558162689209, variance: 1.5309041738510132\n",
      "Train size: [400] hidden size: [977] trial: 20, train_loss: 0.054019, test loss: 1.826087, bias2: 0.296345591545105, variance: 1.529741644859314\n",
      "Train size: [400] hidden size: [977] trial: 21, train_loss: 0.054078, test loss: 1.821506, bias2: 0.294413685798645, variance: 1.5270919799804688\n",
      "Train size: [400] hidden size: [977] trial: 22, train_loss: 0.054262, test loss: 1.814113, bias2: 0.28500282764434814, variance: 1.5291104316711426\n",
      "Train size: [400] hidden size: [977] trial: 23, train_loss: 0.054149, test loss: 1.817523, bias2: 0.2805337905883789, variance: 1.5369895696640015\n",
      "Train size: [400] hidden size: [977] trial: 24, train_loss: 0.054070, test loss: 1.811635, bias2: 0.2764561176300049, variance: 1.5351786613464355\n",
      "Train size: [400] hidden size: [977] trial: 25, train_loss: 0.054225, test loss: 1.813371, bias2: 0.27483904361724854, variance: 1.5385321378707886\n",
      "Train size: [400] hidden size: [977] trial: 26, train_loss: 0.054104, test loss: 1.811272, bias2: 0.273235559463501, variance: 1.5380367040634155\n",
      "Train size: [400] hidden size: [977] trial: 27, train_loss: 0.054076, test loss: 1.809621, bias2: 0.27264833450317383, variance: 1.536972999572754\n",
      "Train size: [400] hidden size: [977] trial: 28, train_loss: 0.054235, test loss: 1.815845, bias2: 0.2714660167694092, variance: 1.5443787574768066\n",
      "Train size: [400] hidden size: [977] trial: 29, train_loss: 0.054431, test loss: 1.813306, bias2: 0.269372820854187, variance: 1.5439327955245972\n",
      "Train size: [400] hidden size: [977] trial: 30, train_loss: 0.054194, test loss: 1.818319, bias2: 0.26824843883514404, variance: 1.5500706434249878\n",
      "Train size: [400] hidden size: [977] trial: 31, train_loss: 0.054078, test loss: 1.815534, bias2: 0.2655235528945923, variance: 1.5500109195709229\n",
      "Train size: [400] hidden size: [977] trial: 32, train_loss: 0.054159, test loss: 1.818107, bias2: 0.26176655292510986, variance: 1.5563404560089111\n",
      "Train size: [400] hidden size: [977] trial: 33, train_loss: 0.054093, test loss: 1.814393, bias2: 0.2597057819366455, variance: 1.554687738418579\n",
      "Train size: [400] hidden size: [977] trial: 34, train_loss: 0.054094, test loss: 1.814413, bias2: 0.26153838634490967, variance: 1.552874207496643\n",
      "Train size: [400] hidden size: [977] trial: 35, train_loss: 0.054070, test loss: 1.815320, bias2: 0.26129984855651855, variance: 1.5540199279785156\n",
      "Train size: [400] hidden size: [977] trial: 36, train_loss: 0.053817, test loss: 1.815841, bias2: 0.26326167583465576, variance: 1.5525792837142944\n",
      "Train size: [400] hidden size: [977] trial: 37, train_loss: 0.053830, test loss: 1.811034, bias2: 0.2611393928527832, variance: 1.5498942136764526\n",
      "Train size: [400] hidden size: [977] trial: 38, train_loss: 0.053694, test loss: 1.805396, bias2: 0.2588334083557129, variance: 1.5465627908706665\n",
      "Train size: [400] hidden size: [977] trial: 39, train_loss: 0.053780, test loss: 1.805237, bias2: 0.25797510147094727, variance: 1.547262191772461\n",
      "Train size: [400] hidden size: [977] trial: 40, train_loss: 0.053998, test loss: 1.808432, bias2: 0.25747811794281006, variance: 1.5509538650512695\n",
      "Train size: [400] hidden size: [977] trial: 41, train_loss: 0.053784, test loss: 1.811414, bias2: 0.26052772998809814, variance: 1.5508867502212524\n",
      "Train size: [400] hidden size: [977] trial: 42, train_loss: 0.053358, test loss: 1.807268, bias2: 0.2578415870666504, variance: 1.549426794052124\n",
      "Train size: [400] hidden size: [977] trial: 43, train_loss: 0.053052, test loss: 1.802754, bias2: 0.25735366344451904, variance: 1.5454002618789673\n",
      "Train size: [400] hidden size: [977] trial: 44, train_loss: 0.053046, test loss: 1.802098, bias2: 0.2572277784347534, variance: 1.5448702573776245\n",
      "Train size: [400] hidden size: [977] trial: 45, train_loss: 0.053142, test loss: 1.801173, bias2: 0.25599098205566406, variance: 1.545182228088379\n",
      "Train size: [400] hidden size: [977] trial: 46, train_loss: 0.053214, test loss: 1.809153, bias2: 0.25720179080963135, variance: 1.5519508123397827\n",
      "Train size: [400] hidden size: [977] trial: 47, train_loss: 0.053072, test loss: 1.809912, bias2: 0.2570796012878418, variance: 1.552832007408142\n",
      "Train size: [400] hidden size: [977] trial: 48, train_loss: 0.052986, test loss: 1.807192, bias2: 0.2544245719909668, variance: 1.5527678728103638\n",
      "Train size: [400] hidden size: [977] trial: 49, train_loss: 0.053046, test loss: 1.806720, bias2: 0.25194060802459717, variance: 1.5547791719436646\n",
      "##################################################\n",
      "Train size: [400] hidden size: [1125] trial: 0, train_loss: 0.035360, test loss: 1.624153, bias2: 1.6241531372070312, variance: 1.5570191802538602e-09\n",
      "Train size: [400] hidden size: [1125] trial: 1, train_loss: 0.035242, test loss: 1.547183, bias2: 0.9006127715110779, variance: 0.64657062292099\n",
      "Train size: [400] hidden size: [1125] trial: 2, train_loss: 0.036948, test loss: 1.612432, bias2: 0.7102036476135254, variance: 0.902228832244873\n",
      "Train size: [400] hidden size: [1125] trial: 3, train_loss: 0.035138, test loss: 1.564705, bias2: 0.5516382455825806, variance: 1.0130671262741089\n",
      "Train size: [400] hidden size: [1125] trial: 4, train_loss: 0.034848, test loss: 1.573075, bias2: 0.4830210208892822, variance: 1.0900545120239258\n",
      "Train size: [400] hidden size: [1125] trial: 5, train_loss: 0.034267, test loss: 1.558047, bias2: 0.4240180253982544, variance: 1.1340293884277344\n",
      "Train size: [400] hidden size: [1125] trial: 6, train_loss: 0.035533, test loss: 1.580077, bias2: 0.3908003568649292, variance: 1.1892770528793335\n",
      "Train size: [400] hidden size: [1125] trial: 7, train_loss: 0.034331, test loss: 1.559453, bias2: 0.371262788772583, variance: 1.1881897449493408\n",
      "Train size: [400] hidden size: [1125] trial: 8, train_loss: 0.034317, test loss: 1.567123, bias2: 0.35139286518096924, variance: 1.2157301902770996\n",
      "Train size: [400] hidden size: [1125] trial: 9, train_loss: 0.034572, test loss: 1.583650, bias2: 0.34724152088165283, variance: 1.2364084720611572\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [1125] trial: 10, train_loss: 0.034841, test loss: 1.597840, bias2: 0.33840441703796387, variance: 1.2594355344772339\n",
      "Train size: [400] hidden size: [1125] trial: 11, train_loss: 0.034114, test loss: 1.584058, bias2: 0.32771384716033936, variance: 1.2563443183898926\n",
      "Train size: [400] hidden size: [1125] trial: 12, train_loss: 0.033774, test loss: 1.593656, bias2: 0.32868123054504395, variance: 1.2649749517440796\n",
      "Train size: [400] hidden size: [1125] trial: 13, train_loss: 0.033805, test loss: 1.600321, bias2: 0.32014381885528564, variance: 1.2801775932312012\n",
      "Train size: [400] hidden size: [1125] trial: 14, train_loss: 0.034323, test loss: 1.596549, bias2: 0.30822277069091797, variance: 1.2883261442184448\n",
      "Train size: [400] hidden size: [1125] trial: 15, train_loss: 0.034169, test loss: 1.594680, bias2: 0.3037693500518799, variance: 1.290910243988037\n",
      "Train size: [400] hidden size: [1125] trial: 16, train_loss: 0.033960, test loss: 1.595814, bias2: 0.300731897354126, variance: 1.2950818538665771\n",
      "Train size: [400] hidden size: [1125] trial: 17, train_loss: 0.033807, test loss: 1.591579, bias2: 0.30129802227020264, variance: 1.2902814149856567\n",
      "Train size: [400] hidden size: [1125] trial: 18, train_loss: 0.033852, test loss: 1.594003, bias2: 0.29693567752838135, variance: 1.2970675230026245\n",
      "Train size: [400] hidden size: [1125] trial: 19, train_loss: 0.033905, test loss: 1.593667, bias2: 0.2909656763076782, variance: 1.302701711654663\n",
      "Train size: [400] hidden size: [1125] trial: 20, train_loss: 0.033805, test loss: 1.596802, bias2: 0.2904921770095825, variance: 1.306309700012207\n",
      "Train size: [400] hidden size: [1125] trial: 21, train_loss: 0.033499, test loss: 1.593813, bias2: 0.28581178188323975, variance: 1.3080012798309326\n",
      "Train size: [400] hidden size: [1125] trial: 22, train_loss: 0.033153, test loss: 1.594737, bias2: 0.2843055725097656, variance: 1.3104310035705566\n",
      "Train size: [400] hidden size: [1125] trial: 23, train_loss: 0.033382, test loss: 1.594394, bias2: 0.2778247594833374, variance: 1.3165690898895264\n",
      "Train size: [400] hidden size: [1125] trial: 24, train_loss: 0.033172, test loss: 1.589407, bias2: 0.2732210159301758, variance: 1.316185712814331\n",
      "Train size: [400] hidden size: [1125] trial: 25, train_loss: 0.033231, test loss: 1.599910, bias2: 0.2713543176651001, variance: 1.328555703163147\n",
      "Train size: [400] hidden size: [1125] trial: 26, train_loss: 0.033262, test loss: 1.604685, bias2: 0.2696768045425415, variance: 1.3350082635879517\n",
      "Train size: [400] hidden size: [1125] trial: 27, train_loss: 0.033226, test loss: 1.603963, bias2: 0.26968085765838623, variance: 1.334282398223877\n",
      "Train size: [400] hidden size: [1125] trial: 28, train_loss: 0.033088, test loss: 1.600426, bias2: 0.26648271083831787, variance: 1.3339436054229736\n",
      "Train size: [400] hidden size: [1125] trial: 29, train_loss: 0.032936, test loss: 1.603549, bias2: 0.265383243560791, variance: 1.3381654024124146\n",
      "Train size: [400] hidden size: [1125] trial: 30, train_loss: 0.032697, test loss: 1.596740, bias2: 0.2626986503601074, variance: 1.3340409994125366\n",
      "Train size: [400] hidden size: [1125] trial: 31, train_loss: 0.032664, test loss: 1.601149, bias2: 0.26226556301116943, variance: 1.338883876800537\n",
      "Train size: [400] hidden size: [1125] trial: 32, train_loss: 0.032612, test loss: 1.598374, bias2: 0.26125359535217285, variance: 1.3371206521987915\n",
      "Train size: [400] hidden size: [1125] trial: 33, train_loss: 0.032610, test loss: 1.593352, bias2: 0.25876152515411377, variance: 1.3345905542373657\n",
      "Train size: [400] hidden size: [1125] trial: 34, train_loss: 0.032530, test loss: 1.591020, bias2: 0.2558324337005615, variance: 1.3351879119873047\n",
      "Train size: [400] hidden size: [1125] trial: 35, train_loss: 0.032421, test loss: 1.588890, bias2: 0.25392723083496094, variance: 1.3349632024765015\n",
      "Train size: [400] hidden size: [1125] trial: 36, train_loss: 0.032225, test loss: 1.584074, bias2: 0.25270116329193115, variance: 1.3313727378845215\n",
      "Train size: [400] hidden size: [1125] trial: 37, train_loss: 0.032260, test loss: 1.581953, bias2: 0.2509143352508545, variance: 1.3310391902923584\n",
      "Train size: [400] hidden size: [1125] trial: 38, train_loss: 0.032361, test loss: 1.581004, bias2: 0.24983751773834229, variance: 1.3311662673950195\n",
      "Train size: [400] hidden size: [1125] trial: 39, train_loss: 0.032274, test loss: 1.578949, bias2: 0.24747180938720703, variance: 1.3314768075942993\n",
      "Train size: [400] hidden size: [1125] trial: 40, train_loss: 0.032171, test loss: 1.578203, bias2: 0.24510478973388672, variance: 1.3330978155136108\n",
      "Train size: [400] hidden size: [1125] trial: 41, train_loss: 0.032119, test loss: 1.575668, bias2: 0.24409186840057373, variance: 1.3315765857696533\n",
      "Train size: [400] hidden size: [1125] trial: 42, train_loss: 0.032185, test loss: 1.575994, bias2: 0.24180257320404053, variance: 1.3341909646987915\n",
      "Train size: [400] hidden size: [1125] trial: 43, train_loss: 0.032175, test loss: 1.572502, bias2: 0.2417505979537964, variance: 1.330751657485962\n",
      "Train size: [400] hidden size: [1125] trial: 44, train_loss: 0.032099, test loss: 1.569294, bias2: 0.2404341697692871, variance: 1.328859567642212\n",
      "Train size: [400] hidden size: [1125] trial: 45, train_loss: 0.032197, test loss: 1.573874, bias2: 0.2392369508743286, variance: 1.3346374034881592\n",
      "Train size: [400] hidden size: [1125] trial: 46, train_loss: 0.032162, test loss: 1.570463, bias2: 0.23812782764434814, variance: 1.3323355913162231\n",
      "Train size: [400] hidden size: [1125] trial: 47, train_loss: 0.032245, test loss: 1.570206, bias2: 0.23702895641326904, variance: 1.3331774473190308\n",
      "Train size: [400] hidden size: [1125] trial: 48, train_loss: 0.032334, test loss: 1.570828, bias2: 0.23781085014343262, variance: 1.3330174684524536\n",
      "Train size: [400] hidden size: [1125] trial: 49, train_loss: 0.032331, test loss: 1.572165, bias2: 0.23654556274414062, variance: 1.3356198072433472\n",
      "##################################################\n",
      "Train size: [400] hidden size: [1295] trial: 0, train_loss: 0.017720, test loss: 1.249890, bias2: 1.2498902082443237, variance: -2.2576777780614066e-08\n",
      "Train size: [400] hidden size: [1295] trial: 1, train_loss: 0.021055, test loss: 1.357545, bias2: 0.8279308080673218, variance: 0.5296145677566528\n",
      "Train size: [400] hidden size: [1295] trial: 2, train_loss: 0.022668, test loss: 1.353651, bias2: 0.5814707279205322, variance: 0.7721805572509766\n",
      "Train size: [400] hidden size: [1295] trial: 3, train_loss: 0.022670, test loss: 1.351612, bias2: 0.46248382329940796, variance: 0.8891286253929138\n",
      "Train size: [400] hidden size: [1295] trial: 4, train_loss: 0.023363, test loss: 1.382974, bias2: 0.4199388027191162, variance: 0.9630354642868042\n",
      "Train size: [400] hidden size: [1295] trial: 5, train_loss: 0.023637, test loss: 1.401113, bias2: 0.3921421766281128, variance: 1.0089703798294067\n",
      "Train size: [400] hidden size: [1295] trial: 6, train_loss: 0.023181, test loss: 1.393938, bias2: 0.3643934726715088, variance: 1.029544711112976\n",
      "Train size: [400] hidden size: [1295] trial: 7, train_loss: 0.023610, test loss: 1.388463, bias2: 0.3425476551055908, variance: 1.0459158420562744\n",
      "Train size: [400] hidden size: [1295] trial: 8, train_loss: 0.023723, test loss: 1.384942, bias2: 0.32510411739349365, variance: 1.0598374605178833\n",
      "Train size: [400] hidden size: [1295] trial: 9, train_loss: 0.023338, test loss: 1.378525, bias2: 0.31425607204437256, variance: 1.0642691850662231\n",
      "Train size: [400] hidden size: [1295] trial: 10, train_loss: 0.023136, test loss: 1.372817, bias2: 0.30332744121551514, variance: 1.0694894790649414\n",
      "Train size: [400] hidden size: [1295] trial: 11, train_loss: 0.022902, test loss: 1.365603, bias2: 0.2965850830078125, variance: 1.069018006324768\n",
      "Train size: [400] hidden size: [1295] trial: 12, train_loss: 0.022755, test loss: 1.363839, bias2: 0.2865309715270996, variance: 1.0773085355758667\n",
      "Train size: [400] hidden size: [1295] trial: 13, train_loss: 0.022339, test loss: 1.356439, bias2: 0.2819950580596924, variance: 1.0744435787200928\n",
      "Train size: [400] hidden size: [1295] trial: 14, train_loss: 0.022299, test loss: 1.353969, bias2: 0.2715005874633789, variance: 1.0824682712554932\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [1295] trial: 15, train_loss: 0.022234, test loss: 1.343054, bias2: 0.2600456476211548, variance: 1.083008050918579\n",
      "Train size: [400] hidden size: [1295] trial: 16, train_loss: 0.022309, test loss: 1.346886, bias2: 0.25914931297302246, variance: 1.0877366065979004\n",
      "Train size: [400] hidden size: [1295] trial: 17, train_loss: 0.022281, test loss: 1.355977, bias2: 0.2598099708557129, variance: 1.0961673259735107\n",
      "Train size: [400] hidden size: [1295] trial: 18, train_loss: 0.022634, test loss: 1.367645, bias2: 0.25879228115081787, variance: 1.1088528633117676\n",
      "Train size: [400] hidden size: [1295] trial: 19, train_loss: 0.022579, test loss: 1.370149, bias2: 0.2561929225921631, variance: 1.1139559745788574\n",
      "Train size: [400] hidden size: [1295] trial: 20, train_loss: 0.022488, test loss: 1.370562, bias2: 0.25375843048095703, variance: 1.1168034076690674\n",
      "Train size: [400] hidden size: [1295] trial: 21, train_loss: 0.022623, test loss: 1.378686, bias2: 0.2515648603439331, variance: 1.1271209716796875\n",
      "Train size: [400] hidden size: [1295] trial: 22, train_loss: 0.022611, test loss: 1.379352, bias2: 0.25033700466156006, variance: 1.1290146112442017\n",
      "Train size: [400] hidden size: [1295] trial: 23, train_loss: 0.022606, test loss: 1.381325, bias2: 0.24547946453094482, variance: 1.1358458995819092\n",
      "Train size: [400] hidden size: [1295] trial: 24, train_loss: 0.022645, test loss: 1.382872, bias2: 0.24453234672546387, variance: 1.1383399963378906\n",
      "Train size: [400] hidden size: [1295] trial: 25, train_loss: 0.022535, test loss: 1.385264, bias2: 0.24365508556365967, variance: 1.141608476638794\n",
      "Train size: [400] hidden size: [1295] trial: 26, train_loss: 0.022705, test loss: 1.387455, bias2: 0.241521954536438, variance: 1.1459332704544067\n",
      "Train size: [400] hidden size: [1295] trial: 27, train_loss: 0.022695, test loss: 1.386040, bias2: 0.2390742301940918, variance: 1.1469660997390747\n",
      "Train size: [400] hidden size: [1295] trial: 28, train_loss: 0.022758, test loss: 1.391218, bias2: 0.23859179019927979, variance: 1.1526260375976562\n",
      "Train size: [400] hidden size: [1295] trial: 29, train_loss: 0.022846, test loss: 1.395420, bias2: 0.23632466793060303, variance: 1.1590951681137085\n",
      "Train size: [400] hidden size: [1295] trial: 30, train_loss: 0.022914, test loss: 1.394769, bias2: 0.23482513427734375, variance: 1.1599442958831787\n",
      "Train size: [400] hidden size: [1295] trial: 31, train_loss: 0.022812, test loss: 1.391370, bias2: 0.23542654514312744, variance: 1.1559438705444336\n",
      "Train size: [400] hidden size: [1295] trial: 32, train_loss: 0.022829, test loss: 1.391740, bias2: 0.2358088493347168, variance: 1.1559308767318726\n",
      "Train size: [400] hidden size: [1295] trial: 33, train_loss: 0.022914, test loss: 1.394842, bias2: 0.23325061798095703, variance: 1.1615910530090332\n",
      "Train size: [400] hidden size: [1295] trial: 34, train_loss: 0.022850, test loss: 1.394476, bias2: 0.23083055019378662, variance: 1.1636455059051514\n",
      "Train size: [400] hidden size: [1295] trial: 35, train_loss: 0.022774, test loss: 1.398893, bias2: 0.23066222667694092, variance: 1.168230652809143\n",
      "Train size: [400] hidden size: [1295] trial: 36, train_loss: 0.022724, test loss: 1.397832, bias2: 0.22834479808807373, variance: 1.169487476348877\n",
      "Train size: [400] hidden size: [1295] trial: 37, train_loss: 0.022646, test loss: 1.396724, bias2: 0.2282637357711792, variance: 1.1684598922729492\n",
      "Train size: [400] hidden size: [1295] trial: 38, train_loss: 0.022685, test loss: 1.395402, bias2: 0.2293233871459961, variance: 1.1660780906677246\n",
      "Train size: [400] hidden size: [1295] trial: 39, train_loss: 0.022681, test loss: 1.392147, bias2: 0.22941279411315918, variance: 1.1627346277236938\n",
      "Train size: [400] hidden size: [1295] trial: 40, train_loss: 0.022689, test loss: 1.395279, bias2: 0.23067164421081543, variance: 1.1646074056625366\n",
      "Train size: [400] hidden size: [1295] trial: 41, train_loss: 0.022760, test loss: 1.393024, bias2: 0.22729992866516113, variance: 1.165724277496338\n",
      "Train size: [400] hidden size: [1295] trial: 42, train_loss: 0.022681, test loss: 1.392758, bias2: 0.22610890865325928, variance: 1.1666489839553833\n",
      "Train size: [400] hidden size: [1295] trial: 43, train_loss: 0.022620, test loss: 1.392086, bias2: 0.22658634185791016, variance: 1.1655000448226929\n",
      "Train size: [400] hidden size: [1295] trial: 44, train_loss: 0.022605, test loss: 1.392911, bias2: 0.22769999504089355, variance: 1.165210485458374\n",
      "Train size: [400] hidden size: [1295] trial: 45, train_loss: 0.022553, test loss: 1.394385, bias2: 0.2281259298324585, variance: 1.1662589311599731\n",
      "Train size: [400] hidden size: [1295] trial: 46, train_loss: 0.022423, test loss: 1.393117, bias2: 0.22853600978851318, variance: 1.1645811796188354\n",
      "Train size: [400] hidden size: [1295] trial: 47, train_loss: 0.022373, test loss: 1.392445, bias2: 0.22808265686035156, variance: 1.1643627882003784\n",
      "Train size: [400] hidden size: [1295] trial: 48, train_loss: 0.022322, test loss: 1.387915, bias2: 0.22726893424987793, variance: 1.1606459617614746\n",
      "Train size: [400] hidden size: [1295] trial: 49, train_loss: 0.022300, test loss: 1.388102, bias2: 0.2273116111755371, variance: 1.1607900857925415\n",
      "##################################################\n",
      "Train size: [400] hidden size: [1491] trial: 0, train_loss: 0.017020, test loss: 1.208229, bias2: 1.2082293033599854, variance: -3.1140383605077204e-09\n",
      "Train size: [400] hidden size: [1491] trial: 1, train_loss: 0.017358, test loss: 1.245193, bias2: 0.713313639163971, variance: 0.5318792462348938\n",
      "Train size: [400] hidden size: [1491] trial: 2, train_loss: 0.017037, test loss: 1.243678, bias2: 0.5265451073646545, variance: 0.7171328663825989\n",
      "Train size: [400] hidden size: [1491] trial: 3, train_loss: 0.016547, test loss: 1.253369, bias2: 0.4679865837097168, variance: 0.7853819131851196\n",
      "Train size: [400] hidden size: [1491] trial: 4, train_loss: 0.016940, test loss: 1.288782, bias2: 0.44656234979629517, variance: 0.8422194123268127\n",
      "Train size: [400] hidden size: [1491] trial: 5, train_loss: 0.017034, test loss: 1.281416, bias2: 0.4002103805541992, variance: 0.8812053203582764\n",
      "Train size: [400] hidden size: [1491] trial: 6, train_loss: 0.016713, test loss: 1.275460, bias2: 0.37094730138778687, variance: 0.904512345790863\n",
      "Train size: [400] hidden size: [1491] trial: 7, train_loss: 0.016953, test loss: 1.276616, bias2: 0.3529655337333679, variance: 0.9236509203910828\n",
      "Train size: [400] hidden size: [1491] trial: 8, train_loss: 0.016819, test loss: 1.283810, bias2: 0.3320631980895996, variance: 0.9517471790313721\n",
      "Train size: [400] hidden size: [1491] trial: 9, train_loss: 0.016834, test loss: 1.280263, bias2: 0.3188566565513611, variance: 0.9614067673683167\n",
      "Train size: [400] hidden size: [1491] trial: 10, train_loss: 0.016897, test loss: 1.284104, bias2: 0.3163379430770874, variance: 0.9677660465240479\n",
      "Train size: [400] hidden size: [1491] trial: 11, train_loss: 0.016874, test loss: 1.287284, bias2: 0.3088837265968323, variance: 0.9784001708030701\n",
      "Train size: [400] hidden size: [1491] trial: 12, train_loss: 0.016829, test loss: 1.297172, bias2: 0.3074570298194885, variance: 0.9897146821022034\n",
      "Train size: [400] hidden size: [1491] trial: 13, train_loss: 0.016530, test loss: 1.288742, bias2: 0.30517905950546265, variance: 0.9835630059242249\n",
      "Train size: [400] hidden size: [1491] trial: 14, train_loss: 0.016624, test loss: 1.291079, bias2: 0.3020150065422058, variance: 0.9890639185905457\n",
      "Train size: [400] hidden size: [1491] trial: 15, train_loss: 0.016565, test loss: 1.291249, bias2: 0.2987578511238098, variance: 0.9924909472465515\n",
      "Train size: [400] hidden size: [1491] trial: 16, train_loss: 0.016401, test loss: 1.295112, bias2: 0.2929149866104126, variance: 1.0021971464157104\n",
      "Train size: [400] hidden size: [1491] trial: 17, train_loss: 0.016416, test loss: 1.298240, bias2: 0.2876969575881958, variance: 1.0105433464050293\n",
      "Train size: [400] hidden size: [1491] trial: 18, train_loss: 0.016447, test loss: 1.296711, bias2: 0.2840759754180908, variance: 1.0126349925994873\n",
      "Train size: [400] hidden size: [1491] trial: 19, train_loss: 0.016403, test loss: 1.286883, bias2: 0.27329301834106445, variance: 1.01358962059021\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [1491] trial: 20, train_loss: 0.016474, test loss: 1.289224, bias2: 0.27081406116485596, variance: 1.0184099674224854\n",
      "Train size: [400] hidden size: [1491] trial: 21, train_loss: 0.016266, test loss: 1.283055, bias2: 0.26856517791748047, variance: 1.0144896507263184\n",
      "Train size: [400] hidden size: [1491] trial: 22, train_loss: 0.016329, test loss: 1.282815, bias2: 0.26493048667907715, variance: 1.0178842544555664\n",
      "Train size: [400] hidden size: [1491] trial: 23, train_loss: 0.016338, test loss: 1.282740, bias2: 0.2642045021057129, variance: 1.0185356140136719\n",
      "Train size: [400] hidden size: [1491] trial: 24, train_loss: 0.016375, test loss: 1.283767, bias2: 0.2622537612915039, variance: 1.021512746810913\n",
      "Train size: [400] hidden size: [1491] trial: 25, train_loss: 0.016406, test loss: 1.286836, bias2: 0.2610757350921631, variance: 1.025760531425476\n",
      "Train size: [400] hidden size: [1491] trial: 26, train_loss: 0.016483, test loss: 1.286502, bias2: 0.257612943649292, variance: 1.0288894176483154\n",
      "Train size: [400] hidden size: [1491] trial: 27, train_loss: 0.016484, test loss: 1.286210, bias2: 0.2577751874923706, variance: 1.0284349918365479\n",
      "Train size: [400] hidden size: [1491] trial: 28, train_loss: 0.016419, test loss: 1.286997, bias2: 0.2572448253631592, variance: 1.029752254486084\n",
      "Train size: [400] hidden size: [1491] trial: 29, train_loss: 0.016432, test loss: 1.287745, bias2: 0.2579559087753296, variance: 1.0297894477844238\n",
      "Train size: [400] hidden size: [1491] trial: 30, train_loss: 0.016433, test loss: 1.289648, bias2: 0.256585955619812, variance: 1.0330623388290405\n",
      "Train size: [400] hidden size: [1491] trial: 31, train_loss: 0.016466, test loss: 1.292322, bias2: 0.2559783458709717, variance: 1.0363435745239258\n",
      "Train size: [400] hidden size: [1491] trial: 32, train_loss: 0.016407, test loss: 1.288150, bias2: 0.25267839431762695, variance: 1.0354715585708618\n",
      "Train size: [400] hidden size: [1491] trial: 33, train_loss: 0.016373, test loss: 1.287937, bias2: 0.2542301416397095, variance: 1.033706545829773\n",
      "Train size: [400] hidden size: [1491] trial: 34, train_loss: 0.016396, test loss: 1.289827, bias2: 0.2525825500488281, variance: 1.0372449159622192\n",
      "Train size: [400] hidden size: [1491] trial: 35, train_loss: 0.016444, test loss: 1.295015, bias2: 0.25428855419158936, variance: 1.0407264232635498\n",
      "Train size: [400] hidden size: [1491] trial: 36, train_loss: 0.016418, test loss: 1.292256, bias2: 0.2555863857269287, variance: 1.0366700887680054\n",
      "Train size: [400] hidden size: [1491] trial: 37, train_loss: 0.016403, test loss: 1.292192, bias2: 0.25505971908569336, variance: 1.0371320247650146\n",
      "Train size: [400] hidden size: [1491] trial: 38, train_loss: 0.016475, test loss: 1.291148, bias2: 0.25354814529418945, variance: 1.0376001596450806\n",
      "Train size: [400] hidden size: [1491] trial: 39, train_loss: 0.016486, test loss: 1.292663, bias2: 0.2524726390838623, variance: 1.0401904582977295\n",
      "Train size: [400] hidden size: [1491] trial: 40, train_loss: 0.016567, test loss: 1.291275, bias2: 0.24937200546264648, variance: 1.041902780532837\n",
      "Train size: [400] hidden size: [1491] trial: 41, train_loss: 0.016598, test loss: 1.288516, bias2: 0.24769318103790283, variance: 1.0408227443695068\n",
      "Train size: [400] hidden size: [1491] trial: 42, train_loss: 0.016575, test loss: 1.288222, bias2: 0.24706697463989258, variance: 1.0411547422409058\n",
      "Train size: [400] hidden size: [1491] trial: 43, train_loss: 0.016547, test loss: 1.287704, bias2: 0.24436771869659424, variance: 1.0433367490768433\n",
      "Train size: [400] hidden size: [1491] trial: 44, train_loss: 0.016567, test loss: 1.284902, bias2: 0.24414467811584473, variance: 1.0407568216323853\n",
      "Train size: [400] hidden size: [1491] trial: 45, train_loss: 0.016534, test loss: 1.282749, bias2: 0.24364149570465088, variance: 1.0391079187393188\n",
      "Train size: [400] hidden size: [1491] trial: 46, train_loss: 0.016564, test loss: 1.284749, bias2: 0.2435523271560669, variance: 1.0411967039108276\n",
      "Train size: [400] hidden size: [1491] trial: 47, train_loss: 0.016561, test loss: 1.284836, bias2: 0.24280059337615967, variance: 1.0420351028442383\n",
      "Train size: [400] hidden size: [1491] trial: 48, train_loss: 0.016611, test loss: 1.285499, bias2: 0.24194598197937012, variance: 1.0435525178909302\n",
      "Train size: [400] hidden size: [1491] trial: 49, train_loss: 0.016662, test loss: 1.287276, bias2: 0.241013765335083, variance: 1.0462620258331299\n",
      "##################################################\n",
      "Train size: [400] hidden size: [1717] trial: 0, train_loss: 0.012037, test loss: 1.107232, bias2: 1.1072322130203247, variance: 2.8804857166164766e-08\n",
      "Train size: [400] hidden size: [1717] trial: 1, train_loss: 0.013753, test loss: 1.177277, bias2: 0.6657449007034302, variance: 0.5115325450897217\n",
      "Train size: [400] hidden size: [1717] trial: 2, train_loss: 0.013202, test loss: 1.147542, bias2: 0.4922541379928589, variance: 0.655287504196167\n",
      "Train size: [400] hidden size: [1717] trial: 3, train_loss: 0.013115, test loss: 1.141274, bias2: 0.4204201102256775, variance: 0.7208533883094788\n",
      "Train size: [400] hidden size: [1717] trial: 4, train_loss: 0.013206, test loss: 1.145703, bias2: 0.37391722202301025, variance: 0.7717856168746948\n",
      "Train size: [400] hidden size: [1717] trial: 5, train_loss: 0.013100, test loss: 1.137052, bias2: 0.3431386947631836, variance: 0.7939133644104004\n",
      "Train size: [400] hidden size: [1717] trial: 6, train_loss: 0.012796, test loss: 1.135710, bias2: 0.3204016089439392, variance: 0.8153087496757507\n",
      "Train size: [400] hidden size: [1717] trial: 7, train_loss: 0.012901, test loss: 1.137999, bias2: 0.30568253993988037, variance: 0.8323163986206055\n",
      "Train size: [400] hidden size: [1717] trial: 8, train_loss: 0.012843, test loss: 1.136065, bias2: 0.2993243932723999, variance: 0.8367408514022827\n",
      "Train size: [400] hidden size: [1717] trial: 9, train_loss: 0.013371, test loss: 1.148188, bias2: 0.28940409421920776, variance: 0.8587842583656311\n",
      "Train size: [400] hidden size: [1717] trial: 10, train_loss: 0.013591, test loss: 1.158323, bias2: 0.28118449449539185, variance: 0.8771389126777649\n",
      "Train size: [400] hidden size: [1717] trial: 11, train_loss: 0.013654, test loss: 1.167039, bias2: 0.2751205563545227, variance: 0.8919182419776917\n",
      "Train size: [400] hidden size: [1717] trial: 12, train_loss: 0.013593, test loss: 1.169750, bias2: 0.2657836079597473, variance: 0.9039660096168518\n",
      "Train size: [400] hidden size: [1717] trial: 13, train_loss: 0.013517, test loss: 1.167818, bias2: 0.2604665756225586, variance: 0.9073517322540283\n",
      "Train size: [400] hidden size: [1717] trial: 14, train_loss: 0.013574, test loss: 1.173964, bias2: 0.25341910123825073, variance: 0.920544445514679\n",
      "Train size: [400] hidden size: [1717] trial: 15, train_loss: 0.013503, test loss: 1.174054, bias2: 0.24783849716186523, variance: 0.9262157678604126\n",
      "Train size: [400] hidden size: [1717] trial: 16, train_loss: 0.013564, test loss: 1.178354, bias2: 0.2455958127975464, variance: 0.932758092880249\n",
      "Train size: [400] hidden size: [1717] trial: 17, train_loss: 0.013647, test loss: 1.179626, bias2: 0.2444366216659546, variance: 0.9351896047592163\n",
      "Train size: [400] hidden size: [1717] trial: 18, train_loss: 0.013656, test loss: 1.173379, bias2: 0.24129635095596313, variance: 0.9320827126502991\n",
      "Train size: [400] hidden size: [1717] trial: 19, train_loss: 0.013630, test loss: 1.176879, bias2: 0.2406325340270996, variance: 0.9362467527389526\n",
      "Train size: [400] hidden size: [1717] trial: 20, train_loss: 0.013606, test loss: 1.175982, bias2: 0.23684686422348022, variance: 0.9391347765922546\n",
      "Train size: [400] hidden size: [1717] trial: 21, train_loss: 0.013532, test loss: 1.174932, bias2: 0.23604202270507812, variance: 0.9388899803161621\n",
      "Train size: [400] hidden size: [1717] trial: 22, train_loss: 0.013533, test loss: 1.174818, bias2: 0.23469525575637817, variance: 0.9401227831840515\n",
      "Train size: [400] hidden size: [1717] trial: 23, train_loss: 0.013525, test loss: 1.175199, bias2: 0.23328256607055664, variance: 0.9419167041778564\n",
      "Train size: [400] hidden size: [1717] trial: 24, train_loss: 0.013673, test loss: 1.177998, bias2: 0.2329387664794922, variance: 0.9450595378875732\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [1717] trial: 25, train_loss: 0.013576, test loss: 1.180496, bias2: 0.23427510261535645, variance: 0.9462205171585083\n",
      "Train size: [400] hidden size: [1717] trial: 26, train_loss: 0.013469, test loss: 1.176420, bias2: 0.23260021209716797, variance: 0.943819522857666\n",
      "Train size: [400] hidden size: [1717] trial: 27, train_loss: 0.013473, test loss: 1.175833, bias2: 0.231117844581604, variance: 0.9447149038314819\n",
      "Train size: [400] hidden size: [1717] trial: 28, train_loss: 0.013466, test loss: 1.178147, bias2: 0.23006796836853027, variance: 0.9480794668197632\n",
      "Train size: [400] hidden size: [1717] trial: 29, train_loss: 0.013387, test loss: 1.173824, bias2: 0.2286854386329651, variance: 0.945138156414032\n",
      "Train size: [400] hidden size: [1717] trial: 30, train_loss: 0.013291, test loss: 1.166424, bias2: 0.22669559717178345, variance: 0.939728319644928\n",
      "Train size: [400] hidden size: [1717] trial: 31, train_loss: 0.013318, test loss: 1.169940, bias2: 0.22658759355545044, variance: 0.9433525204658508\n",
      "Train size: [400] hidden size: [1717] trial: 32, train_loss: 0.013287, test loss: 1.166650, bias2: 0.22668206691741943, variance: 0.9399677515029907\n",
      "Train size: [400] hidden size: [1717] trial: 33, train_loss: 0.013353, test loss: 1.167318, bias2: 0.2265392541885376, variance: 0.9407788515090942\n",
      "Train size: [400] hidden size: [1717] trial: 34, train_loss: 0.013301, test loss: 1.161798, bias2: 0.2242148518562317, variance: 0.9375830292701721\n",
      "Train size: [400] hidden size: [1717] trial: 35, train_loss: 0.013239, test loss: 1.159246, bias2: 0.2223629355430603, variance: 0.936883270740509\n",
      "Train size: [400] hidden size: [1717] trial: 36, train_loss: 0.013212, test loss: 1.158052, bias2: 0.22177118062973022, variance: 0.936281144618988\n",
      "Train size: [400] hidden size: [1717] trial: 37, train_loss: 0.013179, test loss: 1.155147, bias2: 0.2203626036643982, variance: 0.9347847104072571\n",
      "Train size: [400] hidden size: [1717] trial: 38, train_loss: 0.013215, test loss: 1.156216, bias2: 0.2204943299293518, variance: 0.9357214570045471\n",
      "Train size: [400] hidden size: [1717] trial: 39, train_loss: 0.013209, test loss: 1.157908, bias2: 0.22074443101882935, variance: 0.9371634125709534\n",
      "Train size: [400] hidden size: [1717] trial: 40, train_loss: 0.013213, test loss: 1.157974, bias2: 0.22063565254211426, variance: 0.9373388290405273\n",
      "Train size: [400] hidden size: [1717] trial: 41, train_loss: 0.013135, test loss: 1.155743, bias2: 0.21997219324111938, variance: 0.9357706904411316\n",
      "Train size: [400] hidden size: [1717] trial: 42, train_loss: 0.013148, test loss: 1.159805, bias2: 0.2193503975868225, variance: 0.9404546618461609\n",
      "Train size: [400] hidden size: [1717] trial: 43, train_loss: 0.013194, test loss: 1.158996, bias2: 0.2172052264213562, variance: 0.9417906403541565\n",
      "Train size: [400] hidden size: [1717] trial: 44, train_loss: 0.013163, test loss: 1.158450, bias2: 0.21604037284851074, variance: 0.942409873008728\n",
      "Train size: [400] hidden size: [1717] trial: 45, train_loss: 0.013161, test loss: 1.157444, bias2: 0.2160261869430542, variance: 0.9414173364639282\n",
      "Train size: [400] hidden size: [1717] trial: 46, train_loss: 0.013169, test loss: 1.160830, bias2: 0.21806687116622925, variance: 0.9427627921104431\n",
      "Train size: [400] hidden size: [1717] trial: 47, train_loss: 0.013172, test loss: 1.159151, bias2: 0.21778184175491333, variance: 0.9413694739341736\n",
      "Train size: [400] hidden size: [1717] trial: 48, train_loss: 0.013227, test loss: 1.161477, bias2: 0.21782654523849487, variance: 0.9436505436897278\n",
      "Train size: [400] hidden size: [1717] trial: 49, train_loss: 0.013329, test loss: 1.164263, bias2: 0.21876096725463867, variance: 0.9455015659332275\n",
      "##################################################\n",
      "Train size: [400] hidden size: [1977] trial: 0, train_loss: 0.012578, test loss: 1.109437, bias2: 1.1094372272491455, variance: -7.785095901269301e-10\n",
      "Train size: [400] hidden size: [1977] trial: 1, train_loss: 0.010290, test loss: 1.020935, bias2: 0.6137499809265137, variance: 0.40718522667884827\n",
      "Train size: [400] hidden size: [1977] trial: 2, train_loss: 0.010032, test loss: 1.026257, bias2: 0.45774126052856445, variance: 0.5685160160064697\n",
      "Train size: [400] hidden size: [1977] trial: 3, train_loss: 0.010817, test loss: 1.092884, bias2: 0.4111971855163574, variance: 0.6816868782043457\n",
      "Train size: [400] hidden size: [1977] trial: 4, train_loss: 0.010803, test loss: 1.093535, bias2: 0.37386786937713623, variance: 0.7196675539016724\n",
      "Train size: [400] hidden size: [1977] trial: 5, train_loss: 0.010785, test loss: 1.088151, bias2: 0.3333759903907776, variance: 0.7547745108604431\n",
      "Train size: [400] hidden size: [1977] trial: 6, train_loss: 0.011113, test loss: 1.097592, bias2: 0.3158878684043884, variance: 0.7817044854164124\n",
      "Train size: [400] hidden size: [1977] trial: 7, train_loss: 0.010908, test loss: 1.092506, bias2: 0.30091941356658936, variance: 0.7915862798690796\n",
      "Train size: [400] hidden size: [1977] trial: 8, train_loss: 0.010900, test loss: 1.092974, bias2: 0.29328322410583496, variance: 0.7996910810470581\n",
      "Train size: [400] hidden size: [1977] trial: 9, train_loss: 0.010753, test loss: 1.092145, bias2: 0.28862297534942627, variance: 0.803521990776062\n",
      "Train size: [400] hidden size: [1977] trial: 10, train_loss: 0.010528, test loss: 1.087982, bias2: 0.2864977717399597, variance: 0.8014838099479675\n",
      "Train size: [400] hidden size: [1977] trial: 11, train_loss: 0.010526, test loss: 1.089357, bias2: 0.28116559982299805, variance: 0.8081918954849243\n",
      "Train size: [400] hidden size: [1977] trial: 12, train_loss: 0.010617, test loss: 1.087340, bias2: 0.27525049448013306, variance: 0.8120890259742737\n",
      "Train size: [400] hidden size: [1977] trial: 13, train_loss: 0.010565, test loss: 1.082091, bias2: 0.2685447931289673, variance: 0.8135457038879395\n",
      "Train size: [400] hidden size: [1977] trial: 14, train_loss: 0.010509, test loss: 1.083366, bias2: 0.2637808322906494, variance: 0.8195849657058716\n",
      "Train size: [400] hidden size: [1977] trial: 15, train_loss: 0.010594, test loss: 1.077825, bias2: 0.2607914209365845, variance: 0.8170338869094849\n",
      "Train size: [400] hidden size: [1977] trial: 16, train_loss: 0.010537, test loss: 1.077646, bias2: 0.25792908668518066, variance: 0.819717288017273\n",
      "Train size: [400] hidden size: [1977] trial: 17, train_loss: 0.010468, test loss: 1.076255, bias2: 0.2515007257461548, variance: 0.8247543573379517\n",
      "Train size: [400] hidden size: [1977] trial: 18, train_loss: 0.010434, test loss: 1.077689, bias2: 0.25187861919403076, variance: 0.8258099555969238\n",
      "Train size: [400] hidden size: [1977] trial: 19, train_loss: 0.010487, test loss: 1.082228, bias2: 0.252644419670105, variance: 0.829584002494812\n",
      "Train size: [400] hidden size: [1977] trial: 20, train_loss: 0.010501, test loss: 1.077244, bias2: 0.2489684820175171, variance: 0.8282756805419922\n",
      "Train size: [400] hidden size: [1977] trial: 21, train_loss: 0.010553, test loss: 1.083550, bias2: 0.2503713369369507, variance: 0.8331782817840576\n",
      "Train size: [400] hidden size: [1977] trial: 22, train_loss: 0.010548, test loss: 1.087660, bias2: 0.24821168184280396, variance: 0.8394483923912048\n",
      "Train size: [400] hidden size: [1977] trial: 23, train_loss: 0.010549, test loss: 1.087952, bias2: 0.24646401405334473, variance: 0.8414883613586426\n",
      "Train size: [400] hidden size: [1977] trial: 24, train_loss: 0.010584, test loss: 1.088897, bias2: 0.24365580081939697, variance: 0.8452408313751221\n",
      "Train size: [400] hidden size: [1977] trial: 25, train_loss: 0.010659, test loss: 1.089507, bias2: 0.24479961395263672, variance: 0.8447072505950928\n",
      "Train size: [400] hidden size: [1977] trial: 26, train_loss: 0.010615, test loss: 1.087993, bias2: 0.24484699964523315, variance: 0.843146026134491\n",
      "Train size: [400] hidden size: [1977] trial: 27, train_loss: 0.010615, test loss: 1.089151, bias2: 0.24375629425048828, variance: 0.8453943729400635\n",
      "Train size: [400] hidden size: [1977] trial: 28, train_loss: 0.010661, test loss: 1.090157, bias2: 0.24098843336105347, variance: 0.8491681218147278\n",
      "Train size: [400] hidden size: [1977] trial: 29, train_loss: 0.010688, test loss: 1.090543, bias2: 0.2415943741798401, variance: 0.8489485383033752\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [1977] trial: 30, train_loss: 0.010659, test loss: 1.088222, bias2: 0.23973095417022705, variance: 0.8484909534454346\n",
      "Train size: [400] hidden size: [1977] trial: 31, train_loss: 0.010623, test loss: 1.085070, bias2: 0.23849064111709595, variance: 0.8465792536735535\n",
      "Train size: [400] hidden size: [1977] trial: 32, train_loss: 0.010662, test loss: 1.090565, bias2: 0.2379111647605896, variance: 0.8526533246040344\n",
      "Train size: [400] hidden size: [1977] trial: 33, train_loss: 0.010638, test loss: 1.091604, bias2: 0.237460196018219, variance: 0.8541437983512878\n",
      "Train size: [400] hidden size: [1977] trial: 34, train_loss: 0.010580, test loss: 1.090511, bias2: 0.23603850603103638, variance: 0.8544719815254211\n",
      "Train size: [400] hidden size: [1977] trial: 35, train_loss: 0.010575, test loss: 1.089838, bias2: 0.23376953601837158, variance: 0.8560682535171509\n",
      "Train size: [400] hidden size: [1977] trial: 36, train_loss: 0.010561, test loss: 1.089261, bias2: 0.23300164937973022, variance: 0.8562595248222351\n",
      "Train size: [400] hidden size: [1977] trial: 37, train_loss: 0.010533, test loss: 1.092484, bias2: 0.23351651430130005, variance: 0.8589674830436707\n",
      "Train size: [400] hidden size: [1977] trial: 38, train_loss: 0.010499, test loss: 1.091240, bias2: 0.23297500610351562, variance: 0.858264684677124\n",
      "Train size: [400] hidden size: [1977] trial: 39, train_loss: 0.010519, test loss: 1.089878, bias2: 0.23149985074996948, variance: 0.8583785891532898\n",
      "Train size: [400] hidden size: [1977] trial: 40, train_loss: 0.010529, test loss: 1.087819, bias2: 0.22904199361801147, variance: 0.8587766289710999\n",
      "Train size: [400] hidden size: [1977] trial: 41, train_loss: 0.010487, test loss: 1.086325, bias2: 0.22870135307312012, variance: 0.8576235771179199\n",
      "Train size: [400] hidden size: [1977] trial: 42, train_loss: 0.010499, test loss: 1.086111, bias2: 0.2279449701309204, variance: 0.858165979385376\n",
      "Train size: [400] hidden size: [1977] trial: 43, train_loss: 0.010490, test loss: 1.083786, bias2: 0.22841095924377441, variance: 0.8553750514984131\n",
      "Train size: [400] hidden size: [1977] trial: 44, train_loss: 0.010474, test loss: 1.083327, bias2: 0.22738617658615112, variance: 0.8559408783912659\n",
      "Train size: [400] hidden size: [1977] trial: 45, train_loss: 0.010468, test loss: 1.082478, bias2: 0.22634297609329224, variance: 0.8561351895332336\n",
      "Train size: [400] hidden size: [1977] trial: 46, train_loss: 0.010488, test loss: 1.083213, bias2: 0.22562682628631592, variance: 0.8575857877731323\n",
      "Train size: [400] hidden size: [1977] trial: 47, train_loss: 0.010496, test loss: 1.085241, bias2: 0.22560787200927734, variance: 0.8596327304840088\n",
      "Train size: [400] hidden size: [1977] trial: 48, train_loss: 0.010538, test loss: 1.086011, bias2: 0.22629213333129883, variance: 0.8597185611724854\n",
      "Train size: [400] hidden size: [1977] trial: 49, train_loss: 0.010518, test loss: 1.085935, bias2: 0.22688812017440796, variance: 0.8590472340583801\n",
      "##################################################\n",
      "Train size: [400] hidden size: [2276] trial: 0, train_loss: 0.008432, test loss: 1.003948, bias2: 1.0039478540420532, variance: -3.1140383605077204e-09\n",
      "Train size: [400] hidden size: [2276] trial: 1, train_loss: 0.008739, test loss: 1.013117, bias2: 0.6333826780319214, variance: 0.37973442673683167\n",
      "Train size: [400] hidden size: [2276] trial: 2, train_loss: 0.009612, test loss: 1.045966, bias2: 0.5008900165557861, variance: 0.5450757741928101\n",
      "Train size: [400] hidden size: [2276] trial: 3, train_loss: 0.009568, test loss: 1.046509, bias2: 0.43033158779144287, variance: 0.6161774396896362\n",
      "Train size: [400] hidden size: [2276] trial: 4, train_loss: 0.009362, test loss: 1.025900, bias2: 0.37645167112350464, variance: 0.6494478583335876\n",
      "Train size: [400] hidden size: [2276] trial: 5, train_loss: 0.009838, test loss: 1.025910, bias2: 0.34106123447418213, variance: 0.6848492622375488\n",
      "Train size: [400] hidden size: [2276] trial: 6, train_loss: 0.009755, test loss: 1.040341, bias2: 0.327001690864563, variance: 0.7133393287658691\n",
      "Train size: [400] hidden size: [2276] trial: 7, train_loss: 0.009646, test loss: 1.047628, bias2: 0.3149217963218689, variance: 0.7327067255973816\n",
      "Train size: [400] hidden size: [2276] trial: 8, train_loss: 0.009601, test loss: 1.038376, bias2: 0.29377228021621704, variance: 0.7446038126945496\n",
      "Train size: [400] hidden size: [2276] trial: 9, train_loss: 0.009364, test loss: 1.033473, bias2: 0.2921138405799866, variance: 0.7413588166236877\n",
      "Train size: [400] hidden size: [2276] trial: 10, train_loss: 0.009267, test loss: 1.031735, bias2: 0.2881922721862793, variance: 0.7435423135757446\n",
      "Train size: [400] hidden size: [2276] trial: 11, train_loss: 0.009169, test loss: 1.032986, bias2: 0.28341948986053467, variance: 0.7495664358139038\n",
      "Train size: [400] hidden size: [2276] trial: 12, train_loss: 0.009163, test loss: 1.034211, bias2: 0.2795831561088562, variance: 0.7546280026435852\n",
      "Train size: [400] hidden size: [2276] trial: 13, train_loss: 0.009185, test loss: 1.037247, bias2: 0.2769865393638611, variance: 0.7602605223655701\n",
      "Train size: [400] hidden size: [2276] trial: 14, train_loss: 0.009174, test loss: 1.034808, bias2: 0.2709502577781677, variance: 0.7638576626777649\n",
      "Train size: [400] hidden size: [2276] trial: 15, train_loss: 0.009221, test loss: 1.036842, bias2: 0.26902318000793457, variance: 0.7678185701370239\n",
      "Train size: [400] hidden size: [2276] trial: 16, train_loss: 0.009226, test loss: 1.044740, bias2: 0.27069222927093506, variance: 0.7740478515625\n",
      "Train size: [400] hidden size: [2276] trial: 17, train_loss: 0.009191, test loss: 1.041213, bias2: 0.2663953900337219, variance: 0.7748181223869324\n",
      "Train size: [400] hidden size: [2276] trial: 18, train_loss: 0.009194, test loss: 1.041812, bias2: 0.26774609088897705, variance: 0.7740656137466431\n",
      "Train size: [400] hidden size: [2276] trial: 19, train_loss: 0.009171, test loss: 1.042888, bias2: 0.26586973667144775, variance: 0.7770179510116577\n",
      "Train size: [400] hidden size: [2276] trial: 20, train_loss: 0.009180, test loss: 1.040910, bias2: 0.2627584934234619, variance: 0.7781515121459961\n",
      "Train size: [400] hidden size: [2276] trial: 21, train_loss: 0.009260, test loss: 1.040325, bias2: 0.25920140743255615, variance: 0.7811239957809448\n",
      "Train size: [400] hidden size: [2276] trial: 22, train_loss: 0.009246, test loss: 1.043305, bias2: 0.2561601400375366, variance: 0.7871443033218384\n",
      "Train size: [400] hidden size: [2276] trial: 23, train_loss: 0.009286, test loss: 1.041994, bias2: 0.2536972165107727, variance: 0.7882972359657288\n",
      "Train size: [400] hidden size: [2276] trial: 24, train_loss: 0.009267, test loss: 1.042506, bias2: 0.25255876779556274, variance: 0.7899472117424011\n",
      "Train size: [400] hidden size: [2276] trial: 25, train_loss: 0.009327, test loss: 1.044503, bias2: 0.2506519556045532, variance: 0.7938505411148071\n",
      "Train size: [400] hidden size: [2276] trial: 26, train_loss: 0.009291, test loss: 1.043145, bias2: 0.24848222732543945, variance: 0.7946624755859375\n",
      "Train size: [400] hidden size: [2276] trial: 27, train_loss: 0.009291, test loss: 1.040574, bias2: 0.24704915285110474, variance: 0.7935245633125305\n",
      "Train size: [400] hidden size: [2276] trial: 28, train_loss: 0.009217, test loss: 1.038572, bias2: 0.24700582027435303, variance: 0.7915666103363037\n",
      "Train size: [400] hidden size: [2276] trial: 29, train_loss: 0.009200, test loss: 1.038967, bias2: 0.24578863382339478, variance: 0.7931786179542542\n",
      "Train size: [400] hidden size: [2276] trial: 30, train_loss: 0.009224, test loss: 1.040253, bias2: 0.24506133794784546, variance: 0.7951918244361877\n",
      "Train size: [400] hidden size: [2276] trial: 31, train_loss: 0.009200, test loss: 1.037777, bias2: 0.24354803562164307, variance: 0.79422926902771\n",
      "Train size: [400] hidden size: [2276] trial: 32, train_loss: 0.009207, test loss: 1.036296, bias2: 0.2415347695350647, variance: 0.7947611212730408\n",
      "Train size: [400] hidden size: [2276] trial: 33, train_loss: 0.009206, test loss: 1.035878, bias2: 0.24082612991333008, variance: 0.7950514554977417\n",
      "Train size: [400] hidden size: [2276] trial: 34, train_loss: 0.009201, test loss: 1.034895, bias2: 0.23728346824645996, variance: 0.7976115942001343\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [2276] trial: 35, train_loss: 0.009181, test loss: 1.033496, bias2: 0.2379491925239563, variance: 0.7955471873283386\n",
      "Train size: [400] hidden size: [2276] trial: 36, train_loss: 0.009194, test loss: 1.033083, bias2: 0.23732036352157593, variance: 0.7957629561424255\n",
      "Train size: [400] hidden size: [2276] trial: 37, train_loss: 0.009140, test loss: 1.031314, bias2: 0.23792070150375366, variance: 0.7933934330940247\n",
      "Train size: [400] hidden size: [2276] trial: 38, train_loss: 0.009085, test loss: 1.030780, bias2: 0.23786628246307373, variance: 0.7929131984710693\n",
      "Train size: [400] hidden size: [2276] trial: 39, train_loss: 0.009092, test loss: 1.028401, bias2: 0.23566371202468872, variance: 0.7927376627922058\n",
      "Train size: [400] hidden size: [2276] trial: 40, train_loss: 0.009074, test loss: 1.026619, bias2: 0.23407667875289917, variance: 0.7925426363945007\n",
      "Train size: [400] hidden size: [2276] trial: 41, train_loss: 0.009052, test loss: 1.023381, bias2: 0.23263192176818848, variance: 0.7907488346099854\n",
      "Train size: [400] hidden size: [2276] trial: 42, train_loss: 0.009085, test loss: 1.023789, bias2: 0.23289138078689575, variance: 0.7908980250358582\n",
      "Train size: [400] hidden size: [2276] trial: 43, train_loss: 0.009094, test loss: 1.025148, bias2: 0.23223459720611572, variance: 0.7929131984710693\n",
      "Train size: [400] hidden size: [2276] trial: 44, train_loss: 0.009169, test loss: 1.026366, bias2: 0.23187404870986938, variance: 0.7944923043251038\n",
      "Train size: [400] hidden size: [2276] trial: 45, train_loss: 0.009181, test loss: 1.025571, bias2: 0.2311764359474182, variance: 0.7943947911262512\n",
      "Train size: [400] hidden size: [2276] trial: 46, train_loss: 0.009145, test loss: 1.024035, bias2: 0.23018240928649902, variance: 0.7938528060913086\n",
      "Train size: [400] hidden size: [2276] trial: 47, train_loss: 0.009116, test loss: 1.023640, bias2: 0.22924184799194336, variance: 0.7943977117538452\n",
      "Train size: [400] hidden size: [2276] trial: 48, train_loss: 0.009114, test loss: 1.024550, bias2: 0.22935819625854492, variance: 0.7951912879943848\n",
      "Train size: [400] hidden size: [2276] trial: 49, train_loss: 0.009101, test loss: 1.022894, bias2: 0.22796505689620972, variance: 0.7949293255805969\n",
      "##################################################\n",
      "Train size: [400] hidden size: [2621] trial: 0, train_loss: 0.007268, test loss: 1.092543, bias2: 1.0925425291061401, variance: 7.785095901269301e-10\n",
      "Train size: [400] hidden size: [2621] trial: 1, train_loss: 0.007569, test loss: 1.052044, bias2: 0.6650452613830566, variance: 0.38699889183044434\n",
      "Train size: [400] hidden size: [2621] trial: 2, train_loss: 0.007895, test loss: 0.991678, bias2: 0.4825893044471741, variance: 0.5090882778167725\n",
      "Train size: [400] hidden size: [2621] trial: 3, train_loss: 0.008088, test loss: 1.014295, bias2: 0.4171856641769409, variance: 0.5971091985702515\n",
      "Train size: [400] hidden size: [2621] trial: 4, train_loss: 0.007998, test loss: 0.989153, bias2: 0.35404038429260254, variance: 0.6351128816604614\n",
      "Train size: [400] hidden size: [2621] trial: 5, train_loss: 0.008059, test loss: 0.986091, bias2: 0.3227161765098572, variance: 0.6633744239807129\n",
      "Train size: [400] hidden size: [2621] trial: 6, train_loss: 0.007894, test loss: 0.974444, bias2: 0.29746729135513306, variance: 0.6769768595695496\n",
      "Train size: [400] hidden size: [2621] trial: 7, train_loss: 0.007797, test loss: 0.971599, bias2: 0.2795490026473999, variance: 0.6920496821403503\n",
      "Train size: [400] hidden size: [2621] trial: 8, train_loss: 0.007930, test loss: 0.981648, bias2: 0.27668458223342896, variance: 0.7049638032913208\n",
      "Train size: [400] hidden size: [2621] trial: 9, train_loss: 0.007910, test loss: 0.975450, bias2: 0.266676127910614, variance: 0.7087741494178772\n",
      "Train size: [400] hidden size: [2621] trial: 10, train_loss: 0.007917, test loss: 0.986221, bias2: 0.2708144783973694, variance: 0.7154067754745483\n",
      "Train size: [400] hidden size: [2621] trial: 11, train_loss: 0.007895, test loss: 0.977088, bias2: 0.26271164417266846, variance: 0.7143766283988953\n",
      "Train size: [400] hidden size: [2621] trial: 12, train_loss: 0.007851, test loss: 0.976203, bias2: 0.25977927446365356, variance: 0.7164239287376404\n",
      "Train size: [400] hidden size: [2621] trial: 13, train_loss: 0.007818, test loss: 0.978340, bias2: 0.2574358582496643, variance: 0.7209041118621826\n",
      "Train size: [400] hidden size: [2621] trial: 14, train_loss: 0.007759, test loss: 0.972377, bias2: 0.25062859058380127, variance: 0.7217484712600708\n",
      "Train size: [400] hidden size: [2621] trial: 15, train_loss: 0.007765, test loss: 0.970425, bias2: 0.24600917100906372, variance: 0.7244160771369934\n",
      "Train size: [400] hidden size: [2621] trial: 16, train_loss: 0.007776, test loss: 0.968476, bias2: 0.24019497632980347, variance: 0.728280782699585\n",
      "Train size: [400] hidden size: [2621] trial: 17, train_loss: 0.007811, test loss: 0.970596, bias2: 0.24234795570373535, variance: 0.728248119354248\n",
      "Train size: [400] hidden size: [2621] trial: 18, train_loss: 0.007800, test loss: 0.969800, bias2: 0.24201613664627075, variance: 0.7277835011482239\n",
      "Train size: [400] hidden size: [2621] trial: 19, train_loss: 0.007769, test loss: 0.971066, bias2: 0.24211585521697998, variance: 0.7289500832557678\n",
      "Train size: [400] hidden size: [2621] trial: 20, train_loss: 0.007765, test loss: 0.968292, bias2: 0.2390769124031067, variance: 0.7292148470878601\n",
      "Train size: [400] hidden size: [2621] trial: 21, train_loss: 0.007757, test loss: 0.966566, bias2: 0.23783975839614868, variance: 0.728725790977478\n",
      "Train size: [400] hidden size: [2621] trial: 22, train_loss: 0.007773, test loss: 0.962649, bias2: 0.23631829023361206, variance: 0.7263309359550476\n",
      "Train size: [400] hidden size: [2621] trial: 23, train_loss: 0.007752, test loss: 0.961348, bias2: 0.23239171504974365, variance: 0.7289565801620483\n",
      "Train size: [400] hidden size: [2621] trial: 24, train_loss: 0.007724, test loss: 0.960249, bias2: 0.23091036081314087, variance: 0.7293387055397034\n",
      "Train size: [400] hidden size: [2621] trial: 25, train_loss: 0.007697, test loss: 0.961286, bias2: 0.2303159236907959, variance: 0.7309699654579163\n",
      "Train size: [400] hidden size: [2621] trial: 26, train_loss: 0.007633, test loss: 0.957220, bias2: 0.22992151975631714, variance: 0.7272984981536865\n",
      "Train size: [400] hidden size: [2621] trial: 27, train_loss: 0.007600, test loss: 0.954077, bias2: 0.228753924369812, variance: 0.7253232002258301\n",
      "Train size: [400] hidden size: [2621] trial: 28, train_loss: 0.007661, test loss: 0.956554, bias2: 0.22841084003448486, variance: 0.7281432747840881\n",
      "Train size: [400] hidden size: [2621] trial: 29, train_loss: 0.007648, test loss: 0.953675, bias2: 0.22639960050582886, variance: 0.7272757291793823\n",
      "Train size: [400] hidden size: [2621] trial: 30, train_loss: 0.007649, test loss: 0.956097, bias2: 0.22675436735153198, variance: 0.7293426394462585\n",
      "Train size: [400] hidden size: [2621] trial: 31, train_loss: 0.007642, test loss: 0.955337, bias2: 0.2260667085647583, variance: 0.7292701601982117\n",
      "Train size: [400] hidden size: [2621] trial: 32, train_loss: 0.007716, test loss: 0.956438, bias2: 0.2242116928100586, variance: 0.7322260141372681\n",
      "Train size: [400] hidden size: [2621] trial: 33, train_loss: 0.007754, test loss: 0.958906, bias2: 0.22393333911895752, variance: 0.7349727153778076\n",
      "Train size: [400] hidden size: [2621] trial: 34, train_loss: 0.007752, test loss: 0.959564, bias2: 0.22277098894119263, variance: 0.7367933988571167\n",
      "Train size: [400] hidden size: [2621] trial: 35, train_loss: 0.007724, test loss: 0.960813, bias2: 0.22031283378601074, variance: 0.7405004501342773\n",
      "Train size: [400] hidden size: [2621] trial: 36, train_loss: 0.007706, test loss: 0.961198, bias2: 0.22013109922409058, variance: 0.7410667538642883\n",
      "Train size: [400] hidden size: [2621] trial: 37, train_loss: 0.007759, test loss: 0.959888, bias2: 0.218070387840271, variance: 0.7418172359466553\n",
      "Train size: [400] hidden size: [2621] trial: 38, train_loss: 0.007775, test loss: 0.961336, bias2: 0.217781662940979, variance: 0.7435547113418579\n",
      "Train size: [400] hidden size: [2621] trial: 39, train_loss: 0.007797, test loss: 0.962267, bias2: 0.21848374605178833, variance: 0.7437835335731506\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [2621] trial: 40, train_loss: 0.007788, test loss: 0.960863, bias2: 0.21817916631698608, variance: 0.7426835298538208\n",
      "Train size: [400] hidden size: [2621] trial: 41, train_loss: 0.007760, test loss: 0.958170, bias2: 0.21803557872772217, variance: 0.7401347756385803\n",
      "Train size: [400] hidden size: [2621] trial: 42, train_loss: 0.007751, test loss: 0.958249, bias2: 0.21761715412139893, variance: 0.740631639957428\n",
      "Train size: [400] hidden size: [2621] trial: 43, train_loss: 0.007735, test loss: 0.957678, bias2: 0.21600675582885742, variance: 0.7416707277297974\n",
      "Train size: [400] hidden size: [2621] trial: 44, train_loss: 0.007734, test loss: 0.954146, bias2: 0.21476954221725464, variance: 0.7393761277198792\n",
      "Train size: [400] hidden size: [2621] trial: 45, train_loss: 0.007723, test loss: 0.956226, bias2: 0.21555012464523315, variance: 0.7406759858131409\n",
      "Train size: [400] hidden size: [2621] trial: 46, train_loss: 0.007740, test loss: 0.956824, bias2: 0.21492457389831543, variance: 0.7418992519378662\n",
      "Train size: [400] hidden size: [2621] trial: 47, train_loss: 0.007803, test loss: 0.956995, bias2: 0.2132347822189331, variance: 0.7437605261802673\n",
      "Train size: [400] hidden size: [2621] trial: 48, train_loss: 0.007794, test loss: 0.956406, bias2: 0.21324050426483154, variance: 0.7431653141975403\n",
      "Train size: [400] hidden size: [2621] trial: 49, train_loss: 0.007810, test loss: 0.959246, bias2: 0.21495169401168823, variance: 0.744294285774231\n",
      "##################################################\n",
      "Train size: [400] hidden size: [3017] trial: 0, train_loss: 0.006966, test loss: 0.994629, bias2: 0.9946289658546448, variance: -1.0120625226761604e-08\n",
      "Train size: [400] hidden size: [3017] trial: 1, train_loss: 0.006554, test loss: 0.938289, bias2: 0.5823904275894165, variance: 0.35589852929115295\n",
      "Train size: [400] hidden size: [3017] trial: 2, train_loss: 0.006506, test loss: 0.948061, bias2: 0.46381813287734985, variance: 0.48424267768859863\n",
      "Train size: [400] hidden size: [3017] trial: 3, train_loss: 0.006710, test loss: 0.934712, bias2: 0.39729422330856323, variance: 0.5374179482460022\n",
      "Train size: [400] hidden size: [3017] trial: 4, train_loss: 0.006728, test loss: 0.941137, bias2: 0.354458749294281, variance: 0.5866778492927551\n",
      "Train size: [400] hidden size: [3017] trial: 5, train_loss: 0.006722, test loss: 0.939368, bias2: 0.3340045213699341, variance: 0.6053639054298401\n",
      "Train size: [400] hidden size: [3017] trial: 6, train_loss: 0.006768, test loss: 0.931764, bias2: 0.30899959802627563, variance: 0.6227641105651855\n",
      "Train size: [400] hidden size: [3017] trial: 7, train_loss: 0.006764, test loss: 0.921117, bias2: 0.2942255139350891, variance: 0.6268911957740784\n",
      "Train size: [400] hidden size: [3017] trial: 8, train_loss: 0.006872, test loss: 0.920107, bias2: 0.2837832570075989, variance: 0.6363238096237183\n",
      "Train size: [400] hidden size: [3017] trial: 9, train_loss: 0.006857, test loss: 0.924347, bias2: 0.27780866622924805, variance: 0.6465383172035217\n",
      "Train size: [400] hidden size: [3017] trial: 10, train_loss: 0.006936, test loss: 0.917231, bias2: 0.26493221521377563, variance: 0.6522990465164185\n",
      "Train size: [400] hidden size: [3017] trial: 11, train_loss: 0.006839, test loss: 0.921914, bias2: 0.26272255182266235, variance: 0.6591909527778625\n",
      "Train size: [400] hidden size: [3017] trial: 12, train_loss: 0.006844, test loss: 0.925025, bias2: 0.255176842212677, variance: 0.6698479652404785\n",
      "Train size: [400] hidden size: [3017] trial: 13, train_loss: 0.006762, test loss: 0.920669, bias2: 0.25026148557662964, variance: 0.6704073548316956\n",
      "Train size: [400] hidden size: [3017] trial: 14, train_loss: 0.006822, test loss: 0.923460, bias2: 0.24400514364242554, variance: 0.6794551610946655\n",
      "Train size: [400] hidden size: [3017] trial: 15, train_loss: 0.006819, test loss: 0.922211, bias2: 0.24427306652069092, variance: 0.6779376864433289\n",
      "Train size: [400] hidden size: [3017] trial: 16, train_loss: 0.006858, test loss: 0.927693, bias2: 0.24568676948547363, variance: 0.6820064187049866\n",
      "Train size: [400] hidden size: [3017] trial: 17, train_loss: 0.006924, test loss: 0.926708, bias2: 0.24456548690795898, variance: 0.6821421980857849\n",
      "Train size: [400] hidden size: [3017] trial: 18, train_loss: 0.006903, test loss: 0.929069, bias2: 0.24443507194519043, variance: 0.6846334934234619\n",
      "Train size: [400] hidden size: [3017] trial: 19, train_loss: 0.006971, test loss: 0.929832, bias2: 0.24160635471343994, variance: 0.6882258653640747\n",
      "Train size: [400] hidden size: [3017] trial: 20, train_loss: 0.006962, test loss: 0.929484, bias2: 0.24070441722869873, variance: 0.6887792944908142\n",
      "Train size: [400] hidden size: [3017] trial: 21, train_loss: 0.006985, test loss: 0.925229, bias2: 0.23639369010925293, variance: 0.6888349652290344\n",
      "Train size: [400] hidden size: [3017] trial: 22, train_loss: 0.006994, test loss: 0.922195, bias2: 0.23339027166366577, variance: 0.6888049840927124\n",
      "Train size: [400] hidden size: [3017] trial: 23, train_loss: 0.007072, test loss: 0.919769, bias2: 0.23218882083892822, variance: 0.6875804662704468\n",
      "Train size: [400] hidden size: [3017] trial: 24, train_loss: 0.007069, test loss: 0.916523, bias2: 0.2296825647354126, variance: 0.686840832233429\n",
      "Train size: [400] hidden size: [3017] trial: 25, train_loss: 0.007101, test loss: 0.915914, bias2: 0.22680014371871948, variance: 0.6891137361526489\n",
      "Train size: [400] hidden size: [3017] trial: 26, train_loss: 0.007071, test loss: 0.915368, bias2: 0.22715389728546143, variance: 0.6882140636444092\n",
      "Train size: [400] hidden size: [3017] trial: 27, train_loss: 0.007060, test loss: 0.917159, bias2: 0.22672569751739502, variance: 0.6904330253601074\n",
      "Train size: [400] hidden size: [3017] trial: 28, train_loss: 0.007070, test loss: 0.918765, bias2: 0.22467154264450073, variance: 0.6940939426422119\n",
      "Train size: [400] hidden size: [3017] trial: 29, train_loss: 0.007015, test loss: 0.916834, bias2: 0.22556906938552856, variance: 0.6912651062011719\n",
      "Train size: [400] hidden size: [3017] trial: 30, train_loss: 0.007021, test loss: 0.918899, bias2: 0.22311502695083618, variance: 0.6957843899726868\n",
      "Train size: [400] hidden size: [3017] trial: 31, train_loss: 0.007021, test loss: 0.915089, bias2: 0.22149187326431274, variance: 0.6935966610908508\n",
      "Train size: [400] hidden size: [3017] trial: 32, train_loss: 0.007033, test loss: 0.916458, bias2: 0.21867936849594116, variance: 0.6977782845497131\n",
      "Train size: [400] hidden size: [3017] trial: 33, train_loss: 0.007028, test loss: 0.917148, bias2: 0.21988826990127563, variance: 0.697259247303009\n",
      "Train size: [400] hidden size: [3017] trial: 34, train_loss: 0.007000, test loss: 0.919024, bias2: 0.22077995538711548, variance: 0.6982440948486328\n",
      "Train size: [400] hidden size: [3017] trial: 35, train_loss: 0.006982, test loss: 0.921006, bias2: 0.22301071882247925, variance: 0.6979949474334717\n",
      "Train size: [400] hidden size: [3017] trial: 36, train_loss: 0.007028, test loss: 0.921243, bias2: 0.22042632102966309, variance: 0.7008169889450073\n",
      "Train size: [400] hidden size: [3017] trial: 37, train_loss: 0.007063, test loss: 0.921231, bias2: 0.21906638145446777, variance: 0.7021649479866028\n",
      "Train size: [400] hidden size: [3017] trial: 38, train_loss: 0.007116, test loss: 0.925906, bias2: 0.21956866979599, variance: 0.7063369750976562\n",
      "Train size: [400] hidden size: [3017] trial: 39, train_loss: 0.007113, test loss: 0.925958, bias2: 0.21949464082717896, variance: 0.7064629197120667\n",
      "Train size: [400] hidden size: [3017] trial: 40, train_loss: 0.007127, test loss: 0.928202, bias2: 0.21842718124389648, variance: 0.7097748517990112\n",
      "Train size: [400] hidden size: [3017] trial: 41, train_loss: 0.007128, test loss: 0.928120, bias2: 0.21796339750289917, variance: 0.7101565599441528\n",
      "Train size: [400] hidden size: [3017] trial: 42, train_loss: 0.007129, test loss: 0.929818, bias2: 0.21784210205078125, variance: 0.711976170539856\n",
      "Train size: [400] hidden size: [3017] trial: 43, train_loss: 0.007138, test loss: 0.929240, bias2: 0.21783751249313354, variance: 0.7114030122756958\n",
      "Train size: [400] hidden size: [3017] trial: 44, train_loss: 0.007175, test loss: 0.929856, bias2: 0.21820056438446045, variance: 0.7116559147834778\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [3017] trial: 45, train_loss: 0.007168, test loss: 0.930319, bias2: 0.2179502248764038, variance: 0.7123687267303467\n",
      "Train size: [400] hidden size: [3017] trial: 46, train_loss: 0.007130, test loss: 0.930140, bias2: 0.21862441301345825, variance: 0.7115156650543213\n",
      "Train size: [400] hidden size: [3017] trial: 47, train_loss: 0.007141, test loss: 0.929706, bias2: 0.21754562854766846, variance: 0.7121607661247253\n",
      "Train size: [400] hidden size: [3017] trial: 48, train_loss: 0.007165, test loss: 0.927396, bias2: 0.21698051691055298, variance: 0.710415244102478\n",
      "Train size: [400] hidden size: [3017] trial: 49, train_loss: 0.007157, test loss: 0.927223, bias2: 0.2160997986793518, variance: 0.711123526096344\n",
      "##################################################\n",
      "Train size: [400] hidden size: [3474] trial: 0, train_loss: 0.006084, test loss: 0.996962, bias2: 0.996962308883667, variance: 0.0\n",
      "Train size: [400] hidden size: [3474] trial: 1, train_loss: 0.005972, test loss: 0.949278, bias2: 0.5692962408065796, variance: 0.3799821436405182\n",
      "Train size: [400] hidden size: [3474] trial: 2, train_loss: 0.006691, test loss: 0.950460, bias2: 0.43397796154022217, variance: 0.516482412815094\n",
      "Train size: [400] hidden size: [3474] trial: 3, train_loss: 0.006618, test loss: 0.925255, bias2: 0.3734123706817627, variance: 0.5518425703048706\n",
      "Train size: [400] hidden size: [3474] trial: 4, train_loss: 0.006764, test loss: 0.920744, bias2: 0.3376314640045166, variance: 0.5831122994422913\n",
      "Train size: [400] hidden size: [3474] trial: 5, train_loss: 0.006773, test loss: 0.909067, bias2: 0.31426745653152466, variance: 0.5948000550270081\n",
      "Train size: [400] hidden size: [3474] trial: 6, train_loss: 0.006713, test loss: 0.896895, bias2: 0.2962711453437805, variance: 0.6006239652633667\n",
      "Train size: [400] hidden size: [3474] trial: 7, train_loss: 0.006687, test loss: 0.904850, bias2: 0.2891550064086914, variance: 0.6156952381134033\n",
      "Train size: [400] hidden size: [3474] trial: 8, train_loss: 0.006711, test loss: 0.908729, bias2: 0.2763139605522156, variance: 0.6324149966239929\n",
      "Train size: [400] hidden size: [3474] trial: 9, train_loss: 0.006705, test loss: 0.899573, bias2: 0.2649945020675659, variance: 0.6345788240432739\n",
      "Train size: [400] hidden size: [3474] trial: 10, train_loss: 0.006672, test loss: 0.895159, bias2: 0.25748109817504883, variance: 0.6376774311065674\n",
      "Train size: [400] hidden size: [3474] trial: 11, train_loss: 0.006657, test loss: 0.898043, bias2: 0.2540755867958069, variance: 0.6439673900604248\n",
      "Train size: [400] hidden size: [3474] trial: 12, train_loss: 0.006609, test loss: 0.901628, bias2: 0.25133055448532104, variance: 0.650297224521637\n",
      "Train size: [400] hidden size: [3474] trial: 13, train_loss: 0.006654, test loss: 0.904581, bias2: 0.2504844069480896, variance: 0.6540965437889099\n",
      "Train size: [400] hidden size: [3474] trial: 14, train_loss: 0.006642, test loss: 0.910741, bias2: 0.25011909008026123, variance: 0.6606221199035645\n",
      "Train size: [400] hidden size: [3474] trial: 15, train_loss: 0.006653, test loss: 0.918607, bias2: 0.2518714666366577, variance: 0.666735827922821\n",
      "Train size: [400] hidden size: [3474] trial: 16, train_loss: 0.006627, test loss: 0.916814, bias2: 0.24603581428527832, variance: 0.6707778573036194\n",
      "Train size: [400] hidden size: [3474] trial: 17, train_loss: 0.006625, test loss: 0.915108, bias2: 0.24139046669006348, variance: 0.6737175583839417\n",
      "Train size: [400] hidden size: [3474] trial: 18, train_loss: 0.006626, test loss: 0.915877, bias2: 0.239219069480896, variance: 0.6766583919525146\n",
      "Train size: [400] hidden size: [3474] trial: 19, train_loss: 0.006615, test loss: 0.912394, bias2: 0.23807525634765625, variance: 0.6743190288543701\n",
      "Train size: [400] hidden size: [3474] trial: 20, train_loss: 0.006615, test loss: 0.908301, bias2: 0.23457229137420654, variance: 0.6737282276153564\n",
      "Train size: [400] hidden size: [3474] trial: 21, train_loss: 0.006598, test loss: 0.914082, bias2: 0.23395884037017822, variance: 0.6801234483718872\n",
      "Train size: [400] hidden size: [3474] trial: 22, train_loss: 0.006588, test loss: 0.910079, bias2: 0.2308446764945984, variance: 0.6792340874671936\n",
      "Train size: [400] hidden size: [3474] trial: 23, train_loss: 0.006591, test loss: 0.906952, bias2: 0.23093944787979126, variance: 0.6760122776031494\n",
      "Train size: [400] hidden size: [3474] trial: 24, train_loss: 0.006593, test loss: 0.905077, bias2: 0.23228037357330322, variance: 0.6727969646453857\n",
      "Train size: [400] hidden size: [3474] trial: 25, train_loss: 0.006593, test loss: 0.903320, bias2: 0.2302548885345459, variance: 0.6730647087097168\n",
      "Train size: [400] hidden size: [3474] trial: 26, train_loss: 0.006599, test loss: 0.900805, bias2: 0.22885775566101074, variance: 0.6719474792480469\n",
      "Train size: [400] hidden size: [3474] trial: 27, train_loss: 0.006604, test loss: 0.898615, bias2: 0.22627264261245728, variance: 0.6723424792289734\n",
      "Train size: [400] hidden size: [3474] trial: 28, train_loss: 0.006608, test loss: 0.895848, bias2: 0.2243870496749878, variance: 0.6714609265327454\n",
      "Train size: [400] hidden size: [3474] trial: 29, train_loss: 0.006582, test loss: 0.896226, bias2: 0.22435224056243896, variance: 0.6718739867210388\n",
      "Train size: [400] hidden size: [3474] trial: 30, train_loss: 0.006584, test loss: 0.895857, bias2: 0.22389864921569824, variance: 0.6719585061073303\n",
      "Train size: [400] hidden size: [3474] trial: 31, train_loss: 0.006584, test loss: 0.895993, bias2: 0.22256207466125488, variance: 0.6734306812286377\n",
      "Train size: [400] hidden size: [3474] trial: 32, train_loss: 0.006576, test loss: 0.896785, bias2: 0.2239648699760437, variance: 0.6728201508522034\n",
      "Train size: [400] hidden size: [3474] trial: 33, train_loss: 0.006559, test loss: 0.893833, bias2: 0.22226649522781372, variance: 0.6715661287307739\n",
      "Train size: [400] hidden size: [3474] trial: 34, train_loss: 0.006600, test loss: 0.893082, bias2: 0.22026532888412476, variance: 0.6728169918060303\n",
      "Train size: [400] hidden size: [3474] trial: 35, train_loss: 0.006589, test loss: 0.893233, bias2: 0.21784371137619019, variance: 0.6753894686698914\n",
      "Train size: [400] hidden size: [3474] trial: 36, train_loss: 0.006583, test loss: 0.890185, bias2: 0.21582257747650146, variance: 0.6743627190589905\n",
      "Train size: [400] hidden size: [3474] trial: 37, train_loss: 0.006562, test loss: 0.891251, bias2: 0.217448890209198, variance: 0.6738022565841675\n",
      "Train size: [400] hidden size: [3474] trial: 38, train_loss: 0.006544, test loss: 0.890035, bias2: 0.21691495180130005, variance: 0.673120379447937\n",
      "Train size: [400] hidden size: [3474] trial: 39, train_loss: 0.006541, test loss: 0.890449, bias2: 0.21738815307617188, variance: 0.673061192035675\n",
      "Train size: [400] hidden size: [3474] trial: 40, train_loss: 0.006527, test loss: 0.890015, bias2: 0.21614795923233032, variance: 0.6738669872283936\n",
      "Train size: [400] hidden size: [3474] trial: 41, train_loss: 0.006523, test loss: 0.892197, bias2: 0.21755945682525635, variance: 0.6746378540992737\n",
      "Train size: [400] hidden size: [3474] trial: 42, train_loss: 0.006523, test loss: 0.890251, bias2: 0.21729087829589844, variance: 0.6729596853256226\n",
      "Train size: [400] hidden size: [3474] trial: 43, train_loss: 0.006521, test loss: 0.891017, bias2: 0.2172984480857849, variance: 0.6737185120582581\n",
      "Train size: [400] hidden size: [3474] trial: 44, train_loss: 0.006511, test loss: 0.891179, bias2: 0.21780872344970703, variance: 0.6733704805374146\n",
      "Train size: [400] hidden size: [3474] trial: 45, train_loss: 0.006490, test loss: 0.890619, bias2: 0.21656125783920288, variance: 0.6740577816963196\n",
      "Train size: [400] hidden size: [3474] trial: 46, train_loss: 0.006507, test loss: 0.890501, bias2: 0.21577125787734985, variance: 0.6747300028800964\n",
      "Train size: [400] hidden size: [3474] trial: 47, train_loss: 0.006514, test loss: 0.890474, bias2: 0.21685737371444702, variance: 0.6736162304878235\n",
      "Train size: [400] hidden size: [3474] trial: 48, train_loss: 0.006506, test loss: 0.891973, bias2: 0.21681922674179077, variance: 0.675153911113739\n",
      "Train size: [400] hidden size: [3474] trial: 49, train_loss: 0.006497, test loss: 0.888897, bias2: 0.21516233682632446, variance: 0.6737345457077026\n",
      "##################################################\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [4000] trial: 0, train_loss: 0.006654, test loss: 0.777261, bias2: 0.7772606611251831, variance: 1.5570191802538602e-09\n",
      "Train size: [400] hidden size: [4000] trial: 1, train_loss: 0.006576, test loss: 0.829587, bias2: 0.5062869787216187, variance: 0.32329997420310974\n",
      "Train size: [400] hidden size: [4000] trial: 2, train_loss: 0.006792, test loss: 0.865190, bias2: 0.42470088601112366, variance: 0.4404895007610321\n",
      "Train size: [400] hidden size: [4000] trial: 3, train_loss: 0.006519, test loss: 0.856875, bias2: 0.36520418524742126, variance: 0.49167075753211975\n",
      "Train size: [400] hidden size: [4000] trial: 4, train_loss: 0.006321, test loss: 0.855306, bias2: 0.33653169870376587, variance: 0.5187747478485107\n",
      "Train size: [400] hidden size: [4000] trial: 5, train_loss: 0.006251, test loss: 0.859330, bias2: 0.31334346532821655, variance: 0.5459864139556885\n",
      "Train size: [400] hidden size: [4000] trial: 6, train_loss: 0.006327, test loss: 0.865576, bias2: 0.2980840802192688, variance: 0.5674923658370972\n",
      "Train size: [400] hidden size: [4000] trial: 7, train_loss: 0.006300, test loss: 0.868489, bias2: 0.29329854249954224, variance: 0.5751908421516418\n",
      "Train size: [400] hidden size: [4000] trial: 8, train_loss: 0.006201, test loss: 0.862555, bias2: 0.2838704586029053, variance: 0.5786848664283752\n",
      "Train size: [400] hidden size: [4000] trial: 9, train_loss: 0.006102, test loss: 0.860136, bias2: 0.27865225076675415, variance: 0.5814834237098694\n",
      "Train size: [400] hidden size: [4000] trial: 10, train_loss: 0.006031, test loss: 0.857715, bias2: 0.27280300855636597, variance: 0.5849119424819946\n",
      "Train size: [400] hidden size: [4000] trial: 11, train_loss: 0.006031, test loss: 0.863498, bias2: 0.27256911993026733, variance: 0.590928852558136\n",
      "Train size: [400] hidden size: [4000] trial: 12, train_loss: 0.005970, test loss: 0.856025, bias2: 0.26237422227859497, variance: 0.5936504006385803\n",
      "Train size: [400] hidden size: [4000] trial: 13, train_loss: 0.006038, test loss: 0.856424, bias2: 0.2557385563850403, variance: 0.6006855964660645\n",
      "Train size: [400] hidden size: [4000] trial: 14, train_loss: 0.005954, test loss: 0.860297, bias2: 0.253665030002594, variance: 0.6066323518753052\n",
      "Train size: [400] hidden size: [4000] trial: 15, train_loss: 0.005958, test loss: 0.859066, bias2: 0.25425952672958374, variance: 0.604806125164032\n",
      "Train size: [400] hidden size: [4000] trial: 16, train_loss: 0.005946, test loss: 0.862872, bias2: 0.2521803379058838, variance: 0.610692024230957\n",
      "Train size: [400] hidden size: [4000] trial: 17, train_loss: 0.006043, test loss: 0.862374, bias2: 0.24336570501327515, variance: 0.619008481502533\n",
      "Train size: [400] hidden size: [4000] trial: 18, train_loss: 0.006104, test loss: 0.863393, bias2: 0.2415165901184082, variance: 0.6218767166137695\n",
      "Train size: [400] hidden size: [4000] trial: 19, train_loss: 0.006070, test loss: 0.863796, bias2: 0.24279677867889404, variance: 0.6209989786148071\n",
      "Train size: [400] hidden size: [4000] trial: 20, train_loss: 0.006051, test loss: 0.861250, bias2: 0.23832863569259644, variance: 0.622921347618103\n",
      "Train size: [400] hidden size: [4000] trial: 21, train_loss: 0.006072, test loss: 0.859018, bias2: 0.23466181755065918, variance: 0.6243565082550049\n",
      "Train size: [400] hidden size: [4000] trial: 22, train_loss: 0.006024, test loss: 0.863238, bias2: 0.23677486181259155, variance: 0.6264634728431702\n",
      "Train size: [400] hidden size: [4000] trial: 23, train_loss: 0.006020, test loss: 0.864165, bias2: 0.236619234085083, variance: 0.6275457143783569\n",
      "Train size: [400] hidden size: [4000] trial: 24, train_loss: 0.006028, test loss: 0.866654, bias2: 0.23565983772277832, variance: 0.6309940814971924\n",
      "Train size: [400] hidden size: [4000] trial: 25, train_loss: 0.006003, test loss: 0.867369, bias2: 0.23654860258102417, variance: 0.6308202743530273\n",
      "Train size: [400] hidden size: [4000] trial: 26, train_loss: 0.006006, test loss: 0.867234, bias2: 0.23601281642913818, variance: 0.6312207579612732\n",
      "Train size: [400] hidden size: [4000] trial: 27, train_loss: 0.005990, test loss: 0.868576, bias2: 0.23578625917434692, variance: 0.632790207862854\n",
      "Train size: [400] hidden size: [4000] trial: 28, train_loss: 0.005998, test loss: 0.864851, bias2: 0.2322371006011963, variance: 0.6326138973236084\n",
      "Train size: [400] hidden size: [4000] trial: 29, train_loss: 0.005989, test loss: 0.864994, bias2: 0.23352819681167603, variance: 0.6314653754234314\n",
      "Train size: [400] hidden size: [4000] trial: 30, train_loss: 0.005977, test loss: 0.864004, bias2: 0.23310941457748413, variance: 0.630894124507904\n",
      "Train size: [400] hidden size: [4000] trial: 31, train_loss: 0.005986, test loss: 0.863442, bias2: 0.23218989372253418, variance: 0.6312516331672668\n",
      "Train size: [400] hidden size: [4000] trial: 32, train_loss: 0.005986, test loss: 0.863381, bias2: 0.2313908338546753, variance: 0.6319896578788757\n",
      "Train size: [400] hidden size: [4000] trial: 33, train_loss: 0.005974, test loss: 0.863978, bias2: 0.22959530353546143, variance: 0.6343827247619629\n",
      "Train size: [400] hidden size: [4000] trial: 34, train_loss: 0.005969, test loss: 0.861647, bias2: 0.227958083152771, variance: 0.6336885690689087\n",
      "Train size: [400] hidden size: [4000] trial: 35, train_loss: 0.005953, test loss: 0.862993, bias2: 0.22949600219726562, variance: 0.6334972977638245\n",
      "Train size: [400] hidden size: [4000] trial: 36, train_loss: 0.005948, test loss: 0.862015, bias2: 0.22573840618133545, variance: 0.6362767815589905\n",
      "Train size: [400] hidden size: [4000] trial: 37, train_loss: 0.005931, test loss: 0.862308, bias2: 0.22576075792312622, variance: 0.636546790599823\n",
      "Train size: [400] hidden size: [4000] trial: 38, train_loss: 0.005933, test loss: 0.863202, bias2: 0.22570300102233887, variance: 0.6374987363815308\n",
      "Train size: [400] hidden size: [4000] trial: 39, train_loss: 0.005917, test loss: 0.863177, bias2: 0.22627484798431396, variance: 0.6369023323059082\n",
      "Train size: [400] hidden size: [4000] trial: 40, train_loss: 0.005913, test loss: 0.862942, bias2: 0.22647637128829956, variance: 0.6364659667015076\n",
      "Train size: [400] hidden size: [4000] trial: 41, train_loss: 0.005902, test loss: 0.863794, bias2: 0.22642719745635986, variance: 0.6373671293258667\n",
      "Train size: [400] hidden size: [4000] trial: 42, train_loss: 0.005901, test loss: 0.864070, bias2: 0.2269764542579651, variance: 0.6370936036109924\n",
      "Train size: [400] hidden size: [4000] trial: 43, train_loss: 0.005915, test loss: 0.863171, bias2: 0.22493994235992432, variance: 0.6382315158843994\n",
      "Train size: [400] hidden size: [4000] trial: 44, train_loss: 0.005933, test loss: 0.862982, bias2: 0.22346991300582886, variance: 0.6395124793052673\n",
      "Train size: [400] hidden size: [4000] trial: 45, train_loss: 0.005941, test loss: 0.861185, bias2: 0.22156000137329102, variance: 0.6396247148513794\n",
      "Train size: [400] hidden size: [4000] trial: 46, train_loss: 0.005933, test loss: 0.860386, bias2: 0.2215823531150818, variance: 0.6388036012649536\n",
      "Train size: [400] hidden size: [4000] trial: 47, train_loss: 0.005930, test loss: 0.860181, bias2: 0.2217143177986145, variance: 0.6384663581848145\n",
      "Train size: [400] hidden size: [4000] trial: 48, train_loss: 0.005909, test loss: 0.859888, bias2: 0.22125929594039917, variance: 0.6386282444000244\n",
      "Train size: [400] hidden size: [4000] trial: 49, train_loss: 0.005915, test loss: 0.861268, bias2: 0.22153806686401367, variance: 0.6397302150726318\n",
      "##################################################\n"
     ]
    }
   ],
   "source": [
    "run_exps_ridge(train_sizes, N_Ds, P_Ns, beta, test_size, feature_dim, num_classes, num_trials, coef,\n",
    "             outdir, 'ensembleNNK=2_output.csv', SNR= SNR, K = 2, F_norm = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "K2_df = pd.read_csv(os.path.join(outdir, 'ensembleNNK=2_output.csv'))\n",
    "K1_df = pd.read_csv(os.path.join(outdir, 'singleNN_output.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "font = {\n",
    "        'size'   : 18}\n",
    "matplotlib.rc('font', **font)\n",
    "figsize = (16, 5)\n",
    "import seaborn as sns\n",
    "sns.set_style('darkgrid')\n",
    "\n",
    "def plot_bias_var(df, N_D, ymin=0, ymax=1.0):\n",
    "    fig1, axes1 = plt.subplots(1, 3, figsize=figsize)\n",
    "    axes1[0].set_xscale('log')\n",
    "    axes1[1].set_xscale('log')\n",
    "    axes1[2].set_xscale('log')\n",
    "    cur_df = df[df['train_size']/feature_dim==N_D]\n",
    "    test_loss = cur_df['test_loss']\n",
    "    bias2 = cur_df['bias2']\n",
    "    var = cur_df['variance']\n",
    "    P_N = cur_df['hidden_size']/cur_df['train_size']\n",
    "    axes1[0].plot(P_N, test_loss)\n",
    "    axes1[0].set_xlabel(\"P/N\")\n",
    "    axes1[0].set_ylabel(\"Test Loss\")\n",
    "    axes1[0].set_ylim(ymin, ymax)\n",
    "    axes1[1].plot(P_N, bias2)\n",
    "    axes1[1].set_xlabel(\"P/N\")\n",
    "    axes1[1].set_ylabel(\"Bias Square\")\n",
    "    axes1[1].set_ylim(ymin, ymax)\n",
    "    axes1[2].plot(P_N, var)\n",
    "    axes1[2].set_xlabel(\"P/N\")\n",
    "    axes1[2].set_ylabel(\"Variance\")\n",
    "    axes1[2].set_ylim(ymin, ymax)\n",
    "    fig1.suptitle(\"Bias-Variance Decomposition (N/D={:.2f})\".format(N_D))\n",
    "    plt.show()\n",
    "def plot_single_vs_ensemble(dfs_list, Ks_list, N_D, feature_dim, ymin=0, ymax=1.0):\n",
    "    assert len(dfs_list) == len(Ks_list)\n",
    "    fig1, axes1 = plt.subplots(1, 3, figsize=figsize)\n",
    "    for i in range(3):\n",
    "        axes1[i].set_xscale('log')\n",
    "    dfs_list = [df[df['train_size']/feature_dim==N_D] for df in dfs_list]\n",
    "    for cur_df, K in zip(dfs_list, Ks_list):\n",
    "        test_loss = cur_df['test_loss']\n",
    "        bias2 = cur_df['bias2']\n",
    "        var = cur_df['variance']\n",
    "        P_N = cur_df['hidden_size']/cur_df['train_size']\n",
    "        axes1[0].plot(P_N, test_loss, label='K={}'.format(K))\n",
    "        axes1[1].plot(P_N, bias2, label='K={}'.format(K))\n",
    "        axes1[2].plot(P_N, var, label='K={}'.format(K))\n",
    "    \n",
    "    axes1[0].set_xlabel(\"P/N\")\n",
    "    axes1[0].set_ylabel(\"Test Loss\")\n",
    "    axes1[0].set_ylim(ymin, ymax)\n",
    "    \n",
    "    axes1[1].set_xlabel(\"P/N\")\n",
    "    axes1[1].set_ylabel(\"Bias Square\")\n",
    "    axes1[1].set_ylim(ymin, ymax)\n",
    "    \n",
    "    axes1[2].set_xlabel(\"P/N\")\n",
    "    axes1[2].set_ylabel(\"Variance\")\n",
    "    axes1[2].set_ylim(ymin, ymax)\n",
    "    fig1.suptitle(\"Bias-Variance Decomposition (N/D={:.2f})\".format(N_D))\n",
    "    plt.legend()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x360 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_single_vs_ensemble([K1_df, K2_df], [1, 2], N_Ds[0], feature_dim, ymax=2.0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
