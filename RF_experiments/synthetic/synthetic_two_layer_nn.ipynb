{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Feature Model on Synthetic Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "class RF_NonLinear_Model(nn.Module):\n",
    "    def __init__(self, p, d, o, coef):\n",
    "        \"\"\"RF_models\n",
    "        \n",
    "        Args:\n",
    "            p (int): the hidden size\n",
    "            d (int): the input feature dimension\n",
    "            o (int): the output dimension\n",
    "            coef (floatl): the ridge regression penalty coefficient\n",
    "        \"\"\"\n",
    "        super(RF_NonLinear_Model, self).__init__()\n",
    "\n",
    "        self.fc1 = nn.Linear(d, p, bias=False)\n",
    "        stdv = 1\n",
    "        self.fc1.weight.data.normal_(mean=0.0, std = stdv) # Gaussian initialization\n",
    "        self.fc2 = nn.Linear(p, o, bias=False)\n",
    "        self.p = p\n",
    "        self.d = d\n",
    "        self.o = o \n",
    "        self.coef = coef\n",
    "\n",
    "    def forward(self, x):\n",
    "        z = 1/np.sqrt(self.d) * F.relu(1/np.sqrt(self.d)* torch.mm(x, self.fc1.weight.data.t()))\n",
    "        out = np.sqrt(self.d) * torch.mm(self.fc2.weight.data, z.t())\n",
    "        return out.t()\n",
    "    def optimize_second_layer(self, x, y):\n",
    "        N = x.size(0)\n",
    "        z = 1/np.sqrt(self.d) * F.relu(1/np.sqrt(self.d)* torch.mm(x, self.fc1.weight.data.t()))\n",
    "        identity = torch.eye(self.p)\n",
    "        identity = identity.to(x.device)\n",
    "        beta = torch.mm(z.t(), z) + self.coef*self.p*N/(self.d**2) * identity\n",
    "        beta = torch.mm(z, torch.inverse(beta))\n",
    "        a = 1/np.sqrt(self.d) * torch.mm(y.t(), beta) \n",
    "        self.fc2.weight = torch.nn.Parameter(a)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import queue\n",
    "class Ensemble_Two_Layer_NN(object):\n",
    "    def __init__(self, n_classifiers, p, d=784, o=10, coef=1e-1):\n",
    "        \"\"\"Ensemble_Two_Layer_NN\n",
    "        \n",
    "        Args:\n",
    "            p (int): the hidden size\n",
    "            d (int, optional): the input feature dimension\n",
    "            o (int, optional): the output dimension\n",
    "            coef (float, optional): the ridge regression penalty coefficient\n",
    "        \"\"\"\n",
    "        self.n_classifiers = n_classifiers\n",
    "        self.p = p\n",
    "        self.d = d \n",
    "        self.o = o \n",
    "        self.coef = coef\n",
    "        self.learners = queue.LifoQueue(maxsize = self.n_classifiers)\n",
    "        self.MODEL_TYPE = RF_NonLinear_Model\n",
    "    def __len__(self):\n",
    "        return len(self.learners.queue)\n",
    "    \n",
    "    def train_one_classifier(self, x, y):\n",
    "        model = self.MODEL_TYPE(self.p, self.d, self.o, self.coef)\n",
    "        if x.is_cuda:\n",
    "            model.cuda()\n",
    "        rho = 1/self.n_classifiers\n",
    "        model.optimize_second_layer(x, y)\n",
    "        self.learners.put([model, rho])\n",
    "    def put_model_rho(self, model, rho):\n",
    "        self.learners.put([model, rho])\n",
    "    def get_init_model(self, cuda=True):\n",
    "        model = self.MODEL_TYPE(self.p, self.d, self.o, self.coef)\n",
    "        if cuda:\n",
    "            model.cuda()\n",
    "        return model\n",
    "    def cuda(self):\n",
    "        if len(self) == 0:\n",
    "            return \n",
    "        else:\n",
    "            for model, rho in self.learners.queue:\n",
    "                model.cuda()\n",
    "            return\n",
    "    def train(self):\n",
    "        if len(self)!=0:\n",
    "            for model, rho in self.learners.queue:\n",
    "                model.train()\n",
    "    def eval(self):\n",
    "        if len(self)!=0:\n",
    "            for model, rho in self.learners.queue:\n",
    "                model.eval()\n",
    "    def forward(self, x):\n",
    "        Bs = x.size(0)\n",
    "        if len(self) == 0:\n",
    "            zeros = torch.zeros(Bs, self.o)\n",
    "            zeros = zeros.to(x.device)\n",
    "            return zeros\n",
    "        else:\n",
    "            outputs = torch.zeros(Bs, self.o)\n",
    "            outputs = outputs.to(x.device) \n",
    "            for model, rho in self.learners.queue:\n",
    "                output = model(x)\n",
    "                outputs += rho*output\n",
    "            return outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import numpy as np\n",
    "from typing import Type, Any, Callable, Union, List, Optional\n",
    "\n",
    "def sample_true_distribution(feature_dim, output_dim, norm = 1):\n",
    "    beta = np.random.multivariate_normal(np.zeros([feature_dim]), np.eye(feature_dim)/feature_dim, \n",
    "        size=(output_dim)).T\n",
    "    beta = beta/np.linalg.norm(beta, ord=2) * norm # F norm = norm\n",
    "    beta = beta.astype('float32')\n",
    "    return beta\n",
    "def random_draw_samples(beta, feature_dim, output_dim, num_samples):\n",
    "    data = np.random.multivariate_normal(\n",
    "        np.zeros([feature_dim])  , \n",
    "        np.eye(feature_dim), \n",
    "        size=(num_samples)) #X ~ N(0,1)\n",
    "    data = data.astype('float32')\n",
    "    targets = np.matmul(data, beta)\n",
    "    targets = targets.astype('float32')\n",
    "    return data, targets\n",
    "\n",
    "def sample_nosie_to_data(data, targets, output_dim, variance):\n",
    "\n",
    "    noises = np.random.multivariate_normal(\n",
    "        np.zeros([output_dim]), \n",
    "        np.eye(output_dim)* (variance),\n",
    "        size = (len(targets)))\n",
    "    noises = noises.astype('float32')\n",
    "    return data, targets + noises\n",
    "def sample_dataset(feature_dim, output_dim, F_norm, SNR, num_samples, beta=None):\n",
    "\n",
    "    if beta is None:\n",
    "        beta = sample_true_distribution(feature_dim, output_dim, F_norm)\n",
    "    data, targets = random_draw_samples(beta, feature_dim, output_dim, num_samples)\n",
    "    if SNR !=0:\n",
    "        variance = F_norm * SNR\n",
    "        data, targets = sample_nosie_to_data(data, targets, output_dim, variance)\n",
    "    return torch.from_numpy(data), torch.from_numpy(targets)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "import copy \n",
    "\n",
    "# def get_subsample_dataset(trainset, subset):\n",
    "#     trainsubset = copy.deepcopy(trainset)\n",
    "#     trainsubset.data = [trainsubset.data[index] for index in subset]\n",
    "#     trainsubset.targets = [trainsubset.targets[index] for index in subset]\n",
    "#     return trainsubset\n",
    "def fix_width_number(width, n_classifiers):\n",
    "    return max(1, width//n_classifiers)\n",
    "\n",
    "# Training\n",
    "def train(net, train_beta, train_size, feature_dim, output_dim, F_norm, SNR):\n",
    "    net.train()\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    trainset = sample_dataset(feature_dim, output_dim, F_norm, SNR, train_size, beta = train_beta)\n",
    "    trainset = TensorDataset(*trainset)\n",
    "    trainloader = torch.utils.data.DataLoader(trainset, batch_size=len(trainset), shuffle=True)\n",
    "    trainloader = iter(trainloader)\n",
    "    inputs, targets = next(trainloader)\n",
    "    Bs = inputs.size(0)\n",
    "    inputs = inputs.reshape(Bs, -1)\n",
    "    inputs, targets = inputs.cuda(), targets.cuda()\n",
    "    for _ in range(net.n_classifiers):\n",
    "        net.train_one_classifier(inputs, targets)\n",
    "    outputs = net.forward(inputs)\n",
    "    loss = criterion(outputs, targets)\n",
    "    train_loss = loss.item() * outputs.numel()\n",
    "    total = targets.size(0)\n",
    "    return train_loss/ total\n",
    "\n",
    "# Test\n",
    "def test(net, testloader):\n",
    "    net.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs, targets) in enumerate(testloader):\n",
    "            inputs, targets = inputs.cuda(), targets.cuda()\n",
    "            Bs = inputs.size(0)\n",
    "            inputs = inputs.reshape(Bs, -1)\n",
    "            outputs = net.forward(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            test_loss += loss.item() * outputs.numel()\n",
    "            total += targets.size(0)\n",
    "    return test_loss / total\n",
    "\n",
    "def compute_bias_variance(net, testloader, trial, OUTPUST_SUM, OUTPUTS_SUMNORMSQUARED):\n",
    "    net.eval()\n",
    "    bias2 = 0\n",
    "    variance = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs, targets) in enumerate(testloader):\n",
    "            inputs, targets = inputs.cuda(), targets.cuda()\n",
    "            Bs = inputs.size(0)\n",
    "            inputs = inputs.reshape(Bs, -1)\n",
    "            outputs = net.forward(inputs)\n",
    "            OUTPUST_SUM[total:(total + targets.size(0)), :] += outputs\n",
    "            OUTPUTS_SUMNORMSQUARED[total:total + targets.size(0)] += outputs.norm(dim=1) ** 2.0\n",
    "\n",
    "            bias2 += (OUTPUST_SUM[total:total + targets.size(0), :] / (trial + 1) - targets).norm() ** 2.0\n",
    "            variance += OUTPUTS_SUMNORMSQUARED[total:total + targets.size(0)].sum()/(trial + 1) - (OUTPUST_SUM[total:total + targets.size(0), :]/(trial + 1)).norm() ** 2.0\n",
    "            total += targets.size(0)\n",
    "\n",
    "    return bias2 / total, variance / total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the synthetic dataset:\n",
    "$y=X\\beta + \\epsilon_\\mu, ||\\beta|| = F, \\epsilon_{mu} ~ \\mathcal{N}(0, 1), SNR = F/\\tau$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# class Synthetic_Dataset():\n",
    "#     def __init__(self,\n",
    "#                 feature_dim: int,\n",
    "#                 output_dim: int,\n",
    "#                 num_samples: int = 100,\n",
    "#                 seed: Optional[int] = None,\n",
    "#                 theta: Optional[np.ndarray] = None,\n",
    "#                 SNR: Optional[float] = 0.1,\n",
    "#                 )->None:\n",
    "#         \"\"\"The synthetic dataset ${(x_i, y_i)}^{n}_{i=1}$ is drawn from a distribution :\n",
    "#             $y = x^T\\beta + \\epsilon$\n",
    "#             where $\\theta$ is a weight vector, and x is an input vector whose dimension is determined by feature_dim.\n",
    "#             Weight vector $\\theta$ is drawn from Gaussian distribution $N(0, I/d)$, where d stands for feature_dim.\n",
    "#             $x$ is randomly drawn from $N(0, I)$.\n",
    "        \n",
    "#         Args:\n",
    "#             feature_dim (int): the dimensionality of input feature $x$.\n",
    "#             output_dim (int): the dimensionality of output vector $y$.\n",
    "#             train_n (int, optional): the number of samples in the training set.\n",
    "#             val_n (int, optional): the number of samples in the validation set.\n",
    "#             test_n (int, optional): the number of samples in the test set.\n",
    "#             seed (Optional, int): the random seed, if specified.\n",
    "\n",
    "#         Returns:\n",
    "#             list: a list of TensorDatast objects:[trainset, valset, testset]\n",
    "#         \"\"\"\n",
    "#         self._feature_dim = feature_dim\n",
    "#         self._output_dim = output_dim\n",
    "#         self._num_samples = num_samples\n",
    "#         self._seed = seed\n",
    "#         if self._seed is not None:\n",
    "#             assert isinstance(self._seed, int), \"Random seed must be an integer.\"\n",
    "#             np.random.seed(self._seed)\n",
    "#         if theta is None:\n",
    "#             theta = np.random.multivariate_normal(np.zeros([self._feature_dim]), np.eye(self._feature_dim)/self._feature_dim, \n",
    "#                 size=(self._output_dim)).T\n",
    "#             theta = theta/np.linalg.norm(theta, ord=2) # F norm = 1\n",
    "#             theta = theta.astype('float32')\n",
    "#         self._theta = theta\n",
    "#         self.SNR = SNR\n",
    "#         self.data, self.targets = self.random_draw(self._num_samples)\n",
    "#     @property\n",
    "#     def theta(self):\n",
    "#         return self._theta\n",
    "    \n",
    "#     def __getitem__(self, index):\n",
    "#         return self.data[index], self.targets[index]\n",
    "#     def __len__(self):\n",
    "#         return len(self.data)\n",
    "\n",
    "#     def random_draw(self, num_samples):\n",
    "#         data = np.random.multivariate_normal(\n",
    "#             np.zeros([self._feature_dim])  , \n",
    "#             np.eye(self._feature_dim), \n",
    "#             size=(num_samples)) #X ~ N(0,1)\n",
    "#         data = data.astype('float32')\n",
    "#         targets = np.matmul(data, self._theta)\n",
    "#         targets = targets.astype('float32')\n",
    "\n",
    "#         noises = np.random.multivariate_normal(\n",
    "#             np.zeros([self._output_dim]), \n",
    "#             np.eye(self._output_dim)* (self.SNR ),\n",
    "#             size = (num_samples))\n",
    "#         noises = noises.astype('float32')\n",
    "#         return torch.from_numpy(data+noises), torch.from_numpy(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "feature_dim = 400\n",
    "num_classes = 1\n",
    "SNR = 1\n",
    "test_size = 10000\n",
    "beta = sample_true_distribution(feature_dim, num_classes, norm = 1)\n",
    "#trainset = Synthetic_Dataset(feature_dim=feature_dim, output_dim=1, num_samples=50000, seed=10, SNR = SNR)\n",
    "testset = sample_dataset(feature_dim, num_classes, F_norm = 1, SNR =0., num_samples=test_size, beta = beta)\n",
    "testset = TensorDataset(*testset)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=100, shuffle=False, num_workers=4)\n",
    "# loss definition\n",
    "criterion = nn.MSELoss(reduction='mean').cuda()\n",
    "\n",
    "num_trials = 50\n",
    "coef = 0.1\n",
    "N_Ds = [1]\n",
    "train_sizes = [int(np.around(x*feature_dim)) for x in N_Ds]\n",
    "\n",
    "P_Ns = 10** np.linspace(-2, 1, 50)\n",
    "\n",
    "outdir = 'synthetic_coef_{}'.format(coef)\n",
    "if not os.path.exists(outdir):\n",
    "    os.makedirs(outdir)\n",
    "\n",
    "def run_exps_ridge(train_sizes, N_Ds, P_Ns, train_beta, test_size, feature_dim, num_classes, num_trials, coef,\n",
    "             outdir, save_csv, SNR, K = 1, F_norm= 1):\n",
    "    df = pd.DataFrame()\n",
    "    # When training single NN\n",
    "    for train_size in train_sizes:\n",
    "        hidden_sizes = P_Ns * train_size\n",
    "        hidden_sizes = np.unique([int(np.around(x)) for x in hidden_sizes])\n",
    "        for hidden_size in hidden_sizes:\n",
    "            TRAIN_LOSS_SUM = 0.0\n",
    "            TEST_LOSS_SUM = 0.0\n",
    "            #permute_index = np.random.permutation(len(trainset))\n",
    "            OUTPUST_SUM = torch.Tensor(test_size, num_classes).zero_().cuda()\n",
    "            OUTPUTS_SUMNORMSQUARED = torch.Tensor(test_size).zero_().cuda()\n",
    "            for trial in range(num_trials):\n",
    "                net = Ensemble_Two_Layer_NN(n_classifiers = K, p = fix_width_number(hidden_size, K), d=feature_dim, o=num_classes, coef=coef)\n",
    "                net.cuda()\n",
    "                train_loss = train(net, train_beta, train_size, feature_dim, num_classes, F_norm, SNR)\n",
    "                test_loss = test(net, testloader)\n",
    "\n",
    "                TRAIN_LOSS_SUM += train_loss\n",
    "                TEST_LOSS_SUM += test_loss\n",
    "\n",
    "                # compute bias and variance\n",
    "                bias2, variance = compute_bias_variance(net, testloader, trial, OUTPUST_SUM, OUTPUTS_SUMNORMSQUARED)\n",
    "                variance_unbias = variance * num_trials / (num_trials - 1.0)\n",
    "                bias2_unbias = TEST_LOSS_SUM / (trial + 1) - variance_unbias\n",
    "                print('Train size: [{}] hidden size: [{}] trial: {}, train_loss: {:.6f}, test loss: {:.6f}, bias2: {}, variance: {}'.format(\n",
    "                    train_size, hidden_size,\n",
    "                    trial, TRAIN_LOSS_SUM / (trial + 1),  TEST_LOSS_SUM / (trial + 1),\n",
    "                    bias2_unbias, variance_unbias))\n",
    "                torch.cuda.empty_cache()\n",
    "            print('#'*50)\n",
    "            df = df.append({'train_size': train_size, 'hidden_size':hidden_size, \n",
    "                            'train_loss': TRAIN_LOSS_SUM / (trial + 1), \n",
    "                            'test_loss': TEST_LOSS_SUM / (trial + 1), \n",
    "                           'variance': variance_unbias.item(),\n",
    "                           'bias2': bias2_unbias.item()}, ignore_index=True)\n",
    "            df.to_csv(os.path.join(outdir, save_csv))\n",
    "    df.to_csv(os.path.join(outdir, save_csv))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [4] trial: 0, train_loss: 1.873188, test loss: 1.010338, bias2: 1.0103384256362915, variance: -1.2164212345733283e-11\n",
      "Train size: [400] hidden size: [4] trial: 1, train_loss: 1.872133, test loss: 1.013576, bias2: 1.0052107572555542, variance: 0.008365447632968426\n",
      "Train size: [400] hidden size: [4] trial: 2, train_loss: 1.933110, test loss: 1.015678, bias2: 1.006278157234192, variance: 0.00939978752285242\n",
      "Train size: [400] hidden size: [4] trial: 3, train_loss: 1.922342, test loss: 1.019024, bias2: 1.00632643699646, variance: 0.01269767340272665\n",
      "Train size: [400] hidden size: [4] trial: 4, train_loss: 1.953800, test loss: 1.022892, bias2: 1.008689522743225, variance: 0.014202233403921127\n",
      "Train size: [400] hidden size: [4] trial: 5, train_loss: 1.954054, test loss: 1.033255, bias2: 1.0084874629974365, variance: 0.02476736716926098\n",
      "Train size: [400] hidden size: [4] trial: 6, train_loss: 1.957506, test loss: 1.051093, bias2: 1.0047799348831177, variance: 0.046312619000673294\n",
      "Train size: [400] hidden size: [4] trial: 7, train_loss: 1.949019, test loss: 1.047775, bias2: 1.0040162801742554, variance: 0.043758463114500046\n",
      "Train size: [400] hidden size: [4] trial: 8, train_loss: 1.947344, test loss: 1.042013, bias2: 1.000745177268982, variance: 0.041267503052949905\n",
      "Train size: [400] hidden size: [4] trial: 9, train_loss: 1.956620, test loss: 1.040976, bias2: 1.0008305311203003, variance: 0.04014573618769646\n",
      "Train size: [400] hidden size: [4] trial: 10, train_loss: 1.969985, test loss: 1.038685, bias2: 1.0007240772247314, variance: 0.03796137124300003\n",
      "Train size: [400] hidden size: [4] trial: 11, train_loss: 1.960080, test loss: 1.037440, bias2: 0.9990932941436768, variance: 0.038346316665410995\n",
      "Train size: [400] hidden size: [4] trial: 12, train_loss: 1.947370, test loss: 1.036872, bias2: 0.9991185069084167, variance: 0.03775341436266899\n",
      "Train size: [400] hidden size: [4] trial: 13, train_loss: 1.944265, test loss: 1.035509, bias2: 0.9981653690338135, variance: 0.03734312579035759\n",
      "Train size: [400] hidden size: [4] trial: 14, train_loss: 1.935803, test loss: 1.033709, bias2: 0.9972842931747437, variance: 0.036424897611141205\n",
      "Train size: [400] hidden size: [4] trial: 15, train_loss: 1.941862, test loss: 1.034710, bias2: 0.9953107833862305, variance: 0.03939928859472275\n",
      "Train size: [400] hidden size: [4] trial: 16, train_loss: 1.934501, test loss: 1.032069, bias2: 0.9925203919410706, variance: 0.03954823687672615\n",
      "Train size: [400] hidden size: [4] trial: 17, train_loss: 1.947449, test loss: 1.031469, bias2: 0.9931572675704956, variance: 0.03831150382757187\n",
      "Train size: [400] hidden size: [4] trial: 18, train_loss: 1.938197, test loss: 1.032130, bias2: 0.989767849445343, variance: 0.042362410575151443\n",
      "Train size: [400] hidden size: [4] trial: 19, train_loss: 1.938451, test loss: 1.031252, bias2: 0.9906092882156372, variance: 0.040643006563186646\n",
      "Train size: [400] hidden size: [4] trial: 20, train_loss: 1.942068, test loss: 1.031915, bias2: 0.9919036626815796, variance: 0.040011752396821976\n",
      "Train size: [400] hidden size: [4] trial: 21, train_loss: 1.947082, test loss: 1.030506, bias2: 0.9909691214561462, variance: 0.03953655809164047\n",
      "Train size: [400] hidden size: [4] trial: 22, train_loss: 1.936925, test loss: 1.030275, bias2: 0.9908740520477295, variance: 0.03940096125006676\n",
      "Train size: [400] hidden size: [4] trial: 23, train_loss: 1.930643, test loss: 1.029754, bias2: 0.9906335473060608, variance: 0.03912051394581795\n",
      "Train size: [400] hidden size: [4] trial: 24, train_loss: 1.933659, test loss: 1.029031, bias2: 0.9907742738723755, variance: 0.03825712203979492\n",
      "Train size: [400] hidden size: [4] trial: 25, train_loss: 1.929699, test loss: 1.027905, bias2: 0.9903075098991394, variance: 0.03759785741567612\n",
      "Train size: [400] hidden size: [4] trial: 26, train_loss: 1.927730, test loss: 1.028444, bias2: 0.9902822375297546, variance: 0.03816124424338341\n",
      "Train size: [400] hidden size: [4] trial: 27, train_loss: 1.926939, test loss: 1.027655, bias2: 0.9904375672340393, variance: 0.037217769771814346\n",
      "Train size: [400] hidden size: [4] trial: 28, train_loss: 1.927394, test loss: 1.027016, bias2: 0.9907970428466797, variance: 0.03621898218989372\n",
      "Train size: [400] hidden size: [4] trial: 29, train_loss: 1.936129, test loss: 1.026823, bias2: 0.9911959171295166, variance: 0.03562739118933678\n",
      "Train size: [400] hidden size: [4] trial: 30, train_loss: 1.941924, test loss: 1.026327, bias2: 0.9912310242652893, variance: 0.03509586676955223\n",
      "Train size: [400] hidden size: [4] trial: 31, train_loss: 1.940421, test loss: 1.026471, bias2: 0.9912662506103516, variance: 0.03520441800355911\n",
      "Train size: [400] hidden size: [4] trial: 32, train_loss: 1.936380, test loss: 1.025628, bias2: 0.9912052154541016, variance: 0.03442249819636345\n",
      "Train size: [400] hidden size: [4] trial: 33, train_loss: 1.943619, test loss: 1.025129, bias2: 0.9915892481803894, variance: 0.03353957459330559\n",
      "Train size: [400] hidden size: [4] trial: 34, train_loss: 1.944263, test loss: 1.025006, bias2: 0.9912246465682983, variance: 0.03378155454993248\n",
      "Train size: [400] hidden size: [4] trial: 35, train_loss: 1.947157, test loss: 1.024959, bias2: 0.9916272759437561, variance: 0.033331308513879776\n",
      "Train size: [400] hidden size: [4] trial: 36, train_loss: 1.944122, test loss: 1.024584, bias2: 0.9915662407875061, variance: 0.033018190413713455\n",
      "Train size: [400] hidden size: [4] trial: 37, train_loss: 1.939607, test loss: 1.024825, bias2: 0.9921706914901733, variance: 0.03265415504574776\n",
      "Train size: [400] hidden size: [4] trial: 38, train_loss: 1.945316, test loss: 1.024332, bias2: 0.9922442436218262, variance: 0.0320875383913517\n",
      "Train size: [400] hidden size: [4] trial: 39, train_loss: 1.947554, test loss: 1.024148, bias2: 0.9921339154243469, variance: 0.03201454505324364\n",
      "Train size: [400] hidden size: [4] trial: 40, train_loss: 1.947133, test loss: 1.023602, bias2: 0.9921011924743652, variance: 0.03150031343102455\n",
      "Train size: [400] hidden size: [4] trial: 41, train_loss: 1.941550, test loss: 1.023524, bias2: 0.9924390316009521, variance: 0.03108503296971321\n",
      "Train size: [400] hidden size: [4] trial: 42, train_loss: 1.940576, test loss: 1.023368, bias2: 0.9928467273712158, variance: 0.03052125684916973\n",
      "Train size: [400] hidden size: [4] trial: 43, train_loss: 1.946005, test loss: 1.023363, bias2: 0.9931210875511169, variance: 0.030242010951042175\n",
      "Train size: [400] hidden size: [4] trial: 44, train_loss: 1.947183, test loss: 1.024229, bias2: 0.993152916431427, variance: 0.03107577934861183\n",
      "Train size: [400] hidden size: [4] trial: 45, train_loss: 1.944058, test loss: 1.024285, bias2: 0.9936301708221436, variance: 0.030655261129140854\n",
      "Train size: [400] hidden size: [4] trial: 46, train_loss: 1.944124, test loss: 1.024526, bias2: 0.9939743876457214, variance: 0.03055182471871376\n",
      "Train size: [400] hidden size: [4] trial: 47, train_loss: 1.939293, test loss: 1.024508, bias2: 0.9942803382873535, variance: 0.030227765440940857\n",
      "Train size: [400] hidden size: [4] trial: 48, train_loss: 1.938306, test loss: 1.024330, bias2: 0.9944084882736206, variance: 0.029921194538474083\n",
      "Train size: [400] hidden size: [4] trial: 49, train_loss: 1.936679, test loss: 1.024180, bias2: 0.9944340586662292, variance: 0.029745986685156822\n",
      "##################################################\n",
      "Train size: [400] hidden size: [5] trial: 0, train_loss: 2.226363, test loss: 1.013389, bias2: 1.013388991355896, variance: 2.7977689609492984e-10\n",
      "Train size: [400] hidden size: [5] trial: 1, train_loss: 2.054454, test loss: 1.011871, bias2: 1.0006966590881348, variance: 0.011174274608492851\n",
      "Train size: [400] hidden size: [5] trial: 2, train_loss: 2.014141, test loss: 1.013991, bias2: 1.0001622438430786, variance: 0.013829264789819717\n",
      "Train size: [400] hidden size: [5] trial: 3, train_loss: 2.059222, test loss: 1.010570, bias2: 0.9910808205604553, variance: 0.019488617777824402\n",
      "Train size: [400] hidden size: [5] trial: 4, train_loss: 2.107990, test loss: 1.016275, bias2: 0.9934219717979431, variance: 0.022852715104818344\n",
      "Train size: [400] hidden size: [5] trial: 5, train_loss: 2.096219, test loss: 1.018048, bias2: 0.995384931564331, variance: 0.022663380950689316\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [5] trial: 6, train_loss: 2.079584, test loss: 1.016961, bias2: 0.9929576516151428, variance: 0.024003690108656883\n",
      "Train size: [400] hidden size: [5] trial: 7, train_loss: 2.052676, test loss: 1.017833, bias2: 0.9923009872436523, variance: 0.025532495230436325\n",
      "Train size: [400] hidden size: [5] trial: 8, train_loss: 2.025000, test loss: 1.016222, bias2: 0.9916982054710388, variance: 0.024523913860321045\n",
      "Train size: [400] hidden size: [5] trial: 9, train_loss: 2.025075, test loss: 1.015962, bias2: 0.9922941327095032, variance: 0.023667994886636734\n",
      "Train size: [400] hidden size: [5] trial: 10, train_loss: 2.016794, test loss: 1.014742, bias2: 0.9913386106491089, variance: 0.023403288796544075\n",
      "Train size: [400] hidden size: [5] trial: 11, train_loss: 2.005108, test loss: 1.018529, bias2: 0.9930344820022583, variance: 0.02549406886100769\n",
      "Train size: [400] hidden size: [5] trial: 12, train_loss: 2.024300, test loss: 1.023911, bias2: 0.9914436936378479, variance: 0.03246694058179855\n",
      "Train size: [400] hidden size: [5] trial: 13, train_loss: 2.033522, test loss: 1.024297, bias2: 0.992138683795929, variance: 0.03215830773115158\n",
      "Train size: [400] hidden size: [5] trial: 14, train_loss: 2.026415, test loss: 1.024716, bias2: 0.9915401339530945, variance: 0.03317589685320854\n",
      "Train size: [400] hidden size: [5] trial: 15, train_loss: 2.016689, test loss: 1.027385, bias2: 0.9933713674545288, variance: 0.03401317447423935\n",
      "Train size: [400] hidden size: [5] trial: 16, train_loss: 2.010104, test loss: 1.025156, bias2: 0.9916330575942993, variance: 0.0335225947201252\n",
      "Train size: [400] hidden size: [5] trial: 17, train_loss: 2.010625, test loss: 1.025473, bias2: 0.9927518367767334, variance: 0.032720692455768585\n",
      "Train size: [400] hidden size: [5] trial: 18, train_loss: 2.015162, test loss: 1.025279, bias2: 0.9912569522857666, variance: 0.03402223438024521\n",
      "Train size: [400] hidden size: [5] trial: 19, train_loss: 2.009836, test loss: 1.024663, bias2: 0.9897598624229431, variance: 0.03490360081195831\n",
      "Train size: [400] hidden size: [5] trial: 20, train_loss: 2.008490, test loss: 1.024905, bias2: 0.9903706312179565, variance: 0.034534793347120285\n",
      "Train size: [400] hidden size: [5] trial: 21, train_loss: 2.006432, test loss: 1.026129, bias2: 0.9900898337364197, variance: 0.03603951632976532\n",
      "Train size: [400] hidden size: [5] trial: 22, train_loss: 2.005919, test loss: 1.025242, bias2: 0.9902485013008118, variance: 0.03499394282698631\n",
      "Train size: [400] hidden size: [5] trial: 23, train_loss: 2.010724, test loss: 1.025424, bias2: 0.990653932094574, variance: 0.03476971760392189\n",
      "Train size: [400] hidden size: [5] trial: 24, train_loss: 2.005346, test loss: 1.024543, bias2: 0.9901394844055176, variance: 0.03440353646874428\n",
      "Train size: [400] hidden size: [5] trial: 25, train_loss: 2.019299, test loss: 1.025624, bias2: 0.9910426139831543, variance: 0.03458166867494583\n",
      "Train size: [400] hidden size: [5] trial: 26, train_loss: 2.022299, test loss: 1.024542, bias2: 0.9905229806900024, variance: 0.03401949256658554\n",
      "Train size: [400] hidden size: [5] trial: 27, train_loss: 2.030051, test loss: 1.024195, bias2: 0.9901334643363953, variance: 0.0340617410838604\n",
      "Train size: [400] hidden size: [5] trial: 28, train_loss: 2.021545, test loss: 1.025089, bias2: 0.9900795817375183, variance: 0.035009805113077164\n",
      "Train size: [400] hidden size: [5] trial: 29, train_loss: 2.023084, test loss: 1.024357, bias2: 0.9901372194290161, variance: 0.03421963378787041\n",
      "Train size: [400] hidden size: [5] trial: 30, train_loss: 2.021035, test loss: 1.024412, bias2: 0.9906080365180969, variance: 0.03380436822772026\n",
      "Train size: [400] hidden size: [5] trial: 31, train_loss: 2.027501, test loss: 1.023777, bias2: 0.9907737970352173, variance: 0.033003468066453934\n",
      "Train size: [400] hidden size: [5] trial: 32, train_loss: 2.025973, test loss: 1.023299, bias2: 0.99091637134552, variance: 0.03238258138298988\n",
      "Train size: [400] hidden size: [5] trial: 33, train_loss: 2.024137, test loss: 1.023101, bias2: 0.9900916218757629, variance: 0.03300924599170685\n",
      "Train size: [400] hidden size: [5] trial: 34, train_loss: 2.026259, test loss: 1.022931, bias2: 0.9901386499404907, variance: 0.032792240381240845\n",
      "Train size: [400] hidden size: [5] trial: 35, train_loss: 2.026702, test loss: 1.022873, bias2: 0.9900621771812439, variance: 0.032810721546411514\n",
      "Train size: [400] hidden size: [5] trial: 36, train_loss: 2.019771, test loss: 1.022463, bias2: 0.9904111623764038, variance: 0.03205215930938721\n",
      "Train size: [400] hidden size: [5] trial: 37, train_loss: 2.017247, test loss: 1.022217, bias2: 0.9904810190200806, variance: 0.03173555061221123\n",
      "Train size: [400] hidden size: [5] trial: 38, train_loss: 2.009405, test loss: 1.022006, bias2: 0.990341305732727, variance: 0.03166482225060463\n",
      "Train size: [400] hidden size: [5] trial: 39, train_loss: 2.006558, test loss: 1.021888, bias2: 0.9903217554092407, variance: 0.03156639635562897\n",
      "Train size: [400] hidden size: [5] trial: 40, train_loss: 2.004822, test loss: 1.022370, bias2: 0.9902299046516418, variance: 0.03214041143655777\n",
      "Train size: [400] hidden size: [5] trial: 41, train_loss: 2.005505, test loss: 1.022014, bias2: 0.9903252720832825, variance: 0.031688980758190155\n",
      "Train size: [400] hidden size: [5] trial: 42, train_loss: 2.002739, test loss: 1.021799, bias2: 0.99006587266922, variance: 0.03173309937119484\n",
      "Train size: [400] hidden size: [5] trial: 43, train_loss: 1.994117, test loss: 1.021356, bias2: 0.9899325370788574, variance: 0.03142367675900459\n",
      "Train size: [400] hidden size: [5] trial: 44, train_loss: 1.991738, test loss: 1.021198, bias2: 0.989936113357544, variance: 0.031261950731277466\n",
      "Train size: [400] hidden size: [5] trial: 45, train_loss: 1.989930, test loss: 1.021689, bias2: 0.9900575280189514, variance: 0.03163152560591698\n",
      "Train size: [400] hidden size: [5] trial: 46, train_loss: 1.989104, test loss: 1.021369, bias2: 0.989916980266571, variance: 0.031452253460884094\n",
      "Train size: [400] hidden size: [5] trial: 47, train_loss: 1.990088, test loss: 1.021560, bias2: 0.9898761510848999, variance: 0.03168405219912529\n",
      "Train size: [400] hidden size: [5] trial: 48, train_loss: 1.992258, test loss: 1.021429, bias2: 0.9897820949554443, variance: 0.03164646029472351\n",
      "Train size: [400] hidden size: [5] trial: 49, train_loss: 1.995553, test loss: 1.021042, bias2: 0.9888545274734497, variance: 0.03218759596347809\n",
      "##################################################\n",
      "Train size: [400] hidden size: [6] trial: 0, train_loss: 1.915273, test loss: 1.059013, bias2: 1.0590132474899292, variance: 9.731369876586626e-11\n",
      "Train size: [400] hidden size: [6] trial: 1, train_loss: 1.935711, test loss: 1.033417, bias2: 1.0147738456726074, variance: 0.018643587827682495\n",
      "Train size: [400] hidden size: [6] trial: 2, train_loss: 2.028959, test loss: 1.032625, bias2: 1.0075432062149048, variance: 0.025082213804125786\n",
      "Train size: [400] hidden size: [6] trial: 3, train_loss: 2.015089, test loss: 1.031567, bias2: 1.0007309913635254, variance: 0.03083563782274723\n",
      "Train size: [400] hidden size: [6] trial: 4, train_loss: 2.024119, test loss: 1.033340, bias2: 1.0012922286987305, variance: 0.03204740583896637\n",
      "Train size: [400] hidden size: [6] trial: 5, train_loss: 2.031366, test loss: 1.030061, bias2: 1.0004637241363525, variance: 0.029597654938697815\n",
      "Train size: [400] hidden size: [6] trial: 6, train_loss: 2.021753, test loss: 1.030348, bias2: 1.0003113746643066, variance: 0.0300366822630167\n",
      "Train size: [400] hidden size: [6] trial: 7, train_loss: 2.017265, test loss: 1.028371, bias2: 0.9994354844093323, variance: 0.028935251757502556\n",
      "Train size: [400] hidden size: [6] trial: 8, train_loss: 2.033426, test loss: 1.025975, bias2: 0.9927780628204346, variance: 0.033196695148944855\n",
      "Train size: [400] hidden size: [6] trial: 9, train_loss: 2.038508, test loss: 1.025454, bias2: 0.9933242797851562, variance: 0.032129496335983276\n",
      "Train size: [400] hidden size: [6] trial: 10, train_loss: 2.039393, test loss: 1.027586, bias2: 0.9906150698661804, variance: 0.036970797926187515\n",
      "Train size: [400] hidden size: [6] trial: 11, train_loss: 2.020814, test loss: 1.027713, bias2: 0.9900428056716919, variance: 0.037670016288757324\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [6] trial: 12, train_loss: 2.024855, test loss: 1.027278, bias2: 0.9895469546318054, variance: 0.037730872631073\n",
      "Train size: [400] hidden size: [6] trial: 13, train_loss: 2.008937, test loss: 1.029316, bias2: 0.9904427528381348, variance: 0.03887283056974411\n",
      "Train size: [400] hidden size: [6] trial: 14, train_loss: 2.007208, test loss: 1.031327, bias2: 0.9913281202316284, variance: 0.039998866617679596\n",
      "Train size: [400] hidden size: [6] trial: 15, train_loss: 2.012604, test loss: 1.033236, bias2: 0.9917299747467041, variance: 0.041505783796310425\n",
      "Train size: [400] hidden size: [6] trial: 16, train_loss: 2.019094, test loss: 1.033535, bias2: 0.993302047252655, variance: 0.04023308679461479\n",
      "Train size: [400] hidden size: [6] trial: 17, train_loss: 2.018945, test loss: 1.033127, bias2: 0.9941985607147217, variance: 0.03892827406525612\n",
      "Train size: [400] hidden size: [6] trial: 18, train_loss: 2.018125, test loss: 1.033093, bias2: 0.9934868812561035, variance: 0.03960574418306351\n",
      "Train size: [400] hidden size: [6] trial: 19, train_loss: 2.017591, test loss: 1.032304, bias2: 0.9935507774353027, variance: 0.03875303268432617\n",
      "Train size: [400] hidden size: [6] trial: 20, train_loss: 2.010609, test loss: 1.031593, bias2: 0.9920737743377686, variance: 0.03951966017484665\n",
      "Train size: [400] hidden size: [6] trial: 21, train_loss: 2.015582, test loss: 1.030997, bias2: 0.9919404983520508, variance: 0.039057016372680664\n",
      "Train size: [400] hidden size: [6] trial: 22, train_loss: 2.021338, test loss: 1.030328, bias2: 0.992416262626648, variance: 0.03791152685880661\n",
      "Train size: [400] hidden size: [6] trial: 23, train_loss: 2.016483, test loss: 1.029867, bias2: 0.9924145936965942, variance: 0.03745267167687416\n",
      "Train size: [400] hidden size: [6] trial: 24, train_loss: 2.004359, test loss: 1.029417, bias2: 0.9928684234619141, variance: 0.03654906526207924\n",
      "Train size: [400] hidden size: [6] trial: 25, train_loss: 2.006753, test loss: 1.028758, bias2: 0.9916259050369263, variance: 0.0371326245367527\n",
      "Train size: [400] hidden size: [6] trial: 26, train_loss: 2.010313, test loss: 1.028274, bias2: 0.991367518901825, variance: 0.03690655156970024\n",
      "Train size: [400] hidden size: [6] trial: 27, train_loss: 2.004319, test loss: 1.028543, bias2: 0.9917561411857605, variance: 0.03678683191537857\n",
      "Train size: [400] hidden size: [6] trial: 28, train_loss: 1.997626, test loss: 1.028266, bias2: 0.9915940761566162, variance: 0.036671653389930725\n",
      "Train size: [400] hidden size: [6] trial: 29, train_loss: 1.992707, test loss: 1.028509, bias2: 0.9918403625488281, variance: 0.03666901960968971\n",
      "Train size: [400] hidden size: [6] trial: 30, train_loss: 1.993782, test loss: 1.028236, bias2: 0.9921475052833557, variance: 0.03608878701925278\n",
      "Train size: [400] hidden size: [6] trial: 31, train_loss: 1.994818, test loss: 1.027561, bias2: 0.99187171459198, variance: 0.03568971902132034\n",
      "Train size: [400] hidden size: [6] trial: 32, train_loss: 2.002082, test loss: 1.027112, bias2: 0.9921461343765259, variance: 0.0349661223590374\n",
      "Train size: [400] hidden size: [6] trial: 33, train_loss: 1.997044, test loss: 1.026974, bias2: 0.9918535947799683, variance: 0.03512025624513626\n",
      "Train size: [400] hidden size: [6] trial: 34, train_loss: 1.997054, test loss: 1.026657, bias2: 0.9911876320838928, variance: 0.03546970337629318\n",
      "Train size: [400] hidden size: [6] trial: 35, train_loss: 1.994784, test loss: 1.027960, bias2: 0.9911948442459106, variance: 0.036765240132808685\n",
      "Train size: [400] hidden size: [6] trial: 36, train_loss: 1.988536, test loss: 1.028087, bias2: 0.9915697574615479, variance: 0.036517489701509476\n",
      "Train size: [400] hidden size: [6] trial: 37, train_loss: 1.982282, test loss: 1.028873, bias2: 0.9921894669532776, variance: 0.03668315336108208\n",
      "Train size: [400] hidden size: [6] trial: 38, train_loss: 1.988236, test loss: 1.029160, bias2: 0.9918819069862366, variance: 0.037278588861227036\n",
      "Train size: [400] hidden size: [6] trial: 39, train_loss: 1.986201, test loss: 1.029189, bias2: 0.9919163584709167, variance: 0.037272755056619644\n",
      "Train size: [400] hidden size: [6] trial: 40, train_loss: 1.985421, test loss: 1.028808, bias2: 0.9922691583633423, variance: 0.036538947373628616\n",
      "Train size: [400] hidden size: [6] trial: 41, train_loss: 1.985851, test loss: 1.028423, bias2: 0.9921875596046448, variance: 0.03623576834797859\n",
      "Train size: [400] hidden size: [6] trial: 42, train_loss: 1.991108, test loss: 1.027734, bias2: 0.9914951920509338, variance: 0.03623909503221512\n",
      "Train size: [400] hidden size: [6] trial: 43, train_loss: 1.988394, test loss: 1.027881, bias2: 0.9913910627365112, variance: 0.03649007901549339\n",
      "Train size: [400] hidden size: [6] trial: 44, train_loss: 1.981258, test loss: 1.027746, bias2: 0.9916327595710754, variance: 0.03611283004283905\n",
      "Train size: [400] hidden size: [6] trial: 45, train_loss: 1.987731, test loss: 1.027403, bias2: 0.9914624691009521, variance: 0.035940997302532196\n",
      "Train size: [400] hidden size: [6] trial: 46, train_loss: 1.989690, test loss: 1.028106, bias2: 0.9908992052078247, variance: 0.0372069887816906\n",
      "Train size: [400] hidden size: [6] trial: 47, train_loss: 1.988824, test loss: 1.028617, bias2: 0.991025447845459, variance: 0.03759179264307022\n",
      "Train size: [400] hidden size: [6] trial: 48, train_loss: 1.989461, test loss: 1.028314, bias2: 0.9898784160614014, variance: 0.038435447961091995\n",
      "Train size: [400] hidden size: [6] trial: 49, train_loss: 1.989406, test loss: 1.027941, bias2: 0.9900137186050415, variance: 0.037927646189928055\n",
      "##################################################\n",
      "Train size: [400] hidden size: [7] trial: 0, train_loss: 2.018064, test loss: 1.022247, bias2: 1.0222468376159668, variance: -2.2503794661066223e-10\n",
      "Train size: [400] hidden size: [7] trial: 1, train_loss: 1.937378, test loss: 1.029548, bias2: 1.0124176740646362, variance: 0.017130276188254356\n",
      "Train size: [400] hidden size: [7] trial: 2, train_loss: 1.925715, test loss: 1.030103, bias2: 1.0020036697387695, variance: 0.0280997846275568\n",
      "Train size: [400] hidden size: [7] trial: 3, train_loss: 1.953007, test loss: 1.034711, bias2: 0.9984031319618225, variance: 0.03630772978067398\n",
      "Train size: [400] hidden size: [7] trial: 4, train_loss: 1.945806, test loss: 1.033681, bias2: 0.9958374500274658, variance: 0.03784323111176491\n",
      "Train size: [400] hidden size: [7] trial: 5, train_loss: 1.927855, test loss: 1.031893, bias2: 0.9933647513389587, variance: 0.038527894765138626\n",
      "Train size: [400] hidden size: [7] trial: 6, train_loss: 1.930522, test loss: 1.029722, bias2: 0.9895458817481995, variance: 0.04017595946788788\n",
      "Train size: [400] hidden size: [7] trial: 7, train_loss: 1.949381, test loss: 1.028008, bias2: 0.9845218062400818, variance: 0.04348663240671158\n",
      "Train size: [400] hidden size: [7] trial: 8, train_loss: 1.979530, test loss: 1.031048, bias2: 0.9866530895233154, variance: 0.0443946048617363\n",
      "Train size: [400] hidden size: [7] trial: 9, train_loss: 1.978465, test loss: 1.028588, bias2: 0.9867832064628601, variance: 0.0418047159910202\n",
      "Train size: [400] hidden size: [7] trial: 10, train_loss: 1.975731, test loss: 1.027234, bias2: 0.9861927628517151, variance: 0.041040726006031036\n",
      "Train size: [400] hidden size: [7] trial: 11, train_loss: 1.988584, test loss: 1.029739, bias2: 0.983940839767456, variance: 0.04579852893948555\n",
      "Train size: [400] hidden size: [7] trial: 12, train_loss: 1.994722, test loss: 1.028520, bias2: 0.9829939603805542, variance: 0.045526400208473206\n",
      "Train size: [400] hidden size: [7] trial: 13, train_loss: 1.983064, test loss: 1.028478, bias2: 0.9816069602966309, variance: 0.046870727092027664\n",
      "Train size: [400] hidden size: [7] trial: 14, train_loss: 1.981473, test loss: 1.028550, bias2: 0.9832291603088379, variance: 0.045320842415094376\n",
      "Train size: [400] hidden size: [7] trial: 15, train_loss: 1.972357, test loss: 1.029360, bias2: 0.9838925004005432, variance: 0.045467205345630646\n",
      "Train size: [400] hidden size: [7] trial: 16, train_loss: 1.979498, test loss: 1.029160, bias2: 0.9851183295249939, variance: 0.04404119402170181\n",
      "Train size: [400] hidden size: [7] trial: 17, train_loss: 1.973022, test loss: 1.028415, bias2: 0.985515832901001, variance: 0.04289928078651428\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [7] trial: 18, train_loss: 1.972172, test loss: 1.028868, bias2: 0.9859683513641357, variance: 0.042899589985609055\n",
      "Train size: [400] hidden size: [7] trial: 19, train_loss: 1.968317, test loss: 1.031457, bias2: 0.987251341342926, variance: 0.04420595243573189\n",
      "Train size: [400] hidden size: [7] trial: 20, train_loss: 1.967017, test loss: 1.032222, bias2: 0.9856501817703247, variance: 0.04657182842493057\n",
      "Train size: [400] hidden size: [7] trial: 21, train_loss: 1.964687, test loss: 1.032731, bias2: 0.9835095405578613, variance: 0.04922172799706459\n",
      "Train size: [400] hidden size: [7] trial: 22, train_loss: 1.964362, test loss: 1.032705, bias2: 0.9839402437210083, variance: 0.04876480624079704\n",
      "Train size: [400] hidden size: [7] trial: 23, train_loss: 1.967186, test loss: 1.032927, bias2: 0.9830776453018188, variance: 0.04984918236732483\n",
      "Train size: [400] hidden size: [7] trial: 24, train_loss: 1.967226, test loss: 1.033948, bias2: 0.983888566493988, variance: 0.05005925893783569\n",
      "Train size: [400] hidden size: [7] trial: 25, train_loss: 1.967841, test loss: 1.033757, bias2: 0.9847273230552673, variance: 0.049029506742954254\n",
      "Train size: [400] hidden size: [7] trial: 26, train_loss: 1.960093, test loss: 1.033221, bias2: 0.9853504300117493, variance: 0.047870587557554245\n",
      "Train size: [400] hidden size: [7] trial: 27, train_loss: 1.956593, test loss: 1.032005, bias2: 0.9847521781921387, variance: 0.047253113240003586\n",
      "Train size: [400] hidden size: [7] trial: 28, train_loss: 1.956492, test loss: 1.032609, bias2: 0.9851617217063904, variance: 0.047447752207517624\n",
      "Train size: [400] hidden size: [7] trial: 29, train_loss: 1.953510, test loss: 1.032245, bias2: 0.9849148988723755, variance: 0.04732990637421608\n",
      "Train size: [400] hidden size: [7] trial: 30, train_loss: 1.956955, test loss: 1.031710, bias2: 0.9850736856460571, variance: 0.04663684219121933\n",
      "Train size: [400] hidden size: [7] trial: 31, train_loss: 1.960842, test loss: 1.032062, bias2: 0.9858811497688293, variance: 0.04618077352643013\n",
      "Train size: [400] hidden size: [7] trial: 32, train_loss: 1.966189, test loss: 1.033579, bias2: 0.9862624406814575, variance: 0.04731665551662445\n",
      "Train size: [400] hidden size: [7] trial: 33, train_loss: 1.961146, test loss: 1.033938, bias2: 0.9862096309661865, variance: 0.047728195786476135\n",
      "Train size: [400] hidden size: [7] trial: 34, train_loss: 1.962403, test loss: 1.034283, bias2: 0.9864685535430908, variance: 0.04781484976410866\n",
      "Train size: [400] hidden size: [7] trial: 35, train_loss: 1.965449, test loss: 1.034641, bias2: 0.9862911105155945, variance: 0.048349782824516296\n",
      "Train size: [400] hidden size: [7] trial: 36, train_loss: 1.962293, test loss: 1.034155, bias2: 0.9867148995399475, variance: 0.04743964597582817\n",
      "Train size: [400] hidden size: [7] trial: 37, train_loss: 1.963489, test loss: 1.033943, bias2: 0.986412525177002, variance: 0.047530192881822586\n",
      "Train size: [400] hidden size: [7] trial: 38, train_loss: 1.964682, test loss: 1.033731, bias2: 0.9863489866256714, variance: 0.04738149791955948\n",
      "Train size: [400] hidden size: [7] trial: 39, train_loss: 1.966185, test loss: 1.033327, bias2: 0.986096203327179, variance: 0.04723100736737251\n",
      "Train size: [400] hidden size: [7] trial: 40, train_loss: 1.966207, test loss: 1.032751, bias2: 0.9852580428123474, variance: 0.04749279096722603\n",
      "Train size: [400] hidden size: [7] trial: 41, train_loss: 1.965013, test loss: 1.032458, bias2: 0.984855592250824, variance: 0.047602832317352295\n",
      "Train size: [400] hidden size: [7] trial: 42, train_loss: 1.963063, test loss: 1.031930, bias2: 0.9844822883605957, variance: 0.047447316348552704\n",
      "Train size: [400] hidden size: [7] trial: 43, train_loss: 1.961230, test loss: 1.032341, bias2: 0.9848368167877197, variance: 0.04750441014766693\n",
      "Train size: [400] hidden size: [7] trial: 44, train_loss: 1.956960, test loss: 1.032432, bias2: 0.9840990304946899, variance: 0.04833327233791351\n",
      "Train size: [400] hidden size: [7] trial: 45, train_loss: 1.955161, test loss: 1.032384, bias2: 0.9844661355018616, variance: 0.04791804030537605\n",
      "Train size: [400] hidden size: [7] trial: 46, train_loss: 1.955755, test loss: 1.032228, bias2: 0.984699010848999, variance: 0.04752850905060768\n",
      "Train size: [400] hidden size: [7] trial: 47, train_loss: 1.954103, test loss: 1.031963, bias2: 0.9850434064865112, variance: 0.04691968113183975\n",
      "Train size: [400] hidden size: [7] trial: 48, train_loss: 1.953553, test loss: 1.032705, bias2: 0.9855764508247375, variance: 0.04712825268507004\n",
      "Train size: [400] hidden size: [7] trial: 49, train_loss: 1.957886, test loss: 1.032532, bias2: 0.985630989074707, variance: 0.046900972723960876\n",
      "##################################################\n",
      "Train size: [400] hidden size: [8] trial: 0, train_loss: 2.195546, test loss: 1.025274, bias2: 1.0252737998962402, variance: -4.865684938293313e-11\n",
      "Train size: [400] hidden size: [8] trial: 1, train_loss: 2.097568, test loss: 1.026192, bias2: 1.0028027296066284, variance: 0.0233894195407629\n",
      "Train size: [400] hidden size: [8] trial: 2, train_loss: 2.137773, test loss: 1.021327, bias2: 0.9950745701789856, variance: 0.026252828538417816\n",
      "Train size: [400] hidden size: [8] trial: 3, train_loss: 2.184888, test loss: 1.021542, bias2: 0.9976244568824768, variance: 0.02391728013753891\n",
      "Train size: [400] hidden size: [8] trial: 4, train_loss: 2.159438, test loss: 1.027572, bias2: 1.0003100633621216, variance: 0.027262426912784576\n",
      "Train size: [400] hidden size: [8] trial: 5, train_loss: 2.132566, test loss: 1.031884, bias2: 1.0019506216049194, variance: 0.029933102428913116\n",
      "Train size: [400] hidden size: [8] trial: 6, train_loss: 2.109338, test loss: 1.032708, bias2: 1.0002775192260742, variance: 0.032430749386548996\n",
      "Train size: [400] hidden size: [8] trial: 7, train_loss: 2.086969, test loss: 1.032404, bias2: 0.9942716956138611, variance: 0.03813226521015167\n",
      "Train size: [400] hidden size: [8] trial: 8, train_loss: 2.079635, test loss: 1.030378, bias2: 0.991528332233429, variance: 0.03884943574666977\n",
      "Train size: [400] hidden size: [8] trial: 9, train_loss: 2.070820, test loss: 1.032803, bias2: 0.9893761873245239, variance: 0.0434265062212944\n",
      "Train size: [400] hidden size: [8] trial: 10, train_loss: 2.067505, test loss: 1.030961, bias2: 0.989433228969574, variance: 0.041527558118104935\n",
      "Train size: [400] hidden size: [8] trial: 11, train_loss: 2.058375, test loss: 1.030486, bias2: 0.9876869320869446, variance: 0.04279904440045357\n",
      "Train size: [400] hidden size: [8] trial: 12, train_loss: 2.061114, test loss: 1.031734, bias2: 0.9882687926292419, variance: 0.04346557334065437\n",
      "Train size: [400] hidden size: [8] trial: 13, train_loss: 2.035356, test loss: 1.032872, bias2: 0.9899259805679321, variance: 0.04294619709253311\n",
      "Train size: [400] hidden size: [8] trial: 14, train_loss: 2.022214, test loss: 1.032726, bias2: 0.9902172684669495, variance: 0.04250854253768921\n",
      "Train size: [400] hidden size: [8] trial: 15, train_loss: 2.025112, test loss: 1.032852, bias2: 0.9906880259513855, variance: 0.042163655161857605\n",
      "Train size: [400] hidden size: [8] trial: 16, train_loss: 2.017323, test loss: 1.034043, bias2: 0.988583505153656, variance: 0.04545978084206581\n",
      "Train size: [400] hidden size: [8] trial: 17, train_loss: 2.009672, test loss: 1.033838, bias2: 0.9874436259269714, variance: 0.04639415070414543\n",
      "Train size: [400] hidden size: [8] trial: 18, train_loss: 2.017910, test loss: 1.034137, bias2: 0.9868505001068115, variance: 0.0472869873046875\n",
      "Train size: [400] hidden size: [8] trial: 19, train_loss: 2.022067, test loss: 1.035884, bias2: 0.9868226051330566, variance: 0.049061425030231476\n",
      "Train size: [400] hidden size: [8] trial: 20, train_loss: 2.014572, test loss: 1.034476, bias2: 0.9871441721916199, variance: 0.04733162000775337\n",
      "Train size: [400] hidden size: [8] trial: 21, train_loss: 2.019405, test loss: 1.034306, bias2: 0.9852337837219238, variance: 0.04907238483428955\n",
      "Train size: [400] hidden size: [8] trial: 22, train_loss: 2.020696, test loss: 1.033816, bias2: 0.9858123064041138, variance: 0.04800416901707649\n",
      "Train size: [400] hidden size: [8] trial: 23, train_loss: 2.016186, test loss: 1.034431, bias2: 0.9857288599014282, variance: 0.04870209842920303\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [8] trial: 24, train_loss: 2.013677, test loss: 1.036005, bias2: 0.9855073094367981, variance: 0.050498079508543015\n",
      "Train size: [400] hidden size: [8] trial: 25, train_loss: 2.006526, test loss: 1.035540, bias2: 0.9853724837303162, variance: 0.0501672625541687\n",
      "Train size: [400] hidden size: [8] trial: 26, train_loss: 1.999472, test loss: 1.034872, bias2: 0.986007571220398, variance: 0.04886398836970329\n",
      "Train size: [400] hidden size: [8] trial: 27, train_loss: 1.993694, test loss: 1.035408, bias2: 0.9863241910934448, variance: 0.04908420890569687\n",
      "Train size: [400] hidden size: [8] trial: 28, train_loss: 1.982124, test loss: 1.036426, bias2: 0.9868281483650208, variance: 0.049597810953855515\n",
      "Train size: [400] hidden size: [8] trial: 29, train_loss: 1.980796, test loss: 1.035088, bias2: 0.9861201643943787, variance: 0.04896814376115799\n",
      "Train size: [400] hidden size: [8] trial: 30, train_loss: 1.986524, test loss: 1.036186, bias2: 0.9861196279525757, variance: 0.05006611347198486\n",
      "Train size: [400] hidden size: [8] trial: 31, train_loss: 1.985021, test loss: 1.036023, bias2: 0.9867761135101318, variance: 0.04924652352929115\n",
      "Train size: [400] hidden size: [8] trial: 32, train_loss: 1.987937, test loss: 1.035452, bias2: 0.9857854247093201, variance: 0.04966649040579796\n",
      "Train size: [400] hidden size: [8] trial: 33, train_loss: 1.996243, test loss: 1.036154, bias2: 0.9860765337944031, variance: 0.05007759854197502\n",
      "Train size: [400] hidden size: [8] trial: 34, train_loss: 1.992282, test loss: 1.036351, bias2: 0.9870325326919556, variance: 0.04931844770908356\n",
      "Train size: [400] hidden size: [8] trial: 35, train_loss: 1.987534, test loss: 1.035576, bias2: 0.9862409234046936, variance: 0.049335312098264694\n",
      "Train size: [400] hidden size: [8] trial: 36, train_loss: 1.983580, test loss: 1.036314, bias2: 0.9859139919281006, variance: 0.050400510430336\n",
      "Train size: [400] hidden size: [8] trial: 37, train_loss: 1.978284, test loss: 1.036059, bias2: 0.9863398671150208, variance: 0.049719054251909256\n",
      "Train size: [400] hidden size: [8] trial: 38, train_loss: 1.978187, test loss: 1.036463, bias2: 0.9853754639625549, variance: 0.05108789727091789\n",
      "Train size: [400] hidden size: [8] trial: 39, train_loss: 1.979067, test loss: 1.035583, bias2: 0.9851793050765991, variance: 0.05040385201573372\n",
      "Train size: [400] hidden size: [8] trial: 40, train_loss: 1.975002, test loss: 1.035467, bias2: 0.9855025410652161, variance: 0.04996402934193611\n",
      "Train size: [400] hidden size: [8] trial: 41, train_loss: 1.969360, test loss: 1.035374, bias2: 0.9848974347114563, variance: 0.05047646909952164\n",
      "Train size: [400] hidden size: [8] trial: 42, train_loss: 1.973365, test loss: 1.035832, bias2: 0.9858294129371643, variance: 0.05000260844826698\n",
      "Train size: [400] hidden size: [8] trial: 43, train_loss: 1.975079, test loss: 1.035643, bias2: 0.9854617714881897, variance: 0.05018119141459465\n",
      "Train size: [400] hidden size: [8] trial: 44, train_loss: 1.968409, test loss: 1.036797, bias2: 0.985840380191803, variance: 0.05095618963241577\n",
      "Train size: [400] hidden size: [8] trial: 45, train_loss: 1.966204, test loss: 1.036624, bias2: 0.9860303997993469, variance: 0.050593648105859756\n",
      "Train size: [400] hidden size: [8] trial: 46, train_loss: 1.968585, test loss: 1.036670, bias2: 0.9852159023284912, variance: 0.051453977823257446\n",
      "Train size: [400] hidden size: [8] trial: 47, train_loss: 1.961927, test loss: 1.036049, bias2: 0.9849460124969482, variance: 0.051103375852108\n",
      "Train size: [400] hidden size: [8] trial: 48, train_loss: 1.961605, test loss: 1.035467, bias2: 0.9851115942001343, variance: 0.050354935228824615\n",
      "Train size: [400] hidden size: [8] trial: 49, train_loss: 1.958413, test loss: 1.035713, bias2: 0.9853858351707458, variance: 0.050326742231845856\n",
      "##################################################\n",
      "Train size: [400] hidden size: [9] trial: 0, train_loss: 1.876107, test loss: 1.008508, bias2: 1.0085080862045288, variance: 3.6492638771923325e-11\n",
      "Train size: [400] hidden size: [9] trial: 1, train_loss: 1.882371, test loss: 1.024806, bias2: 0.9939167499542236, variance: 0.03088953159749508\n",
      "Train size: [400] hidden size: [9] trial: 2, train_loss: 1.944305, test loss: 1.031718, bias2: 0.9950934648513794, variance: 0.03662445768713951\n",
      "Train size: [400] hidden size: [9] trial: 3, train_loss: 1.963082, test loss: 1.036018, bias2: 0.9980615973472595, variance: 0.03795652836561203\n",
      "Train size: [400] hidden size: [9] trial: 4, train_loss: 1.944551, test loss: 1.048470, bias2: 0.9950942993164062, variance: 0.05337533727288246\n",
      "Train size: [400] hidden size: [9] trial: 5, train_loss: 1.953722, test loss: 1.041904, bias2: 0.9893476366996765, variance: 0.05255671963095665\n",
      "Train size: [400] hidden size: [9] trial: 6, train_loss: 1.939074, test loss: 1.042009, bias2: 0.9866273403167725, variance: 0.05538162961602211\n",
      "Train size: [400] hidden size: [9] trial: 7, train_loss: 1.922976, test loss: 1.037105, bias2: 0.9777921438217163, variance: 0.05931258201599121\n",
      "Train size: [400] hidden size: [9] trial: 8, train_loss: 1.908209, test loss: 1.039353, bias2: 0.9786072969436646, variance: 0.06074550002813339\n",
      "Train size: [400] hidden size: [9] trial: 9, train_loss: 1.899310, test loss: 1.042278, bias2: 0.9767845869064331, variance: 0.0654933750629425\n",
      "Train size: [400] hidden size: [9] trial: 10, train_loss: 1.922704, test loss: 1.041152, bias2: 0.9741256237030029, variance: 0.067026287317276\n",
      "Train size: [400] hidden size: [9] trial: 11, train_loss: 1.916936, test loss: 1.038784, bias2: 0.9746932983398438, variance: 0.06409096717834473\n",
      "Train size: [400] hidden size: [9] trial: 12, train_loss: 1.897317, test loss: 1.037331, bias2: 0.9743937849998474, variance: 0.06293684244155884\n",
      "Train size: [400] hidden size: [9] trial: 13, train_loss: 1.915062, test loss: 1.036379, bias2: 0.9766608476638794, variance: 0.059718579053878784\n",
      "Train size: [400] hidden size: [9] trial: 14, train_loss: 1.916859, test loss: 1.039131, bias2: 0.976524829864502, variance: 0.06260588765144348\n",
      "Train size: [400] hidden size: [9] trial: 15, train_loss: 1.922172, test loss: 1.040474, bias2: 0.9756999015808105, variance: 0.0647740513086319\n",
      "Train size: [400] hidden size: [9] trial: 16, train_loss: 1.915887, test loss: 1.039039, bias2: 0.9754849076271057, variance: 0.06355377286672592\n",
      "Train size: [400] hidden size: [9] trial: 17, train_loss: 1.928169, test loss: 1.039941, bias2: 0.976719081401825, variance: 0.0632215067744255\n",
      "Train size: [400] hidden size: [9] trial: 18, train_loss: 1.925729, test loss: 1.038392, bias2: 0.9772942066192627, variance: 0.06109822541475296\n",
      "Train size: [400] hidden size: [9] trial: 19, train_loss: 1.916037, test loss: 1.039326, bias2: 0.9756075143814087, variance: 0.06371840834617615\n",
      "Train size: [400] hidden size: [9] trial: 20, train_loss: 1.913606, test loss: 1.038138, bias2: 0.9756733775138855, variance: 0.062464166432619095\n",
      "Train size: [400] hidden size: [9] trial: 21, train_loss: 1.909268, test loss: 1.037357, bias2: 0.9768203496932983, variance: 0.06053686514496803\n",
      "Train size: [400] hidden size: [9] trial: 22, train_loss: 1.895266, test loss: 1.036462, bias2: 0.9753156900405884, variance: 0.061146050691604614\n",
      "Train size: [400] hidden size: [9] trial: 23, train_loss: 1.896724, test loss: 1.038089, bias2: 0.9745196104049683, variance: 0.0635693222284317\n",
      "Train size: [400] hidden size: [9] trial: 24, train_loss: 1.897049, test loss: 1.037587, bias2: 0.9751158952713013, variance: 0.06247112900018692\n",
      "Train size: [400] hidden size: [9] trial: 25, train_loss: 1.892369, test loss: 1.037295, bias2: 0.9758424758911133, variance: 0.061452172696590424\n",
      "Train size: [400] hidden size: [9] trial: 26, train_loss: 1.894871, test loss: 1.037018, bias2: 0.9760165810585022, variance: 0.06100136414170265\n",
      "Train size: [400] hidden size: [9] trial: 27, train_loss: 1.905128, test loss: 1.035900, bias2: 0.9753848910331726, variance: 0.06051525101065636\n",
      "Train size: [400] hidden size: [9] trial: 28, train_loss: 1.905280, test loss: 1.035707, bias2: 0.9762265086174011, variance: 0.05948047712445259\n",
      "Train size: [400] hidden size: [9] trial: 29, train_loss: 1.908500, test loss: 1.034581, bias2: 0.975910484790802, variance: 0.05867091938853264\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [9] trial: 30, train_loss: 1.907459, test loss: 1.034934, bias2: 0.9762591123580933, variance: 0.05867454409599304\n",
      "Train size: [400] hidden size: [9] trial: 31, train_loss: 1.904419, test loss: 1.035461, bias2: 0.9767045974731445, variance: 0.058756232261657715\n",
      "Train size: [400] hidden size: [9] trial: 32, train_loss: 1.903607, test loss: 1.035378, bias2: 0.9766167402267456, variance: 0.0587616041302681\n",
      "Train size: [400] hidden size: [9] trial: 33, train_loss: 1.906299, test loss: 1.034642, bias2: 0.9767010807991028, variance: 0.057940881699323654\n",
      "Train size: [400] hidden size: [9] trial: 34, train_loss: 1.901792, test loss: 1.034016, bias2: 0.9764869213104248, variance: 0.057529594749212265\n",
      "Train size: [400] hidden size: [9] trial: 35, train_loss: 1.896781, test loss: 1.034591, bias2: 0.9775692224502563, variance: 0.057022083550691605\n",
      "Train size: [400] hidden size: [9] trial: 36, train_loss: 1.902500, test loss: 1.034895, bias2: 0.978361964225769, variance: 0.056533463299274445\n",
      "Train size: [400] hidden size: [9] trial: 37, train_loss: 1.896940, test loss: 1.034906, bias2: 0.9791114926338196, variance: 0.05579442158341408\n",
      "Train size: [400] hidden size: [9] trial: 38, train_loss: 1.897817, test loss: 1.035092, bias2: 0.9797078967094421, variance: 0.055384449660778046\n",
      "Train size: [400] hidden size: [9] trial: 39, train_loss: 1.898513, test loss: 1.035029, bias2: 0.9793737530708313, variance: 0.05565483495593071\n",
      "Train size: [400] hidden size: [9] trial: 40, train_loss: 1.902420, test loss: 1.034810, bias2: 0.9788662791252136, variance: 0.05594364181160927\n",
      "Train size: [400] hidden size: [9] trial: 41, train_loss: 1.901371, test loss: 1.034672, bias2: 0.9789380431175232, variance: 0.055733878165483475\n",
      "Train size: [400] hidden size: [9] trial: 42, train_loss: 1.901296, test loss: 1.034058, bias2: 0.9787851572036743, variance: 0.05527328699827194\n",
      "Train size: [400] hidden size: [9] trial: 43, train_loss: 1.903220, test loss: 1.033822, bias2: 0.978338360786438, variance: 0.055484041571617126\n",
      "Train size: [400] hidden size: [9] trial: 44, train_loss: 1.897984, test loss: 1.033783, bias2: 0.9783247709274292, variance: 0.05545830726623535\n",
      "Train size: [400] hidden size: [9] trial: 45, train_loss: 1.895505, test loss: 1.033997, bias2: 0.97821044921875, variance: 0.05578684061765671\n",
      "Train size: [400] hidden size: [9] trial: 46, train_loss: 1.897920, test loss: 1.034787, bias2: 0.9780682921409607, variance: 0.056718554347753525\n",
      "Train size: [400] hidden size: [9] trial: 47, train_loss: 1.898256, test loss: 1.035422, bias2: 0.9787936210632324, variance: 0.056627847254276276\n",
      "Train size: [400] hidden size: [9] trial: 48, train_loss: 1.899034, test loss: 1.035581, bias2: 0.9793266654014587, variance: 0.05625458061695099\n",
      "Train size: [400] hidden size: [9] trial: 49, train_loss: 1.903516, test loss: 1.035757, bias2: 0.9792893528938293, variance: 0.056467581540346146\n",
      "##################################################\n",
      "Train size: [400] hidden size: [11] trial: 0, train_loss: 1.988792, test loss: 1.039954, bias2: 1.039954423904419, variance: 7.298527893162543e-10\n",
      "Train size: [400] hidden size: [11] trial: 1, train_loss: 1.921424, test loss: 1.035763, bias2: 1.008607268333435, variance: 0.027156062424182892\n",
      "Train size: [400] hidden size: [11] trial: 2, train_loss: 1.897258, test loss: 1.051874, bias2: 1.0020407438278198, variance: 0.0498335026204586\n",
      "Train size: [400] hidden size: [11] trial: 3, train_loss: 1.858879, test loss: 1.051371, bias2: 0.9924218654632568, variance: 0.05894937738776207\n",
      "Train size: [400] hidden size: [11] trial: 4, train_loss: 1.841943, test loss: 1.048862, bias2: 0.9872574806213379, variance: 0.06160417199134827\n",
      "Train size: [400] hidden size: [11] trial: 5, train_loss: 1.863136, test loss: 1.044747, bias2: 0.9862020015716553, variance: 0.05854538083076477\n",
      "Train size: [400] hidden size: [11] trial: 6, train_loss: 1.870901, test loss: 1.045392, bias2: 0.9876664876937866, variance: 0.0577259361743927\n",
      "Train size: [400] hidden size: [11] trial: 7, train_loss: 1.859433, test loss: 1.043555, bias2: 0.9859641790390015, variance: 0.05759108066558838\n",
      "Train size: [400] hidden size: [11] trial: 8, train_loss: 1.862805, test loss: 1.043473, bias2: 0.9851661324501038, variance: 0.0583067312836647\n",
      "Train size: [400] hidden size: [11] trial: 9, train_loss: 1.887830, test loss: 1.044995, bias2: 0.9836670756340027, variance: 0.06132823973894119\n",
      "Train size: [400] hidden size: [11] trial: 10, train_loss: 1.875879, test loss: 1.042698, bias2: 0.9843807816505432, variance: 0.05831702798604965\n",
      "Train size: [400] hidden size: [11] trial: 11, train_loss: 1.884023, test loss: 1.043475, bias2: 0.98292076587677, variance: 0.06055401638150215\n",
      "Train size: [400] hidden size: [11] trial: 12, train_loss: 1.880903, test loss: 1.042941, bias2: 0.9794556498527527, variance: 0.06348498165607452\n",
      "Train size: [400] hidden size: [11] trial: 13, train_loss: 1.870771, test loss: 1.042060, bias2: 0.9787817001342773, variance: 0.063277967274189\n",
      "Train size: [400] hidden size: [11] trial: 14, train_loss: 1.862792, test loss: 1.041618, bias2: 0.9800510406494141, variance: 0.06156683340668678\n",
      "Train size: [400] hidden size: [11] trial: 15, train_loss: 1.856051, test loss: 1.042110, bias2: 0.9782710671424866, variance: 0.0638393685221672\n",
      "Train size: [400] hidden size: [11] trial: 16, train_loss: 1.857973, test loss: 1.043250, bias2: 0.9777984619140625, variance: 0.06545162200927734\n",
      "Train size: [400] hidden size: [11] trial: 17, train_loss: 1.853010, test loss: 1.043444, bias2: 0.9770724773406982, variance: 0.06637132912874222\n",
      "Train size: [400] hidden size: [11] trial: 18, train_loss: 1.860297, test loss: 1.044196, bias2: 0.9764481782913208, variance: 0.06774821132421494\n",
      "Train size: [400] hidden size: [11] trial: 19, train_loss: 1.858717, test loss: 1.044497, bias2: 0.9772363901138306, variance: 0.06726016849279404\n",
      "Train size: [400] hidden size: [11] trial: 20, train_loss: 1.869130, test loss: 1.043840, bias2: 0.9763959646224976, variance: 0.06744422763586044\n",
      "Train size: [400] hidden size: [11] trial: 21, train_loss: 1.864043, test loss: 1.041578, bias2: 0.9739634990692139, variance: 0.06761482357978821\n",
      "Train size: [400] hidden size: [11] trial: 22, train_loss: 1.872243, test loss: 1.040532, bias2: 0.9737837314605713, variance: 0.06674787402153015\n",
      "Train size: [400] hidden size: [11] trial: 23, train_loss: 1.866817, test loss: 1.040648, bias2: 0.9746400713920593, variance: 0.06600829213857651\n",
      "Train size: [400] hidden size: [11] trial: 24, train_loss: 1.872447, test loss: 1.041031, bias2: 0.9735647439956665, variance: 0.0674661248922348\n",
      "Train size: [400] hidden size: [11] trial: 25, train_loss: 1.878585, test loss: 1.041307, bias2: 0.9732029438018799, variance: 0.06810427457094193\n",
      "Train size: [400] hidden size: [11] trial: 26, train_loss: 1.882000, test loss: 1.040919, bias2: 0.9730663299560547, variance: 0.06785287708044052\n",
      "Train size: [400] hidden size: [11] trial: 27, train_loss: 1.889589, test loss: 1.040786, bias2: 0.9736506342887878, variance: 0.06713540852069855\n",
      "Train size: [400] hidden size: [11] trial: 28, train_loss: 1.891285, test loss: 1.040040, bias2: 0.9730704426765442, variance: 0.06696967035531998\n",
      "Train size: [400] hidden size: [11] trial: 29, train_loss: 1.887946, test loss: 1.040781, bias2: 0.9718471169471741, variance: 0.0689341202378273\n",
      "Train size: [400] hidden size: [11] trial: 30, train_loss: 1.892823, test loss: 1.040039, bias2: 0.9713128209114075, variance: 0.06872658431529999\n",
      "Train size: [400] hidden size: [11] trial: 31, train_loss: 1.890904, test loss: 1.039598, bias2: 0.9717667102813721, variance: 0.06783101707696915\n",
      "Train size: [400] hidden size: [11] trial: 32, train_loss: 1.891313, test loss: 1.040532, bias2: 0.9722854495048523, variance: 0.06824629753828049\n",
      "Train size: [400] hidden size: [11] trial: 33, train_loss: 1.889561, test loss: 1.041134, bias2: 0.9724746942520142, variance: 0.06865908950567245\n",
      "Train size: [400] hidden size: [11] trial: 34, train_loss: 1.888500, test loss: 1.041396, bias2: 0.9728818535804749, variance: 0.06851378828287125\n",
      "Train size: [400] hidden size: [11] trial: 35, train_loss: 1.887152, test loss: 1.040665, bias2: 0.9713301062583923, variance: 0.06933505088090897\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [11] trial: 36, train_loss: 1.884030, test loss: 1.040579, bias2: 0.9708268642425537, variance: 0.06975211948156357\n",
      "Train size: [400] hidden size: [11] trial: 37, train_loss: 1.889652, test loss: 1.040419, bias2: 0.9711500406265259, variance: 0.06926873326301575\n",
      "Train size: [400] hidden size: [11] trial: 38, train_loss: 1.888124, test loss: 1.041069, bias2: 0.9703706502914429, variance: 0.07069805264472961\n",
      "Train size: [400] hidden size: [11] trial: 39, train_loss: 1.890907, test loss: 1.040278, bias2: 0.9695018529891968, variance: 0.07077620923519135\n",
      "Train size: [400] hidden size: [11] trial: 40, train_loss: 1.891036, test loss: 1.041885, bias2: 0.9698728919029236, variance: 0.07201223820447922\n",
      "Train size: [400] hidden size: [11] trial: 41, train_loss: 1.894873, test loss: 1.042502, bias2: 0.9697483777999878, variance: 0.07275381684303284\n",
      "Train size: [400] hidden size: [11] trial: 42, train_loss: 1.894110, test loss: 1.042713, bias2: 0.9690598249435425, variance: 0.07365356385707855\n",
      "Train size: [400] hidden size: [11] trial: 43, train_loss: 1.895801, test loss: 1.043291, bias2: 0.969828724861145, variance: 0.07346213608980179\n",
      "Train size: [400] hidden size: [11] trial: 44, train_loss: 1.896097, test loss: 1.043767, bias2: 0.9695398807525635, variance: 0.07422759383916855\n",
      "Train size: [400] hidden size: [11] trial: 45, train_loss: 1.897005, test loss: 1.045166, bias2: 0.970302164554596, variance: 0.07486408203840256\n",
      "Train size: [400] hidden size: [11] trial: 46, train_loss: 1.900974, test loss: 1.044590, bias2: 0.9699975252151489, variance: 0.07459244132041931\n",
      "Train size: [400] hidden size: [11] trial: 47, train_loss: 1.908998, test loss: 1.044994, bias2: 0.9703705310821533, variance: 0.07462380826473236\n",
      "Train size: [400] hidden size: [11] trial: 48, train_loss: 1.907192, test loss: 1.044618, bias2: 0.970780074596405, variance: 0.07383816689252853\n",
      "Train size: [400] hidden size: [11] trial: 49, train_loss: 1.904254, test loss: 1.044498, bias2: 0.9711989164352417, variance: 0.07329884171485901\n",
      "##################################################\n",
      "Train size: [400] hidden size: [12] trial: 0, train_loss: 1.772915, test loss: 1.029737, bias2: 1.029736876487732, variance: 1.2164212345733283e-11\n",
      "Train size: [400] hidden size: [12] trial: 1, train_loss: 1.891533, test loss: 1.029846, bias2: 1.0137817859649658, variance: 0.016064506024122238\n",
      "Train size: [400] hidden size: [12] trial: 2, train_loss: 1.957093, test loss: 1.031381, bias2: 0.9947080016136169, variance: 0.03667265549302101\n",
      "Train size: [400] hidden size: [12] trial: 3, train_loss: 1.999708, test loss: 1.028779, bias2: 0.9842300415039062, variance: 0.04454900696873665\n",
      "Train size: [400] hidden size: [12] trial: 4, train_loss: 1.986625, test loss: 1.029630, bias2: 0.97916579246521, variance: 0.05046460032463074\n",
      "Train size: [400] hidden size: [12] trial: 5, train_loss: 1.963073, test loss: 1.026480, bias2: 0.9704238176345825, variance: 0.05605664104223251\n",
      "Train size: [400] hidden size: [12] trial: 6, train_loss: 1.928612, test loss: 1.028747, bias2: 0.9691945314407349, variance: 0.05955267697572708\n",
      "Train size: [400] hidden size: [12] trial: 7, train_loss: 1.928140, test loss: 1.031442, bias2: 0.9708760380744934, variance: 0.06056636944413185\n",
      "Train size: [400] hidden size: [12] trial: 8, train_loss: 1.917695, test loss: 1.032882, bias2: 0.9665514230728149, variance: 0.06633066385984421\n",
      "Train size: [400] hidden size: [12] trial: 9, train_loss: 1.903385, test loss: 1.040788, bias2: 0.9699685573577881, variance: 0.07081988453865051\n",
      "Train size: [400] hidden size: [12] trial: 10, train_loss: 1.917903, test loss: 1.042365, bias2: 0.9691474437713623, variance: 0.07321715354919434\n",
      "Train size: [400] hidden size: [12] trial: 11, train_loss: 1.927904, test loss: 1.043294, bias2: 0.9678472280502319, variance: 0.0754462331533432\n",
      "Train size: [400] hidden size: [12] trial: 12, train_loss: 1.925547, test loss: 1.046625, bias2: 0.9699928760528564, variance: 0.07663165032863617\n",
      "Train size: [400] hidden size: [12] trial: 13, train_loss: 1.919031, test loss: 1.045706, bias2: 0.9687994718551636, variance: 0.07690633088350296\n",
      "Train size: [400] hidden size: [12] trial: 14, train_loss: 1.927273, test loss: 1.042975, bias2: 0.9650304317474365, variance: 0.07794426381587982\n",
      "Train size: [400] hidden size: [12] trial: 15, train_loss: 1.919954, test loss: 1.042144, bias2: 0.9643723368644714, variance: 0.07777147740125656\n",
      "Train size: [400] hidden size: [12] trial: 16, train_loss: 1.918002, test loss: 1.043746, bias2: 0.9628427028656006, variance: 0.0809037908911705\n",
      "Train size: [400] hidden size: [12] trial: 17, train_loss: 1.916274, test loss: 1.044796, bias2: 0.9600669145584106, variance: 0.08472856879234314\n",
      "Train size: [400] hidden size: [12] trial: 18, train_loss: 1.929891, test loss: 1.044172, bias2: 0.9604207873344421, variance: 0.08375101536512375\n",
      "Train size: [400] hidden size: [12] trial: 19, train_loss: 1.934776, test loss: 1.045252, bias2: 0.9622190594673157, variance: 0.08303292095661163\n",
      "Train size: [400] hidden size: [12] trial: 20, train_loss: 1.935489, test loss: 1.048371, bias2: 0.9622509479522705, variance: 0.0861203670501709\n",
      "Train size: [400] hidden size: [12] trial: 21, train_loss: 1.933233, test loss: 1.048048, bias2: 0.963483452796936, variance: 0.08456423878669739\n",
      "Train size: [400] hidden size: [12] trial: 22, train_loss: 1.936595, test loss: 1.046718, bias2: 0.9629038572311401, variance: 0.08381462097167969\n",
      "Train size: [400] hidden size: [12] trial: 23, train_loss: 1.933066, test loss: 1.045527, bias2: 0.9604544043540955, variance: 0.08507224172353745\n",
      "Train size: [400] hidden size: [12] trial: 24, train_loss: 1.932037, test loss: 1.044411, bias2: 0.9607800841331482, variance: 0.08363122493028641\n",
      "Train size: [400] hidden size: [12] trial: 25, train_loss: 1.934113, test loss: 1.044217, bias2: 0.9614599943161011, variance: 0.0827566608786583\n",
      "Train size: [400] hidden size: [12] trial: 26, train_loss: 1.941035, test loss: 1.044723, bias2: 0.9615667462348938, variance: 0.08315582573413849\n",
      "Train size: [400] hidden size: [12] trial: 27, train_loss: 1.939865, test loss: 1.044439, bias2: 0.9602779150009155, variance: 0.08416150510311127\n",
      "Train size: [400] hidden size: [12] trial: 28, train_loss: 1.941630, test loss: 1.044909, bias2: 0.9599767923355103, variance: 0.08493245393037796\n",
      "Train size: [400] hidden size: [12] trial: 29, train_loss: 1.939395, test loss: 1.044560, bias2: 0.9606595039367676, variance: 0.08390071243047714\n",
      "Train size: [400] hidden size: [12] trial: 30, train_loss: 1.940850, test loss: 1.043600, bias2: 0.9605273604393005, variance: 0.08307305723428726\n",
      "Train size: [400] hidden size: [12] trial: 31, train_loss: 1.935885, test loss: 1.042917, bias2: 0.9607149958610535, variance: 0.08220163732767105\n",
      "Train size: [400] hidden size: [12] trial: 32, train_loss: 1.933282, test loss: 1.043837, bias2: 0.9613462090492249, variance: 0.08249123394489288\n",
      "Train size: [400] hidden size: [12] trial: 33, train_loss: 1.934773, test loss: 1.043699, bias2: 0.961098849773407, variance: 0.08260053396224976\n",
      "Train size: [400] hidden size: [12] trial: 34, train_loss: 1.937792, test loss: 1.042671, bias2: 0.9612085819244385, variance: 0.08146238327026367\n",
      "Train size: [400] hidden size: [12] trial: 35, train_loss: 1.939234, test loss: 1.043111, bias2: 0.9617739915847778, variance: 0.08133676648139954\n",
      "Train size: [400] hidden size: [12] trial: 36, train_loss: 1.942070, test loss: 1.043539, bias2: 0.9615130424499512, variance: 0.08202579617500305\n",
      "Train size: [400] hidden size: [12] trial: 37, train_loss: 1.942366, test loss: 1.043294, bias2: 0.961823046207428, variance: 0.0814712643623352\n",
      "Train size: [400] hidden size: [12] trial: 38, train_loss: 1.949405, test loss: 1.043630, bias2: 0.961594820022583, variance: 0.08203539997339249\n",
      "Train size: [400] hidden size: [12] trial: 39, train_loss: 1.953113, test loss: 1.043591, bias2: 0.9617002010345459, variance: 0.08189106732606888\n",
      "Train size: [400] hidden size: [12] trial: 40, train_loss: 1.950854, test loss: 1.044640, bias2: 0.9622387886047363, variance: 0.08240129053592682\n",
      "Train size: [400] hidden size: [12] trial: 41, train_loss: 1.951899, test loss: 1.046220, bias2: 0.9631713628768921, variance: 0.08304844796657562\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [12] trial: 42, train_loss: 1.953644, test loss: 1.046146, bias2: 0.9635574817657471, variance: 0.08258821070194244\n",
      "Train size: [400] hidden size: [12] trial: 43, train_loss: 1.948878, test loss: 1.046640, bias2: 0.9642429351806641, variance: 0.0823967456817627\n",
      "Train size: [400] hidden size: [12] trial: 44, train_loss: 1.945842, test loss: 1.046535, bias2: 0.9641438722610474, variance: 0.08239088207483292\n",
      "Train size: [400] hidden size: [12] trial: 45, train_loss: 1.947446, test loss: 1.046730, bias2: 0.9635717868804932, variance: 0.08315850794315338\n",
      "Train size: [400] hidden size: [12] trial: 46, train_loss: 1.943746, test loss: 1.047254, bias2: 0.9638417363166809, variance: 0.08341176807880402\n",
      "Train size: [400] hidden size: [12] trial: 47, train_loss: 1.940731, test loss: 1.046846, bias2: 0.9638140201568604, variance: 0.08303210139274597\n",
      "Train size: [400] hidden size: [12] trial: 48, train_loss: 1.943697, test loss: 1.047132, bias2: 0.9633458852767944, variance: 0.08378647267818451\n",
      "Train size: [400] hidden size: [12] trial: 49, train_loss: 1.943748, test loss: 1.045874, bias2: 0.9625897407531738, variance: 0.08328428119421005\n",
      "##################################################\n",
      "Train size: [400] hidden size: [14] trial: 0, train_loss: 1.868757, test loss: 1.026361, bias2: 1.0263612270355225, variance: 3.8925479506346505e-10\n",
      "Train size: [400] hidden size: [14] trial: 1, train_loss: 2.074568, test loss: 1.047483, bias2: 1.0034769773483276, variance: 0.0440063402056694\n",
      "Train size: [400] hidden size: [14] trial: 2, train_loss: 2.044914, test loss: 1.057568, bias2: 0.9901542663574219, variance: 0.0674140527844429\n",
      "Train size: [400] hidden size: [14] trial: 3, train_loss: 2.068129, test loss: 1.062991, bias2: 0.9861000776290894, variance: 0.07689045369625092\n",
      "Train size: [400] hidden size: [14] trial: 4, train_loss: 2.047918, test loss: 1.057820, bias2: 0.9830302000045776, variance: 0.07478951662778854\n",
      "Train size: [400] hidden size: [14] trial: 5, train_loss: 2.031876, test loss: 1.052731, bias2: 0.9794578552246094, variance: 0.0732731819152832\n",
      "Train size: [400] hidden size: [14] trial: 6, train_loss: 2.009573, test loss: 1.061354, bias2: 0.984214186668396, variance: 0.07713936269283295\n",
      "Train size: [400] hidden size: [14] trial: 7, train_loss: 1.999933, test loss: 1.060573, bias2: 0.9831922054290771, variance: 0.07738053053617477\n",
      "Train size: [400] hidden size: [14] trial: 8, train_loss: 1.985570, test loss: 1.054274, bias2: 0.9797921776771545, variance: 0.074482262134552\n",
      "Train size: [400] hidden size: [14] trial: 9, train_loss: 1.988041, test loss: 1.054250, bias2: 0.9764735102653503, variance: 0.07777637243270874\n",
      "Train size: [400] hidden size: [14] trial: 10, train_loss: 1.968040, test loss: 1.055538, bias2: 0.9706942439079285, variance: 0.08484414964914322\n",
      "Train size: [400] hidden size: [14] trial: 11, train_loss: 1.965594, test loss: 1.054964, bias2: 0.9710499048233032, variance: 0.0839138999581337\n",
      "Train size: [400] hidden size: [14] trial: 12, train_loss: 1.958618, test loss: 1.053014, bias2: 0.9698222279548645, variance: 0.08319190889596939\n",
      "Train size: [400] hidden size: [14] trial: 13, train_loss: 1.940248, test loss: 1.052982, bias2: 0.9675930738449097, variance: 0.08538869023323059\n",
      "Train size: [400] hidden size: [14] trial: 14, train_loss: 1.947762, test loss: 1.052386, bias2: 0.9672489166259766, variance: 0.08513710647821426\n",
      "Train size: [400] hidden size: [14] trial: 15, train_loss: 1.931011, test loss: 1.051079, bias2: 0.9669988751411438, variance: 0.08407970517873764\n",
      "Train size: [400] hidden size: [14] trial: 16, train_loss: 1.944312, test loss: 1.050113, bias2: 0.9681340456008911, variance: 0.08197867125272751\n",
      "Train size: [400] hidden size: [14] trial: 17, train_loss: 1.959023, test loss: 1.050757, bias2: 0.9664584398269653, variance: 0.08429883420467377\n",
      "Train size: [400] hidden size: [14] trial: 18, train_loss: 1.955745, test loss: 1.050817, bias2: 0.965540885925293, variance: 0.08527614176273346\n",
      "Train size: [400] hidden size: [14] trial: 19, train_loss: 1.945787, test loss: 1.049591, bias2: 0.966560959815979, variance: 0.08302973210811615\n",
      "Train size: [400] hidden size: [14] trial: 20, train_loss: 1.943150, test loss: 1.048027, bias2: 0.9649075269699097, variance: 0.08311974257230759\n",
      "Train size: [400] hidden size: [14] trial: 21, train_loss: 1.933309, test loss: 1.047667, bias2: 0.9630692601203918, variance: 0.08459825813770294\n",
      "Train size: [400] hidden size: [14] trial: 22, train_loss: 1.947807, test loss: 1.048814, bias2: 0.9612041115760803, variance: 0.08761005103588104\n",
      "Train size: [400] hidden size: [14] trial: 23, train_loss: 1.941717, test loss: 1.048680, bias2: 0.9606994390487671, variance: 0.08798036724328995\n",
      "Train size: [400] hidden size: [14] trial: 24, train_loss: 1.939573, test loss: 1.048228, bias2: 0.9621361494064331, variance: 0.08609186857938766\n",
      "Train size: [400] hidden size: [14] trial: 25, train_loss: 1.936134, test loss: 1.047471, bias2: 0.9609156847000122, variance: 0.08655574172735214\n",
      "Train size: [400] hidden size: [14] trial: 26, train_loss: 1.930683, test loss: 1.046103, bias2: 0.9584571123123169, variance: 0.08764556050300598\n",
      "Train size: [400] hidden size: [14] trial: 27, train_loss: 1.938944, test loss: 1.045591, bias2: 0.9588053226470947, variance: 0.0867854431271553\n",
      "Train size: [400] hidden size: [14] trial: 28, train_loss: 1.933482, test loss: 1.044633, bias2: 0.9582456946372986, variance: 0.08638747781515121\n",
      "Train size: [400] hidden size: [14] trial: 29, train_loss: 1.927865, test loss: 1.045049, bias2: 0.9586566090583801, variance: 0.08639272302389145\n",
      "Train size: [400] hidden size: [14] trial: 30, train_loss: 1.932464, test loss: 1.045738, bias2: 0.9585269093513489, variance: 0.08721081912517548\n",
      "Train size: [400] hidden size: [14] trial: 31, train_loss: 1.930203, test loss: 1.047575, bias2: 0.9597633481025696, variance: 0.08781131356954575\n",
      "Train size: [400] hidden size: [14] trial: 32, train_loss: 1.932102, test loss: 1.047342, bias2: 0.9598581194877625, variance: 0.0874834805727005\n",
      "Train size: [400] hidden size: [14] trial: 33, train_loss: 1.931965, test loss: 1.048334, bias2: 0.9598910808563232, variance: 0.08844301104545593\n",
      "Train size: [400] hidden size: [14] trial: 34, train_loss: 1.929900, test loss: 1.049203, bias2: 0.9600481986999512, variance: 0.08915483206510544\n",
      "Train size: [400] hidden size: [14] trial: 35, train_loss: 1.931144, test loss: 1.050647, bias2: 0.9599035978317261, variance: 0.09074390679597855\n",
      "Train size: [400] hidden size: [14] trial: 36, train_loss: 1.928362, test loss: 1.051648, bias2: 0.9581552147865295, variance: 0.09349231421947479\n",
      "Train size: [400] hidden size: [14] trial: 37, train_loss: 1.930482, test loss: 1.051905, bias2: 0.958411455154419, variance: 0.09349358826875687\n",
      "Train size: [400] hidden size: [14] trial: 38, train_loss: 1.929115, test loss: 1.050873, bias2: 0.9579864740371704, variance: 0.09288658946752548\n",
      "Train size: [400] hidden size: [14] trial: 39, train_loss: 1.924929, test loss: 1.051335, bias2: 0.9581934809684753, variance: 0.09314163774251938\n",
      "Train size: [400] hidden size: [14] trial: 40, train_loss: 1.925736, test loss: 1.050962, bias2: 0.9594443440437317, variance: 0.09151798486709595\n",
      "Train size: [400] hidden size: [14] trial: 41, train_loss: 1.928084, test loss: 1.050274, bias2: 0.9600616693496704, variance: 0.09021235257387161\n",
      "Train size: [400] hidden size: [14] trial: 42, train_loss: 1.929315, test loss: 1.050370, bias2: 0.9605752825737, variance: 0.08979492634534836\n",
      "Train size: [400] hidden size: [14] trial: 43, train_loss: 1.928338, test loss: 1.051047, bias2: 0.9601038098335266, variance: 0.09094352275133133\n",
      "Train size: [400] hidden size: [14] trial: 44, train_loss: 1.920805, test loss: 1.051561, bias2: 0.9600009918212891, variance: 0.091559998691082\n",
      "Train size: [400] hidden size: [14] trial: 45, train_loss: 1.930227, test loss: 1.052507, bias2: 0.9606368541717529, variance: 0.09187030792236328\n",
      "Train size: [400] hidden size: [14] trial: 46, train_loss: 1.925352, test loss: 1.052355, bias2: 0.9601837396621704, variance: 0.09217144548892975\n",
      "Train size: [400] hidden size: [14] trial: 47, train_loss: 1.928429, test loss: 1.053701, bias2: 0.9595643877983093, variance: 0.09413618594408035\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [14] trial: 48, train_loss: 1.932046, test loss: 1.053715, bias2: 0.9600530862808228, variance: 0.09366229176521301\n",
      "Train size: [400] hidden size: [14] trial: 49, train_loss: 1.929322, test loss: 1.053264, bias2: 0.960527777671814, variance: 0.09273625910282135\n",
      "##################################################\n",
      "Train size: [400] hidden size: [16] trial: 0, train_loss: 1.884857, test loss: 1.121086, bias2: 1.1210864782333374, variance: 0.0\n",
      "Train size: [400] hidden size: [16] trial: 1, train_loss: 1.938207, test loss: 1.098607, bias2: 1.0409209728240967, variance: 0.05768585950136185\n",
      "Train size: [400] hidden size: [16] trial: 2, train_loss: 1.891131, test loss: 1.079681, bias2: 1.0047228336334229, variance: 0.07495862245559692\n",
      "Train size: [400] hidden size: [16] trial: 3, train_loss: 1.898568, test loss: 1.085562, bias2: 0.9878390431404114, variance: 0.09772273153066635\n",
      "Train size: [400] hidden size: [16] trial: 4, train_loss: 1.912710, test loss: 1.074971, bias2: 0.9739933609962463, variance: 0.10097771883010864\n",
      "Train size: [400] hidden size: [16] trial: 5, train_loss: 1.911687, test loss: 1.070330, bias2: 0.9699241518974304, variance: 0.10040562599897385\n",
      "Train size: [400] hidden size: [16] trial: 6, train_loss: 1.911527, test loss: 1.069180, bias2: 0.9662508964538574, variance: 0.10292886197566986\n",
      "Train size: [400] hidden size: [16] trial: 7, train_loss: 1.905891, test loss: 1.065529, bias2: 0.9554947018623352, variance: 0.11003441363573074\n",
      "Train size: [400] hidden size: [16] trial: 8, train_loss: 1.932650, test loss: 1.068490, bias2: 0.9553000926971436, variance: 0.11318980157375336\n",
      "Train size: [400] hidden size: [16] trial: 9, train_loss: 1.926718, test loss: 1.067676, bias2: 0.9513585567474365, variance: 0.11631704866886139\n",
      "Train size: [400] hidden size: [16] trial: 10, train_loss: 1.915420, test loss: 1.064012, bias2: 0.9494262933731079, variance: 0.11458573490381241\n",
      "Train size: [400] hidden size: [16] trial: 11, train_loss: 1.913366, test loss: 1.061395, bias2: 0.9510360360145569, variance: 0.11035890877246857\n",
      "Train size: [400] hidden size: [16] trial: 12, train_loss: 1.904135, test loss: 1.060496, bias2: 0.9527686238288879, variance: 0.10772757232189178\n",
      "Train size: [400] hidden size: [16] trial: 13, train_loss: 1.915074, test loss: 1.057712, bias2: 0.9522033929824829, variance: 0.10550843179225922\n",
      "Train size: [400] hidden size: [16] trial: 14, train_loss: 1.910373, test loss: 1.057935, bias2: 0.9502028226852417, variance: 0.10773205757141113\n",
      "Train size: [400] hidden size: [16] trial: 15, train_loss: 1.916482, test loss: 1.053918, bias2: 0.9493348002433777, variance: 0.10458344966173172\n",
      "Train size: [400] hidden size: [16] trial: 16, train_loss: 1.922014, test loss: 1.053317, bias2: 0.9485915899276733, variance: 0.10472501814365387\n",
      "Train size: [400] hidden size: [16] trial: 17, train_loss: 1.914836, test loss: 1.052052, bias2: 0.9490743279457092, variance: 0.10297791659832001\n",
      "Train size: [400] hidden size: [16] trial: 18, train_loss: 1.925430, test loss: 1.052836, bias2: 0.948906660079956, variance: 0.10392889380455017\n",
      "Train size: [400] hidden size: [16] trial: 19, train_loss: 1.928358, test loss: 1.051437, bias2: 0.9492711424827576, variance: 0.10216598957777023\n",
      "Train size: [400] hidden size: [16] trial: 20, train_loss: 1.931780, test loss: 1.049213, bias2: 0.9476274847984314, variance: 0.10158602148294449\n",
      "Train size: [400] hidden size: [16] trial: 21, train_loss: 1.929754, test loss: 1.048788, bias2: 0.9478558897972107, variance: 0.10093195736408234\n",
      "Train size: [400] hidden size: [16] trial: 22, train_loss: 1.923799, test loss: 1.048126, bias2: 0.9469546675682068, variance: 0.10117153078317642\n",
      "Train size: [400] hidden size: [16] trial: 23, train_loss: 1.915452, test loss: 1.048855, bias2: 0.9481497406959534, variance: 0.1007051020860672\n",
      "Train size: [400] hidden size: [16] trial: 24, train_loss: 1.917974, test loss: 1.048109, bias2: 0.9490928053855896, variance: 0.0990167111158371\n",
      "Train size: [400] hidden size: [16] trial: 25, train_loss: 1.911539, test loss: 1.050219, bias2: 0.9507912993431091, variance: 0.09942811727523804\n",
      "Train size: [400] hidden size: [16] trial: 26, train_loss: 1.916216, test loss: 1.049287, bias2: 0.9495466947555542, variance: 0.09974071383476257\n",
      "Train size: [400] hidden size: [16] trial: 27, train_loss: 1.911852, test loss: 1.051561, bias2: 0.9503214955329895, variance: 0.10123951733112335\n",
      "Train size: [400] hidden size: [16] trial: 28, train_loss: 1.915667, test loss: 1.051696, bias2: 0.9513840675354004, variance: 0.10031189769506454\n",
      "Train size: [400] hidden size: [16] trial: 29, train_loss: 1.916189, test loss: 1.051222, bias2: 0.9512019157409668, variance: 0.10001982003450394\n",
      "Train size: [400] hidden size: [16] trial: 30, train_loss: 1.915451, test loss: 1.051524, bias2: 0.9509409666061401, variance: 0.10058257728815079\n",
      "Train size: [400] hidden size: [16] trial: 31, train_loss: 1.922448, test loss: 1.053776, bias2: 0.9524857997894287, variance: 0.10128998756408691\n",
      "Train size: [400] hidden size: [16] trial: 32, train_loss: 1.918592, test loss: 1.054686, bias2: 0.9526563286781311, variance: 0.10202949494123459\n",
      "Train size: [400] hidden size: [16] trial: 33, train_loss: 1.920968, test loss: 1.054341, bias2: 0.9524563550949097, variance: 0.10188422352075577\n",
      "Train size: [400] hidden size: [16] trial: 34, train_loss: 1.919039, test loss: 1.054474, bias2: 0.9528694152832031, variance: 0.10160472244024277\n",
      "Train size: [400] hidden size: [16] trial: 35, train_loss: 1.916548, test loss: 1.056110, bias2: 0.9536011815071106, variance: 0.10250846296548843\n",
      "Train size: [400] hidden size: [16] trial: 36, train_loss: 1.915301, test loss: 1.056191, bias2: 0.9532495141029358, variance: 0.10294109582901001\n",
      "Train size: [400] hidden size: [16] trial: 37, train_loss: 1.915747, test loss: 1.055927, bias2: 0.9542680978775024, variance: 0.10165895521640778\n",
      "Train size: [400] hidden size: [16] trial: 38, train_loss: 1.912809, test loss: 1.056155, bias2: 0.9547513127326965, variance: 0.1014038696885109\n",
      "Train size: [400] hidden size: [16] trial: 39, train_loss: 1.912633, test loss: 1.055593, bias2: 0.9543457627296448, variance: 0.10124772787094116\n",
      "Train size: [400] hidden size: [16] trial: 40, train_loss: 1.906175, test loss: 1.055384, bias2: 0.9538092017173767, variance: 0.10157518833875656\n",
      "Train size: [400] hidden size: [16] trial: 41, train_loss: 1.902047, test loss: 1.056092, bias2: 0.9536081552505493, variance: 0.10248348116874695\n",
      "Train size: [400] hidden size: [16] trial: 42, train_loss: 1.903114, test loss: 1.055345, bias2: 0.9537161588668823, variance: 0.10162892192602158\n",
      "Train size: [400] hidden size: [16] trial: 43, train_loss: 1.909069, test loss: 1.055620, bias2: 0.9536912441253662, variance: 0.10192916542291641\n",
      "Train size: [400] hidden size: [16] trial: 44, train_loss: 1.903904, test loss: 1.056794, bias2: 0.9537136554718018, variance: 0.10308005660772324\n",
      "Train size: [400] hidden size: [16] trial: 45, train_loss: 1.905224, test loss: 1.056613, bias2: 0.9540667533874512, variance: 0.10254621505737305\n",
      "Train size: [400] hidden size: [16] trial: 46, train_loss: 1.906883, test loss: 1.057669, bias2: 0.9548022150993347, variance: 0.10286637395620346\n",
      "Train size: [400] hidden size: [16] trial: 47, train_loss: 1.903942, test loss: 1.059001, bias2: 0.9550532102584839, variance: 0.10394763946533203\n",
      "Train size: [400] hidden size: [16] trial: 48, train_loss: 1.904848, test loss: 1.058130, bias2: 0.953454315662384, variance: 0.10467571020126343\n",
      "Train size: [400] hidden size: [16] trial: 49, train_loss: 1.908492, test loss: 1.058022, bias2: 0.9531203508377075, variance: 0.10490116477012634\n",
      "##################################################\n",
      "Train size: [400] hidden size: [19] trial: 0, train_loss: 1.673559, test loss: 1.054185, bias2: 1.0541852712631226, variance: 7.785095901269301e-10\n",
      "Train size: [400] hidden size: [19] trial: 1, train_loss: 1.758524, test loss: 1.024967, bias2: 0.9818451404571533, variance: 0.04312146455049515\n",
      "Train size: [400] hidden size: [19] trial: 2, train_loss: 1.858631, test loss: 1.025539, bias2: 0.9588902592658997, variance: 0.06664852797985077\n",
      "Train size: [400] hidden size: [19] trial: 3, train_loss: 1.856362, test loss: 1.031780, bias2: 0.9591994881629944, variance: 0.07258061319589615\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [19] trial: 4, train_loss: 1.854125, test loss: 1.036020, bias2: 0.9568495154380798, variance: 0.07917026430368423\n",
      "Train size: [400] hidden size: [19] trial: 5, train_loss: 1.853311, test loss: 1.057545, bias2: 0.9618873596191406, variance: 0.09565773606300354\n",
      "Train size: [400] hidden size: [19] trial: 6, train_loss: 1.870694, test loss: 1.068073, bias2: 0.966884195804596, variance: 0.10118885338306427\n",
      "Train size: [400] hidden size: [19] trial: 7, train_loss: 1.876595, test loss: 1.065453, bias2: 0.9638341069221497, variance: 0.10161896795034409\n",
      "Train size: [400] hidden size: [19] trial: 8, train_loss: 1.880485, test loss: 1.073438, bias2: 0.9525700807571411, variance: 0.12086822092533112\n",
      "Train size: [400] hidden size: [19] trial: 9, train_loss: 1.869476, test loss: 1.075892, bias2: 0.9530947804450989, variance: 0.12279743701219559\n",
      "Train size: [400] hidden size: [19] trial: 10, train_loss: 1.865335, test loss: 1.073313, bias2: 0.9530602693557739, variance: 0.12025260925292969\n",
      "Train size: [400] hidden size: [19] trial: 11, train_loss: 1.869475, test loss: 1.078074, bias2: 0.9555083513259888, variance: 0.12256596982479095\n",
      "Train size: [400] hidden size: [19] trial: 12, train_loss: 1.868928, test loss: 1.077736, bias2: 0.9571204781532288, variance: 0.12061532586812973\n",
      "Train size: [400] hidden size: [19] trial: 13, train_loss: 1.863558, test loss: 1.080832, bias2: 0.9534450769424438, variance: 0.12738646566867828\n",
      "Train size: [400] hidden size: [19] trial: 14, train_loss: 1.854233, test loss: 1.079569, bias2: 0.9533066153526306, variance: 0.1262621283531189\n",
      "Train size: [400] hidden size: [19] trial: 15, train_loss: 1.857444, test loss: 1.082226, bias2: 0.9526392817497253, variance: 0.12958641350269318\n",
      "Train size: [400] hidden size: [19] trial: 16, train_loss: 1.862791, test loss: 1.084122, bias2: 0.9541651010513306, variance: 0.12995684146881104\n",
      "Train size: [400] hidden size: [19] trial: 17, train_loss: 1.872325, test loss: 1.082191, bias2: 0.9501906037330627, variance: 0.13200052082538605\n",
      "Train size: [400] hidden size: [19] trial: 18, train_loss: 1.865356, test loss: 1.083117, bias2: 0.9508981704711914, variance: 0.1322183609008789\n",
      "Train size: [400] hidden size: [19] trial: 19, train_loss: 1.846594, test loss: 1.082633, bias2: 0.9519208669662476, variance: 0.13071206212043762\n",
      "Train size: [400] hidden size: [19] trial: 20, train_loss: 1.843596, test loss: 1.082074, bias2: 0.9484006762504578, variance: 0.13367335498332977\n",
      "Train size: [400] hidden size: [19] trial: 21, train_loss: 1.844738, test loss: 1.083121, bias2: 0.9486966133117676, variance: 0.13442468643188477\n",
      "Train size: [400] hidden size: [19] trial: 22, train_loss: 1.846451, test loss: 1.083183, bias2: 0.9463395476341248, variance: 0.1368432641029358\n",
      "Train size: [400] hidden size: [19] trial: 23, train_loss: 1.843036, test loss: 1.083855, bias2: 0.9463633894920349, variance: 0.1374913901090622\n",
      "Train size: [400] hidden size: [19] trial: 24, train_loss: 1.842910, test loss: 1.083585, bias2: 0.9470723867416382, variance: 0.13651297986507416\n",
      "Train size: [400] hidden size: [19] trial: 25, train_loss: 1.840924, test loss: 1.083615, bias2: 0.9457473754882812, variance: 0.1378680318593979\n",
      "Train size: [400] hidden size: [19] trial: 26, train_loss: 1.849802, test loss: 1.084315, bias2: 0.9459716081619263, variance: 0.13834348320960999\n",
      "Train size: [400] hidden size: [19] trial: 27, train_loss: 1.845276, test loss: 1.083770, bias2: 0.9471347332000732, variance: 0.1366351991891861\n",
      "Train size: [400] hidden size: [19] trial: 28, train_loss: 1.840505, test loss: 1.083930, bias2: 0.9466391801834106, variance: 0.13729046285152435\n",
      "Train size: [400] hidden size: [19] trial: 29, train_loss: 1.847850, test loss: 1.083013, bias2: 0.9480249881744385, variance: 0.13498784601688385\n",
      "Train size: [400] hidden size: [19] trial: 30, train_loss: 1.844808, test loss: 1.080892, bias2: 0.9472139477729797, variance: 0.13367800414562225\n",
      "Train size: [400] hidden size: [19] trial: 31, train_loss: 1.841149, test loss: 1.079193, bias2: 0.9443918466567993, variance: 0.13480138778686523\n",
      "Train size: [400] hidden size: [19] trial: 32, train_loss: 1.846452, test loss: 1.079709, bias2: 0.9446249008178711, variance: 0.1350841373205185\n",
      "Train size: [400] hidden size: [19] trial: 33, train_loss: 1.843616, test loss: 1.079140, bias2: 0.9456251859664917, variance: 0.1335146129131317\n",
      "Train size: [400] hidden size: [19] trial: 34, train_loss: 1.844337, test loss: 1.079023, bias2: 0.9447426795959473, variance: 0.13428018987178802\n",
      "Train size: [400] hidden size: [19] trial: 35, train_loss: 1.853567, test loss: 1.079698, bias2: 0.9461869597434998, variance: 0.13351112604141235\n",
      "Train size: [400] hidden size: [19] trial: 36, train_loss: 1.855040, test loss: 1.082746, bias2: 0.9460898637771606, variance: 0.13665606081485748\n",
      "Train size: [400] hidden size: [19] trial: 37, train_loss: 1.852481, test loss: 1.082314, bias2: 0.9465371966362, variance: 0.1357770562171936\n",
      "Train size: [400] hidden size: [19] trial: 38, train_loss: 1.851892, test loss: 1.082233, bias2: 0.945380449295044, variance: 0.13685263693332672\n",
      "Train size: [400] hidden size: [19] trial: 39, train_loss: 1.849714, test loss: 1.081569, bias2: 0.9438621997833252, variance: 0.13770699501037598\n",
      "Train size: [400] hidden size: [19] trial: 40, train_loss: 1.850596, test loss: 1.082683, bias2: 0.9435809850692749, variance: 0.13910186290740967\n",
      "Train size: [400] hidden size: [19] trial: 41, train_loss: 1.850711, test loss: 1.081613, bias2: 0.9436509609222412, variance: 0.1379624754190445\n",
      "Train size: [400] hidden size: [19] trial: 42, train_loss: 1.851753, test loss: 1.080681, bias2: 0.9442750811576843, variance: 0.13640612363815308\n",
      "Train size: [400] hidden size: [19] trial: 43, train_loss: 1.852386, test loss: 1.080415, bias2: 0.9448791742324829, variance: 0.13553619384765625\n",
      "Train size: [400] hidden size: [19] trial: 44, train_loss: 1.853387, test loss: 1.080993, bias2: 0.9450845718383789, variance: 0.13590863347053528\n",
      "Train size: [400] hidden size: [19] trial: 45, train_loss: 1.849510, test loss: 1.081063, bias2: 0.9454123973846436, variance: 0.1356504112482071\n",
      "Train size: [400] hidden size: [19] trial: 46, train_loss: 1.847918, test loss: 1.080900, bias2: 0.9467003345489502, variance: 0.13419999182224274\n",
      "Train size: [400] hidden size: [19] trial: 47, train_loss: 1.851527, test loss: 1.080475, bias2: 0.9465806484222412, variance: 0.13389478623867035\n",
      "Train size: [400] hidden size: [19] trial: 48, train_loss: 1.850330, test loss: 1.080096, bias2: 0.9466167092323303, variance: 0.1334793120622635\n",
      "Train size: [400] hidden size: [19] trial: 49, train_loss: 1.851111, test loss: 1.079962, bias2: 0.9469150900840759, variance: 0.1330464631319046\n",
      "##################################################\n",
      "Train size: [400] hidden size: [22] trial: 0, train_loss: 1.920516, test loss: 1.065850, bias2: 1.0658504962921143, variance: 4.865685077071191e-10\n",
      "Train size: [400] hidden size: [22] trial: 1, train_loss: 1.887330, test loss: 1.077280, bias2: 0.9963440299034119, variance: 0.08093579858541489\n",
      "Train size: [400] hidden size: [22] trial: 2, train_loss: 1.882025, test loss: 1.077236, bias2: 0.9749897122383118, variance: 0.1022464781999588\n",
      "Train size: [400] hidden size: [22] trial: 3, train_loss: 1.794548, test loss: 1.072254, bias2: 0.950928270816803, variance: 0.12132542580366135\n",
      "Train size: [400] hidden size: [22] trial: 4, train_loss: 1.758066, test loss: 1.074143, bias2: 0.9419900178909302, variance: 0.13215316832065582\n",
      "Train size: [400] hidden size: [22] trial: 5, train_loss: 1.837932, test loss: 1.082512, bias2: 0.9350866079330444, variance: 0.1474258005619049\n",
      "Train size: [400] hidden size: [22] trial: 6, train_loss: 1.866814, test loss: 1.088835, bias2: 0.9339412450790405, variance: 0.15489408373832703\n",
      "Train size: [400] hidden size: [22] trial: 7, train_loss: 1.872335, test loss: 1.097777, bias2: 0.9337491989135742, variance: 0.16402742266654968\n",
      "Train size: [400] hidden size: [22] trial: 8, train_loss: 1.874801, test loss: 1.092960, bias2: 0.9362803101539612, variance: 0.1566799432039261\n",
      "Train size: [400] hidden size: [22] trial: 9, train_loss: 1.853699, test loss: 1.097203, bias2: 0.9357054829597473, variance: 0.16149799525737762\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [22] trial: 10, train_loss: 1.858650, test loss: 1.093162, bias2: 0.9344061613082886, variance: 0.158756285905838\n",
      "Train size: [400] hidden size: [22] trial: 11, train_loss: 1.867590, test loss: 1.087667, bias2: 0.9302675724029541, variance: 0.15739916265010834\n",
      "Train size: [400] hidden size: [22] trial: 12, train_loss: 1.872367, test loss: 1.086814, bias2: 0.9301156997680664, variance: 0.15669788420200348\n",
      "Train size: [400] hidden size: [22] trial: 13, train_loss: 1.874776, test loss: 1.086406, bias2: 0.9297446012496948, variance: 0.1566615253686905\n",
      "Train size: [400] hidden size: [22] trial: 14, train_loss: 1.870588, test loss: 1.085118, bias2: 0.9309920072555542, variance: 0.15412546694278717\n",
      "Train size: [400] hidden size: [22] trial: 15, train_loss: 1.869892, test loss: 1.084688, bias2: 0.9328709244728088, variance: 0.15181690454483032\n",
      "Train size: [400] hidden size: [22] trial: 16, train_loss: 1.861875, test loss: 1.082258, bias2: 0.9337219595909119, variance: 0.14853636920452118\n",
      "Train size: [400] hidden size: [22] trial: 17, train_loss: 1.867682, test loss: 1.079835, bias2: 0.9320403337478638, variance: 0.14779426157474518\n",
      "Train size: [400] hidden size: [22] trial: 18, train_loss: 1.871032, test loss: 1.079937, bias2: 0.9312729835510254, variance: 0.14866387844085693\n",
      "Train size: [400] hidden size: [22] trial: 19, train_loss: 1.878448, test loss: 1.081525, bias2: 0.9279410243034363, variance: 0.1535840630531311\n",
      "Train size: [400] hidden size: [22] trial: 20, train_loss: 1.870018, test loss: 1.078950, bias2: 0.9280909895896912, variance: 0.15085940062999725\n",
      "Train size: [400] hidden size: [22] trial: 21, train_loss: 1.868866, test loss: 1.077584, bias2: 0.9289053678512573, variance: 0.14867839217185974\n",
      "Train size: [400] hidden size: [22] trial: 22, train_loss: 1.864657, test loss: 1.077633, bias2: 0.9286789298057556, variance: 0.14895397424697876\n",
      "Train size: [400] hidden size: [22] trial: 23, train_loss: 1.860290, test loss: 1.074831, bias2: 0.9266276955604553, variance: 0.14820320904254913\n",
      "Train size: [400] hidden size: [22] trial: 24, train_loss: 1.854575, test loss: 1.075662, bias2: 0.9261739253997803, variance: 0.14948785305023193\n",
      "Train size: [400] hidden size: [22] trial: 25, train_loss: 1.847006, test loss: 1.075504, bias2: 0.926067054271698, variance: 0.14943735301494598\n",
      "Train size: [400] hidden size: [22] trial: 26, train_loss: 1.848418, test loss: 1.077066, bias2: 0.9257025122642517, variance: 0.15136390924453735\n",
      "Train size: [400] hidden size: [22] trial: 27, train_loss: 1.844887, test loss: 1.076264, bias2: 0.9256526231765747, variance: 0.15061131119728088\n",
      "Train size: [400] hidden size: [22] trial: 28, train_loss: 1.841473, test loss: 1.073722, bias2: 0.9232966899871826, variance: 0.15042565762996674\n",
      "Train size: [400] hidden size: [22] trial: 29, train_loss: 1.844255, test loss: 1.072007, bias2: 0.922260046005249, variance: 0.14974664151668549\n",
      "Train size: [400] hidden size: [22] trial: 30, train_loss: 1.849889, test loss: 1.072707, bias2: 0.9226434230804443, variance: 0.15006400644779205\n",
      "Train size: [400] hidden size: [22] trial: 31, train_loss: 1.850313, test loss: 1.071251, bias2: 0.9233272075653076, variance: 0.14792393147945404\n",
      "Train size: [400] hidden size: [22] trial: 32, train_loss: 1.855125, test loss: 1.073662, bias2: 0.9242664575576782, variance: 0.14939583837985992\n",
      "Train size: [400] hidden size: [22] trial: 33, train_loss: 1.855101, test loss: 1.074416, bias2: 0.9260555505752563, variance: 0.1483602523803711\n",
      "Train size: [400] hidden size: [22] trial: 34, train_loss: 1.850792, test loss: 1.075148, bias2: 0.9264488220214844, variance: 0.14869962632656097\n",
      "Train size: [400] hidden size: [22] trial: 35, train_loss: 1.846862, test loss: 1.076527, bias2: 0.925064742565155, variance: 0.15146251022815704\n",
      "Train size: [400] hidden size: [22] trial: 36, train_loss: 1.845566, test loss: 1.075707, bias2: 0.925388753414154, variance: 0.15031783282756805\n",
      "Train size: [400] hidden size: [22] trial: 37, train_loss: 1.843207, test loss: 1.076396, bias2: 0.9240193367004395, variance: 0.15237663686275482\n",
      "Train size: [400] hidden size: [22] trial: 38, train_loss: 1.848002, test loss: 1.075895, bias2: 0.9240244626998901, variance: 0.15187039971351624\n",
      "Train size: [400] hidden size: [22] trial: 39, train_loss: 1.843428, test loss: 1.076056, bias2: 0.9253174662590027, variance: 0.15073828399181366\n",
      "Train size: [400] hidden size: [22] trial: 40, train_loss: 1.849455, test loss: 1.075173, bias2: 0.9255181550979614, variance: 0.14965461194515228\n",
      "Train size: [400] hidden size: [22] trial: 41, train_loss: 1.843470, test loss: 1.075228, bias2: 0.926411509513855, variance: 0.14881619811058044\n",
      "Train size: [400] hidden size: [22] trial: 42, train_loss: 1.842782, test loss: 1.075805, bias2: 0.9278861880302429, variance: 0.14791876077651978\n",
      "Train size: [400] hidden size: [22] trial: 43, train_loss: 1.844223, test loss: 1.076844, bias2: 0.9288018941879272, variance: 0.14804229140281677\n",
      "Train size: [400] hidden size: [22] trial: 44, train_loss: 1.840083, test loss: 1.076240, bias2: 0.928252637386322, variance: 0.14798764884471893\n",
      "Train size: [400] hidden size: [22] trial: 45, train_loss: 1.844849, test loss: 1.076242, bias2: 0.9265305399894714, variance: 0.14971096813678741\n",
      "Train size: [400] hidden size: [22] trial: 46, train_loss: 1.848001, test loss: 1.077355, bias2: 0.9272240400314331, variance: 0.1501304805278778\n",
      "Train size: [400] hidden size: [22] trial: 47, train_loss: 1.850685, test loss: 1.077182, bias2: 0.9274338483810425, variance: 0.14974799752235413\n",
      "Train size: [400] hidden size: [22] trial: 48, train_loss: 1.850277, test loss: 1.078253, bias2: 0.9269955158233643, variance: 0.15125712752342224\n",
      "Train size: [400] hidden size: [22] trial: 49, train_loss: 1.845212, test loss: 1.079099, bias2: 0.9255321621894836, variance: 0.153567373752594\n",
      "##################################################\n",
      "Train size: [400] hidden size: [25] trial: 0, train_loss: 1.783553, test loss: 1.102423, bias2: 1.1024234294891357, variance: 0.0\n",
      "Train size: [400] hidden size: [25] trial: 1, train_loss: 1.772312, test loss: 1.110845, bias2: 1.0281572341918945, variance: 0.08268805593252182\n",
      "Train size: [400] hidden size: [25] trial: 2, train_loss: 1.756523, test loss: 1.120636, bias2: 0.9989224076271057, variance: 0.12171357125043869\n",
      "Train size: [400] hidden size: [25] trial: 3, train_loss: 1.769884, test loss: 1.132276, bias2: 0.9950990080833435, variance: 0.13717679679393768\n",
      "Train size: [400] hidden size: [25] trial: 4, train_loss: 1.772794, test loss: 1.111693, bias2: 0.9824484586715698, variance: 0.1292445808649063\n",
      "Train size: [400] hidden size: [25] trial: 5, train_loss: 1.767229, test loss: 1.113930, bias2: 0.9762653112411499, variance: 0.1376645565032959\n",
      "Train size: [400] hidden size: [25] trial: 6, train_loss: 1.766686, test loss: 1.116514, bias2: 0.9638588428497314, variance: 0.1526554971933365\n",
      "Train size: [400] hidden size: [25] trial: 7, train_loss: 1.778638, test loss: 1.111796, bias2: 0.9636073112487793, variance: 0.14818879961967468\n",
      "Train size: [400] hidden size: [25] trial: 8, train_loss: 1.779266, test loss: 1.104734, bias2: 0.9562917947769165, variance: 0.14844226837158203\n",
      "Train size: [400] hidden size: [25] trial: 9, train_loss: 1.763400, test loss: 1.107876, bias2: 0.9471219182014465, variance: 0.16075415909290314\n",
      "Train size: [400] hidden size: [25] trial: 10, train_loss: 1.756920, test loss: 1.103351, bias2: 0.944564163684845, variance: 0.1587868183851242\n",
      "Train size: [400] hidden size: [25] trial: 11, train_loss: 1.776332, test loss: 1.100648, bias2: 0.9445972442626953, variance: 0.15605081617832184\n",
      "Train size: [400] hidden size: [25] trial: 12, train_loss: 1.763734, test loss: 1.098407, bias2: 0.9405308961868286, variance: 0.1578756719827652\n",
      "Train size: [400] hidden size: [25] trial: 13, train_loss: 1.765844, test loss: 1.095149, bias2: 0.9409308433532715, variance: 0.15421822667121887\n",
      "Train size: [400] hidden size: [25] trial: 14, train_loss: 1.760622, test loss: 1.094453, bias2: 0.9429948329925537, variance: 0.15145829319953918\n",
      "Train size: [400] hidden size: [25] trial: 15, train_loss: 1.769506, test loss: 1.090865, bias2: 0.9421051144599915, variance: 0.14875978231430054\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [25] trial: 16, train_loss: 1.771851, test loss: 1.087657, bias2: 0.9414093494415283, variance: 0.1462475210428238\n",
      "Train size: [400] hidden size: [25] trial: 17, train_loss: 1.781334, test loss: 1.088899, bias2: 0.9424029588699341, variance: 0.14649644494056702\n",
      "Train size: [400] hidden size: [25] trial: 18, train_loss: 1.784004, test loss: 1.088477, bias2: 0.9412253499031067, variance: 0.1472518891096115\n",
      "Train size: [400] hidden size: [25] trial: 19, train_loss: 1.779058, test loss: 1.088964, bias2: 0.9402554035186768, variance: 0.14870870113372803\n",
      "Train size: [400] hidden size: [25] trial: 20, train_loss: 1.778240, test loss: 1.089747, bias2: 0.9404556751251221, variance: 0.14929163455963135\n",
      "Train size: [400] hidden size: [25] trial: 21, train_loss: 1.776688, test loss: 1.087055, bias2: 0.9390733242034912, variance: 0.14798139035701752\n",
      "Train size: [400] hidden size: [25] trial: 22, train_loss: 1.778061, test loss: 1.086117, bias2: 0.939354658126831, variance: 0.14676186442375183\n",
      "Train size: [400] hidden size: [25] trial: 23, train_loss: 1.777718, test loss: 1.086684, bias2: 0.9386293292045593, variance: 0.14805489778518677\n",
      "Train size: [400] hidden size: [25] trial: 24, train_loss: 1.788938, test loss: 1.086725, bias2: 0.939263105392456, variance: 0.14746226370334625\n",
      "Train size: [400] hidden size: [25] trial: 25, train_loss: 1.784597, test loss: 1.085420, bias2: 0.9384488463401794, variance: 0.14697150886058807\n",
      "Train size: [400] hidden size: [25] trial: 26, train_loss: 1.798021, test loss: 1.084142, bias2: 0.9384583830833435, variance: 0.14568348228931427\n",
      "Train size: [400] hidden size: [25] trial: 27, train_loss: 1.796095, test loss: 1.084629, bias2: 0.9381122589111328, variance: 0.1465165615081787\n",
      "Train size: [400] hidden size: [25] trial: 28, train_loss: 1.800817, test loss: 1.085013, bias2: 0.935562789440155, variance: 0.14945010840892792\n",
      "Train size: [400] hidden size: [25] trial: 29, train_loss: 1.797832, test loss: 1.085319, bias2: 0.9353032112121582, variance: 0.15001608431339264\n",
      "Train size: [400] hidden size: [25] trial: 30, train_loss: 1.795755, test loss: 1.084756, bias2: 0.9343337416648865, variance: 0.1504219025373459\n",
      "Train size: [400] hidden size: [25] trial: 31, train_loss: 1.800367, test loss: 1.087547, bias2: 0.9337780475616455, variance: 0.153769388794899\n",
      "Train size: [400] hidden size: [25] trial: 32, train_loss: 1.793522, test loss: 1.086449, bias2: 0.9333806037902832, variance: 0.1530679613351822\n",
      "Train size: [400] hidden size: [25] trial: 33, train_loss: 1.799232, test loss: 1.085545, bias2: 0.9331322908401489, variance: 0.1524125635623932\n",
      "Train size: [400] hidden size: [25] trial: 34, train_loss: 1.802716, test loss: 1.086818, bias2: 0.933475136756897, variance: 0.15334275364875793\n",
      "Train size: [400] hidden size: [25] trial: 35, train_loss: 1.802559, test loss: 1.089163, bias2: 0.9328020811080933, variance: 0.15636099874973297\n",
      "Train size: [400] hidden size: [25] trial: 36, train_loss: 1.801300, test loss: 1.088110, bias2: 0.9324091672897339, variance: 0.1557011604309082\n",
      "Train size: [400] hidden size: [25] trial: 37, train_loss: 1.800737, test loss: 1.089773, bias2: 0.9320417642593384, variance: 0.157730832695961\n",
      "Train size: [400] hidden size: [25] trial: 38, train_loss: 1.802128, test loss: 1.089993, bias2: 0.9326337575912476, variance: 0.15735898911952972\n",
      "Train size: [400] hidden size: [25] trial: 39, train_loss: 1.804477, test loss: 1.090451, bias2: 0.9328532218933105, variance: 0.15759778022766113\n",
      "Train size: [400] hidden size: [25] trial: 40, train_loss: 1.812473, test loss: 1.091595, bias2: 0.9324239492416382, variance: 0.15917064249515533\n",
      "Train size: [400] hidden size: [25] trial: 41, train_loss: 1.809455, test loss: 1.091189, bias2: 0.9325242042541504, variance: 0.15866434574127197\n",
      "Train size: [400] hidden size: [25] trial: 42, train_loss: 1.810598, test loss: 1.090682, bias2: 0.9315117597579956, variance: 0.15917037427425385\n",
      "Train size: [400] hidden size: [25] trial: 43, train_loss: 1.812950, test loss: 1.089310, bias2: 0.9309044480323792, variance: 0.1584051102399826\n",
      "Train size: [400] hidden size: [25] trial: 44, train_loss: 1.814383, test loss: 1.089528, bias2: 0.9304433465003967, variance: 0.15908484160900116\n",
      "Train size: [400] hidden size: [25] trial: 45, train_loss: 1.816361, test loss: 1.089468, bias2: 0.9294458031654358, variance: 0.16002245247364044\n",
      "Train size: [400] hidden size: [25] trial: 46, train_loss: 1.811421, test loss: 1.090843, bias2: 0.9301723837852478, variance: 0.1606704592704773\n",
      "Train size: [400] hidden size: [25] trial: 47, train_loss: 1.807792, test loss: 1.090002, bias2: 0.9285371899604797, variance: 0.1614644080400467\n",
      "Train size: [400] hidden size: [25] trial: 48, train_loss: 1.808049, test loss: 1.090232, bias2: 0.9288318157196045, variance: 0.16140034794807434\n",
      "Train size: [400] hidden size: [25] trial: 49, train_loss: 1.810672, test loss: 1.090491, bias2: 0.9283467531204224, variance: 0.16214393079280853\n",
      "##################################################\n",
      "Train size: [400] hidden size: [29] trial: 0, train_loss: 1.881296, test loss: 1.113999, bias2: 1.1139990091323853, variance: 5.838822203507732e-10\n",
      "Train size: [400] hidden size: [29] trial: 1, train_loss: 1.783146, test loss: 1.090277, bias2: 1.0266671180725098, variance: 0.06360958516597748\n",
      "Train size: [400] hidden size: [29] trial: 2, train_loss: 1.735181, test loss: 1.072539, bias2: 0.9811195731163025, variance: 0.09141986072063446\n",
      "Train size: [400] hidden size: [29] trial: 3, train_loss: 1.732753, test loss: 1.089763, bias2: 0.9624389410018921, variance: 0.12732437252998352\n",
      "Train size: [400] hidden size: [29] trial: 4, train_loss: 1.754729, test loss: 1.086988, bias2: 0.953991711139679, variance: 0.13299663364887238\n",
      "Train size: [400] hidden size: [29] trial: 5, train_loss: 1.781720, test loss: 1.096177, bias2: 0.9450002312660217, variance: 0.15117625892162323\n",
      "Train size: [400] hidden size: [29] trial: 6, train_loss: 1.786269, test loss: 1.091786, bias2: 0.9451361298561096, variance: 0.1466502696275711\n",
      "Train size: [400] hidden size: [29] trial: 7, train_loss: 1.767743, test loss: 1.094546, bias2: 0.9457610845565796, variance: 0.1487848460674286\n",
      "Train size: [400] hidden size: [29] trial: 8, train_loss: 1.771969, test loss: 1.094932, bias2: 0.9426013231277466, variance: 0.15233014523983002\n",
      "Train size: [400] hidden size: [29] trial: 9, train_loss: 1.769716, test loss: 1.090861, bias2: 0.936070442199707, variance: 0.1547902524471283\n",
      "Train size: [400] hidden size: [29] trial: 10, train_loss: 1.772181, test loss: 1.092812, bias2: 0.9360359311103821, variance: 0.15677575767040253\n",
      "Train size: [400] hidden size: [29] trial: 11, train_loss: 1.774330, test loss: 1.095450, bias2: 0.9343522787094116, variance: 0.1610974222421646\n",
      "Train size: [400] hidden size: [29] trial: 12, train_loss: 1.764967, test loss: 1.090191, bias2: 0.9306629300117493, variance: 0.1595284342765808\n",
      "Train size: [400] hidden size: [29] trial: 13, train_loss: 1.763899, test loss: 1.089339, bias2: 0.9284957647323608, variance: 0.16084326803684235\n",
      "Train size: [400] hidden size: [29] trial: 14, train_loss: 1.763951, test loss: 1.091712, bias2: 0.9263572096824646, variance: 0.1653551608324051\n",
      "Train size: [400] hidden size: [29] trial: 15, train_loss: 1.772758, test loss: 1.091209, bias2: 0.923090398311615, variance: 0.16811878979206085\n",
      "Train size: [400] hidden size: [29] trial: 16, train_loss: 1.779683, test loss: 1.090514, bias2: 0.9222304821014404, variance: 0.1682833433151245\n",
      "Train size: [400] hidden size: [29] trial: 17, train_loss: 1.778388, test loss: 1.088994, bias2: 0.9214491844177246, variance: 0.16754519939422607\n",
      "Train size: [400] hidden size: [29] trial: 18, train_loss: 1.786021, test loss: 1.090951, bias2: 0.920685887336731, variance: 0.1702652871608734\n",
      "Train size: [400] hidden size: [29] trial: 19, train_loss: 1.785875, test loss: 1.087954, bias2: 0.9197797775268555, variance: 0.1681741178035736\n",
      "Train size: [400] hidden size: [29] trial: 20, train_loss: 1.792401, test loss: 1.089197, bias2: 0.9205625057220459, variance: 0.16863402724266052\n",
      "Train size: [400] hidden size: [29] trial: 21, train_loss: 1.794212, test loss: 1.093606, bias2: 0.9186115264892578, variance: 0.17499448359012604\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [29] trial: 22, train_loss: 1.786958, test loss: 1.094095, bias2: 0.9199475049972534, variance: 0.17414721846580505\n",
      "Train size: [400] hidden size: [29] trial: 23, train_loss: 1.786164, test loss: 1.094142, bias2: 0.9186868667602539, variance: 0.17545495927333832\n",
      "Train size: [400] hidden size: [29] trial: 24, train_loss: 1.791020, test loss: 1.093864, bias2: 0.917701244354248, variance: 0.1761629432439804\n",
      "Train size: [400] hidden size: [29] trial: 25, train_loss: 1.786396, test loss: 1.092735, bias2: 0.9145858287811279, variance: 0.17814943194389343\n",
      "Train size: [400] hidden size: [29] trial: 26, train_loss: 1.787839, test loss: 1.091948, bias2: 0.9130297899246216, variance: 0.17891791462898254\n",
      "Train size: [400] hidden size: [29] trial: 27, train_loss: 1.783836, test loss: 1.092601, bias2: 0.9129753708839417, variance: 0.17962521314620972\n",
      "Train size: [400] hidden size: [29] trial: 28, train_loss: 1.779939, test loss: 1.091832, bias2: 0.9133188724517822, variance: 0.17851269245147705\n",
      "Train size: [400] hidden size: [29] trial: 29, train_loss: 1.784004, test loss: 1.092319, bias2: 0.9116433262825012, variance: 0.1806759089231491\n",
      "Train size: [400] hidden size: [29] trial: 30, train_loss: 1.788653, test loss: 1.092371, bias2: 0.9115294814109802, variance: 0.18084128201007843\n",
      "Train size: [400] hidden size: [29] trial: 31, train_loss: 1.786663, test loss: 1.094700, bias2: 0.9116186499595642, variance: 0.18308095633983612\n",
      "Train size: [400] hidden size: [29] trial: 32, train_loss: 1.780271, test loss: 1.093701, bias2: 0.9103278517723083, variance: 0.18337363004684448\n",
      "Train size: [400] hidden size: [29] trial: 33, train_loss: 1.779775, test loss: 1.094703, bias2: 0.9091107845306396, variance: 0.1855916678905487\n",
      "Train size: [400] hidden size: [29] trial: 34, train_loss: 1.782265, test loss: 1.092805, bias2: 0.9076173901557922, variance: 0.18518753349781036\n",
      "Train size: [400] hidden size: [29] trial: 35, train_loss: 1.778974, test loss: 1.092794, bias2: 0.9063444137573242, variance: 0.1864500194787979\n",
      "Train size: [400] hidden size: [29] trial: 36, train_loss: 1.780262, test loss: 1.091459, bias2: 0.9040841460227966, variance: 0.1873752623796463\n",
      "Train size: [400] hidden size: [29] trial: 37, train_loss: 1.781155, test loss: 1.090961, bias2: 0.9031195640563965, variance: 0.18784141540527344\n",
      "Train size: [400] hidden size: [29] trial: 38, train_loss: 1.778857, test loss: 1.091047, bias2: 0.9038399457931519, variance: 0.1872071921825409\n",
      "Train size: [400] hidden size: [29] trial: 39, train_loss: 1.779937, test loss: 1.091848, bias2: 0.9041467905044556, variance: 0.18770122528076172\n",
      "Train size: [400] hidden size: [29] trial: 40, train_loss: 1.773467, test loss: 1.089921, bias2: 0.9048280715942383, variance: 0.18509256839752197\n",
      "Train size: [400] hidden size: [29] trial: 41, train_loss: 1.773433, test loss: 1.089670, bias2: 0.9037677049636841, variance: 0.18590211868286133\n",
      "Train size: [400] hidden size: [29] trial: 42, train_loss: 1.773401, test loss: 1.090140, bias2: 0.9056531190872192, variance: 0.18448641896247864\n",
      "Train size: [400] hidden size: [29] trial: 43, train_loss: 1.779271, test loss: 1.090357, bias2: 0.9048997759819031, variance: 0.1854567974805832\n",
      "Train size: [400] hidden size: [29] trial: 44, train_loss: 1.772331, test loss: 1.091538, bias2: 0.9049421548843384, variance: 0.18659579753875732\n",
      "Train size: [400] hidden size: [29] trial: 45, train_loss: 1.780877, test loss: 1.092329, bias2: 0.906291663646698, variance: 0.1860368847846985\n",
      "Train size: [400] hidden size: [29] trial: 46, train_loss: 1.775635, test loss: 1.092895, bias2: 0.9069974422454834, variance: 0.18589724600315094\n",
      "Train size: [400] hidden size: [29] trial: 47, train_loss: 1.774192, test loss: 1.091921, bias2: 0.9058421850204468, variance: 0.18607863783836365\n",
      "Train size: [400] hidden size: [29] trial: 48, train_loss: 1.771880, test loss: 1.091534, bias2: 0.9064809679985046, variance: 0.1850532740354538\n",
      "Train size: [400] hidden size: [29] trial: 49, train_loss: 1.770558, test loss: 1.091614, bias2: 0.9058369994163513, variance: 0.1857765167951584\n",
      "##################################################\n",
      "Train size: [400] hidden size: [33] trial: 0, train_loss: 1.974927, test loss: 1.133330, bias2: 1.1333304643630981, variance: 9.731370154142382e-10\n",
      "Train size: [400] hidden size: [33] trial: 1, train_loss: 1.926732, test loss: 1.114990, bias2: 1.0254539251327515, variance: 0.08953585475683212\n",
      "Train size: [400] hidden size: [33] trial: 2, train_loss: 1.877539, test loss: 1.118419, bias2: 0.9962676763534546, variance: 0.12215173244476318\n",
      "Train size: [400] hidden size: [33] trial: 3, train_loss: 1.799155, test loss: 1.099217, bias2: 0.958672285079956, variance: 0.1405448615550995\n",
      "Train size: [400] hidden size: [33] trial: 4, train_loss: 1.789419, test loss: 1.095333, bias2: 0.9349275827407837, variance: 0.16040538251399994\n",
      "Train size: [400] hidden size: [33] trial: 5, train_loss: 1.827971, test loss: 1.099806, bias2: 0.9270974397659302, variance: 0.17270837724208832\n",
      "Train size: [400] hidden size: [33] trial: 6, train_loss: 1.801528, test loss: 1.102265, bias2: 0.9245515465736389, variance: 0.17771321535110474\n",
      "Train size: [400] hidden size: [33] trial: 7, train_loss: 1.792448, test loss: 1.102428, bias2: 0.9152969121932983, variance: 0.18713118135929108\n",
      "Train size: [400] hidden size: [33] trial: 8, train_loss: 1.784159, test loss: 1.105650, bias2: 0.9122473001480103, variance: 0.19340267777442932\n",
      "Train size: [400] hidden size: [33] trial: 9, train_loss: 1.786224, test loss: 1.103354, bias2: 0.9020938873291016, variance: 0.20125994086265564\n",
      "Train size: [400] hidden size: [33] trial: 10, train_loss: 1.799915, test loss: 1.111155, bias2: 0.9024155139923096, variance: 0.20873941481113434\n",
      "Train size: [400] hidden size: [33] trial: 11, train_loss: 1.787339, test loss: 1.109536, bias2: 0.9084368348121643, variance: 0.2010994553565979\n",
      "Train size: [400] hidden size: [33] trial: 12, train_loss: 1.786184, test loss: 1.106801, bias2: 0.9075455665588379, variance: 0.1992550790309906\n",
      "Train size: [400] hidden size: [33] trial: 13, train_loss: 1.779168, test loss: 1.105674, bias2: 0.9071580767631531, variance: 0.19851605594158173\n",
      "Train size: [400] hidden size: [33] trial: 14, train_loss: 1.764445, test loss: 1.104657, bias2: 0.9014238119125366, variance: 0.20323289930820465\n",
      "Train size: [400] hidden size: [33] trial: 15, train_loss: 1.760441, test loss: 1.100221, bias2: 0.8950755000114441, variance: 0.20514540374279022\n",
      "Train size: [400] hidden size: [33] trial: 16, train_loss: 1.764332, test loss: 1.100830, bias2: 0.8931611776351929, variance: 0.20766890048980713\n",
      "Train size: [400] hidden size: [33] trial: 17, train_loss: 1.761803, test loss: 1.101457, bias2: 0.8949665427207947, variance: 0.2064909189939499\n",
      "Train size: [400] hidden size: [33] trial: 18, train_loss: 1.773754, test loss: 1.104144, bias2: 0.8929486870765686, variance: 0.2111949324607849\n",
      "Train size: [400] hidden size: [33] trial: 19, train_loss: 1.768032, test loss: 1.101237, bias2: 0.8911005854606628, variance: 0.21013660728931427\n",
      "Train size: [400] hidden size: [33] trial: 20, train_loss: 1.764791, test loss: 1.099882, bias2: 0.8886040449142456, variance: 0.21127846837043762\n",
      "Train size: [400] hidden size: [33] trial: 21, train_loss: 1.764571, test loss: 1.097254, bias2: 0.8870976567268372, variance: 0.2101568579673767\n",
      "Train size: [400] hidden size: [33] trial: 22, train_loss: 1.761514, test loss: 1.097604, bias2: 0.886969804763794, variance: 0.21063436567783356\n",
      "Train size: [400] hidden size: [33] trial: 23, train_loss: 1.773218, test loss: 1.099419, bias2: 0.888238251209259, variance: 0.2111806422472\n",
      "Train size: [400] hidden size: [33] trial: 24, train_loss: 1.769218, test loss: 1.100248, bias2: 0.8900777101516724, variance: 0.21017052233219147\n",
      "Train size: [400] hidden size: [33] trial: 25, train_loss: 1.776900, test loss: 1.102618, bias2: 0.892737627029419, variance: 0.20987984538078308\n",
      "Train size: [400] hidden size: [33] trial: 26, train_loss: 1.772716, test loss: 1.107258, bias2: 0.8929962515830994, variance: 0.21426159143447876\n",
      "Train size: [400] hidden size: [33] trial: 27, train_loss: 1.776898, test loss: 1.109706, bias2: 0.8920524716377258, variance: 0.2176540493965149\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [33] trial: 28, train_loss: 1.776876, test loss: 1.107170, bias2: 0.8902997970581055, variance: 0.21686992049217224\n",
      "Train size: [400] hidden size: [33] trial: 29, train_loss: 1.780531, test loss: 1.104539, bias2: 0.8884462118148804, variance: 0.21609283983707428\n",
      "Train size: [400] hidden size: [33] trial: 30, train_loss: 1.779187, test loss: 1.105706, bias2: 0.8915073871612549, variance: 0.21419896185398102\n",
      "Train size: [400] hidden size: [33] trial: 31, train_loss: 1.776831, test loss: 1.104280, bias2: 0.8907828330993652, variance: 0.21349692344665527\n",
      "Train size: [400] hidden size: [33] trial: 32, train_loss: 1.770571, test loss: 1.105691, bias2: 0.8928768038749695, variance: 0.21281439065933228\n",
      "Train size: [400] hidden size: [33] trial: 33, train_loss: 1.773723, test loss: 1.105346, bias2: 0.8932361006736755, variance: 0.21210938692092896\n",
      "Train size: [400] hidden size: [33] trial: 34, train_loss: 1.774399, test loss: 1.104928, bias2: 0.8928207755088806, variance: 0.2121071219444275\n",
      "Train size: [400] hidden size: [33] trial: 35, train_loss: 1.773284, test loss: 1.106154, bias2: 0.893531322479248, variance: 0.21262308955192566\n",
      "Train size: [400] hidden size: [33] trial: 36, train_loss: 1.770862, test loss: 1.104867, bias2: 0.8919680118560791, variance: 0.21289898455142975\n",
      "Train size: [400] hidden size: [33] trial: 37, train_loss: 1.772483, test loss: 1.104672, bias2: 0.8932209014892578, variance: 0.2114509493112564\n",
      "Train size: [400] hidden size: [33] trial: 38, train_loss: 1.774569, test loss: 1.104594, bias2: 0.8936538100242615, variance: 0.21094030141830444\n",
      "Train size: [400] hidden size: [33] trial: 39, train_loss: 1.776865, test loss: 1.103045, bias2: 0.8940180540084839, variance: 0.20902667939662933\n",
      "Train size: [400] hidden size: [33] trial: 40, train_loss: 1.772920, test loss: 1.102276, bias2: 0.8931995630264282, variance: 0.20907685160636902\n",
      "Train size: [400] hidden size: [33] trial: 41, train_loss: 1.769000, test loss: 1.103575, bias2: 0.8925369381904602, variance: 0.21103815734386444\n",
      "Train size: [400] hidden size: [33] trial: 42, train_loss: 1.774023, test loss: 1.103972, bias2: 0.8943569660186768, variance: 0.20961523056030273\n",
      "Train size: [400] hidden size: [33] trial: 43, train_loss: 1.773011, test loss: 1.104577, bias2: 0.8955624103546143, variance: 0.20901426672935486\n",
      "Train size: [400] hidden size: [33] trial: 44, train_loss: 1.771848, test loss: 1.106390, bias2: 0.8941885232925415, variance: 0.21220098435878754\n",
      "Train size: [400] hidden size: [33] trial: 45, train_loss: 1.769256, test loss: 1.106363, bias2: 0.8953856229782104, variance: 0.2109769880771637\n",
      "Train size: [400] hidden size: [33] trial: 46, train_loss: 1.774990, test loss: 1.106644, bias2: 0.8957236409187317, variance: 0.21092039346694946\n",
      "Train size: [400] hidden size: [33] trial: 47, train_loss: 1.776122, test loss: 1.106433, bias2: 0.8948976397514343, variance: 0.2115355134010315\n",
      "Train size: [400] hidden size: [33] trial: 48, train_loss: 1.773907, test loss: 1.107938, bias2: 0.8947329521179199, variance: 0.21320533752441406\n",
      "Train size: [400] hidden size: [33] trial: 49, train_loss: 1.771296, test loss: 1.110316, bias2: 0.893366813659668, variance: 0.21694955229759216\n",
      "##################################################\n",
      "Train size: [400] hidden size: [38] trial: 0, train_loss: 2.153658, test loss: 1.137592, bias2: 1.1375924348831177, variance: 1.0704507280578923e-09\n",
      "Train size: [400] hidden size: [38] trial: 1, train_loss: 1.893932, test loss: 1.136186, bias2: 1.0101476907730103, variance: 0.1260378360748291\n",
      "Train size: [400] hidden size: [38] trial: 2, train_loss: 1.818698, test loss: 1.154318, bias2: 0.989385724067688, variance: 0.1649320125579834\n",
      "Train size: [400] hidden size: [38] trial: 3, train_loss: 1.821835, test loss: 1.162713, bias2: 0.9692521691322327, variance: 0.19346053898334503\n",
      "Train size: [400] hidden size: [38] trial: 4, train_loss: 1.807187, test loss: 1.155705, bias2: 0.962284505367279, variance: 0.19342069327831268\n",
      "Train size: [400] hidden size: [38] trial: 5, train_loss: 1.807120, test loss: 1.140337, bias2: 0.9426903128623962, variance: 0.19764666259288788\n",
      "Train size: [400] hidden size: [38] trial: 6, train_loss: 1.774002, test loss: 1.145616, bias2: 0.9336603283882141, variance: 0.2119554728269577\n",
      "Train size: [400] hidden size: [38] trial: 7, train_loss: 1.774539, test loss: 1.137953, bias2: 0.9325127601623535, variance: 0.20544053614139557\n",
      "Train size: [400] hidden size: [38] trial: 8, train_loss: 1.754705, test loss: 1.130487, bias2: 0.920669436454773, variance: 0.20981715619564056\n",
      "Train size: [400] hidden size: [38] trial: 9, train_loss: 1.744114, test loss: 1.140312, bias2: 0.9211485385894775, variance: 0.2191639095544815\n",
      "Train size: [400] hidden size: [38] trial: 10, train_loss: 1.729516, test loss: 1.139970, bias2: 0.9257472157478333, variance: 0.21422284841537476\n",
      "Train size: [400] hidden size: [38] trial: 11, train_loss: 1.725225, test loss: 1.142045, bias2: 0.9277276992797852, variance: 0.21431684494018555\n",
      "Train size: [400] hidden size: [38] trial: 12, train_loss: 1.721187, test loss: 1.142230, bias2: 0.9266952872276306, variance: 0.2155342847108841\n",
      "Train size: [400] hidden size: [38] trial: 13, train_loss: 1.719601, test loss: 1.142833, bias2: 0.9206042289733887, variance: 0.2222292274236679\n",
      "Train size: [400] hidden size: [38] trial: 14, train_loss: 1.734379, test loss: 1.141371, bias2: 0.9193586707115173, variance: 0.22201187908649445\n",
      "Train size: [400] hidden size: [38] trial: 15, train_loss: 1.741891, test loss: 1.136621, bias2: 0.9159505367279053, variance: 0.22067047655582428\n",
      "Train size: [400] hidden size: [38] trial: 16, train_loss: 1.742240, test loss: 1.136476, bias2: 0.9128667712211609, variance: 0.2236090451478958\n",
      "Train size: [400] hidden size: [38] trial: 17, train_loss: 1.744656, test loss: 1.135003, bias2: 0.9128287434577942, variance: 0.22217421233654022\n",
      "Train size: [400] hidden size: [38] trial: 18, train_loss: 1.750753, test loss: 1.137000, bias2: 0.9116856455802917, variance: 0.2253144234418869\n",
      "Train size: [400] hidden size: [38] trial: 19, train_loss: 1.761822, test loss: 1.134184, bias2: 0.9087706804275513, variance: 0.22541283071041107\n",
      "Train size: [400] hidden size: [38] trial: 20, train_loss: 1.760691, test loss: 1.136139, bias2: 0.9091452360153198, variance: 0.22699414193630219\n",
      "Train size: [400] hidden size: [38] trial: 21, train_loss: 1.761089, test loss: 1.137097, bias2: 0.9095696210861206, variance: 0.22752714157104492\n",
      "Train size: [400] hidden size: [38] trial: 22, train_loss: 1.750341, test loss: 1.134396, bias2: 0.9048848152160645, variance: 0.22951152920722961\n",
      "Train size: [400] hidden size: [38] trial: 23, train_loss: 1.754243, test loss: 1.134005, bias2: 0.904144823551178, variance: 0.2298598736524582\n",
      "Train size: [400] hidden size: [38] trial: 24, train_loss: 1.757984, test loss: 1.134292, bias2: 0.9047845005989075, variance: 0.22950725257396698\n",
      "Train size: [400] hidden size: [38] trial: 25, train_loss: 1.762595, test loss: 1.131638, bias2: 0.9067288637161255, variance: 0.2249089479446411\n",
      "Train size: [400] hidden size: [38] trial: 26, train_loss: 1.763060, test loss: 1.132276, bias2: 0.9058821201324463, variance: 0.22639347612857819\n",
      "Train size: [400] hidden size: [38] trial: 27, train_loss: 1.764118, test loss: 1.132255, bias2: 0.907261848449707, variance: 0.22499272227287292\n",
      "Train size: [400] hidden size: [38] trial: 28, train_loss: 1.761347, test loss: 1.131447, bias2: 0.9080628752708435, variance: 0.2233843207359314\n",
      "Train size: [400] hidden size: [38] trial: 29, train_loss: 1.765668, test loss: 1.133141, bias2: 0.9058971405029297, variance: 0.22724400460720062\n",
      "Train size: [400] hidden size: [38] trial: 30, train_loss: 1.763856, test loss: 1.133099, bias2: 0.9045988917350769, variance: 0.22849969565868378\n",
      "Train size: [400] hidden size: [38] trial: 31, train_loss: 1.766469, test loss: 1.134620, bias2: 0.9054650068283081, variance: 0.2291552871465683\n",
      "Train size: [400] hidden size: [38] trial: 32, train_loss: 1.759669, test loss: 1.135324, bias2: 0.9062532186508179, variance: 0.22907043993473053\n",
      "Train size: [400] hidden size: [38] trial: 33, train_loss: 1.757902, test loss: 1.134118, bias2: 0.9032100439071655, variance: 0.2309075891971588\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [38] trial: 34, train_loss: 1.761004, test loss: 1.133101, bias2: 0.9033804535865784, variance: 0.22972087562084198\n",
      "Train size: [400] hidden size: [38] trial: 35, train_loss: 1.756439, test loss: 1.131511, bias2: 0.9017601013183594, variance: 0.2297506034374237\n",
      "Train size: [400] hidden size: [38] trial: 36, train_loss: 1.756934, test loss: 1.131511, bias2: 0.9010517597198486, variance: 0.23045897483825684\n",
      "Train size: [400] hidden size: [38] trial: 37, train_loss: 1.758108, test loss: 1.132681, bias2: 0.9017865061759949, variance: 0.23089486360549927\n",
      "Train size: [400] hidden size: [38] trial: 38, train_loss: 1.758084, test loss: 1.132730, bias2: 0.9027853012084961, variance: 0.22994448244571686\n",
      "Train size: [400] hidden size: [38] trial: 39, train_loss: 1.761229, test loss: 1.134657, bias2: 0.904534637928009, variance: 0.23012273013591766\n",
      "Train size: [400] hidden size: [38] trial: 40, train_loss: 1.760265, test loss: 1.134767, bias2: 0.9038887619972229, variance: 0.2308778315782547\n",
      "Train size: [400] hidden size: [38] trial: 41, train_loss: 1.757450, test loss: 1.135012, bias2: 0.9040012359619141, variance: 0.2310110479593277\n",
      "Train size: [400] hidden size: [38] trial: 42, train_loss: 1.757673, test loss: 1.135801, bias2: 0.9046369791030884, variance: 0.23116423189640045\n",
      "Train size: [400] hidden size: [38] trial: 43, train_loss: 1.754468, test loss: 1.134478, bias2: 0.9039171934127808, variance: 0.2305610328912735\n",
      "Train size: [400] hidden size: [38] trial: 44, train_loss: 1.757852, test loss: 1.133322, bias2: 0.90386563539505, variance: 0.22945648431777954\n",
      "Train size: [400] hidden size: [38] trial: 45, train_loss: 1.755708, test loss: 1.132605, bias2: 0.9042190313339233, variance: 0.2283865213394165\n",
      "Train size: [400] hidden size: [38] trial: 46, train_loss: 1.754081, test loss: 1.131520, bias2: 0.9053946733474731, variance: 0.22612513601779938\n",
      "Train size: [400] hidden size: [38] trial: 47, train_loss: 1.752129, test loss: 1.130558, bias2: 0.9044924974441528, variance: 0.2260657548904419\n",
      "Train size: [400] hidden size: [38] trial: 48, train_loss: 1.752350, test loss: 1.129139, bias2: 0.9039621949195862, variance: 0.22517722845077515\n",
      "Train size: [400] hidden size: [38] trial: 49, train_loss: 1.753042, test loss: 1.130192, bias2: 0.9021155834197998, variance: 0.22807671129703522\n",
      "##################################################\n",
      "Train size: [400] hidden size: [44] trial: 0, train_loss: 1.855612, test loss: 1.157009, bias2: 1.1570091247558594, variance: 9.731370154142382e-10\n",
      "Train size: [400] hidden size: [44] trial: 1, train_loss: 1.895486, test loss: 1.135442, bias2: 0.9653432369232178, variance: 0.1700991541147232\n",
      "Train size: [400] hidden size: [44] trial: 2, train_loss: 1.796252, test loss: 1.148978, bias2: 0.9225980043411255, variance: 0.22637951374053955\n",
      "Train size: [400] hidden size: [44] trial: 3, train_loss: 1.803953, test loss: 1.172750, bias2: 0.9057879447937012, variance: 0.2669622600078583\n",
      "Train size: [400] hidden size: [44] trial: 4, train_loss: 1.762279, test loss: 1.161090, bias2: 0.88894122838974, variance: 0.2721490263938904\n",
      "Train size: [400] hidden size: [44] trial: 5, train_loss: 1.747549, test loss: 1.157545, bias2: 0.8808709383010864, variance: 0.27667438983917236\n",
      "Train size: [400] hidden size: [44] trial: 6, train_loss: 1.727761, test loss: 1.160838, bias2: 0.8737953901290894, variance: 0.28704285621643066\n",
      "Train size: [400] hidden size: [44] trial: 7, train_loss: 1.738830, test loss: 1.157194, bias2: 0.8673434257507324, variance: 0.2898510992527008\n",
      "Train size: [400] hidden size: [44] trial: 8, train_loss: 1.759973, test loss: 1.161768, bias2: 0.8705141544342041, variance: 0.2912537157535553\n",
      "Train size: [400] hidden size: [44] trial: 9, train_loss: 1.733109, test loss: 1.160430, bias2: 0.8761150240898132, variance: 0.284315288066864\n",
      "Train size: [400] hidden size: [44] trial: 10, train_loss: 1.727393, test loss: 1.163912, bias2: 0.8686805963516235, variance: 0.29523107409477234\n",
      "Train size: [400] hidden size: [44] trial: 11, train_loss: 1.729744, test loss: 1.161770, bias2: 0.8659064769744873, variance: 0.29586365818977356\n",
      "Train size: [400] hidden size: [44] trial: 12, train_loss: 1.724625, test loss: 1.160762, bias2: 0.8636586666107178, variance: 0.29710304737091064\n",
      "Train size: [400] hidden size: [44] trial: 13, train_loss: 1.714002, test loss: 1.163198, bias2: 0.8638746738433838, variance: 0.29932352900505066\n",
      "Train size: [400] hidden size: [44] trial: 14, train_loss: 1.714488, test loss: 1.159607, bias2: 0.8645220994949341, variance: 0.29508495330810547\n",
      "Train size: [400] hidden size: [44] trial: 15, train_loss: 1.720181, test loss: 1.160213, bias2: 0.8660664558410645, variance: 0.29414689540863037\n",
      "Train size: [400] hidden size: [44] trial: 16, train_loss: 1.719674, test loss: 1.155286, bias2: 0.8646496534347534, variance: 0.29063618183135986\n",
      "Train size: [400] hidden size: [44] trial: 17, train_loss: 1.710394, test loss: 1.152336, bias2: 0.8620317578315735, variance: 0.29030412435531616\n",
      "Train size: [400] hidden size: [44] trial: 18, train_loss: 1.702265, test loss: 1.153962, bias2: 0.8641159534454346, variance: 0.2898459732532501\n",
      "Train size: [400] hidden size: [44] trial: 19, train_loss: 1.694908, test loss: 1.152319, bias2: 0.8641773462295532, variance: 0.2881418764591217\n",
      "Train size: [400] hidden size: [44] trial: 20, train_loss: 1.700683, test loss: 1.151141, bias2: 0.8608999252319336, variance: 0.29024097323417664\n",
      "Train size: [400] hidden size: [44] trial: 21, train_loss: 1.710431, test loss: 1.147195, bias2: 0.8610036969184875, variance: 0.2861911654472351\n",
      "Train size: [400] hidden size: [44] trial: 22, train_loss: 1.707360, test loss: 1.149091, bias2: 0.8628052473068237, variance: 0.28628531098365784\n",
      "Train size: [400] hidden size: [44] trial: 23, train_loss: 1.711938, test loss: 1.151565, bias2: 0.8640605807304382, variance: 0.28750425577163696\n",
      "Train size: [400] hidden size: [44] trial: 24, train_loss: 1.707023, test loss: 1.156495, bias2: 0.8655096292495728, variance: 0.2909855544567108\n",
      "Train size: [400] hidden size: [44] trial: 25, train_loss: 1.705708, test loss: 1.157076, bias2: 0.8636661767959595, variance: 0.29341015219688416\n",
      "Train size: [400] hidden size: [44] trial: 26, train_loss: 1.696555, test loss: 1.154773, bias2: 0.8611130118370056, variance: 0.29366010427474976\n",
      "Train size: [400] hidden size: [44] trial: 27, train_loss: 1.691898, test loss: 1.152932, bias2: 0.8591482043266296, variance: 0.2937842011451721\n",
      "Train size: [400] hidden size: [44] trial: 28, train_loss: 1.691255, test loss: 1.156730, bias2: 0.8584713935852051, variance: 0.2982586622238159\n",
      "Train size: [400] hidden size: [44] trial: 29, train_loss: 1.693209, test loss: 1.155407, bias2: 0.8579842448234558, variance: 0.29742270708084106\n",
      "Train size: [400] hidden size: [44] trial: 30, train_loss: 1.693747, test loss: 1.155784, bias2: 0.8592767715454102, variance: 0.29650744795799255\n",
      "Train size: [400] hidden size: [44] trial: 31, train_loss: 1.691121, test loss: 1.156914, bias2: 0.8582718372344971, variance: 0.29864180088043213\n",
      "Train size: [400] hidden size: [44] trial: 32, train_loss: 1.689827, test loss: 1.158003, bias2: 0.8588322401046753, variance: 0.2991710603237152\n",
      "Train size: [400] hidden size: [44] trial: 33, train_loss: 1.685725, test loss: 1.156457, bias2: 0.8570736646652222, variance: 0.2993834316730499\n",
      "Train size: [400] hidden size: [44] trial: 34, train_loss: 1.687686, test loss: 1.155926, bias2: 0.8549410104751587, variance: 0.30098533630371094\n",
      "Train size: [400] hidden size: [44] trial: 35, train_loss: 1.689607, test loss: 1.154981, bias2: 0.8557398915290833, variance: 0.29924100637435913\n",
      "Train size: [400] hidden size: [44] trial: 36, train_loss: 1.688387, test loss: 1.156535, bias2: 0.8573487997055054, variance: 0.2991863191127777\n",
      "Train size: [400] hidden size: [44] trial: 37, train_loss: 1.686735, test loss: 1.155728, bias2: 0.853421688079834, variance: 0.3023059070110321\n",
      "Train size: [400] hidden size: [44] trial: 38, train_loss: 1.684695, test loss: 1.155843, bias2: 0.853812575340271, variance: 0.30203020572662354\n",
      "Train size: [400] hidden size: [44] trial: 39, train_loss: 1.682085, test loss: 1.153534, bias2: 0.8521015644073486, variance: 0.3014321029186249\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [44] trial: 40, train_loss: 1.685425, test loss: 1.151371, bias2: 0.8509425520896912, variance: 0.30042868852615356\n",
      "Train size: [400] hidden size: [44] trial: 41, train_loss: 1.688442, test loss: 1.152780, bias2: 0.8510324954986572, variance: 0.30174732208251953\n",
      "Train size: [400] hidden size: [44] trial: 42, train_loss: 1.687701, test loss: 1.150552, bias2: 0.8520292043685913, variance: 0.2985225021839142\n",
      "Train size: [400] hidden size: [44] trial: 43, train_loss: 1.689880, test loss: 1.149960, bias2: 0.8528539538383484, variance: 0.2971060872077942\n",
      "Train size: [400] hidden size: [44] trial: 44, train_loss: 1.687283, test loss: 1.148966, bias2: 0.8531256318092346, variance: 0.2958407998085022\n",
      "Train size: [400] hidden size: [44] trial: 45, train_loss: 1.686688, test loss: 1.149569, bias2: 0.8519578576087952, variance: 0.29761070013046265\n",
      "Train size: [400] hidden size: [44] trial: 46, train_loss: 1.687675, test loss: 1.148233, bias2: 0.8525961637496948, variance: 0.295636922121048\n",
      "Train size: [400] hidden size: [44] trial: 47, train_loss: 1.683618, test loss: 1.146825, bias2: 0.8512529134750366, variance: 0.2955721914768219\n",
      "Train size: [400] hidden size: [44] trial: 48, train_loss: 1.679413, test loss: 1.149744, bias2: 0.8507687449455261, variance: 0.29897528886795044\n",
      "Train size: [400] hidden size: [44] trial: 49, train_loss: 1.683563, test loss: 1.149382, bias2: 0.8504753708839417, variance: 0.2989066243171692\n",
      "##################################################\n",
      "Train size: [400] hidden size: [51] trial: 0, train_loss: 1.857943, test loss: 1.200029, bias2: 1.2000293731689453, variance: 1.3623918659888545e-09\n",
      "Train size: [400] hidden size: [51] trial: 1, train_loss: 1.676412, test loss: 1.200041, bias2: 0.9779475927352905, variance: 0.22209319472312927\n",
      "Train size: [400] hidden size: [51] trial: 2, train_loss: 1.612307, test loss: 1.168049, bias2: 0.920307993888855, variance: 0.2477407455444336\n",
      "Train size: [400] hidden size: [51] trial: 3, train_loss: 1.619399, test loss: 1.141236, bias2: 0.8687999248504639, variance: 0.272436261177063\n",
      "Train size: [400] hidden size: [51] trial: 4, train_loss: 1.619421, test loss: 1.141021, bias2: 0.8505245447158813, variance: 0.29049643874168396\n",
      "Train size: [400] hidden size: [51] trial: 5, train_loss: 1.648790, test loss: 1.140558, bias2: 0.8434659242630005, variance: 0.2970925271511078\n",
      "Train size: [400] hidden size: [51] trial: 6, train_loss: 1.670980, test loss: 1.149571, bias2: 0.8501704931259155, variance: 0.2994008958339691\n",
      "Train size: [400] hidden size: [51] trial: 7, train_loss: 1.679607, test loss: 1.169593, bias2: 0.8507874011993408, variance: 0.3188055455684662\n",
      "Train size: [400] hidden size: [51] trial: 8, train_loss: 1.681994, test loss: 1.172834, bias2: 0.8522128462791443, variance: 0.3206215500831604\n",
      "Train size: [400] hidden size: [51] trial: 9, train_loss: 1.677890, test loss: 1.163281, bias2: 0.8341951370239258, variance: 0.3290860950946808\n",
      "Train size: [400] hidden size: [51] trial: 10, train_loss: 1.669390, test loss: 1.157887, bias2: 0.8295565843582153, variance: 0.32833078503608704\n",
      "Train size: [400] hidden size: [51] trial: 11, train_loss: 1.660474, test loss: 1.154273, bias2: 0.8396677374839783, variance: 0.3146054148674011\n",
      "Train size: [400] hidden size: [51] trial: 12, train_loss: 1.673002, test loss: 1.160272, bias2: 0.8387953639030457, variance: 0.3214762806892395\n",
      "Train size: [400] hidden size: [51] trial: 13, train_loss: 1.674802, test loss: 1.161236, bias2: 0.8349961042404175, variance: 0.32624027132987976\n",
      "Train size: [400] hidden size: [51] trial: 14, train_loss: 1.682653, test loss: 1.153414, bias2: 0.8365782499313354, variance: 0.31683531403541565\n",
      "Train size: [400] hidden size: [51] trial: 15, train_loss: 1.672529, test loss: 1.147492, bias2: 0.8331411480903625, variance: 0.31435126066207886\n",
      "Train size: [400] hidden size: [51] trial: 16, train_loss: 1.672468, test loss: 1.156329, bias2: 0.8345978856086731, variance: 0.32173091173171997\n",
      "Train size: [400] hidden size: [51] trial: 17, train_loss: 1.672241, test loss: 1.156964, bias2: 0.8354476690292358, variance: 0.32151666283607483\n",
      "Train size: [400] hidden size: [51] trial: 18, train_loss: 1.666365, test loss: 1.153034, bias2: 0.8354873657226562, variance: 0.31754693388938904\n",
      "Train size: [400] hidden size: [51] trial: 19, train_loss: 1.668704, test loss: 1.158788, bias2: 0.838411271572113, variance: 0.3203762173652649\n",
      "Train size: [400] hidden size: [51] trial: 20, train_loss: 1.662024, test loss: 1.158039, bias2: 0.8373485803604126, variance: 0.3206906020641327\n",
      "Train size: [400] hidden size: [51] trial: 21, train_loss: 1.668364, test loss: 1.156037, bias2: 0.8352596163749695, variance: 0.3207772374153137\n",
      "Train size: [400] hidden size: [51] trial: 22, train_loss: 1.662983, test loss: 1.159462, bias2: 0.8339262008666992, variance: 0.32553526759147644\n",
      "Train size: [400] hidden size: [51] trial: 23, train_loss: 1.660016, test loss: 1.159680, bias2: 0.8335655927658081, variance: 0.32611432671546936\n",
      "Train size: [400] hidden size: [51] trial: 24, train_loss: 1.661052, test loss: 1.159364, bias2: 0.83597332239151, variance: 0.32339030504226685\n",
      "Train size: [400] hidden size: [51] trial: 25, train_loss: 1.661305, test loss: 1.161866, bias2: 0.8374015092849731, variance: 0.3244647979736328\n",
      "Train size: [400] hidden size: [51] trial: 26, train_loss: 1.660148, test loss: 1.162362, bias2: 0.8357386589050293, variance: 0.326623797416687\n",
      "Train size: [400] hidden size: [51] trial: 27, train_loss: 1.653782, test loss: 1.161190, bias2: 0.8364334106445312, variance: 0.3247568607330322\n",
      "Train size: [400] hidden size: [51] trial: 28, train_loss: 1.655945, test loss: 1.162150, bias2: 0.8371317386627197, variance: 0.32501843571662903\n",
      "Train size: [400] hidden size: [51] trial: 29, train_loss: 1.656266, test loss: 1.162183, bias2: 0.8381167054176331, variance: 0.3240665793418884\n",
      "Train size: [400] hidden size: [51] trial: 30, train_loss: 1.656968, test loss: 1.161769, bias2: 0.8402209281921387, variance: 0.3215477168560028\n",
      "Train size: [400] hidden size: [51] trial: 31, train_loss: 1.656815, test loss: 1.160714, bias2: 0.8417899012565613, variance: 0.3189240097999573\n",
      "Train size: [400] hidden size: [51] trial: 32, train_loss: 1.653640, test loss: 1.160007, bias2: 0.8416140079498291, variance: 0.31839266419410706\n",
      "Train size: [400] hidden size: [51] trial: 33, train_loss: 1.655454, test loss: 1.161731, bias2: 0.8429098129272461, variance: 0.31882110238075256\n",
      "Train size: [400] hidden size: [51] trial: 34, train_loss: 1.655784, test loss: 1.162133, bias2: 0.8452717065811157, variance: 0.3168611526489258\n",
      "Train size: [400] hidden size: [51] trial: 35, train_loss: 1.661910, test loss: 1.163073, bias2: 0.845702052116394, variance: 0.3173709809780121\n",
      "Train size: [400] hidden size: [51] trial: 36, train_loss: 1.664595, test loss: 1.162550, bias2: 0.8465737104415894, variance: 0.31597664952278137\n",
      "Train size: [400] hidden size: [51] trial: 37, train_loss: 1.660400, test loss: 1.161110, bias2: 0.8449069261550903, variance: 0.3162032663822174\n",
      "Train size: [400] hidden size: [51] trial: 38, train_loss: 1.659887, test loss: 1.160784, bias2: 0.8440948128700256, variance: 0.31668907403945923\n",
      "Train size: [400] hidden size: [51] trial: 39, train_loss: 1.661978, test loss: 1.162907, bias2: 0.8449206352233887, variance: 0.317986398935318\n",
      "Train size: [400] hidden size: [51] trial: 40, train_loss: 1.660579, test loss: 1.163854, bias2: 0.8450409173965454, variance: 0.31881317496299744\n",
      "Train size: [400] hidden size: [51] trial: 41, train_loss: 1.658750, test loss: 1.165479, bias2: 0.846088171005249, variance: 0.3193911015987396\n",
      "Train size: [400] hidden size: [51] trial: 42, train_loss: 1.658913, test loss: 1.164569, bias2: 0.8457121849060059, variance: 0.3188563585281372\n",
      "Train size: [400] hidden size: [51] trial: 43, train_loss: 1.655431, test loss: 1.165966, bias2: 0.8462046384811401, variance: 0.3197614848613739\n",
      "Train size: [400] hidden size: [51] trial: 44, train_loss: 1.654796, test loss: 1.166177, bias2: 0.8455612659454346, variance: 0.32061541080474854\n",
      "Train size: [400] hidden size: [51] trial: 45, train_loss: 1.653119, test loss: 1.167200, bias2: 0.8450047969818115, variance: 0.3221946954727173\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [51] trial: 46, train_loss: 1.653009, test loss: 1.166349, bias2: 0.8452012538909912, variance: 0.3211474120616913\n",
      "Train size: [400] hidden size: [51] trial: 47, train_loss: 1.649938, test loss: 1.165705, bias2: 0.8428529500961304, variance: 0.32285168766975403\n",
      "Train size: [400] hidden size: [51] trial: 48, train_loss: 1.649711, test loss: 1.165932, bias2: 0.841825544834137, variance: 0.3241061568260193\n",
      "Train size: [400] hidden size: [51] trial: 49, train_loss: 1.645066, test loss: 1.166713, bias2: 0.8420159816741943, variance: 0.32469674944877625\n",
      "##################################################\n",
      "Train size: [400] hidden size: [58] trial: 0, train_loss: 1.741705, test loss: 1.140476, bias2: 1.1404756307601929, variance: -2.1409014561157846e-09\n",
      "Train size: [400] hidden size: [58] trial: 1, train_loss: 1.753433, test loss: 1.114124, bias2: 0.9634265899658203, variance: 0.15069708228111267\n",
      "Train size: [400] hidden size: [58] trial: 2, train_loss: 1.699725, test loss: 1.144262, bias2: 0.9112032651901245, variance: 0.23305831849575043\n",
      "Train size: [400] hidden size: [58] trial: 3, train_loss: 1.671356, test loss: 1.161630, bias2: 0.8916194438934326, variance: 0.2700108289718628\n",
      "Train size: [400] hidden size: [58] trial: 4, train_loss: 1.680799, test loss: 1.169162, bias2: 0.8817757368087769, variance: 0.28738608956336975\n",
      "Train size: [400] hidden size: [58] trial: 5, train_loss: 1.690013, test loss: 1.167061, bias2: 0.8548330664634705, variance: 0.31222766637802124\n",
      "Train size: [400] hidden size: [58] trial: 6, train_loss: 1.673704, test loss: 1.167494, bias2: 0.8463239669799805, variance: 0.32116982340812683\n",
      "Train size: [400] hidden size: [58] trial: 7, train_loss: 1.654274, test loss: 1.179003, bias2: 0.849040150642395, variance: 0.3299630582332611\n",
      "Train size: [400] hidden size: [58] trial: 8, train_loss: 1.649802, test loss: 1.181800, bias2: 0.8377360105514526, variance: 0.3440643846988678\n",
      "Train size: [400] hidden size: [58] trial: 9, train_loss: 1.653249, test loss: 1.185617, bias2: 0.8355085253715515, variance: 0.3501080870628357\n",
      "Train size: [400] hidden size: [58] trial: 10, train_loss: 1.663324, test loss: 1.188583, bias2: 0.8357048034667969, variance: 0.3528781235218048\n",
      "Train size: [400] hidden size: [58] trial: 11, train_loss: 1.651604, test loss: 1.197157, bias2: 0.8423968553543091, variance: 0.3547600507736206\n",
      "Train size: [400] hidden size: [58] trial: 12, train_loss: 1.653384, test loss: 1.184628, bias2: 0.8324246406555176, variance: 0.35220304131507874\n",
      "Train size: [400] hidden size: [58] trial: 13, train_loss: 1.647873, test loss: 1.189302, bias2: 0.8315656185150146, variance: 0.35773614048957825\n",
      "Train size: [400] hidden size: [58] trial: 14, train_loss: 1.643040, test loss: 1.190776, bias2: 0.8256064653396606, variance: 0.36516904830932617\n",
      "Train size: [400] hidden size: [58] trial: 15, train_loss: 1.642407, test loss: 1.188240, bias2: 0.8201941251754761, variance: 0.3680454194545746\n",
      "Train size: [400] hidden size: [58] trial: 16, train_loss: 1.650025, test loss: 1.186550, bias2: 0.8135659694671631, variance: 0.37298426032066345\n",
      "Train size: [400] hidden size: [58] trial: 17, train_loss: 1.654918, test loss: 1.186111, bias2: 0.8164564371109009, variance: 0.36965444684028625\n",
      "Train size: [400] hidden size: [58] trial: 18, train_loss: 1.658134, test loss: 1.183606, bias2: 0.8152673244476318, variance: 0.3683392107486725\n",
      "Train size: [400] hidden size: [58] trial: 19, train_loss: 1.656846, test loss: 1.184499, bias2: 0.8131718635559082, variance: 0.37132728099823\n",
      "Train size: [400] hidden size: [58] trial: 20, train_loss: 1.647094, test loss: 1.191169, bias2: 0.81319260597229, variance: 0.37797650694847107\n",
      "Train size: [400] hidden size: [58] trial: 21, train_loss: 1.658783, test loss: 1.189465, bias2: 0.8139406442642212, variance: 0.3755249083042145\n",
      "Train size: [400] hidden size: [58] trial: 22, train_loss: 1.664438, test loss: 1.191301, bias2: 0.8136478662490845, variance: 0.37765300273895264\n",
      "Train size: [400] hidden size: [58] trial: 23, train_loss: 1.662145, test loss: 1.192574, bias2: 0.8129190802574158, variance: 0.3796551823616028\n",
      "Train size: [400] hidden size: [58] trial: 24, train_loss: 1.662815, test loss: 1.194959, bias2: 0.8146959543228149, variance: 0.38026344776153564\n",
      "Train size: [400] hidden size: [58] trial: 25, train_loss: 1.661676, test loss: 1.194488, bias2: 0.8134778738021851, variance: 0.38101038336753845\n",
      "Train size: [400] hidden size: [58] trial: 26, train_loss: 1.658923, test loss: 1.191227, bias2: 0.8133901953697205, variance: 0.3778366446495056\n",
      "Train size: [400] hidden size: [58] trial: 27, train_loss: 1.654917, test loss: 1.191102, bias2: 0.8112505674362183, variance: 0.3798515796661377\n",
      "Train size: [400] hidden size: [58] trial: 28, train_loss: 1.652035, test loss: 1.192100, bias2: 0.8079361915588379, variance: 0.38416406512260437\n",
      "Train size: [400] hidden size: [58] trial: 29, train_loss: 1.648978, test loss: 1.197926, bias2: 0.8077490925788879, variance: 0.3901767134666443\n",
      "Train size: [400] hidden size: [58] trial: 30, train_loss: 1.646371, test loss: 1.199106, bias2: 0.8080187439918518, variance: 0.3910868763923645\n",
      "Train size: [400] hidden size: [58] trial: 31, train_loss: 1.648368, test loss: 1.198934, bias2: 0.8105868101119995, variance: 0.3883475363254547\n",
      "Train size: [400] hidden size: [58] trial: 32, train_loss: 1.647912, test loss: 1.200770, bias2: 0.8087427020072937, variance: 0.3920270800590515\n",
      "Train size: [400] hidden size: [58] trial: 33, train_loss: 1.645334, test loss: 1.202035, bias2: 0.808518648147583, variance: 0.39351677894592285\n",
      "Train size: [400] hidden size: [58] trial: 34, train_loss: 1.645564, test loss: 1.203703, bias2: 0.808458685874939, variance: 0.395244836807251\n",
      "Train size: [400] hidden size: [58] trial: 35, train_loss: 1.643238, test loss: 1.203379, bias2: 0.8078613877296448, variance: 0.39551788568496704\n",
      "Train size: [400] hidden size: [58] trial: 36, train_loss: 1.648881, test loss: 1.201956, bias2: 0.8079834580421448, variance: 0.39397233724594116\n",
      "Train size: [400] hidden size: [58] trial: 37, train_loss: 1.649703, test loss: 1.200815, bias2: 0.80726158618927, variance: 0.39355385303497314\n",
      "Train size: [400] hidden size: [58] trial: 38, train_loss: 1.652642, test loss: 1.202315, bias2: 0.8080482482910156, variance: 0.3942665755748749\n",
      "Train size: [400] hidden size: [58] trial: 39, train_loss: 1.650257, test loss: 1.200650, bias2: 0.8097482919692993, variance: 0.39090144634246826\n",
      "Train size: [400] hidden size: [58] trial: 40, train_loss: 1.652055, test loss: 1.198284, bias2: 0.8082871437072754, variance: 0.38999664783477783\n",
      "Train size: [400] hidden size: [58] trial: 41, train_loss: 1.653207, test loss: 1.198256, bias2: 0.8060483932495117, variance: 0.39220747351646423\n",
      "Train size: [400] hidden size: [58] trial: 42, train_loss: 1.651485, test loss: 1.199322, bias2: 0.8066785335540771, variance: 0.39264336228370667\n",
      "Train size: [400] hidden size: [58] trial: 43, train_loss: 1.650174, test loss: 1.198140, bias2: 0.8051258325576782, variance: 0.3930138349533081\n",
      "Train size: [400] hidden size: [58] trial: 44, train_loss: 1.652504, test loss: 1.198115, bias2: 0.806145191192627, variance: 0.39197012782096863\n",
      "Train size: [400] hidden size: [58] trial: 45, train_loss: 1.652603, test loss: 1.197574, bias2: 0.8083440661430359, variance: 0.3892297148704529\n",
      "Train size: [400] hidden size: [58] trial: 46, train_loss: 1.646483, test loss: 1.195880, bias2: 0.8079943656921387, variance: 0.3878856897354126\n",
      "Train size: [400] hidden size: [58] trial: 47, train_loss: 1.652407, test loss: 1.195911, bias2: 0.810188889503479, variance: 0.3857226073741913\n",
      "Train size: [400] hidden size: [58] trial: 48, train_loss: 1.651087, test loss: 1.195375, bias2: 0.8097962737083435, variance: 0.38557833433151245\n",
      "Train size: [400] hidden size: [58] trial: 49, train_loss: 1.650733, test loss: 1.194518, bias2: 0.8097518086433411, variance: 0.3847658038139343\n",
      "##################################################\n",
      "Train size: [400] hidden size: [67] trial: 0, train_loss: 1.662327, test loss: 1.223536, bias2: 1.2235356569290161, variance: -3.8925479506346505e-10\n",
      "Train size: [400] hidden size: [67] trial: 1, train_loss: 1.694846, test loss: 1.231810, bias2: 1.0077139139175415, variance: 0.2240956723690033\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [67] trial: 2, train_loss: 1.708260, test loss: 1.210954, bias2: 0.9206035137176514, variance: 0.2903508245944977\n",
      "Train size: [400] hidden size: [67] trial: 3, train_loss: 1.682777, test loss: 1.215346, bias2: 0.9032639861106873, variance: 0.3120822310447693\n",
      "Train size: [400] hidden size: [67] trial: 4, train_loss: 1.672856, test loss: 1.245632, bias2: 0.8842436075210571, variance: 0.3613879382610321\n",
      "Train size: [400] hidden size: [67] trial: 5, train_loss: 1.639261, test loss: 1.239313, bias2: 0.8729450702667236, variance: 0.3663676083087921\n",
      "Train size: [400] hidden size: [67] trial: 6, train_loss: 1.604264, test loss: 1.232830, bias2: 0.8559252023696899, variance: 0.37690484523773193\n",
      "Train size: [400] hidden size: [67] trial: 7, train_loss: 1.609003, test loss: 1.229522, bias2: 0.8485839366912842, variance: 0.3809375762939453\n",
      "Train size: [400] hidden size: [67] trial: 8, train_loss: 1.593861, test loss: 1.217105, bias2: 0.8377559185028076, variance: 0.3793487548828125\n",
      "Train size: [400] hidden size: [67] trial: 9, train_loss: 1.603305, test loss: 1.210131, bias2: 0.8322639465332031, variance: 0.3778672516345978\n",
      "Train size: [400] hidden size: [67] trial: 10, train_loss: 1.590239, test loss: 1.203536, bias2: 0.8243825435638428, variance: 0.3791534900665283\n",
      "Train size: [400] hidden size: [67] trial: 11, train_loss: 1.589144, test loss: 1.201061, bias2: 0.8251947164535522, variance: 0.3758666217327118\n",
      "Train size: [400] hidden size: [67] trial: 12, train_loss: 1.588830, test loss: 1.200087, bias2: 0.8241057395935059, variance: 0.3759814500808716\n",
      "Train size: [400] hidden size: [67] trial: 13, train_loss: 1.587543, test loss: 1.204831, bias2: 0.8264274597167969, variance: 0.3784036338329315\n",
      "Train size: [400] hidden size: [67] trial: 14, train_loss: 1.588654, test loss: 1.205338, bias2: 0.8269398212432861, variance: 0.3783981502056122\n",
      "Train size: [400] hidden size: [67] trial: 15, train_loss: 1.580646, test loss: 1.201287, bias2: 0.8248403072357178, variance: 0.3764462172985077\n",
      "Train size: [400] hidden size: [67] trial: 16, train_loss: 1.571816, test loss: 1.201919, bias2: 0.8237780332565308, variance: 0.37814095616340637\n",
      "Train size: [400] hidden size: [67] trial: 17, train_loss: 1.570223, test loss: 1.201528, bias2: 0.825725257396698, variance: 0.37580233812332153\n",
      "Train size: [400] hidden size: [67] trial: 18, train_loss: 1.571840, test loss: 1.207885, bias2: 0.8213560581207275, variance: 0.3865292966365814\n",
      "Train size: [400] hidden size: [67] trial: 19, train_loss: 1.570294, test loss: 1.211664, bias2: 0.8247542381286621, variance: 0.3869093656539917\n",
      "Train size: [400] hidden size: [67] trial: 20, train_loss: 1.570129, test loss: 1.210571, bias2: 0.8201920390129089, variance: 0.3903791308403015\n",
      "Train size: [400] hidden size: [67] trial: 21, train_loss: 1.577198, test loss: 1.207851, bias2: 0.8165011405944824, variance: 0.391350120306015\n",
      "Train size: [400] hidden size: [67] trial: 22, train_loss: 1.573301, test loss: 1.209730, bias2: 0.819307804107666, variance: 0.3904224634170532\n",
      "Train size: [400] hidden size: [67] trial: 23, train_loss: 1.584379, test loss: 1.206679, bias2: 0.8175011873245239, variance: 0.3891775608062744\n",
      "Train size: [400] hidden size: [67] trial: 24, train_loss: 1.581821, test loss: 1.206273, bias2: 0.8156729936599731, variance: 0.3906001150608063\n",
      "Train size: [400] hidden size: [67] trial: 25, train_loss: 1.578855, test loss: 1.205465, bias2: 0.8168757557868958, variance: 0.3885888457298279\n",
      "Train size: [400] hidden size: [67] trial: 26, train_loss: 1.581034, test loss: 1.207831, bias2: 0.8135632276535034, variance: 0.39426741003990173\n",
      "Train size: [400] hidden size: [67] trial: 27, train_loss: 1.586128, test loss: 1.206636, bias2: 0.8152557015419006, variance: 0.3913804888725281\n",
      "Train size: [400] hidden size: [67] trial: 28, train_loss: 1.587765, test loss: 1.208728, bias2: 0.815741240978241, variance: 0.39298683404922485\n",
      "Train size: [400] hidden size: [67] trial: 29, train_loss: 1.582242, test loss: 1.210886, bias2: 0.8130322694778442, variance: 0.39785340428352356\n",
      "Train size: [400] hidden size: [67] trial: 30, train_loss: 1.585670, test loss: 1.210859, bias2: 0.8107136487960815, variance: 0.4001455008983612\n",
      "Train size: [400] hidden size: [67] trial: 31, train_loss: 1.585314, test loss: 1.209410, bias2: 0.8115386962890625, variance: 0.3978711664676666\n",
      "Train size: [400] hidden size: [67] trial: 32, train_loss: 1.585044, test loss: 1.210993, bias2: 0.8145301938056946, variance: 0.396462619304657\n",
      "Train size: [400] hidden size: [67] trial: 33, train_loss: 1.581487, test loss: 1.210658, bias2: 0.8149402141571045, variance: 0.3957175314426422\n",
      "Train size: [400] hidden size: [67] trial: 34, train_loss: 1.577915, test loss: 1.212504, bias2: 0.8136351704597473, variance: 0.3988686203956604\n",
      "Train size: [400] hidden size: [67] trial: 35, train_loss: 1.578447, test loss: 1.209319, bias2: 0.8117678165435791, variance: 0.39755114912986755\n",
      "Train size: [400] hidden size: [67] trial: 36, train_loss: 1.583286, test loss: 1.211352, bias2: 0.812472939491272, variance: 0.3988795280456543\n",
      "Train size: [400] hidden size: [67] trial: 37, train_loss: 1.582165, test loss: 1.207871, bias2: 0.8138195872306824, variance: 0.39405184984207153\n",
      "Train size: [400] hidden size: [67] trial: 38, train_loss: 1.582235, test loss: 1.211111, bias2: 0.8119474649429321, variance: 0.39916369318962097\n",
      "Train size: [400] hidden size: [67] trial: 39, train_loss: 1.582937, test loss: 1.211954, bias2: 0.8096252679824829, variance: 0.402328759431839\n",
      "Train size: [400] hidden size: [67] trial: 40, train_loss: 1.584545, test loss: 1.210555, bias2: 0.8101588487625122, variance: 0.4003959000110626\n",
      "Train size: [400] hidden size: [67] trial: 41, train_loss: 1.589950, test loss: 1.211779, bias2: 0.8107052445411682, variance: 0.4010741114616394\n",
      "Train size: [400] hidden size: [67] trial: 42, train_loss: 1.591307, test loss: 1.213821, bias2: 0.811852216720581, variance: 0.4019683301448822\n",
      "Train size: [400] hidden size: [67] trial: 43, train_loss: 1.596991, test loss: 1.213574, bias2: 0.8129189014434814, variance: 0.4006553888320923\n",
      "Train size: [400] hidden size: [67] trial: 44, train_loss: 1.598612, test loss: 1.215512, bias2: 0.8145332336425781, variance: 0.40097835659980774\n",
      "Train size: [400] hidden size: [67] trial: 45, train_loss: 1.596621, test loss: 1.216768, bias2: 0.8132165670394897, variance: 0.4035514295101166\n",
      "Train size: [400] hidden size: [67] trial: 46, train_loss: 1.600298, test loss: 1.216664, bias2: 0.8136054277420044, variance: 0.40305840969085693\n",
      "Train size: [400] hidden size: [67] trial: 47, train_loss: 1.599584, test loss: 1.216296, bias2: 0.8133325576782227, variance: 0.4029635488986969\n",
      "Train size: [400] hidden size: [67] trial: 48, train_loss: 1.600326, test loss: 1.216695, bias2: 0.8131296634674072, variance: 0.40356525778770447\n",
      "Train size: [400] hidden size: [67] trial: 49, train_loss: 1.602743, test loss: 1.217800, bias2: 0.8109935522079468, variance: 0.40680620074272156\n",
      "##################################################\n",
      "Train size: [400] hidden size: [77] trial: 0, train_loss: 1.632204, test loss: 1.139850, bias2: 1.1398502588272095, variance: -7.785095901269301e-10\n",
      "Train size: [400] hidden size: [77] trial: 1, train_loss: 1.579746, test loss: 1.200902, bias2: 0.9612767696380615, variance: 0.23962554335594177\n",
      "Train size: [400] hidden size: [77] trial: 2, train_loss: 1.547097, test loss: 1.229876, bias2: 0.8990563154220581, variance: 0.3308199346065521\n",
      "Train size: [400] hidden size: [77] trial: 3, train_loss: 1.503730, test loss: 1.231939, bias2: 0.8609673380851746, variance: 0.3709719777107239\n",
      "Train size: [400] hidden size: [77] trial: 4, train_loss: 1.515986, test loss: 1.209837, bias2: 0.8237788677215576, variance: 0.38605859875679016\n",
      "Train size: [400] hidden size: [77] trial: 5, train_loss: 1.540271, test loss: 1.238313, bias2: 0.8290693759918213, variance: 0.4092436730861664\n",
      "Train size: [400] hidden size: [77] trial: 6, train_loss: 1.544719, test loss: 1.244054, bias2: 0.818882405757904, variance: 0.42517155408859253\n",
      "Train size: [400] hidden size: [77] trial: 7, train_loss: 1.525031, test loss: 1.253378, bias2: 0.8131144046783447, variance: 0.4402635395526886\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [77] trial: 8, train_loss: 1.533654, test loss: 1.253233, bias2: 0.8109139204025269, variance: 0.4423189163208008\n",
      "Train size: [400] hidden size: [77] trial: 9, train_loss: 1.505025, test loss: 1.255682, bias2: 0.7994312047958374, variance: 0.45625102519989014\n",
      "Train size: [400] hidden size: [77] trial: 10, train_loss: 1.512015, test loss: 1.250915, bias2: 0.7943611145019531, variance: 0.45655420422554016\n",
      "Train size: [400] hidden size: [77] trial: 11, train_loss: 1.498192, test loss: 1.254920, bias2: 0.7992023825645447, variance: 0.45571738481521606\n",
      "Train size: [400] hidden size: [77] trial: 12, train_loss: 1.499052, test loss: 1.253081, bias2: 0.7979516983032227, variance: 0.45512938499450684\n",
      "Train size: [400] hidden size: [77] trial: 13, train_loss: 1.499010, test loss: 1.251347, bias2: 0.7973570823669434, variance: 0.45399031043052673\n",
      "Train size: [400] hidden size: [77] trial: 14, train_loss: 1.499654, test loss: 1.244966, bias2: 0.7934814095497131, variance: 0.4514846205711365\n",
      "Train size: [400] hidden size: [77] trial: 15, train_loss: 1.498152, test loss: 1.245595, bias2: 0.7912352085113525, variance: 0.4543593227863312\n",
      "Train size: [400] hidden size: [77] trial: 16, train_loss: 1.495182, test loss: 1.244694, bias2: 0.7915279865264893, variance: 0.4531664550304413\n",
      "Train size: [400] hidden size: [77] trial: 17, train_loss: 1.490255, test loss: 1.247597, bias2: 0.7932009100914001, variance: 0.4543958306312561\n",
      "Train size: [400] hidden size: [77] trial: 18, train_loss: 1.485829, test loss: 1.243229, bias2: 0.7886334657669067, variance: 0.45459508895874023\n",
      "Train size: [400] hidden size: [77] trial: 19, train_loss: 1.490533, test loss: 1.239897, bias2: 0.7881330251693726, variance: 0.4517643451690674\n",
      "Train size: [400] hidden size: [77] trial: 20, train_loss: 1.484847, test loss: 1.238232, bias2: 0.789199948310852, variance: 0.4490325152873993\n",
      "Train size: [400] hidden size: [77] trial: 21, train_loss: 1.492482, test loss: 1.236388, bias2: 0.7876383066177368, variance: 0.4487494230270386\n",
      "Train size: [400] hidden size: [77] trial: 22, train_loss: 1.502134, test loss: 1.240769, bias2: 0.7865052819252014, variance: 0.45426350831985474\n",
      "Train size: [400] hidden size: [77] trial: 23, train_loss: 1.504880, test loss: 1.242971, bias2: 0.7839992642402649, variance: 0.45897191762924194\n",
      "Train size: [400] hidden size: [77] trial: 24, train_loss: 1.506057, test loss: 1.239662, bias2: 0.781076192855835, variance: 0.4585854709148407\n",
      "Train size: [400] hidden size: [77] trial: 25, train_loss: 1.504807, test loss: 1.236384, bias2: 0.7826889157295227, variance: 0.4536955952644348\n",
      "Train size: [400] hidden size: [77] trial: 26, train_loss: 1.499113, test loss: 1.240998, bias2: 0.7849751114845276, variance: 0.4560226798057556\n",
      "Train size: [400] hidden size: [77] trial: 27, train_loss: 1.489494, test loss: 1.236940, bias2: 0.7849215865135193, variance: 0.4520185589790344\n",
      "Train size: [400] hidden size: [77] trial: 28, train_loss: 1.491878, test loss: 1.236235, bias2: 0.7876135110855103, variance: 0.44862139225006104\n",
      "Train size: [400] hidden size: [77] trial: 29, train_loss: 1.496522, test loss: 1.239074, bias2: 0.7875016927719116, variance: 0.4515722095966339\n",
      "Train size: [400] hidden size: [77] trial: 30, train_loss: 1.497227, test loss: 1.238926, bias2: 0.7876728773117065, variance: 0.45125317573547363\n",
      "Train size: [400] hidden size: [77] trial: 31, train_loss: 1.492870, test loss: 1.239892, bias2: 0.7865525484085083, variance: 0.453339546918869\n",
      "Train size: [400] hidden size: [77] trial: 32, train_loss: 1.494297, test loss: 1.236421, bias2: 0.7841512560844421, variance: 0.4522692561149597\n",
      "Train size: [400] hidden size: [77] trial: 33, train_loss: 1.492273, test loss: 1.233669, bias2: 0.779885470867157, variance: 0.45378345251083374\n",
      "Train size: [400] hidden size: [77] trial: 34, train_loss: 1.491139, test loss: 1.236888, bias2: 0.7814048528671265, variance: 0.45548272132873535\n",
      "Train size: [400] hidden size: [77] trial: 35, train_loss: 1.487780, test loss: 1.238633, bias2: 0.7820634841918945, variance: 0.45656904578208923\n",
      "Train size: [400] hidden size: [77] trial: 36, train_loss: 1.492866, test loss: 1.237117, bias2: 0.7801597714424133, variance: 0.45695775747299194\n",
      "Train size: [400] hidden size: [77] trial: 37, train_loss: 1.488375, test loss: 1.235901, bias2: 0.7792483568191528, variance: 0.4566531181335449\n",
      "Train size: [400] hidden size: [77] trial: 38, train_loss: 1.490948, test loss: 1.236030, bias2: 0.7795162200927734, variance: 0.4565141499042511\n",
      "Train size: [400] hidden size: [77] trial: 39, train_loss: 1.489090, test loss: 1.234362, bias2: 0.7795827388763428, variance: 0.4547788202762604\n",
      "Train size: [400] hidden size: [77] trial: 40, train_loss: 1.485957, test loss: 1.235371, bias2: 0.7775090932846069, variance: 0.4578620195388794\n",
      "Train size: [400] hidden size: [77] trial: 41, train_loss: 1.487681, test loss: 1.235421, bias2: 0.7775843739509583, variance: 0.4578363299369812\n",
      "Train size: [400] hidden size: [77] trial: 42, train_loss: 1.485230, test loss: 1.234299, bias2: 0.7740066051483154, variance: 0.4602926969528198\n",
      "Train size: [400] hidden size: [77] trial: 43, train_loss: 1.487925, test loss: 1.235438, bias2: 0.7731071710586548, variance: 0.4623306691646576\n",
      "Train size: [400] hidden size: [77] trial: 44, train_loss: 1.485572, test loss: 1.235093, bias2: 0.7699376344680786, variance: 0.465155690908432\n",
      "Train size: [400] hidden size: [77] trial: 45, train_loss: 1.482729, test loss: 1.237791, bias2: 0.7708569765090942, variance: 0.4669336974620819\n",
      "Train size: [400] hidden size: [77] trial: 46, train_loss: 1.486912, test loss: 1.235838, bias2: 0.7708715200424194, variance: 0.4649660587310791\n",
      "Train size: [400] hidden size: [77] trial: 47, train_loss: 1.479314, test loss: 1.235432, bias2: 0.7693626880645752, variance: 0.4660697281360626\n",
      "Train size: [400] hidden size: [77] trial: 48, train_loss: 1.482564, test loss: 1.233991, bias2: 0.7702279090881348, variance: 0.4637626111507416\n",
      "Train size: [400] hidden size: [77] trial: 49, train_loss: 1.485588, test loss: 1.232236, bias2: 0.7698072195053101, variance: 0.46242842078208923\n",
      "##################################################\n",
      "Train size: [400] hidden size: [89] trial: 0, train_loss: 1.538901, test loss: 1.338688, bias2: 1.3386878967285156, variance: 7.785095901269301e-10\n",
      "Train size: [400] hidden size: [89] trial: 1, train_loss: 1.487451, test loss: 1.340177, bias2: 1.0587525367736816, variance: 0.2814246416091919\n",
      "Train size: [400] hidden size: [89] trial: 2, train_loss: 1.472437, test loss: 1.288793, bias2: 0.9272323846817017, variance: 0.3615601062774658\n",
      "Train size: [400] hidden size: [89] trial: 3, train_loss: 1.421030, test loss: 1.320630, bias2: 0.9062294960021973, variance: 0.41440072655677795\n",
      "Train size: [400] hidden size: [89] trial: 4, train_loss: 1.429825, test loss: 1.314631, bias2: 0.8560380935668945, variance: 0.45859289169311523\n",
      "Train size: [400] hidden size: [89] trial: 5, train_loss: 1.434463, test loss: 1.305071, bias2: 0.8445814251899719, variance: 0.4604896903038025\n",
      "Train size: [400] hidden size: [89] trial: 6, train_loss: 1.432535, test loss: 1.292560, bias2: 0.8298795223236084, variance: 0.4626799523830414\n",
      "Train size: [400] hidden size: [89] trial: 7, train_loss: 1.411900, test loss: 1.272553, bias2: 0.8147990703582764, variance: 0.4577536880970001\n",
      "Train size: [400] hidden size: [89] trial: 8, train_loss: 1.408281, test loss: 1.272265, bias2: 0.8174799680709839, variance: 0.45478472113609314\n",
      "Train size: [400] hidden size: [89] trial: 9, train_loss: 1.404916, test loss: 1.266381, bias2: 0.8024039268493652, variance: 0.46397721767425537\n",
      "Train size: [400] hidden size: [89] trial: 10, train_loss: 1.438994, test loss: 1.265014, bias2: 0.7998709678649902, variance: 0.46514347195625305\n",
      "Train size: [400] hidden size: [89] trial: 11, train_loss: 1.438622, test loss: 1.257658, bias2: 0.7923154830932617, variance: 0.4653424024581909\n",
      "Train size: [400] hidden size: [89] trial: 12, train_loss: 1.423528, test loss: 1.255693, bias2: 0.7836620807647705, variance: 0.47203120589256287\n",
      "Train size: [400] hidden size: [89] trial: 13, train_loss: 1.432617, test loss: 1.261483, bias2: 0.7786744832992554, variance: 0.48280811309814453\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [89] trial: 14, train_loss: 1.437592, test loss: 1.265379, bias2: 0.7757608294487, variance: 0.48961836099624634\n",
      "Train size: [400] hidden size: [89] trial: 15, train_loss: 1.435322, test loss: 1.266644, bias2: 0.7740836143493652, variance: 0.4925605058670044\n",
      "Train size: [400] hidden size: [89] trial: 16, train_loss: 1.440134, test loss: 1.266984, bias2: 0.7708311080932617, variance: 0.49615320563316345\n",
      "Train size: [400] hidden size: [89] trial: 17, train_loss: 1.435887, test loss: 1.273751, bias2: 0.7744721174240112, variance: 0.49927935004234314\n",
      "Train size: [400] hidden size: [89] trial: 18, train_loss: 1.443808, test loss: 1.268881, bias2: 0.7748913764953613, variance: 0.4939897060394287\n",
      "Train size: [400] hidden size: [89] trial: 19, train_loss: 1.446684, test loss: 1.262296, bias2: 0.7684204578399658, variance: 0.4938758313655853\n",
      "Train size: [400] hidden size: [89] trial: 20, train_loss: 1.446054, test loss: 1.266003, bias2: 0.7727447748184204, variance: 0.4932583272457123\n",
      "Train size: [400] hidden size: [89] trial: 21, train_loss: 1.443730, test loss: 1.264122, bias2: 0.765394926071167, variance: 0.4987275302410126\n",
      "Train size: [400] hidden size: [89] trial: 22, train_loss: 1.457211, test loss: 1.265422, bias2: 0.7607661485671997, variance: 0.5046558380126953\n",
      "Train size: [400] hidden size: [89] trial: 23, train_loss: 1.462608, test loss: 1.264460, bias2: 0.7582061886787415, variance: 0.5062533020973206\n",
      "Train size: [400] hidden size: [89] trial: 24, train_loss: 1.461966, test loss: 1.263789, bias2: 0.758829653263092, variance: 0.5049590468406677\n",
      "Train size: [400] hidden size: [89] trial: 25, train_loss: 1.460315, test loss: 1.258451, bias2: 0.7588961124420166, variance: 0.499555379152298\n",
      "Train size: [400] hidden size: [89] trial: 26, train_loss: 1.462819, test loss: 1.260831, bias2: 0.7567331790924072, variance: 0.5040980577468872\n",
      "Train size: [400] hidden size: [89] trial: 27, train_loss: 1.464314, test loss: 1.262206, bias2: 0.7569835782051086, variance: 0.5052228569984436\n",
      "Train size: [400] hidden size: [89] trial: 28, train_loss: 1.459104, test loss: 1.259949, bias2: 0.7543021440505981, variance: 0.5056464672088623\n",
      "Train size: [400] hidden size: [89] trial: 29, train_loss: 1.458212, test loss: 1.262458, bias2: 0.7507320046424866, variance: 0.5117256045341492\n",
      "Train size: [400] hidden size: [89] trial: 30, train_loss: 1.451768, test loss: 1.264091, bias2: 0.7519360184669495, variance: 0.5121549963951111\n",
      "Train size: [400] hidden size: [89] trial: 31, train_loss: 1.450142, test loss: 1.259702, bias2: 0.7473943829536438, variance: 0.5123074650764465\n",
      "Train size: [400] hidden size: [89] trial: 32, train_loss: 1.451443, test loss: 1.259702, bias2: 0.7498062252998352, variance: 0.509895384311676\n",
      "Train size: [400] hidden size: [89] trial: 33, train_loss: 1.458048, test loss: 1.261484, bias2: 0.7532592415809631, variance: 0.5082243084907532\n",
      "Train size: [400] hidden size: [89] trial: 34, train_loss: 1.456236, test loss: 1.264428, bias2: 0.7544668912887573, variance: 0.5099608898162842\n",
      "Train size: [400] hidden size: [89] trial: 35, train_loss: 1.451163, test loss: 1.265190, bias2: 0.7533629536628723, variance: 0.5118266940116882\n",
      "Train size: [400] hidden size: [89] trial: 36, train_loss: 1.448270, test loss: 1.267384, bias2: 0.7513542175292969, variance: 0.5160295963287354\n",
      "Train size: [400] hidden size: [89] trial: 37, train_loss: 1.445566, test loss: 1.267689, bias2: 0.7505640387535095, variance: 0.5171247124671936\n",
      "Train size: [400] hidden size: [89] trial: 38, train_loss: 1.443067, test loss: 1.267813, bias2: 0.7512577772140503, variance: 0.5165550708770752\n",
      "Train size: [400] hidden size: [89] trial: 39, train_loss: 1.441943, test loss: 1.265392, bias2: 0.7520048022270203, variance: 0.5133876204490662\n",
      "Train size: [400] hidden size: [89] trial: 40, train_loss: 1.442269, test loss: 1.266348, bias2: 0.7484488487243652, variance: 0.5178993940353394\n",
      "Train size: [400] hidden size: [89] trial: 41, train_loss: 1.438451, test loss: 1.268915, bias2: 0.7468302845954895, variance: 0.5220842957496643\n",
      "Train size: [400] hidden size: [89] trial: 42, train_loss: 1.440133, test loss: 1.268794, bias2: 0.7461963295936584, variance: 0.5225980877876282\n",
      "Train size: [400] hidden size: [89] trial: 43, train_loss: 1.440696, test loss: 1.265620, bias2: 0.7435848116874695, variance: 0.522035539150238\n",
      "Train size: [400] hidden size: [89] trial: 44, train_loss: 1.437806, test loss: 1.267978, bias2: 0.7445732355117798, variance: 0.523404598236084\n",
      "Train size: [400] hidden size: [89] trial: 45, train_loss: 1.437651, test loss: 1.267360, bias2: 0.7411185503005981, variance: 0.5262410640716553\n",
      "Train size: [400] hidden size: [89] trial: 46, train_loss: 1.436979, test loss: 1.267155, bias2: 0.7421216368675232, variance: 0.525033175945282\n",
      "Train size: [400] hidden size: [89] trial: 47, train_loss: 1.436647, test loss: 1.267017, bias2: 0.7420166730880737, variance: 0.5250004529953003\n",
      "Train size: [400] hidden size: [89] trial: 48, train_loss: 1.438784, test loss: 1.268174, bias2: 0.7420702576637268, variance: 0.5261037945747375\n",
      "Train size: [400] hidden size: [89] trial: 49, train_loss: 1.434783, test loss: 1.270362, bias2: 0.7416130900382996, variance: 0.5287489295005798\n",
      "##################################################\n",
      "Train size: [400] hidden size: [102] trial: 0, train_loss: 1.427589, test loss: 1.282962, bias2: 1.2829618453979492, variance: 0.0\n",
      "Train size: [400] hidden size: [102] trial: 1, train_loss: 1.343027, test loss: 1.336233, bias2: 1.0156711339950562, variance: 0.32056161761283875\n",
      "Train size: [400] hidden size: [102] trial: 2, train_loss: 1.345349, test loss: 1.371265, bias2: 0.9235879182815552, variance: 0.4476766586303711\n",
      "Train size: [400] hidden size: [102] trial: 3, train_loss: 1.336663, test loss: 1.309895, bias2: 0.8382887244224548, variance: 0.4716060757637024\n",
      "Train size: [400] hidden size: [102] trial: 4, train_loss: 1.366833, test loss: 1.340252, bias2: 0.795717179775238, variance: 0.5445348620414734\n",
      "Train size: [400] hidden size: [102] trial: 5, train_loss: 1.396399, test loss: 1.325548, bias2: 0.7686094045639038, variance: 0.5569387674331665\n",
      "Train size: [400] hidden size: [102] trial: 6, train_loss: 1.405150, test loss: 1.332259, bias2: 0.7683936357498169, variance: 0.5638657808303833\n",
      "Train size: [400] hidden size: [102] trial: 7, train_loss: 1.383063, test loss: 1.326947, bias2: 0.7551850080490112, variance: 0.5717624425888062\n",
      "Train size: [400] hidden size: [102] trial: 8, train_loss: 1.387409, test loss: 1.323406, bias2: 0.7367396354675293, variance: 0.5866659879684448\n",
      "Train size: [400] hidden size: [102] trial: 9, train_loss: 1.370177, test loss: 1.313994, bias2: 0.7277078628540039, variance: 0.5862864255905151\n",
      "Train size: [400] hidden size: [102] trial: 10, train_loss: 1.374070, test loss: 1.311933, bias2: 0.7202335596084595, variance: 0.5916990041732788\n",
      "Train size: [400] hidden size: [102] trial: 11, train_loss: 1.381217, test loss: 1.312389, bias2: 0.7173831462860107, variance: 0.5950055122375488\n",
      "Train size: [400] hidden size: [102] trial: 12, train_loss: 1.381870, test loss: 1.315708, bias2: 0.7151366472244263, variance: 0.600571870803833\n",
      "Train size: [400] hidden size: [102] trial: 13, train_loss: 1.373269, test loss: 1.309915, bias2: 0.7078843712806702, variance: 0.6020309329032898\n",
      "Train size: [400] hidden size: [102] trial: 14, train_loss: 1.380453, test loss: 1.305434, bias2: 0.7040562629699707, variance: 0.6013778448104858\n",
      "Train size: [400] hidden size: [102] trial: 15, train_loss: 1.375670, test loss: 1.313877, bias2: 0.7055994868278503, variance: 0.6082772612571716\n",
      "Train size: [400] hidden size: [102] trial: 16, train_loss: 1.371221, test loss: 1.321990, bias2: 0.7037490606307983, variance: 0.6182410717010498\n",
      "Train size: [400] hidden size: [102] trial: 17, train_loss: 1.370261, test loss: 1.320004, bias2: 0.7031818628311157, variance: 0.6168220043182373\n",
      "Train size: [400] hidden size: [102] trial: 18, train_loss: 1.374163, test loss: 1.315283, bias2: 0.7006970047950745, variance: 0.6145864129066467\n",
      "Train size: [400] hidden size: [102] trial: 19, train_loss: 1.364799, test loss: 1.313812, bias2: 0.7029481530189514, variance: 0.6108636260032654\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [102] trial: 20, train_loss: 1.368824, test loss: 1.318578, bias2: 0.7005598545074463, variance: 0.6180177927017212\n",
      "Train size: [400] hidden size: [102] trial: 21, train_loss: 1.366121, test loss: 1.322016, bias2: 0.6985630989074707, variance: 0.6234530210494995\n",
      "Train size: [400] hidden size: [102] trial: 22, train_loss: 1.367647, test loss: 1.325290, bias2: 0.6960392594337463, variance: 0.6292509436607361\n",
      "Train size: [400] hidden size: [102] trial: 23, train_loss: 1.366996, test loss: 1.325680, bias2: 0.6971191763877869, variance: 0.6285613179206848\n",
      "Train size: [400] hidden size: [102] trial: 24, train_loss: 1.373097, test loss: 1.322742, bias2: 0.6986117362976074, variance: 0.6241302490234375\n",
      "Train size: [400] hidden size: [102] trial: 25, train_loss: 1.378122, test loss: 1.325970, bias2: 0.704435408115387, variance: 0.6215344071388245\n",
      "Train size: [400] hidden size: [102] trial: 26, train_loss: 1.383158, test loss: 1.329475, bias2: 0.7056074738502502, variance: 0.6238676905632019\n",
      "Train size: [400] hidden size: [102] trial: 27, train_loss: 1.384415, test loss: 1.331287, bias2: 0.70851731300354, variance: 0.622769832611084\n",
      "Train size: [400] hidden size: [102] trial: 28, train_loss: 1.378268, test loss: 1.326259, bias2: 0.7027171850204468, variance: 0.6235413551330566\n",
      "Train size: [400] hidden size: [102] trial: 29, train_loss: 1.377518, test loss: 1.328008, bias2: 0.7055204510688782, variance: 0.6224873661994934\n",
      "Train size: [400] hidden size: [102] trial: 30, train_loss: 1.380269, test loss: 1.326493, bias2: 0.704390823841095, variance: 0.6221025586128235\n",
      "Train size: [400] hidden size: [102] trial: 31, train_loss: 1.378858, test loss: 1.323444, bias2: 0.7055889368057251, variance: 0.6178551912307739\n",
      "Train size: [400] hidden size: [102] trial: 32, train_loss: 1.373507, test loss: 1.321286, bias2: 0.7051278948783875, variance: 0.6161584258079529\n",
      "Train size: [400] hidden size: [102] trial: 33, train_loss: 1.371734, test loss: 1.321729, bias2: 0.7054453492164612, variance: 0.6162835955619812\n",
      "Train size: [400] hidden size: [102] trial: 34, train_loss: 1.377497, test loss: 1.329377, bias2: 0.7063124775886536, variance: 0.6230648159980774\n",
      "Train size: [400] hidden size: [102] trial: 35, train_loss: 1.382054, test loss: 1.334993, bias2: 0.7073619365692139, variance: 0.627631425857544\n",
      "Train size: [400] hidden size: [102] trial: 36, train_loss: 1.383221, test loss: 1.334871, bias2: 0.7034982442855835, variance: 0.6313726902008057\n",
      "Train size: [400] hidden size: [102] trial: 37, train_loss: 1.382211, test loss: 1.332699, bias2: 0.7020284533500671, variance: 0.6306708455085754\n",
      "Train size: [400] hidden size: [102] trial: 38, train_loss: 1.381279, test loss: 1.330627, bias2: 0.7022154927253723, variance: 0.6284111142158508\n",
      "Train size: [400] hidden size: [102] trial: 39, train_loss: 1.382666, test loss: 1.330802, bias2: 0.7036756873130798, variance: 0.627126157283783\n",
      "Train size: [400] hidden size: [102] trial: 40, train_loss: 1.381645, test loss: 1.328389, bias2: 0.7041580080986023, variance: 0.6242310404777527\n",
      "Train size: [400] hidden size: [102] trial: 41, train_loss: 1.379535, test loss: 1.329350, bias2: 0.7046772241592407, variance: 0.6246728897094727\n",
      "Train size: [400] hidden size: [102] trial: 42, train_loss: 1.375972, test loss: 1.328508, bias2: 0.7017727494239807, variance: 0.626735508441925\n",
      "Train size: [400] hidden size: [102] trial: 43, train_loss: 1.370089, test loss: 1.324969, bias2: 0.7010027766227722, variance: 0.6239660382270813\n",
      "Train size: [400] hidden size: [102] trial: 44, train_loss: 1.368342, test loss: 1.323425, bias2: 0.7011339664459229, variance: 0.6222912073135376\n",
      "Train size: [400] hidden size: [102] trial: 45, train_loss: 1.371414, test loss: 1.322644, bias2: 0.7014535069465637, variance: 0.6211901307106018\n",
      "Train size: [400] hidden size: [102] trial: 46, train_loss: 1.370996, test loss: 1.323590, bias2: 0.7024494409561157, variance: 0.6211410760879517\n",
      "Train size: [400] hidden size: [102] trial: 47, train_loss: 1.375453, test loss: 1.326245, bias2: 0.7039836049079895, variance: 0.6222609877586365\n",
      "Train size: [400] hidden size: [102] trial: 48, train_loss: 1.374453, test loss: 1.326717, bias2: 0.7039073705673218, variance: 0.6228091716766357\n",
      "Train size: [400] hidden size: [102] trial: 49, train_loss: 1.371375, test loss: 1.326609, bias2: 0.7035413384437561, variance: 0.6230674386024475\n",
      "##################################################\n",
      "Train size: [400] hidden size: [118] trial: 0, train_loss: 1.217290, test loss: 1.566433, bias2: 1.5664327144622803, variance: 7.785096123313906e-09\n",
      "Train size: [400] hidden size: [118] trial: 1, train_loss: 1.330546, test loss: 1.458040, bias2: 1.0883843898773193, variance: 0.3696554899215698\n",
      "Train size: [400] hidden size: [118] trial: 2, train_loss: 1.337160, test loss: 1.418704, bias2: 0.921075701713562, variance: 0.49762842059135437\n",
      "Train size: [400] hidden size: [118] trial: 3, train_loss: 1.277507, test loss: 1.360641, bias2: 0.8592809438705444, variance: 0.501360297203064\n",
      "Train size: [400] hidden size: [118] trial: 4, train_loss: 1.256346, test loss: 1.360609, bias2: 0.8120316863059998, variance: 0.5485774874687195\n",
      "Train size: [400] hidden size: [118] trial: 5, train_loss: 1.272427, test loss: 1.377908, bias2: 0.7972103953361511, variance: 0.580697238445282\n",
      "Train size: [400] hidden size: [118] trial: 6, train_loss: 1.269189, test loss: 1.380022, bias2: 0.7935813665390015, variance: 0.5864400863647461\n",
      "Train size: [400] hidden size: [118] trial: 7, train_loss: 1.294142, test loss: 1.370132, bias2: 0.781764566898346, variance: 0.5883675217628479\n",
      "Train size: [400] hidden size: [118] trial: 8, train_loss: 1.295708, test loss: 1.373904, bias2: 0.7747973203659058, variance: 0.5991066694259644\n",
      "Train size: [400] hidden size: [118] trial: 9, train_loss: 1.278186, test loss: 1.377825, bias2: 0.7622974514961243, variance: 0.6155275702476501\n",
      "Train size: [400] hidden size: [118] trial: 10, train_loss: 1.273823, test loss: 1.365232, bias2: 0.75777268409729, variance: 0.6074589490890503\n",
      "Train size: [400] hidden size: [118] trial: 11, train_loss: 1.271022, test loss: 1.356295, bias2: 0.7419720888137817, variance: 0.6143230199813843\n",
      "Train size: [400] hidden size: [118] trial: 12, train_loss: 1.254326, test loss: 1.360907, bias2: 0.7415263056755066, variance: 0.6193804144859314\n",
      "Train size: [400] hidden size: [118] trial: 13, train_loss: 1.257205, test loss: 1.364689, bias2: 0.7298828363418579, variance: 0.6348061561584473\n",
      "Train size: [400] hidden size: [118] trial: 14, train_loss: 1.264939, test loss: 1.362520, bias2: 0.7238854765892029, variance: 0.6386346220970154\n",
      "Train size: [400] hidden size: [118] trial: 15, train_loss: 1.255322, test loss: 1.369354, bias2: 0.7201477289199829, variance: 0.6492066383361816\n",
      "Train size: [400] hidden size: [118] trial: 16, train_loss: 1.267087, test loss: 1.377276, bias2: 0.7231938242912292, variance: 0.6540820002555847\n",
      "Train size: [400] hidden size: [118] trial: 17, train_loss: 1.257597, test loss: 1.375401, bias2: 0.7222995162010193, variance: 0.6531016230583191\n",
      "Train size: [400] hidden size: [118] trial: 18, train_loss: 1.253482, test loss: 1.376158, bias2: 0.7173344492912292, variance: 0.6588237881660461\n",
      "Train size: [400] hidden size: [118] trial: 19, train_loss: 1.259190, test loss: 1.378150, bias2: 0.713813841342926, variance: 0.6643365025520325\n",
      "Train size: [400] hidden size: [118] trial: 20, train_loss: 1.259561, test loss: 1.381863, bias2: 0.7098422646522522, variance: 0.6720210909843445\n",
      "Train size: [400] hidden size: [118] trial: 21, train_loss: 1.257222, test loss: 1.381533, bias2: 0.7033753991127014, variance: 0.67815762758255\n",
      "Train size: [400] hidden size: [118] trial: 22, train_loss: 1.264546, test loss: 1.376174, bias2: 0.7029363512992859, variance: 0.6732377409934998\n",
      "Train size: [400] hidden size: [118] trial: 23, train_loss: 1.263071, test loss: 1.371453, bias2: 0.7002208828926086, variance: 0.6712319254875183\n",
      "Train size: [400] hidden size: [118] trial: 24, train_loss: 1.267642, test loss: 1.371634, bias2: 0.7021194696426392, variance: 0.6695147752761841\n",
      "Train size: [400] hidden size: [118] trial: 25, train_loss: 1.266451, test loss: 1.370446, bias2: 0.7051645517349243, variance: 0.6652818918228149\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [118] trial: 26, train_loss: 1.263275, test loss: 1.367143, bias2: 0.7048063278198242, variance: 0.662337064743042\n",
      "Train size: [400] hidden size: [118] trial: 27, train_loss: 1.266381, test loss: 1.371462, bias2: 0.7045270800590515, variance: 0.6669345498085022\n",
      "Train size: [400] hidden size: [118] trial: 28, train_loss: 1.269774, test loss: 1.370502, bias2: 0.7038813829421997, variance: 0.6666209697723389\n",
      "Train size: [400] hidden size: [118] trial: 29, train_loss: 1.267805, test loss: 1.369720, bias2: 0.7028586864471436, variance: 0.6668610572814941\n",
      "Train size: [400] hidden size: [118] trial: 30, train_loss: 1.274634, test loss: 1.370675, bias2: 0.7002062797546387, variance: 0.6704686880111694\n",
      "Train size: [400] hidden size: [118] trial: 31, train_loss: 1.276248, test loss: 1.367481, bias2: 0.6996148824691772, variance: 0.6678663492202759\n",
      "Train size: [400] hidden size: [118] trial: 32, train_loss: 1.273414, test loss: 1.366652, bias2: 0.6968916058540344, variance: 0.6697601675987244\n",
      "Train size: [400] hidden size: [118] trial: 33, train_loss: 1.276747, test loss: 1.365923, bias2: 0.6966577768325806, variance: 0.6692647933959961\n",
      "Train size: [400] hidden size: [118] trial: 34, train_loss: 1.274856, test loss: 1.368352, bias2: 0.692068874835968, variance: 0.6762828230857849\n",
      "Train size: [400] hidden size: [118] trial: 35, train_loss: 1.274794, test loss: 1.367006, bias2: 0.6909233331680298, variance: 0.6760823726654053\n",
      "Train size: [400] hidden size: [118] trial: 36, train_loss: 1.272896, test loss: 1.369223, bias2: 0.6898467540740967, variance: 0.679376482963562\n",
      "Train size: [400] hidden size: [118] trial: 37, train_loss: 1.270730, test loss: 1.366855, bias2: 0.6912682056427002, variance: 0.6755869388580322\n",
      "Train size: [400] hidden size: [118] trial: 38, train_loss: 1.268464, test loss: 1.368322, bias2: 0.6888924241065979, variance: 0.6794291138648987\n",
      "Train size: [400] hidden size: [118] trial: 39, train_loss: 1.268520, test loss: 1.367426, bias2: 0.6862320303916931, variance: 0.6811941266059875\n",
      "Train size: [400] hidden size: [118] trial: 40, train_loss: 1.263250, test loss: 1.366843, bias2: 0.6862190365791321, variance: 0.6806244254112244\n",
      "Train size: [400] hidden size: [118] trial: 41, train_loss: 1.263446, test loss: 1.368026, bias2: 0.6816408038139343, variance: 0.6863849759101868\n",
      "Train size: [400] hidden size: [118] trial: 42, train_loss: 1.261443, test loss: 1.368489, bias2: 0.6814122200012207, variance: 0.6870771646499634\n",
      "Train size: [400] hidden size: [118] trial: 43, train_loss: 1.261256, test loss: 1.366887, bias2: 0.6829209327697754, variance: 0.6839660406112671\n",
      "Train size: [400] hidden size: [118] trial: 44, train_loss: 1.261032, test loss: 1.365357, bias2: 0.68447345495224, variance: 0.6808831095695496\n",
      "Train size: [400] hidden size: [118] trial: 45, train_loss: 1.260069, test loss: 1.364432, bias2: 0.6853225231170654, variance: 0.6791096925735474\n",
      "Train size: [400] hidden size: [118] trial: 46, train_loss: 1.263068, test loss: 1.365105, bias2: 0.6837143898010254, variance: 0.6813908815383911\n",
      "Train size: [400] hidden size: [118] trial: 47, train_loss: 1.262973, test loss: 1.365821, bias2: 0.6832905411720276, variance: 0.6825303435325623\n",
      "Train size: [400] hidden size: [118] trial: 48, train_loss: 1.265885, test loss: 1.362804, bias2: 0.6823796033859253, variance: 0.6804242134094238\n",
      "Train size: [400] hidden size: [118] trial: 49, train_loss: 1.266727, test loss: 1.362864, bias2: 0.6823448538780212, variance: 0.6805194020271301\n",
      "##################################################\n",
      "Train size: [400] hidden size: [136] trial: 0, train_loss: 1.125345, test loss: 1.368033, bias2: 1.3680329322814941, variance: 3.8925479506346505e-10\n",
      "Train size: [400] hidden size: [136] trial: 1, train_loss: 1.255872, test loss: 1.370481, bias2: 0.9956965446472168, variance: 0.3747849762439728\n",
      "Train size: [400] hidden size: [136] trial: 2, train_loss: 1.230599, test loss: 1.355914, bias2: 0.8565440773963928, variance: 0.4993698000907898\n",
      "Train size: [400] hidden size: [136] trial: 3, train_loss: 1.202271, test loss: 1.389981, bias2: 0.8098546266555786, variance: 0.5801262855529785\n",
      "Train size: [400] hidden size: [136] trial: 4, train_loss: 1.211711, test loss: 1.379434, bias2: 0.7682650685310364, variance: 0.6111685633659363\n",
      "Train size: [400] hidden size: [136] trial: 5, train_loss: 1.207141, test loss: 1.398624, bias2: 0.7599362134933472, variance: 0.6386878490447998\n",
      "Train size: [400] hidden size: [136] trial: 6, train_loss: 1.207085, test loss: 1.383212, bias2: 0.7381767630577087, variance: 0.6450356841087341\n",
      "Train size: [400] hidden size: [136] trial: 7, train_loss: 1.214699, test loss: 1.379658, bias2: 0.7210003733634949, variance: 0.6586580872535706\n",
      "Train size: [400] hidden size: [136] trial: 8, train_loss: 1.227608, test loss: 1.373300, bias2: 0.7153979539871216, variance: 0.6579016447067261\n",
      "Train size: [400] hidden size: [136] trial: 9, train_loss: 1.225850, test loss: 1.376675, bias2: 0.7123116850852966, variance: 0.6643633246421814\n",
      "Train size: [400] hidden size: [136] trial: 10, train_loss: 1.223997, test loss: 1.366960, bias2: 0.7072823643684387, variance: 0.6596773266792297\n",
      "Train size: [400] hidden size: [136] trial: 11, train_loss: 1.224303, test loss: 1.352535, bias2: 0.7018337845802307, variance: 0.6507015824317932\n",
      "Train size: [400] hidden size: [136] trial: 12, train_loss: 1.216345, test loss: 1.363714, bias2: 0.6966724395751953, variance: 0.6670418977737427\n",
      "Train size: [400] hidden size: [136] trial: 13, train_loss: 1.214478, test loss: 1.363064, bias2: 0.684710681438446, variance: 0.6783531308174133\n",
      "Train size: [400] hidden size: [136] trial: 14, train_loss: 1.210760, test loss: 1.360634, bias2: 0.6744457483291626, variance: 0.6861884593963623\n",
      "Train size: [400] hidden size: [136] trial: 15, train_loss: 1.204902, test loss: 1.360863, bias2: 0.6744504570960999, variance: 0.6864121556282043\n",
      "Train size: [400] hidden size: [136] trial: 16, train_loss: 1.201644, test loss: 1.361046, bias2: 0.6712545156478882, variance: 0.6897919178009033\n",
      "Train size: [400] hidden size: [136] trial: 17, train_loss: 1.204069, test loss: 1.365138, bias2: 0.6645610928535461, variance: 0.7005766034126282\n",
      "Train size: [400] hidden size: [136] trial: 18, train_loss: 1.207423, test loss: 1.374570, bias2: 0.6685313582420349, variance: 0.7060388922691345\n",
      "Train size: [400] hidden size: [136] trial: 19, train_loss: 1.206934, test loss: 1.383562, bias2: 0.6700775027275085, variance: 0.7134842276573181\n",
      "Train size: [400] hidden size: [136] trial: 20, train_loss: 1.212730, test loss: 1.391241, bias2: 0.6689510941505432, variance: 0.7222893834114075\n",
      "Train size: [400] hidden size: [136] trial: 21, train_loss: 1.217989, test loss: 1.396494, bias2: 0.669442355632782, variance: 0.7270516753196716\n",
      "Train size: [400] hidden size: [136] trial: 22, train_loss: 1.220244, test loss: 1.391694, bias2: 0.6679388880729675, variance: 0.7237547039985657\n",
      "Train size: [400] hidden size: [136] trial: 23, train_loss: 1.223076, test loss: 1.390005, bias2: 0.6623166799545288, variance: 0.727688193321228\n",
      "Train size: [400] hidden size: [136] trial: 24, train_loss: 1.218916, test loss: 1.389650, bias2: 0.658939003944397, variance: 0.7307112216949463\n",
      "Train size: [400] hidden size: [136] trial: 25, train_loss: 1.217171, test loss: 1.397132, bias2: 0.6567375063896179, variance: 0.7403944134712219\n",
      "Train size: [400] hidden size: [136] trial: 26, train_loss: 1.221166, test loss: 1.398766, bias2: 0.6574323773384094, variance: 0.7413333058357239\n",
      "Train size: [400] hidden size: [136] trial: 27, train_loss: 1.222084, test loss: 1.397833, bias2: 0.6554834246635437, variance: 0.7423490881919861\n",
      "Train size: [400] hidden size: [136] trial: 28, train_loss: 1.218346, test loss: 1.399289, bias2: 0.6545864939689636, variance: 0.7447027564048767\n",
      "Train size: [400] hidden size: [136] trial: 29, train_loss: 1.220780, test loss: 1.401148, bias2: 0.6542835831642151, variance: 0.7468648552894592\n",
      "Train size: [400] hidden size: [136] trial: 30, train_loss: 1.224795, test loss: 1.395541, bias2: 0.6508659720420837, variance: 0.74467533826828\n",
      "Train size: [400] hidden size: [136] trial: 31, train_loss: 1.222592, test loss: 1.394015, bias2: 0.6472001671791077, variance: 0.7468145489692688\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [136] trial: 32, train_loss: 1.221127, test loss: 1.390703, bias2: 0.644737184047699, variance: 0.7459655404090881\n",
      "Train size: [400] hidden size: [136] trial: 33, train_loss: 1.218077, test loss: 1.392886, bias2: 0.6459167003631592, variance: 0.7469691038131714\n",
      "Train size: [400] hidden size: [136] trial: 34, train_loss: 1.215215, test loss: 1.393424, bias2: 0.6464259624481201, variance: 0.7469979524612427\n",
      "Train size: [400] hidden size: [136] trial: 35, train_loss: 1.212006, test loss: 1.393140, bias2: 0.643906831741333, variance: 0.7492334842681885\n",
      "Train size: [400] hidden size: [136] trial: 36, train_loss: 1.209934, test loss: 1.389196, bias2: 0.6423226594924927, variance: 0.7468734979629517\n",
      "Train size: [400] hidden size: [136] trial: 37, train_loss: 1.209726, test loss: 1.387696, bias2: 0.6414347290992737, variance: 0.7462612986564636\n",
      "Train size: [400] hidden size: [136] trial: 38, train_loss: 1.211283, test loss: 1.386015, bias2: 0.640145480632782, variance: 0.7458699345588684\n",
      "Train size: [400] hidden size: [136] trial: 39, train_loss: 1.208527, test loss: 1.383520, bias2: 0.6392090916633606, variance: 0.7443111538887024\n",
      "Train size: [400] hidden size: [136] trial: 40, train_loss: 1.210237, test loss: 1.382087, bias2: 0.6388243436813354, variance: 0.743262767791748\n",
      "Train size: [400] hidden size: [136] trial: 41, train_loss: 1.211014, test loss: 1.384330, bias2: 0.637429416179657, variance: 0.7469004988670349\n",
      "Train size: [400] hidden size: [136] trial: 42, train_loss: 1.208751, test loss: 1.385308, bias2: 0.6369605660438538, variance: 0.7483471035957336\n",
      "Train size: [400] hidden size: [136] trial: 43, train_loss: 1.205110, test loss: 1.384929, bias2: 0.6368033289909363, variance: 0.7481257319450378\n",
      "Train size: [400] hidden size: [136] trial: 44, train_loss: 1.203181, test loss: 1.385891, bias2: 0.6364808678627014, variance: 0.7494098544120789\n",
      "Train size: [400] hidden size: [136] trial: 45, train_loss: 1.203927, test loss: 1.385901, bias2: 0.6368154883384705, variance: 0.7490854859352112\n",
      "Train size: [400] hidden size: [136] trial: 46, train_loss: 1.201227, test loss: 1.387433, bias2: 0.6364294290542603, variance: 0.7510031461715698\n",
      "Train size: [400] hidden size: [136] trial: 47, train_loss: 1.201610, test loss: 1.384091, bias2: 0.6332108378410339, variance: 0.7508801817893982\n",
      "Train size: [400] hidden size: [136] trial: 48, train_loss: 1.200460, test loss: 1.385400, bias2: 0.6323812007904053, variance: 0.7530187368392944\n",
      "Train size: [400] hidden size: [136] trial: 49, train_loss: 1.197328, test loss: 1.386474, bias2: 0.6333655118942261, variance: 0.7531087398529053\n",
      "##################################################\n",
      "Train size: [400] hidden size: [156] trial: 0, train_loss: 1.174235, test loss: 1.296533, bias2: 1.2965325117111206, variance: -4.6710577628061856e-09\n",
      "Train size: [400] hidden size: [156] trial: 1, train_loss: 1.096148, test loss: 1.436562, bias2: 0.910574197769165, variance: 0.5259882211685181\n",
      "Train size: [400] hidden size: [156] trial: 2, train_loss: 1.045205, test loss: 1.374113, bias2: 0.7567065954208374, variance: 0.6174060106277466\n",
      "Train size: [400] hidden size: [156] trial: 3, train_loss: 1.040872, test loss: 1.380717, bias2: 0.7339103817939758, variance: 0.646806538105011\n",
      "Train size: [400] hidden size: [156] trial: 4, train_loss: 1.047434, test loss: 1.377925, bias2: 0.6948990821838379, variance: 0.683025598526001\n",
      "Train size: [400] hidden size: [156] trial: 5, train_loss: 1.067114, test loss: 1.407886, bias2: 0.6748539209365845, variance: 0.7330317497253418\n",
      "Train size: [400] hidden size: [156] trial: 6, train_loss: 1.061524, test loss: 1.400630, bias2: 0.6516836285591125, variance: 0.7489460110664368\n",
      "Train size: [400] hidden size: [156] trial: 7, train_loss: 1.062977, test loss: 1.398700, bias2: 0.6455101370811462, variance: 0.7531898617744446\n",
      "Train size: [400] hidden size: [156] trial: 8, train_loss: 1.070676, test loss: 1.402691, bias2: 0.649937629699707, variance: 0.752753496170044\n",
      "Train size: [400] hidden size: [156] trial: 9, train_loss: 1.088790, test loss: 1.400314, bias2: 0.6393894553184509, variance: 0.7609243988990784\n",
      "Train size: [400] hidden size: [156] trial: 10, train_loss: 1.088055, test loss: 1.404350, bias2: 0.6338406205177307, variance: 0.770509660243988\n",
      "Train size: [400] hidden size: [156] trial: 11, train_loss: 1.102648, test loss: 1.408812, bias2: 0.6347119212150574, variance: 0.7741003632545471\n",
      "Train size: [400] hidden size: [156] trial: 12, train_loss: 1.098228, test loss: 1.413131, bias2: 0.6332772970199585, variance: 0.7798538208007812\n",
      "Train size: [400] hidden size: [156] trial: 13, train_loss: 1.097580, test loss: 1.409310, bias2: 0.6303223967552185, variance: 0.778987467288971\n",
      "Train size: [400] hidden size: [156] trial: 14, train_loss: 1.092408, test loss: 1.404222, bias2: 0.6227990388870239, variance: 0.78142249584198\n",
      "Train size: [400] hidden size: [156] trial: 15, train_loss: 1.101189, test loss: 1.405030, bias2: 0.6273133158683777, variance: 0.777716338634491\n",
      "Train size: [400] hidden size: [156] trial: 16, train_loss: 1.094650, test loss: 1.405069, bias2: 0.6288694739341736, variance: 0.7761998772621155\n",
      "Train size: [400] hidden size: [156] trial: 17, train_loss: 1.092410, test loss: 1.412261, bias2: 0.6299819350242615, variance: 0.782278835773468\n",
      "Train size: [400] hidden size: [156] trial: 18, train_loss: 1.093514, test loss: 1.407781, bias2: 0.6226683855056763, variance: 0.7851130962371826\n",
      "Train size: [400] hidden size: [156] trial: 19, train_loss: 1.096111, test loss: 1.414191, bias2: 0.6178495287895203, variance: 0.7963412404060364\n",
      "Train size: [400] hidden size: [156] trial: 20, train_loss: 1.096895, test loss: 1.422839, bias2: 0.6132268309593201, variance: 0.8096123337745667\n",
      "Train size: [400] hidden size: [156] trial: 21, train_loss: 1.100905, test loss: 1.427855, bias2: 0.6166369915008545, variance: 0.8112177848815918\n",
      "Train size: [400] hidden size: [156] trial: 22, train_loss: 1.105457, test loss: 1.426002, bias2: 0.6152411699295044, variance: 0.8107603788375854\n",
      "Train size: [400] hidden size: [156] trial: 23, train_loss: 1.099675, test loss: 1.425684, bias2: 0.6166685819625854, variance: 0.8090149164199829\n",
      "Train size: [400] hidden size: [156] trial: 24, train_loss: 1.102864, test loss: 1.423939, bias2: 0.6154372096061707, variance: 0.8085020184516907\n",
      "Train size: [400] hidden size: [156] trial: 25, train_loss: 1.110499, test loss: 1.423642, bias2: 0.616369366645813, variance: 0.8072729110717773\n",
      "Train size: [400] hidden size: [156] trial: 26, train_loss: 1.104979, test loss: 1.424805, bias2: 0.6218435764312744, variance: 0.8029614686965942\n",
      "Train size: [400] hidden size: [156] trial: 27, train_loss: 1.104695, test loss: 1.421912, bias2: 0.622046709060669, variance: 0.7998650074005127\n",
      "Train size: [400] hidden size: [156] trial: 28, train_loss: 1.107506, test loss: 1.419286, bias2: 0.6210810542106628, variance: 0.7982051968574524\n",
      "Train size: [400] hidden size: [156] trial: 29, train_loss: 1.106248, test loss: 1.421951, bias2: 0.6211240887641907, variance: 0.8008268475532532\n",
      "Train size: [400] hidden size: [156] trial: 30, train_loss: 1.105634, test loss: 1.421511, bias2: 0.6202998161315918, variance: 0.8012109994888306\n",
      "Train size: [400] hidden size: [156] trial: 31, train_loss: 1.100352, test loss: 1.422865, bias2: 0.6227731108665466, variance: 0.8000920414924622\n",
      "Train size: [400] hidden size: [156] trial: 32, train_loss: 1.103905, test loss: 1.421086, bias2: 0.6236658096313477, variance: 0.7974206209182739\n",
      "Train size: [400] hidden size: [156] trial: 33, train_loss: 1.107080, test loss: 1.423691, bias2: 0.6187472343444824, variance: 0.804943323135376\n",
      "Train size: [400] hidden size: [156] trial: 34, train_loss: 1.109059, test loss: 1.424759, bias2: 0.6191025972366333, variance: 0.8056559562683105\n",
      "Train size: [400] hidden size: [156] trial: 35, train_loss: 1.110233, test loss: 1.424839, bias2: 0.6177434325218201, variance: 0.8070959448814392\n",
      "Train size: [400] hidden size: [156] trial: 36, train_loss: 1.106888, test loss: 1.422014, bias2: 0.6153900027275085, variance: 0.8066242337226868\n",
      "Train size: [400] hidden size: [156] trial: 37, train_loss: 1.108838, test loss: 1.418376, bias2: 0.6167093515396118, variance: 0.801666259765625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [156] trial: 38, train_loss: 1.101104, test loss: 1.421942, bias2: 0.6149997711181641, variance: 0.8069418668746948\n",
      "Train size: [400] hidden size: [156] trial: 39, train_loss: 1.102952, test loss: 1.419952, bias2: 0.613219678401947, variance: 0.806732714176178\n",
      "Train size: [400] hidden size: [156] trial: 40, train_loss: 1.100505, test loss: 1.417715, bias2: 0.6099201440811157, variance: 0.8077946901321411\n",
      "Train size: [400] hidden size: [156] trial: 41, train_loss: 1.097827, test loss: 1.420416, bias2: 0.609295666217804, variance: 0.8111204504966736\n",
      "Train size: [400] hidden size: [156] trial: 42, train_loss: 1.096292, test loss: 1.418526, bias2: 0.6094858050346375, variance: 0.8090406060218811\n",
      "Train size: [400] hidden size: [156] trial: 43, train_loss: 1.100014, test loss: 1.416580, bias2: 0.6084858775138855, variance: 0.8080945611000061\n",
      "Train size: [400] hidden size: [156] trial: 44, train_loss: 1.099482, test loss: 1.411047, bias2: 0.6075415015220642, variance: 0.8035054802894592\n",
      "Train size: [400] hidden size: [156] trial: 45, train_loss: 1.101075, test loss: 1.411839, bias2: 0.6075002551078796, variance: 0.8043391108512878\n",
      "Train size: [400] hidden size: [156] trial: 46, train_loss: 1.099694, test loss: 1.409156, bias2: 0.6079660654067993, variance: 0.8011897802352905\n",
      "Train size: [400] hidden size: [156] trial: 47, train_loss: 1.099951, test loss: 1.410890, bias2: 0.609275758266449, variance: 0.8016137480735779\n",
      "Train size: [400] hidden size: [156] trial: 48, train_loss: 1.100207, test loss: 1.411994, bias2: 0.6103540062904358, variance: 0.8016400933265686\n",
      "Train size: [400] hidden size: [156] trial: 49, train_loss: 1.098070, test loss: 1.409594, bias2: 0.610130250453949, variance: 0.7994640469551086\n",
      "##################################################\n",
      "Train size: [400] hidden size: [180] trial: 0, train_loss: 1.031609, test loss: 1.454135, bias2: 1.4541352987289429, variance: -4.6710577628061856e-09\n",
      "Train size: [400] hidden size: [180] trial: 1, train_loss: 1.007719, test loss: 1.508294, bias2: 1.0650644302368164, variance: 0.443229079246521\n",
      "Train size: [400] hidden size: [180] trial: 2, train_loss: 1.013765, test loss: 1.491765, bias2: 0.8971421122550964, variance: 0.5946231484413147\n",
      "Train size: [400] hidden size: [180] trial: 3, train_loss: 0.994428, test loss: 1.489786, bias2: 0.8250849843025208, variance: 0.6647009253501892\n",
      "Train size: [400] hidden size: [180] trial: 4, train_loss: 1.014140, test loss: 1.471563, bias2: 0.7774052619934082, variance: 0.6941574811935425\n",
      "Train size: [400] hidden size: [180] trial: 5, train_loss: 0.996174, test loss: 1.447852, bias2: 0.7389997839927673, variance: 0.7088518738746643\n",
      "Train size: [400] hidden size: [180] trial: 6, train_loss: 0.986008, test loss: 1.465571, bias2: 0.7373455166816711, variance: 0.7282252907752991\n",
      "Train size: [400] hidden size: [180] trial: 7, train_loss: 0.998788, test loss: 1.475356, bias2: 0.714208722114563, variance: 0.7611476182937622\n",
      "Train size: [400] hidden size: [180] trial: 8, train_loss: 0.975413, test loss: 1.444498, bias2: 0.6855866312980652, variance: 0.758911669254303\n",
      "Train size: [400] hidden size: [180] trial: 9, train_loss: 0.968361, test loss: 1.434269, bias2: 0.6773489117622375, variance: 0.7569199204444885\n",
      "Train size: [400] hidden size: [180] trial: 10, train_loss: 0.965471, test loss: 1.432321, bias2: 0.672800600528717, variance: 0.7595203518867493\n",
      "Train size: [400] hidden size: [180] trial: 11, train_loss: 0.967761, test loss: 1.429617, bias2: 0.6596046090126038, variance: 0.7700129151344299\n",
      "Train size: [400] hidden size: [180] trial: 12, train_loss: 0.982417, test loss: 1.428559, bias2: 0.6566043496131897, variance: 0.7719542384147644\n",
      "Train size: [400] hidden size: [180] trial: 13, train_loss: 0.986998, test loss: 1.419370, bias2: 0.653278648853302, variance: 0.7660912871360779\n",
      "Train size: [400] hidden size: [180] trial: 14, train_loss: 0.980960, test loss: 1.413517, bias2: 0.6426222324371338, variance: 0.7708948850631714\n",
      "Train size: [400] hidden size: [180] trial: 15, train_loss: 0.980394, test loss: 1.414791, bias2: 0.6385970115661621, variance: 0.7761937379837036\n",
      "Train size: [400] hidden size: [180] trial: 16, train_loss: 0.978480, test loss: 1.421270, bias2: 0.6289278268814087, variance: 0.7923417091369629\n",
      "Train size: [400] hidden size: [180] trial: 17, train_loss: 0.976372, test loss: 1.412168, bias2: 0.6247662305831909, variance: 0.7874014377593994\n",
      "Train size: [400] hidden size: [180] trial: 18, train_loss: 0.975436, test loss: 1.411454, bias2: 0.6236721873283386, variance: 0.787781298160553\n",
      "Train size: [400] hidden size: [180] trial: 19, train_loss: 0.973453, test loss: 1.416504, bias2: 0.6242762207984924, variance: 0.7922280430793762\n",
      "Train size: [400] hidden size: [180] trial: 20, train_loss: 0.980330, test loss: 1.409092, bias2: 0.6230000257492065, variance: 0.7860919237136841\n",
      "Train size: [400] hidden size: [180] trial: 21, train_loss: 0.973116, test loss: 1.405588, bias2: 0.6183948516845703, variance: 0.7871932983398438\n",
      "Train size: [400] hidden size: [180] trial: 22, train_loss: 0.970409, test loss: 1.411626, bias2: 0.6111570596694946, variance: 0.8004690408706665\n",
      "Train size: [400] hidden size: [180] trial: 23, train_loss: 0.973913, test loss: 1.406923, bias2: 0.6057493090629578, variance: 0.8011733889579773\n",
      "Train size: [400] hidden size: [180] trial: 24, train_loss: 0.977708, test loss: 1.411669, bias2: 0.606304407119751, variance: 0.805364727973938\n",
      "Train size: [400] hidden size: [180] trial: 25, train_loss: 0.980826, test loss: 1.417258, bias2: 0.6031309366226196, variance: 0.8141273260116577\n",
      "Train size: [400] hidden size: [180] trial: 26, train_loss: 0.988610, test loss: 1.420975, bias2: 0.6056546568870544, variance: 0.8153204321861267\n",
      "Train size: [400] hidden size: [180] trial: 27, train_loss: 0.990371, test loss: 1.423078, bias2: 0.6082573533058167, variance: 0.8148209452629089\n",
      "Train size: [400] hidden size: [180] trial: 28, train_loss: 0.997560, test loss: 1.422519, bias2: 0.6084993481636047, variance: 0.8140200972557068\n",
      "Train size: [400] hidden size: [180] trial: 29, train_loss: 0.994267, test loss: 1.423705, bias2: 0.6093234419822693, variance: 0.8143813014030457\n",
      "Train size: [400] hidden size: [180] trial: 30, train_loss: 0.996781, test loss: 1.423568, bias2: 0.6117234230041504, variance: 0.8118447065353394\n",
      "Train size: [400] hidden size: [180] trial: 31, train_loss: 1.006572, test loss: 1.431150, bias2: 0.6155075430870056, variance: 0.8156421780586243\n",
      "Train size: [400] hidden size: [180] trial: 32, train_loss: 1.005471, test loss: 1.426380, bias2: 0.6106297969818115, variance: 0.8157507181167603\n",
      "Train size: [400] hidden size: [180] trial: 33, train_loss: 1.003799, test loss: 1.421645, bias2: 0.6072672009468079, variance: 0.8143782019615173\n",
      "Train size: [400] hidden size: [180] trial: 34, train_loss: 1.002349, test loss: 1.421111, bias2: 0.6066048741340637, variance: 0.8145063519477844\n",
      "Train size: [400] hidden size: [180] trial: 35, train_loss: 0.999464, test loss: 1.424328, bias2: 0.6083826422691345, variance: 0.8159449696540833\n",
      "Train size: [400] hidden size: [180] trial: 36, train_loss: 1.001483, test loss: 1.420881, bias2: 0.6061269640922546, variance: 0.81475430727005\n",
      "Train size: [400] hidden size: [180] trial: 37, train_loss: 1.002058, test loss: 1.421968, bias2: 0.6062654852867126, variance: 0.8157020211219788\n",
      "Train size: [400] hidden size: [180] trial: 38, train_loss: 1.000035, test loss: 1.420614, bias2: 0.6021713614463806, variance: 0.8184428811073303\n",
      "Train size: [400] hidden size: [180] trial: 39, train_loss: 0.996837, test loss: 1.420011, bias2: 0.6030821800231934, variance: 0.8169292211532593\n",
      "Train size: [400] hidden size: [180] trial: 40, train_loss: 0.993617, test loss: 1.420909, bias2: 0.6033451557159424, variance: 0.8175636529922485\n",
      "Train size: [400] hidden size: [180] trial: 41, train_loss: 0.992787, test loss: 1.418892, bias2: 0.6023306846618652, variance: 0.8165613412857056\n",
      "Train size: [400] hidden size: [180] trial: 42, train_loss: 0.994351, test loss: 1.419541, bias2: 0.6000250577926636, variance: 0.819515585899353\n",
      "Train size: [400] hidden size: [180] trial: 43, train_loss: 0.989791, test loss: 1.416235, bias2: 0.5968950390815735, variance: 0.8193395733833313\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [180] trial: 44, train_loss: 0.988374, test loss: 1.413833, bias2: 0.5952622890472412, variance: 0.8185707330703735\n",
      "Train size: [400] hidden size: [180] trial: 45, train_loss: 0.990539, test loss: 1.413820, bias2: 0.5935812592506409, variance: 0.8202390074729919\n",
      "Train size: [400] hidden size: [180] trial: 46, train_loss: 0.991324, test loss: 1.414824, bias2: 0.5934234261512756, variance: 0.8214003443717957\n",
      "Train size: [400] hidden size: [180] trial: 47, train_loss: 0.991109, test loss: 1.416279, bias2: 0.5929503440856934, variance: 0.8233284950256348\n",
      "Train size: [400] hidden size: [180] trial: 48, train_loss: 0.992574, test loss: 1.413153, bias2: 0.5906087756156921, variance: 0.8225446343421936\n",
      "Train size: [400] hidden size: [180] trial: 49, train_loss: 0.992005, test loss: 1.412547, bias2: 0.5905547738075256, variance: 0.8219920992851257\n",
      "##################################################\n",
      "Train size: [400] hidden size: [207] trial: 0, train_loss: 0.901819, test loss: 1.602655, bias2: 1.6026548147201538, variance: 7.785095901269301e-10\n",
      "Train size: [400] hidden size: [207] trial: 1, train_loss: 0.903522, test loss: 1.529224, bias2: 1.0459973812103271, variance: 0.48322683572769165\n",
      "Train size: [400] hidden size: [207] trial: 2, train_loss: 0.918936, test loss: 1.540296, bias2: 0.8781850934028625, variance: 0.6621107459068298\n",
      "Train size: [400] hidden size: [207] trial: 3, train_loss: 0.902757, test loss: 1.516341, bias2: 0.7576351165771484, variance: 0.7587053775787354\n",
      "Train size: [400] hidden size: [207] trial: 4, train_loss: 0.891334, test loss: 1.497039, bias2: 0.6998234391212463, variance: 0.79721599817276\n",
      "Train size: [400] hidden size: [207] trial: 5, train_loss: 0.896333, test loss: 1.479125, bias2: 0.6552066206932068, variance: 0.8239182829856873\n",
      "Train size: [400] hidden size: [207] trial: 6, train_loss: 0.892520, test loss: 1.455554, bias2: 0.6321940422058105, variance: 0.8233603239059448\n",
      "Train size: [400] hidden size: [207] trial: 7, train_loss: 0.893109, test loss: 1.476793, bias2: 0.6292774677276611, variance: 0.8475151062011719\n",
      "Train size: [400] hidden size: [207] trial: 8, train_loss: 0.897123, test loss: 1.469029, bias2: 0.6170121431350708, variance: 0.8520163297653198\n",
      "Train size: [400] hidden size: [207] trial: 9, train_loss: 0.897073, test loss: 1.457247, bias2: 0.6067640781402588, variance: 0.8504830598831177\n",
      "Train size: [400] hidden size: [207] trial: 10, train_loss: 0.895818, test loss: 1.445588, bias2: 0.5910847783088684, variance: 0.8545036911964417\n",
      "Train size: [400] hidden size: [207] trial: 11, train_loss: 0.882409, test loss: 1.445482, bias2: 0.5876277089118958, variance: 0.8578545451164246\n",
      "Train size: [400] hidden size: [207] trial: 12, train_loss: 0.874487, test loss: 1.442736, bias2: 0.5837382078170776, variance: 0.8589978218078613\n",
      "Train size: [400] hidden size: [207] trial: 13, train_loss: 0.879975, test loss: 1.458216, bias2: 0.5809361934661865, variance: 0.8772792816162109\n",
      "Train size: [400] hidden size: [207] trial: 14, train_loss: 0.882308, test loss: 1.456160, bias2: 0.581866443157196, variance: 0.8742931485176086\n",
      "Train size: [400] hidden size: [207] trial: 15, train_loss: 0.885183, test loss: 1.455061, bias2: 0.5834000706672668, variance: 0.8716607689857483\n",
      "Train size: [400] hidden size: [207] trial: 16, train_loss: 0.878419, test loss: 1.451562, bias2: 0.580019474029541, variance: 0.8715424537658691\n",
      "Train size: [400] hidden size: [207] trial: 17, train_loss: 0.877540, test loss: 1.444210, bias2: 0.5791938304901123, variance: 0.865015983581543\n",
      "Train size: [400] hidden size: [207] trial: 18, train_loss: 0.883333, test loss: 1.440494, bias2: 0.5741952657699585, variance: 0.8662987947463989\n",
      "Train size: [400] hidden size: [207] trial: 19, train_loss: 0.881642, test loss: 1.451025, bias2: 0.5741853713989258, variance: 0.8768391609191895\n",
      "Train size: [400] hidden size: [207] trial: 20, train_loss: 0.875148, test loss: 1.454583, bias2: 0.5729468464851379, variance: 0.8816364407539368\n",
      "Train size: [400] hidden size: [207] trial: 21, train_loss: 0.869397, test loss: 1.448941, bias2: 0.5626229047775269, variance: 0.886318564414978\n",
      "Train size: [400] hidden size: [207] trial: 22, train_loss: 0.870490, test loss: 1.446948, bias2: 0.5635758638381958, variance: 0.8833717107772827\n",
      "Train size: [400] hidden size: [207] trial: 23, train_loss: 0.872505, test loss: 1.442013, bias2: 0.5588680505752563, variance: 0.8831449747085571\n",
      "Train size: [400] hidden size: [207] trial: 24, train_loss: 0.868821, test loss: 1.445334, bias2: 0.562912106513977, variance: 0.8824214935302734\n",
      "Train size: [400] hidden size: [207] trial: 25, train_loss: 0.867075, test loss: 1.440400, bias2: 0.5641646981239319, variance: 0.8762354254722595\n",
      "Train size: [400] hidden size: [207] trial: 26, train_loss: 0.865509, test loss: 1.439547, bias2: 0.5660906434059143, variance: 0.8734565377235413\n",
      "Train size: [400] hidden size: [207] trial: 27, train_loss: 0.868402, test loss: 1.440614, bias2: 0.5649943351745605, variance: 0.8756198883056641\n",
      "Train size: [400] hidden size: [207] trial: 28, train_loss: 0.872129, test loss: 1.442455, bias2: 0.5608388781547546, variance: 0.8816160559654236\n",
      "Train size: [400] hidden size: [207] trial: 29, train_loss: 0.872316, test loss: 1.439533, bias2: 0.5626307129859924, variance: 0.8769026398658752\n",
      "Train size: [400] hidden size: [207] trial: 30, train_loss: 0.875176, test loss: 1.443928, bias2: 0.5622947216033936, variance: 0.8816328048706055\n",
      "Train size: [400] hidden size: [207] trial: 31, train_loss: 0.874759, test loss: 1.443119, bias2: 0.5638639330863953, variance: 0.879255473613739\n",
      "Train size: [400] hidden size: [207] trial: 32, train_loss: 0.871040, test loss: 1.438626, bias2: 0.5626851320266724, variance: 0.875941276550293\n",
      "Train size: [400] hidden size: [207] trial: 33, train_loss: 0.871735, test loss: 1.435981, bias2: 0.5586243867874146, variance: 0.8773571252822876\n",
      "Train size: [400] hidden size: [207] trial: 34, train_loss: 0.874594, test loss: 1.437500, bias2: 0.5542367696762085, variance: 0.8832628726959229\n",
      "Train size: [400] hidden size: [207] trial: 35, train_loss: 0.876013, test loss: 1.440194, bias2: 0.5534213185310364, variance: 0.8867729306221008\n",
      "Train size: [400] hidden size: [207] trial: 36, train_loss: 0.873016, test loss: 1.442871, bias2: 0.5563163161277771, variance: 0.8865541815757751\n",
      "Train size: [400] hidden size: [207] trial: 37, train_loss: 0.876454, test loss: 1.448565, bias2: 0.5552585124969482, variance: 0.8933063745498657\n",
      "Train size: [400] hidden size: [207] trial: 38, train_loss: 0.877717, test loss: 1.449203, bias2: 0.5535327196121216, variance: 0.8956702947616577\n",
      "Train size: [400] hidden size: [207] trial: 39, train_loss: 0.877088, test loss: 1.449929, bias2: 0.5545410513877869, variance: 0.8953883051872253\n",
      "Train size: [400] hidden size: [207] trial: 40, train_loss: 0.877499, test loss: 1.446327, bias2: 0.5546043515205383, variance: 0.8917228579521179\n",
      "Train size: [400] hidden size: [207] trial: 41, train_loss: 0.874701, test loss: 1.448045, bias2: 0.5547442436218262, variance: 0.8933007717132568\n",
      "Train size: [400] hidden size: [207] trial: 42, train_loss: 0.873590, test loss: 1.448347, bias2: 0.553734302520752, variance: 0.8946130275726318\n",
      "Train size: [400] hidden size: [207] trial: 43, train_loss: 0.875242, test loss: 1.445992, bias2: 0.5519054532051086, variance: 0.8940864205360413\n",
      "Train size: [400] hidden size: [207] trial: 44, train_loss: 0.873396, test loss: 1.443754, bias2: 0.551774799823761, variance: 0.8919788002967834\n",
      "Train size: [400] hidden size: [207] trial: 45, train_loss: 0.875871, test loss: 1.442574, bias2: 0.549037754535675, variance: 0.8935362696647644\n",
      "Train size: [400] hidden size: [207] trial: 46, train_loss: 0.875896, test loss: 1.441817, bias2: 0.5519503355026245, variance: 0.8898667097091675\n",
      "Train size: [400] hidden size: [207] trial: 47, train_loss: 0.874749, test loss: 1.440318, bias2: 0.5495721697807312, variance: 0.8907461762428284\n",
      "Train size: [400] hidden size: [207] trial: 48, train_loss: 0.878690, test loss: 1.441100, bias2: 0.5514701008796692, variance: 0.8896303772926331\n",
      "Train size: [400] hidden size: [207] trial: 49, train_loss: 0.876861, test loss: 1.438865, bias2: 0.5516183972358704, variance: 0.8872470259666443\n",
      "##################################################\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [239] trial: 0, train_loss: 0.854961, test loss: 1.607034, bias2: 1.6070342063903809, variance: -4.6710577628061856e-09\n",
      "Train size: [400] hidden size: [239] trial: 1, train_loss: 0.797583, test loss: 1.508613, bias2: 1.0258750915527344, variance: 0.4827379882335663\n",
      "Train size: [400] hidden size: [239] trial: 2, train_loss: 0.806089, test loss: 1.521725, bias2: 0.8392072916030884, variance: 0.6825175285339355\n",
      "Train size: [400] hidden size: [239] trial: 3, train_loss: 0.784885, test loss: 1.523511, bias2: 0.7493507266044617, variance: 0.7741600871086121\n",
      "Train size: [400] hidden size: [239] trial: 4, train_loss: 0.801821, test loss: 1.501518, bias2: 0.702480137348175, variance: 0.799037754535675\n",
      "Train size: [400] hidden size: [239] trial: 5, train_loss: 0.791862, test loss: 1.489814, bias2: 0.6701051592826843, variance: 0.8197090029716492\n",
      "Train size: [400] hidden size: [239] trial: 6, train_loss: 0.780267, test loss: 1.492346, bias2: 0.6526858806610107, variance: 0.8396602869033813\n",
      "Train size: [400] hidden size: [239] trial: 7, train_loss: 0.774956, test loss: 1.480225, bias2: 0.6422452330589294, variance: 0.8379796147346497\n",
      "Train size: [400] hidden size: [239] trial: 8, train_loss: 0.775028, test loss: 1.483429, bias2: 0.6339110136032104, variance: 0.8495181798934937\n",
      "Train size: [400] hidden size: [239] trial: 9, train_loss: 0.780564, test loss: 1.470378, bias2: 0.6122379302978516, variance: 0.8581401109695435\n",
      "Train size: [400] hidden size: [239] trial: 10, train_loss: 0.791253, test loss: 1.481627, bias2: 0.6069117188453674, variance: 0.8747149109840393\n",
      "Train size: [400] hidden size: [239] trial: 11, train_loss: 0.778169, test loss: 1.483691, bias2: 0.6097303628921509, variance: 0.8739608526229858\n",
      "Train size: [400] hidden size: [239] trial: 12, train_loss: 0.787955, test loss: 1.473904, bias2: 0.5988384485244751, variance: 0.8750652074813843\n",
      "Train size: [400] hidden size: [239] trial: 13, train_loss: 0.790984, test loss: 1.466378, bias2: 0.5910027623176575, variance: 0.8753747344017029\n",
      "Train size: [400] hidden size: [239] trial: 14, train_loss: 0.792046, test loss: 1.470349, bias2: 0.5853766202926636, variance: 0.884972095489502\n",
      "Train size: [400] hidden size: [239] trial: 15, train_loss: 0.800451, test loss: 1.467332, bias2: 0.5861807465553284, variance: 0.8811511397361755\n",
      "Train size: [400] hidden size: [239] trial: 16, train_loss: 0.791033, test loss: 1.454044, bias2: 0.5817114114761353, variance: 0.8723330497741699\n",
      "Train size: [400] hidden size: [239] trial: 17, train_loss: 0.795381, test loss: 1.438596, bias2: 0.5715092420578003, variance: 0.8670871257781982\n",
      "Train size: [400] hidden size: [239] trial: 18, train_loss: 0.797647, test loss: 1.442150, bias2: 0.5660922527313232, variance: 0.8760577440261841\n",
      "Train size: [400] hidden size: [239] trial: 19, train_loss: 0.801640, test loss: 1.435314, bias2: 0.5546181797981262, variance: 0.8806958794593811\n",
      "Train size: [400] hidden size: [239] trial: 20, train_loss: 0.804251, test loss: 1.430568, bias2: 0.5445601344108582, variance: 0.8860074877738953\n",
      "Train size: [400] hidden size: [239] trial: 21, train_loss: 0.801360, test loss: 1.429475, bias2: 0.5399855971336365, variance: 0.8894898295402527\n",
      "Train size: [400] hidden size: [239] trial: 22, train_loss: 0.802898, test loss: 1.435557, bias2: 0.5380591154098511, variance: 0.8974981307983398\n",
      "Train size: [400] hidden size: [239] trial: 23, train_loss: 0.803324, test loss: 1.439596, bias2: 0.5361632108688354, variance: 0.9034332036972046\n",
      "Train size: [400] hidden size: [239] trial: 24, train_loss: 0.802623, test loss: 1.443354, bias2: 0.5323718190193176, variance: 0.9109817147254944\n",
      "Train size: [400] hidden size: [239] trial: 25, train_loss: 0.803086, test loss: 1.438787, bias2: 0.530117928981781, variance: 0.9086694121360779\n",
      "Train size: [400] hidden size: [239] trial: 26, train_loss: 0.804037, test loss: 1.441163, bias2: 0.5287282466888428, variance: 0.9124352931976318\n",
      "Train size: [400] hidden size: [239] trial: 27, train_loss: 0.807055, test loss: 1.439184, bias2: 0.5252069234848022, variance: 0.9139771461486816\n",
      "Train size: [400] hidden size: [239] trial: 28, train_loss: 0.806688, test loss: 1.441200, bias2: 0.5243144631385803, variance: 0.9168856739997864\n",
      "Train size: [400] hidden size: [239] trial: 29, train_loss: 0.806896, test loss: 1.445387, bias2: 0.5228712558746338, variance: 0.9225157499313354\n",
      "Train size: [400] hidden size: [239] trial: 30, train_loss: 0.804899, test loss: 1.442682, bias2: 0.5175842046737671, variance: 0.9250977039337158\n",
      "Train size: [400] hidden size: [239] trial: 31, train_loss: 0.810311, test loss: 1.441616, bias2: 0.5154524445533752, variance: 0.9261639714241028\n",
      "Train size: [400] hidden size: [239] trial: 32, train_loss: 0.811645, test loss: 1.438981, bias2: 0.5161702036857605, variance: 0.9228107333183289\n",
      "Train size: [400] hidden size: [239] trial: 33, train_loss: 0.807818, test loss: 1.436956, bias2: 0.5158411860466003, variance: 0.9211143851280212\n",
      "Train size: [400] hidden size: [239] trial: 34, train_loss: 0.810929, test loss: 1.436248, bias2: 0.513755202293396, variance: 0.9224929809570312\n",
      "Train size: [400] hidden size: [239] trial: 35, train_loss: 0.809790, test loss: 1.435226, bias2: 0.512830913066864, variance: 0.9223954081535339\n",
      "Train size: [400] hidden size: [239] trial: 36, train_loss: 0.808870, test loss: 1.433540, bias2: 0.5099495649337769, variance: 0.9235904216766357\n",
      "Train size: [400] hidden size: [239] trial: 37, train_loss: 0.811019, test loss: 1.433484, bias2: 0.511705219745636, variance: 0.9217788577079773\n",
      "Train size: [400] hidden size: [239] trial: 38, train_loss: 0.805765, test loss: 1.435895, bias2: 0.5130931735038757, variance: 0.9228014349937439\n",
      "Train size: [400] hidden size: [239] trial: 39, train_loss: 0.804087, test loss: 1.433151, bias2: 0.5123551487922668, variance: 0.9207959771156311\n",
      "Train size: [400] hidden size: [239] trial: 40, train_loss: 0.803547, test loss: 1.432775, bias2: 0.5115310549736023, variance: 0.9212436079978943\n",
      "Train size: [400] hidden size: [239] trial: 41, train_loss: 0.803289, test loss: 1.434334, bias2: 0.5118502378463745, variance: 0.9224836826324463\n",
      "Train size: [400] hidden size: [239] trial: 42, train_loss: 0.804244, test loss: 1.431074, bias2: 0.5093518495559692, variance: 0.9217220544815063\n",
      "Train size: [400] hidden size: [239] trial: 43, train_loss: 0.802503, test loss: 1.426653, bias2: 0.5080801844596863, variance: 0.918572723865509\n",
      "Train size: [400] hidden size: [239] trial: 44, train_loss: 0.801215, test loss: 1.427364, bias2: 0.5078449249267578, variance: 0.9195194244384766\n",
      "Train size: [400] hidden size: [239] trial: 45, train_loss: 0.800636, test loss: 1.432377, bias2: 0.5082547664642334, variance: 0.9241218566894531\n",
      "Train size: [400] hidden size: [239] trial: 46, train_loss: 0.801373, test loss: 1.434250, bias2: 0.5088889598846436, variance: 0.9253612756729126\n",
      "Train size: [400] hidden size: [239] trial: 47, train_loss: 0.802046, test loss: 1.435485, bias2: 0.5082390904426575, variance: 0.9272461533546448\n",
      "Train size: [400] hidden size: [239] trial: 48, train_loss: 0.802099, test loss: 1.436040, bias2: 0.5080872178077698, variance: 0.9279524683952332\n",
      "Train size: [400] hidden size: [239] trial: 49, train_loss: 0.804254, test loss: 1.436351, bias2: 0.508757472038269, variance: 0.9275929927825928\n",
      "##################################################\n",
      "Train size: [400] hidden size: [275] trial: 0, train_loss: 0.753669, test loss: 1.601109, bias2: 1.601109266281128, variance: 3.1140383605077204e-09\n",
      "Train size: [400] hidden size: [275] trial: 1, train_loss: 0.727710, test loss: 1.546258, bias2: 0.9425912499427795, variance: 0.6036671996116638\n",
      "Train size: [400] hidden size: [275] trial: 2, train_loss: 0.738246, test loss: 1.509239, bias2: 0.7783977389335632, variance: 0.730841338634491\n",
      "Train size: [400] hidden size: [275] trial: 3, train_loss: 0.729955, test loss: 1.455883, bias2: 0.6997783184051514, variance: 0.756104588508606\n",
      "Train size: [400] hidden size: [275] trial: 4, train_loss: 0.744752, test loss: 1.476936, bias2: 0.6576634049415588, variance: 0.8192726969718933\n",
      "Train size: [400] hidden size: [275] trial: 5, train_loss: 0.736547, test loss: 1.488211, bias2: 0.6350843906402588, variance: 0.8531262874603271\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [275] trial: 6, train_loss: 0.733911, test loss: 1.473861, bias2: 0.610905647277832, variance: 0.86295485496521\n",
      "Train size: [400] hidden size: [275] trial: 7, train_loss: 0.723819, test loss: 1.464278, bias2: 0.5930711627006531, variance: 0.8712067008018494\n",
      "Train size: [400] hidden size: [275] trial: 8, train_loss: 0.715991, test loss: 1.472652, bias2: 0.5799276828765869, variance: 0.8927243947982788\n",
      "Train size: [400] hidden size: [275] trial: 9, train_loss: 0.712376, test loss: 1.463172, bias2: 0.5598878264427185, variance: 0.90328449010849\n",
      "Train size: [400] hidden size: [275] trial: 10, train_loss: 0.715969, test loss: 1.449883, bias2: 0.5555017590522766, variance: 0.8943814635276794\n",
      "Train size: [400] hidden size: [275] trial: 11, train_loss: 0.718391, test loss: 1.438546, bias2: 0.5498849153518677, variance: 0.8886607885360718\n",
      "Train size: [400] hidden size: [275] trial: 12, train_loss: 0.721567, test loss: 1.429862, bias2: 0.5434077978134155, variance: 0.8864541053771973\n",
      "Train size: [400] hidden size: [275] trial: 13, train_loss: 0.719763, test loss: 1.422376, bias2: 0.534642219543457, variance: 0.8877335786819458\n",
      "Train size: [400] hidden size: [275] trial: 14, train_loss: 0.718543, test loss: 1.414677, bias2: 0.5343322157859802, variance: 0.8803449273109436\n",
      "Train size: [400] hidden size: [275] trial: 15, train_loss: 0.712848, test loss: 1.414545, bias2: 0.5264177918434143, variance: 0.8881271481513977\n",
      "Train size: [400] hidden size: [275] trial: 16, train_loss: 0.714246, test loss: 1.419438, bias2: 0.5270724892616272, variance: 0.8923657536506653\n",
      "Train size: [400] hidden size: [275] trial: 17, train_loss: 0.711211, test loss: 1.417972, bias2: 0.5219504237174988, variance: 0.8960217833518982\n",
      "Train size: [400] hidden size: [275] trial: 18, train_loss: 0.706702, test loss: 1.418437, bias2: 0.5181952118873596, variance: 0.9002416729927063\n",
      "Train size: [400] hidden size: [275] trial: 19, train_loss: 0.706117, test loss: 1.417135, bias2: 0.5155577659606934, variance: 0.9015767574310303\n",
      "Train size: [400] hidden size: [275] trial: 20, train_loss: 0.704466, test loss: 1.419542, bias2: 0.5143581628799438, variance: 0.9051839113235474\n",
      "Train size: [400] hidden size: [275] trial: 21, train_loss: 0.706753, test loss: 1.422675, bias2: 0.5159648060798645, variance: 0.9067098498344421\n",
      "Train size: [400] hidden size: [275] trial: 22, train_loss: 0.710535, test loss: 1.419006, bias2: 0.5140100121498108, variance: 0.9049956202507019\n",
      "Train size: [400] hidden size: [275] trial: 23, train_loss: 0.706042, test loss: 1.422526, bias2: 0.5120575428009033, variance: 0.910468578338623\n",
      "Train size: [400] hidden size: [275] trial: 24, train_loss: 0.709776, test loss: 1.421001, bias2: 0.511496901512146, variance: 0.9095044136047363\n",
      "Train size: [400] hidden size: [275] trial: 25, train_loss: 0.710357, test loss: 1.422777, bias2: 0.5135160684585571, variance: 0.9092614650726318\n",
      "Train size: [400] hidden size: [275] trial: 26, train_loss: 0.707277, test loss: 1.418524, bias2: 0.5109752416610718, variance: 0.9075486660003662\n",
      "Train size: [400] hidden size: [275] trial: 27, train_loss: 0.702099, test loss: 1.416564, bias2: 0.5115511417388916, variance: 0.905012845993042\n",
      "Train size: [400] hidden size: [275] trial: 28, train_loss: 0.705051, test loss: 1.415872, bias2: 0.5109995007514954, variance: 0.904872715473175\n",
      "Train size: [400] hidden size: [275] trial: 29, train_loss: 0.702501, test loss: 1.413340, bias2: 0.5079294443130493, variance: 0.9054102897644043\n",
      "Train size: [400] hidden size: [275] trial: 30, train_loss: 0.699024, test loss: 1.415450, bias2: 0.5081479549407959, variance: 0.9073021411895752\n",
      "Train size: [400] hidden size: [275] trial: 31, train_loss: 0.700533, test loss: 1.414982, bias2: 0.5079740881919861, variance: 0.9070077538490295\n",
      "Train size: [400] hidden size: [275] trial: 32, train_loss: 0.702754, test loss: 1.417055, bias2: 0.5055674910545349, variance: 0.911487877368927\n",
      "Train size: [400] hidden size: [275] trial: 33, train_loss: 0.705174, test loss: 1.418129, bias2: 0.5058026909828186, variance: 0.9123262763023376\n",
      "Train size: [400] hidden size: [275] trial: 34, train_loss: 0.703625, test loss: 1.414667, bias2: 0.5056513547897339, variance: 0.9090152978897095\n",
      "Train size: [400] hidden size: [275] trial: 35, train_loss: 0.703880, test loss: 1.413978, bias2: 0.5066730976104736, variance: 0.9073045253753662\n",
      "Train size: [400] hidden size: [275] trial: 36, train_loss: 0.697595, test loss: 1.409310, bias2: 0.5044859647750854, variance: 0.9048236608505249\n",
      "Train size: [400] hidden size: [275] trial: 37, train_loss: 0.697642, test loss: 1.405218, bias2: 0.5022546648979187, variance: 0.902962863445282\n",
      "Train size: [400] hidden size: [275] trial: 38, train_loss: 0.696441, test loss: 1.403446, bias2: 0.502631425857544, variance: 0.9008148908615112\n",
      "Train size: [400] hidden size: [275] trial: 39, train_loss: 0.695205, test loss: 1.399355, bias2: 0.5007667541503906, variance: 0.8985885381698608\n",
      "Train size: [400] hidden size: [275] trial: 40, train_loss: 0.696387, test loss: 1.397175, bias2: 0.49926793575286865, variance: 0.897907018661499\n",
      "Train size: [400] hidden size: [275] trial: 41, train_loss: 0.694839, test loss: 1.399796, bias2: 0.498821496963501, variance: 0.9009748697280884\n",
      "Train size: [400] hidden size: [275] trial: 42, train_loss: 0.697580, test loss: 1.401890, bias2: 0.49753350019454956, variance: 0.9043561816215515\n",
      "Train size: [400] hidden size: [275] trial: 43, train_loss: 0.696542, test loss: 1.400269, bias2: 0.49560075998306274, variance: 0.9046680331230164\n",
      "Train size: [400] hidden size: [275] trial: 44, train_loss: 0.695232, test loss: 1.396209, bias2: 0.49453169107437134, variance: 0.901677668094635\n",
      "Train size: [400] hidden size: [275] trial: 45, train_loss: 0.694634, test loss: 1.395591, bias2: 0.4953436851501465, variance: 0.9002472162246704\n",
      "Train size: [400] hidden size: [275] trial: 46, train_loss: 0.697534, test loss: 1.396304, bias2: 0.489859938621521, variance: 0.9064444303512573\n",
      "Train size: [400] hidden size: [275] trial: 47, train_loss: 0.700064, test loss: 1.398574, bias2: 0.49125081300735474, variance: 0.9073230624198914\n",
      "Train size: [400] hidden size: [275] trial: 48, train_loss: 0.699260, test loss: 1.397980, bias2: 0.48993980884552, variance: 0.9080401659011841\n",
      "Train size: [400] hidden size: [275] trial: 49, train_loss: 0.699135, test loss: 1.397209, bias2: 0.4886704683303833, variance: 0.9085381031036377\n",
      "##################################################\n",
      "Train size: [400] hidden size: [316] trial: 0, train_loss: 0.664227, test loss: 1.499123, bias2: 1.4991228580474854, variance: 0.0\n",
      "Train size: [400] hidden size: [316] trial: 1, train_loss: 0.632798, test loss: 1.397286, bias2: 0.9258947372436523, variance: 0.47139132022857666\n",
      "Train size: [400] hidden size: [316] trial: 2, train_loss: 0.635890, test loss: 1.446628, bias2: 0.7955281138420105, variance: 0.6510995030403137\n",
      "Train size: [400] hidden size: [316] trial: 3, train_loss: 0.617359, test loss: 1.420455, bias2: 0.7070077061653137, variance: 0.7134469151496887\n",
      "Train size: [400] hidden size: [316] trial: 4, train_loss: 0.611540, test loss: 1.413025, bias2: 0.6578095555305481, variance: 0.755215585231781\n",
      "Train size: [400] hidden size: [316] trial: 5, train_loss: 0.604747, test loss: 1.404589, bias2: 0.61561518907547, variance: 0.7889735102653503\n",
      "Train size: [400] hidden size: [316] trial: 6, train_loss: 0.625782, test loss: 1.389709, bias2: 0.5785403847694397, variance: 0.8111681342124939\n",
      "Train size: [400] hidden size: [316] trial: 7, train_loss: 0.629506, test loss: 1.378657, bias2: 0.5608230829238892, variance: 0.8178342580795288\n",
      "Train size: [400] hidden size: [316] trial: 8, train_loss: 0.630616, test loss: 1.383080, bias2: 0.5601344704627991, variance: 0.8229455351829529\n",
      "Train size: [400] hidden size: [316] trial: 9, train_loss: 0.633216, test loss: 1.386692, bias2: 0.555265486240387, variance: 0.831426203250885\n",
      "Train size: [400] hidden size: [316] trial: 10, train_loss: 0.639674, test loss: 1.376299, bias2: 0.5387784242630005, variance: 0.8375210762023926\n",
      "Train size: [400] hidden size: [316] trial: 11, train_loss: 0.641492, test loss: 1.362655, bias2: 0.5190154910087585, variance: 0.8436394333839417\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [316] trial: 12, train_loss: 0.635111, test loss: 1.360910, bias2: 0.5152584910392761, variance: 0.8456510901451111\n",
      "Train size: [400] hidden size: [316] trial: 13, train_loss: 0.632015, test loss: 1.364405, bias2: 0.5128983855247498, variance: 0.8515062928199768\n",
      "Train size: [400] hidden size: [316] trial: 14, train_loss: 0.629542, test loss: 1.360649, bias2: 0.5045483708381653, variance: 0.8561007380485535\n",
      "Train size: [400] hidden size: [316] trial: 15, train_loss: 0.623064, test loss: 1.359359, bias2: 0.5039954781532288, variance: 0.8553633093833923\n",
      "Train size: [400] hidden size: [316] trial: 16, train_loss: 0.625809, test loss: 1.360355, bias2: 0.499747633934021, variance: 0.8606072664260864\n",
      "Train size: [400] hidden size: [316] trial: 17, train_loss: 0.624726, test loss: 1.354639, bias2: 0.49368607997894287, variance: 0.8609530925750732\n",
      "Train size: [400] hidden size: [316] trial: 18, train_loss: 0.630692, test loss: 1.355723, bias2: 0.4887639284133911, variance: 0.8669594526290894\n",
      "Train size: [400] hidden size: [316] trial: 19, train_loss: 0.634698, test loss: 1.355153, bias2: 0.4887382984161377, variance: 0.8664151430130005\n",
      "Train size: [400] hidden size: [316] trial: 20, train_loss: 0.640692, test loss: 1.355814, bias2: 0.4868178963661194, variance: 0.8689964413642883\n",
      "Train size: [400] hidden size: [316] trial: 21, train_loss: 0.634709, test loss: 1.357646, bias2: 0.48875510692596436, variance: 0.8688905239105225\n",
      "Train size: [400] hidden size: [316] trial: 22, train_loss: 0.629978, test loss: 1.355762, bias2: 0.48439985513687134, variance: 0.8713626265525818\n",
      "Train size: [400] hidden size: [316] trial: 23, train_loss: 0.625454, test loss: 1.352809, bias2: 0.480892539024353, variance: 0.8719161748886108\n",
      "Train size: [400] hidden size: [316] trial: 24, train_loss: 0.621199, test loss: 1.348583, bias2: 0.47776079177856445, variance: 0.8708226680755615\n",
      "Train size: [400] hidden size: [316] trial: 25, train_loss: 0.620609, test loss: 1.345535, bias2: 0.4728444814682007, variance: 0.8726906776428223\n",
      "Train size: [400] hidden size: [316] trial: 26, train_loss: 0.618444, test loss: 1.348721, bias2: 0.47463297843933105, variance: 0.8740881681442261\n",
      "Train size: [400] hidden size: [316] trial: 27, train_loss: 0.616673, test loss: 1.349756, bias2: 0.4710020422935486, variance: 0.8787543177604675\n",
      "Train size: [400] hidden size: [316] trial: 28, train_loss: 0.613992, test loss: 1.349081, bias2: 0.47249096632003784, variance: 0.876589834690094\n",
      "Train size: [400] hidden size: [316] trial: 29, train_loss: 0.611274, test loss: 1.352877, bias2: 0.47589927911758423, variance: 0.8769778609275818\n",
      "Train size: [400] hidden size: [316] trial: 30, train_loss: 0.609491, test loss: 1.351451, bias2: 0.47414225339889526, variance: 0.8773091435432434\n",
      "Train size: [400] hidden size: [316] trial: 31, train_loss: 0.609916, test loss: 1.351607, bias2: 0.47299444675445557, variance: 0.8786120414733887\n",
      "Train size: [400] hidden size: [316] trial: 32, train_loss: 0.609244, test loss: 1.351845, bias2: 0.47125959396362305, variance: 0.8805850744247437\n",
      "Train size: [400] hidden size: [316] trial: 33, train_loss: 0.608361, test loss: 1.354755, bias2: 0.4696117639541626, variance: 0.8851433992385864\n",
      "Train size: [400] hidden size: [316] trial: 34, train_loss: 0.610696, test loss: 1.357224, bias2: 0.4701768159866333, variance: 0.8870474100112915\n",
      "Train size: [400] hidden size: [316] trial: 35, train_loss: 0.607289, test loss: 1.357230, bias2: 0.47205257415771484, variance: 0.8851771354675293\n",
      "Train size: [400] hidden size: [316] trial: 36, train_loss: 0.608473, test loss: 1.364624, bias2: 0.4736294746398926, variance: 0.8909949064254761\n",
      "Train size: [400] hidden size: [316] trial: 37, train_loss: 0.607571, test loss: 1.364674, bias2: 0.47276216745376587, variance: 0.8919121623039246\n",
      "Train size: [400] hidden size: [316] trial: 38, train_loss: 0.605503, test loss: 1.362880, bias2: 0.46886056661605835, variance: 0.8940194249153137\n",
      "Train size: [400] hidden size: [316] trial: 39, train_loss: 0.603730, test loss: 1.363329, bias2: 0.46758341789245605, variance: 0.8957459926605225\n",
      "Train size: [400] hidden size: [316] trial: 40, train_loss: 0.604787, test loss: 1.364714, bias2: 0.46528929471969604, variance: 0.8994244933128357\n",
      "Train size: [400] hidden size: [316] trial: 41, train_loss: 0.603615, test loss: 1.361863, bias2: 0.46511518955230713, variance: 0.8967474699020386\n",
      "Train size: [400] hidden size: [316] trial: 42, train_loss: 0.602123, test loss: 1.360275, bias2: 0.4614836573600769, variance: 0.898791491985321\n",
      "Train size: [400] hidden size: [316] trial: 43, train_loss: 0.600874, test loss: 1.359072, bias2: 0.46133852005004883, variance: 0.8977339267730713\n",
      "Train size: [400] hidden size: [316] trial: 44, train_loss: 0.601686, test loss: 1.358810, bias2: 0.46008098125457764, variance: 0.8987293243408203\n",
      "Train size: [400] hidden size: [316] trial: 45, train_loss: 0.601770, test loss: 1.358622, bias2: 0.45977967977523804, variance: 0.8988425135612488\n",
      "Train size: [400] hidden size: [316] trial: 46, train_loss: 0.602183, test loss: 1.357171, bias2: 0.4579163193702698, variance: 0.899255096912384\n",
      "Train size: [400] hidden size: [316] trial: 47, train_loss: 0.602394, test loss: 1.360150, bias2: 0.45692962408065796, variance: 0.9032207131385803\n",
      "Train size: [400] hidden size: [316] trial: 48, train_loss: 0.602729, test loss: 1.360551, bias2: 0.457960307598114, variance: 0.9025905728340149\n",
      "Train size: [400] hidden size: [316] trial: 49, train_loss: 0.602071, test loss: 1.359525, bias2: 0.4563848376274109, variance: 0.9031397700309753\n",
      "##################################################\n",
      "Train size: [400] hidden size: [364] trial: 0, train_loss: 0.595116, test loss: 1.290952, bias2: 1.2909517288208008, variance: 2.3355288814030928e-09\n",
      "Train size: [400] hidden size: [364] trial: 1, train_loss: 0.557641, test loss: 1.311298, bias2: 0.8896777033805847, variance: 0.42162007093429565\n",
      "Train size: [400] hidden size: [364] trial: 2, train_loss: 0.548661, test loss: 1.307485, bias2: 0.7378472685813904, variance: 0.5696372389793396\n",
      "Train size: [400] hidden size: [364] trial: 3, train_loss: 0.532771, test loss: 1.308265, bias2: 0.6400570273399353, variance: 0.6682080626487732\n",
      "Train size: [400] hidden size: [364] trial: 4, train_loss: 0.505520, test loss: 1.289104, bias2: 0.5808285474777222, variance: 0.7082751989364624\n",
      "Train size: [400] hidden size: [364] trial: 5, train_loss: 0.499983, test loss: 1.292467, bias2: 0.5547059774398804, variance: 0.7377609014511108\n",
      "Train size: [400] hidden size: [364] trial: 6, train_loss: 0.517999, test loss: 1.290081, bias2: 0.5319844484329224, variance: 0.7580965757369995\n",
      "Train size: [400] hidden size: [364] trial: 7, train_loss: 0.521004, test loss: 1.295712, bias2: 0.5270209908485413, variance: 0.7686914801597595\n",
      "Train size: [400] hidden size: [364] trial: 8, train_loss: 0.533068, test loss: 1.305559, bias2: 0.5166825652122498, variance: 0.788876473903656\n",
      "Train size: [400] hidden size: [364] trial: 9, train_loss: 0.529682, test loss: 1.319449, bias2: 0.5139752626419067, variance: 0.805473804473877\n",
      "Train size: [400] hidden size: [364] trial: 10, train_loss: 0.525238, test loss: 1.321549, bias2: 0.5114445686340332, variance: 0.810104489326477\n",
      "Train size: [400] hidden size: [364] trial: 11, train_loss: 0.529072, test loss: 1.318423, bias2: 0.5041489005088806, variance: 0.8142741322517395\n",
      "Train size: [400] hidden size: [364] trial: 12, train_loss: 0.526756, test loss: 1.319330, bias2: 0.4984942078590393, variance: 0.8208360075950623\n",
      "Train size: [400] hidden size: [364] trial: 13, train_loss: 0.519969, test loss: 1.311516, bias2: 0.4898897409439087, variance: 0.8216266632080078\n",
      "Train size: [400] hidden size: [364] trial: 14, train_loss: 0.524668, test loss: 1.318902, bias2: 0.4846060872077942, variance: 0.8342954516410828\n",
      "Train size: [400] hidden size: [364] trial: 15, train_loss: 0.524742, test loss: 1.321196, bias2: 0.4811755418777466, variance: 0.8400200605392456\n",
      "Train size: [400] hidden size: [364] trial: 16, train_loss: 0.525603, test loss: 1.321432, bias2: 0.48154157400131226, variance: 0.8398907780647278\n",
      "Train size: [400] hidden size: [364] trial: 17, train_loss: 0.523904, test loss: 1.323646, bias2: 0.47791045904159546, variance: 0.8457357287406921\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [364] trial: 18, train_loss: 0.522419, test loss: 1.324242, bias2: 0.4757152199745178, variance: 0.8485265374183655\n",
      "Train size: [400] hidden size: [364] trial: 19, train_loss: 0.520560, test loss: 1.320931, bias2: 0.47721409797668457, variance: 0.8437172174453735\n",
      "Train size: [400] hidden size: [364] trial: 20, train_loss: 0.518724, test loss: 1.321330, bias2: 0.47590208053588867, variance: 0.8454279899597168\n",
      "Train size: [400] hidden size: [364] trial: 21, train_loss: 0.519017, test loss: 1.321026, bias2: 0.47779399156570435, variance: 0.8432318568229675\n",
      "Train size: [400] hidden size: [364] trial: 22, train_loss: 0.518447, test loss: 1.318253, bias2: 0.47467517852783203, variance: 0.8435782194137573\n",
      "Train size: [400] hidden size: [364] trial: 23, train_loss: 0.521799, test loss: 1.317934, bias2: 0.4701622724533081, variance: 0.8477715253829956\n",
      "Train size: [400] hidden size: [364] trial: 24, train_loss: 0.523989, test loss: 1.323357, bias2: 0.47078216075897217, variance: 0.8525747060775757\n",
      "Train size: [400] hidden size: [364] trial: 25, train_loss: 0.524766, test loss: 1.320384, bias2: 0.46441835165023804, variance: 0.8559659123420715\n",
      "Train size: [400] hidden size: [364] trial: 26, train_loss: 0.526622, test loss: 1.324540, bias2: 0.46684277057647705, variance: 0.8576968908309937\n",
      "Train size: [400] hidden size: [364] trial: 27, train_loss: 0.527990, test loss: 1.327282, bias2: 0.466924250125885, variance: 0.8603577017784119\n",
      "Train size: [400] hidden size: [364] trial: 28, train_loss: 0.524469, test loss: 1.324099, bias2: 0.46269261837005615, variance: 0.8614062070846558\n",
      "Train size: [400] hidden size: [364] trial: 29, train_loss: 0.525323, test loss: 1.329420, bias2: 0.4628314971923828, variance: 0.8665889501571655\n",
      "Train size: [400] hidden size: [364] trial: 30, train_loss: 0.527162, test loss: 1.326651, bias2: 0.45987391471862793, variance: 0.8667773008346558\n",
      "Train size: [400] hidden size: [364] trial: 31, train_loss: 0.526090, test loss: 1.326310, bias2: 0.4589788317680359, variance: 0.8673314452171326\n",
      "Train size: [400] hidden size: [364] trial: 32, train_loss: 0.524349, test loss: 1.326441, bias2: 0.46031248569488525, variance: 0.8661280870437622\n",
      "Train size: [400] hidden size: [364] trial: 33, train_loss: 0.524498, test loss: 1.323931, bias2: 0.46195244789123535, variance: 0.8619787693023682\n",
      "Train size: [400] hidden size: [364] trial: 34, train_loss: 0.525157, test loss: 1.326882, bias2: 0.45985740423202515, variance: 0.8670249581336975\n",
      "Train size: [400] hidden size: [364] trial: 35, train_loss: 0.526408, test loss: 1.327529, bias2: 0.4594157338142395, variance: 0.8681129813194275\n",
      "Train size: [400] hidden size: [364] trial: 36, train_loss: 0.527350, test loss: 1.326432, bias2: 0.4585142135620117, variance: 0.8679178953170776\n",
      "Train size: [400] hidden size: [364] trial: 37, train_loss: 0.529829, test loss: 1.324721, bias2: 0.4544541835784912, variance: 0.8702670335769653\n",
      "Train size: [400] hidden size: [364] trial: 38, train_loss: 0.530566, test loss: 1.324060, bias2: 0.452289342880249, variance: 0.8717707395553589\n",
      "Train size: [400] hidden size: [364] trial: 39, train_loss: 0.530627, test loss: 1.323163, bias2: 0.452484667301178, variance: 0.8706788420677185\n",
      "Train size: [400] hidden size: [364] trial: 40, train_loss: 0.533149, test loss: 1.321998, bias2: 0.4495049715042114, variance: 0.872492790222168\n",
      "Train size: [400] hidden size: [364] trial: 41, train_loss: 0.533945, test loss: 1.323258, bias2: 0.45062685012817383, variance: 0.8726315498352051\n",
      "Train size: [400] hidden size: [364] trial: 42, train_loss: 0.534472, test loss: 1.322850, bias2: 0.4509071111679077, variance: 0.8719426393508911\n",
      "Train size: [400] hidden size: [364] trial: 43, train_loss: 0.535052, test loss: 1.325942, bias2: 0.45144200325012207, variance: 0.8744999170303345\n",
      "Train size: [400] hidden size: [364] trial: 44, train_loss: 0.533822, test loss: 1.325002, bias2: 0.45111507177352905, variance: 0.8738871216773987\n",
      "Train size: [400] hidden size: [364] trial: 45, train_loss: 0.532449, test loss: 1.321343, bias2: 0.448947548866272, variance: 0.872395396232605\n",
      "Train size: [400] hidden size: [364] trial: 46, train_loss: 0.531334, test loss: 1.323654, bias2: 0.45181381702423096, variance: 0.8718407154083252\n",
      "Train size: [400] hidden size: [364] trial: 47, train_loss: 0.531056, test loss: 1.323436, bias2: 0.45205068588256836, variance: 0.8713855743408203\n",
      "Train size: [400] hidden size: [364] trial: 48, train_loss: 0.531017, test loss: 1.320946, bias2: 0.4504033327102661, variance: 0.8705428838729858\n",
      "Train size: [400] hidden size: [364] trial: 49, train_loss: 0.530317, test loss: 1.321019, bias2: 0.4486313462257385, variance: 0.8723872303962708\n",
      "##################################################\n",
      "Train size: [400] hidden size: [419] trial: 0, train_loss: 0.450863, test loss: 1.328144, bias2: 1.3281437158584595, variance: 2.3355288814030928e-09\n",
      "Train size: [400] hidden size: [419] trial: 1, train_loss: 0.454216, test loss: 1.288040, bias2: 0.8122549653053284, variance: 0.4757848381996155\n",
      "Train size: [400] hidden size: [419] trial: 2, train_loss: 0.451311, test loss: 1.261894, bias2: 0.659346342086792, variance: 0.6025477647781372\n",
      "Train size: [400] hidden size: [419] trial: 3, train_loss: 0.445062, test loss: 1.255316, bias2: 0.5967177152633667, variance: 0.6585979461669922\n",
      "Train size: [400] hidden size: [419] trial: 4, train_loss: 0.453526, test loss: 1.286408, bias2: 0.5738825798034668, variance: 0.712525486946106\n",
      "Train size: [400] hidden size: [419] trial: 5, train_loss: 0.446318, test loss: 1.270958, bias2: 0.5504432320594788, variance: 0.720514714717865\n",
      "Train size: [400] hidden size: [419] trial: 6, train_loss: 0.447244, test loss: 1.268424, bias2: 0.5293196439743042, variance: 0.7391039133071899\n",
      "Train size: [400] hidden size: [419] trial: 7, train_loss: 0.457013, test loss: 1.275422, bias2: 0.5195721387863159, variance: 0.7558498382568359\n",
      "Train size: [400] hidden size: [419] trial: 8, train_loss: 0.456895, test loss: 1.257921, bias2: 0.5008462071418762, variance: 0.7570751309394836\n",
      "Train size: [400] hidden size: [419] trial: 9, train_loss: 0.445818, test loss: 1.241135, bias2: 0.4847893714904785, variance: 0.7563461065292358\n",
      "Train size: [400] hidden size: [419] trial: 10, train_loss: 0.447902, test loss: 1.252459, bias2: 0.47791439294815063, variance: 0.7745446562767029\n",
      "Train size: [400] hidden size: [419] trial: 11, train_loss: 0.449243, test loss: 1.256947, bias2: 0.4735803008079529, variance: 0.783366858959198\n",
      "Train size: [400] hidden size: [419] trial: 12, train_loss: 0.448548, test loss: 1.249202, bias2: 0.4606900215148926, variance: 0.7885117530822754\n",
      "Train size: [400] hidden size: [419] trial: 13, train_loss: 0.449541, test loss: 1.254910, bias2: 0.4586191177368164, variance: 0.7962911128997803\n",
      "Train size: [400] hidden size: [419] trial: 14, train_loss: 0.453191, test loss: 1.254494, bias2: 0.45370835065841675, variance: 0.8007860779762268\n",
      "Train size: [400] hidden size: [419] trial: 15, train_loss: 0.452734, test loss: 1.256798, bias2: 0.453630268573761, variance: 0.8031681180000305\n",
      "Train size: [400] hidden size: [419] trial: 16, train_loss: 0.452156, test loss: 1.255689, bias2: 0.4529569745063782, variance: 0.8027321696281433\n",
      "Train size: [400] hidden size: [419] trial: 17, train_loss: 0.451157, test loss: 1.254762, bias2: 0.4542001485824585, variance: 0.8005620241165161\n",
      "Train size: [400] hidden size: [419] trial: 18, train_loss: 0.453686, test loss: 1.253569, bias2: 0.4491901397705078, variance: 0.8043787479400635\n",
      "Train size: [400] hidden size: [419] trial: 19, train_loss: 0.455734, test loss: 1.251574, bias2: 0.44651567935943604, variance: 0.8050585985183716\n",
      "Train size: [400] hidden size: [419] trial: 20, train_loss: 0.455142, test loss: 1.248363, bias2: 0.4437042474746704, variance: 0.8046585321426392\n",
      "Train size: [400] hidden size: [419] trial: 21, train_loss: 0.450718, test loss: 1.243525, bias2: 0.44096869230270386, variance: 0.8025566935539246\n",
      "Train size: [400] hidden size: [419] trial: 22, train_loss: 0.447780, test loss: 1.238467, bias2: 0.43548059463500977, variance: 0.8029863834381104\n",
      "Train size: [400] hidden size: [419] trial: 23, train_loss: 0.449065, test loss: 1.238804, bias2: 0.43208855390548706, variance: 0.8067154288291931\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [419] trial: 24, train_loss: 0.447175, test loss: 1.238413, bias2: 0.4313451051712036, variance: 0.8070676326751709\n",
      "Train size: [400] hidden size: [419] trial: 25, train_loss: 0.448903, test loss: 1.238625, bias2: 0.43050307035446167, variance: 0.8081217408180237\n",
      "Train size: [400] hidden size: [419] trial: 26, train_loss: 0.450122, test loss: 1.242286, bias2: 0.4337993860244751, variance: 0.808487057685852\n",
      "Train size: [400] hidden size: [419] trial: 27, train_loss: 0.450391, test loss: 1.237423, bias2: 0.4320579171180725, variance: 0.8053645491600037\n",
      "Train size: [400] hidden size: [419] trial: 28, train_loss: 0.452762, test loss: 1.238556, bias2: 0.43093574047088623, variance: 0.8076198101043701\n",
      "Train size: [400] hidden size: [419] trial: 29, train_loss: 0.452448, test loss: 1.235193, bias2: 0.42869096994400024, variance: 0.8065020442008972\n",
      "Train size: [400] hidden size: [419] trial: 30, train_loss: 0.451003, test loss: 1.233996, bias2: 0.428851842880249, variance: 0.8051439523696899\n",
      "Train size: [400] hidden size: [419] trial: 31, train_loss: 0.448548, test loss: 1.233216, bias2: 0.4268608093261719, variance: 0.8063549995422363\n",
      "Train size: [400] hidden size: [419] trial: 32, train_loss: 0.452841, test loss: 1.234770, bias2: 0.4280667304992676, variance: 0.8067035675048828\n",
      "Train size: [400] hidden size: [419] trial: 33, train_loss: 0.452797, test loss: 1.235911, bias2: 0.42816829681396484, variance: 0.8077428340911865\n",
      "Train size: [400] hidden size: [419] trial: 34, train_loss: 0.450610, test loss: 1.235855, bias2: 0.4285910129547119, variance: 0.8072642087936401\n",
      "Train size: [400] hidden size: [419] trial: 35, train_loss: 0.450856, test loss: 1.236642, bias2: 0.4295792579650879, variance: 0.8070623874664307\n",
      "Train size: [400] hidden size: [419] trial: 36, train_loss: 0.454064, test loss: 1.235435, bias2: 0.42829185724258423, variance: 0.8071433901786804\n",
      "Train size: [400] hidden size: [419] trial: 37, train_loss: 0.455886, test loss: 1.235292, bias2: 0.4246408939361572, variance: 0.8106511831283569\n",
      "Train size: [400] hidden size: [419] trial: 38, train_loss: 0.455296, test loss: 1.230274, bias2: 0.4237797260284424, variance: 0.8064947128295898\n",
      "Train size: [400] hidden size: [419] trial: 39, train_loss: 0.454416, test loss: 1.227889, bias2: 0.4239059090614319, variance: 0.8039827942848206\n",
      "Train size: [400] hidden size: [419] trial: 40, train_loss: 0.454365, test loss: 1.231013, bias2: 0.42493510246276855, variance: 0.8060781955718994\n",
      "Train size: [400] hidden size: [419] trial: 41, train_loss: 0.456883, test loss: 1.231034, bias2: 0.42286545038223267, variance: 0.8081688284873962\n",
      "Train size: [400] hidden size: [419] trial: 42, train_loss: 0.457457, test loss: 1.230820, bias2: 0.4206545352935791, variance: 0.8101658821105957\n",
      "Train size: [400] hidden size: [419] trial: 43, train_loss: 0.458248, test loss: 1.230701, bias2: 0.42002880573272705, variance: 0.810672402381897\n",
      "Train size: [400] hidden size: [419] trial: 44, train_loss: 0.457326, test loss: 1.231716, bias2: 0.4217938184738159, variance: 0.8099220991134644\n",
      "Train size: [400] hidden size: [419] trial: 45, train_loss: 0.457080, test loss: 1.234045, bias2: 0.42223721742630005, variance: 0.8118078112602234\n",
      "Train size: [400] hidden size: [419] trial: 46, train_loss: 0.455898, test loss: 1.235738, bias2: 0.42432713508605957, variance: 0.811410665512085\n",
      "Train size: [400] hidden size: [419] trial: 47, train_loss: 0.455678, test loss: 1.235573, bias2: 0.4228631854057312, variance: 0.8127101063728333\n",
      "Train size: [400] hidden size: [419] trial: 48, train_loss: 0.456296, test loss: 1.235925, bias2: 0.42154496908187866, variance: 0.8143801093101501\n",
      "Train size: [400] hidden size: [419] trial: 49, train_loss: 0.456196, test loss: 1.236682, bias2: 0.42047035694122314, variance: 0.816211462020874\n",
      "##################################################\n",
      "Train size: [400] hidden size: [483] trial: 0, train_loss: 0.394601, test loss: 1.404875, bias2: 1.4048751592636108, variance: 7.0065864221646734e-09\n",
      "Train size: [400] hidden size: [483] trial: 1, train_loss: 0.424148, test loss: 1.216907, bias2: 0.7987212538719177, variance: 0.4181860089302063\n",
      "Train size: [400] hidden size: [483] trial: 2, train_loss: 0.425092, test loss: 1.224677, bias2: 0.6722280383110046, variance: 0.552448570728302\n",
      "Train size: [400] hidden size: [483] trial: 3, train_loss: 0.446283, test loss: 1.224429, bias2: 0.6068906188011169, variance: 0.6175383925437927\n",
      "Train size: [400] hidden size: [483] trial: 4, train_loss: 0.433722, test loss: 1.211714, bias2: 0.5545303225517273, variance: 0.6571837067604065\n",
      "Train size: [400] hidden size: [483] trial: 5, train_loss: 0.429786, test loss: 1.218526, bias2: 0.5245422124862671, variance: 0.6939836740493774\n",
      "Train size: [400] hidden size: [483] trial: 6, train_loss: 0.423091, test loss: 1.211180, bias2: 0.5069888234138489, variance: 0.7041907906532288\n",
      "Train size: [400] hidden size: [483] trial: 7, train_loss: 0.420982, test loss: 1.220796, bias2: 0.5105783343315125, variance: 0.7102174162864685\n",
      "Train size: [400] hidden size: [483] trial: 8, train_loss: 0.426201, test loss: 1.232453, bias2: 0.5107386708259583, variance: 0.7217145562171936\n",
      "Train size: [400] hidden size: [483] trial: 9, train_loss: 0.420888, test loss: 1.221199, bias2: 0.49387985467910767, variance: 0.727319061756134\n",
      "Train size: [400] hidden size: [483] trial: 10, train_loss: 0.420391, test loss: 1.217361, bias2: 0.48397403955459595, variance: 0.733387291431427\n",
      "Train size: [400] hidden size: [483] trial: 11, train_loss: 0.419204, test loss: 1.214332, bias2: 0.4745863080024719, variance: 0.7397459149360657\n",
      "Train size: [400] hidden size: [483] trial: 12, train_loss: 0.419874, test loss: 1.209483, bias2: 0.4678729772567749, variance: 0.7416099309921265\n",
      "Train size: [400] hidden size: [483] trial: 13, train_loss: 0.421508, test loss: 1.207840, bias2: 0.46176600456237793, variance: 0.7460737228393555\n",
      "Train size: [400] hidden size: [483] trial: 14, train_loss: 0.418429, test loss: 1.203534, bias2: 0.45264291763305664, variance: 0.7508910894393921\n",
      "Train size: [400] hidden size: [483] trial: 15, train_loss: 0.418938, test loss: 1.205199, bias2: 0.44723695516586304, variance: 0.757962167263031\n",
      "Train size: [400] hidden size: [483] trial: 16, train_loss: 0.417666, test loss: 1.208843, bias2: 0.4446108341217041, variance: 0.7642325162887573\n",
      "Train size: [400] hidden size: [483] trial: 17, train_loss: 0.418243, test loss: 1.206901, bias2: 0.4419704079627991, variance: 0.7649300694465637\n",
      "Train size: [400] hidden size: [483] trial: 18, train_loss: 0.415080, test loss: 1.201637, bias2: 0.441325843334198, variance: 0.760310709476471\n",
      "Train size: [400] hidden size: [483] trial: 19, train_loss: 0.417762, test loss: 1.202244, bias2: 0.4392586350440979, variance: 0.7629849314689636\n",
      "Train size: [400] hidden size: [483] trial: 20, train_loss: 0.416290, test loss: 1.204704, bias2: 0.43643760681152344, variance: 0.7682663202285767\n",
      "Train size: [400] hidden size: [483] trial: 21, train_loss: 0.414993, test loss: 1.211679, bias2: 0.4382551312446594, variance: 0.7734236121177673\n",
      "Train size: [400] hidden size: [483] trial: 22, train_loss: 0.416358, test loss: 1.208459, bias2: 0.43409669399261475, variance: 0.7743619680404663\n",
      "Train size: [400] hidden size: [483] trial: 23, train_loss: 0.417920, test loss: 1.203720, bias2: 0.4303288459777832, variance: 0.7733910083770752\n",
      "Train size: [400] hidden size: [483] trial: 24, train_loss: 0.415451, test loss: 1.198019, bias2: 0.4262304902076721, variance: 0.7717882990837097\n",
      "Train size: [400] hidden size: [483] trial: 25, train_loss: 0.414864, test loss: 1.199537, bias2: 0.42888087034225464, variance: 0.7706560492515564\n",
      "Train size: [400] hidden size: [483] trial: 26, train_loss: 0.416525, test loss: 1.202812, bias2: 0.4274584650993347, variance: 0.7753539681434631\n",
      "Train size: [400] hidden size: [483] trial: 27, train_loss: 0.417225, test loss: 1.201297, bias2: 0.4284345507621765, variance: 0.7728623747825623\n",
      "Train size: [400] hidden size: [483] trial: 28, train_loss: 0.416518, test loss: 1.200981, bias2: 0.42870432138442993, variance: 0.7722763419151306\n",
      "Train size: [400] hidden size: [483] trial: 29, train_loss: 0.415183, test loss: 1.201755, bias2: 0.4301944375038147, variance: 0.7715609669685364\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [483] trial: 30, train_loss: 0.414228, test loss: 1.198732, bias2: 0.42828208208084106, variance: 0.7704499363899231\n",
      "Train size: [400] hidden size: [483] trial: 31, train_loss: 0.414478, test loss: 1.199428, bias2: 0.42852920293807983, variance: 0.7708987593650818\n",
      "Train size: [400] hidden size: [483] trial: 32, train_loss: 0.415000, test loss: 1.199833, bias2: 0.4278165102005005, variance: 0.7720170021057129\n",
      "Train size: [400] hidden size: [483] trial: 33, train_loss: 0.414867, test loss: 1.197590, bias2: 0.4251387119293213, variance: 0.7724510431289673\n",
      "Train size: [400] hidden size: [483] trial: 34, train_loss: 0.414333, test loss: 1.196517, bias2: 0.42315590381622314, variance: 0.7733607292175293\n",
      "Train size: [400] hidden size: [483] trial: 35, train_loss: 0.413147, test loss: 1.197039, bias2: 0.42292970418930054, variance: 0.7741089463233948\n",
      "Train size: [400] hidden size: [483] trial: 36, train_loss: 0.412688, test loss: 1.194763, bias2: 0.4188724756240845, variance: 0.775890588760376\n",
      "Train size: [400] hidden size: [483] trial: 37, train_loss: 0.412317, test loss: 1.193322, bias2: 0.419303834438324, variance: 0.7740185856819153\n",
      "Train size: [400] hidden size: [483] trial: 38, train_loss: 0.412288, test loss: 1.190562, bias2: 0.4185982346534729, variance: 0.7719637751579285\n",
      "Train size: [400] hidden size: [483] trial: 39, train_loss: 0.413077, test loss: 1.190059, bias2: 0.4164745807647705, variance: 0.7735844850540161\n",
      "Train size: [400] hidden size: [483] trial: 40, train_loss: 0.413155, test loss: 1.187880, bias2: 0.41629523038864136, variance: 0.7715849280357361\n",
      "Train size: [400] hidden size: [483] trial: 41, train_loss: 0.414120, test loss: 1.184017, bias2: 0.41404128074645996, variance: 0.7699754238128662\n",
      "Train size: [400] hidden size: [483] trial: 42, train_loss: 0.413416, test loss: 1.183609, bias2: 0.41276901960372925, variance: 0.7708399891853333\n",
      "Train size: [400] hidden size: [483] trial: 43, train_loss: 0.411918, test loss: 1.183460, bias2: 0.4127989411354065, variance: 0.7706606984138489\n",
      "Train size: [400] hidden size: [483] trial: 44, train_loss: 0.413104, test loss: 1.182299, bias2: 0.4101734757423401, variance: 0.772125780582428\n",
      "Train size: [400] hidden size: [483] trial: 45, train_loss: 0.413034, test loss: 1.183008, bias2: 0.4083271622657776, variance: 0.7746806740760803\n",
      "Train size: [400] hidden size: [483] trial: 46, train_loss: 0.412518, test loss: 1.181338, bias2: 0.40968579053878784, variance: 0.7716525197029114\n",
      "Train size: [400] hidden size: [483] trial: 47, train_loss: 0.413559, test loss: 1.181061, bias2: 0.4090820550918579, variance: 0.7719787359237671\n",
      "Train size: [400] hidden size: [483] trial: 48, train_loss: 0.413381, test loss: 1.178330, bias2: 0.40757715702056885, variance: 0.770753026008606\n",
      "Train size: [400] hidden size: [483] trial: 49, train_loss: 0.413748, test loss: 1.178462, bias2: 0.40768516063690186, variance: 0.7707767486572266\n",
      "##################################################\n",
      "Train size: [400] hidden size: [556] trial: 0, train_loss: 0.320439, test loss: 1.132752, bias2: 1.132751703262329, variance: 5.060312613380802e-09\n",
      "Train size: [400] hidden size: [556] trial: 1, train_loss: 0.326945, test loss: 1.116047, bias2: 0.7909709215164185, variance: 0.32507583498954773\n",
      "Train size: [400] hidden size: [556] trial: 2, train_loss: 0.315069, test loss: 1.105112, bias2: 0.6725151538848877, variance: 0.43259695172309875\n",
      "Train size: [400] hidden size: [556] trial: 3, train_loss: 0.318371, test loss: 1.101013, bias2: 0.6055128574371338, variance: 0.49550020694732666\n",
      "Train size: [400] hidden size: [556] trial: 4, train_loss: 0.333174, test loss: 1.097770, bias2: 0.5440641641616821, variance: 0.5537056922912598\n",
      "Train size: [400] hidden size: [556] trial: 5, train_loss: 0.336760, test loss: 1.098737, bias2: 0.523236095905304, variance: 0.5755007863044739\n",
      "Train size: [400] hidden size: [556] trial: 6, train_loss: 0.340812, test loss: 1.103324, bias2: 0.5131151676177979, variance: 0.5902091264724731\n",
      "Train size: [400] hidden size: [556] trial: 7, train_loss: 0.342346, test loss: 1.099493, bias2: 0.5014132261276245, variance: 0.5980801582336426\n",
      "Train size: [400] hidden size: [556] trial: 8, train_loss: 0.344537, test loss: 1.102101, bias2: 0.4860023856163025, variance: 0.6160982251167297\n",
      "Train size: [400] hidden size: [556] trial: 9, train_loss: 0.345662, test loss: 1.115202, bias2: 0.4817626476287842, variance: 0.6334395408630371\n",
      "Train size: [400] hidden size: [556] trial: 10, train_loss: 0.343652, test loss: 1.099978, bias2: 0.47167372703552246, variance: 0.6283046007156372\n",
      "Train size: [400] hidden size: [556] trial: 11, train_loss: 0.347246, test loss: 1.103521, bias2: 0.464424729347229, variance: 0.639096736907959\n",
      "Train size: [400] hidden size: [556] trial: 12, train_loss: 0.355401, test loss: 1.103177, bias2: 0.4562925696372986, variance: 0.6468847393989563\n",
      "Train size: [400] hidden size: [556] trial: 13, train_loss: 0.355449, test loss: 1.100154, bias2: 0.4475017786026001, variance: 0.6526527404785156\n",
      "Train size: [400] hidden size: [556] trial: 14, train_loss: 0.351561, test loss: 1.096767, bias2: 0.43710577487945557, variance: 0.6596609354019165\n",
      "Train size: [400] hidden size: [556] trial: 15, train_loss: 0.349439, test loss: 1.100015, bias2: 0.44355177879333496, variance: 0.656463623046875\n",
      "Train size: [400] hidden size: [556] trial: 16, train_loss: 0.347760, test loss: 1.096574, bias2: 0.43859249353408813, variance: 0.6579814553260803\n",
      "Train size: [400] hidden size: [556] trial: 17, train_loss: 0.346862, test loss: 1.098650, bias2: 0.43726491928100586, variance: 0.6613848209381104\n",
      "Train size: [400] hidden size: [556] trial: 18, train_loss: 0.348116, test loss: 1.099973, bias2: 0.4361588954925537, variance: 0.6638144254684448\n",
      "Train size: [400] hidden size: [556] trial: 19, train_loss: 0.346283, test loss: 1.105847, bias2: 0.436551570892334, variance: 0.6692953109741211\n",
      "Train size: [400] hidden size: [556] trial: 20, train_loss: 0.346509, test loss: 1.106722, bias2: 0.43492257595062256, variance: 0.6717997789382935\n",
      "Train size: [400] hidden size: [556] trial: 21, train_loss: 0.345350, test loss: 1.107033, bias2: 0.43199312686920166, variance: 0.6750400066375732\n",
      "Train size: [400] hidden size: [556] trial: 22, train_loss: 0.346524, test loss: 1.106316, bias2: 0.4295211434364319, variance: 0.6767951846122742\n",
      "Train size: [400] hidden size: [556] trial: 23, train_loss: 0.345972, test loss: 1.107220, bias2: 0.4285009503364563, variance: 0.6787191033363342\n",
      "Train size: [400] hidden size: [556] trial: 24, train_loss: 0.345139, test loss: 1.104349, bias2: 0.423750102519989, variance: 0.6805985569953918\n",
      "Train size: [400] hidden size: [556] trial: 25, train_loss: 0.344077, test loss: 1.104417, bias2: 0.4219704270362854, variance: 0.682446300983429\n",
      "Train size: [400] hidden size: [556] trial: 26, train_loss: 0.346808, test loss: 1.106061, bias2: 0.4201192259788513, variance: 0.6859416365623474\n",
      "Train size: [400] hidden size: [556] trial: 27, train_loss: 0.348476, test loss: 1.110017, bias2: 0.4217519760131836, variance: 0.6882646083831787\n",
      "Train size: [400] hidden size: [556] trial: 28, train_loss: 0.348139, test loss: 1.115589, bias2: 0.4225373864173889, variance: 0.6930513978004456\n",
      "Train size: [400] hidden size: [556] trial: 29, train_loss: 0.347839, test loss: 1.116045, bias2: 0.42165476083755493, variance: 0.6943902373313904\n",
      "Train size: [400] hidden size: [556] trial: 30, train_loss: 0.347136, test loss: 1.115778, bias2: 0.42096036672592163, variance: 0.6948173642158508\n",
      "Train size: [400] hidden size: [556] trial: 31, train_loss: 0.347896, test loss: 1.118175, bias2: 0.4210830330848694, variance: 0.6970924735069275\n",
      "Train size: [400] hidden size: [556] trial: 32, train_loss: 0.349221, test loss: 1.116579, bias2: 0.4198148846626282, variance: 0.6967639327049255\n",
      "Train size: [400] hidden size: [556] trial: 33, train_loss: 0.348753, test loss: 1.114537, bias2: 0.41818952560424805, variance: 0.6963479518890381\n",
      "Train size: [400] hidden size: [556] trial: 34, train_loss: 0.348356, test loss: 1.114316, bias2: 0.4159132242202759, variance: 0.6984025239944458\n",
      "Train size: [400] hidden size: [556] trial: 35, train_loss: 0.348284, test loss: 1.113882, bias2: 0.4148164987564087, variance: 0.6990659236907959\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [556] trial: 36, train_loss: 0.350339, test loss: 1.113602, bias2: 0.4113098382949829, variance: 0.7022920846939087\n",
      "Train size: [400] hidden size: [556] trial: 37, train_loss: 0.350506, test loss: 1.115541, bias2: 0.4090615510940552, variance: 0.7064799070358276\n",
      "Train size: [400] hidden size: [556] trial: 38, train_loss: 0.348440, test loss: 1.112117, bias2: 0.40783822536468506, variance: 0.7042785882949829\n",
      "Train size: [400] hidden size: [556] trial: 39, train_loss: 0.347218, test loss: 1.111455, bias2: 0.40790867805480957, variance: 0.7035466432571411\n",
      "Train size: [400] hidden size: [556] trial: 40, train_loss: 0.348427, test loss: 1.113199, bias2: 0.40586739778518677, variance: 0.7073318362236023\n",
      "Train size: [400] hidden size: [556] trial: 41, train_loss: 0.349069, test loss: 1.112922, bias2: 0.40562134981155396, variance: 0.7073009610176086\n",
      "Train size: [400] hidden size: [556] trial: 42, train_loss: 0.348444, test loss: 1.110395, bias2: 0.4026487469673157, variance: 0.7077460885047913\n",
      "Train size: [400] hidden size: [556] trial: 43, train_loss: 0.348801, test loss: 1.109347, bias2: 0.4005082845687866, variance: 0.7088391780853271\n",
      "Train size: [400] hidden size: [556] trial: 44, train_loss: 0.348890, test loss: 1.109473, bias2: 0.4004632234573364, variance: 0.7090096473693848\n",
      "Train size: [400] hidden size: [556] trial: 45, train_loss: 0.348908, test loss: 1.107669, bias2: 0.3989354968070984, variance: 0.7087331414222717\n",
      "Train size: [400] hidden size: [556] trial: 46, train_loss: 0.347642, test loss: 1.107168, bias2: 0.39858829975128174, variance: 0.7085798978805542\n",
      "Train size: [400] hidden size: [556] trial: 47, train_loss: 0.348313, test loss: 1.108465, bias2: 0.3975364565849304, variance: 0.7109288573265076\n",
      "Train size: [400] hidden size: [556] trial: 48, train_loss: 0.349515, test loss: 1.110097, bias2: 0.39943069219589233, variance: 0.7106662392616272\n",
      "Train size: [400] hidden size: [556] trial: 49, train_loss: 0.349212, test loss: 1.111224, bias2: 0.40008431673049927, variance: 0.7111397385597229\n",
      "##################################################\n",
      "Train size: [400] hidden size: [640] trial: 0, train_loss: 0.322011, test loss: 1.071732, bias2: 1.0717319250106812, variance: 8.174350973888522e-09\n",
      "Train size: [400] hidden size: [640] trial: 1, train_loss: 0.340655, test loss: 1.067543, bias2: 0.7207704782485962, variance: 0.346772164106369\n",
      "Train size: [400] hidden size: [640] trial: 2, train_loss: 0.326938, test loss: 1.027501, bias2: 0.5983710289001465, variance: 0.4291297197341919\n",
      "Train size: [400] hidden size: [640] trial: 3, train_loss: 0.320371, test loss: 1.017415, bias2: 0.5369728207588196, variance: 0.48044246435165405\n",
      "Train size: [400] hidden size: [640] trial: 4, train_loss: 0.325088, test loss: 1.025115, bias2: 0.5021533966064453, variance: 0.5229614973068237\n",
      "Train size: [400] hidden size: [640] trial: 5, train_loss: 0.329790, test loss: 1.044625, bias2: 0.48334193229675293, variance: 0.5612832307815552\n",
      "Train size: [400] hidden size: [640] trial: 6, train_loss: 0.327951, test loss: 1.043489, bias2: 0.4638534188270569, variance: 0.5796355605125427\n",
      "Train size: [400] hidden size: [640] trial: 7, train_loss: 0.326010, test loss: 1.049607, bias2: 0.4560685157775879, variance: 0.5935385227203369\n",
      "Train size: [400] hidden size: [640] trial: 8, train_loss: 0.331584, test loss: 1.052306, bias2: 0.4505225419998169, variance: 0.6017836332321167\n",
      "Train size: [400] hidden size: [640] trial: 9, train_loss: 0.331455, test loss: 1.054282, bias2: 0.4442756772041321, variance: 0.6100067496299744\n",
      "Train size: [400] hidden size: [640] trial: 10, train_loss: 0.333248, test loss: 1.061411, bias2: 0.43996429443359375, variance: 0.6214472055435181\n",
      "Train size: [400] hidden size: [640] trial: 11, train_loss: 0.335064, test loss: 1.064189, bias2: 0.4372541904449463, variance: 0.6269350051879883\n",
      "Train size: [400] hidden size: [640] trial: 12, train_loss: 0.332987, test loss: 1.063523, bias2: 0.4332433342933655, variance: 0.6302793622016907\n",
      "Train size: [400] hidden size: [640] trial: 13, train_loss: 0.330973, test loss: 1.067946, bias2: 0.43188363313674927, variance: 0.6360625624656677\n",
      "Train size: [400] hidden size: [640] trial: 14, train_loss: 0.330145, test loss: 1.065293, bias2: 0.4248514771461487, variance: 0.640441358089447\n",
      "Train size: [400] hidden size: [640] trial: 15, train_loss: 0.326346, test loss: 1.062172, bias2: 0.42234426736831665, variance: 0.63982754945755\n",
      "Train size: [400] hidden size: [640] trial: 16, train_loss: 0.324348, test loss: 1.063848, bias2: 0.41589123010635376, variance: 0.6479571461677551\n",
      "Train size: [400] hidden size: [640] trial: 17, train_loss: 0.321806, test loss: 1.062550, bias2: 0.41628217697143555, variance: 0.6462678909301758\n",
      "Train size: [400] hidden size: [640] trial: 18, train_loss: 0.321763, test loss: 1.057330, bias2: 0.40917325019836426, variance: 0.6481565237045288\n",
      "Train size: [400] hidden size: [640] trial: 19, train_loss: 0.319745, test loss: 1.055430, bias2: 0.409002423286438, variance: 0.6464271545410156\n",
      "Train size: [400] hidden size: [640] trial: 20, train_loss: 0.317557, test loss: 1.055533, bias2: 0.4053751826286316, variance: 0.6501573920249939\n",
      "Train size: [400] hidden size: [640] trial: 21, train_loss: 0.317384, test loss: 1.055605, bias2: 0.4058389663696289, variance: 0.6497659683227539\n",
      "Train size: [400] hidden size: [640] trial: 22, train_loss: 0.317090, test loss: 1.052445, bias2: 0.40250498056411743, variance: 0.6499398350715637\n",
      "Train size: [400] hidden size: [640] trial: 23, train_loss: 0.319803, test loss: 1.052021, bias2: 0.40324389934539795, variance: 0.6487776041030884\n",
      "Train size: [400] hidden size: [640] trial: 24, train_loss: 0.318336, test loss: 1.051411, bias2: 0.4009220004081726, variance: 0.6504886746406555\n",
      "Train size: [400] hidden size: [640] trial: 25, train_loss: 0.319127, test loss: 1.049926, bias2: 0.39976656436920166, variance: 0.6501597166061401\n",
      "Train size: [400] hidden size: [640] trial: 26, train_loss: 0.319645, test loss: 1.048915, bias2: 0.39707648754119873, variance: 0.6518388986587524\n",
      "Train size: [400] hidden size: [640] trial: 27, train_loss: 0.321497, test loss: 1.046343, bias2: 0.39488571882247925, variance: 0.6514577269554138\n",
      "Train size: [400] hidden size: [640] trial: 28, train_loss: 0.322395, test loss: 1.045018, bias2: 0.3929874897003174, variance: 0.6520304679870605\n",
      "Train size: [400] hidden size: [640] trial: 29, train_loss: 0.321900, test loss: 1.044925, bias2: 0.39097052812576294, variance: 0.6539545655250549\n",
      "Train size: [400] hidden size: [640] trial: 30, train_loss: 0.319874, test loss: 1.043521, bias2: 0.3903474807739258, variance: 0.6531736850738525\n",
      "Train size: [400] hidden size: [640] trial: 31, train_loss: 0.320292, test loss: 1.044730, bias2: 0.39003098011016846, variance: 0.6546993255615234\n",
      "Train size: [400] hidden size: [640] trial: 32, train_loss: 0.319517, test loss: 1.042567, bias2: 0.38800299167633057, variance: 0.6545644998550415\n",
      "Train size: [400] hidden size: [640] trial: 33, train_loss: 0.319171, test loss: 1.046660, bias2: 0.3894399404525757, variance: 0.657219648361206\n",
      "Train size: [400] hidden size: [640] trial: 34, train_loss: 0.320534, test loss: 1.045146, bias2: 0.3870154023170471, variance: 0.6581302285194397\n",
      "Train size: [400] hidden size: [640] trial: 35, train_loss: 0.320996, test loss: 1.045808, bias2: 0.3849417567253113, variance: 0.6608663201332092\n",
      "Train size: [400] hidden size: [640] trial: 36, train_loss: 0.321132, test loss: 1.048167, bias2: 0.3862016797065735, variance: 0.6619651913642883\n",
      "Train size: [400] hidden size: [640] trial: 37, train_loss: 0.320599, test loss: 1.048644, bias2: 0.3856126070022583, variance: 0.6630313396453857\n",
      "Train size: [400] hidden size: [640] trial: 38, train_loss: 0.320548, test loss: 1.052038, bias2: 0.38663607835769653, variance: 0.6654015183448792\n",
      "Train size: [400] hidden size: [640] trial: 39, train_loss: 0.320597, test loss: 1.052497, bias2: 0.38687652349472046, variance: 0.6656201481819153\n",
      "Train size: [400] hidden size: [640] trial: 40, train_loss: 0.321194, test loss: 1.052103, bias2: 0.3865709900856018, variance: 0.6655324101448059\n",
      "Train size: [400] hidden size: [640] trial: 41, train_loss: 0.321280, test loss: 1.050306, bias2: 0.38439303636550903, variance: 0.6659134030342102\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [640] trial: 42, train_loss: 0.321804, test loss: 1.051407, bias2: 0.3840486407279968, variance: 0.6673586964607239\n",
      "Train size: [400] hidden size: [640] trial: 43, train_loss: 0.320594, test loss: 1.053688, bias2: 0.38574081659317017, variance: 0.667946994304657\n",
      "Train size: [400] hidden size: [640] trial: 44, train_loss: 0.321333, test loss: 1.054028, bias2: 0.3846902847290039, variance: 0.6693381071090698\n",
      "Train size: [400] hidden size: [640] trial: 45, train_loss: 0.322220, test loss: 1.055548, bias2: 0.38439369201660156, variance: 0.6711547374725342\n",
      "Train size: [400] hidden size: [640] trial: 46, train_loss: 0.321809, test loss: 1.056235, bias2: 0.3848285675048828, variance: 0.6714062690734863\n",
      "Train size: [400] hidden size: [640] trial: 47, train_loss: 0.320933, test loss: 1.055610, bias2: 0.3830574154853821, variance: 0.6725530028343201\n",
      "Train size: [400] hidden size: [640] trial: 48, train_loss: 0.319855, test loss: 1.054715, bias2: 0.38345932960510254, variance: 0.6712555885314941\n",
      "Train size: [400] hidden size: [640] trial: 49, train_loss: 0.319943, test loss: 1.055487, bias2: 0.3830239772796631, variance: 0.6724629402160645\n",
      "##################################################\n",
      "Train size: [400] hidden size: [737] trial: 0, train_loss: 0.321573, test loss: 0.988252, bias2: 0.9882523417472839, variance: 3.1140383605077204e-09\n",
      "Train size: [400] hidden size: [737] trial: 1, train_loss: 0.301592, test loss: 1.010910, bias2: 0.7123931050300598, variance: 0.2985174059867859\n",
      "Train size: [400] hidden size: [737] trial: 2, train_loss: 0.312774, test loss: 1.011293, bias2: 0.6131078004837036, variance: 0.398185133934021\n",
      "Train size: [400] hidden size: [737] trial: 3, train_loss: 0.309920, test loss: 1.021000, bias2: 0.5619909763336182, variance: 0.45900893211364746\n",
      "Train size: [400] hidden size: [737] trial: 4, train_loss: 0.306697, test loss: 1.017479, bias2: 0.5174975395202637, variance: 0.499981552362442\n",
      "Train size: [400] hidden size: [737] trial: 5, train_loss: 0.297093, test loss: 1.025055, bias2: 0.4850553870201111, variance: 0.5399996638298035\n",
      "Train size: [400] hidden size: [737] trial: 6, train_loss: 0.296453, test loss: 1.009153, bias2: 0.45848870277404785, variance: 0.5506641864776611\n",
      "Train size: [400] hidden size: [737] trial: 7, train_loss: 0.297365, test loss: 1.019536, bias2: 0.45362353324890137, variance: 0.5659122467041016\n",
      "Train size: [400] hidden size: [737] trial: 8, train_loss: 0.297720, test loss: 1.017287, bias2: 0.4430634379386902, variance: 0.5742233395576477\n",
      "Train size: [400] hidden size: [737] trial: 9, train_loss: 0.297469, test loss: 1.015356, bias2: 0.4382972717285156, variance: 0.5770589113235474\n",
      "Train size: [400] hidden size: [737] trial: 10, train_loss: 0.297118, test loss: 1.020017, bias2: 0.4336228370666504, variance: 0.5863940715789795\n",
      "Train size: [400] hidden size: [737] trial: 11, train_loss: 0.296880, test loss: 1.014536, bias2: 0.42300862073898315, variance: 0.5915276408195496\n",
      "Train size: [400] hidden size: [737] trial: 12, train_loss: 0.294208, test loss: 1.011540, bias2: 0.4220004081726074, variance: 0.5895392894744873\n",
      "Train size: [400] hidden size: [737] trial: 13, train_loss: 0.294685, test loss: 1.006955, bias2: 0.41413038969039917, variance: 0.592824399471283\n",
      "Train size: [400] hidden size: [737] trial: 14, train_loss: 0.295375, test loss: 1.005976, bias2: 0.4156269431114197, variance: 0.5903493762016296\n",
      "Train size: [400] hidden size: [737] trial: 15, train_loss: 0.295310, test loss: 1.004703, bias2: 0.41382718086242676, variance: 0.5908756256103516\n",
      "Train size: [400] hidden size: [737] trial: 16, train_loss: 0.295621, test loss: 1.006496, bias2: 0.4142701029777527, variance: 0.5922262072563171\n",
      "Train size: [400] hidden size: [737] trial: 17, train_loss: 0.294296, test loss: 1.006014, bias2: 0.4121495485305786, variance: 0.5938643217086792\n",
      "Train size: [400] hidden size: [737] trial: 18, train_loss: 0.296136, test loss: 1.003155, bias2: 0.4070265293121338, variance: 0.5961287021636963\n",
      "Train size: [400] hidden size: [737] trial: 19, train_loss: 0.294108, test loss: 1.005041, bias2: 0.4070844054222107, variance: 0.5979565978050232\n",
      "Train size: [400] hidden size: [737] trial: 20, train_loss: 0.294704, test loss: 1.002771, bias2: 0.4041558504104614, variance: 0.5986151695251465\n",
      "Train size: [400] hidden size: [737] trial: 21, train_loss: 0.295434, test loss: 1.005212, bias2: 0.40388017892837524, variance: 0.6013317704200745\n",
      "Train size: [400] hidden size: [737] trial: 22, train_loss: 0.296334, test loss: 1.006393, bias2: 0.39836055040359497, variance: 0.608032763004303\n",
      "Train size: [400] hidden size: [737] trial: 23, train_loss: 0.295373, test loss: 1.007649, bias2: 0.399091899394989, variance: 0.6085576415061951\n",
      "Train size: [400] hidden size: [737] trial: 24, train_loss: 0.296465, test loss: 1.009747, bias2: 0.3984531760215759, variance: 0.6112938523292542\n",
      "Train size: [400] hidden size: [737] trial: 25, train_loss: 0.294334, test loss: 1.014115, bias2: 0.39882200956344604, variance: 0.6152928471565247\n",
      "Train size: [400] hidden size: [737] trial: 26, train_loss: 0.294998, test loss: 1.012834, bias2: 0.3963550925254822, variance: 0.6164788603782654\n",
      "Train size: [400] hidden size: [737] trial: 27, train_loss: 0.295466, test loss: 1.014024, bias2: 0.39425909519195557, variance: 0.6197651624679565\n",
      "Train size: [400] hidden size: [737] trial: 28, train_loss: 0.294970, test loss: 1.013578, bias2: 0.3943268656730652, variance: 0.619251549243927\n",
      "Train size: [400] hidden size: [737] trial: 29, train_loss: 0.294217, test loss: 1.011733, bias2: 0.39257287979125977, variance: 0.6191598176956177\n",
      "Train size: [400] hidden size: [737] trial: 30, train_loss: 0.293249, test loss: 1.012607, bias2: 0.39124786853790283, variance: 0.6213595867156982\n",
      "Train size: [400] hidden size: [737] trial: 31, train_loss: 0.292439, test loss: 1.009524, bias2: 0.3884066343307495, variance: 0.621117353439331\n",
      "Train size: [400] hidden size: [737] trial: 32, train_loss: 0.293096, test loss: 1.010235, bias2: 0.3881266117095947, variance: 0.6221086978912354\n",
      "Train size: [400] hidden size: [737] trial: 33, train_loss: 0.293006, test loss: 1.009562, bias2: 0.3872496485710144, variance: 0.6223123669624329\n",
      "Train size: [400] hidden size: [737] trial: 34, train_loss: 0.292618, test loss: 1.007197, bias2: 0.38607823848724365, variance: 0.6211189031600952\n",
      "Train size: [400] hidden size: [737] trial: 35, train_loss: 0.293671, test loss: 1.007877, bias2: 0.3860763907432556, variance: 0.6218007206916809\n",
      "Train size: [400] hidden size: [737] trial: 36, train_loss: 0.293094, test loss: 1.009328, bias2: 0.3871658444404602, variance: 0.6221622824668884\n",
      "Train size: [400] hidden size: [737] trial: 37, train_loss: 0.293041, test loss: 1.012527, bias2: 0.3906451463699341, variance: 0.6218823194503784\n",
      "Train size: [400] hidden size: [737] trial: 38, train_loss: 0.292615, test loss: 1.009442, bias2: 0.38847047090530396, variance: 0.620971143245697\n",
      "Train size: [400] hidden size: [737] trial: 39, train_loss: 0.292214, test loss: 1.008146, bias2: 0.3862040042877197, variance: 0.6219418048858643\n",
      "Train size: [400] hidden size: [737] trial: 40, train_loss: 0.291780, test loss: 1.007383, bias2: 0.3846147656440735, variance: 0.6227681040763855\n",
      "Train size: [400] hidden size: [737] trial: 41, train_loss: 0.291432, test loss: 1.009372, bias2: 0.3850439190864563, variance: 0.6243279576301575\n",
      "Train size: [400] hidden size: [737] trial: 42, train_loss: 0.291979, test loss: 1.008107, bias2: 0.3847035765647888, variance: 0.6234032511711121\n",
      "Train size: [400] hidden size: [737] trial: 43, train_loss: 0.292098, test loss: 1.006277, bias2: 0.383419930934906, variance: 0.6228569149971008\n",
      "Train size: [400] hidden size: [737] trial: 44, train_loss: 0.291670, test loss: 1.005814, bias2: 0.38308268785476685, variance: 0.6227317452430725\n",
      "Train size: [400] hidden size: [737] trial: 45, train_loss: 0.291745, test loss: 1.007412, bias2: 0.383192241191864, variance: 0.6242198348045349\n",
      "Train size: [400] hidden size: [737] trial: 46, train_loss: 0.291712, test loss: 1.005240, bias2: 0.3816300630569458, variance: 0.6236096620559692\n",
      "Train size: [400] hidden size: [737] trial: 47, train_loss: 0.291929, test loss: 1.005454, bias2: 0.3805651068687439, variance: 0.6248885989189148\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [737] trial: 48, train_loss: 0.292672, test loss: 1.005354, bias2: 0.37945789098739624, variance: 0.625896155834198\n",
      "Train size: [400] hidden size: [737] trial: 49, train_loss: 0.293279, test loss: 1.004691, bias2: 0.37922215461730957, variance: 0.6254687309265137\n",
      "##################################################\n",
      "Train size: [400] hidden size: [848] trial: 0, train_loss: 0.232427, test loss: 0.937516, bias2: 0.9375160932540894, variance: 3.5032932110823367e-09\n",
      "Train size: [400] hidden size: [848] trial: 1, train_loss: 0.245556, test loss: 0.923757, bias2: 0.6318141222000122, variance: 0.2919425368309021\n",
      "Train size: [400] hidden size: [848] trial: 2, train_loss: 0.258588, test loss: 0.926405, bias2: 0.5315507650375366, variance: 0.39485403895378113\n",
      "Train size: [400] hidden size: [848] trial: 3, train_loss: 0.264707, test loss: 0.926824, bias2: 0.4906887710094452, variance: 0.43613556027412415\n",
      "Train size: [400] hidden size: [848] trial: 4, train_loss: 0.275543, test loss: 0.941512, bias2: 0.4695691168308258, variance: 0.4719424545764923\n",
      "Train size: [400] hidden size: [848] trial: 5, train_loss: 0.274490, test loss: 0.942180, bias2: 0.4481218755245209, variance: 0.49405786395072937\n",
      "Train size: [400] hidden size: [848] trial: 6, train_loss: 0.272425, test loss: 0.944975, bias2: 0.4327998757362366, variance: 0.5121750831604004\n",
      "Train size: [400] hidden size: [848] trial: 7, train_loss: 0.268897, test loss: 0.946860, bias2: 0.4328714609146118, variance: 0.5139883756637573\n",
      "Train size: [400] hidden size: [848] trial: 8, train_loss: 0.268042, test loss: 0.947532, bias2: 0.42666614055633545, variance: 0.5208654403686523\n",
      "Train size: [400] hidden size: [848] trial: 9, train_loss: 0.270440, test loss: 0.948539, bias2: 0.4178626537322998, variance: 0.5306768417358398\n",
      "Train size: [400] hidden size: [848] trial: 10, train_loss: 0.267385, test loss: 0.945680, bias2: 0.4151063561439514, variance: 0.5305734276771545\n",
      "Train size: [400] hidden size: [848] trial: 11, train_loss: 0.265044, test loss: 0.941833, bias2: 0.40893805027008057, variance: 0.5328949093818665\n",
      "Train size: [400] hidden size: [848] trial: 12, train_loss: 0.262729, test loss: 0.945206, bias2: 0.40733349323272705, variance: 0.5378729701042175\n",
      "Train size: [400] hidden size: [848] trial: 13, train_loss: 0.260482, test loss: 0.942131, bias2: 0.4077882766723633, variance: 0.5343426465988159\n",
      "Train size: [400] hidden size: [848] trial: 14, train_loss: 0.261730, test loss: 0.940219, bias2: 0.4012988209724426, variance: 0.5389196872711182\n",
      "Train size: [400] hidden size: [848] trial: 15, train_loss: 0.263248, test loss: 0.942499, bias2: 0.40156108140945435, variance: 0.5409379005432129\n",
      "Train size: [400] hidden size: [848] trial: 16, train_loss: 0.264276, test loss: 0.946120, bias2: 0.39905083179473877, variance: 0.5470694899559021\n",
      "Train size: [400] hidden size: [848] trial: 17, train_loss: 0.263403, test loss: 0.945349, bias2: 0.3953048586845398, variance: 0.5500440001487732\n",
      "Train size: [400] hidden size: [848] trial: 18, train_loss: 0.263217, test loss: 0.947594, bias2: 0.3963109850883484, variance: 0.5512834787368774\n",
      "Train size: [400] hidden size: [848] trial: 19, train_loss: 0.263029, test loss: 0.946452, bias2: 0.3917694687843323, variance: 0.5546827912330627\n",
      "Train size: [400] hidden size: [848] trial: 20, train_loss: 0.263537, test loss: 0.944777, bias2: 0.3871406316757202, variance: 0.5576364994049072\n",
      "Train size: [400] hidden size: [848] trial: 21, train_loss: 0.264096, test loss: 0.947976, bias2: 0.38581138849258423, variance: 0.5621644854545593\n",
      "Train size: [400] hidden size: [848] trial: 22, train_loss: 0.263448, test loss: 0.950314, bias2: 0.3844738006591797, variance: 0.5658398866653442\n",
      "Train size: [400] hidden size: [848] trial: 23, train_loss: 0.263589, test loss: 0.951722, bias2: 0.3839445114135742, variance: 0.5677775740623474\n",
      "Train size: [400] hidden size: [848] trial: 24, train_loss: 0.261380, test loss: 0.949699, bias2: 0.38435256481170654, variance: 0.5653467774391174\n",
      "Train size: [400] hidden size: [848] trial: 25, train_loss: 0.261730, test loss: 0.948545, bias2: 0.380959689617157, variance: 0.5675849914550781\n",
      "Train size: [400] hidden size: [848] trial: 26, train_loss: 0.261428, test loss: 0.948047, bias2: 0.38058537244796753, variance: 0.567461371421814\n",
      "Train size: [400] hidden size: [848] trial: 27, train_loss: 0.262166, test loss: 0.946015, bias2: 0.37765365839004517, variance: 0.568361759185791\n",
      "Train size: [400] hidden size: [848] trial: 28, train_loss: 0.262667, test loss: 0.945438, bias2: 0.3771361708641052, variance: 0.5683022737503052\n",
      "Train size: [400] hidden size: [848] trial: 29, train_loss: 0.264136, test loss: 0.949001, bias2: 0.3787427544593811, variance: 0.5702582001686096\n",
      "Train size: [400] hidden size: [848] trial: 30, train_loss: 0.265107, test loss: 0.950737, bias2: 0.37880152463912964, variance: 0.5719356536865234\n",
      "Train size: [400] hidden size: [848] trial: 31, train_loss: 0.264742, test loss: 0.951532, bias2: 0.37821364402770996, variance: 0.5733184814453125\n",
      "Train size: [400] hidden size: [848] trial: 32, train_loss: 0.264954, test loss: 0.948354, bias2: 0.3753308057785034, variance: 0.5730230808258057\n",
      "Train size: [400] hidden size: [848] trial: 33, train_loss: 0.264802, test loss: 0.948330, bias2: 0.3738671541213989, variance: 0.5744631290435791\n",
      "Train size: [400] hidden size: [848] trial: 34, train_loss: 0.265258, test loss: 0.948410, bias2: 0.372788667678833, variance: 0.5756209492683411\n",
      "Train size: [400] hidden size: [848] trial: 35, train_loss: 0.264520, test loss: 0.948645, bias2: 0.37405914068222046, variance: 0.5745854377746582\n",
      "Train size: [400] hidden size: [848] trial: 36, train_loss: 0.265340, test loss: 0.948324, bias2: 0.37268346548080444, variance: 0.5756405591964722\n",
      "Train size: [400] hidden size: [848] trial: 37, train_loss: 0.264551, test loss: 0.945618, bias2: 0.37063390016555786, variance: 0.5749844908714294\n",
      "Train size: [400] hidden size: [848] trial: 38, train_loss: 0.264432, test loss: 0.944635, bias2: 0.3699542284011841, variance: 0.5746808052062988\n",
      "Train size: [400] hidden size: [848] trial: 39, train_loss: 0.264583, test loss: 0.944910, bias2: 0.3699444532394409, variance: 0.5749652981758118\n",
      "Train size: [400] hidden size: [848] trial: 40, train_loss: 0.265363, test loss: 0.944311, bias2: 0.3694417476654053, variance: 0.5748693943023682\n",
      "Train size: [400] hidden size: [848] trial: 41, train_loss: 0.265413, test loss: 0.945321, bias2: 0.369428813457489, variance: 0.57589191198349\n",
      "Train size: [400] hidden size: [848] trial: 42, train_loss: 0.265003, test loss: 0.945410, bias2: 0.3711944818496704, variance: 0.5742154121398926\n",
      "Train size: [400] hidden size: [848] trial: 43, train_loss: 0.265728, test loss: 0.946649, bias2: 0.37219852209091187, variance: 0.5744500160217285\n",
      "Train size: [400] hidden size: [848] trial: 44, train_loss: 0.265608, test loss: 0.947217, bias2: 0.3730594515800476, variance: 0.5741575956344604\n",
      "Train size: [400] hidden size: [848] trial: 45, train_loss: 0.266158, test loss: 0.946580, bias2: 0.37217241525650024, variance: 0.5744076371192932\n",
      "Train size: [400] hidden size: [848] trial: 46, train_loss: 0.265942, test loss: 0.946454, bias2: 0.3724817633628845, variance: 0.573972225189209\n",
      "Train size: [400] hidden size: [848] trial: 47, train_loss: 0.265978, test loss: 0.946598, bias2: 0.37063735723495483, variance: 0.5759602189064026\n",
      "Train size: [400] hidden size: [848] trial: 48, train_loss: 0.265563, test loss: 0.944610, bias2: 0.3696008324623108, variance: 0.575009286403656\n",
      "Train size: [400] hidden size: [848] trial: 49, train_loss: 0.266145, test loss: 0.944681, bias2: 0.3683122396469116, variance: 0.5763691663742065\n",
      "##################################################\n",
      "Train size: [400] hidden size: [977] trial: 0, train_loss: 0.243649, test loss: 0.884058, bias2: 0.8840577602386475, variance: 1.5180937396053196e-08\n",
      "Train size: [400] hidden size: [977] trial: 1, train_loss: 0.238205, test loss: 0.895343, bias2: 0.6337038278579712, variance: 0.26163965463638306\n",
      "Train size: [400] hidden size: [977] trial: 2, train_loss: 0.239510, test loss: 0.930080, bias2: 0.5539031624794006, variance: 0.37617647647857666\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [977] trial: 3, train_loss: 0.243698, test loss: 0.930776, bias2: 0.5074639916419983, variance: 0.4233121871948242\n",
      "Train size: [400] hidden size: [977] trial: 4, train_loss: 0.234165, test loss: 0.923813, bias2: 0.47791945934295654, variance: 0.44589340686798096\n",
      "Train size: [400] hidden size: [977] trial: 5, train_loss: 0.237839, test loss: 0.911514, bias2: 0.45220792293548584, variance: 0.4593057632446289\n",
      "Train size: [400] hidden size: [977] trial: 6, train_loss: 0.243524, test loss: 0.921111, bias2: 0.4479365050792694, variance: 0.47317472100257874\n",
      "Train size: [400] hidden size: [977] trial: 7, train_loss: 0.248782, test loss: 0.910746, bias2: 0.4277789890766144, variance: 0.48296669125556946\n",
      "Train size: [400] hidden size: [977] trial: 8, train_loss: 0.246479, test loss: 0.906717, bias2: 0.4181915521621704, variance: 0.4885255694389343\n",
      "Train size: [400] hidden size: [977] trial: 9, train_loss: 0.247520, test loss: 0.905060, bias2: 0.4132869839668274, variance: 0.49177342653274536\n",
      "Train size: [400] hidden size: [977] trial: 10, train_loss: 0.250048, test loss: 0.904591, bias2: 0.4076708257198334, variance: 0.49692007899284363\n",
      "Train size: [400] hidden size: [977] trial: 11, train_loss: 0.251989, test loss: 0.906280, bias2: 0.4060991406440735, variance: 0.5001808404922485\n",
      "Train size: [400] hidden size: [977] trial: 12, train_loss: 0.254312, test loss: 0.905292, bias2: 0.4005976915359497, variance: 0.5046945810317993\n",
      "Train size: [400] hidden size: [977] trial: 13, train_loss: 0.252208, test loss: 0.902338, bias2: 0.39618563652038574, variance: 0.5061520338058472\n",
      "Train size: [400] hidden size: [977] trial: 14, train_loss: 0.251085, test loss: 0.900128, bias2: 0.39260542392730713, variance: 0.5075228214263916\n",
      "Train size: [400] hidden size: [977] trial: 15, train_loss: 0.250115, test loss: 0.902110, bias2: 0.39208030700683594, variance: 0.5100297331809998\n",
      "Train size: [400] hidden size: [977] trial: 16, train_loss: 0.249857, test loss: 0.907941, bias2: 0.3917731046676636, variance: 0.5161680579185486\n",
      "Train size: [400] hidden size: [977] trial: 17, train_loss: 0.250923, test loss: 0.910131, bias2: 0.38949334621429443, variance: 0.5206373333930969\n",
      "Train size: [400] hidden size: [977] trial: 18, train_loss: 0.249941, test loss: 0.911160, bias2: 0.38662290573120117, variance: 0.5245375037193298\n",
      "Train size: [400] hidden size: [977] trial: 19, train_loss: 0.248823, test loss: 0.911345, bias2: 0.38813966512680054, variance: 0.5232049226760864\n",
      "Train size: [400] hidden size: [977] trial: 20, train_loss: 0.251523, test loss: 0.910226, bias2: 0.38640111684799194, variance: 0.52382493019104\n",
      "Train size: [400] hidden size: [977] trial: 21, train_loss: 0.251738, test loss: 0.913139, bias2: 0.38839244842529297, variance: 0.524746835231781\n",
      "Train size: [400] hidden size: [977] trial: 22, train_loss: 0.251470, test loss: 0.910150, bias2: 0.3821631669998169, variance: 0.5279869437217712\n",
      "Train size: [400] hidden size: [977] trial: 23, train_loss: 0.252640, test loss: 0.908035, bias2: 0.3783629536628723, variance: 0.5296717882156372\n",
      "Train size: [400] hidden size: [977] trial: 24, train_loss: 0.252745, test loss: 0.906917, bias2: 0.37730324268341064, variance: 0.5296134948730469\n",
      "Train size: [400] hidden size: [977] trial: 25, train_loss: 0.253896, test loss: 0.909229, bias2: 0.37642836570739746, variance: 0.5328006148338318\n",
      "Train size: [400] hidden size: [977] trial: 26, train_loss: 0.253814, test loss: 0.909633, bias2: 0.37581729888916016, variance: 0.5338156223297119\n",
      "Train size: [400] hidden size: [977] trial: 27, train_loss: 0.254230, test loss: 0.911615, bias2: 0.3763720393180847, variance: 0.5352429747581482\n",
      "Train size: [400] hidden size: [977] trial: 28, train_loss: 0.254338, test loss: 0.913604, bias2: 0.3759379982948303, variance: 0.5376662611961365\n",
      "Train size: [400] hidden size: [977] trial: 29, train_loss: 0.254422, test loss: 0.914454, bias2: 0.37537795305252075, variance: 0.5390765070915222\n",
      "Train size: [400] hidden size: [977] trial: 30, train_loss: 0.253696, test loss: 0.914084, bias2: 0.373663067817688, variance: 0.540420651435852\n",
      "Train size: [400] hidden size: [977] trial: 31, train_loss: 0.252582, test loss: 0.913515, bias2: 0.3726727366447449, variance: 0.5408426523208618\n",
      "Train size: [400] hidden size: [977] trial: 32, train_loss: 0.252689, test loss: 0.914353, bias2: 0.3748820424079895, variance: 0.5394706130027771\n",
      "Train size: [400] hidden size: [977] trial: 33, train_loss: 0.252259, test loss: 0.915894, bias2: 0.375155508518219, variance: 0.5407385230064392\n",
      "Train size: [400] hidden size: [977] trial: 34, train_loss: 0.251277, test loss: 0.916035, bias2: 0.3750544786453247, variance: 0.5409807562828064\n",
      "Train size: [400] hidden size: [977] trial: 35, train_loss: 0.251390, test loss: 0.916327, bias2: 0.3741304874420166, variance: 0.5421966910362244\n",
      "Train size: [400] hidden size: [977] trial: 36, train_loss: 0.251085, test loss: 0.916361, bias2: 0.37408387660980225, variance: 0.5422773361206055\n",
      "Train size: [400] hidden size: [977] trial: 37, train_loss: 0.251582, test loss: 0.915415, bias2: 0.3728402256965637, variance: 0.542574942111969\n",
      "Train size: [400] hidden size: [977] trial: 38, train_loss: 0.251137, test loss: 0.917065, bias2: 0.37383830547332764, variance: 0.5432264804840088\n",
      "Train size: [400] hidden size: [977] trial: 39, train_loss: 0.250493, test loss: 0.917302, bias2: 0.37422722578048706, variance: 0.543074369430542\n",
      "Train size: [400] hidden size: [977] trial: 40, train_loss: 0.250402, test loss: 0.917616, bias2: 0.3741641044616699, variance: 0.5434518456459045\n",
      "Train size: [400] hidden size: [977] trial: 41, train_loss: 0.251412, test loss: 0.918111, bias2: 0.3720327615737915, variance: 0.5460778474807739\n",
      "Train size: [400] hidden size: [977] trial: 42, train_loss: 0.250235, test loss: 0.917044, bias2: 0.37174904346466064, variance: 0.5452954173088074\n",
      "Train size: [400] hidden size: [977] trial: 43, train_loss: 0.249734, test loss: 0.916564, bias2: 0.3718337416648865, variance: 0.5447306632995605\n",
      "Train size: [400] hidden size: [977] trial: 44, train_loss: 0.249194, test loss: 0.915937, bias2: 0.371131956577301, variance: 0.5448048710823059\n",
      "Train size: [400] hidden size: [977] trial: 45, train_loss: 0.248259, test loss: 0.915750, bias2: 0.37142133712768555, variance: 0.5443287491798401\n",
      "Train size: [400] hidden size: [977] trial: 46, train_loss: 0.247846, test loss: 0.915356, bias2: 0.3717076778411865, variance: 0.5436481833457947\n",
      "Train size: [400] hidden size: [977] trial: 47, train_loss: 0.246679, test loss: 0.915651, bias2: 0.3728857636451721, variance: 0.5427655577659607\n",
      "Train size: [400] hidden size: [977] trial: 48, train_loss: 0.246098, test loss: 0.915705, bias2: 0.37255537509918213, variance: 0.5431498885154724\n",
      "Train size: [400] hidden size: [977] trial: 49, train_loss: 0.246843, test loss: 0.917427, bias2: 0.372989296913147, variance: 0.5444377064704895\n",
      "##################################################\n",
      "Train size: [400] hidden size: [1125] trial: 0, train_loss: 0.184695, test loss: 0.844611, bias2: 0.8446113467216492, variance: 4.6710577628061856e-09\n",
      "Train size: [400] hidden size: [1125] trial: 1, train_loss: 0.219468, test loss: 0.822428, bias2: 0.5540218949317932, variance: 0.2684062123298645\n",
      "Train size: [400] hidden size: [1125] trial: 2, train_loss: 0.224291, test loss: 0.823898, bias2: 0.48100465536117554, variance: 0.342893123626709\n",
      "Train size: [400] hidden size: [1125] trial: 3, train_loss: 0.231864, test loss: 0.839937, bias2: 0.4442358613014221, variance: 0.39570069313049316\n",
      "Train size: [400] hidden size: [1125] trial: 4, train_loss: 0.231548, test loss: 0.837120, bias2: 0.41715338826179504, variance: 0.4199669063091278\n",
      "Train size: [400] hidden size: [1125] trial: 5, train_loss: 0.231081, test loss: 0.842870, bias2: 0.4066188335418701, variance: 0.43625152111053467\n",
      "Train size: [400] hidden size: [1125] trial: 6, train_loss: 0.229194, test loss: 0.853018, bias2: 0.40436065196990967, variance: 0.4486568570137024\n",
      "Train size: [400] hidden size: [1125] trial: 7, train_loss: 0.227704, test loss: 0.858955, bias2: 0.39917752146720886, variance: 0.45977720618247986\n",
      "Train size: [400] hidden size: [1125] trial: 8, train_loss: 0.231628, test loss: 0.863686, bias2: 0.39097583293914795, variance: 0.4727098345756531\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [1125] trial: 9, train_loss: 0.232394, test loss: 0.872328, bias2: 0.386570543050766, variance: 0.4857575595378876\n",
      "Train size: [400] hidden size: [1125] trial: 10, train_loss: 0.236262, test loss: 0.879058, bias2: 0.3813437819480896, variance: 0.49771374464035034\n",
      "Train size: [400] hidden size: [1125] trial: 11, train_loss: 0.237663, test loss: 0.886444, bias2: 0.37984830141067505, variance: 0.5065961480140686\n",
      "Train size: [400] hidden size: [1125] trial: 12, train_loss: 0.236552, test loss: 0.881026, bias2: 0.3730502128601074, variance: 0.507975697517395\n",
      "Train size: [400] hidden size: [1125] trial: 13, train_loss: 0.236151, test loss: 0.881656, bias2: 0.37136590480804443, variance: 0.5102901458740234\n",
      "Train size: [400] hidden size: [1125] trial: 14, train_loss: 0.234560, test loss: 0.884599, bias2: 0.37651342153549194, variance: 0.5080854892730713\n",
      "Train size: [400] hidden size: [1125] trial: 15, train_loss: 0.235209, test loss: 0.887842, bias2: 0.3758177161216736, variance: 0.5120240449905396\n",
      "Train size: [400] hidden size: [1125] trial: 16, train_loss: 0.235348, test loss: 0.890690, bias2: 0.37494343519210815, variance: 0.5157468914985657\n",
      "Train size: [400] hidden size: [1125] trial: 17, train_loss: 0.237815, test loss: 0.890733, bias2: 0.3745415210723877, variance: 0.5161915421485901\n",
      "Train size: [400] hidden size: [1125] trial: 18, train_loss: 0.238284, test loss: 0.889617, bias2: 0.3727119565010071, variance: 0.5169050693511963\n",
      "Train size: [400] hidden size: [1125] trial: 19, train_loss: 0.237916, test loss: 0.890417, bias2: 0.37291836738586426, variance: 0.5174989104270935\n",
      "Train size: [400] hidden size: [1125] trial: 20, train_loss: 0.238934, test loss: 0.885250, bias2: 0.36941325664520264, variance: 0.5158364772796631\n",
      "Train size: [400] hidden size: [1125] trial: 21, train_loss: 0.239124, test loss: 0.885499, bias2: 0.3689095377922058, variance: 0.5165895819664001\n",
      "Train size: [400] hidden size: [1125] trial: 22, train_loss: 0.239134, test loss: 0.890521, bias2: 0.3719504475593567, variance: 0.5185701251029968\n",
      "Train size: [400] hidden size: [1125] trial: 23, train_loss: 0.239059, test loss: 0.892696, bias2: 0.3729802966117859, variance: 0.5197151899337769\n",
      "Train size: [400] hidden size: [1125] trial: 24, train_loss: 0.239308, test loss: 0.897937, bias2: 0.37497812509536743, variance: 0.5229589939117432\n",
      "Train size: [400] hidden size: [1125] trial: 25, train_loss: 0.238746, test loss: 0.899825, bias2: 0.37491804361343384, variance: 0.5249070525169373\n",
      "Train size: [400] hidden size: [1125] trial: 26, train_loss: 0.237477, test loss: 0.898841, bias2: 0.37345415353775024, variance: 0.5253866314888\n",
      "Train size: [400] hidden size: [1125] trial: 27, train_loss: 0.237772, test loss: 0.897159, bias2: 0.3708382248878479, variance: 0.5263211131095886\n",
      "Train size: [400] hidden size: [1125] trial: 28, train_loss: 0.238347, test loss: 0.897690, bias2: 0.37018102407455444, variance: 0.5275091528892517\n",
      "Train size: [400] hidden size: [1125] trial: 29, train_loss: 0.237307, test loss: 0.898067, bias2: 0.36951518058776855, variance: 0.5285518169403076\n",
      "Train size: [400] hidden size: [1125] trial: 30, train_loss: 0.236819, test loss: 0.901745, bias2: 0.3721461296081543, variance: 0.5295987129211426\n",
      "Train size: [400] hidden size: [1125] trial: 31, train_loss: 0.235844, test loss: 0.901580, bias2: 0.3720567226409912, variance: 0.5295231342315674\n",
      "Train size: [400] hidden size: [1125] trial: 32, train_loss: 0.235350, test loss: 0.900150, bias2: 0.3732786774635315, variance: 0.526870846748352\n",
      "Train size: [400] hidden size: [1125] trial: 33, train_loss: 0.234400, test loss: 0.898458, bias2: 0.3733566403388977, variance: 0.5251018404960632\n",
      "Train size: [400] hidden size: [1125] trial: 34, train_loss: 0.234019, test loss: 0.897201, bias2: 0.3747909665107727, variance: 0.5224097967147827\n",
      "Train size: [400] hidden size: [1125] trial: 35, train_loss: 0.233927, test loss: 0.895909, bias2: 0.37353992462158203, variance: 0.5223687291145325\n",
      "Train size: [400] hidden size: [1125] trial: 36, train_loss: 0.233943, test loss: 0.897728, bias2: 0.37469691038131714, variance: 0.523030698299408\n",
      "Train size: [400] hidden size: [1125] trial: 37, train_loss: 0.234813, test loss: 0.897633, bias2: 0.37348127365112305, variance: 0.5241517424583435\n",
      "Train size: [400] hidden size: [1125] trial: 38, train_loss: 0.234717, test loss: 0.900023, bias2: 0.37388771772384644, variance: 0.5261349678039551\n",
      "Train size: [400] hidden size: [1125] trial: 39, train_loss: 0.234910, test loss: 0.899753, bias2: 0.3723658323287964, variance: 0.5273869633674622\n",
      "Train size: [400] hidden size: [1125] trial: 40, train_loss: 0.234697, test loss: 0.897661, bias2: 0.3709344267845154, variance: 0.5267266035079956\n",
      "Train size: [400] hidden size: [1125] trial: 41, train_loss: 0.235103, test loss: 0.898367, bias2: 0.3705194592475891, variance: 0.527847945690155\n",
      "Train size: [400] hidden size: [1125] trial: 42, train_loss: 0.234341, test loss: 0.896443, bias2: 0.3704320192337036, variance: 0.5260114669799805\n",
      "Train size: [400] hidden size: [1125] trial: 43, train_loss: 0.234287, test loss: 0.895076, bias2: 0.3684430718421936, variance: 0.5266330242156982\n",
      "Train size: [400] hidden size: [1125] trial: 44, train_loss: 0.233511, test loss: 0.895458, bias2: 0.36841070652008057, variance: 0.5270470380783081\n",
      "Train size: [400] hidden size: [1125] trial: 45, train_loss: 0.233273, test loss: 0.894048, bias2: 0.3687695860862732, variance: 0.5252785682678223\n",
      "Train size: [400] hidden size: [1125] trial: 46, train_loss: 0.233043, test loss: 0.893458, bias2: 0.36788809299468994, variance: 0.5255700945854187\n",
      "Train size: [400] hidden size: [1125] trial: 47, train_loss: 0.232289, test loss: 0.893172, bias2: 0.36866456270217896, variance: 0.5245073437690735\n",
      "Train size: [400] hidden size: [1125] trial: 48, train_loss: 0.231974, test loss: 0.893960, bias2: 0.3684420585632324, variance: 0.5255181193351746\n",
      "Train size: [400] hidden size: [1125] trial: 49, train_loss: 0.232022, test loss: 0.893949, bias2: 0.3674924373626709, variance: 0.5264562964439392\n",
      "##################################################\n",
      "Train size: [400] hidden size: [1295] trial: 0, train_loss: 0.206534, test loss: 0.815910, bias2: 0.8159103393554688, variance: 3.892548061656953e-09\n",
      "Train size: [400] hidden size: [1295] trial: 1, train_loss: 0.209381, test loss: 0.866792, bias2: 0.5994608402252197, variance: 0.26733145117759705\n",
      "Train size: [400] hidden size: [1295] trial: 2, train_loss: 0.216205, test loss: 0.848172, bias2: 0.4939959943294525, variance: 0.3541760742664337\n",
      "Train size: [400] hidden size: [1295] trial: 3, train_loss: 0.212844, test loss: 0.839315, bias2: 0.45322439074516296, variance: 0.3860902488231659\n",
      "Train size: [400] hidden size: [1295] trial: 4, train_loss: 0.214611, test loss: 0.856493, bias2: 0.43715551495552063, variance: 0.4193378984928131\n",
      "Train size: [400] hidden size: [1295] trial: 5, train_loss: 0.216268, test loss: 0.848200, bias2: 0.41391944885253906, variance: 0.43428027629852295\n",
      "Train size: [400] hidden size: [1295] trial: 6, train_loss: 0.222933, test loss: 0.839580, bias2: 0.39933380484580994, variance: 0.44024595618247986\n",
      "Train size: [400] hidden size: [1295] trial: 7, train_loss: 0.219569, test loss: 0.838515, bias2: 0.3910144865512848, variance: 0.4475001394748688\n",
      "Train size: [400] hidden size: [1295] trial: 8, train_loss: 0.218831, test loss: 0.842118, bias2: 0.38473206758499146, variance: 0.4573855400085449\n",
      "Train size: [400] hidden size: [1295] trial: 9, train_loss: 0.215543, test loss: 0.843945, bias2: 0.385779470205307, variance: 0.45816561579704285\n",
      "Train size: [400] hidden size: [1295] trial: 10, train_loss: 0.217154, test loss: 0.843205, bias2: 0.38552820682525635, variance: 0.4576772451400757\n",
      "Train size: [400] hidden size: [1295] trial: 11, train_loss: 0.218972, test loss: 0.840075, bias2: 0.37779495120048523, variance: 0.4622795879840851\n",
      "Train size: [400] hidden size: [1295] trial: 12, train_loss: 0.219660, test loss: 0.837856, bias2: 0.37408220767974854, variance: 0.46377354860305786\n",
      "Train size: [400] hidden size: [1295] trial: 13, train_loss: 0.217264, test loss: 0.835635, bias2: 0.37009382247924805, variance: 0.46554088592529297\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [1295] trial: 14, train_loss: 0.216150, test loss: 0.835297, bias2: 0.36821550130844116, variance: 0.4670812487602234\n",
      "Train size: [400] hidden size: [1295] trial: 15, train_loss: 0.217824, test loss: 0.839977, bias2: 0.3673536479473114, variance: 0.4726232588291168\n",
      "Train size: [400] hidden size: [1295] trial: 16, train_loss: 0.217592, test loss: 0.837441, bias2: 0.3650885224342346, variance: 0.47235286235809326\n",
      "Train size: [400] hidden size: [1295] trial: 17, train_loss: 0.217182, test loss: 0.837781, bias2: 0.36393463611602783, variance: 0.4738466143608093\n",
      "Train size: [400] hidden size: [1295] trial: 18, train_loss: 0.217767, test loss: 0.838143, bias2: 0.36204466223716736, variance: 0.4760984480381012\n",
      "Train size: [400] hidden size: [1295] trial: 19, train_loss: 0.216568, test loss: 0.836787, bias2: 0.36070817708969116, variance: 0.47607922554016113\n",
      "Train size: [400] hidden size: [1295] trial: 20, train_loss: 0.217479, test loss: 0.835196, bias2: 0.35563555359840393, variance: 0.47956040501594543\n",
      "Train size: [400] hidden size: [1295] trial: 21, train_loss: 0.216760, test loss: 0.838477, bias2: 0.3591685891151428, variance: 0.4793088436126709\n",
      "Train size: [400] hidden size: [1295] trial: 22, train_loss: 0.217896, test loss: 0.838487, bias2: 0.3573227822780609, variance: 0.4811643660068512\n",
      "Train size: [400] hidden size: [1295] trial: 23, train_loss: 0.218161, test loss: 0.843627, bias2: 0.35952726006507874, variance: 0.48410001397132874\n",
      "Train size: [400] hidden size: [1295] trial: 24, train_loss: 0.219691, test loss: 0.841378, bias2: 0.35658395290374756, variance: 0.4847942590713501\n",
      "Train size: [400] hidden size: [1295] trial: 25, train_loss: 0.219743, test loss: 0.844818, bias2: 0.3584861755371094, variance: 0.4863319396972656\n",
      "Train size: [400] hidden size: [1295] trial: 26, train_loss: 0.220005, test loss: 0.842427, bias2: 0.3543168008327484, variance: 0.4881105124950409\n",
      "Train size: [400] hidden size: [1295] trial: 27, train_loss: 0.219928, test loss: 0.843475, bias2: 0.354946106672287, variance: 0.48852911591529846\n",
      "Train size: [400] hidden size: [1295] trial: 28, train_loss: 0.218274, test loss: 0.843129, bias2: 0.356321781873703, variance: 0.4868070185184479\n",
      "Train size: [400] hidden size: [1295] trial: 29, train_loss: 0.217767, test loss: 0.843386, bias2: 0.35762470960617065, variance: 0.48576104640960693\n",
      "Train size: [400] hidden size: [1295] trial: 30, train_loss: 0.217297, test loss: 0.843618, bias2: 0.3566742539405823, variance: 0.4869440793991089\n",
      "Train size: [400] hidden size: [1295] trial: 31, train_loss: 0.216846, test loss: 0.845475, bias2: 0.3575214147567749, variance: 0.48795318603515625\n",
      "Train size: [400] hidden size: [1295] trial: 32, train_loss: 0.217202, test loss: 0.845953, bias2: 0.3567044734954834, variance: 0.48924845457077026\n",
      "Train size: [400] hidden size: [1295] trial: 33, train_loss: 0.217078, test loss: 0.846666, bias2: 0.3570232689380646, variance: 0.4896427094936371\n",
      "Train size: [400] hidden size: [1295] trial: 34, train_loss: 0.216782, test loss: 0.846430, bias2: 0.3562068045139313, variance: 0.4902232587337494\n",
      "Train size: [400] hidden size: [1295] trial: 35, train_loss: 0.216371, test loss: 0.846285, bias2: 0.3547707200050354, variance: 0.49151408672332764\n",
      "Train size: [400] hidden size: [1295] trial: 36, train_loss: 0.216948, test loss: 0.848034, bias2: 0.35559287667274475, variance: 0.49244067072868347\n",
      "Train size: [400] hidden size: [1295] trial: 37, train_loss: 0.216962, test loss: 0.846744, bias2: 0.354783296585083, variance: 0.49196046590805054\n",
      "Train size: [400] hidden size: [1295] trial: 38, train_loss: 0.217307, test loss: 0.846366, bias2: 0.3539694547653198, variance: 0.49239611625671387\n",
      "Train size: [400] hidden size: [1295] trial: 39, train_loss: 0.217193, test loss: 0.846852, bias2: 0.3536732494831085, variance: 0.4931786358356476\n",
      "Train size: [400] hidden size: [1295] trial: 40, train_loss: 0.217640, test loss: 0.847200, bias2: 0.3543115258216858, variance: 0.49288851022720337\n",
      "Train size: [400] hidden size: [1295] trial: 41, train_loss: 0.218163, test loss: 0.846448, bias2: 0.35334983468055725, variance: 0.49309834837913513\n",
      "Train size: [400] hidden size: [1295] trial: 42, train_loss: 0.217461, test loss: 0.847133, bias2: 0.35410431027412415, variance: 0.4930286705493927\n",
      "Train size: [400] hidden size: [1295] trial: 43, train_loss: 0.216974, test loss: 0.849360, bias2: 0.35607436299324036, variance: 0.49328574538230896\n",
      "Train size: [400] hidden size: [1295] trial: 44, train_loss: 0.217063, test loss: 0.848105, bias2: 0.3542027175426483, variance: 0.4939022362232208\n",
      "Train size: [400] hidden size: [1295] trial: 45, train_loss: 0.216924, test loss: 0.846674, bias2: 0.35331737995147705, variance: 0.49335622787475586\n",
      "Train size: [400] hidden size: [1295] trial: 46, train_loss: 0.217304, test loss: 0.845616, bias2: 0.35159599781036377, variance: 0.49402034282684326\n",
      "Train size: [400] hidden size: [1295] trial: 47, train_loss: 0.217534, test loss: 0.844437, bias2: 0.3513862192630768, variance: 0.493051141500473\n",
      "Train size: [400] hidden size: [1295] trial: 48, train_loss: 0.217593, test loss: 0.844702, bias2: 0.35060709714889526, variance: 0.49409496784210205\n",
      "Train size: [400] hidden size: [1295] trial: 49, train_loss: 0.218077, test loss: 0.845120, bias2: 0.35084399580955505, variance: 0.4942755401134491\n",
      "##################################################\n",
      "Train size: [400] hidden size: [1491] trial: 0, train_loss: 0.217989, test loss: 0.755227, bias2: 0.7552268505096436, variance: -3.8925479506346505e-10\n",
      "Train size: [400] hidden size: [1491] trial: 1, train_loss: 0.216575, test loss: 0.768780, bias2: 0.5344428420066833, variance: 0.23433732986450195\n",
      "Train size: [400] hidden size: [1491] trial: 2, train_loss: 0.217085, test loss: 0.807966, bias2: 0.5018821358680725, variance: 0.3060839772224426\n",
      "Train size: [400] hidden size: [1491] trial: 3, train_loss: 0.212338, test loss: 0.794494, bias2: 0.44210946559906006, variance: 0.352384090423584\n",
      "Train size: [400] hidden size: [1491] trial: 4, train_loss: 0.214796, test loss: 0.784674, bias2: 0.40425553917884827, variance: 0.3804182708263397\n",
      "Train size: [400] hidden size: [1491] trial: 5, train_loss: 0.214451, test loss: 0.793658, bias2: 0.3944215476512909, variance: 0.39923617243766785\n",
      "Train size: [400] hidden size: [1491] trial: 6, train_loss: 0.216941, test loss: 0.784703, bias2: 0.37575364112854004, variance: 0.40894919633865356\n",
      "Train size: [400] hidden size: [1491] trial: 7, train_loss: 0.218866, test loss: 0.797083, bias2: 0.37445560097694397, variance: 0.4226275384426117\n",
      "Train size: [400] hidden size: [1491] trial: 8, train_loss: 0.215744, test loss: 0.803223, bias2: 0.3779110312461853, variance: 0.425311803817749\n",
      "Train size: [400] hidden size: [1491] trial: 9, train_loss: 0.215803, test loss: 0.813220, bias2: 0.3798643946647644, variance: 0.43335509300231934\n",
      "Train size: [400] hidden size: [1491] trial: 10, train_loss: 0.214429, test loss: 0.808899, bias2: 0.376552939414978, variance: 0.4323461055755615\n",
      "Train size: [400] hidden size: [1491] trial: 11, train_loss: 0.214244, test loss: 0.808235, bias2: 0.3717312514781952, variance: 0.4365036189556122\n",
      "Train size: [400] hidden size: [1491] trial: 12, train_loss: 0.214848, test loss: 0.815993, bias2: 0.376616507768631, variance: 0.4393766224384308\n",
      "Train size: [400] hidden size: [1491] trial: 13, train_loss: 0.213307, test loss: 0.815421, bias2: 0.37244945764541626, variance: 0.4429711699485779\n",
      "Train size: [400] hidden size: [1491] trial: 14, train_loss: 0.212438, test loss: 0.811490, bias2: 0.36500227451324463, variance: 0.44648730754852295\n",
      "Train size: [400] hidden size: [1491] trial: 15, train_loss: 0.212364, test loss: 0.818092, bias2: 0.3662591278553009, variance: 0.45183315873146057\n",
      "Train size: [400] hidden size: [1491] trial: 16, train_loss: 0.210482, test loss: 0.815499, bias2: 0.3637077510356903, variance: 0.451791375875473\n",
      "Train size: [400] hidden size: [1491] trial: 17, train_loss: 0.209820, test loss: 0.817663, bias2: 0.36096832156181335, variance: 0.4566948115825653\n",
      "Train size: [400] hidden size: [1491] trial: 18, train_loss: 0.208313, test loss: 0.817625, bias2: 0.3594498634338379, variance: 0.4581755995750427\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [1491] trial: 19, train_loss: 0.208212, test loss: 0.818628, bias2: 0.3587963283061981, variance: 0.45983198285102844\n",
      "Train size: [400] hidden size: [1491] trial: 20, train_loss: 0.209700, test loss: 0.815611, bias2: 0.35499975085258484, variance: 0.46061113476753235\n",
      "Train size: [400] hidden size: [1491] trial: 21, train_loss: 0.209352, test loss: 0.816701, bias2: 0.3526296317577362, variance: 0.4640709459781647\n",
      "Train size: [400] hidden size: [1491] trial: 22, train_loss: 0.210055, test loss: 0.818384, bias2: 0.35118016600608826, variance: 0.4672043025493622\n",
      "Train size: [400] hidden size: [1491] trial: 23, train_loss: 0.211307, test loss: 0.819693, bias2: 0.35067805647850037, variance: 0.46901461482048035\n",
      "Train size: [400] hidden size: [1491] trial: 24, train_loss: 0.210786, test loss: 0.817810, bias2: 0.3515171706676483, variance: 0.46629324555397034\n",
      "Train size: [400] hidden size: [1491] trial: 25, train_loss: 0.210624, test loss: 0.821324, bias2: 0.35215508937835693, variance: 0.46916890144348145\n",
      "Train size: [400] hidden size: [1491] trial: 26, train_loss: 0.210062, test loss: 0.822036, bias2: 0.3529171049594879, variance: 0.46911874413490295\n",
      "Train size: [400] hidden size: [1491] trial: 27, train_loss: 0.211266, test loss: 0.820501, bias2: 0.3468685448169708, variance: 0.4736328423023224\n",
      "Train size: [400] hidden size: [1491] trial: 28, train_loss: 0.210186, test loss: 0.823637, bias2: 0.34920626878738403, variance: 0.47443073987960815\n",
      "Train size: [400] hidden size: [1491] trial: 29, train_loss: 0.209723, test loss: 0.823771, bias2: 0.3505300283432007, variance: 0.4732412099838257\n",
      "Train size: [400] hidden size: [1491] trial: 30, train_loss: 0.209708, test loss: 0.824801, bias2: 0.3492821156978607, variance: 0.4755185544490814\n",
      "Train size: [400] hidden size: [1491] trial: 31, train_loss: 0.209341, test loss: 0.827730, bias2: 0.3512699604034424, variance: 0.47645968198776245\n",
      "Train size: [400] hidden size: [1491] trial: 32, train_loss: 0.210011, test loss: 0.827044, bias2: 0.35200488567352295, variance: 0.4750392436981201\n",
      "Train size: [400] hidden size: [1491] trial: 33, train_loss: 0.209748, test loss: 0.827627, bias2: 0.3529163599014282, variance: 0.47471052408218384\n",
      "Train size: [400] hidden size: [1491] trial: 34, train_loss: 0.209613, test loss: 0.829709, bias2: 0.3549329340457916, variance: 0.4747762382030487\n",
      "Train size: [400] hidden size: [1491] trial: 35, train_loss: 0.208994, test loss: 0.826698, bias2: 0.3523387610912323, variance: 0.47435906529426575\n",
      "Train size: [400] hidden size: [1491] trial: 36, train_loss: 0.209822, test loss: 0.826742, bias2: 0.3507664203643799, variance: 0.4759758710861206\n",
      "Train size: [400] hidden size: [1491] trial: 37, train_loss: 0.210198, test loss: 0.826827, bias2: 0.3500756025314331, variance: 0.47675174474716187\n",
      "Train size: [400] hidden size: [1491] trial: 38, train_loss: 0.210575, test loss: 0.828861, bias2: 0.34956490993499756, variance: 0.4792957901954651\n",
      "Train size: [400] hidden size: [1491] trial: 39, train_loss: 0.210497, test loss: 0.827291, bias2: 0.3477020263671875, variance: 0.4795893430709839\n",
      "Train size: [400] hidden size: [1491] trial: 40, train_loss: 0.211346, test loss: 0.825034, bias2: 0.3459203243255615, variance: 0.47911351919174194\n",
      "Train size: [400] hidden size: [1491] trial: 41, train_loss: 0.211704, test loss: 0.824173, bias2: 0.34408876299858093, variance: 0.48008373379707336\n",
      "Train size: [400] hidden size: [1491] trial: 42, train_loss: 0.211388, test loss: 0.823729, bias2: 0.3428722321987152, variance: 0.48085638880729675\n",
      "Train size: [400] hidden size: [1491] trial: 43, train_loss: 0.211025, test loss: 0.823711, bias2: 0.34254714846611023, variance: 0.48116418719291687\n",
      "Train size: [400] hidden size: [1491] trial: 44, train_loss: 0.210729, test loss: 0.825161, bias2: 0.3434789478778839, variance: 0.481682151556015\n",
      "Train size: [400] hidden size: [1491] trial: 45, train_loss: 0.210836, test loss: 0.823359, bias2: 0.3425840139389038, variance: 0.4807747006416321\n",
      "Train size: [400] hidden size: [1491] trial: 46, train_loss: 0.211063, test loss: 0.821591, bias2: 0.3411741554737091, variance: 0.48041680455207825\n",
      "Train size: [400] hidden size: [1491] trial: 47, train_loss: 0.210546, test loss: 0.822624, bias2: 0.3419429659843445, variance: 0.4806807041168213\n",
      "Train size: [400] hidden size: [1491] trial: 48, train_loss: 0.210334, test loss: 0.825849, bias2: 0.3440708518028259, variance: 0.481778085231781\n",
      "Train size: [400] hidden size: [1491] trial: 49, train_loss: 0.209875, test loss: 0.826765, bias2: 0.34343358874320984, variance: 0.4833313524723053\n",
      "##################################################\n",
      "Train size: [400] hidden size: [1717] trial: 0, train_loss: 0.200565, test loss: 0.797820, bias2: 0.7978197336196899, variance: 3.8925479506346505e-10\n",
      "Train size: [400] hidden size: [1717] trial: 1, train_loss: 0.188107, test loss: 0.776966, bias2: 0.557910680770874, variance: 0.2190554440021515\n",
      "Train size: [400] hidden size: [1717] trial: 2, train_loss: 0.185335, test loss: 0.789080, bias2: 0.493338406085968, variance: 0.29574131965637207\n",
      "Train size: [400] hidden size: [1717] trial: 3, train_loss: 0.189992, test loss: 0.787759, bias2: 0.4667403995990753, variance: 0.3210190236568451\n",
      "Train size: [400] hidden size: [1717] trial: 4, train_loss: 0.192379, test loss: 0.807417, bias2: 0.4501410126686096, variance: 0.3572758436203003\n",
      "Train size: [400] hidden size: [1717] trial: 5, train_loss: 0.192247, test loss: 0.813490, bias2: 0.4319354295730591, variance: 0.38155460357666016\n",
      "Train size: [400] hidden size: [1717] trial: 6, train_loss: 0.189923, test loss: 0.814774, bias2: 0.42757129669189453, variance: 0.3872023820877075\n",
      "Train size: [400] hidden size: [1717] trial: 7, train_loss: 0.191747, test loss: 0.803559, bias2: 0.4093421697616577, variance: 0.39421677589416504\n",
      "Train size: [400] hidden size: [1717] trial: 8, train_loss: 0.189593, test loss: 0.802491, bias2: 0.40093207359313965, variance: 0.40155869722366333\n",
      "Train size: [400] hidden size: [1717] trial: 9, train_loss: 0.189584, test loss: 0.802929, bias2: 0.39447617530822754, variance: 0.40845298767089844\n",
      "Train size: [400] hidden size: [1717] trial: 10, train_loss: 0.191243, test loss: 0.798576, bias2: 0.38993123173713684, variance: 0.40864506363868713\n",
      "Train size: [400] hidden size: [1717] trial: 11, train_loss: 0.190090, test loss: 0.801822, bias2: 0.38691937923431396, variance: 0.41490286588668823\n",
      "Train size: [400] hidden size: [1717] trial: 12, train_loss: 0.189582, test loss: 0.806980, bias2: 0.3876747488975525, variance: 0.4193054437637329\n",
      "Train size: [400] hidden size: [1717] trial: 13, train_loss: 0.188044, test loss: 0.810590, bias2: 0.38767188787460327, variance: 0.4229181408882141\n",
      "Train size: [400] hidden size: [1717] trial: 14, train_loss: 0.187338, test loss: 0.810158, bias2: 0.38342028856277466, variance: 0.4267377257347107\n",
      "Train size: [400] hidden size: [1717] trial: 15, train_loss: 0.189710, test loss: 0.806085, bias2: 0.378250390291214, variance: 0.42783501744270325\n",
      "Train size: [400] hidden size: [1717] trial: 16, train_loss: 0.190491, test loss: 0.808173, bias2: 0.3790753185749054, variance: 0.4290980398654938\n",
      "Train size: [400] hidden size: [1717] trial: 17, train_loss: 0.190555, test loss: 0.805885, bias2: 0.37547850608825684, variance: 0.43040645122528076\n",
      "Train size: [400] hidden size: [1717] trial: 18, train_loss: 0.191827, test loss: 0.803586, bias2: 0.37368345260620117, variance: 0.4299021363258362\n",
      "Train size: [400] hidden size: [1717] trial: 19, train_loss: 0.191684, test loss: 0.801098, bias2: 0.37144213914871216, variance: 0.42965561151504517\n",
      "Train size: [400] hidden size: [1717] trial: 20, train_loss: 0.190566, test loss: 0.798436, bias2: 0.3685111701488495, variance: 0.42992451786994934\n",
      "Train size: [400] hidden size: [1717] trial: 21, train_loss: 0.191568, test loss: 0.797571, bias2: 0.3640461266040802, variance: 0.43352487683296204\n",
      "Train size: [400] hidden size: [1717] trial: 22, train_loss: 0.191343, test loss: 0.797112, bias2: 0.36126190423965454, variance: 0.4358501434326172\n",
      "Train size: [400] hidden size: [1717] trial: 23, train_loss: 0.191458, test loss: 0.800192, bias2: 0.36044639348983765, variance: 0.43974602222442627\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [1717] trial: 24, train_loss: 0.191676, test loss: 0.799553, bias2: 0.3595392107963562, variance: 0.4400135278701782\n",
      "Train size: [400] hidden size: [1717] trial: 25, train_loss: 0.192124, test loss: 0.799198, bias2: 0.3581414818763733, variance: 0.44105637073516846\n",
      "Train size: [400] hidden size: [1717] trial: 26, train_loss: 0.192692, test loss: 0.797524, bias2: 0.3555449843406677, variance: 0.44197946786880493\n",
      "Train size: [400] hidden size: [1717] trial: 27, train_loss: 0.192531, test loss: 0.798170, bias2: 0.3555694818496704, variance: 0.44260042905807495\n",
      "Train size: [400] hidden size: [1717] trial: 28, train_loss: 0.192720, test loss: 0.796267, bias2: 0.35317549109458923, variance: 0.44309118390083313\n",
      "Train size: [400] hidden size: [1717] trial: 29, train_loss: 0.192607, test loss: 0.795150, bias2: 0.3533351421356201, variance: 0.441814661026001\n",
      "Train size: [400] hidden size: [1717] trial: 30, train_loss: 0.193950, test loss: 0.795461, bias2: 0.3508774936199188, variance: 0.44458380341529846\n",
      "Train size: [400] hidden size: [1717] trial: 31, train_loss: 0.193200, test loss: 0.793406, bias2: 0.3496493697166443, variance: 0.4437562823295593\n",
      "Train size: [400] hidden size: [1717] trial: 32, train_loss: 0.193401, test loss: 0.793306, bias2: 0.3492303788661957, variance: 0.44407543540000916\n",
      "Train size: [400] hidden size: [1717] trial: 33, train_loss: 0.193845, test loss: 0.794718, bias2: 0.3492489457130432, variance: 0.4454690217971802\n",
      "Train size: [400] hidden size: [1717] trial: 34, train_loss: 0.193466, test loss: 0.798264, bias2: 0.35139667987823486, variance: 0.44686686992645264\n",
      "Train size: [400] hidden size: [1717] trial: 35, train_loss: 0.193763, test loss: 0.799008, bias2: 0.35091614723205566, variance: 0.44809144735336304\n",
      "Train size: [400] hidden size: [1717] trial: 36, train_loss: 0.194377, test loss: 0.801899, bias2: 0.35117971897125244, variance: 0.4507192373275757\n",
      "Train size: [400] hidden size: [1717] trial: 37, train_loss: 0.195050, test loss: 0.802388, bias2: 0.35050728917121887, variance: 0.45188096165657043\n",
      "Train size: [400] hidden size: [1717] trial: 38, train_loss: 0.195777, test loss: 0.800970, bias2: 0.34862083196640015, variance: 0.4523490071296692\n",
      "Train size: [400] hidden size: [1717] trial: 39, train_loss: 0.197364, test loss: 0.800482, bias2: 0.34781861305236816, variance: 0.4526635408401489\n",
      "Train size: [400] hidden size: [1717] trial: 40, train_loss: 0.197354, test loss: 0.801872, bias2: 0.34843865036964417, variance: 0.4534335434436798\n",
      "Train size: [400] hidden size: [1717] trial: 41, train_loss: 0.196890, test loss: 0.802639, bias2: 0.34835001826286316, variance: 0.45428863167762756\n",
      "Train size: [400] hidden size: [1717] trial: 42, train_loss: 0.196836, test loss: 0.802527, bias2: 0.3470270335674286, variance: 0.45550021529197693\n",
      "Train size: [400] hidden size: [1717] trial: 43, train_loss: 0.197275, test loss: 0.803329, bias2: 0.34766778349876404, variance: 0.4556609094142914\n",
      "Train size: [400] hidden size: [1717] trial: 44, train_loss: 0.197947, test loss: 0.802520, bias2: 0.3457823395729065, variance: 0.45673733949661255\n",
      "Train size: [400] hidden size: [1717] trial: 45, train_loss: 0.197711, test loss: 0.801748, bias2: 0.34512731432914734, variance: 0.4566207826137543\n",
      "Train size: [400] hidden size: [1717] trial: 46, train_loss: 0.197791, test loss: 0.801932, bias2: 0.34426215291023254, variance: 0.4576694667339325\n",
      "Train size: [400] hidden size: [1717] trial: 47, train_loss: 0.197535, test loss: 0.802337, bias2: 0.3447471261024475, variance: 0.45759016275405884\n",
      "Train size: [400] hidden size: [1717] trial: 48, train_loss: 0.197666, test loss: 0.802423, bias2: 0.3441358208656311, variance: 0.4582871198654175\n",
      "Train size: [400] hidden size: [1717] trial: 49, train_loss: 0.197535, test loss: 0.802697, bias2: 0.3445928990840912, variance: 0.4581044018268585\n",
      "##################################################\n",
      "Train size: [400] hidden size: [1977] trial: 0, train_loss: 0.216902, test loss: 0.751593, bias2: 0.751593291759491, variance: -3.8925479506346505e-10\n",
      "Train size: [400] hidden size: [1977] trial: 1, train_loss: 0.209602, test loss: 0.798774, bias2: 0.5877315998077393, variance: 0.21104231476783752\n",
      "Train size: [400] hidden size: [1977] trial: 2, train_loss: 0.192307, test loss: 0.795653, bias2: 0.5208228826522827, variance: 0.2748298943042755\n",
      "Train size: [400] hidden size: [1977] trial: 3, train_loss: 0.189687, test loss: 0.776175, bias2: 0.4671339988708496, variance: 0.30904120206832886\n",
      "Train size: [400] hidden size: [1977] trial: 4, train_loss: 0.188298, test loss: 0.771505, bias2: 0.43506327271461487, variance: 0.33644184470176697\n",
      "Train size: [400] hidden size: [1977] trial: 5, train_loss: 0.189160, test loss: 0.776403, bias2: 0.42202678322792053, variance: 0.35437652468681335\n",
      "Train size: [400] hidden size: [1977] trial: 6, train_loss: 0.192468, test loss: 0.786067, bias2: 0.417584091424942, variance: 0.3684825003147125\n",
      "Train size: [400] hidden size: [1977] trial: 7, train_loss: 0.192021, test loss: 0.785154, bias2: 0.40650537610054016, variance: 0.37864890694618225\n",
      "Train size: [400] hidden size: [1977] trial: 8, train_loss: 0.194783, test loss: 0.783728, bias2: 0.39582306146621704, variance: 0.38790446519851685\n",
      "Train size: [400] hidden size: [1977] trial: 9, train_loss: 0.193410, test loss: 0.778785, bias2: 0.38543465733528137, variance: 0.393350213766098\n",
      "Train size: [400] hidden size: [1977] trial: 10, train_loss: 0.195768, test loss: 0.792301, bias2: 0.386020302772522, variance: 0.4062803387641907\n",
      "Train size: [400] hidden size: [1977] trial: 11, train_loss: 0.196751, test loss: 0.788775, bias2: 0.3792078197002411, variance: 0.4095672070980072\n",
      "Train size: [400] hidden size: [1977] trial: 12, train_loss: 0.196541, test loss: 0.794891, bias2: 0.38384461402893066, variance: 0.41104620695114136\n",
      "Train size: [400] hidden size: [1977] trial: 13, train_loss: 0.198708, test loss: 0.787804, bias2: 0.3718544542789459, variance: 0.41594943404197693\n",
      "Train size: [400] hidden size: [1977] trial: 14, train_loss: 0.199481, test loss: 0.786007, bias2: 0.3693699240684509, variance: 0.41663658618927\n",
      "Train size: [400] hidden size: [1977] trial: 15, train_loss: 0.198990, test loss: 0.781590, bias2: 0.36499324440956116, variance: 0.416596382856369\n",
      "Train size: [400] hidden size: [1977] trial: 16, train_loss: 0.196816, test loss: 0.788740, bias2: 0.3708151578903198, variance: 0.4179248809814453\n",
      "Train size: [400] hidden size: [1977] trial: 17, train_loss: 0.197093, test loss: 0.791253, bias2: 0.3721901476383209, variance: 0.41906335949897766\n",
      "Train size: [400] hidden size: [1977] trial: 18, train_loss: 0.196373, test loss: 0.789331, bias2: 0.37084484100341797, variance: 0.4184860587120056\n",
      "Train size: [400] hidden size: [1977] trial: 19, train_loss: 0.196369, test loss: 0.792688, bias2: 0.37299761176109314, variance: 0.4196905791759491\n",
      "Train size: [400] hidden size: [1977] trial: 20, train_loss: 0.196070, test loss: 0.793008, bias2: 0.36999762058258057, variance: 0.42301028966903687\n",
      "Train size: [400] hidden size: [1977] trial: 21, train_loss: 0.196530, test loss: 0.788306, bias2: 0.3637065291404724, variance: 0.4245993494987488\n",
      "Train size: [400] hidden size: [1977] trial: 22, train_loss: 0.196024, test loss: 0.786200, bias2: 0.3607926666736603, variance: 0.42540743947029114\n",
      "Train size: [400] hidden size: [1977] trial: 23, train_loss: 0.195817, test loss: 0.783923, bias2: 0.3581240773200989, variance: 0.4257991909980774\n",
      "Train size: [400] hidden size: [1977] trial: 24, train_loss: 0.194916, test loss: 0.784253, bias2: 0.3580566644668579, variance: 0.4261965751647949\n",
      "Train size: [400] hidden size: [1977] trial: 25, train_loss: 0.193865, test loss: 0.782683, bias2: 0.35663679242134094, variance: 0.42604610323905945\n",
      "Train size: [400] hidden size: [1977] trial: 26, train_loss: 0.193887, test loss: 0.780321, bias2: 0.3541032075881958, variance: 0.4262179732322693\n",
      "Train size: [400] hidden size: [1977] trial: 27, train_loss: 0.193168, test loss: 0.781052, bias2: 0.3555990755558014, variance: 0.42545321583747864\n",
      "Train size: [400] hidden size: [1977] trial: 28, train_loss: 0.192492, test loss: 0.780646, bias2: 0.35554128885269165, variance: 0.42510443925857544\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [1977] trial: 29, train_loss: 0.192649, test loss: 0.784310, bias2: 0.35745736956596375, variance: 0.42685267329216003\n",
      "Train size: [400] hidden size: [1977] trial: 30, train_loss: 0.191560, test loss: 0.781956, bias2: 0.35569503903388977, variance: 0.4262607991695404\n",
      "Train size: [400] hidden size: [1977] trial: 31, train_loss: 0.191171, test loss: 0.778026, bias2: 0.3541651964187622, variance: 0.4238610863685608\n",
      "Train size: [400] hidden size: [1977] trial: 32, train_loss: 0.190760, test loss: 0.779202, bias2: 0.3556336462497711, variance: 0.42356809973716736\n",
      "Train size: [400] hidden size: [1977] trial: 33, train_loss: 0.189970, test loss: 0.779278, bias2: 0.35549384355545044, variance: 0.4237845540046692\n",
      "Train size: [400] hidden size: [1977] trial: 34, train_loss: 0.189997, test loss: 0.779769, bias2: 0.35583388805389404, variance: 0.4239351749420166\n",
      "Train size: [400] hidden size: [1977] trial: 35, train_loss: 0.189051, test loss: 0.779257, bias2: 0.3544889986515045, variance: 0.4247683584690094\n",
      "Train size: [400] hidden size: [1977] trial: 36, train_loss: 0.188979, test loss: 0.779876, bias2: 0.35518956184387207, variance: 0.4246866703033447\n",
      "Train size: [400] hidden size: [1977] trial: 37, train_loss: 0.188859, test loss: 0.779013, bias2: 0.3540063500404358, variance: 0.4250069856643677\n",
      "Train size: [400] hidden size: [1977] trial: 38, train_loss: 0.189138, test loss: 0.776676, bias2: 0.3514944016933441, variance: 0.42518118023872375\n",
      "Train size: [400] hidden size: [1977] trial: 39, train_loss: 0.189688, test loss: 0.776009, bias2: 0.35120314359664917, variance: 0.42480581998825073\n",
      "Train size: [400] hidden size: [1977] trial: 40, train_loss: 0.189174, test loss: 0.774316, bias2: 0.350423127412796, variance: 0.423893004655838\n",
      "Train size: [400] hidden size: [1977] trial: 41, train_loss: 0.188207, test loss: 0.773821, bias2: 0.35118621587753296, variance: 0.42263466119766235\n",
      "Train size: [400] hidden size: [1977] trial: 42, train_loss: 0.188300, test loss: 0.775896, bias2: 0.3527553975582123, variance: 0.42314091324806213\n",
      "Train size: [400] hidden size: [1977] trial: 43, train_loss: 0.187418, test loss: 0.777631, bias2: 0.35477766394615173, variance: 0.42285284399986267\n",
      "Train size: [400] hidden size: [1977] trial: 44, train_loss: 0.187398, test loss: 0.778517, bias2: 0.35487106442451477, variance: 0.42364558577537537\n",
      "Train size: [400] hidden size: [1977] trial: 45, train_loss: 0.187708, test loss: 0.777803, bias2: 0.3543155789375305, variance: 0.42348700761795044\n",
      "Train size: [400] hidden size: [1977] trial: 46, train_loss: 0.187486, test loss: 0.778818, bias2: 0.3547915518283844, variance: 0.42402616143226624\n",
      "Train size: [400] hidden size: [1977] trial: 47, train_loss: 0.187176, test loss: 0.780835, bias2: 0.3561382591724396, variance: 0.4246971309185028\n",
      "Train size: [400] hidden size: [1977] trial: 48, train_loss: 0.187246, test loss: 0.781822, bias2: 0.35687947273254395, variance: 0.4249420762062073\n",
      "Train size: [400] hidden size: [1977] trial: 49, train_loss: 0.187119, test loss: 0.780054, bias2: 0.3560754954814911, variance: 0.4239788353443146\n",
      "##################################################\n",
      "Train size: [400] hidden size: [2276] trial: 0, train_loss: 0.171323, test loss: 0.807095, bias2: 0.807095468044281, variance: -3.892548061656953e-09\n",
      "Train size: [400] hidden size: [2276] trial: 1, train_loss: 0.176229, test loss: 0.808010, bias2: 0.5740985870361328, variance: 0.23391103744506836\n",
      "Train size: [400] hidden size: [2276] trial: 2, train_loss: 0.194325, test loss: 0.790994, bias2: 0.5051483511924744, variance: 0.28584569692611694\n",
      "Train size: [400] hidden size: [2276] trial: 3, train_loss: 0.191690, test loss: 0.780688, bias2: 0.4648834764957428, variance: 0.31580498814582825\n",
      "Train size: [400] hidden size: [2276] trial: 4, train_loss: 0.186595, test loss: 0.778724, bias2: 0.4443114995956421, variance: 0.334412157535553\n",
      "Train size: [400] hidden size: [2276] trial: 5, train_loss: 0.183099, test loss: 0.770145, bias2: 0.4279727339744568, variance: 0.34217214584350586\n",
      "Train size: [400] hidden size: [2276] trial: 6, train_loss: 0.181100, test loss: 0.768188, bias2: 0.4147084057331085, variance: 0.35347917675971985\n",
      "Train size: [400] hidden size: [2276] trial: 7, train_loss: 0.180963, test loss: 0.765537, bias2: 0.40909332036972046, variance: 0.35644346475601196\n",
      "Train size: [400] hidden size: [2276] trial: 8, train_loss: 0.181162, test loss: 0.780760, bias2: 0.4071991741657257, variance: 0.3735603988170624\n",
      "Train size: [400] hidden size: [2276] trial: 9, train_loss: 0.182546, test loss: 0.773989, bias2: 0.3983016610145569, variance: 0.37568771839141846\n",
      "Train size: [400] hidden size: [2276] trial: 10, train_loss: 0.182962, test loss: 0.773855, bias2: 0.3925967514514923, variance: 0.38125792145729065\n",
      "Train size: [400] hidden size: [2276] trial: 11, train_loss: 0.183203, test loss: 0.773998, bias2: 0.3904433846473694, variance: 0.38355499505996704\n",
      "Train size: [400] hidden size: [2276] trial: 12, train_loss: 0.182849, test loss: 0.771252, bias2: 0.3844447731971741, variance: 0.38680702447891235\n",
      "Train size: [400] hidden size: [2276] trial: 13, train_loss: 0.182267, test loss: 0.769938, bias2: 0.38241100311279297, variance: 0.38752710819244385\n",
      "Train size: [400] hidden size: [2276] trial: 14, train_loss: 0.181826, test loss: 0.768789, bias2: 0.3786967396736145, variance: 0.3900919556617737\n",
      "Train size: [400] hidden size: [2276] trial: 15, train_loss: 0.181334, test loss: 0.769923, bias2: 0.37630751729011536, variance: 0.3936155140399933\n",
      "Train size: [400] hidden size: [2276] trial: 16, train_loss: 0.181681, test loss: 0.771734, bias2: 0.37766292691230774, variance: 0.394071489572525\n",
      "Train size: [400] hidden size: [2276] trial: 17, train_loss: 0.180282, test loss: 0.768097, bias2: 0.3741317391395569, variance: 0.3939657211303711\n",
      "Train size: [400] hidden size: [2276] trial: 18, train_loss: 0.180229, test loss: 0.763782, bias2: 0.3697301745414734, variance: 0.39405202865600586\n",
      "Train size: [400] hidden size: [2276] trial: 19, train_loss: 0.181535, test loss: 0.764719, bias2: 0.3662993907928467, variance: 0.3984193801879883\n",
      "Train size: [400] hidden size: [2276] trial: 20, train_loss: 0.181936, test loss: 0.759544, bias2: 0.3614957630634308, variance: 0.39804813265800476\n",
      "Train size: [400] hidden size: [2276] trial: 21, train_loss: 0.182491, test loss: 0.759333, bias2: 0.3605972230434418, variance: 0.39873597025871277\n",
      "Train size: [400] hidden size: [2276] trial: 22, train_loss: 0.183149, test loss: 0.758528, bias2: 0.3593456745147705, variance: 0.3991823196411133\n",
      "Train size: [400] hidden size: [2276] trial: 23, train_loss: 0.183539, test loss: 0.757870, bias2: 0.3590657413005829, variance: 0.3988041579723358\n",
      "Train size: [400] hidden size: [2276] trial: 24, train_loss: 0.183212, test loss: 0.758094, bias2: 0.35913875699043274, variance: 0.39895519614219666\n",
      "Train size: [400] hidden size: [2276] trial: 25, train_loss: 0.184069, test loss: 0.754691, bias2: 0.35372307896614075, variance: 0.4009683430194855\n",
      "Train size: [400] hidden size: [2276] trial: 26, train_loss: 0.184727, test loss: 0.753917, bias2: 0.35240134596824646, variance: 0.4015158712863922\n",
      "Train size: [400] hidden size: [2276] trial: 27, train_loss: 0.184422, test loss: 0.752518, bias2: 0.35224491357803345, variance: 0.4002726078033447\n",
      "Train size: [400] hidden size: [2276] trial: 28, train_loss: 0.184408, test loss: 0.748574, bias2: 0.34776026010513306, variance: 0.40081334114074707\n",
      "Train size: [400] hidden size: [2276] trial: 29, train_loss: 0.184626, test loss: 0.749490, bias2: 0.34800001978874207, variance: 0.4014897048473358\n",
      "Train size: [400] hidden size: [2276] trial: 30, train_loss: 0.184024, test loss: 0.750109, bias2: 0.35038360953330994, variance: 0.3997251093387604\n",
      "Train size: [400] hidden size: [2276] trial: 31, train_loss: 0.184664, test loss: 0.751375, bias2: 0.3511281907558441, variance: 0.40024659037590027\n",
      "Train size: [400] hidden size: [2276] trial: 32, train_loss: 0.185390, test loss: 0.749962, bias2: 0.34842050075531006, variance: 0.4015417695045471\n",
      "Train size: [400] hidden size: [2276] trial: 33, train_loss: 0.185889, test loss: 0.749870, bias2: 0.34898048639297485, variance: 0.4008893370628357\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [2276] trial: 34, train_loss: 0.185600, test loss: 0.749596, bias2: 0.3484260141849518, variance: 0.40117040276527405\n",
      "Train size: [400] hidden size: [2276] trial: 35, train_loss: 0.185663, test loss: 0.749388, bias2: 0.34805163741111755, variance: 0.40133681893348694\n",
      "Train size: [400] hidden size: [2276] trial: 36, train_loss: 0.185225, test loss: 0.749410, bias2: 0.34761619567871094, variance: 0.4017937183380127\n",
      "Train size: [400] hidden size: [2276] trial: 37, train_loss: 0.185418, test loss: 0.749141, bias2: 0.34719616174697876, variance: 0.40194523334503174\n",
      "Train size: [400] hidden size: [2276] trial: 38, train_loss: 0.185738, test loss: 0.746685, bias2: 0.3451026678085327, variance: 0.4015825390815735\n",
      "Train size: [400] hidden size: [2276] trial: 39, train_loss: 0.186695, test loss: 0.746799, bias2: 0.3439779281616211, variance: 0.40282100439071655\n",
      "Train size: [400] hidden size: [2276] trial: 40, train_loss: 0.186137, test loss: 0.747340, bias2: 0.3437323570251465, variance: 0.40360724925994873\n",
      "Train size: [400] hidden size: [2276] trial: 41, train_loss: 0.185799, test loss: 0.747594, bias2: 0.3449831008911133, variance: 0.40261054039001465\n",
      "Train size: [400] hidden size: [2276] trial: 42, train_loss: 0.185652, test loss: 0.747991, bias2: 0.34545835852622986, variance: 0.4025331437587738\n",
      "Train size: [400] hidden size: [2276] trial: 43, train_loss: 0.185237, test loss: 0.748312, bias2: 0.3461954891681671, variance: 0.4021165668964386\n",
      "Train size: [400] hidden size: [2276] trial: 44, train_loss: 0.185302, test loss: 0.748114, bias2: 0.34568873047828674, variance: 0.4024254381656647\n",
      "Train size: [400] hidden size: [2276] trial: 45, train_loss: 0.185298, test loss: 0.749591, bias2: 0.3470643162727356, variance: 0.40252625942230225\n",
      "Train size: [400] hidden size: [2276] trial: 46, train_loss: 0.185373, test loss: 0.748497, bias2: 0.3456416726112366, variance: 0.4028555750846863\n",
      "Train size: [400] hidden size: [2276] trial: 47, train_loss: 0.185175, test loss: 0.748745, bias2: 0.34570035338401794, variance: 0.403044193983078\n",
      "Train size: [400] hidden size: [2276] trial: 48, train_loss: 0.184902, test loss: 0.748420, bias2: 0.34585732221603394, variance: 0.4025631546974182\n",
      "Train size: [400] hidden size: [2276] trial: 49, train_loss: 0.184770, test loss: 0.750018, bias2: 0.3468935787677765, variance: 0.40312448143959045\n",
      "##################################################\n",
      "Train size: [400] hidden size: [2621] trial: 0, train_loss: 0.184488, test loss: 0.666306, bias2: 0.6663062572479248, variance: 4.281802912231569e-09\n",
      "Train size: [400] hidden size: [2621] trial: 1, train_loss: 0.180587, test loss: 0.673411, bias2: 0.4748626947402954, variance: 0.19854873418807983\n",
      "Train size: [400] hidden size: [2621] trial: 2, train_loss: 0.175740, test loss: 0.714238, bias2: 0.44721102714538574, variance: 0.26702743768692017\n",
      "Train size: [400] hidden size: [2621] trial: 3, train_loss: 0.174456, test loss: 0.723542, bias2: 0.42644739151000977, variance: 0.297094464302063\n",
      "Train size: [400] hidden size: [2621] trial: 4, train_loss: 0.179182, test loss: 0.725212, bias2: 0.4099246859550476, variance: 0.3152875304222107\n",
      "Train size: [400] hidden size: [2621] trial: 5, train_loss: 0.179760, test loss: 0.728040, bias2: 0.4045250117778778, variance: 0.32351455092430115\n",
      "Train size: [400] hidden size: [2621] trial: 6, train_loss: 0.175899, test loss: 0.737670, bias2: 0.40335482358932495, variance: 0.3343154788017273\n",
      "Train size: [400] hidden size: [2621] trial: 7, train_loss: 0.179313, test loss: 0.729623, bias2: 0.3916739821434021, variance: 0.3379487991333008\n",
      "Train size: [400] hidden size: [2621] trial: 8, train_loss: 0.180627, test loss: 0.724325, bias2: 0.38033175468444824, variance: 0.3439928889274597\n",
      "Train size: [400] hidden size: [2621] trial: 9, train_loss: 0.184676, test loss: 0.725992, bias2: 0.37871330976486206, variance: 0.34727853536605835\n",
      "Train size: [400] hidden size: [2621] trial: 10, train_loss: 0.184422, test loss: 0.730369, bias2: 0.37894150614738464, variance: 0.3514276444911957\n",
      "Train size: [400] hidden size: [2621] trial: 11, train_loss: 0.184115, test loss: 0.728648, bias2: 0.3763589560985565, variance: 0.3522893488407135\n",
      "Train size: [400] hidden size: [2621] trial: 12, train_loss: 0.183578, test loss: 0.729251, bias2: 0.37451499700546265, variance: 0.35473573207855225\n",
      "Train size: [400] hidden size: [2621] trial: 13, train_loss: 0.181423, test loss: 0.728700, bias2: 0.3725453019142151, variance: 0.3561546802520752\n",
      "Train size: [400] hidden size: [2621] trial: 14, train_loss: 0.182797, test loss: 0.730112, bias2: 0.3701121509075165, variance: 0.3600001037120819\n",
      "Train size: [400] hidden size: [2621] trial: 15, train_loss: 0.181615, test loss: 0.731864, bias2: 0.3708287477493286, variance: 0.36103570461273193\n",
      "Train size: [400] hidden size: [2621] trial: 16, train_loss: 0.181037, test loss: 0.734063, bias2: 0.3708864152431488, variance: 0.3631766140460968\n",
      "Train size: [400] hidden size: [2621] trial: 17, train_loss: 0.180021, test loss: 0.733468, bias2: 0.370046466588974, variance: 0.36342117190361023\n",
      "Train size: [400] hidden size: [2621] trial: 18, train_loss: 0.178475, test loss: 0.731629, bias2: 0.3665975034236908, variance: 0.3650319278240204\n",
      "Train size: [400] hidden size: [2621] trial: 19, train_loss: 0.177939, test loss: 0.728693, bias2: 0.36354905366897583, variance: 0.36514437198638916\n",
      "Train size: [400] hidden size: [2621] trial: 20, train_loss: 0.176746, test loss: 0.730776, bias2: 0.3611120283603668, variance: 0.36966440081596375\n",
      "Train size: [400] hidden size: [2621] trial: 21, train_loss: 0.177354, test loss: 0.730570, bias2: 0.36028796434402466, variance: 0.37028247117996216\n",
      "Train size: [400] hidden size: [2621] trial: 22, train_loss: 0.177971, test loss: 0.729756, bias2: 0.36054229736328125, variance: 0.36921340227127075\n",
      "Train size: [400] hidden size: [2621] trial: 23, train_loss: 0.177901, test loss: 0.727758, bias2: 0.3584057092666626, variance: 0.3693523406982422\n",
      "Train size: [400] hidden size: [2621] trial: 24, train_loss: 0.178452, test loss: 0.728683, bias2: 0.3572526276111603, variance: 0.3714299499988556\n",
      "Train size: [400] hidden size: [2621] trial: 25, train_loss: 0.177931, test loss: 0.728341, bias2: 0.355965793132782, variance: 0.3723757266998291\n",
      "Train size: [400] hidden size: [2621] trial: 26, train_loss: 0.178648, test loss: 0.727246, bias2: 0.35408419370651245, variance: 0.37316155433654785\n",
      "Train size: [400] hidden size: [2621] trial: 27, train_loss: 0.177396, test loss: 0.726577, bias2: 0.3527505099773407, variance: 0.37382665276527405\n",
      "Train size: [400] hidden size: [2621] trial: 28, train_loss: 0.177589, test loss: 0.727499, bias2: 0.352499783039093, variance: 0.37499940395355225\n",
      "Train size: [400] hidden size: [2621] trial: 29, train_loss: 0.178005, test loss: 0.727537, bias2: 0.3518851101398468, variance: 0.3756515681743622\n",
      "Train size: [400] hidden size: [2621] trial: 30, train_loss: 0.177705, test loss: 0.727488, bias2: 0.3498401641845703, variance: 0.3776475191116333\n",
      "Train size: [400] hidden size: [2621] trial: 31, train_loss: 0.177119, test loss: 0.727747, bias2: 0.350326806306839, variance: 0.3774197995662689\n",
      "Train size: [400] hidden size: [2621] trial: 32, train_loss: 0.177128, test loss: 0.728812, bias2: 0.3510761857032776, variance: 0.37773597240448\n",
      "Train size: [400] hidden size: [2621] trial: 33, train_loss: 0.177029, test loss: 0.729383, bias2: 0.3519912660121918, variance: 0.37739136815071106\n",
      "Train size: [400] hidden size: [2621] trial: 34, train_loss: 0.177572, test loss: 0.729261, bias2: 0.3508732318878174, variance: 0.3783873915672302\n",
      "Train size: [400] hidden size: [2621] trial: 35, train_loss: 0.177658, test loss: 0.731255, bias2: 0.3518997132778168, variance: 0.37935516238212585\n",
      "Train size: [400] hidden size: [2621] trial: 36, train_loss: 0.177549, test loss: 0.730844, bias2: 0.350389301776886, variance: 0.3804543614387512\n",
      "Train size: [400] hidden size: [2621] trial: 37, train_loss: 0.178264, test loss: 0.732627, bias2: 0.34972885251045227, variance: 0.38289859890937805\n",
      "Train size: [400] hidden size: [2621] trial: 38, train_loss: 0.178011, test loss: 0.732414, bias2: 0.3485736846923828, variance: 0.3838399052619934\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [2621] trial: 39, train_loss: 0.177815, test loss: 0.732564, bias2: 0.34970903396606445, variance: 0.38285547494888306\n",
      "Train size: [400] hidden size: [2621] trial: 40, train_loss: 0.177801, test loss: 0.732734, bias2: 0.349763423204422, variance: 0.38297024369239807\n",
      "Train size: [400] hidden size: [2621] trial: 41, train_loss: 0.178286, test loss: 0.731495, bias2: 0.34852656722068787, variance: 0.3829684555530548\n",
      "Train size: [400] hidden size: [2621] trial: 42, train_loss: 0.178622, test loss: 0.731444, bias2: 0.34820419549942017, variance: 0.3832399249076843\n",
      "Train size: [400] hidden size: [2621] trial: 43, train_loss: 0.178675, test loss: 0.731505, bias2: 0.34628531336784363, variance: 0.3852197229862213\n",
      "Train size: [400] hidden size: [2621] trial: 44, train_loss: 0.178941, test loss: 0.733306, bias2: 0.34659242630004883, variance: 0.38671380281448364\n",
      "Train size: [400] hidden size: [2621] trial: 45, train_loss: 0.179045, test loss: 0.733190, bias2: 0.34572336077690125, variance: 0.387466698884964\n",
      "Train size: [400] hidden size: [2621] trial: 46, train_loss: 0.179289, test loss: 0.733389, bias2: 0.34585821628570557, variance: 0.3875312805175781\n",
      "Train size: [400] hidden size: [2621] trial: 47, train_loss: 0.179374, test loss: 0.732453, bias2: 0.34462931752204895, variance: 0.3878239095211029\n",
      "Train size: [400] hidden size: [2621] trial: 48, train_loss: 0.179381, test loss: 0.732985, bias2: 0.3447915315628052, variance: 0.3881933093070984\n",
      "Train size: [400] hidden size: [2621] trial: 49, train_loss: 0.179433, test loss: 0.732836, bias2: 0.3453589379787445, variance: 0.38747677206993103\n",
      "##################################################\n",
      "Train size: [400] hidden size: [3017] trial: 0, train_loss: 0.168100, test loss: 0.648526, bias2: 0.6485257148742676, variance: -1.1677644407015464e-09\n",
      "Train size: [400] hidden size: [3017] trial: 1, train_loss: 0.161406, test loss: 0.652901, bias2: 0.4792827367782593, variance: 0.17361827194690704\n",
      "Train size: [400] hidden size: [3017] trial: 2, train_loss: 0.163368, test loss: 0.682676, bias2: 0.4324978291988373, variance: 0.25017818808555603\n",
      "Train size: [400] hidden size: [3017] trial: 3, train_loss: 0.164484, test loss: 0.693340, bias2: 0.4123997688293457, variance: 0.2809401750564575\n",
      "Train size: [400] hidden size: [3017] trial: 4, train_loss: 0.165964, test loss: 0.704329, bias2: 0.4051990211009979, variance: 0.29913046956062317\n",
      "Train size: [400] hidden size: [3017] trial: 5, train_loss: 0.168323, test loss: 0.699041, bias2: 0.3815024495124817, variance: 0.31753838062286377\n",
      "Train size: [400] hidden size: [3017] trial: 6, train_loss: 0.173776, test loss: 0.699966, bias2: 0.3729403018951416, variance: 0.32702553272247314\n",
      "Train size: [400] hidden size: [3017] trial: 7, train_loss: 0.171644, test loss: 0.692860, bias2: 0.36298123002052307, variance: 0.32987889647483826\n",
      "Train size: [400] hidden size: [3017] trial: 8, train_loss: 0.172351, test loss: 0.693379, bias2: 0.36130958795547485, variance: 0.3320697546005249\n",
      "Train size: [400] hidden size: [3017] trial: 9, train_loss: 0.172771, test loss: 0.694701, bias2: 0.35679879784584045, variance: 0.3379017412662506\n",
      "Train size: [400] hidden size: [3017] trial: 10, train_loss: 0.173087, test loss: 0.698402, bias2: 0.3567967414855957, variance: 0.3416052460670471\n",
      "Train size: [400] hidden size: [3017] trial: 11, train_loss: 0.174251, test loss: 0.703732, bias2: 0.3542245924472809, variance: 0.34950706362724304\n",
      "Train size: [400] hidden size: [3017] trial: 12, train_loss: 0.174004, test loss: 0.703639, bias2: 0.3527366816997528, variance: 0.35090258717536926\n",
      "Train size: [400] hidden size: [3017] trial: 13, train_loss: 0.174325, test loss: 0.704317, bias2: 0.3513410687446594, variance: 0.35297590494155884\n",
      "Train size: [400] hidden size: [3017] trial: 14, train_loss: 0.173406, test loss: 0.705866, bias2: 0.3495556116104126, variance: 0.3563101291656494\n",
      "Train size: [400] hidden size: [3017] trial: 15, train_loss: 0.173182, test loss: 0.706818, bias2: 0.34891757369041443, variance: 0.3579001724720001\n",
      "Train size: [400] hidden size: [3017] trial: 16, train_loss: 0.171594, test loss: 0.709832, bias2: 0.35031986236572266, variance: 0.35951244831085205\n",
      "Train size: [400] hidden size: [3017] trial: 17, train_loss: 0.170497, test loss: 0.711904, bias2: 0.35087430477142334, variance: 0.36102962493896484\n",
      "Train size: [400] hidden size: [3017] trial: 18, train_loss: 0.170881, test loss: 0.711929, bias2: 0.34907767176628113, variance: 0.36285123229026794\n",
      "Train size: [400] hidden size: [3017] trial: 19, train_loss: 0.170811, test loss: 0.718354, bias2: 0.3515128195285797, variance: 0.3668411672115326\n",
      "Train size: [400] hidden size: [3017] trial: 20, train_loss: 0.169565, test loss: 0.717745, bias2: 0.34991779923439026, variance: 0.367826908826828\n",
      "Train size: [400] hidden size: [3017] trial: 21, train_loss: 0.169734, test loss: 0.714819, bias2: 0.3465854823589325, variance: 0.36823323369026184\n",
      "Train size: [400] hidden size: [3017] trial: 22, train_loss: 0.169904, test loss: 0.714862, bias2: 0.34445810317993164, variance: 0.37040382623672485\n",
      "Train size: [400] hidden size: [3017] trial: 23, train_loss: 0.170033, test loss: 0.715224, bias2: 0.34360453486442566, variance: 0.37161973118782043\n",
      "Train size: [400] hidden size: [3017] trial: 24, train_loss: 0.169976, test loss: 0.714185, bias2: 0.34223875403404236, variance: 0.3719462454319\n",
      "Train size: [400] hidden size: [3017] trial: 25, train_loss: 0.169581, test loss: 0.715512, bias2: 0.34255075454711914, variance: 0.37296122312545776\n",
      "Train size: [400] hidden size: [3017] trial: 26, train_loss: 0.168941, test loss: 0.716405, bias2: 0.3439566195011139, variance: 0.37244847416877747\n",
      "Train size: [400] hidden size: [3017] trial: 27, train_loss: 0.169215, test loss: 0.713749, bias2: 0.3414174020290375, variance: 0.37233206629753113\n",
      "Train size: [400] hidden size: [3017] trial: 28, train_loss: 0.169375, test loss: 0.714787, bias2: 0.34231939911842346, variance: 0.37246784567832947\n",
      "Train size: [400] hidden size: [3017] trial: 29, train_loss: 0.169431, test loss: 0.714284, bias2: 0.3417256772518158, variance: 0.37255850434303284\n",
      "Train size: [400] hidden size: [3017] trial: 30, train_loss: 0.169523, test loss: 0.717771, bias2: 0.34418320655822754, variance: 0.37358808517456055\n",
      "Train size: [400] hidden size: [3017] trial: 31, train_loss: 0.169386, test loss: 0.719445, bias2: 0.34470608830451965, variance: 0.37473931908607483\n",
      "Train size: [400] hidden size: [3017] trial: 32, train_loss: 0.169851, test loss: 0.719427, bias2: 0.3441208302974701, variance: 0.3753063380718231\n",
      "Train size: [400] hidden size: [3017] trial: 33, train_loss: 0.170318, test loss: 0.719485, bias2: 0.3433827757835388, variance: 0.3761024475097656\n",
      "Train size: [400] hidden size: [3017] trial: 34, train_loss: 0.170555, test loss: 0.718913, bias2: 0.34140968322753906, variance: 0.3775033950805664\n",
      "Train size: [400] hidden size: [3017] trial: 35, train_loss: 0.170870, test loss: 0.721356, bias2: 0.3426073491573334, variance: 0.3787483870983124\n",
      "Train size: [400] hidden size: [3017] trial: 36, train_loss: 0.170479, test loss: 0.722039, bias2: 0.34402182698249817, variance: 0.37801727652549744\n",
      "Train size: [400] hidden size: [3017] trial: 37, train_loss: 0.170303, test loss: 0.721703, bias2: 0.3433988392353058, variance: 0.37830445170402527\n",
      "Train size: [400] hidden size: [3017] trial: 38, train_loss: 0.170376, test loss: 0.722662, bias2: 0.3446650803089142, variance: 0.3779967725276947\n",
      "Train size: [400] hidden size: [3017] trial: 39, train_loss: 0.170431, test loss: 0.721536, bias2: 0.3434654176235199, variance: 0.37807056307792664\n",
      "Train size: [400] hidden size: [3017] trial: 40, train_loss: 0.170221, test loss: 0.720479, bias2: 0.34258604049682617, variance: 0.3778930902481079\n",
      "Train size: [400] hidden size: [3017] trial: 41, train_loss: 0.170510, test loss: 0.721949, bias2: 0.34197282791137695, variance: 0.37997567653656006\n",
      "Train size: [400] hidden size: [3017] trial: 42, train_loss: 0.170590, test loss: 0.721083, bias2: 0.34013837575912476, variance: 0.38094431161880493\n",
      "Train size: [400] hidden size: [3017] trial: 43, train_loss: 0.170340, test loss: 0.718215, bias2: 0.3380281627178192, variance: 0.3801864683628082\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [3017] trial: 44, train_loss: 0.170019, test loss: 0.717715, bias2: 0.33827367424964905, variance: 0.37944093346595764\n",
      "Train size: [400] hidden size: [3017] trial: 45, train_loss: 0.170495, test loss: 0.719542, bias2: 0.339143842458725, variance: 0.38039836287498474\n",
      "Train size: [400] hidden size: [3017] trial: 46, train_loss: 0.171357, test loss: 0.719045, bias2: 0.3388051986694336, variance: 0.38024014234542847\n",
      "Train size: [400] hidden size: [3017] trial: 47, train_loss: 0.170796, test loss: 0.720186, bias2: 0.34011510014533997, variance: 0.3800713121891022\n",
      "Train size: [400] hidden size: [3017] trial: 48, train_loss: 0.170518, test loss: 0.721402, bias2: 0.33998265862464905, variance: 0.38141974806785583\n",
      "Train size: [400] hidden size: [3017] trial: 49, train_loss: 0.170519, test loss: 0.720646, bias2: 0.33948421478271484, variance: 0.38116204738616943\n",
      "##################################################\n",
      "Train size: [400] hidden size: [3474] trial: 0, train_loss: 0.158931, test loss: 0.681349, bias2: 0.6813490986824036, variance: 8.563605824463139e-09\n",
      "Train size: [400] hidden size: [3474] trial: 1, train_loss: 0.165452, test loss: 0.651249, bias2: 0.4777489900588989, variance: 0.17350037395954132\n",
      "Train size: [400] hidden size: [3474] trial: 2, train_loss: 0.161990, test loss: 0.699266, bias2: 0.4517410397529602, variance: 0.2475246638059616\n",
      "Train size: [400] hidden size: [3474] trial: 3, train_loss: 0.159594, test loss: 0.690685, bias2: 0.4128085970878601, variance: 0.2778761386871338\n",
      "Train size: [400] hidden size: [3474] trial: 4, train_loss: 0.159894, test loss: 0.697843, bias2: 0.4012252688407898, variance: 0.2966175675392151\n",
      "Train size: [400] hidden size: [3474] trial: 5, train_loss: 0.160664, test loss: 0.705337, bias2: 0.39145341515541077, variance: 0.3138836920261383\n",
      "Train size: [400] hidden size: [3474] trial: 6, train_loss: 0.160222, test loss: 0.701996, bias2: 0.3850562572479248, variance: 0.3169392943382263\n",
      "Train size: [400] hidden size: [3474] trial: 7, train_loss: 0.161019, test loss: 0.704520, bias2: 0.37524890899658203, variance: 0.32927143573760986\n",
      "Train size: [400] hidden size: [3474] trial: 8, train_loss: 0.162633, test loss: 0.707745, bias2: 0.37723833322525024, variance: 0.33050644397735596\n",
      "Train size: [400] hidden size: [3474] trial: 9, train_loss: 0.165224, test loss: 0.716846, bias2: 0.37761184573173523, variance: 0.3392341434955597\n",
      "Train size: [400] hidden size: [3474] trial: 10, train_loss: 0.167889, test loss: 0.717998, bias2: 0.37325406074523926, variance: 0.34474390745162964\n",
      "Train size: [400] hidden size: [3474] trial: 11, train_loss: 0.166519, test loss: 0.719874, bias2: 0.37616974115371704, variance: 0.3437044024467468\n",
      "Train size: [400] hidden size: [3474] trial: 12, train_loss: 0.165537, test loss: 0.714886, bias2: 0.37258321046829224, variance: 0.3423025608062744\n",
      "Train size: [400] hidden size: [3474] trial: 13, train_loss: 0.165588, test loss: 0.713801, bias2: 0.3682469129562378, variance: 0.3455541133880615\n",
      "Train size: [400] hidden size: [3474] trial: 14, train_loss: 0.166275, test loss: 0.712351, bias2: 0.3631172776222229, variance: 0.3492335081100464\n",
      "Train size: [400] hidden size: [3474] trial: 15, train_loss: 0.167045, test loss: 0.712527, bias2: 0.3598482012748718, variance: 0.3526788353919983\n",
      "Train size: [400] hidden size: [3474] trial: 16, train_loss: 0.168564, test loss: 0.713632, bias2: 0.3582121431827545, variance: 0.3554198443889618\n",
      "Train size: [400] hidden size: [3474] trial: 17, train_loss: 0.168564, test loss: 0.713047, bias2: 0.3557320833206177, variance: 0.3573150634765625\n",
      "Train size: [400] hidden size: [3474] trial: 18, train_loss: 0.170202, test loss: 0.716575, bias2: 0.354617178440094, variance: 0.36195796728134155\n",
      "Train size: [400] hidden size: [3474] trial: 19, train_loss: 0.171637, test loss: 0.716222, bias2: 0.35250550508499146, variance: 0.3637160062789917\n",
      "Train size: [400] hidden size: [3474] trial: 20, train_loss: 0.170921, test loss: 0.712857, bias2: 0.35063785314559937, variance: 0.36221903562545776\n",
      "Train size: [400] hidden size: [3474] trial: 21, train_loss: 0.170374, test loss: 0.714546, bias2: 0.35288283228874207, variance: 0.36166271567344666\n",
      "Train size: [400] hidden size: [3474] trial: 22, train_loss: 0.170363, test loss: 0.713289, bias2: 0.35158246755599976, variance: 0.3617069125175476\n",
      "Train size: [400] hidden size: [3474] trial: 23, train_loss: 0.170635, test loss: 0.712138, bias2: 0.3495565354824066, variance: 0.36258140206336975\n",
      "Train size: [400] hidden size: [3474] trial: 24, train_loss: 0.170012, test loss: 0.714659, bias2: 0.35113510489463806, variance: 0.36352410912513733\n",
      "Train size: [400] hidden size: [3474] trial: 25, train_loss: 0.169764, test loss: 0.714495, bias2: 0.3508641719818115, variance: 0.3636311888694763\n",
      "Train size: [400] hidden size: [3474] trial: 26, train_loss: 0.170813, test loss: 0.712678, bias2: 0.3482663929462433, variance: 0.3644119203090668\n",
      "Train size: [400] hidden size: [3474] trial: 27, train_loss: 0.170711, test loss: 0.710381, bias2: 0.34644296765327454, variance: 0.36393818259239197\n",
      "Train size: [400] hidden size: [3474] trial: 28, train_loss: 0.170869, test loss: 0.709358, bias2: 0.34422874450683594, variance: 0.36512887477874756\n",
      "Train size: [400] hidden size: [3474] trial: 29, train_loss: 0.171529, test loss: 0.709005, bias2: 0.3427569568157196, variance: 0.36624768376350403\n",
      "Train size: [400] hidden size: [3474] trial: 30, train_loss: 0.170968, test loss: 0.710253, bias2: 0.34349727630615234, variance: 0.3667556047439575\n",
      "Train size: [400] hidden size: [3474] trial: 31, train_loss: 0.171144, test loss: 0.709270, bias2: 0.34188345074653625, variance: 0.367386132478714\n",
      "Train size: [400] hidden size: [3474] trial: 32, train_loss: 0.171494, test loss: 0.710572, bias2: 0.3435761332511902, variance: 0.36699604988098145\n",
      "Train size: [400] hidden size: [3474] trial: 33, train_loss: 0.171994, test loss: 0.710708, bias2: 0.34230563044548035, variance: 0.3684028685092926\n",
      "Train size: [400] hidden size: [3474] trial: 34, train_loss: 0.172065, test loss: 0.709183, bias2: 0.341164767742157, variance: 0.36801832914352417\n",
      "Train size: [400] hidden size: [3474] trial: 35, train_loss: 0.171648, test loss: 0.707527, bias2: 0.3413066864013672, variance: 0.36622053384780884\n",
      "Train size: [400] hidden size: [3474] trial: 36, train_loss: 0.171991, test loss: 0.707232, bias2: 0.3401601314544678, variance: 0.36707180738449097\n",
      "Train size: [400] hidden size: [3474] trial: 37, train_loss: 0.171754, test loss: 0.707792, bias2: 0.3397056758403778, variance: 0.3680858910083771\n",
      "Train size: [400] hidden size: [3474] trial: 38, train_loss: 0.172290, test loss: 0.706046, bias2: 0.33851057291030884, variance: 0.3675357699394226\n",
      "Train size: [400] hidden size: [3474] trial: 39, train_loss: 0.172665, test loss: 0.704830, bias2: 0.33676543831825256, variance: 0.36806413531303406\n",
      "Train size: [400] hidden size: [3474] trial: 40, train_loss: 0.172580, test loss: 0.704883, bias2: 0.33659955859184265, variance: 0.36828359961509705\n",
      "Train size: [400] hidden size: [3474] trial: 41, train_loss: 0.172277, test loss: 0.704339, bias2: 0.33637821674346924, variance: 0.367961049079895\n",
      "Train size: [400] hidden size: [3474] trial: 42, train_loss: 0.171942, test loss: 0.704726, bias2: 0.33698850870132446, variance: 0.36773747205734253\n",
      "Train size: [400] hidden size: [3474] trial: 43, train_loss: 0.171324, test loss: 0.704792, bias2: 0.337056040763855, variance: 0.36773574352264404\n",
      "Train size: [400] hidden size: [3474] trial: 44, train_loss: 0.171428, test loss: 0.706401, bias2: 0.33778685331344604, variance: 0.3686145544052124\n",
      "Train size: [400] hidden size: [3474] trial: 45, train_loss: 0.171629, test loss: 0.705510, bias2: 0.3363598585128784, variance: 0.36915016174316406\n",
      "Train size: [400] hidden size: [3474] trial: 46, train_loss: 0.171341, test loss: 0.704836, bias2: 0.33632880449295044, variance: 0.36850714683532715\n",
      "Train size: [400] hidden size: [3474] trial: 47, train_loss: 0.171369, test loss: 0.703848, bias2: 0.3350594937801361, variance: 0.3687882125377655\n",
      "Train size: [400] hidden size: [3474] trial: 48, train_loss: 0.171523, test loss: 0.704558, bias2: 0.3344244360923767, variance: 0.37013375759124756\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [3474] trial: 49, train_loss: 0.171648, test loss: 0.705972, bias2: 0.33541324734687805, variance: 0.37055906653404236\n",
      "##################################################\n",
      "Train size: [400] hidden size: [4000] trial: 0, train_loss: 0.164026, test loss: 0.666356, bias2: 0.6663554906845093, variance: 4.6710577628061856e-09\n",
      "Train size: [400] hidden size: [4000] trial: 1, train_loss: 0.170545, test loss: 0.696273, bias2: 0.5200822949409485, variance: 0.17619077861309052\n",
      "Train size: [400] hidden size: [4000] trial: 2, train_loss: 0.161616, test loss: 0.676099, bias2: 0.44568389654159546, variance: 0.2304147332906723\n",
      "Train size: [400] hidden size: [4000] trial: 3, train_loss: 0.163345, test loss: 0.689343, bias2: 0.4290739893913269, variance: 0.26026856899261475\n",
      "Train size: [400] hidden size: [4000] trial: 4, train_loss: 0.167074, test loss: 0.682072, bias2: 0.39641448855400085, variance: 0.2856576144695282\n",
      "Train size: [400] hidden size: [4000] trial: 5, train_loss: 0.164046, test loss: 0.686468, bias2: 0.3880188763141632, variance: 0.2984495460987091\n",
      "Train size: [400] hidden size: [4000] trial: 6, train_loss: 0.168229, test loss: 0.689332, bias2: 0.3789905607700348, variance: 0.31034108996391296\n",
      "Train size: [400] hidden size: [4000] trial: 7, train_loss: 0.166806, test loss: 0.678676, bias2: 0.3657096326351166, variance: 0.31296661496162415\n",
      "Train size: [400] hidden size: [4000] trial: 8, train_loss: 0.168700, test loss: 0.679192, bias2: 0.35688745975494385, variance: 0.32230448722839355\n",
      "Train size: [400] hidden size: [4000] trial: 9, train_loss: 0.168041, test loss: 0.680909, bias2: 0.35234391689300537, variance: 0.3285646438598633\n",
      "Train size: [400] hidden size: [4000] trial: 10, train_loss: 0.167394, test loss: 0.683301, bias2: 0.3519514501094818, variance: 0.3313499987125397\n",
      "Train size: [400] hidden size: [4000] trial: 11, train_loss: 0.166291, test loss: 0.686104, bias2: 0.35111913084983826, variance: 0.3349844515323639\n",
      "Train size: [400] hidden size: [4000] trial: 12, train_loss: 0.165702, test loss: 0.680480, bias2: 0.34506282210350037, variance: 0.3354171812534332\n",
      "Train size: [400] hidden size: [4000] trial: 13, train_loss: 0.164025, test loss: 0.681269, bias2: 0.3412366807460785, variance: 0.34003207087516785\n",
      "Train size: [400] hidden size: [4000] trial: 14, train_loss: 0.164123, test loss: 0.682606, bias2: 0.339245468378067, variance: 0.3433610498905182\n",
      "Train size: [400] hidden size: [4000] trial: 15, train_loss: 0.164046, test loss: 0.686493, bias2: 0.3407769501209259, variance: 0.34571602940559387\n",
      "Train size: [400] hidden size: [4000] trial: 16, train_loss: 0.164765, test loss: 0.688064, bias2: 0.33927178382873535, variance: 0.34879177808761597\n",
      "Train size: [400] hidden size: [4000] trial: 17, train_loss: 0.163957, test loss: 0.687662, bias2: 0.3383259177207947, variance: 0.34933584928512573\n",
      "Train size: [400] hidden size: [4000] trial: 18, train_loss: 0.164572, test loss: 0.686468, bias2: 0.33873170614242554, variance: 0.3477365970611572\n",
      "Train size: [400] hidden size: [4000] trial: 19, train_loss: 0.164990, test loss: 0.687812, bias2: 0.3393433094024658, variance: 0.3484688997268677\n",
      "Train size: [400] hidden size: [4000] trial: 20, train_loss: 0.166913, test loss: 0.688045, bias2: 0.33869969844818115, variance: 0.3493450880050659\n",
      "Train size: [400] hidden size: [4000] trial: 21, train_loss: 0.167252, test loss: 0.692312, bias2: 0.34045496582984924, variance: 0.35185685753822327\n",
      "Train size: [400] hidden size: [4000] trial: 22, train_loss: 0.167270, test loss: 0.692411, bias2: 0.3384702205657959, variance: 0.3539409637451172\n",
      "Train size: [400] hidden size: [4000] trial: 23, train_loss: 0.166749, test loss: 0.694255, bias2: 0.33852601051330566, variance: 0.355729341506958\n",
      "Train size: [400] hidden size: [4000] trial: 24, train_loss: 0.166512, test loss: 0.692388, bias2: 0.338189035654068, variance: 0.3541986048221588\n",
      "Train size: [400] hidden size: [4000] trial: 25, train_loss: 0.166139, test loss: 0.692477, bias2: 0.3367709815502167, variance: 0.35570576786994934\n",
      "Train size: [400] hidden size: [4000] trial: 26, train_loss: 0.166838, test loss: 0.691664, bias2: 0.3357713520526886, variance: 0.35589298605918884\n",
      "Train size: [400] hidden size: [4000] trial: 27, train_loss: 0.167325, test loss: 0.692422, bias2: 0.3355209529399872, variance: 0.35690101981163025\n",
      "Train size: [400] hidden size: [4000] trial: 28, train_loss: 0.168462, test loss: 0.693428, bias2: 0.33413562178611755, variance: 0.35929253697395325\n",
      "Train size: [400] hidden size: [4000] trial: 29, train_loss: 0.167441, test loss: 0.693213, bias2: 0.3335462510585785, variance: 0.3596670925617218\n",
      "Train size: [400] hidden size: [4000] trial: 30, train_loss: 0.167919, test loss: 0.692623, bias2: 0.33256766200065613, variance: 0.36005493998527527\n",
      "Train size: [400] hidden size: [4000] trial: 31, train_loss: 0.167623, test loss: 0.694706, bias2: 0.3340284824371338, variance: 0.36067765951156616\n",
      "Train size: [400] hidden size: [4000] trial: 32, train_loss: 0.167271, test loss: 0.694506, bias2: 0.3329872786998749, variance: 0.361518532037735\n",
      "Train size: [400] hidden size: [4000] trial: 33, train_loss: 0.166644, test loss: 0.696496, bias2: 0.33455657958984375, variance: 0.36193913221359253\n",
      "Train size: [400] hidden size: [4000] trial: 34, train_loss: 0.166345, test loss: 0.695913, bias2: 0.3350604772567749, variance: 0.36085253953933716\n",
      "Train size: [400] hidden size: [4000] trial: 35, train_loss: 0.166495, test loss: 0.696140, bias2: 0.3352227807044983, variance: 0.3609170913696289\n",
      "Train size: [400] hidden size: [4000] trial: 36, train_loss: 0.166466, test loss: 0.696671, bias2: 0.3359278440475464, variance: 0.3607432246208191\n",
      "Train size: [400] hidden size: [4000] trial: 37, train_loss: 0.166855, test loss: 0.696715, bias2: 0.33581286668777466, variance: 0.3609020709991455\n",
      "Train size: [400] hidden size: [4000] trial: 38, train_loss: 0.166452, test loss: 0.696104, bias2: 0.3356020450592041, variance: 0.360501766204834\n",
      "Train size: [400] hidden size: [4000] trial: 39, train_loss: 0.166818, test loss: 0.696220, bias2: 0.33439505100250244, variance: 0.36182504892349243\n",
      "Train size: [400] hidden size: [4000] trial: 40, train_loss: 0.166560, test loss: 0.696249, bias2: 0.33505529165267944, variance: 0.36119353771209717\n",
      "Train size: [400] hidden size: [4000] trial: 41, train_loss: 0.166483, test loss: 0.696947, bias2: 0.3358754515647888, variance: 0.3610711693763733\n",
      "Train size: [400] hidden size: [4000] trial: 42, train_loss: 0.166850, test loss: 0.695393, bias2: 0.33418434858322144, variance: 0.36120837926864624\n",
      "Train size: [400] hidden size: [4000] trial: 43, train_loss: 0.166799, test loss: 0.693354, bias2: 0.33318522572517395, variance: 0.3601689040660858\n",
      "Train size: [400] hidden size: [4000] trial: 44, train_loss: 0.166353, test loss: 0.693707, bias2: 0.33323854207992554, variance: 0.3604680895805359\n",
      "Train size: [400] hidden size: [4000] trial: 45, train_loss: 0.166903, test loss: 0.693562, bias2: 0.33230236172676086, variance: 0.3612591326236725\n",
      "Train size: [400] hidden size: [4000] trial: 46, train_loss: 0.166847, test loss: 0.693099, bias2: 0.33213913440704346, variance: 0.360959529876709\n",
      "Train size: [400] hidden size: [4000] trial: 47, train_loss: 0.167371, test loss: 0.692531, bias2: 0.33122390508651733, variance: 0.3613075017929077\n",
      "Train size: [400] hidden size: [4000] trial: 48, train_loss: 0.166947, test loss: 0.693326, bias2: 0.33185845613479614, variance: 0.3614673614501953\n",
      "Train size: [400] hidden size: [4000] trial: 49, train_loss: 0.167313, test loss: 0.693394, bias2: 0.33205854892730713, variance: 0.3613351583480835\n",
      "##################################################\n"
     ]
    }
   ],
   "source": [
    "run_exps_ridge(train_sizes, N_Ds, P_Ns, beta, test_size, feature_dim, num_classes, num_trials, coef,\n",
    "             outdir, 'singleNN_output.csv', SNR= SNR, K = 1, F_norm = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [4] trial: 0, train_loss: 1.926988, test loss: 1.005509, bias2: 1.0055092573165894, variance: 2.5088688071495113e-11\n",
      "Train size: [400] hidden size: [4] trial: 1, train_loss: 1.909421, test loss: 1.005395, bias2: 1.004164457321167, variance: 0.0012300811940804124\n",
      "Train size: [400] hidden size: [4] trial: 2, train_loss: 1.924670, test loss: 1.007745, bias2: 1.0021342039108276, variance: 0.005610555876046419\n",
      "Train size: [400] hidden size: [4] trial: 3, train_loss: 1.924726, test loss: 1.009335, bias2: 1.0031623840332031, variance: 0.006172841880470514\n",
      "Train size: [400] hidden size: [4] trial: 4, train_loss: 1.912132, test loss: 1.006996, bias2: 1.0009149312973022, variance: 0.006081241182982922\n",
      "Train size: [400] hidden size: [4] trial: 5, train_loss: 1.905424, test loss: 1.008016, bias2: 1.0019820928573608, variance: 0.006033885292708874\n",
      "Train size: [400] hidden size: [4] trial: 6, train_loss: 1.913150, test loss: 1.008038, bias2: 1.0026092529296875, variance: 0.005428565666079521\n",
      "Train size: [400] hidden size: [4] trial: 7, train_loss: 1.916347, test loss: 1.008979, bias2: 1.0035768747329712, variance: 0.005402409005910158\n",
      "Train size: [400] hidden size: [4] trial: 8, train_loss: 1.924973, test loss: 1.009565, bias2: 1.0043684244155884, variance: 0.0051963794976472855\n",
      "Train size: [400] hidden size: [4] trial: 9, train_loss: 1.913872, test loss: 1.008927, bias2: 1.0035436153411865, variance: 0.005383895710110664\n",
      "Train size: [400] hidden size: [4] trial: 10, train_loss: 1.915436, test loss: 1.008801, bias2: 1.0030474662780762, variance: 0.005753613077104092\n",
      "Train size: [400] hidden size: [4] trial: 11, train_loss: 1.918703, test loss: 1.008650, bias2: 1.0029633045196533, variance: 0.005686466582119465\n",
      "Train size: [400] hidden size: [4] trial: 12, train_loss: 1.931979, test loss: 1.008200, bias2: 1.0025790929794312, variance: 0.005620792042464018\n",
      "Train size: [400] hidden size: [4] trial: 13, train_loss: 1.941944, test loss: 1.008157, bias2: 1.0028259754180908, variance: 0.005331065040081739\n",
      "Train size: [400] hidden size: [4] trial: 14, train_loss: 1.954402, test loss: 1.007903, bias2: 1.0026569366455078, variance: 0.005246400833129883\n",
      "Train size: [400] hidden size: [4] trial: 15, train_loss: 1.933846, test loss: 1.008666, bias2: 1.0032379627227783, variance: 0.005427861586213112\n",
      "Train size: [400] hidden size: [4] trial: 16, train_loss: 1.933285, test loss: 1.008245, bias2: 1.0020982027053833, variance: 0.006147162523120642\n",
      "Train size: [400] hidden size: [4] trial: 17, train_loss: 1.929733, test loss: 1.008085, bias2: 1.0018553733825684, variance: 0.006229456048458815\n",
      "Train size: [400] hidden size: [4] trial: 18, train_loss: 1.938645, test loss: 1.008143, bias2: 1.0021071434020996, variance: 0.006035765167325735\n",
      "Train size: [400] hidden size: [4] trial: 19, train_loss: 1.935504, test loss: 1.008219, bias2: 1.0014785528182983, variance: 0.006739987060427666\n",
      "Train size: [400] hidden size: [4] trial: 20, train_loss: 1.933670, test loss: 1.008261, bias2: 1.001579999923706, variance: 0.006680633407086134\n",
      "Train size: [400] hidden size: [4] trial: 21, train_loss: 1.938865, test loss: 1.008307, bias2: 1.0014972686767578, variance: 0.006809657905250788\n",
      "Train size: [400] hidden size: [4] trial: 22, train_loss: 1.947125, test loss: 1.008290, bias2: 1.0017211437225342, variance: 0.006568701006472111\n",
      "Train size: [400] hidden size: [4] trial: 23, train_loss: 1.948764, test loss: 1.008422, bias2: 1.00194251537323, variance: 0.006479113362729549\n",
      "Train size: [400] hidden size: [4] trial: 24, train_loss: 1.949389, test loss: 1.008383, bias2: 1.0020737648010254, variance: 0.006309186108410358\n",
      "Train size: [400] hidden size: [4] trial: 25, train_loss: 1.946751, test loss: 1.008663, bias2: 1.0022600889205933, variance: 0.006402892060577869\n",
      "Train size: [400] hidden size: [4] trial: 26, train_loss: 1.955788, test loss: 1.008689, bias2: 1.0023514032363892, variance: 0.006337124388664961\n",
      "Train size: [400] hidden size: [4] trial: 27, train_loss: 1.963102, test loss: 1.008790, bias2: 1.0025912523269653, variance: 0.006199236493557692\n",
      "Train size: [400] hidden size: [4] trial: 28, train_loss: 1.968443, test loss: 1.008806, bias2: 1.0024813413619995, variance: 0.006324895191937685\n",
      "Train size: [400] hidden size: [4] trial: 29, train_loss: 1.981008, test loss: 1.008976, bias2: 1.0025978088378906, variance: 0.0063785286620259285\n",
      "Train size: [400] hidden size: [4] trial: 30, train_loss: 1.985266, test loss: 1.008745, bias2: 1.0020980834960938, variance: 0.006646859925240278\n",
      "Train size: [400] hidden size: [4] trial: 31, train_loss: 1.979804, test loss: 1.008690, bias2: 1.0020757913589478, variance: 0.006614216137677431\n",
      "Train size: [400] hidden size: [4] trial: 32, train_loss: 1.980363, test loss: 1.008994, bias2: 1.002103328704834, variance: 0.006890829186886549\n",
      "Train size: [400] hidden size: [4] trial: 33, train_loss: 1.980056, test loss: 1.009026, bias2: 1.0022151470184326, variance: 0.00681057944893837\n",
      "Train size: [400] hidden size: [4] trial: 34, train_loss: 1.984341, test loss: 1.009205, bias2: 1.0023653507232666, variance: 0.006840008310973644\n",
      "Train size: [400] hidden size: [4] trial: 35, train_loss: 1.988769, test loss: 1.009177, bias2: 1.0022422075271606, variance: 0.006934782024472952\n",
      "Train size: [400] hidden size: [4] trial: 36, train_loss: 1.985057, test loss: 1.009181, bias2: 1.0023826360702515, variance: 0.006798760034143925\n",
      "Train size: [400] hidden size: [4] trial: 37, train_loss: 1.982603, test loss: 1.009277, bias2: 1.0025417804718018, variance: 0.006735334638506174\n",
      "Train size: [400] hidden size: [4] trial: 38, train_loss: 1.981560, test loss: 1.008993, bias2: 1.0020391941070557, variance: 0.006954165641218424\n",
      "Train size: [400] hidden size: [4] trial: 39, train_loss: 1.979092, test loss: 1.008981, bias2: 1.0020581483840942, variance: 0.006923008244484663\n",
      "Train size: [400] hidden size: [4] trial: 40, train_loss: 1.971802, test loss: 1.008677, bias2: 1.001746654510498, variance: 0.006930155213922262\n",
      "Train size: [400] hidden size: [4] trial: 41, train_loss: 1.974488, test loss: 1.008599, bias2: 1.001734733581543, variance: 0.006864562164992094\n",
      "Train size: [400] hidden size: [4] trial: 42, train_loss: 1.982026, test loss: 1.008547, bias2: 1.0017808675765991, variance: 0.0067664277739822865\n",
      "Train size: [400] hidden size: [4] trial: 43, train_loss: 1.980926, test loss: 1.008683, bias2: 1.0018784999847412, variance: 0.006804667413234711\n",
      "Train size: [400] hidden size: [4] trial: 44, train_loss: 1.979826, test loss: 1.008720, bias2: 1.0020005702972412, variance: 0.006719033233821392\n",
      "Train size: [400] hidden size: [4] trial: 45, train_loss: 1.984304, test loss: 1.008668, bias2: 1.0018380880355835, variance: 0.006829466205090284\n",
      "Train size: [400] hidden size: [4] trial: 46, train_loss: 1.989386, test loss: 1.008625, bias2: 1.001783013343811, variance: 0.0068421028554439545\n",
      "Train size: [400] hidden size: [4] trial: 47, train_loss: 1.990845, test loss: 1.008652, bias2: 1.0017973184585571, variance: 0.006854790262877941\n",
      "Train size: [400] hidden size: [4] trial: 48, train_loss: 1.988613, test loss: 1.008540, bias2: 1.0016523599624634, variance: 0.006887509487569332\n",
      "Train size: [400] hidden size: [4] trial: 49, train_loss: 1.988989, test loss: 1.008611, bias2: 1.0015231370925903, variance: 0.00708801718428731\n",
      "##################################################\n",
      "Train size: [400] hidden size: [5] trial: 0, train_loss: 2.241183, test loss: 1.001681, bias2: 1.0016812086105347, variance: 4.865684938293313e-11\n",
      "Train size: [400] hidden size: [5] trial: 1, train_loss: 2.088420, test loss: 1.005285, bias2: 1.0041084289550781, variance: 0.0011764252558350563\n",
      "Train size: [400] hidden size: [5] trial: 2, train_loss: 2.103956, test loss: 1.006700, bias2: 1.0037565231323242, variance: 0.002943083643913269\n",
      "Train size: [400] hidden size: [5] trial: 3, train_loss: 2.047113, test loss: 1.007836, bias2: 1.0042803287506104, variance: 0.00355553044937551\n",
      "Train size: [400] hidden size: [5] trial: 4, train_loss: 2.047628, test loss: 1.008110, bias2: 1.004191279411316, variance: 0.003918623086065054\n",
      "Train size: [400] hidden size: [5] trial: 5, train_loss: 2.018979, test loss: 1.009426, bias2: 1.0053422451019287, variance: 0.004083746112883091\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [5] trial: 6, train_loss: 1.982598, test loss: 1.009019, bias2: 1.0042155981063843, variance: 0.0048028863966465\n",
      "Train size: [400] hidden size: [5] trial: 7, train_loss: 1.962745, test loss: 1.008823, bias2: 1.0040282011032104, variance: 0.004794908221811056\n",
      "Train size: [400] hidden size: [5] trial: 8, train_loss: 1.971198, test loss: 1.010026, bias2: 1.0051714181900024, variance: 0.004854341968894005\n",
      "Train size: [400] hidden size: [5] trial: 9, train_loss: 1.995219, test loss: 1.009363, bias2: 1.0045764446258545, variance: 0.004786611534655094\n",
      "Train size: [400] hidden size: [5] trial: 10, train_loss: 1.997020, test loss: 1.009514, bias2: 1.0048052072525024, variance: 0.004708353895694017\n",
      "Train size: [400] hidden size: [5] trial: 11, train_loss: 1.987588, test loss: 1.008675, bias2: 1.0034862756729126, variance: 0.00518827885389328\n",
      "Train size: [400] hidden size: [5] trial: 12, train_loss: 1.993133, test loss: 1.008704, bias2: 1.0029399394989014, variance: 0.005763980094343424\n",
      "Train size: [400] hidden size: [5] trial: 13, train_loss: 1.997534, test loss: 1.008566, bias2: 1.0031250715255737, variance: 0.005440802313387394\n",
      "Train size: [400] hidden size: [5] trial: 14, train_loss: 1.995867, test loss: 1.008539, bias2: 1.0029948949813843, variance: 0.005543773993849754\n",
      "Train size: [400] hidden size: [5] trial: 15, train_loss: 1.982753, test loss: 1.008592, bias2: 1.003292441368103, variance: 0.005299366544932127\n",
      "Train size: [400] hidden size: [5] trial: 16, train_loss: 1.981260, test loss: 1.009267, bias2: 1.0036743879318237, variance: 0.005592969711869955\n",
      "Train size: [400] hidden size: [5] trial: 17, train_loss: 1.970123, test loss: 1.008955, bias2: 1.0032708644866943, variance: 0.005683674477040768\n",
      "Train size: [400] hidden size: [5] trial: 18, train_loss: 1.978948, test loss: 1.009195, bias2: 1.0036340951919556, variance: 0.005560738034546375\n",
      "Train size: [400] hidden size: [5] trial: 19, train_loss: 1.975897, test loss: 1.009495, bias2: 1.003994107246399, variance: 0.005500686354935169\n",
      "Train size: [400] hidden size: [5] trial: 20, train_loss: 1.969098, test loss: 1.008416, bias2: 1.0027806758880615, variance: 0.005635779816657305\n",
      "Train size: [400] hidden size: [5] trial: 21, train_loss: 1.975204, test loss: 1.007912, bias2: 1.0022255182266235, variance: 0.005686874035745859\n",
      "Train size: [400] hidden size: [5] trial: 22, train_loss: 1.979656, test loss: 1.007946, bias2: 1.0024687051773071, variance: 0.005477708298712969\n",
      "Train size: [400] hidden size: [5] trial: 23, train_loss: 1.979184, test loss: 1.008266, bias2: 1.002104640007019, variance: 0.006161361932754517\n",
      "Train size: [400] hidden size: [5] trial: 24, train_loss: 1.977314, test loss: 1.008334, bias2: 1.0023372173309326, variance: 0.00599717115983367\n",
      "Train size: [400] hidden size: [5] trial: 25, train_loss: 1.984059, test loss: 1.008357, bias2: 1.0024089813232422, variance: 0.005947678349912167\n",
      "Train size: [400] hidden size: [5] trial: 26, train_loss: 1.983461, test loss: 1.008332, bias2: 1.0025118589401245, variance: 0.0058197686448693275\n",
      "Train size: [400] hidden size: [5] trial: 27, train_loss: 1.973039, test loss: 1.008242, bias2: 1.0023610591888428, variance: 0.0058806538581848145\n",
      "Train size: [400] hidden size: [5] trial: 28, train_loss: 1.975953, test loss: 1.008377, bias2: 1.0024638175964355, variance: 0.005913428496569395\n",
      "Train size: [400] hidden size: [5] trial: 29, train_loss: 1.969884, test loss: 1.008276, bias2: 1.0024912357330322, variance: 0.005784438457340002\n",
      "Train size: [400] hidden size: [5] trial: 30, train_loss: 1.976111, test loss: 1.008244, bias2: 1.0024852752685547, variance: 0.005759024526923895\n",
      "Train size: [400] hidden size: [5] trial: 31, train_loss: 1.969380, test loss: 1.008306, bias2: 1.0025838613510132, variance: 0.005722023081034422\n",
      "Train size: [400] hidden size: [5] trial: 32, train_loss: 1.965870, test loss: 1.008414, bias2: 1.0027616024017334, variance: 0.00565221905708313\n",
      "Train size: [400] hidden size: [5] trial: 33, train_loss: 1.958779, test loss: 1.008145, bias2: 1.002572774887085, variance: 0.00557187432423234\n",
      "Train size: [400] hidden size: [5] trial: 34, train_loss: 1.967217, test loss: 1.008103, bias2: 1.0025460720062256, variance: 0.0055567123927176\n",
      "Train size: [400] hidden size: [5] trial: 35, train_loss: 1.963399, test loss: 1.008076, bias2: 1.002634882926941, variance: 0.005441417917609215\n",
      "Train size: [400] hidden size: [5] trial: 36, train_loss: 1.964693, test loss: 1.007939, bias2: 1.002455711364746, variance: 0.005483520217239857\n",
      "Train size: [400] hidden size: [5] trial: 37, train_loss: 1.960097, test loss: 1.008271, bias2: 1.0026707649230957, variance: 0.005599924363195896\n",
      "Train size: [400] hidden size: [5] trial: 38, train_loss: 1.959928, test loss: 1.008102, bias2: 1.0024268627166748, variance: 0.005674948915839195\n",
      "Train size: [400] hidden size: [5] trial: 39, train_loss: 1.954143, test loss: 1.008285, bias2: 1.0023990869522095, variance: 0.005885574035346508\n",
      "Train size: [400] hidden size: [5] trial: 40, train_loss: 1.954420, test loss: 1.008239, bias2: 1.0024690628051758, variance: 0.00577026791870594\n",
      "Train size: [400] hidden size: [5] trial: 41, train_loss: 1.951174, test loss: 1.007911, bias2: 1.0019298791885376, variance: 0.005981582682579756\n",
      "Train size: [400] hidden size: [5] trial: 42, train_loss: 1.948878, test loss: 1.008126, bias2: 1.002198338508606, variance: 0.005927528720349073\n",
      "Train size: [400] hidden size: [5] trial: 43, train_loss: 1.950459, test loss: 1.008647, bias2: 1.00247323513031, variance: 0.006174155976623297\n",
      "Train size: [400] hidden size: [5] trial: 44, train_loss: 1.953492, test loss: 1.008581, bias2: 1.0024176836013794, variance: 0.006163580343127251\n",
      "Train size: [400] hidden size: [5] trial: 45, train_loss: 1.959585, test loss: 1.008522, bias2: 1.0024428367614746, variance: 0.006079485174268484\n",
      "Train size: [400] hidden size: [5] trial: 46, train_loss: 1.957052, test loss: 1.008608, bias2: 1.002548336982727, variance: 0.006059946957975626\n",
      "Train size: [400] hidden size: [5] trial: 47, train_loss: 1.957552, test loss: 1.008586, bias2: 1.002569556236267, variance: 0.006016220897436142\n",
      "Train size: [400] hidden size: [5] trial: 48, train_loss: 1.958079, test loss: 1.008482, bias2: 1.0024688243865967, variance: 0.006012867204844952\n",
      "Train size: [400] hidden size: [5] trial: 49, train_loss: 1.960924, test loss: 1.008440, bias2: 1.0024993419647217, variance: 0.0059408205561339855\n",
      "##################################################\n",
      "Train size: [400] hidden size: [6] trial: 0, train_loss: 2.099843, test loss: 1.011108, bias2: 1.0111079216003418, variance: -6.690317050361827e-11\n",
      "Train size: [400] hidden size: [6] trial: 1, train_loss: 2.138603, test loss: 1.008206, bias2: 1.0049959421157837, variance: 0.00320980092510581\n",
      "Train size: [400] hidden size: [6] trial: 2, train_loss: 2.179610, test loss: 0.998445, bias2: 0.9918450117111206, variance: 0.006600106135010719\n",
      "Train size: [400] hidden size: [6] trial: 3, train_loss: 2.102132, test loss: 1.002627, bias2: 0.9964437484741211, variance: 0.006183752324432135\n",
      "Train size: [400] hidden size: [6] trial: 4, train_loss: 2.077302, test loss: 1.003340, bias2: 0.9970673322677612, variance: 0.006272787693887949\n",
      "Train size: [400] hidden size: [6] trial: 5, train_loss: 2.037717, test loss: 1.003219, bias2: 0.9967012405395508, variance: 0.0065178582444787025\n",
      "Train size: [400] hidden size: [6] trial: 6, train_loss: 2.048085, test loss: 1.003805, bias2: 0.9954044222831726, variance: 0.008400403894484043\n",
      "Train size: [400] hidden size: [6] trial: 7, train_loss: 2.032160, test loss: 1.003986, bias2: 0.9957069158554077, variance: 0.008279073052108288\n",
      "Train size: [400] hidden size: [6] trial: 8, train_loss: 2.047397, test loss: 1.004795, bias2: 0.9954777956008911, variance: 0.009316676296293736\n",
      "Train size: [400] hidden size: [6] trial: 9, train_loss: 2.049451, test loss: 1.005137, bias2: 0.9957770705223083, variance: 0.009359641931951046\n",
      "Train size: [400] hidden size: [6] trial: 10, train_loss: 2.037825, test loss: 1.005165, bias2: 0.9961481690406799, variance: 0.00901702418923378\n",
      "Train size: [400] hidden size: [6] trial: 11, train_loss: 2.034755, test loss: 1.005281, bias2: 0.9964120388031006, variance: 0.008868939243257046\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [6] trial: 12, train_loss: 2.037877, test loss: 1.004746, bias2: 0.9958992600440979, variance: 0.008846821263432503\n",
      "Train size: [400] hidden size: [6] trial: 13, train_loss: 2.026893, test loss: 1.004648, bias2: 0.9962985515594482, variance: 0.008349630050361156\n",
      "Train size: [400] hidden size: [6] trial: 14, train_loss: 2.032256, test loss: 1.004996, bias2: 0.9966527223587036, variance: 0.008343368768692017\n",
      "Train size: [400] hidden size: [6] trial: 15, train_loss: 2.035434, test loss: 1.005099, bias2: 0.9969939589500427, variance: 0.008105472661554813\n",
      "Train size: [400] hidden size: [6] trial: 16, train_loss: 2.022492, test loss: 1.005590, bias2: 0.9973664283752441, variance: 0.008223386481404305\n",
      "Train size: [400] hidden size: [6] trial: 17, train_loss: 2.015904, test loss: 1.005306, bias2: 0.9971697926521301, variance: 0.008136694319546223\n",
      "Train size: [400] hidden size: [6] trial: 18, train_loss: 2.014055, test loss: 1.005954, bias2: 0.9971294403076172, variance: 0.008824104443192482\n",
      "Train size: [400] hidden size: [6] trial: 19, train_loss: 2.010137, test loss: 1.006079, bias2: 0.9968795776367188, variance: 0.00919960718601942\n",
      "Train size: [400] hidden size: [6] trial: 20, train_loss: 2.011888, test loss: 1.006117, bias2: 0.9967504143714905, variance: 0.009366068989038467\n",
      "Train size: [400] hidden size: [6] trial: 21, train_loss: 2.011377, test loss: 1.006401, bias2: 0.9967156648635864, variance: 0.00968542043119669\n",
      "Train size: [400] hidden size: [6] trial: 22, train_loss: 2.004463, test loss: 1.007121, bias2: 0.9970417618751526, variance: 0.01007931586354971\n",
      "Train size: [400] hidden size: [6] trial: 23, train_loss: 2.000739, test loss: 1.007157, bias2: 0.9972071051597595, variance: 0.009950337931513786\n",
      "Train size: [400] hidden size: [6] trial: 24, train_loss: 2.003698, test loss: 1.007462, bias2: 0.9976588487625122, variance: 0.009803197346627712\n",
      "Train size: [400] hidden size: [6] trial: 25, train_loss: 2.001137, test loss: 1.007434, bias2: 0.997771143913269, variance: 0.009663247503340244\n",
      "Train size: [400] hidden size: [6] trial: 26, train_loss: 1.999430, test loss: 1.007496, bias2: 0.9979870319366455, variance: 0.009508613497018814\n",
      "Train size: [400] hidden size: [6] trial: 27, train_loss: 2.004189, test loss: 1.007612, bias2: 0.9979731440544128, variance: 0.00963906291872263\n",
      "Train size: [400] hidden size: [6] trial: 28, train_loss: 2.006235, test loss: 1.007858, bias2: 0.9981194138526917, variance: 0.009738652035593987\n",
      "Train size: [400] hidden size: [6] trial: 29, train_loss: 2.010857, test loss: 1.007748, bias2: 0.9981421828269958, variance: 0.009605925530195236\n",
      "Train size: [400] hidden size: [6] trial: 30, train_loss: 2.015736, test loss: 1.007913, bias2: 0.9984433054924011, variance: 0.009469463489949703\n",
      "Train size: [400] hidden size: [6] trial: 31, train_loss: 2.010271, test loss: 1.007718, bias2: 0.9983112215995789, variance: 0.009406373836100101\n",
      "Train size: [400] hidden size: [6] trial: 32, train_loss: 2.006844, test loss: 1.008274, bias2: 0.9986622929573059, variance: 0.00961169321089983\n",
      "Train size: [400] hidden size: [6] trial: 33, train_loss: 2.007970, test loss: 1.008272, bias2: 0.9986721277236938, variance: 0.009599552489817142\n",
      "Train size: [400] hidden size: [6] trial: 34, train_loss: 2.008108, test loss: 1.008676, bias2: 0.9984079003334045, variance: 0.010267549194395542\n",
      "Train size: [400] hidden size: [6] trial: 35, train_loss: 2.005630, test loss: 1.008678, bias2: 0.9985647797584534, variance: 0.010112825781106949\n",
      "Train size: [400] hidden size: [6] trial: 36, train_loss: 2.004269, test loss: 1.008541, bias2: 0.9984131455421448, variance: 0.010127942077815533\n",
      "Train size: [400] hidden size: [6] trial: 37, train_loss: 2.002944, test loss: 1.008716, bias2: 0.9984046816825867, variance: 0.010311183519661427\n",
      "Train size: [400] hidden size: [6] trial: 38, train_loss: 2.005371, test loss: 1.008545, bias2: 0.9979951977729797, variance: 0.010549347847700119\n",
      "Train size: [400] hidden size: [6] trial: 39, train_loss: 2.002597, test loss: 1.008532, bias2: 0.9980776309967041, variance: 0.010454441420733929\n",
      "Train size: [400] hidden size: [6] trial: 40, train_loss: 2.004811, test loss: 1.008372, bias2: 0.9979785084724426, variance: 0.010393058881163597\n",
      "Train size: [400] hidden size: [6] trial: 41, train_loss: 2.000164, test loss: 1.008347, bias2: 0.9980612397193909, variance: 0.010285919532179832\n",
      "Train size: [400] hidden size: [6] trial: 42, train_loss: 2.001213, test loss: 1.008181, bias2: 0.9977856874465942, variance: 0.010395769029855728\n",
      "Train size: [400] hidden size: [6] trial: 43, train_loss: 2.000203, test loss: 1.008095, bias2: 0.9978380799293518, variance: 0.010257325135171413\n",
      "Train size: [400] hidden size: [6] trial: 44, train_loss: 2.001454, test loss: 1.007960, bias2: 0.9978967905044556, variance: 0.010063273832201958\n",
      "Train size: [400] hidden size: [6] trial: 45, train_loss: 1.998605, test loss: 1.008114, bias2: 0.9979262351989746, variance: 0.010187633335590363\n",
      "Train size: [400] hidden size: [6] trial: 46, train_loss: 2.001616, test loss: 1.008606, bias2: 0.997959554195404, variance: 0.010646769776940346\n",
      "Train size: [400] hidden size: [6] trial: 47, train_loss: 1.996049, test loss: 1.008568, bias2: 0.998100757598877, variance: 0.010466809384524822\n",
      "Train size: [400] hidden size: [6] trial: 48, train_loss: 1.996558, test loss: 1.008424, bias2: 0.9980791807174683, variance: 0.010344397276639938\n",
      "Train size: [400] hidden size: [6] trial: 49, train_loss: 1.994919, test loss: 1.008406, bias2: 0.9980127811431885, variance: 0.010393262840807438\n",
      "##################################################\n",
      "Train size: [400] hidden size: [7] trial: 0, train_loss: 1.818720, test loss: 1.002950, bias2: 1.0029500722885132, variance: -2.889000497163785e-11\n",
      "Train size: [400] hidden size: [7] trial: 1, train_loss: 1.902143, test loss: 1.008174, bias2: 1.0061150789260864, variance: 0.0020592911168932915\n",
      "Train size: [400] hidden size: [7] trial: 2, train_loss: 1.892659, test loss: 1.011011, bias2: 1.0079693794250488, variance: 0.0030419330578297377\n",
      "Train size: [400] hidden size: [7] trial: 3, train_loss: 1.920466, test loss: 1.010210, bias2: 1.0060060024261475, variance: 0.004203699063509703\n",
      "Train size: [400] hidden size: [7] trial: 4, train_loss: 1.957873, test loss: 1.010028, bias2: 1.0028003454208374, variance: 0.007227267604321241\n",
      "Train size: [400] hidden size: [7] trial: 5, train_loss: 1.977714, test loss: 1.008926, bias2: 1.0022059679031372, variance: 0.006719965022057295\n",
      "Train size: [400] hidden size: [7] trial: 6, train_loss: 1.990455, test loss: 1.008717, bias2: 1.0017505884170532, variance: 0.006966396700590849\n",
      "Train size: [400] hidden size: [7] trial: 7, train_loss: 1.949804, test loss: 1.008759, bias2: 1.001933217048645, variance: 0.006825641728937626\n",
      "Train size: [400] hidden size: [7] trial: 8, train_loss: 1.963418, test loss: 1.007813, bias2: 1.0006413459777832, variance: 0.007171788718551397\n",
      "Train size: [400] hidden size: [7] trial: 9, train_loss: 1.982518, test loss: 1.008082, bias2: 1.0010426044464111, variance: 0.0070395455695688725\n",
      "Train size: [400] hidden size: [7] trial: 10, train_loss: 1.996105, test loss: 1.008460, bias2: 0.9992420077323914, variance: 0.009217445738613605\n",
      "Train size: [400] hidden size: [7] trial: 11, train_loss: 2.015087, test loss: 1.008918, bias2: 1.0001405477523804, variance: 0.008776847273111343\n",
      "Train size: [400] hidden size: [7] trial: 12, train_loss: 2.013196, test loss: 1.008961, bias2: 1.0003553628921509, variance: 0.008605645038187504\n",
      "Train size: [400] hidden size: [7] trial: 13, train_loss: 2.005447, test loss: 1.008556, bias2: 1.0002769231796265, variance: 0.008279375731945038\n",
      "Train size: [400] hidden size: [7] trial: 14, train_loss: 2.026781, test loss: 1.008332, bias2: 0.9997538924217224, variance: 0.008578146807849407\n",
      "Train size: [400] hidden size: [7] trial: 15, train_loss: 2.023503, test loss: 1.007866, bias2: 0.9986652135848999, variance: 0.009200566448271275\n",
      "Train size: [400] hidden size: [7] trial: 16, train_loss: 2.005319, test loss: 1.008000, bias2: 0.9989452958106995, variance: 0.009054340422153473\n",
      "Train size: [400] hidden size: [7] trial: 17, train_loss: 2.005353, test loss: 1.007658, bias2: 0.9988109469413757, variance: 0.00884730089455843\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [7] trial: 18, train_loss: 2.010931, test loss: 1.007540, bias2: 0.9979427456855774, variance: 0.0095974737778306\n",
      "Train size: [400] hidden size: [7] trial: 19, train_loss: 2.009693, test loss: 1.007627, bias2: 0.998199462890625, variance: 0.009427756071090698\n",
      "Train size: [400] hidden size: [7] trial: 20, train_loss: 2.001992, test loss: 1.007863, bias2: 0.998424768447876, variance: 0.009438293986022472\n",
      "Train size: [400] hidden size: [7] trial: 21, train_loss: 1.998820, test loss: 1.007129, bias2: 0.9977622628211975, variance: 0.009366358630359173\n",
      "Train size: [400] hidden size: [7] trial: 22, train_loss: 1.999821, test loss: 1.007350, bias2: 0.9975376129150391, variance: 0.00981257576495409\n",
      "Train size: [400] hidden size: [7] trial: 23, train_loss: 2.005815, test loss: 1.007381, bias2: 0.9977648854255676, variance: 0.009615838527679443\n",
      "Train size: [400] hidden size: [7] trial: 24, train_loss: 2.005601, test loss: 1.007599, bias2: 0.9978274703025818, variance: 0.009771065786480904\n",
      "Train size: [400] hidden size: [7] trial: 25, train_loss: 2.020836, test loss: 1.007610, bias2: 0.997874915599823, variance: 0.009735402651131153\n",
      "Train size: [400] hidden size: [7] trial: 26, train_loss: 2.014243, test loss: 1.007405, bias2: 0.9979149699211121, variance: 0.009489953517913818\n",
      "Train size: [400] hidden size: [7] trial: 27, train_loss: 2.009152, test loss: 1.007654, bias2: 0.9981339573860168, variance: 0.009520592167973518\n",
      "Train size: [400] hidden size: [7] trial: 28, train_loss: 2.012083, test loss: 1.007792, bias2: 0.9982434511184692, variance: 0.009548411704599857\n",
      "Train size: [400] hidden size: [7] trial: 29, train_loss: 2.007897, test loss: 1.007901, bias2: 0.9985947608947754, variance: 0.009305953979492188\n",
      "Train size: [400] hidden size: [7] trial: 30, train_loss: 2.000630, test loss: 1.008145, bias2: 0.998696506023407, variance: 0.009448709897696972\n",
      "Train size: [400] hidden size: [7] trial: 31, train_loss: 1.999708, test loss: 1.008510, bias2: 0.9989472031593323, variance: 0.009562450461089611\n",
      "Train size: [400] hidden size: [7] trial: 32, train_loss: 2.010053, test loss: 1.008503, bias2: 0.9991929531097412, variance: 0.009310376830399036\n",
      "Train size: [400] hidden size: [7] trial: 33, train_loss: 2.002474, test loss: 1.008882, bias2: 0.9993837475776672, variance: 0.009497912600636482\n",
      "Train size: [400] hidden size: [7] trial: 34, train_loss: 1.999010, test loss: 1.008659, bias2: 0.9987354874610901, variance: 0.00992389116436243\n",
      "Train size: [400] hidden size: [7] trial: 35, train_loss: 1.992625, test loss: 1.008414, bias2: 0.9981546998023987, variance: 0.0102593544870615\n",
      "Train size: [400] hidden size: [7] trial: 36, train_loss: 1.992172, test loss: 1.008131, bias2: 0.9977478384971619, variance: 0.010382839478552341\n",
      "Train size: [400] hidden size: [7] trial: 37, train_loss: 1.990041, test loss: 1.008010, bias2: 0.9977530241012573, variance: 0.01025735680013895\n",
      "Train size: [400] hidden size: [7] trial: 38, train_loss: 1.989309, test loss: 1.008002, bias2: 0.9976356625556946, variance: 0.010366284288465977\n",
      "Train size: [400] hidden size: [7] trial: 39, train_loss: 1.988750, test loss: 1.007671, bias2: 0.9973082542419434, variance: 0.010363002307713032\n",
      "Train size: [400] hidden size: [7] trial: 40, train_loss: 1.987232, test loss: 1.007442, bias2: 0.9970219135284424, variance: 0.010419702157378197\n",
      "Train size: [400] hidden size: [7] trial: 41, train_loss: 1.988737, test loss: 1.007440, bias2: 0.9970608949661255, variance: 0.01037882175296545\n",
      "Train size: [400] hidden size: [7] trial: 42, train_loss: 1.991283, test loss: 1.007138, bias2: 0.9966504573822021, variance: 0.010487538762390614\n",
      "Train size: [400] hidden size: [7] trial: 43, train_loss: 1.985970, test loss: 1.007361, bias2: 0.996857762336731, variance: 0.010503632016479969\n",
      "Train size: [400] hidden size: [7] trial: 44, train_loss: 1.986891, test loss: 1.007709, bias2: 0.9970252513885498, variance: 0.010683918371796608\n",
      "Train size: [400] hidden size: [7] trial: 45, train_loss: 1.987936, test loss: 1.007708, bias2: 0.9968213438987732, variance: 0.010886376723647118\n",
      "Train size: [400] hidden size: [7] trial: 46, train_loss: 1.990521, test loss: 1.007646, bias2: 0.9969655871391296, variance: 0.010680748149752617\n",
      "Train size: [400] hidden size: [7] trial: 47, train_loss: 1.987580, test loss: 1.007482, bias2: 0.996986985206604, variance: 0.010495404712855816\n",
      "Train size: [400] hidden size: [7] trial: 48, train_loss: 1.985933, test loss: 1.007458, bias2: 0.9971358180046082, variance: 0.010322030633687973\n",
      "Train size: [400] hidden size: [7] trial: 49, train_loss: 1.987589, test loss: 1.007440, bias2: 0.9971311092376709, variance: 0.010308491997420788\n",
      "##################################################\n",
      "Train size: [400] hidden size: [8] trial: 0, train_loss: 1.692078, test loss: 1.012617, bias2: 1.0126168727874756, variance: 8.514949162430341e-11\n",
      "Train size: [400] hidden size: [8] trial: 1, train_loss: 1.866834, test loss: 1.008037, bias2: 1.0007920265197754, variance: 0.007245129905641079\n",
      "Train size: [400] hidden size: [8] trial: 2, train_loss: 1.839712, test loss: 1.004063, bias2: 0.9950122237205505, variance: 0.009050575084984303\n",
      "Train size: [400] hidden size: [8] trial: 3, train_loss: 1.915230, test loss: 1.005786, bias2: 0.9967937469482422, variance: 0.008991964161396027\n",
      "Train size: [400] hidden size: [8] trial: 4, train_loss: 1.947130, test loss: 1.004237, bias2: 0.9938383102416992, variance: 0.010398504324257374\n",
      "Train size: [400] hidden size: [8] trial: 5, train_loss: 1.963951, test loss: 1.007763, bias2: 0.9951567649841309, variance: 0.012605811469256878\n",
      "Train size: [400] hidden size: [8] trial: 6, train_loss: 1.974596, test loss: 1.006925, bias2: 0.9946500062942505, variance: 0.012275232933461666\n",
      "Train size: [400] hidden size: [8] trial: 7, train_loss: 1.937108, test loss: 1.006839, bias2: 0.9923003315925598, variance: 0.014538570307195187\n",
      "Train size: [400] hidden size: [8] trial: 8, train_loss: 1.968389, test loss: 1.006895, bias2: 0.9926174283027649, variance: 0.01427775714546442\n",
      "Train size: [400] hidden size: [8] trial: 9, train_loss: 1.969253, test loss: 1.006201, bias2: 0.9923442602157593, variance: 0.013856538571417332\n",
      "Train size: [400] hidden size: [8] trial: 10, train_loss: 1.974108, test loss: 1.006154, bias2: 0.9927495718002319, variance: 0.013404506258666515\n",
      "Train size: [400] hidden size: [8] trial: 11, train_loss: 1.989882, test loss: 1.005555, bias2: 0.992172360420227, variance: 0.013382764533162117\n",
      "Train size: [400] hidden size: [8] trial: 12, train_loss: 1.996717, test loss: 1.005806, bias2: 0.9927033185958862, variance: 0.013102778233587742\n",
      "Train size: [400] hidden size: [8] trial: 13, train_loss: 1.993689, test loss: 1.006334, bias2: 0.992489755153656, variance: 0.013844205997884274\n",
      "Train size: [400] hidden size: [8] trial: 14, train_loss: 2.002058, test loss: 1.007170, bias2: 0.992845892906189, variance: 0.014324414543807507\n",
      "Train size: [400] hidden size: [8] trial: 15, train_loss: 2.001133, test loss: 1.007694, bias2: 0.9934256076812744, variance: 0.014268527738749981\n",
      "Train size: [400] hidden size: [8] trial: 16, train_loss: 1.999268, test loss: 1.007751, bias2: 0.9939759373664856, variance: 0.013774698600172997\n",
      "Train size: [400] hidden size: [8] trial: 17, train_loss: 2.012164, test loss: 1.008183, bias2: 0.9937407374382019, variance: 0.014441780745983124\n",
      "Train size: [400] hidden size: [8] trial: 18, train_loss: 2.014322, test loss: 1.008060, bias2: 0.992810845375061, variance: 0.015249484218657017\n",
      "Train size: [400] hidden size: [8] trial: 19, train_loss: 2.005904, test loss: 1.007776, bias2: 0.9928270578384399, variance: 0.01494872197508812\n",
      "Train size: [400] hidden size: [8] trial: 20, train_loss: 2.008662, test loss: 1.008321, bias2: 0.9937337636947632, variance: 0.014587139710783958\n",
      "Train size: [400] hidden size: [8] trial: 21, train_loss: 2.004895, test loss: 1.008589, bias2: 0.9934108853340149, variance: 0.015178012661635876\n",
      "Train size: [400] hidden size: [8] trial: 22, train_loss: 2.013587, test loss: 1.008266, bias2: 0.9934491515159607, variance: 0.014816719107329845\n",
      "Train size: [400] hidden size: [8] trial: 23, train_loss: 2.014380, test loss: 1.008292, bias2: 0.9938933253288269, variance: 0.014398294501006603\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [8] trial: 24, train_loss: 2.004655, test loss: 1.008151, bias2: 0.9938469529151917, variance: 0.014304451644420624\n",
      "Train size: [400] hidden size: [8] trial: 25, train_loss: 2.003174, test loss: 1.008298, bias2: 0.9940242767333984, variance: 0.014274015091359615\n",
      "Train size: [400] hidden size: [8] trial: 26, train_loss: 1.999448, test loss: 1.008384, bias2: 0.9940499067306519, variance: 0.01433410681784153\n",
      "Train size: [400] hidden size: [8] trial: 27, train_loss: 1.998133, test loss: 1.008677, bias2: 0.9941128492355347, variance: 0.014564257115125656\n",
      "Train size: [400] hidden size: [8] trial: 28, train_loss: 1.989744, test loss: 1.008894, bias2: 0.9943034052848816, variance: 0.01459033228456974\n",
      "Train size: [400] hidden size: [8] trial: 29, train_loss: 1.990159, test loss: 1.009119, bias2: 0.9947448372840881, variance: 0.014374296180903912\n",
      "Train size: [400] hidden size: [8] trial: 30, train_loss: 1.988046, test loss: 1.008807, bias2: 0.9944530129432678, variance: 0.014353569597005844\n",
      "Train size: [400] hidden size: [8] trial: 31, train_loss: 1.982809, test loss: 1.008419, bias2: 0.9941679835319519, variance: 0.014251316897571087\n",
      "Train size: [400] hidden size: [8] trial: 32, train_loss: 1.975666, test loss: 1.008676, bias2: 0.9945634603500366, variance: 0.014112243428826332\n",
      "Train size: [400] hidden size: [8] trial: 33, train_loss: 1.973150, test loss: 1.008343, bias2: 0.9944329261779785, variance: 0.013910272158682346\n",
      "Train size: [400] hidden size: [8] trial: 34, train_loss: 1.972961, test loss: 1.008273, bias2: 0.9945230484008789, variance: 0.013749458827078342\n",
      "Train size: [400] hidden size: [8] trial: 35, train_loss: 1.970066, test loss: 1.008401, bias2: 0.9949105381965637, variance: 0.013490976765751839\n",
      "Train size: [400] hidden size: [8] trial: 36, train_loss: 1.973048, test loss: 1.008533, bias2: 0.9949765205383301, variance: 0.013556712307035923\n",
      "Train size: [400] hidden size: [8] trial: 37, train_loss: 1.974905, test loss: 1.008117, bias2: 0.9941391348838806, variance: 0.013977560214698315\n",
      "Train size: [400] hidden size: [8] trial: 38, train_loss: 1.979771, test loss: 1.008465, bias2: 0.9943163394927979, variance: 0.014148964546620846\n",
      "Train size: [400] hidden size: [8] trial: 39, train_loss: 1.986327, test loss: 1.008787, bias2: 0.9946609735488892, variance: 0.014125972054898739\n",
      "Train size: [400] hidden size: [8] trial: 40, train_loss: 1.987605, test loss: 1.008753, bias2: 0.9947715997695923, variance: 0.013981453143060207\n",
      "Train size: [400] hidden size: [8] trial: 41, train_loss: 1.987662, test loss: 1.008777, bias2: 0.9950007796287537, variance: 0.013776001520454884\n",
      "Train size: [400] hidden size: [8] trial: 42, train_loss: 1.989660, test loss: 1.008789, bias2: 0.9950202107429504, variance: 0.013768704608082771\n",
      "Train size: [400] hidden size: [8] trial: 43, train_loss: 1.987168, test loss: 1.008812, bias2: 0.9949609637260437, variance: 0.013850633054971695\n",
      "Train size: [400] hidden size: [8] trial: 44, train_loss: 1.983036, test loss: 1.008867, bias2: 0.9949181079864502, variance: 0.013948800042271614\n",
      "Train size: [400] hidden size: [8] trial: 45, train_loss: 1.985351, test loss: 1.008983, bias2: 0.995087742805481, variance: 0.013895509764552116\n",
      "Train size: [400] hidden size: [8] trial: 46, train_loss: 1.983127, test loss: 1.008966, bias2: 0.9950932264328003, variance: 0.013872762210667133\n",
      "Train size: [400] hidden size: [8] trial: 47, train_loss: 1.980169, test loss: 1.008918, bias2: 0.995212733745575, variance: 0.01370497327297926\n",
      "Train size: [400] hidden size: [8] trial: 48, train_loss: 1.982947, test loss: 1.009020, bias2: 0.9953855276107788, variance: 0.013634794391691685\n",
      "Train size: [400] hidden size: [8] trial: 49, train_loss: 1.984338, test loss: 1.008717, bias2: 0.9951141476631165, variance: 0.013602416031062603\n",
      "##################################################\n",
      "Train size: [400] hidden size: [9] trial: 0, train_loss: 1.678971, test loss: 1.001513, bias2: 1.0015130043029785, variance: 9.731369876586626e-11\n",
      "Train size: [400] hidden size: [9] trial: 1, train_loss: 1.791808, test loss: 1.003071, bias2: 0.9960038661956787, variance: 0.007066721096634865\n",
      "Train size: [400] hidden size: [9] trial: 2, train_loss: 1.850383, test loss: 1.007625, bias2: 1.0001003742218018, variance: 0.007524693850427866\n",
      "Train size: [400] hidden size: [9] trial: 3, train_loss: 1.859292, test loss: 1.011595, bias2: 1.0013415813446045, variance: 0.010253039188683033\n",
      "Train size: [400] hidden size: [9] trial: 4, train_loss: 1.830898, test loss: 1.010963, bias2: 0.9996597766876221, variance: 0.011303429491817951\n",
      "Train size: [400] hidden size: [9] trial: 5, train_loss: 1.843672, test loss: 1.010493, bias2: 0.9990009069442749, variance: 0.011492369696497917\n",
      "Train size: [400] hidden size: [9] trial: 6, train_loss: 1.884650, test loss: 1.013497, bias2: 0.999156653881073, variance: 0.014340449124574661\n",
      "Train size: [400] hidden size: [9] trial: 7, train_loss: 1.878787, test loss: 1.013656, bias2: 1.000007152557373, variance: 0.013648574240505695\n",
      "Train size: [400] hidden size: [9] trial: 8, train_loss: 1.928609, test loss: 1.013953, bias2: 1.0002409219741821, variance: 0.013711629435420036\n",
      "Train size: [400] hidden size: [9] trial: 9, train_loss: 1.928679, test loss: 1.013838, bias2: 0.9996389150619507, variance: 0.014198774471879005\n",
      "Train size: [400] hidden size: [9] trial: 10, train_loss: 1.905297, test loss: 1.015415, bias2: 1.0010265111923218, variance: 0.01438823901116848\n",
      "Train size: [400] hidden size: [9] trial: 11, train_loss: 1.917309, test loss: 1.014620, bias2: 0.999413251876831, variance: 0.015207061544060707\n",
      "Train size: [400] hidden size: [9] trial: 12, train_loss: 1.936518, test loss: 1.013209, bias2: 0.9977663159370422, variance: 0.01544242724776268\n",
      "Train size: [400] hidden size: [9] trial: 13, train_loss: 1.941653, test loss: 1.013102, bias2: 0.9983617663383484, variance: 0.01474042423069477\n",
      "Train size: [400] hidden size: [9] trial: 14, train_loss: 1.939050, test loss: 1.012740, bias2: 0.9975776672363281, variance: 0.015162011608481407\n",
      "Train size: [400] hidden size: [9] trial: 15, train_loss: 1.961564, test loss: 1.012082, bias2: 0.9970197081565857, variance: 0.015062520280480385\n",
      "Train size: [400] hidden size: [9] trial: 16, train_loss: 1.956345, test loss: 1.011945, bias2: 0.9973064661026001, variance: 0.014638674445450306\n",
      "Train size: [400] hidden size: [9] trial: 17, train_loss: 1.947289, test loss: 1.011942, bias2: 0.9973071813583374, variance: 0.014634964987635612\n",
      "Train size: [400] hidden size: [9] trial: 18, train_loss: 1.945965, test loss: 1.012437, bias2: 0.9969768524169922, variance: 0.015460348688066006\n",
      "Train size: [400] hidden size: [9] trial: 19, train_loss: 1.931920, test loss: 1.012496, bias2: 0.9970099329948425, variance: 0.015485930256545544\n",
      "Train size: [400] hidden size: [9] trial: 20, train_loss: 1.931244, test loss: 1.012699, bias2: 0.9969989061355591, variance: 0.015699857845902443\n",
      "Train size: [400] hidden size: [9] trial: 21, train_loss: 1.931108, test loss: 1.012324, bias2: 0.9968701004981995, variance: 0.015453523024916649\n",
      "Train size: [400] hidden size: [9] trial: 22, train_loss: 1.927483, test loss: 1.011576, bias2: 0.9961823225021362, variance: 0.015393370762467384\n",
      "Train size: [400] hidden size: [9] trial: 23, train_loss: 1.942411, test loss: 1.011572, bias2: 0.9963447451591492, variance: 0.015227502211928368\n",
      "Train size: [400] hidden size: [9] trial: 24, train_loss: 1.940313, test loss: 1.011657, bias2: 0.996691107749939, variance: 0.014965745620429516\n",
      "Train size: [400] hidden size: [9] trial: 25, train_loss: 1.944910, test loss: 1.011590, bias2: 0.9969778656959534, variance: 0.014611687511205673\n",
      "Train size: [400] hidden size: [9] trial: 26, train_loss: 1.944196, test loss: 1.011959, bias2: 0.9973640441894531, variance: 0.01459505595266819\n",
      "Train size: [400] hidden size: [9] trial: 27, train_loss: 1.937335, test loss: 1.011382, bias2: 0.9969422817230225, variance: 0.014440082013607025\n",
      "Train size: [400] hidden size: [9] trial: 28, train_loss: 1.943060, test loss: 1.011648, bias2: 0.9969936013221741, variance: 0.01465457770973444\n",
      "Train size: [400] hidden size: [9] trial: 29, train_loss: 1.944226, test loss: 1.011204, bias2: 0.9966472387313843, variance: 0.014557142741978168\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [9] trial: 30, train_loss: 1.944843, test loss: 1.011437, bias2: 0.9962251782417297, variance: 0.015211661346256733\n",
      "Train size: [400] hidden size: [9] trial: 31, train_loss: 1.946895, test loss: 1.011473, bias2: 0.9962947964668274, variance: 0.01517835445702076\n",
      "Train size: [400] hidden size: [9] trial: 32, train_loss: 1.948221, test loss: 1.011342, bias2: 0.9964187741279602, variance: 0.014923259615898132\n",
      "Train size: [400] hidden size: [9] trial: 33, train_loss: 1.952717, test loss: 1.011310, bias2: 0.9960150122642517, variance: 0.01529470831155777\n",
      "Train size: [400] hidden size: [9] trial: 34, train_loss: 1.949775, test loss: 1.010853, bias2: 0.9955829977989197, variance: 0.015269569121301174\n",
      "Train size: [400] hidden size: [9] trial: 35, train_loss: 1.948721, test loss: 1.010454, bias2: 0.9952656626701355, variance: 0.015188129618763924\n",
      "Train size: [400] hidden size: [9] trial: 36, train_loss: 1.947566, test loss: 1.010648, bias2: 0.9954016804695129, variance: 0.01524631679058075\n",
      "Train size: [400] hidden size: [9] trial: 37, train_loss: 1.946530, test loss: 1.010438, bias2: 0.9953017234802246, variance: 0.015135763213038445\n",
      "Train size: [400] hidden size: [9] trial: 38, train_loss: 1.948406, test loss: 1.010252, bias2: 0.9947589635848999, variance: 0.015492535196244717\n",
      "Train size: [400] hidden size: [9] trial: 39, train_loss: 1.945230, test loss: 1.010435, bias2: 0.9950751066207886, variance: 0.015359771437942982\n",
      "Train size: [400] hidden size: [9] trial: 40, train_loss: 1.945006, test loss: 1.010468, bias2: 0.9952732920646667, variance: 0.015194623731076717\n",
      "Train size: [400] hidden size: [9] trial: 41, train_loss: 1.949201, test loss: 1.010904, bias2: 0.9949194192886353, variance: 0.015984894707798958\n",
      "Train size: [400] hidden size: [9] trial: 42, train_loss: 1.950543, test loss: 1.010752, bias2: 0.9943261742591858, variance: 0.016426173970103264\n",
      "Train size: [400] hidden size: [9] trial: 43, train_loss: 1.952783, test loss: 1.010755, bias2: 0.9945592284202576, variance: 0.016195859760046005\n",
      "Train size: [400] hidden size: [9] trial: 44, train_loss: 1.947861, test loss: 1.010933, bias2: 0.994779109954834, variance: 0.01615382917225361\n",
      "Train size: [400] hidden size: [9] trial: 45, train_loss: 1.946835, test loss: 1.011128, bias2: 0.9947850704193115, variance: 0.016342531889677048\n",
      "Train size: [400] hidden size: [9] trial: 46, train_loss: 1.945289, test loss: 1.011112, bias2: 0.9949216842651367, variance: 0.016190174967050552\n",
      "Train size: [400] hidden size: [9] trial: 47, train_loss: 1.948538, test loss: 1.011158, bias2: 0.9949556589126587, variance: 0.016202224418520927\n",
      "Train size: [400] hidden size: [9] trial: 48, train_loss: 1.947041, test loss: 1.011420, bias2: 0.9952200055122375, variance: 0.016199741512537003\n",
      "Train size: [400] hidden size: [9] trial: 49, train_loss: 1.944951, test loss: 1.011535, bias2: 0.9951233267784119, variance: 0.016411392018198967\n",
      "##################################################\n",
      "Train size: [400] hidden size: [11] trial: 0, train_loss: 1.848370, test loss: 1.015615, bias2: 1.0156148672103882, variance: 3.6492638771923325e-11\n",
      "Train size: [400] hidden size: [11] trial: 1, train_loss: 1.820625, test loss: 1.015920, bias2: 1.0077730417251587, variance: 0.0081472834572196\n",
      "Train size: [400] hidden size: [11] trial: 2, train_loss: 1.852651, test loss: 1.015908, bias2: 1.0039094686508179, variance: 0.011999060399830341\n",
      "Train size: [400] hidden size: [11] trial: 3, train_loss: 1.904631, test loss: 1.012228, bias2: 0.9981551170349121, variance: 0.014072670601308346\n",
      "Train size: [400] hidden size: [11] trial: 4, train_loss: 1.929960, test loss: 1.011414, bias2: 0.9963736534118652, variance: 0.01504062581807375\n",
      "Train size: [400] hidden size: [11] trial: 5, train_loss: 1.935410, test loss: 1.009836, bias2: 0.9935076832771301, variance: 0.016328373923897743\n",
      "Train size: [400] hidden size: [11] trial: 6, train_loss: 1.950829, test loss: 1.008553, bias2: 0.9926478862762451, variance: 0.015905488282442093\n",
      "Train size: [400] hidden size: [11] trial: 7, train_loss: 1.924430, test loss: 1.010372, bias2: 0.9944700002670288, variance: 0.01590191200375557\n",
      "Train size: [400] hidden size: [11] trial: 8, train_loss: 1.938221, test loss: 1.009859, bias2: 0.9949309825897217, variance: 0.014928461983799934\n",
      "Train size: [400] hidden size: [11] trial: 9, train_loss: 1.939939, test loss: 1.010218, bias2: 0.9958826899528503, variance: 0.0143356928601861\n",
      "Train size: [400] hidden size: [11] trial: 10, train_loss: 1.943084, test loss: 1.010563, bias2: 0.9960135817527771, variance: 0.014549441635608673\n",
      "Train size: [400] hidden size: [11] trial: 11, train_loss: 1.928952, test loss: 1.009200, bias2: 0.9939695000648499, variance: 0.015230700373649597\n",
      "Train size: [400] hidden size: [11] trial: 12, train_loss: 1.951512, test loss: 1.010023, bias2: 0.995013415813446, variance: 0.015010050497949123\n",
      "Train size: [400] hidden size: [11] trial: 13, train_loss: 1.945309, test loss: 1.010011, bias2: 0.9946991205215454, variance: 0.015312333591282368\n",
      "Train size: [400] hidden size: [11] trial: 14, train_loss: 1.943293, test loss: 1.010469, bias2: 0.9950748682022095, variance: 0.015393989160656929\n",
      "Train size: [400] hidden size: [11] trial: 15, train_loss: 1.940796, test loss: 1.012446, bias2: 0.9959457516670227, variance: 0.0165000781416893\n",
      "Train size: [400] hidden size: [11] trial: 16, train_loss: 1.937902, test loss: 1.012464, bias2: 0.9956077933311462, variance: 0.016856474801898003\n",
      "Train size: [400] hidden size: [11] trial: 17, train_loss: 1.925723, test loss: 1.012372, bias2: 0.9954133629798889, variance: 0.016959039494395256\n",
      "Train size: [400] hidden size: [11] trial: 18, train_loss: 1.934294, test loss: 1.011593, bias2: 0.9947578310966492, variance: 0.016835525631904602\n",
      "Train size: [400] hidden size: [11] trial: 19, train_loss: 1.941268, test loss: 1.011266, bias2: 0.9941126108169556, variance: 0.01715347170829773\n",
      "Train size: [400] hidden size: [11] trial: 20, train_loss: 1.946203, test loss: 1.010748, bias2: 0.9935079216957092, variance: 0.017240213230252266\n",
      "Train size: [400] hidden size: [11] trial: 21, train_loss: 1.963240, test loss: 1.010892, bias2: 0.9937119483947754, variance: 0.0171805452555418\n",
      "Train size: [400] hidden size: [11] trial: 22, train_loss: 1.957913, test loss: 1.010590, bias2: 0.9922765493392944, variance: 0.018313026055693626\n",
      "Train size: [400] hidden size: [11] trial: 23, train_loss: 1.955597, test loss: 1.010726, bias2: 0.9922051429748535, variance: 0.01852133497595787\n",
      "Train size: [400] hidden size: [11] trial: 24, train_loss: 1.947856, test loss: 1.010706, bias2: 0.9920180439949036, variance: 0.018687548115849495\n",
      "Train size: [400] hidden size: [11] trial: 25, train_loss: 1.947754, test loss: 1.010632, bias2: 0.9912101030349731, variance: 0.019421467557549477\n",
      "Train size: [400] hidden size: [11] trial: 26, train_loss: 1.944439, test loss: 1.010588, bias2: 0.9914140105247498, variance: 0.019173676148056984\n",
      "Train size: [400] hidden size: [11] trial: 27, train_loss: 1.947175, test loss: 1.010866, bias2: 0.9918544292449951, variance: 0.019011637195944786\n",
      "Train size: [400] hidden size: [11] trial: 28, train_loss: 1.948886, test loss: 1.010595, bias2: 0.9918057918548584, variance: 0.018789658322930336\n",
      "Train size: [400] hidden size: [11] trial: 29, train_loss: 1.943707, test loss: 1.010002, bias2: 0.991133451461792, variance: 0.018868345767259598\n",
      "Train size: [400] hidden size: [11] trial: 30, train_loss: 1.937040, test loss: 1.009992, bias2: 0.9912146925926208, variance: 0.018777091056108475\n",
      "Train size: [400] hidden size: [11] trial: 31, train_loss: 1.936245, test loss: 1.009636, bias2: 0.9909659624099731, variance: 0.018669962882995605\n",
      "Train size: [400] hidden size: [11] trial: 32, train_loss: 1.942297, test loss: 1.010544, bias2: 0.9909318089485168, variance: 0.019612105563282967\n",
      "Train size: [400] hidden size: [11] trial: 33, train_loss: 1.946129, test loss: 1.010266, bias2: 0.9904872179031372, variance: 0.01977837085723877\n",
      "Train size: [400] hidden size: [11] trial: 34, train_loss: 1.944279, test loss: 1.010008, bias2: 0.990361213684082, variance: 0.0196462944149971\n",
      "Train size: [400] hidden size: [11] trial: 35, train_loss: 1.942817, test loss: 1.010135, bias2: 0.9904743432998657, variance: 0.019660571590065956\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [11] trial: 36, train_loss: 1.942860, test loss: 1.009926, bias2: 0.9904873967170715, variance: 0.01943855732679367\n",
      "Train size: [400] hidden size: [11] trial: 37, train_loss: 1.951844, test loss: 1.010271, bias2: 0.9909148812294006, variance: 0.01935572177171707\n",
      "Train size: [400] hidden size: [11] trial: 38, train_loss: 1.947705, test loss: 1.010119, bias2: 0.9910950660705566, variance: 0.019024034962058067\n",
      "Train size: [400] hidden size: [11] trial: 39, train_loss: 1.947669, test loss: 1.010054, bias2: 0.9909765720367432, variance: 0.019077874720096588\n",
      "Train size: [400] hidden size: [11] trial: 40, train_loss: 1.953418, test loss: 1.010178, bias2: 0.9913793206214905, variance: 0.018799006938934326\n",
      "Train size: [400] hidden size: [11] trial: 41, train_loss: 1.955145, test loss: 1.010088, bias2: 0.9913300275802612, variance: 0.018758440390229225\n",
      "Train size: [400] hidden size: [11] trial: 42, train_loss: 1.952483, test loss: 1.010110, bias2: 0.9915810227394104, variance: 0.01852874457836151\n",
      "Train size: [400] hidden size: [11] trial: 43, train_loss: 1.948113, test loss: 1.009719, bias2: 0.9910233616828918, variance: 0.01869530789554119\n",
      "Train size: [400] hidden size: [11] trial: 44, train_loss: 1.957451, test loss: 1.009675, bias2: 0.9913052916526794, variance: 0.018369734287261963\n",
      "Train size: [400] hidden size: [11] trial: 45, train_loss: 1.953644, test loss: 1.009510, bias2: 0.9913527369499207, variance: 0.01815696246922016\n",
      "Train size: [400] hidden size: [11] trial: 46, train_loss: 1.951494, test loss: 1.009585, bias2: 0.9913913011550903, variance: 0.0181941706687212\n",
      "Train size: [400] hidden size: [11] trial: 47, train_loss: 1.948317, test loss: 1.010121, bias2: 0.9915807843208313, variance: 0.018540222197771072\n",
      "Train size: [400] hidden size: [11] trial: 48, train_loss: 1.948717, test loss: 1.010221, bias2: 0.9918087124824524, variance: 0.018412668257951736\n",
      "Train size: [400] hidden size: [11] trial: 49, train_loss: 1.950946, test loss: 1.009918, bias2: 0.9915329217910767, variance: 0.018384916707873344\n",
      "##################################################\n",
      "Train size: [400] hidden size: [12] trial: 0, train_loss: 1.682402, test loss: 0.986601, bias2: 0.9866008162498474, variance: 4.865684938293313e-11\n",
      "Train size: [400] hidden size: [12] trial: 1, train_loss: 1.675844, test loss: 0.995683, bias2: 0.983276903629303, variance: 0.012406195513904095\n",
      "Train size: [400] hidden size: [12] trial: 2, train_loss: 1.773071, test loss: 1.000413, bias2: 0.9878031015396118, variance: 0.012609469704329967\n",
      "Train size: [400] hidden size: [12] trial: 3, train_loss: 1.751392, test loss: 1.001357, bias2: 0.9861413240432739, variance: 0.015215659514069557\n",
      "Train size: [400] hidden size: [12] trial: 4, train_loss: 1.815198, test loss: 1.007983, bias2: 0.9912653565406799, variance: 0.016717949882149696\n",
      "Train size: [400] hidden size: [12] trial: 5, train_loss: 1.827911, test loss: 1.006167, bias2: 0.9899835586547852, variance: 0.01618373394012451\n",
      "Train size: [400] hidden size: [12] trial: 6, train_loss: 1.847918, test loss: 1.004898, bias2: 0.9879323840141296, variance: 0.016965674236416817\n",
      "Train size: [400] hidden size: [12] trial: 7, train_loss: 1.858545, test loss: 1.004768, bias2: 0.9885531067848206, variance: 0.016215162351727486\n",
      "Train size: [400] hidden size: [12] trial: 8, train_loss: 1.858300, test loss: 1.003145, bias2: 0.9868327975273132, variance: 0.01631256751716137\n",
      "Train size: [400] hidden size: [12] trial: 9, train_loss: 1.862684, test loss: 1.002299, bias2: 0.9854648113250732, variance: 0.016834476962685585\n",
      "Train size: [400] hidden size: [12] trial: 10, train_loss: 1.882544, test loss: 1.002249, bias2: 0.9855871796607971, variance: 0.016661344096064568\n",
      "Train size: [400] hidden size: [12] trial: 11, train_loss: 1.910939, test loss: 1.002649, bias2: 0.9863287210464478, variance: 0.01632043905556202\n",
      "Train size: [400] hidden size: [12] trial: 12, train_loss: 1.926833, test loss: 1.002699, bias2: 0.9865748882293701, variance: 0.016123898327350616\n",
      "Train size: [400] hidden size: [12] trial: 13, train_loss: 1.914362, test loss: 1.003730, bias2: 0.986912190914154, variance: 0.016818014904856682\n",
      "Train size: [400] hidden size: [12] trial: 14, train_loss: 1.905022, test loss: 1.003737, bias2: 0.986618161201477, variance: 0.017118358984589577\n",
      "Train size: [400] hidden size: [12] trial: 15, train_loss: 1.911998, test loss: 1.002968, bias2: 0.9859433174133301, variance: 0.017024535685777664\n",
      "Train size: [400] hidden size: [12] trial: 16, train_loss: 1.924175, test loss: 1.004052, bias2: 0.9868742823600769, variance: 0.01717773638665676\n",
      "Train size: [400] hidden size: [12] trial: 17, train_loss: 1.921145, test loss: 1.003349, bias2: 0.9846415519714355, variance: 0.01870764046907425\n",
      "Train size: [400] hidden size: [12] trial: 18, train_loss: 1.925092, test loss: 1.003757, bias2: 0.9848593473434448, variance: 0.01889752969145775\n",
      "Train size: [400] hidden size: [12] trial: 19, train_loss: 1.925741, test loss: 1.003600, bias2: 0.9853835701942444, variance: 0.018216446042060852\n",
      "Train size: [400] hidden size: [12] trial: 20, train_loss: 1.933147, test loss: 1.003723, bias2: 0.9848862290382385, variance: 0.01883680745959282\n",
      "Train size: [400] hidden size: [12] trial: 21, train_loss: 1.935079, test loss: 1.002803, bias2: 0.9840061664581299, variance: 0.018796825781464577\n",
      "Train size: [400] hidden size: [12] trial: 22, train_loss: 1.932262, test loss: 1.002848, bias2: 0.9835677742958069, variance: 0.01928001269698143\n",
      "Train size: [400] hidden size: [12] trial: 23, train_loss: 1.940064, test loss: 1.003811, bias2: 0.984309732913971, variance: 0.019501741975545883\n",
      "Train size: [400] hidden size: [12] trial: 24, train_loss: 1.941673, test loss: 1.004779, bias2: 0.9853121042251587, variance: 0.01946650631725788\n",
      "Train size: [400] hidden size: [12] trial: 25, train_loss: 1.939849, test loss: 1.005157, bias2: 0.9857275485992432, variance: 0.019429566338658333\n",
      "Train size: [400] hidden size: [12] trial: 26, train_loss: 1.945759, test loss: 1.005758, bias2: 0.9862842559814453, variance: 0.01947353035211563\n",
      "Train size: [400] hidden size: [12] trial: 27, train_loss: 1.942858, test loss: 1.005744, bias2: 0.9863103628158569, variance: 0.019433116540312767\n",
      "Train size: [400] hidden size: [12] trial: 28, train_loss: 1.941233, test loss: 1.005837, bias2: 0.9859695434570312, variance: 0.019867904484272003\n",
      "Train size: [400] hidden size: [12] trial: 29, train_loss: 1.943064, test loss: 1.007388, bias2: 0.9867444038391113, variance: 0.02064335346221924\n",
      "Train size: [400] hidden size: [12] trial: 30, train_loss: 1.942378, test loss: 1.007164, bias2: 0.9868438839912415, variance: 0.020320363342761993\n",
      "Train size: [400] hidden size: [12] trial: 31, train_loss: 1.942975, test loss: 1.006863, bias2: 0.9865390658378601, variance: 0.020323827862739563\n",
      "Train size: [400] hidden size: [12] trial: 32, train_loss: 1.937162, test loss: 1.006898, bias2: 0.986753523349762, variance: 0.02014477737247944\n",
      "Train size: [400] hidden size: [12] trial: 33, train_loss: 1.932776, test loss: 1.007352, bias2: 0.9871612787246704, variance: 0.02019023522734642\n",
      "Train size: [400] hidden size: [12] trial: 34, train_loss: 1.932961, test loss: 1.006955, bias2: 0.9869024753570557, variance: 0.020052103325724602\n",
      "Train size: [400] hidden size: [12] trial: 35, train_loss: 1.927489, test loss: 1.007173, bias2: 0.9872370958328247, variance: 0.019936207681894302\n",
      "Train size: [400] hidden size: [12] trial: 36, train_loss: 1.923368, test loss: 1.006720, bias2: 0.986573338508606, variance: 0.020147109404206276\n",
      "Train size: [400] hidden size: [12] trial: 37, train_loss: 1.918135, test loss: 1.006511, bias2: 0.9866437911987305, variance: 0.019867319613695145\n",
      "Train size: [400] hidden size: [12] trial: 38, train_loss: 1.922646, test loss: 1.006419, bias2: 0.9865829348564148, variance: 0.019835645332932472\n",
      "Train size: [400] hidden size: [12] trial: 39, train_loss: 1.916463, test loss: 1.006634, bias2: 0.9869570732116699, variance: 0.019676901400089264\n",
      "Train size: [400] hidden size: [12] trial: 40, train_loss: 1.913968, test loss: 1.006546, bias2: 0.986910343170166, variance: 0.019635936245322227\n",
      "Train size: [400] hidden size: [12] trial: 41, train_loss: 1.915100, test loss: 1.006673, bias2: 0.986823558807373, variance: 0.019849151372909546\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [12] trial: 42, train_loss: 1.918000, test loss: 1.006418, bias2: 0.9864505529403687, variance: 0.019967664033174515\n",
      "Train size: [400] hidden size: [12] trial: 43, train_loss: 1.916245, test loss: 1.006327, bias2: 0.9865214824676514, variance: 0.019805578514933586\n",
      "Train size: [400] hidden size: [12] trial: 44, train_loss: 1.918883, test loss: 1.006210, bias2: 0.9862952828407288, variance: 0.019914356991648674\n",
      "Train size: [400] hidden size: [12] trial: 45, train_loss: 1.921662, test loss: 1.006086, bias2: 0.986094057559967, variance: 0.019992263987660408\n",
      "Train size: [400] hidden size: [12] trial: 46, train_loss: 1.922938, test loss: 1.006052, bias2: 0.9862766861915588, variance: 0.019775206223130226\n",
      "Train size: [400] hidden size: [12] trial: 47, train_loss: 1.923296, test loss: 1.006014, bias2: 0.9862505197525024, variance: 0.019762979820370674\n",
      "Train size: [400] hidden size: [12] trial: 48, train_loss: 1.924703, test loss: 1.006163, bias2: 0.9864662289619446, variance: 0.019696751609444618\n",
      "Train size: [400] hidden size: [12] trial: 49, train_loss: 1.927575, test loss: 1.006237, bias2: 0.9866239428520203, variance: 0.01961272768676281\n",
      "##################################################\n",
      "Train size: [400] hidden size: [14] trial: 0, train_loss: 1.908496, test loss: 0.997975, bias2: 0.9979753494262695, variance: -3.8925479506346505e-10\n",
      "Train size: [400] hidden size: [14] trial: 1, train_loss: 1.950281, test loss: 1.005134, bias2: 0.9875431656837463, variance: 0.01759115792810917\n",
      "Train size: [400] hidden size: [14] trial: 2, train_loss: 1.970076, test loss: 0.998255, bias2: 0.9765440821647644, variance: 0.021710507571697235\n",
      "Train size: [400] hidden size: [14] trial: 3, train_loss: 2.001630, test loss: 1.001284, bias2: 0.9805834293365479, variance: 0.020700566470623016\n",
      "Train size: [400] hidden size: [14] trial: 4, train_loss: 1.951089, test loss: 1.014166, bias2: 0.9837961792945862, variance: 0.030370159074664116\n",
      "Train size: [400] hidden size: [14] trial: 5, train_loss: 1.956704, test loss: 1.012341, bias2: 0.9844225645065308, variance: 0.027918357402086258\n",
      "Train size: [400] hidden size: [14] trial: 6, train_loss: 1.970169, test loss: 1.011770, bias2: 0.9815369248390198, variance: 0.030232973396778107\n",
      "Train size: [400] hidden size: [14] trial: 7, train_loss: 1.948413, test loss: 1.013192, bias2: 0.9837383031845093, variance: 0.029453624039888382\n",
      "Train size: [400] hidden size: [14] trial: 8, train_loss: 1.949050, test loss: 1.010548, bias2: 0.9808428883552551, variance: 0.029704896733164787\n",
      "Train size: [400] hidden size: [14] trial: 9, train_loss: 1.960246, test loss: 1.011368, bias2: 0.9813552498817444, variance: 0.03001268394291401\n",
      "Train size: [400] hidden size: [14] trial: 10, train_loss: 1.952112, test loss: 1.010503, bias2: 0.9794676899909973, variance: 0.03103574551641941\n",
      "Train size: [400] hidden size: [14] trial: 11, train_loss: 1.945914, test loss: 1.010617, bias2: 0.9803693890571594, variance: 0.030248112976551056\n",
      "Train size: [400] hidden size: [14] trial: 12, train_loss: 1.942187, test loss: 1.009155, bias2: 0.9787709712982178, variance: 0.030384404584765434\n",
      "Train size: [400] hidden size: [14] trial: 13, train_loss: 1.935121, test loss: 1.009219, bias2: 0.9796770215034485, variance: 0.02954178862273693\n",
      "Train size: [400] hidden size: [14] trial: 14, train_loss: 1.951996, test loss: 1.010060, bias2: 0.980360746383667, variance: 0.029699591919779778\n",
      "Train size: [400] hidden size: [14] trial: 15, train_loss: 1.939715, test loss: 1.009603, bias2: 0.9803420305252075, variance: 0.029261112213134766\n",
      "Train size: [400] hidden size: [14] trial: 16, train_loss: 1.928710, test loss: 1.010849, bias2: 0.9815958738327026, variance: 0.029252856969833374\n",
      "Train size: [400] hidden size: [14] trial: 17, train_loss: 1.925409, test loss: 1.010619, bias2: 0.9820931553840637, variance: 0.028525909408926964\n",
      "Train size: [400] hidden size: [14] trial: 18, train_loss: 1.935031, test loss: 1.010297, bias2: 0.9815087914466858, variance: 0.028787819668650627\n",
      "Train size: [400] hidden size: [14] trial: 19, train_loss: 1.938026, test loss: 1.009777, bias2: 0.9812296628952026, variance: 0.028547286987304688\n",
      "Train size: [400] hidden size: [14] trial: 20, train_loss: 1.938613, test loss: 1.010421, bias2: 0.9802289605140686, variance: 0.030192049220204353\n",
      "Train size: [400] hidden size: [14] trial: 21, train_loss: 1.944836, test loss: 1.009633, bias2: 0.978342592716217, variance: 0.031290728598833084\n",
      "Train size: [400] hidden size: [14] trial: 22, train_loss: 1.948353, test loss: 1.009828, bias2: 0.9787483215332031, variance: 0.031079301610589027\n",
      "Train size: [400] hidden size: [14] trial: 23, train_loss: 1.938444, test loss: 1.009231, bias2: 0.9783364534378052, variance: 0.030894871801137924\n",
      "Train size: [400] hidden size: [14] trial: 24, train_loss: 1.942246, test loss: 1.008905, bias2: 0.978685200214386, variance: 0.030220340937376022\n",
      "Train size: [400] hidden size: [14] trial: 25, train_loss: 1.939572, test loss: 1.008446, bias2: 0.9783384799957275, variance: 0.030107025057077408\n",
      "Train size: [400] hidden size: [14] trial: 26, train_loss: 1.942219, test loss: 1.008126, bias2: 0.9777724146842957, variance: 0.030353736132383347\n",
      "Train size: [400] hidden size: [14] trial: 27, train_loss: 1.949917, test loss: 1.007775, bias2: 0.978023111820221, variance: 0.02975197322666645\n",
      "Train size: [400] hidden size: [14] trial: 28, train_loss: 1.948539, test loss: 1.007505, bias2: 0.9776995778083801, variance: 0.029805123805999756\n",
      "Train size: [400] hidden size: [14] trial: 29, train_loss: 1.940208, test loss: 1.007409, bias2: 0.9779034852981567, variance: 0.029505988582968712\n",
      "Train size: [400] hidden size: [14] trial: 30, train_loss: 1.932683, test loss: 1.007348, bias2: 0.978410005569458, variance: 0.028937550261616707\n",
      "Train size: [400] hidden size: [14] trial: 31, train_loss: 1.930713, test loss: 1.007384, bias2: 0.9784897565841675, variance: 0.028893815353512764\n",
      "Train size: [400] hidden size: [14] trial: 32, train_loss: 1.927424, test loss: 1.006997, bias2: 0.9780834317207336, variance: 0.028913548216223717\n",
      "Train size: [400] hidden size: [14] trial: 33, train_loss: 1.933666, test loss: 1.007419, bias2: 0.9786874055862427, variance: 0.028731465339660645\n",
      "Train size: [400] hidden size: [14] trial: 34, train_loss: 1.926753, test loss: 1.007529, bias2: 0.979131817817688, variance: 0.0283973328769207\n",
      "Train size: [400] hidden size: [14] trial: 35, train_loss: 1.923156, test loss: 1.007843, bias2: 0.9795828461647034, variance: 0.028260504826903343\n",
      "Train size: [400] hidden size: [14] trial: 36, train_loss: 1.923916, test loss: 1.008352, bias2: 0.9794992208480835, variance: 0.028852473944425583\n",
      "Train size: [400] hidden size: [14] trial: 37, train_loss: 1.929040, test loss: 1.008631, bias2: 0.9793827533721924, variance: 0.029248477891087532\n",
      "Train size: [400] hidden size: [14] trial: 38, train_loss: 1.930168, test loss: 1.007946, bias2: 0.9784493446350098, variance: 0.02949640341103077\n",
      "Train size: [400] hidden size: [14] trial: 39, train_loss: 1.930557, test loss: 1.007711, bias2: 0.9776260852813721, variance: 0.030084483325481415\n",
      "Train size: [400] hidden size: [14] trial: 40, train_loss: 1.936611, test loss: 1.007822, bias2: 0.9773646593093872, variance: 0.030457286164164543\n",
      "Train size: [400] hidden size: [14] trial: 41, train_loss: 1.936684, test loss: 1.007905, bias2: 0.9776405692100525, variance: 0.03026396594941616\n",
      "Train size: [400] hidden size: [14] trial: 42, train_loss: 1.937925, test loss: 1.007434, bias2: 0.977315366268158, variance: 0.03011886402964592\n",
      "Train size: [400] hidden size: [14] trial: 43, train_loss: 1.935543, test loss: 1.007350, bias2: 0.9772639870643616, variance: 0.030085979029536247\n",
      "Train size: [400] hidden size: [14] trial: 44, train_loss: 1.934547, test loss: 1.007138, bias2: 0.9768416881561279, variance: 0.03029593825340271\n",
      "Train size: [400] hidden size: [14] trial: 45, train_loss: 1.935675, test loss: 1.007363, bias2: 0.9774127006530762, variance: 0.029950745403766632\n",
      "Train size: [400] hidden size: [14] trial: 46, train_loss: 1.937825, test loss: 1.007294, bias2: 0.9776597023010254, variance: 0.029634451493620872\n",
      "Train size: [400] hidden size: [14] trial: 47, train_loss: 1.938117, test loss: 1.007240, bias2: 0.977949321269989, variance: 0.029290854930877686\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [14] trial: 48, train_loss: 1.940340, test loss: 1.007331, bias2: 0.9783313274383545, variance: 0.028999585658311844\n",
      "Train size: [400] hidden size: [14] trial: 49, train_loss: 1.936916, test loss: 1.007245, bias2: 0.9784054756164551, variance: 0.028839251026511192\n",
      "##################################################\n",
      "Train size: [400] hidden size: [16] trial: 0, train_loss: 1.849494, test loss: 1.014207, bias2: 1.0142066478729248, variance: 1.3380634100723654e-10\n",
      "Train size: [400] hidden size: [16] trial: 1, train_loss: 1.887081, test loss: 1.015712, bias2: 1.0079091787338257, variance: 0.007802724838256836\n",
      "Train size: [400] hidden size: [16] trial: 2, train_loss: 1.822992, test loss: 1.013926, bias2: 1.0002537965774536, variance: 0.013672460801899433\n",
      "Train size: [400] hidden size: [16] trial: 3, train_loss: 1.825724, test loss: 1.010298, bias2: 0.9949454665184021, variance: 0.01535257138311863\n",
      "Train size: [400] hidden size: [16] trial: 4, train_loss: 1.825658, test loss: 1.016651, bias2: 0.9973114132881165, variance: 0.019339362159371376\n",
      "Train size: [400] hidden size: [16] trial: 5, train_loss: 1.846683, test loss: 1.019268, bias2: 0.9989424347877502, variance: 0.02032526396214962\n",
      "Train size: [400] hidden size: [16] trial: 6, train_loss: 1.868147, test loss: 1.016456, bias2: 0.9934203624725342, variance: 0.023035747930407524\n",
      "Train size: [400] hidden size: [16] trial: 7, train_loss: 1.868172, test loss: 1.016186, bias2: 0.9922776818275452, variance: 0.023907965049147606\n",
      "Train size: [400] hidden size: [16] trial: 8, train_loss: 1.844854, test loss: 1.013838, bias2: 0.990486741065979, variance: 0.023351401090621948\n",
      "Train size: [400] hidden size: [16] trial: 9, train_loss: 1.869500, test loss: 1.014406, bias2: 0.9880312085151672, variance: 0.026374418288469315\n",
      "Train size: [400] hidden size: [16] trial: 10, train_loss: 1.868132, test loss: 1.014369, bias2: 0.9868308305740356, variance: 0.027537675574421883\n",
      "Train size: [400] hidden size: [16] trial: 11, train_loss: 1.872699, test loss: 1.012610, bias2: 0.984548807144165, variance: 0.028061266988515854\n",
      "Train size: [400] hidden size: [16] trial: 12, train_loss: 1.872225, test loss: 1.010676, bias2: 0.9820850491523743, variance: 0.02859049290418625\n",
      "Train size: [400] hidden size: [16] trial: 13, train_loss: 1.876972, test loss: 1.010212, bias2: 0.9816106557846069, variance: 0.02860107831656933\n",
      "Train size: [400] hidden size: [16] trial: 14, train_loss: 1.885520, test loss: 1.010454, bias2: 0.9817709922790527, variance: 0.028683077543973923\n",
      "Train size: [400] hidden size: [16] trial: 15, train_loss: 1.887637, test loss: 1.010115, bias2: 0.9800945520401001, variance: 0.030020805075764656\n",
      "Train size: [400] hidden size: [16] trial: 16, train_loss: 1.901573, test loss: 1.010031, bias2: 0.9809010624885559, variance: 0.029129795730113983\n",
      "Train size: [400] hidden size: [16] trial: 17, train_loss: 1.895038, test loss: 1.010471, bias2: 0.9822527170181274, variance: 0.02821815200150013\n",
      "Train size: [400] hidden size: [16] trial: 18, train_loss: 1.884255, test loss: 1.010245, bias2: 0.9821669459342957, variance: 0.02807765267789364\n",
      "Train size: [400] hidden size: [16] trial: 19, train_loss: 1.891323, test loss: 1.009657, bias2: 0.9816493391990662, variance: 0.028007419779896736\n",
      "Train size: [400] hidden size: [16] trial: 20, train_loss: 1.900772, test loss: 1.009372, bias2: 0.9813855290412903, variance: 0.027986610308289528\n",
      "Train size: [400] hidden size: [16] trial: 21, train_loss: 1.903058, test loss: 1.009458, bias2: 0.9821230173110962, variance: 0.027334701269865036\n",
      "Train size: [400] hidden size: [16] trial: 22, train_loss: 1.904737, test loss: 1.009608, bias2: 0.9821097254753113, variance: 0.027498643845319748\n",
      "Train size: [400] hidden size: [16] trial: 23, train_loss: 1.911023, test loss: 1.009430, bias2: 0.9817518591880798, variance: 0.027677807956933975\n",
      "Train size: [400] hidden size: [16] trial: 24, train_loss: 1.910112, test loss: 1.009615, bias2: 0.9822232723236084, variance: 0.02739131823182106\n",
      "Train size: [400] hidden size: [16] trial: 25, train_loss: 1.908270, test loss: 1.008816, bias2: 0.9815055727958679, variance: 0.02731041982769966\n",
      "Train size: [400] hidden size: [16] trial: 26, train_loss: 1.901720, test loss: 1.008645, bias2: 0.9818164706230164, variance: 0.02682836353778839\n",
      "Train size: [400] hidden size: [16] trial: 27, train_loss: 1.903780, test loss: 1.008337, bias2: 0.9813841581344604, variance: 0.02695334143936634\n",
      "Train size: [400] hidden size: [16] trial: 28, train_loss: 1.903463, test loss: 1.008874, bias2: 0.9817004799842834, variance: 0.027173586189746857\n",
      "Train size: [400] hidden size: [16] trial: 29, train_loss: 1.903758, test loss: 1.008784, bias2: 0.9814022183418274, variance: 0.02738157846033573\n",
      "Train size: [400] hidden size: [16] trial: 30, train_loss: 1.900098, test loss: 1.008768, bias2: 0.9815706610679626, variance: 0.027196917682886124\n",
      "Train size: [400] hidden size: [16] trial: 31, train_loss: 1.908191, test loss: 1.008776, bias2: 0.9819262027740479, variance: 0.026849407702684402\n",
      "Train size: [400] hidden size: [16] trial: 32, train_loss: 1.914525, test loss: 1.008766, bias2: 0.9813784956932068, variance: 0.02738792449235916\n",
      "Train size: [400] hidden size: [16] trial: 33, train_loss: 1.912778, test loss: 1.008361, bias2: 0.9811092019081116, variance: 0.02725178748369217\n",
      "Train size: [400] hidden size: [16] trial: 34, train_loss: 1.912344, test loss: 1.008838, bias2: 0.9816761016845703, variance: 0.027161462232470512\n",
      "Train size: [400] hidden size: [16] trial: 35, train_loss: 1.911718, test loss: 1.008633, bias2: 0.9814578294754028, variance: 0.027175569906830788\n",
      "Train size: [400] hidden size: [16] trial: 36, train_loss: 1.913273, test loss: 1.008576, bias2: 0.9811726212501526, variance: 0.02740328572690487\n",
      "Train size: [400] hidden size: [16] trial: 37, train_loss: 1.910026, test loss: 1.008104, bias2: 0.9802359342575073, variance: 0.027867551892995834\n",
      "Train size: [400] hidden size: [16] trial: 38, train_loss: 1.910390, test loss: 1.007709, bias2: 0.9796470999717712, variance: 0.02806159295141697\n",
      "Train size: [400] hidden size: [16] trial: 39, train_loss: 1.913003, test loss: 1.008085, bias2: 0.9796751737594604, variance: 0.028410309925675392\n",
      "Train size: [400] hidden size: [16] trial: 40, train_loss: 1.916527, test loss: 1.008109, bias2: 0.9795618057250977, variance: 0.028547042980790138\n",
      "Train size: [400] hidden size: [16] trial: 41, train_loss: 1.920322, test loss: 1.008120, bias2: 0.9794633984565735, variance: 0.028656208887696266\n",
      "Train size: [400] hidden size: [16] trial: 42, train_loss: 1.917994, test loss: 1.008033, bias2: 0.97955721616745, variance: 0.02847556211054325\n",
      "Train size: [400] hidden size: [16] trial: 43, train_loss: 1.916516, test loss: 1.008538, bias2: 0.9799500107765198, variance: 0.028588222339749336\n",
      "Train size: [400] hidden size: [16] trial: 44, train_loss: 1.917021, test loss: 1.009145, bias2: 0.9802823662757874, variance: 0.02886216714978218\n",
      "Train size: [400] hidden size: [16] trial: 45, train_loss: 1.917463, test loss: 1.008827, bias2: 0.9799054861068726, variance: 0.028921393677592278\n",
      "Train size: [400] hidden size: [16] trial: 46, train_loss: 1.922634, test loss: 1.008483, bias2: 0.9794576168060303, variance: 0.029025645926594734\n",
      "Train size: [400] hidden size: [16] trial: 47, train_loss: 1.926362, test loss: 1.008609, bias2: 0.9790413975715637, variance: 0.029567869380116463\n",
      "Train size: [400] hidden size: [16] trial: 48, train_loss: 1.922975, test loss: 1.008557, bias2: 0.9786050915718079, variance: 0.029951369389891624\n",
      "Train size: [400] hidden size: [16] trial: 49, train_loss: 1.923179, test loss: 1.008300, bias2: 0.9784084558486938, variance: 0.029891828075051308\n",
      "##################################################\n",
      "Train size: [400] hidden size: [19] trial: 0, train_loss: 1.886400, test loss: 0.997016, bias2: 0.9970155954360962, variance: -1.7029898324860682e-10\n",
      "Train size: [400] hidden size: [19] trial: 1, train_loss: 1.799984, test loss: 1.008216, bias2: 0.9923763275146484, variance: 0.015839697793126106\n",
      "Train size: [400] hidden size: [19] trial: 2, train_loss: 1.792785, test loss: 1.011459, bias2: 0.9933468699455261, variance: 0.01811174303293228\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [19] trial: 3, train_loss: 1.848218, test loss: 1.010496, bias2: 0.9839601516723633, variance: 0.02653549052774906\n",
      "Train size: [400] hidden size: [19] trial: 4, train_loss: 1.852955, test loss: 1.011847, bias2: 0.9841907620429993, variance: 0.027655990794301033\n",
      "Train size: [400] hidden size: [19] trial: 5, train_loss: 1.824316, test loss: 1.013311, bias2: 0.9871945381164551, variance: 0.0261160209774971\n",
      "Train size: [400] hidden size: [19] trial: 6, train_loss: 1.823268, test loss: 1.011938, bias2: 0.9850625395774841, variance: 0.026875300332903862\n",
      "Train size: [400] hidden size: [19] trial: 7, train_loss: 1.839288, test loss: 1.011786, bias2: 0.9855703115463257, variance: 0.026215657591819763\n",
      "Train size: [400] hidden size: [19] trial: 8, train_loss: 1.844907, test loss: 1.010013, bias2: 0.9839005470275879, variance: 0.026112545281648636\n",
      "Train size: [400] hidden size: [19] trial: 9, train_loss: 1.860490, test loss: 1.010702, bias2: 0.9845054745674133, variance: 0.02619655802845955\n",
      "Train size: [400] hidden size: [19] trial: 10, train_loss: 1.891505, test loss: 1.011396, bias2: 0.9841121435165405, variance: 0.02728426456451416\n",
      "Train size: [400] hidden size: [19] trial: 11, train_loss: 1.899753, test loss: 1.011419, bias2: 0.9841060042381287, variance: 0.027312934398651123\n",
      "Train size: [400] hidden size: [19] trial: 12, train_loss: 1.922309, test loss: 1.010849, bias2: 0.9831086993217468, variance: 0.02774006500840187\n",
      "Train size: [400] hidden size: [19] trial: 13, train_loss: 1.917773, test loss: 1.010581, bias2: 0.9821680188179016, variance: 0.02841266803443432\n",
      "Train size: [400] hidden size: [19] trial: 14, train_loss: 1.906946, test loss: 1.010142, bias2: 0.9818019270896912, variance: 0.028339935466647148\n",
      "Train size: [400] hidden size: [19] trial: 15, train_loss: 1.897419, test loss: 1.010437, bias2: 0.9824104905128479, variance: 0.028026031330227852\n",
      "Train size: [400] hidden size: [19] trial: 16, train_loss: 1.904835, test loss: 1.011066, bias2: 0.9827696681022644, variance: 0.028295839205384254\n",
      "Train size: [400] hidden size: [19] trial: 17, train_loss: 1.911835, test loss: 1.011275, bias2: 0.9823911190032959, variance: 0.028883840888738632\n",
      "Train size: [400] hidden size: [19] trial: 18, train_loss: 1.910487, test loss: 1.011161, bias2: 0.9820441603660583, variance: 0.029117152094841003\n",
      "Train size: [400] hidden size: [19] trial: 19, train_loss: 1.907750, test loss: 1.010624, bias2: 0.9806814193725586, variance: 0.02994285710155964\n",
      "Train size: [400] hidden size: [19] trial: 20, train_loss: 1.909353, test loss: 1.011203, bias2: 0.98070228099823, variance: 0.030501127243041992\n",
      "Train size: [400] hidden size: [19] trial: 21, train_loss: 1.919204, test loss: 1.010998, bias2: 0.9809441566467285, variance: 0.030053403228521347\n",
      "Train size: [400] hidden size: [19] trial: 22, train_loss: 1.920268, test loss: 1.010804, bias2: 0.9809743165969849, variance: 0.029829949140548706\n",
      "Train size: [400] hidden size: [19] trial: 23, train_loss: 1.910032, test loss: 1.010514, bias2: 0.9808394312858582, variance: 0.029674958437681198\n",
      "Train size: [400] hidden size: [19] trial: 24, train_loss: 1.907784, test loss: 1.009081, bias2: 0.9786883592605591, variance: 0.030392862856388092\n",
      "Train size: [400] hidden size: [19] trial: 25, train_loss: 1.906092, test loss: 1.008776, bias2: 0.9786466360092163, variance: 0.03012920543551445\n",
      "Train size: [400] hidden size: [19] trial: 26, train_loss: 1.916834, test loss: 1.008933, bias2: 0.9792431592941284, variance: 0.029689420014619827\n",
      "Train size: [400] hidden size: [19] trial: 27, train_loss: 1.916022, test loss: 1.007841, bias2: 0.9780319929122925, variance: 0.029808739200234413\n",
      "Train size: [400] hidden size: [19] trial: 28, train_loss: 1.909478, test loss: 1.008173, bias2: 0.9783442616462708, variance: 0.029828956350684166\n",
      "Train size: [400] hidden size: [19] trial: 29, train_loss: 1.903874, test loss: 1.008234, bias2: 0.9784573912620544, variance: 0.02977675572037697\n",
      "Train size: [400] hidden size: [19] trial: 30, train_loss: 1.909970, test loss: 1.008419, bias2: 0.9782429337501526, variance: 0.03017607517540455\n",
      "Train size: [400] hidden size: [19] trial: 31, train_loss: 1.912634, test loss: 1.008487, bias2: 0.9782825112342834, variance: 0.030204949900507927\n",
      "Train size: [400] hidden size: [19] trial: 32, train_loss: 1.906504, test loss: 1.008697, bias2: 0.9778014421463013, variance: 0.030895812436938286\n",
      "Train size: [400] hidden size: [19] trial: 33, train_loss: 1.901812, test loss: 1.009020, bias2: 0.9780664443969727, variance: 0.030953744426369667\n",
      "Train size: [400] hidden size: [19] trial: 34, train_loss: 1.899962, test loss: 1.008858, bias2: 0.9782539010047913, variance: 0.03060407191514969\n",
      "Train size: [400] hidden size: [19] trial: 35, train_loss: 1.911460, test loss: 1.009154, bias2: 0.978893518447876, variance: 0.030260661616921425\n",
      "Train size: [400] hidden size: [19] trial: 36, train_loss: 1.909027, test loss: 1.009436, bias2: 0.9790441989898682, variance: 0.030391588807106018\n",
      "Train size: [400] hidden size: [19] trial: 37, train_loss: 1.901624, test loss: 1.008879, bias2: 0.9782612919807434, variance: 0.030617903918027878\n",
      "Train size: [400] hidden size: [19] trial: 38, train_loss: 1.902248, test loss: 1.009175, bias2: 0.978420078754425, variance: 0.030754512175917625\n",
      "Train size: [400] hidden size: [19] trial: 39, train_loss: 1.903922, test loss: 1.009237, bias2: 0.9782953858375549, variance: 0.030941324308514595\n",
      "Train size: [400] hidden size: [19] trial: 40, train_loss: 1.904544, test loss: 1.009402, bias2: 0.9789021015167236, variance: 0.030499961227178574\n",
      "Train size: [400] hidden size: [19] trial: 41, train_loss: 1.897936, test loss: 1.009401, bias2: 0.9789474606513977, variance: 0.030453985556960106\n",
      "Train size: [400] hidden size: [19] trial: 42, train_loss: 1.899639, test loss: 1.009658, bias2: 0.9792306423187256, variance: 0.0304275956004858\n",
      "Train size: [400] hidden size: [19] trial: 43, train_loss: 1.903861, test loss: 1.009074, bias2: 0.9787442684173584, variance: 0.030329452827572823\n",
      "Train size: [400] hidden size: [19] trial: 44, train_loss: 1.901899, test loss: 1.008874, bias2: 0.9785468578338623, variance: 0.03032682090997696\n",
      "Train size: [400] hidden size: [19] trial: 45, train_loss: 1.896614, test loss: 1.008667, bias2: 0.9783403873443604, variance: 0.030326344072818756\n",
      "Train size: [400] hidden size: [19] trial: 46, train_loss: 1.898714, test loss: 1.008903, bias2: 0.9788474440574646, variance: 0.03005548007786274\n",
      "Train size: [400] hidden size: [19] trial: 47, train_loss: 1.898093, test loss: 1.008989, bias2: 0.9783264994621277, variance: 0.030662592500448227\n",
      "Train size: [400] hidden size: [19] trial: 48, train_loss: 1.895568, test loss: 1.009040, bias2: 0.9780982732772827, variance: 0.03094160184264183\n",
      "Train size: [400] hidden size: [19] trial: 49, train_loss: 1.900987, test loss: 1.008909, bias2: 0.9777386784553528, variance: 0.031170325353741646\n",
      "##################################################\n",
      "Train size: [400] hidden size: [22] trial: 0, train_loss: 1.598521, test loss: 0.994866, bias2: 0.9948657751083374, variance: 9.731369876586626e-11\n",
      "Train size: [400] hidden size: [22] trial: 1, train_loss: 1.779859, test loss: 1.002468, bias2: 0.9872465133666992, variance: 0.015221497975289822\n",
      "Train size: [400] hidden size: [22] trial: 2, train_loss: 1.778488, test loss: 1.001815, bias2: 0.978864848613739, variance: 0.022950224578380585\n",
      "Train size: [400] hidden size: [22] trial: 3, train_loss: 1.809085, test loss: 1.010854, bias2: 0.9767217636108398, variance: 0.034132350236177444\n",
      "Train size: [400] hidden size: [22] trial: 4, train_loss: 1.837981, test loss: 1.012686, bias2: 0.9784561395645142, variance: 0.034230221062898636\n",
      "Train size: [400] hidden size: [22] trial: 5, train_loss: 1.899411, test loss: 1.017034, bias2: 0.9817137122154236, variance: 0.035320576280355453\n",
      "Train size: [400] hidden size: [22] trial: 6, train_loss: 1.927892, test loss: 1.013467, bias2: 0.9791926145553589, variance: 0.03427460789680481\n",
      "Train size: [400] hidden size: [22] trial: 7, train_loss: 1.912268, test loss: 1.017325, bias2: 0.9829831719398499, variance: 0.03434211388230324\n",
      "Train size: [400] hidden size: [22] trial: 8, train_loss: 1.888526, test loss: 1.015356, bias2: 0.9805797934532166, variance: 0.034776266664266586\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [22] trial: 9, train_loss: 1.900421, test loss: 1.016392, bias2: 0.9796793460845947, variance: 0.036712776869535446\n",
      "Train size: [400] hidden size: [22] trial: 10, train_loss: 1.866392, test loss: 1.012075, bias2: 0.9743219017982483, variance: 0.03775278478860855\n",
      "Train size: [400] hidden size: [22] trial: 11, train_loss: 1.861971, test loss: 1.010415, bias2: 0.9726834893226624, variance: 0.037731971591711044\n",
      "Train size: [400] hidden size: [22] trial: 12, train_loss: 1.866212, test loss: 1.011779, bias2: 0.9740248918533325, variance: 0.037754278630018234\n",
      "Train size: [400] hidden size: [22] trial: 13, train_loss: 1.857480, test loss: 1.012507, bias2: 0.974590003490448, variance: 0.03791693225502968\n",
      "Train size: [400] hidden size: [22] trial: 14, train_loss: 1.854938, test loss: 1.011502, bias2: 0.973438024520874, variance: 0.0380643829703331\n",
      "Train size: [400] hidden size: [22] trial: 15, train_loss: 1.858852, test loss: 1.011676, bias2: 0.9742839932441711, variance: 0.03739173710346222\n",
      "Train size: [400] hidden size: [22] trial: 16, train_loss: 1.862229, test loss: 1.011779, bias2: 0.9741904735565186, variance: 0.037588611245155334\n",
      "Train size: [400] hidden size: [22] trial: 17, train_loss: 1.855603, test loss: 1.011863, bias2: 0.9731636643409729, variance: 0.0386992022395134\n",
      "Train size: [400] hidden size: [22] trial: 18, train_loss: 1.852546, test loss: 1.011173, bias2: 0.9724998474121094, variance: 0.03867330402135849\n",
      "Train size: [400] hidden size: [22] trial: 19, train_loss: 1.857066, test loss: 1.011132, bias2: 0.9726165533065796, variance: 0.03851582854986191\n",
      "Train size: [400] hidden size: [22] trial: 20, train_loss: 1.862674, test loss: 1.010348, bias2: 0.972133994102478, variance: 0.03821372613310814\n",
      "Train size: [400] hidden size: [22] trial: 21, train_loss: 1.861093, test loss: 1.010712, bias2: 0.9727228283882141, variance: 0.03798907622694969\n",
      "Train size: [400] hidden size: [22] trial: 22, train_loss: 1.859120, test loss: 1.010141, bias2: 0.972113311290741, variance: 0.03802816569805145\n",
      "Train size: [400] hidden size: [22] trial: 23, train_loss: 1.859019, test loss: 1.009174, bias2: 0.9704881906509399, variance: 0.03868558257818222\n",
      "Train size: [400] hidden size: [22] trial: 24, train_loss: 1.850885, test loss: 1.009267, bias2: 0.9712685346603394, variance: 0.03799867630004883\n",
      "Train size: [400] hidden size: [22] trial: 25, train_loss: 1.850106, test loss: 1.009484, bias2: 0.9712480902671814, variance: 0.038235824555158615\n",
      "Train size: [400] hidden size: [22] trial: 26, train_loss: 1.852899, test loss: 1.010338, bias2: 0.972305178642273, variance: 0.0380324125289917\n",
      "Train size: [400] hidden size: [22] trial: 27, train_loss: 1.854666, test loss: 1.011348, bias2: 0.9730639457702637, variance: 0.03828408196568489\n",
      "Train size: [400] hidden size: [22] trial: 28, train_loss: 1.849169, test loss: 1.011046, bias2: 0.9734859466552734, variance: 0.03756000101566315\n",
      "Train size: [400] hidden size: [22] trial: 29, train_loss: 1.842074, test loss: 1.010363, bias2: 0.973025918006897, variance: 0.037337325513362885\n",
      "Train size: [400] hidden size: [22] trial: 30, train_loss: 1.842121, test loss: 1.009339, bias2: 0.971676766872406, variance: 0.037661708891391754\n",
      "Train size: [400] hidden size: [22] trial: 31, train_loss: 1.839277, test loss: 1.009555, bias2: 0.9719082713127136, variance: 0.037646617740392685\n",
      "Train size: [400] hidden size: [22] trial: 32, train_loss: 1.841881, test loss: 1.009710, bias2: 0.9723325371742249, variance: 0.03737705200910568\n",
      "Train size: [400] hidden size: [22] trial: 33, train_loss: 1.843930, test loss: 1.011023, bias2: 0.9727866053581238, variance: 0.03823595494031906\n",
      "Train size: [400] hidden size: [22] trial: 34, train_loss: 1.854272, test loss: 1.011436, bias2: 0.9730336666107178, variance: 0.03840198740363121\n",
      "Train size: [400] hidden size: [22] trial: 35, train_loss: 1.853861, test loss: 1.010506, bias2: 0.9719607830047607, variance: 0.038545023649930954\n",
      "Train size: [400] hidden size: [22] trial: 36, train_loss: 1.857333, test loss: 1.010960, bias2: 0.9722105264663696, variance: 0.038749560713768005\n",
      "Train size: [400] hidden size: [22] trial: 37, train_loss: 1.858989, test loss: 1.010636, bias2: 0.9721946716308594, variance: 0.03844150900840759\n",
      "Train size: [400] hidden size: [22] trial: 38, train_loss: 1.858443, test loss: 1.010747, bias2: 0.9716034531593323, variance: 0.03914383798837662\n",
      "Train size: [400] hidden size: [22] trial: 39, train_loss: 1.856528, test loss: 1.010815, bias2: 0.9718616008758545, variance: 0.03895355015993118\n",
      "Train size: [400] hidden size: [22] trial: 40, train_loss: 1.858754, test loss: 1.010688, bias2: 0.9717459082603455, variance: 0.03894193843007088\n",
      "Train size: [400] hidden size: [22] trial: 41, train_loss: 1.857731, test loss: 1.010914, bias2: 0.9723566174507141, variance: 0.038556989282369614\n",
      "Train size: [400] hidden size: [22] trial: 42, train_loss: 1.852712, test loss: 1.010930, bias2: 0.9722288846969604, variance: 0.03870156407356262\n",
      "Train size: [400] hidden size: [22] trial: 43, train_loss: 1.855118, test loss: 1.011280, bias2: 0.9729698896408081, variance: 0.03830980509519577\n",
      "Train size: [400] hidden size: [22] trial: 44, train_loss: 1.857754, test loss: 1.011060, bias2: 0.972852885723114, variance: 0.03820665180683136\n",
      "Train size: [400] hidden size: [22] trial: 45, train_loss: 1.858551, test loss: 1.011324, bias2: 0.9729524254798889, variance: 0.03837199881672859\n",
      "Train size: [400] hidden size: [22] trial: 46, train_loss: 1.856769, test loss: 1.011185, bias2: 0.9723820090293884, variance: 0.03880305588245392\n",
      "Train size: [400] hidden size: [22] trial: 47, train_loss: 1.856920, test loss: 1.010970, bias2: 0.972290575504303, variance: 0.03867906332015991\n",
      "Train size: [400] hidden size: [22] trial: 48, train_loss: 1.856467, test loss: 1.010880, bias2: 0.9722216129302979, variance: 0.03865803778171539\n",
      "Train size: [400] hidden size: [22] trial: 49, train_loss: 1.859719, test loss: 1.010970, bias2: 0.9726482629776001, variance: 0.03832148760557175\n",
      "##################################################\n",
      "Train size: [400] hidden size: [25] trial: 0, train_loss: 1.687477, test loss: 1.020197, bias2: 1.0201969146728516, variance: -2.4328425385355956e-10\n",
      "Train size: [400] hidden size: [25] trial: 1, train_loss: 1.776066, test loss: 1.014856, bias2: 0.9965460300445557, variance: 0.018309833481907845\n",
      "Train size: [400] hidden size: [25] trial: 2, train_loss: 1.789026, test loss: 1.009744, bias2: 0.9895590543746948, variance: 0.020185332745313644\n",
      "Train size: [400] hidden size: [25] trial: 3, train_loss: 1.844471, test loss: 1.016774, bias2: 0.9917872548103333, variance: 0.024986697360873222\n",
      "Train size: [400] hidden size: [25] trial: 4, train_loss: 1.869138, test loss: 1.018062, bias2: 0.9912146925926208, variance: 0.026847517117857933\n",
      "Train size: [400] hidden size: [25] trial: 5, train_loss: 1.874948, test loss: 1.019978, bias2: 0.9903923869132996, variance: 0.02958577685058117\n",
      "Train size: [400] hidden size: [25] trial: 6, train_loss: 1.854425, test loss: 1.018044, bias2: 0.9886612892150879, variance: 0.02938237413764\n",
      "Train size: [400] hidden size: [25] trial: 7, train_loss: 1.892310, test loss: 1.015298, bias2: 0.9871600270271301, variance: 0.02813820168375969\n",
      "Train size: [400] hidden size: [25] trial: 8, train_loss: 1.878378, test loss: 1.011183, bias2: 0.9818832278251648, variance: 0.029299795627593994\n",
      "Train size: [400] hidden size: [25] trial: 9, train_loss: 1.871770, test loss: 1.011064, bias2: 0.9772195816040039, variance: 0.033844832330942154\n",
      "Train size: [400] hidden size: [25] trial: 10, train_loss: 1.870063, test loss: 1.014406, bias2: 0.9781192541122437, variance: 0.03628670424222946\n",
      "Train size: [400] hidden size: [25] trial: 11, train_loss: 1.872191, test loss: 1.012224, bias2: 0.9724292755126953, variance: 0.03979470953345299\n",
      "Train size: [400] hidden size: [25] trial: 12, train_loss: 1.861753, test loss: 1.012638, bias2: 0.9733418822288513, variance: 0.03929642215371132\n",
      "Train size: [400] hidden size: [25] trial: 13, train_loss: 1.844461, test loss: 1.011678, bias2: 0.9717759490013123, variance: 0.03990192338824272\n",
      "Train size: [400] hidden size: [25] trial: 14, train_loss: 1.847122, test loss: 1.011307, bias2: 0.9713907241821289, variance: 0.03991665691137314\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [25] trial: 15, train_loss: 1.838827, test loss: 1.011610, bias2: 0.9720054864883423, variance: 0.039604902267456055\n",
      "Train size: [400] hidden size: [25] trial: 16, train_loss: 1.846470, test loss: 1.011184, bias2: 0.9716703295707703, variance: 0.03951329365372658\n",
      "Train size: [400] hidden size: [25] trial: 17, train_loss: 1.855481, test loss: 1.011223, bias2: 0.9706658720970154, variance: 0.04055742919445038\n",
      "Train size: [400] hidden size: [25] trial: 18, train_loss: 1.852215, test loss: 1.011616, bias2: 0.9709435701370239, variance: 0.04067252576351166\n",
      "Train size: [400] hidden size: [25] trial: 19, train_loss: 1.852871, test loss: 1.010906, bias2: 0.9696024060249329, variance: 0.041303906589746475\n",
      "Train size: [400] hidden size: [25] trial: 20, train_loss: 1.851923, test loss: 1.011003, bias2: 0.9704277515411377, variance: 0.04057548567652702\n",
      "Train size: [400] hidden size: [25] trial: 21, train_loss: 1.849073, test loss: 1.010336, bias2: 0.9697562456130981, variance: 0.0405796580016613\n",
      "Train size: [400] hidden size: [25] trial: 22, train_loss: 1.848623, test loss: 1.010356, bias2: 0.969940185546875, variance: 0.040415745228528976\n",
      "Train size: [400] hidden size: [25] trial: 23, train_loss: 1.853006, test loss: 1.010072, bias2: 0.9692578911781311, variance: 0.040813956409692764\n",
      "Train size: [400] hidden size: [25] trial: 24, train_loss: 1.841691, test loss: 1.010923, bias2: 0.969515860080719, variance: 0.04140752553939819\n",
      "Train size: [400] hidden size: [25] trial: 25, train_loss: 1.844021, test loss: 1.011315, bias2: 0.9693443775177002, variance: 0.0419703833758831\n",
      "Train size: [400] hidden size: [25] trial: 26, train_loss: 1.842520, test loss: 1.010624, bias2: 0.9691104888916016, variance: 0.041513919830322266\n",
      "Train size: [400] hidden size: [25] trial: 27, train_loss: 1.852917, test loss: 1.010713, bias2: 0.9696291089057922, variance: 0.041083529591560364\n",
      "Train size: [400] hidden size: [25] trial: 28, train_loss: 1.859329, test loss: 1.010655, bias2: 0.9696412086486816, variance: 0.04101358726620674\n",
      "Train size: [400] hidden size: [25] trial: 29, train_loss: 1.860676, test loss: 1.010538, bias2: 0.9698110222816467, variance: 0.04072717949748039\n",
      "Train size: [400] hidden size: [25] trial: 30, train_loss: 1.863169, test loss: 1.010498, bias2: 0.9697735905647278, variance: 0.04072410240769386\n",
      "Train size: [400] hidden size: [25] trial: 31, train_loss: 1.859941, test loss: 1.010773, bias2: 0.9693767428398132, variance: 0.041396189481019974\n",
      "Train size: [400] hidden size: [25] trial: 32, train_loss: 1.858311, test loss: 1.011703, bias2: 0.9702090620994568, variance: 0.04149418696761131\n",
      "Train size: [400] hidden size: [25] trial: 33, train_loss: 1.866094, test loss: 1.011929, bias2: 0.9709386229515076, variance: 0.04099052771925926\n",
      "Train size: [400] hidden size: [25] trial: 34, train_loss: 1.867999, test loss: 1.011940, bias2: 0.9705924391746521, variance: 0.04134779050946236\n",
      "Train size: [400] hidden size: [25] trial: 35, train_loss: 1.869531, test loss: 1.012114, bias2: 0.9708051681518555, variance: 0.04130851477384567\n",
      "Train size: [400] hidden size: [25] trial: 36, train_loss: 1.866033, test loss: 1.012143, bias2: 0.9710105061531067, variance: 0.041132643818855286\n",
      "Train size: [400] hidden size: [25] trial: 37, train_loss: 1.860267, test loss: 1.011640, bias2: 0.9706070423126221, variance: 0.041032575070858\n",
      "Train size: [400] hidden size: [25] trial: 38, train_loss: 1.862125, test loss: 1.012050, bias2: 0.9708806276321411, variance: 0.04116925969719887\n",
      "Train size: [400] hidden size: [25] trial: 39, train_loss: 1.859273, test loss: 1.011809, bias2: 0.9711195826530457, variance: 0.04068978503346443\n",
      "Train size: [400] hidden size: [25] trial: 40, train_loss: 1.860300, test loss: 1.011837, bias2: 0.971150815486908, variance: 0.04068608209490776\n",
      "Train size: [400] hidden size: [25] trial: 41, train_loss: 1.863649, test loss: 1.012408, bias2: 0.970598042011261, variance: 0.041809484362602234\n",
      "Train size: [400] hidden size: [25] trial: 42, train_loss: 1.862202, test loss: 1.012837, bias2: 0.9713611006736755, variance: 0.04147569090127945\n",
      "Train size: [400] hidden size: [25] trial: 43, train_loss: 1.863038, test loss: 1.012608, bias2: 0.9712801575660706, variance: 0.04132755473256111\n",
      "Train size: [400] hidden size: [25] trial: 44, train_loss: 1.866547, test loss: 1.012553, bias2: 0.9714418053627014, variance: 0.041111286729574203\n",
      "Train size: [400] hidden size: [25] trial: 45, train_loss: 1.864277, test loss: 1.012443, bias2: 0.9715185761451721, variance: 0.040924109518527985\n",
      "Train size: [400] hidden size: [25] trial: 46, train_loss: 1.864094, test loss: 1.012036, bias2: 0.9705320000648499, variance: 0.04150446504354477\n",
      "Train size: [400] hidden size: [25] trial: 47, train_loss: 1.860502, test loss: 1.011428, bias2: 0.9700056910514832, variance: 0.04142197221517563\n",
      "Train size: [400] hidden size: [25] trial: 48, train_loss: 1.866274, test loss: 1.011807, bias2: 0.9699312448501587, variance: 0.04187597334384918\n",
      "Train size: [400] hidden size: [25] trial: 49, train_loss: 1.866838, test loss: 1.011638, bias2: 0.970029890537262, variance: 0.041608382016420364\n",
      "##################################################\n",
      "Train size: [400] hidden size: [29] trial: 0, train_loss: 1.952410, test loss: 1.013329, bias2: 1.0133285522460938, variance: 5.838822203507732e-10\n",
      "Train size: [400] hidden size: [29] trial: 1, train_loss: 1.901373, test loss: 1.008364, bias2: 0.9826512336730957, variance: 0.02571270801126957\n",
      "Train size: [400] hidden size: [29] trial: 2, train_loss: 1.833311, test loss: 1.010716, bias2: 0.977581262588501, variance: 0.03313447907567024\n",
      "Train size: [400] hidden size: [29] trial: 3, train_loss: 1.868848, test loss: 1.016629, bias2: 0.9797958135604858, variance: 0.036833494901657104\n",
      "Train size: [400] hidden size: [29] trial: 4, train_loss: 1.886406, test loss: 1.016079, bias2: 0.9782757759094238, variance: 0.03780306130647659\n",
      "Train size: [400] hidden size: [29] trial: 5, train_loss: 1.893967, test loss: 1.018926, bias2: 0.9804637432098389, variance: 0.03846254199743271\n",
      "Train size: [400] hidden size: [29] trial: 6, train_loss: 1.869947, test loss: 1.016691, bias2: 0.9792951941490173, variance: 0.03739601746201515\n",
      "Train size: [400] hidden size: [29] trial: 7, train_loss: 1.843420, test loss: 1.015061, bias2: 0.9773871898651123, variance: 0.03767383098602295\n",
      "Train size: [400] hidden size: [29] trial: 8, train_loss: 1.864003, test loss: 1.013244, bias2: 0.9743307828903198, variance: 0.038913238793611526\n",
      "Train size: [400] hidden size: [29] trial: 9, train_loss: 1.878649, test loss: 1.016156, bias2: 0.974324107170105, variance: 0.0418323390185833\n",
      "Train size: [400] hidden size: [29] trial: 10, train_loss: 1.876548, test loss: 1.015637, bias2: 0.9735152721405029, variance: 0.042121272534132004\n",
      "Train size: [400] hidden size: [29] trial: 11, train_loss: 1.864312, test loss: 1.017874, bias2: 0.9725471138954163, variance: 0.04532640054821968\n",
      "Train size: [400] hidden size: [29] trial: 12, train_loss: 1.841921, test loss: 1.015176, bias2: 0.9673401117324829, variance: 0.047835856676101685\n",
      "Train size: [400] hidden size: [29] trial: 13, train_loss: 1.833083, test loss: 1.014721, bias2: 0.9669044613838196, variance: 0.04781624302268028\n",
      "Train size: [400] hidden size: [29] trial: 14, train_loss: 1.825514, test loss: 1.014000, bias2: 0.9652700424194336, variance: 0.0487295500934124\n",
      "Train size: [400] hidden size: [29] trial: 15, train_loss: 1.819437, test loss: 1.013890, bias2: 0.9662095308303833, variance: 0.04768059775233269\n",
      "Train size: [400] hidden size: [29] trial: 16, train_loss: 1.820722, test loss: 1.013592, bias2: 0.9644140005111694, variance: 0.04917774721980095\n",
      "Train size: [400] hidden size: [29] trial: 17, train_loss: 1.820482, test loss: 1.015034, bias2: 0.9666104316711426, variance: 0.04842326417565346\n",
      "Train size: [400] hidden size: [29] trial: 18, train_loss: 1.840376, test loss: 1.014805, bias2: 0.9658986330032349, variance: 0.04890666902065277\n",
      "Train size: [400] hidden size: [29] trial: 19, train_loss: 1.843185, test loss: 1.015054, bias2: 0.9664188027381897, variance: 0.04863494634628296\n",
      "Train size: [400] hidden size: [29] trial: 20, train_loss: 1.839260, test loss: 1.013770, bias2: 0.9649029970169067, variance: 0.04886708781123161\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [29] trial: 21, train_loss: 1.827740, test loss: 1.013422, bias2: 0.9646201133728027, variance: 0.04880204796791077\n",
      "Train size: [400] hidden size: [29] trial: 22, train_loss: 1.834396, test loss: 1.012889, bias2: 0.9634888172149658, variance: 0.04940047487616539\n",
      "Train size: [400] hidden size: [29] trial: 23, train_loss: 1.833232, test loss: 1.012713, bias2: 0.9633563756942749, variance: 0.04935609549283981\n",
      "Train size: [400] hidden size: [29] trial: 24, train_loss: 1.829208, test loss: 1.012662, bias2: 0.9637618064880371, variance: 0.048900507390499115\n",
      "Train size: [400] hidden size: [29] trial: 25, train_loss: 1.841411, test loss: 1.013501, bias2: 0.9624866247177124, variance: 0.05101456493139267\n",
      "Train size: [400] hidden size: [29] trial: 26, train_loss: 1.841932, test loss: 1.013186, bias2: 0.9629233479499817, variance: 0.05026241019368172\n",
      "Train size: [400] hidden size: [29] trial: 27, train_loss: 1.842639, test loss: 1.012589, bias2: 0.9628899097442627, variance: 0.049698565155267715\n",
      "Train size: [400] hidden size: [29] trial: 28, train_loss: 1.840931, test loss: 1.012163, bias2: 0.9613601565361023, variance: 0.050802506506443024\n",
      "Train size: [400] hidden size: [29] trial: 29, train_loss: 1.846585, test loss: 1.011160, bias2: 0.9603772163391113, variance: 0.05078256130218506\n",
      "Train size: [400] hidden size: [29] trial: 30, train_loss: 1.853909, test loss: 1.010913, bias2: 0.960169792175293, variance: 0.05074286833405495\n",
      "Train size: [400] hidden size: [29] trial: 31, train_loss: 1.853264, test loss: 1.010434, bias2: 0.9601122140884399, variance: 0.05032191798090935\n",
      "Train size: [400] hidden size: [29] trial: 32, train_loss: 1.848385, test loss: 1.011458, bias2: 0.9610843062400818, variance: 0.05037350580096245\n",
      "Train size: [400] hidden size: [29] trial: 33, train_loss: 1.851191, test loss: 1.011057, bias2: 0.9610098600387573, variance: 0.05004727840423584\n",
      "Train size: [400] hidden size: [29] trial: 34, train_loss: 1.848206, test loss: 1.010913, bias2: 0.9606073498725891, variance: 0.05030576139688492\n",
      "Train size: [400] hidden size: [29] trial: 35, train_loss: 1.852092, test loss: 1.011474, bias2: 0.9609876871109009, variance: 0.05048597976565361\n",
      "Train size: [400] hidden size: [29] trial: 36, train_loss: 1.849056, test loss: 1.011548, bias2: 0.9609614610671997, variance: 0.05058659240603447\n",
      "Train size: [400] hidden size: [29] trial: 37, train_loss: 1.845303, test loss: 1.011776, bias2: 0.9614548683166504, variance: 0.050320882350206375\n",
      "Train size: [400] hidden size: [29] trial: 38, train_loss: 1.846933, test loss: 1.011921, bias2: 0.9615594148635864, variance: 0.050362005829811096\n",
      "Train size: [400] hidden size: [29] trial: 39, train_loss: 1.849037, test loss: 1.011738, bias2: 0.9613240957260132, variance: 0.050413839519023895\n",
      "Train size: [400] hidden size: [29] trial: 40, train_loss: 1.848092, test loss: 1.011613, bias2: 0.9611542224884033, variance: 0.050459131598472595\n",
      "Train size: [400] hidden size: [29] trial: 41, train_loss: 1.850537, test loss: 1.011548, bias2: 0.9608095288276672, variance: 0.050738509744405746\n",
      "Train size: [400] hidden size: [29] trial: 42, train_loss: 1.847714, test loss: 1.010808, bias2: 0.9600477814674377, variance: 0.050760675221681595\n",
      "Train size: [400] hidden size: [29] trial: 43, train_loss: 1.845084, test loss: 1.010921, bias2: 0.9605175256729126, variance: 0.05040359869599342\n",
      "Train size: [400] hidden size: [29] trial: 44, train_loss: 1.843053, test loss: 1.010932, bias2: 0.9607524871826172, variance: 0.05017995834350586\n",
      "Train size: [400] hidden size: [29] trial: 45, train_loss: 1.844625, test loss: 1.011086, bias2: 0.9610114097595215, variance: 0.05007435381412506\n",
      "Train size: [400] hidden size: [29] trial: 46, train_loss: 1.843808, test loss: 1.010162, bias2: 0.9598538875579834, variance: 0.050307877361774445\n",
      "Train size: [400] hidden size: [29] trial: 47, train_loss: 1.849968, test loss: 1.010039, bias2: 0.9591079950332642, variance: 0.05093144252896309\n",
      "Train size: [400] hidden size: [29] trial: 48, train_loss: 1.849477, test loss: 1.009597, bias2: 0.9586742520332336, variance: 0.05092279985547066\n",
      "Train size: [400] hidden size: [29] trial: 49, train_loss: 1.846376, test loss: 1.009677, bias2: 0.9585919380187988, variance: 0.051085203886032104\n",
      "##################################################\n",
      "Train size: [400] hidden size: [33] trial: 0, train_loss: 1.742124, test loss: 1.027351, bias2: 1.0273512601852417, variance: -3.8925479506346505e-10\n",
      "Train size: [400] hidden size: [33] trial: 1, train_loss: 1.772639, test loss: 1.002679, bias2: 0.9738456606864929, variance: 0.028832845389842987\n",
      "Train size: [400] hidden size: [33] trial: 2, train_loss: 1.825034, test loss: 0.998181, bias2: 0.9612839818000793, variance: 0.036897215992212296\n",
      "Train size: [400] hidden size: [33] trial: 3, train_loss: 1.864780, test loss: 1.001271, bias2: 0.9593818783760071, variance: 0.04188887029886246\n",
      "Train size: [400] hidden size: [33] trial: 4, train_loss: 1.864377, test loss: 1.002541, bias2: 0.9579727649688721, variance: 0.04456828534603119\n",
      "Train size: [400] hidden size: [33] trial: 5, train_loss: 1.847070, test loss: 1.005917, bias2: 0.9595752954483032, variance: 0.04634202644228935\n",
      "Train size: [400] hidden size: [33] trial: 6, train_loss: 1.841196, test loss: 0.998642, bias2: 0.9511005282402039, variance: 0.04754191264510155\n",
      "Train size: [400] hidden size: [33] trial: 7, train_loss: 1.849346, test loss: 0.998052, bias2: 0.9452065825462341, variance: 0.05284577235579491\n",
      "Train size: [400] hidden size: [33] trial: 8, train_loss: 1.847939, test loss: 1.000759, bias2: 0.9495230317115784, variance: 0.05123559758067131\n",
      "Train size: [400] hidden size: [33] trial: 9, train_loss: 1.853577, test loss: 1.002622, bias2: 0.9521043300628662, variance: 0.050517816096544266\n",
      "Train size: [400] hidden size: [33] trial: 10, train_loss: 1.861259, test loss: 1.003655, bias2: 0.9540259838104248, variance: 0.0496290922164917\n",
      "Train size: [400] hidden size: [33] trial: 11, train_loss: 1.856831, test loss: 1.002238, bias2: 0.9521867036819458, variance: 0.05005158111453056\n",
      "Train size: [400] hidden size: [33] trial: 12, train_loss: 1.856901, test loss: 1.004080, bias2: 0.952957272529602, variance: 0.05112241953611374\n",
      "Train size: [400] hidden size: [33] trial: 13, train_loss: 1.857608, test loss: 1.003372, bias2: 0.9508922696113586, variance: 0.05247943103313446\n",
      "Train size: [400] hidden size: [33] trial: 14, train_loss: 1.874645, test loss: 1.003935, bias2: 0.9520553350448608, variance: 0.05188009887933731\n",
      "Train size: [400] hidden size: [33] trial: 15, train_loss: 1.878441, test loss: 1.003492, bias2: 0.9514420628547668, variance: 0.052050068974494934\n",
      "Train size: [400] hidden size: [33] trial: 16, train_loss: 1.871023, test loss: 1.004991, bias2: 0.9531850814819336, variance: 0.05180621147155762\n",
      "Train size: [400] hidden size: [33] trial: 17, train_loss: 1.865000, test loss: 1.005187, bias2: 0.9516947269439697, variance: 0.053492315113544464\n",
      "Train size: [400] hidden size: [33] trial: 18, train_loss: 1.879464, test loss: 1.006827, bias2: 0.9526829719543457, variance: 0.05414401739835739\n",
      "Train size: [400] hidden size: [33] trial: 19, train_loss: 1.883127, test loss: 1.006543, bias2: 0.9523736238479614, variance: 0.0541694350540638\n",
      "Train size: [400] hidden size: [33] trial: 20, train_loss: 1.876617, test loss: 1.006532, bias2: 0.9523140788078308, variance: 0.054218094795942307\n",
      "Train size: [400] hidden size: [33] trial: 21, train_loss: 1.877132, test loss: 1.006161, bias2: 0.9521524310112, variance: 0.054009001702070236\n",
      "Train size: [400] hidden size: [33] trial: 22, train_loss: 1.871945, test loss: 1.006600, bias2: 0.9525451064109802, variance: 0.05405453220009804\n",
      "Train size: [400] hidden size: [33] trial: 23, train_loss: 1.868649, test loss: 1.006942, bias2: 0.9530364274978638, variance: 0.05390559881925583\n",
      "Train size: [400] hidden size: [33] trial: 24, train_loss: 1.870445, test loss: 1.007834, bias2: 0.954521656036377, variance: 0.05331195145845413\n",
      "Train size: [400] hidden size: [33] trial: 25, train_loss: 1.880125, test loss: 1.008425, bias2: 0.9551544785499573, variance: 0.053270138800144196\n",
      "Train size: [400] hidden size: [33] trial: 26, train_loss: 1.882684, test loss: 1.008620, bias2: 0.9557207822799683, variance: 0.05289886146783829\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [33] trial: 27, train_loss: 1.875269, test loss: 1.008053, bias2: 0.9549928903579712, variance: 0.053060293197631836\n",
      "Train size: [400] hidden size: [33] trial: 28, train_loss: 1.870882, test loss: 1.009139, bias2: 0.9558483362197876, variance: 0.05329051613807678\n",
      "Train size: [400] hidden size: [33] trial: 29, train_loss: 1.862975, test loss: 1.008297, bias2: 0.955391526222229, variance: 0.05290517956018448\n",
      "Train size: [400] hidden size: [33] trial: 30, train_loss: 1.867737, test loss: 1.007877, bias2: 0.9539913535118103, variance: 0.05388597771525383\n",
      "Train size: [400] hidden size: [33] trial: 31, train_loss: 1.862389, test loss: 1.008099, bias2: 0.9540237188339233, variance: 0.054075345396995544\n",
      "Train size: [400] hidden size: [33] trial: 32, train_loss: 1.855874, test loss: 1.008392, bias2: 0.9544582962989807, variance: 0.05393379554152489\n",
      "Train size: [400] hidden size: [33] trial: 33, train_loss: 1.858951, test loss: 1.007075, bias2: 0.9533388018608093, variance: 0.05373615026473999\n",
      "Train size: [400] hidden size: [33] trial: 34, train_loss: 1.850507, test loss: 1.007608, bias2: 0.9544479250907898, variance: 0.053159769624471664\n",
      "Train size: [400] hidden size: [33] trial: 35, train_loss: 1.850573, test loss: 1.008167, bias2: 0.9555895924568176, variance: 0.05257752910256386\n",
      "Train size: [400] hidden size: [33] trial: 36, train_loss: 1.851199, test loss: 1.008616, bias2: 0.9557443261146545, variance: 0.05287166312336922\n",
      "Train size: [400] hidden size: [33] trial: 37, train_loss: 1.850356, test loss: 1.009495, bias2: 0.956222653388977, variance: 0.053272247314453125\n",
      "Train size: [400] hidden size: [33] trial: 38, train_loss: 1.853555, test loss: 1.008902, bias2: 0.9556373357772827, variance: 0.053264617919921875\n",
      "Train size: [400] hidden size: [33] trial: 39, train_loss: 1.854468, test loss: 1.008961, bias2: 0.955401599407196, variance: 0.05355912074446678\n",
      "Train size: [400] hidden size: [33] trial: 40, train_loss: 1.853670, test loss: 1.008578, bias2: 0.9548563957214355, variance: 0.05372118949890137\n",
      "Train size: [400] hidden size: [33] trial: 41, train_loss: 1.858812, test loss: 1.008187, bias2: 0.9545935392379761, variance: 0.05359341576695442\n",
      "Train size: [400] hidden size: [33] trial: 42, train_loss: 1.856258, test loss: 1.007868, bias2: 0.9544961452484131, variance: 0.053371530026197433\n",
      "Train size: [400] hidden size: [33] trial: 43, train_loss: 1.857533, test loss: 1.008135, bias2: 0.9551292061805725, variance: 0.05300566181540489\n",
      "Train size: [400] hidden size: [33] trial: 44, train_loss: 1.858235, test loss: 1.008536, bias2: 0.9557541012763977, variance: 0.05278162285685539\n",
      "Train size: [400] hidden size: [33] trial: 45, train_loss: 1.857454, test loss: 1.008818, bias2: 0.9560011625289917, variance: 0.05281662195920944\n",
      "Train size: [400] hidden size: [33] trial: 46, train_loss: 1.860462, test loss: 1.008564, bias2: 0.9554920196533203, variance: 0.053072456270456314\n",
      "Train size: [400] hidden size: [33] trial: 47, train_loss: 1.860591, test loss: 1.007922, bias2: 0.9547586441040039, variance: 0.05316302925348282\n",
      "Train size: [400] hidden size: [33] trial: 48, train_loss: 1.859834, test loss: 1.007712, bias2: 0.9542955160140991, variance: 0.05341695249080658\n",
      "Train size: [400] hidden size: [33] trial: 49, train_loss: 1.858649, test loss: 1.007879, bias2: 0.9547103047370911, variance: 0.05316917598247528\n",
      "##################################################\n",
      "Train size: [400] hidden size: [38] trial: 0, train_loss: 1.856905, test loss: 0.999603, bias2: 0.9996033906936646, variance: 2.919411101753866e-10\n",
      "Train size: [400] hidden size: [38] trial: 1, train_loss: 1.784513, test loss: 1.018689, bias2: 0.9804980754852295, variance: 0.03819097951054573\n",
      "Train size: [400] hidden size: [38] trial: 2, train_loss: 1.780437, test loss: 1.029461, bias2: 0.9813223481178284, variance: 0.0481390617787838\n",
      "Train size: [400] hidden size: [38] trial: 3, train_loss: 1.831472, test loss: 1.022527, bias2: 0.963641881942749, variance: 0.05888543650507927\n",
      "Train size: [400] hidden size: [38] trial: 4, train_loss: 1.851271, test loss: 1.022727, bias2: 0.9612606763839722, variance: 0.061466000974178314\n",
      "Train size: [400] hidden size: [38] trial: 5, train_loss: 1.877924, test loss: 1.016160, bias2: 0.9534604549407959, variance: 0.0626993179321289\n",
      "Train size: [400] hidden size: [38] trial: 6, train_loss: 1.858072, test loss: 1.019928, bias2: 0.9556407332420349, variance: 0.06428688019514084\n",
      "Train size: [400] hidden size: [38] trial: 7, train_loss: 1.838434, test loss: 1.018876, bias2: 0.9578595757484436, variance: 0.06101623550057411\n",
      "Train size: [400] hidden size: [38] trial: 8, train_loss: 1.845199, test loss: 1.016855, bias2: 0.9513696432113647, variance: 0.06548548489809036\n",
      "Train size: [400] hidden size: [38] trial: 9, train_loss: 1.846658, test loss: 1.015165, bias2: 0.9487184286117554, variance: 0.06644703447818756\n",
      "Train size: [400] hidden size: [38] trial: 10, train_loss: 1.838567, test loss: 1.014436, bias2: 0.9494264721870422, variance: 0.06500966101884842\n",
      "Train size: [400] hidden size: [38] trial: 11, train_loss: 1.823564, test loss: 1.010762, bias2: 0.9448100924491882, variance: 0.06595154851675034\n",
      "Train size: [400] hidden size: [38] trial: 12, train_loss: 1.840045, test loss: 1.010772, bias2: 0.9428711533546448, variance: 0.06790108233690262\n",
      "Train size: [400] hidden size: [38] trial: 13, train_loss: 1.848570, test loss: 1.010585, bias2: 0.9420633316040039, variance: 0.0685218796133995\n",
      "Train size: [400] hidden size: [38] trial: 14, train_loss: 1.842376, test loss: 1.008480, bias2: 0.9404677748680115, variance: 0.06801207363605499\n",
      "Train size: [400] hidden size: [38] trial: 15, train_loss: 1.839942, test loss: 1.008317, bias2: 0.9403776526451111, variance: 0.06793934851884842\n",
      "Train size: [400] hidden size: [38] trial: 16, train_loss: 1.845437, test loss: 1.008057, bias2: 0.941952645778656, variance: 0.06610459834337234\n",
      "Train size: [400] hidden size: [38] trial: 17, train_loss: 1.835237, test loss: 1.009352, bias2: 0.9435848593711853, variance: 0.06576748192310333\n",
      "Train size: [400] hidden size: [38] trial: 18, train_loss: 1.831867, test loss: 1.008776, bias2: 0.9439734816551208, variance: 0.06480198353528976\n",
      "Train size: [400] hidden size: [38] trial: 19, train_loss: 1.842795, test loss: 1.007370, bias2: 0.942851722240448, variance: 0.06451839208602905\n",
      "Train size: [400] hidden size: [38] trial: 20, train_loss: 1.842089, test loss: 1.007041, bias2: 0.9423629641532898, variance: 0.06467799842357635\n",
      "Train size: [400] hidden size: [38] trial: 21, train_loss: 1.836937, test loss: 1.005961, bias2: 0.9406059980392456, variance: 0.0653546005487442\n",
      "Train size: [400] hidden size: [38] trial: 22, train_loss: 1.832304, test loss: 1.004312, bias2: 0.9384432435035706, variance: 0.0658683106303215\n",
      "Train size: [400] hidden size: [38] trial: 23, train_loss: 1.840492, test loss: 1.003954, bias2: 0.9386702179908752, variance: 0.06528335809707642\n",
      "Train size: [400] hidden size: [38] trial: 24, train_loss: 1.835942, test loss: 1.003565, bias2: 0.9374099373817444, variance: 0.06615535169839859\n",
      "Train size: [400] hidden size: [38] trial: 25, train_loss: 1.834213, test loss: 1.003695, bias2: 0.935897171497345, variance: 0.0677977129817009\n",
      "Train size: [400] hidden size: [38] trial: 26, train_loss: 1.838606, test loss: 1.003891, bias2: 0.9366981983184814, variance: 0.0671929195523262\n",
      "Train size: [400] hidden size: [38] trial: 27, train_loss: 1.834382, test loss: 1.005076, bias2: 0.9377197623252869, variance: 0.067356176674366\n",
      "Train size: [400] hidden size: [38] trial: 28, train_loss: 1.836032, test loss: 1.004721, bias2: 0.9378814697265625, variance: 0.06683918833732605\n",
      "Train size: [400] hidden size: [38] trial: 29, train_loss: 1.833009, test loss: 1.005247, bias2: 0.9392336010932922, variance: 0.06601304560899734\n",
      "Train size: [400] hidden size: [38] trial: 30, train_loss: 1.830341, test loss: 1.004785, bias2: 0.9388887882232666, variance: 0.06589590758085251\n",
      "Train size: [400] hidden size: [38] trial: 31, train_loss: 1.832258, test loss: 1.005649, bias2: 0.9395694732666016, variance: 0.06607913970947266\n",
      "Train size: [400] hidden size: [38] trial: 32, train_loss: 1.835527, test loss: 1.006956, bias2: 0.9408941268920898, variance: 0.06606210768222809\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [38] trial: 33, train_loss: 1.836823, test loss: 1.007122, bias2: 0.941176176071167, variance: 0.06594637036323547\n",
      "Train size: [400] hidden size: [38] trial: 34, train_loss: 1.829486, test loss: 1.007356, bias2: 0.942315936088562, variance: 0.06504037976264954\n",
      "Train size: [400] hidden size: [38] trial: 35, train_loss: 1.835192, test loss: 1.007307, bias2: 0.9422645568847656, variance: 0.06504286825656891\n",
      "Train size: [400] hidden size: [38] trial: 36, train_loss: 1.829972, test loss: 1.007174, bias2: 0.9424931406974792, variance: 0.06468101590871811\n",
      "Train size: [400] hidden size: [38] trial: 37, train_loss: 1.832443, test loss: 1.006813, bias2: 0.9418641924858093, variance: 0.06494911015033722\n",
      "Train size: [400] hidden size: [38] trial: 38, train_loss: 1.837194, test loss: 1.007437, bias2: 0.9419472217559814, variance: 0.06548966467380524\n",
      "Train size: [400] hidden size: [38] trial: 39, train_loss: 1.837539, test loss: 1.007529, bias2: 0.9421738982200623, variance: 0.06535474210977554\n",
      "Train size: [400] hidden size: [38] trial: 40, train_loss: 1.839915, test loss: 1.007301, bias2: 0.9422691464424133, variance: 0.06503216922283173\n",
      "Train size: [400] hidden size: [38] trial: 41, train_loss: 1.837531, test loss: 1.008303, bias2: 0.9428535103797913, variance: 0.06544988602399826\n",
      "Train size: [400] hidden size: [38] trial: 42, train_loss: 1.841244, test loss: 1.008971, bias2: 0.9440572261810303, variance: 0.06491401046514511\n",
      "Train size: [400] hidden size: [38] trial: 43, train_loss: 1.836315, test loss: 1.008342, bias2: 0.9436830878257751, variance: 0.06465870141983032\n",
      "Train size: [400] hidden size: [38] trial: 44, train_loss: 1.840045, test loss: 1.008477, bias2: 0.9438745975494385, variance: 0.06460260599851608\n",
      "Train size: [400] hidden size: [38] trial: 45, train_loss: 1.840076, test loss: 1.008552, bias2: 0.9441348910331726, variance: 0.06441668421030045\n",
      "Train size: [400] hidden size: [38] trial: 46, train_loss: 1.836799, test loss: 1.008752, bias2: 0.9439424872398376, variance: 0.06480949372053146\n",
      "Train size: [400] hidden size: [38] trial: 47, train_loss: 1.838753, test loss: 1.008250, bias2: 0.943535327911377, variance: 0.06471454352140427\n",
      "Train size: [400] hidden size: [38] trial: 48, train_loss: 1.832403, test loss: 1.008129, bias2: 0.9431596994400024, variance: 0.06496880948543549\n",
      "Train size: [400] hidden size: [38] trial: 49, train_loss: 1.833099, test loss: 1.008369, bias2: 0.9434667825698853, variance: 0.06490245461463928\n",
      "##################################################\n",
      "Train size: [400] hidden size: [44] trial: 0, train_loss: 1.749871, test loss: 1.030022, bias2: 1.0300216674804688, variance: 4.379116513852921e-10\n",
      "Train size: [400] hidden size: [44] trial: 1, train_loss: 1.717359, test loss: 1.032423, bias2: 0.9934061765670776, variance: 0.03901706263422966\n",
      "Train size: [400] hidden size: [44] trial: 2, train_loss: 1.743200, test loss: 1.021034, bias2: 0.9677098989486694, variance: 0.0533238910138607\n",
      "Train size: [400] hidden size: [44] trial: 3, train_loss: 1.737087, test loss: 1.018781, bias2: 0.9661093950271606, variance: 0.05267120897769928\n",
      "Train size: [400] hidden size: [44] trial: 4, train_loss: 1.747804, test loss: 1.013267, bias2: 0.9547424912452698, variance: 0.05852432921528816\n",
      "Train size: [400] hidden size: [44] trial: 5, train_loss: 1.775109, test loss: 1.005987, bias2: 0.9449142813682556, variance: 0.061072543263435364\n",
      "Train size: [400] hidden size: [44] trial: 6, train_loss: 1.753228, test loss: 1.008691, bias2: 0.947869062423706, variance: 0.06082199513912201\n",
      "Train size: [400] hidden size: [44] trial: 7, train_loss: 1.764981, test loss: 1.008718, bias2: 0.9425867795944214, variance: 0.06613174080848694\n",
      "Train size: [400] hidden size: [44] trial: 8, train_loss: 1.753692, test loss: 1.008691, bias2: 0.943912923336029, variance: 0.06477754563093185\n",
      "Train size: [400] hidden size: [44] trial: 9, train_loss: 1.743785, test loss: 1.007296, bias2: 0.9431605339050293, variance: 0.06413521617650986\n",
      "Train size: [400] hidden size: [44] trial: 10, train_loss: 1.752902, test loss: 1.009027, bias2: 0.9432004690170288, variance: 0.06582699716091156\n",
      "Train size: [400] hidden size: [44] trial: 11, train_loss: 1.755248, test loss: 1.011924, bias2: 0.9446059465408325, variance: 0.06731843948364258\n",
      "Train size: [400] hidden size: [44] trial: 12, train_loss: 1.762263, test loss: 1.010002, bias2: 0.9413403272628784, variance: 0.06866194307804108\n",
      "Train size: [400] hidden size: [44] trial: 13, train_loss: 1.770151, test loss: 1.012533, bias2: 0.9441940188407898, variance: 0.068339042365551\n",
      "Train size: [400] hidden size: [44] trial: 14, train_loss: 1.776775, test loss: 1.010798, bias2: 0.9415978789329529, variance: 0.06919984519481659\n",
      "Train size: [400] hidden size: [44] trial: 15, train_loss: 1.791566, test loss: 1.014111, bias2: 0.9451666474342346, variance: 0.06894451379776001\n",
      "Train size: [400] hidden size: [44] trial: 16, train_loss: 1.792322, test loss: 1.013641, bias2: 0.9463592171669006, variance: 0.0672813281416893\n",
      "Train size: [400] hidden size: [44] trial: 17, train_loss: 1.804786, test loss: 1.013640, bias2: 0.9456135034561157, variance: 0.06802690029144287\n",
      "Train size: [400] hidden size: [44] trial: 18, train_loss: 1.798193, test loss: 1.012829, bias2: 0.9459944367408752, variance: 0.06683412939310074\n",
      "Train size: [400] hidden size: [44] trial: 19, train_loss: 1.785584, test loss: 1.013373, bias2: 0.9468701481819153, variance: 0.06650274991989136\n",
      "Train size: [400] hidden size: [44] trial: 20, train_loss: 1.788922, test loss: 1.013699, bias2: 0.94720858335495, variance: 0.06649072468280792\n",
      "Train size: [400] hidden size: [44] trial: 21, train_loss: 1.795665, test loss: 1.013908, bias2: 0.9474755525588989, variance: 0.06643233448266983\n",
      "Train size: [400] hidden size: [44] trial: 22, train_loss: 1.795813, test loss: 1.013313, bias2: 0.946191668510437, variance: 0.06712135672569275\n",
      "Train size: [400] hidden size: [44] trial: 23, train_loss: 1.790356, test loss: 1.014689, bias2: 0.9465809464454651, variance: 0.06810768693685532\n",
      "Train size: [400] hidden size: [44] trial: 24, train_loss: 1.789931, test loss: 1.014875, bias2: 0.9451687335968018, variance: 0.06970617920160294\n",
      "Train size: [400] hidden size: [44] trial: 25, train_loss: 1.800678, test loss: 1.015180, bias2: 0.9444112777709961, variance: 0.07076861709356308\n",
      "Train size: [400] hidden size: [44] trial: 26, train_loss: 1.800175, test loss: 1.015509, bias2: 0.9439896941184998, variance: 0.07151883095502853\n",
      "Train size: [400] hidden size: [44] trial: 27, train_loss: 1.801703, test loss: 1.014819, bias2: 0.9432567954063416, variance: 0.07156259566545486\n",
      "Train size: [400] hidden size: [44] trial: 28, train_loss: 1.803416, test loss: 1.015150, bias2: 0.9431516528129578, variance: 0.07199852913618088\n",
      "Train size: [400] hidden size: [44] trial: 29, train_loss: 1.802520, test loss: 1.015128, bias2: 0.9435061812400818, variance: 0.07162181288003922\n",
      "Train size: [400] hidden size: [44] trial: 30, train_loss: 1.802981, test loss: 1.015870, bias2: 0.9444615840911865, variance: 0.07140814512968063\n",
      "Train size: [400] hidden size: [44] trial: 31, train_loss: 1.802584, test loss: 1.016410, bias2: 0.9449433088302612, variance: 0.07146701961755753\n",
      "Train size: [400] hidden size: [44] trial: 32, train_loss: 1.801127, test loss: 1.015887, bias2: 0.9446308016777039, variance: 0.07125632464885712\n",
      "Train size: [400] hidden size: [44] trial: 33, train_loss: 1.809658, test loss: 1.015677, bias2: 0.9442182183265686, variance: 0.07145849615335464\n",
      "Train size: [400] hidden size: [44] trial: 34, train_loss: 1.811405, test loss: 1.015841, bias2: 0.9435902833938599, variance: 0.07225062698125839\n",
      "Train size: [400] hidden size: [44] trial: 35, train_loss: 1.811600, test loss: 1.015973, bias2: 0.9441119432449341, variance: 0.07186105847358704\n",
      "Train size: [400] hidden size: [44] trial: 36, train_loss: 1.813087, test loss: 1.016526, bias2: 0.9446348547935486, variance: 0.07189087569713593\n",
      "Train size: [400] hidden size: [44] trial: 37, train_loss: 1.821287, test loss: 1.017197, bias2: 0.9447698593139648, variance: 0.07242678850889206\n",
      "Train size: [400] hidden size: [44] trial: 38, train_loss: 1.813814, test loss: 1.017199, bias2: 0.94559246301651, variance: 0.07160619646310806\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [44] trial: 39, train_loss: 1.814492, test loss: 1.017226, bias2: 0.9441931247711182, variance: 0.07303334772586823\n",
      "Train size: [400] hidden size: [44] trial: 40, train_loss: 1.813718, test loss: 1.018243, bias2: 0.9449365139007568, variance: 0.07330606132745743\n",
      "Train size: [400] hidden size: [44] trial: 41, train_loss: 1.810339, test loss: 1.017494, bias2: 0.9442223906517029, variance: 0.07327144593000412\n",
      "Train size: [400] hidden size: [44] trial: 42, train_loss: 1.807527, test loss: 1.016935, bias2: 0.9435899257659912, variance: 0.07334461808204651\n",
      "Train size: [400] hidden size: [44] trial: 43, train_loss: 1.806724, test loss: 1.017658, bias2: 0.9445546865463257, variance: 0.07310378551483154\n",
      "Train size: [400] hidden size: [44] trial: 44, train_loss: 1.803877, test loss: 1.017055, bias2: 0.9443190097808838, variance: 0.07273567467927933\n",
      "Train size: [400] hidden size: [44] trial: 45, train_loss: 1.803531, test loss: 1.016379, bias2: 0.9434471726417542, variance: 0.07293171435594559\n",
      "Train size: [400] hidden size: [44] trial: 46, train_loss: 1.801114, test loss: 1.016163, bias2: 0.9430606961250305, variance: 0.07310251146554947\n",
      "Train size: [400] hidden size: [44] trial: 47, train_loss: 1.802464, test loss: 1.016351, bias2: 0.943234920501709, variance: 0.07311604917049408\n",
      "Train size: [400] hidden size: [44] trial: 48, train_loss: 1.801866, test loss: 1.016225, bias2: 0.9427478313446045, variance: 0.07347670197486877\n",
      "Train size: [400] hidden size: [44] trial: 49, train_loss: 1.802840, test loss: 1.015947, bias2: 0.9428139925003052, variance: 0.07313331961631775\n",
      "##################################################\n",
      "Train size: [400] hidden size: [51] trial: 0, train_loss: 1.725370, test loss: 1.017167, bias2: 1.0171672105789185, variance: 5.352253640289462e-10\n",
      "Train size: [400] hidden size: [51] trial: 1, train_loss: 1.741960, test loss: 0.998039, bias2: 0.9538483619689941, variance: 0.04419071599841118\n",
      "Train size: [400] hidden size: [51] trial: 2, train_loss: 1.766710, test loss: 0.987908, bias2: 0.9307193160057068, variance: 0.05718819797039032\n",
      "Train size: [400] hidden size: [51] trial: 3, train_loss: 1.763934, test loss: 0.992584, bias2: 0.9275701642036438, variance: 0.0650133565068245\n",
      "Train size: [400] hidden size: [51] trial: 4, train_loss: 1.799677, test loss: 0.989603, bias2: 0.9202607870101929, variance: 0.06934235244989395\n",
      "Train size: [400] hidden size: [51] trial: 5, train_loss: 1.773952, test loss: 0.985145, bias2: 0.9158003330230713, variance: 0.06934505701065063\n",
      "Train size: [400] hidden size: [51] trial: 6, train_loss: 1.766128, test loss: 0.994431, bias2: 0.9252049922943115, variance: 0.06922616064548492\n",
      "Train size: [400] hidden size: [51] trial: 7, train_loss: 1.761972, test loss: 1.000838, bias2: 0.9280450344085693, variance: 0.07279334962368011\n",
      "Train size: [400] hidden size: [51] trial: 8, train_loss: 1.772876, test loss: 0.999351, bias2: 0.9238301515579224, variance: 0.0755210667848587\n",
      "Train size: [400] hidden size: [51] trial: 9, train_loss: 1.759388, test loss: 1.000127, bias2: 0.9253870248794556, variance: 0.0747404396533966\n",
      "Train size: [400] hidden size: [51] trial: 10, train_loss: 1.767966, test loss: 0.998199, bias2: 0.9216437339782715, variance: 0.07655534148216248\n",
      "Train size: [400] hidden size: [51] trial: 11, train_loss: 1.779587, test loss: 1.000561, bias2: 0.9234873056411743, variance: 0.0770733579993248\n",
      "Train size: [400] hidden size: [51] trial: 12, train_loss: 1.779368, test loss: 1.001277, bias2: 0.9245480298995972, variance: 0.0767287015914917\n",
      "Train size: [400] hidden size: [51] trial: 13, train_loss: 1.769807, test loss: 1.004324, bias2: 0.9264874458312988, variance: 0.07783673703670502\n",
      "Train size: [400] hidden size: [51] trial: 14, train_loss: 1.775015, test loss: 1.004209, bias2: 0.9263777136802673, variance: 0.07783178240060806\n",
      "Train size: [400] hidden size: [51] trial: 15, train_loss: 1.767769, test loss: 1.004106, bias2: 0.9241343140602112, variance: 0.07997173070907593\n",
      "Train size: [400] hidden size: [51] trial: 16, train_loss: 1.772921, test loss: 1.003428, bias2: 0.9216314554214478, variance: 0.08179605007171631\n",
      "Train size: [400] hidden size: [51] trial: 17, train_loss: 1.781755, test loss: 1.006839, bias2: 0.9243411421775818, variance: 0.08249767124652863\n",
      "Train size: [400] hidden size: [51] trial: 18, train_loss: 1.785779, test loss: 1.006533, bias2: 0.924492597579956, variance: 0.08204076439142227\n",
      "Train size: [400] hidden size: [51] trial: 19, train_loss: 1.786780, test loss: 1.006369, bias2: 0.9221413731575012, variance: 0.08422715216875076\n",
      "Train size: [400] hidden size: [51] trial: 20, train_loss: 1.777193, test loss: 1.006805, bias2: 0.923222541809082, variance: 0.08358278125524521\n",
      "Train size: [400] hidden size: [51] trial: 21, train_loss: 1.774840, test loss: 1.006426, bias2: 0.9220982193946838, variance: 0.08432810753583908\n",
      "Train size: [400] hidden size: [51] trial: 22, train_loss: 1.780435, test loss: 1.006873, bias2: 0.9222951531410217, variance: 0.08457810431718826\n",
      "Train size: [400] hidden size: [51] trial: 23, train_loss: 1.779068, test loss: 1.005695, bias2: 0.9197010397911072, variance: 0.08599357306957245\n",
      "Train size: [400] hidden size: [51] trial: 24, train_loss: 1.785274, test loss: 1.004139, bias2: 0.9184545874595642, variance: 0.08568447083234787\n",
      "Train size: [400] hidden size: [51] trial: 25, train_loss: 1.782192, test loss: 1.004421, bias2: 0.9188396334648132, variance: 0.08558160066604614\n",
      "Train size: [400] hidden size: [51] trial: 26, train_loss: 1.785256, test loss: 1.004786, bias2: 0.9195348024368286, variance: 0.0852515920996666\n",
      "Train size: [400] hidden size: [51] trial: 27, train_loss: 1.785089, test loss: 1.005525, bias2: 0.9198117256164551, variance: 0.08571317046880722\n",
      "Train size: [400] hidden size: [51] trial: 28, train_loss: 1.786219, test loss: 1.005765, bias2: 0.919752836227417, variance: 0.08601177483797073\n",
      "Train size: [400] hidden size: [51] trial: 29, train_loss: 1.783624, test loss: 1.006704, bias2: 0.9200588464736938, variance: 0.08664550632238388\n",
      "Train size: [400] hidden size: [51] trial: 30, train_loss: 1.785872, test loss: 1.006343, bias2: 0.9188874363899231, variance: 0.08745511621236801\n",
      "Train size: [400] hidden size: [51] trial: 31, train_loss: 1.785947, test loss: 1.005767, bias2: 0.9182690382003784, variance: 0.08749820291996002\n",
      "Train size: [400] hidden size: [51] trial: 32, train_loss: 1.777303, test loss: 1.005536, bias2: 0.919051468372345, variance: 0.08648437261581421\n",
      "Train size: [400] hidden size: [51] trial: 33, train_loss: 1.776796, test loss: 1.006059, bias2: 0.9199074506759644, variance: 0.08615123480558395\n",
      "Train size: [400] hidden size: [51] trial: 34, train_loss: 1.775864, test loss: 1.005628, bias2: 0.9201582074165344, variance: 0.08547025918960571\n",
      "Train size: [400] hidden size: [51] trial: 35, train_loss: 1.772719, test loss: 1.005759, bias2: 0.9202099442481995, variance: 0.08554906398057938\n",
      "Train size: [400] hidden size: [51] trial: 36, train_loss: 1.769717, test loss: 1.005234, bias2: 0.9189680218696594, variance: 0.08626587688922882\n",
      "Train size: [400] hidden size: [51] trial: 37, train_loss: 1.768071, test loss: 1.005238, bias2: 0.9193132519721985, variance: 0.08592456579208374\n",
      "Train size: [400] hidden size: [51] trial: 38, train_loss: 1.766402, test loss: 1.005794, bias2: 0.920295238494873, variance: 0.08549906313419342\n",
      "Train size: [400] hidden size: [51] trial: 39, train_loss: 1.770356, test loss: 1.005859, bias2: 0.9209927916526794, variance: 0.08486644178628922\n",
      "Train size: [400] hidden size: [51] trial: 40, train_loss: 1.767230, test loss: 1.006383, bias2: 0.921400785446167, variance: 0.0849824845790863\n",
      "Train size: [400] hidden size: [51] trial: 41, train_loss: 1.768951, test loss: 1.006232, bias2: 0.9213863611221313, variance: 0.08484590798616409\n",
      "Train size: [400] hidden size: [51] trial: 42, train_loss: 1.765936, test loss: 1.005688, bias2: 0.9211005568504333, variance: 0.08458741754293442\n",
      "Train size: [400] hidden size: [51] trial: 43, train_loss: 1.759870, test loss: 1.005268, bias2: 0.9195324778556824, variance: 0.08573539555072784\n",
      "Train size: [400] hidden size: [51] trial: 44, train_loss: 1.759629, test loss: 1.005357, bias2: 0.9195507764816284, variance: 0.08580662310123444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [51] trial: 45, train_loss: 1.757660, test loss: 1.006175, bias2: 0.9201167225837708, variance: 0.08605817705392838\n",
      "Train size: [400] hidden size: [51] trial: 46, train_loss: 1.758909, test loss: 1.006217, bias2: 0.9203584790229797, variance: 0.08585898578166962\n",
      "Train size: [400] hidden size: [51] trial: 47, train_loss: 1.755148, test loss: 1.006675, bias2: 0.9208213686943054, variance: 0.08585376292467117\n",
      "Train size: [400] hidden size: [51] trial: 48, train_loss: 1.753689, test loss: 1.007687, bias2: 0.9216073751449585, variance: 0.08607926219701767\n",
      "Train size: [400] hidden size: [51] trial: 49, train_loss: 1.754076, test loss: 1.007696, bias2: 0.9217378497123718, variance: 0.08595866709947586\n",
      "##################################################\n",
      "Train size: [400] hidden size: [58] trial: 0, train_loss: 1.687081, test loss: 1.013843, bias2: 1.0138429403305054, variance: 2.4328425385355956e-10\n",
      "Train size: [400] hidden size: [58] trial: 1, train_loss: 1.674834, test loss: 0.995568, bias2: 0.9495223760604858, variance: 0.046045247465372086\n",
      "Train size: [400] hidden size: [58] trial: 2, train_loss: 1.748387, test loss: 1.007573, bias2: 0.9378000497817993, variance: 0.06977307051420212\n",
      "Train size: [400] hidden size: [58] trial: 3, train_loss: 1.756710, test loss: 1.009414, bias2: 0.9333713054656982, variance: 0.07604239881038666\n",
      "Train size: [400] hidden size: [58] trial: 4, train_loss: 1.758761, test loss: 1.006734, bias2: 0.9317067265510559, variance: 0.07502681016921997\n",
      "Train size: [400] hidden size: [58] trial: 5, train_loss: 1.745996, test loss: 1.005137, bias2: 0.9290488362312317, variance: 0.07608838379383087\n",
      "Train size: [400] hidden size: [58] trial: 6, train_loss: 1.723566, test loss: 1.004973, bias2: 0.9241275191307068, variance: 0.08084563910961151\n",
      "Train size: [400] hidden size: [58] trial: 7, train_loss: 1.723431, test loss: 1.006915, bias2: 0.9248142838478088, variance: 0.08210094273090363\n",
      "Train size: [400] hidden size: [58] trial: 8, train_loss: 1.723164, test loss: 1.010066, bias2: 0.9244022369384766, variance: 0.08566358685493469\n",
      "Train size: [400] hidden size: [58] trial: 9, train_loss: 1.704359, test loss: 1.012825, bias2: 0.9240525960922241, variance: 0.08877264708280563\n",
      "Train size: [400] hidden size: [58] trial: 10, train_loss: 1.691918, test loss: 1.011467, bias2: 0.9226226806640625, variance: 0.08884391188621521\n",
      "Train size: [400] hidden size: [58] trial: 11, train_loss: 1.696771, test loss: 1.010671, bias2: 0.9196653366088867, variance: 0.09100618958473206\n",
      "Train size: [400] hidden size: [58] trial: 12, train_loss: 1.687221, test loss: 1.009427, bias2: 0.9196794629096985, variance: 0.08974794298410416\n",
      "Train size: [400] hidden size: [58] trial: 13, train_loss: 1.697142, test loss: 1.009465, bias2: 0.9188705086708069, variance: 0.09059473127126694\n",
      "Train size: [400] hidden size: [58] trial: 14, train_loss: 1.698982, test loss: 1.009942, bias2: 0.9175093173980713, variance: 0.09243223071098328\n",
      "Train size: [400] hidden size: [58] trial: 15, train_loss: 1.707877, test loss: 1.011685, bias2: 0.9186992049217224, variance: 0.09298615157604218\n",
      "Train size: [400] hidden size: [58] trial: 16, train_loss: 1.708963, test loss: 1.010679, bias2: 0.9160611033439636, variance: 0.09461768716573715\n",
      "Train size: [400] hidden size: [58] trial: 17, train_loss: 1.716657, test loss: 1.010157, bias2: 0.9162067174911499, variance: 0.09395003318786621\n",
      "Train size: [400] hidden size: [58] trial: 18, train_loss: 1.714579, test loss: 1.008265, bias2: 0.9147505164146423, variance: 0.09351400285959244\n",
      "Train size: [400] hidden size: [58] trial: 19, train_loss: 1.708172, test loss: 1.010297, bias2: 0.9138632416725159, variance: 0.09643383324146271\n",
      "Train size: [400] hidden size: [58] trial: 20, train_loss: 1.702328, test loss: 1.009209, bias2: 0.9127494096755981, variance: 0.09645986557006836\n",
      "Train size: [400] hidden size: [58] trial: 21, train_loss: 1.702128, test loss: 1.008541, bias2: 0.9123363494873047, variance: 0.0962042585015297\n",
      "Train size: [400] hidden size: [58] trial: 22, train_loss: 1.704357, test loss: 1.007137, bias2: 0.908970057964325, variance: 0.09816654771566391\n",
      "Train size: [400] hidden size: [58] trial: 23, train_loss: 1.716603, test loss: 1.007053, bias2: 0.9072163701057434, variance: 0.09983674436807632\n",
      "Train size: [400] hidden size: [58] trial: 24, train_loss: 1.713500, test loss: 1.009509, bias2: 0.909565806388855, variance: 0.09994348883628845\n",
      "Train size: [400] hidden size: [58] trial: 25, train_loss: 1.714855, test loss: 1.009786, bias2: 0.9092499613761902, variance: 0.1005355641245842\n",
      "Train size: [400] hidden size: [58] trial: 26, train_loss: 1.723198, test loss: 1.009235, bias2: 0.9088256359100342, variance: 0.10040923953056335\n",
      "Train size: [400] hidden size: [58] trial: 27, train_loss: 1.719000, test loss: 1.009690, bias2: 0.9082082509994507, variance: 0.10148132592439651\n",
      "Train size: [400] hidden size: [58] trial: 28, train_loss: 1.723366, test loss: 1.009568, bias2: 0.9079172611236572, variance: 0.10165119171142578\n",
      "Train size: [400] hidden size: [58] trial: 29, train_loss: 1.726446, test loss: 1.010197, bias2: 0.908464252948761, variance: 0.10173232108354568\n",
      "Train size: [400] hidden size: [58] trial: 30, train_loss: 1.725118, test loss: 1.009664, bias2: 0.908802330493927, variance: 0.10086186230182648\n",
      "Train size: [400] hidden size: [58] trial: 31, train_loss: 1.730203, test loss: 1.010304, bias2: 0.9094728827476501, variance: 0.10083155333995819\n",
      "Train size: [400] hidden size: [58] trial: 32, train_loss: 1.726214, test loss: 1.011278, bias2: 0.911137044429779, variance: 0.10014060884714127\n",
      "Train size: [400] hidden size: [58] trial: 33, train_loss: 1.724129, test loss: 1.011816, bias2: 0.9118510484695435, variance: 0.09996511042118073\n",
      "Train size: [400] hidden size: [58] trial: 34, train_loss: 1.721149, test loss: 1.011170, bias2: 0.9114930033683777, variance: 0.09967677295207977\n",
      "Train size: [400] hidden size: [58] trial: 35, train_loss: 1.712436, test loss: 1.012005, bias2: 0.9124022126197815, variance: 0.09960301220417023\n",
      "Train size: [400] hidden size: [58] trial: 36, train_loss: 1.713674, test loss: 1.010830, bias2: 0.9111171364784241, variance: 0.0997127890586853\n",
      "Train size: [400] hidden size: [58] trial: 37, train_loss: 1.715054, test loss: 1.011520, bias2: 0.9115483164787292, variance: 0.09997181594371796\n",
      "Train size: [400] hidden size: [58] trial: 38, train_loss: 1.714380, test loss: 1.011052, bias2: 0.9112590551376343, variance: 0.09979322552680969\n",
      "Train size: [400] hidden size: [58] trial: 39, train_loss: 1.713472, test loss: 1.010617, bias2: 0.9099052548408508, variance: 0.10071128606796265\n",
      "Train size: [400] hidden size: [58] trial: 40, train_loss: 1.716063, test loss: 1.010556, bias2: 0.9097272157669067, variance: 0.10082890838384628\n",
      "Train size: [400] hidden size: [58] trial: 41, train_loss: 1.715084, test loss: 1.009489, bias2: 0.9088178873062134, variance: 0.1006712019443512\n",
      "Train size: [400] hidden size: [58] trial: 42, train_loss: 1.712338, test loss: 1.010126, bias2: 0.9085797071456909, variance: 0.1015462726354599\n",
      "Train size: [400] hidden size: [58] trial: 43, train_loss: 1.711539, test loss: 1.009894, bias2: 0.9081006050109863, variance: 0.10179343074560165\n",
      "Train size: [400] hidden size: [58] trial: 44, train_loss: 1.711311, test loss: 1.009781, bias2: 0.9080259203910828, variance: 0.10175470262765884\n",
      "Train size: [400] hidden size: [58] trial: 45, train_loss: 1.716976, test loss: 1.010148, bias2: 0.9082678556442261, variance: 0.10188030451536179\n",
      "Train size: [400] hidden size: [58] trial: 46, train_loss: 1.715462, test loss: 1.009626, bias2: 0.9082416892051697, variance: 0.10138420760631561\n",
      "Train size: [400] hidden size: [58] trial: 47, train_loss: 1.715872, test loss: 1.009780, bias2: 0.9084985852241516, variance: 0.10128147900104523\n",
      "Train size: [400] hidden size: [58] trial: 48, train_loss: 1.715436, test loss: 1.008628, bias2: 0.9071441292762756, variance: 0.10148397833108902\n",
      "Train size: [400] hidden size: [58] trial: 49, train_loss: 1.716774, test loss: 1.008711, bias2: 0.9075043797492981, variance: 0.10120683908462524\n",
      "##################################################\n",
      "Train size: [400] hidden size: [67] trial: 0, train_loss: 1.611274, test loss: 1.003735, bias2: 1.0037347078323364, variance: 9.731369876586626e-11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [67] trial: 1, train_loss: 1.786302, test loss: 1.012200, bias2: 0.9675018787384033, variance: 0.04469825327396393\n",
      "Train size: [400] hidden size: [67] trial: 2, train_loss: 1.797933, test loss: 1.013410, bias2: 0.9452685117721558, variance: 0.06814169883728027\n",
      "Train size: [400] hidden size: [67] trial: 3, train_loss: 1.764416, test loss: 1.004275, bias2: 0.9254733324050903, variance: 0.07880163937807083\n",
      "Train size: [400] hidden size: [67] trial: 4, train_loss: 1.764055, test loss: 1.009330, bias2: 0.9301477074623108, variance: 0.0791819617152214\n",
      "Train size: [400] hidden size: [67] trial: 5, train_loss: 1.755877, test loss: 1.006902, bias2: 0.9217566251754761, variance: 0.08514510840177536\n",
      "Train size: [400] hidden size: [67] trial: 6, train_loss: 1.743308, test loss: 1.011571, bias2: 0.918721079826355, variance: 0.09285019338130951\n",
      "Train size: [400] hidden size: [67] trial: 7, train_loss: 1.750673, test loss: 1.019536, bias2: 0.9204191565513611, variance: 0.09911683946847916\n",
      "Train size: [400] hidden size: [67] trial: 8, train_loss: 1.726935, test loss: 1.022978, bias2: 0.9233124256134033, variance: 0.09966529160737991\n",
      "Train size: [400] hidden size: [67] trial: 9, train_loss: 1.714426, test loss: 1.020211, bias2: 0.9176769852638245, variance: 0.10253363847732544\n",
      "Train size: [400] hidden size: [67] trial: 10, train_loss: 1.707364, test loss: 1.020155, bias2: 0.9195746183395386, variance: 0.10058067739009857\n",
      "Train size: [400] hidden size: [67] trial: 11, train_loss: 1.730132, test loss: 1.020927, bias2: 0.9182314276695251, variance: 0.10269588977098465\n",
      "Train size: [400] hidden size: [67] trial: 12, train_loss: 1.727888, test loss: 1.019567, bias2: 0.9155828952789307, variance: 0.10398435592651367\n",
      "Train size: [400] hidden size: [67] trial: 13, train_loss: 1.712920, test loss: 1.017122, bias2: 0.9110059142112732, variance: 0.10611658543348312\n",
      "Train size: [400] hidden size: [67] trial: 14, train_loss: 1.704769, test loss: 1.016384, bias2: 0.9115539193153381, variance: 0.1048305556178093\n",
      "Train size: [400] hidden size: [67] trial: 15, train_loss: 1.688614, test loss: 1.018456, bias2: 0.9113397002220154, variance: 0.10711603611707687\n",
      "Train size: [400] hidden size: [67] trial: 16, train_loss: 1.686934, test loss: 1.020574, bias2: 0.9113712906837463, variance: 0.1092025488615036\n",
      "Train size: [400] hidden size: [67] trial: 17, train_loss: 1.696666, test loss: 1.021766, bias2: 0.9117414951324463, variance: 0.1100241020321846\n",
      "Train size: [400] hidden size: [67] trial: 18, train_loss: 1.697445, test loss: 1.020799, bias2: 0.9108753204345703, variance: 0.10992398113012314\n",
      "Train size: [400] hidden size: [67] trial: 19, train_loss: 1.692129, test loss: 1.020231, bias2: 0.9093988537788391, variance: 0.11083225905895233\n",
      "Train size: [400] hidden size: [67] trial: 20, train_loss: 1.683023, test loss: 1.018972, bias2: 0.9075484275817871, variance: 0.11142328381538391\n",
      "Train size: [400] hidden size: [67] trial: 21, train_loss: 1.687527, test loss: 1.017567, bias2: 0.9061934351921082, variance: 0.11137323826551437\n",
      "Train size: [400] hidden size: [67] trial: 22, train_loss: 1.699431, test loss: 1.017437, bias2: 0.9051121473312378, variance: 0.11232493817806244\n",
      "Train size: [400] hidden size: [67] trial: 23, train_loss: 1.697951, test loss: 1.016899, bias2: 0.9063233733177185, variance: 0.11057528108358383\n",
      "Train size: [400] hidden size: [67] trial: 24, train_loss: 1.697519, test loss: 1.015398, bias2: 0.9056858420372009, variance: 0.10971207171678543\n",
      "Train size: [400] hidden size: [67] trial: 25, train_loss: 1.696727, test loss: 1.015552, bias2: 0.9063379168510437, variance: 0.10921364277601242\n",
      "Train size: [400] hidden size: [67] trial: 26, train_loss: 1.694974, test loss: 1.015760, bias2: 0.906241238117218, variance: 0.10951881110668182\n",
      "Train size: [400] hidden size: [67] trial: 27, train_loss: 1.698454, test loss: 1.014945, bias2: 0.9059141278266907, variance: 0.10903089493513107\n",
      "Train size: [400] hidden size: [67] trial: 28, train_loss: 1.697058, test loss: 1.015484, bias2: 0.9057367444038391, variance: 0.10974673926830292\n",
      "Train size: [400] hidden size: [67] trial: 29, train_loss: 1.702683, test loss: 1.015100, bias2: 0.9046646356582642, variance: 0.11043545603752136\n",
      "Train size: [400] hidden size: [67] trial: 30, train_loss: 1.701448, test loss: 1.016716, bias2: 0.9050846695899963, variance: 0.11163169145584106\n",
      "Train size: [400] hidden size: [67] trial: 31, train_loss: 1.699188, test loss: 1.018100, bias2: 0.9056228399276733, variance: 0.11247683316469193\n",
      "Train size: [400] hidden size: [67] trial: 32, train_loss: 1.699206, test loss: 1.016859, bias2: 0.9044480919837952, variance: 0.11241070926189423\n",
      "Train size: [400] hidden size: [67] trial: 33, train_loss: 1.700482, test loss: 1.017373, bias2: 0.905103862285614, variance: 0.11226899176836014\n",
      "Train size: [400] hidden size: [67] trial: 34, train_loss: 1.703697, test loss: 1.016845, bias2: 0.9053835868835449, variance: 0.11146101355552673\n",
      "Train size: [400] hidden size: [67] trial: 35, train_loss: 1.702253, test loss: 1.017908, bias2: 0.9068912267684937, variance: 0.1110164001584053\n",
      "Train size: [400] hidden size: [67] trial: 36, train_loss: 1.701655, test loss: 1.017390, bias2: 0.9059370756149292, variance: 0.11145295947790146\n",
      "Train size: [400] hidden size: [67] trial: 37, train_loss: 1.699672, test loss: 1.017859, bias2: 0.9052702784538269, variance: 0.11258883774280548\n",
      "Train size: [400] hidden size: [67] trial: 38, train_loss: 1.693290, test loss: 1.017752, bias2: 0.9057385325431824, variance: 0.11201364547014236\n",
      "Train size: [400] hidden size: [67] trial: 39, train_loss: 1.697220, test loss: 1.017221, bias2: 0.9058748483657837, variance: 0.11134610325098038\n",
      "Train size: [400] hidden size: [67] trial: 40, train_loss: 1.695155, test loss: 1.016800, bias2: 0.9052537679672241, variance: 0.11154675483703613\n",
      "Train size: [400] hidden size: [67] trial: 41, train_loss: 1.694970, test loss: 1.017055, bias2: 0.9055427312850952, variance: 0.11151251196861267\n",
      "Train size: [400] hidden size: [67] trial: 42, train_loss: 1.699437, test loss: 1.017321, bias2: 0.9062532186508179, variance: 0.11106742173433304\n",
      "Train size: [400] hidden size: [67] trial: 43, train_loss: 1.699106, test loss: 1.017454, bias2: 0.9064084887504578, variance: 0.11104590445756912\n",
      "Train size: [400] hidden size: [67] trial: 44, train_loss: 1.700023, test loss: 1.017729, bias2: 0.9068987965583801, variance: 0.11083024740219116\n",
      "Train size: [400] hidden size: [67] trial: 45, train_loss: 1.700436, test loss: 1.017788, bias2: 0.9072699546813965, variance: 0.11051788181066513\n",
      "Train size: [400] hidden size: [67] trial: 46, train_loss: 1.700668, test loss: 1.017999, bias2: 0.907678484916687, variance: 0.11032067239284515\n",
      "Train size: [400] hidden size: [67] trial: 47, train_loss: 1.698265, test loss: 1.017678, bias2: 0.9076172113418579, variance: 0.11006056517362595\n",
      "Train size: [400] hidden size: [67] trial: 48, train_loss: 1.696026, test loss: 1.017418, bias2: 0.9075258374214172, variance: 0.10989253222942352\n",
      "Train size: [400] hidden size: [67] trial: 49, train_loss: 1.696229, test loss: 1.017433, bias2: 0.9067087769508362, variance: 0.11072460561990738\n",
      "##################################################\n",
      "Train size: [400] hidden size: [77] trial: 0, train_loss: 1.691479, test loss: 0.973813, bias2: 0.9738126397132874, variance: -1.5570191802538602e-09\n",
      "Train size: [400] hidden size: [77] trial: 1, train_loss: 1.768261, test loss: 0.975591, bias2: 0.9167727828025818, variance: 0.058817751705646515\n",
      "Train size: [400] hidden size: [77] trial: 2, train_loss: 1.761567, test loss: 0.983553, bias2: 0.906356155872345, variance: 0.07719685137271881\n",
      "Train size: [400] hidden size: [77] trial: 3, train_loss: 1.793214, test loss: 0.978936, bias2: 0.8832709193229675, variance: 0.09566498547792435\n",
      "Train size: [400] hidden size: [77] trial: 4, train_loss: 1.773493, test loss: 0.987334, bias2: 0.8775629997253418, variance: 0.10977091640233994\n",
      "Train size: [400] hidden size: [77] trial: 5, train_loss: 1.739342, test loss: 0.983982, bias2: 0.875659704208374, variance: 0.10832224041223526\n",
      "Train size: [400] hidden size: [77] trial: 6, train_loss: 1.726435, test loss: 0.991744, bias2: 0.8862786889076233, variance: 0.10546563565731049\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [77] trial: 7, train_loss: 1.708020, test loss: 0.995082, bias2: 0.8919898867607117, variance: 0.1030922383069992\n",
      "Train size: [400] hidden size: [77] trial: 8, train_loss: 1.703856, test loss: 0.998318, bias2: 0.8914551734924316, variance: 0.10686323046684265\n",
      "Train size: [400] hidden size: [77] trial: 9, train_loss: 1.708224, test loss: 1.004095, bias2: 0.8946092128753662, variance: 0.10948620736598969\n",
      "Train size: [400] hidden size: [77] trial: 10, train_loss: 1.706671, test loss: 1.005420, bias2: 0.8956747651100159, variance: 0.10974554717540741\n",
      "Train size: [400] hidden size: [77] trial: 11, train_loss: 1.707199, test loss: 1.008097, bias2: 0.8973286151885986, variance: 0.11076876521110535\n",
      "Train size: [400] hidden size: [77] trial: 12, train_loss: 1.711409, test loss: 1.008163, bias2: 0.8933707475662231, variance: 0.11479257792234421\n",
      "Train size: [400] hidden size: [77] trial: 13, train_loss: 1.707802, test loss: 1.008067, bias2: 0.8933548331260681, variance: 0.11471255868673325\n",
      "Train size: [400] hidden size: [77] trial: 14, train_loss: 1.702345, test loss: 1.007106, bias2: 0.8906013369560242, variance: 0.11650475114583969\n",
      "Train size: [400] hidden size: [77] trial: 15, train_loss: 1.711153, test loss: 1.007718, bias2: 0.8882842063903809, variance: 0.1194334328174591\n",
      "Train size: [400] hidden size: [77] trial: 16, train_loss: 1.707997, test loss: 1.007053, bias2: 0.8841750621795654, variance: 0.12287793308496475\n",
      "Train size: [400] hidden size: [77] trial: 17, train_loss: 1.708456, test loss: 1.007232, bias2: 0.8846258521080017, variance: 0.1226063147187233\n",
      "Train size: [400] hidden size: [77] trial: 18, train_loss: 1.704976, test loss: 1.009619, bias2: 0.8840108513832092, variance: 0.1256081461906433\n",
      "Train size: [400] hidden size: [77] trial: 19, train_loss: 1.704391, test loss: 1.009244, bias2: 0.882788896560669, variance: 0.12645505368709564\n",
      "Train size: [400] hidden size: [77] trial: 20, train_loss: 1.703870, test loss: 1.011006, bias2: 0.8843894600868225, variance: 0.12661665678024292\n",
      "Train size: [400] hidden size: [77] trial: 21, train_loss: 1.706444, test loss: 1.009443, bias2: 0.88277268409729, variance: 0.12666986882686615\n",
      "Train size: [400] hidden size: [77] trial: 22, train_loss: 1.700190, test loss: 1.009710, bias2: 0.8824434876441956, variance: 0.12726657092571259\n",
      "Train size: [400] hidden size: [77] trial: 23, train_loss: 1.697318, test loss: 1.011329, bias2: 0.8826809525489807, variance: 0.12864811718463898\n",
      "Train size: [400] hidden size: [77] trial: 24, train_loss: 1.697690, test loss: 1.012172, bias2: 0.8840265870094299, variance: 0.12814553081989288\n",
      "Train size: [400] hidden size: [77] trial: 25, train_loss: 1.697061, test loss: 1.011908, bias2: 0.8845636248588562, variance: 0.12734466791152954\n",
      "Train size: [400] hidden size: [77] trial: 26, train_loss: 1.694963, test loss: 1.012738, bias2: 0.8853664994239807, variance: 0.12737102806568146\n",
      "Train size: [400] hidden size: [77] trial: 27, train_loss: 1.701996, test loss: 1.012525, bias2: 0.8853667378425598, variance: 0.1271577626466751\n",
      "Train size: [400] hidden size: [77] trial: 28, train_loss: 1.700595, test loss: 1.010828, bias2: 0.8831547498703003, variance: 0.12767361104488373\n",
      "Train size: [400] hidden size: [77] trial: 29, train_loss: 1.697287, test loss: 1.011651, bias2: 0.882584810256958, variance: 0.12906619906425476\n",
      "Train size: [400] hidden size: [77] trial: 30, train_loss: 1.696900, test loss: 1.011474, bias2: 0.882338285446167, variance: 0.129135861992836\n",
      "Train size: [400] hidden size: [77] trial: 31, train_loss: 1.699978, test loss: 1.012334, bias2: 0.8829441070556641, variance: 0.12939003109931946\n",
      "Train size: [400] hidden size: [77] trial: 32, train_loss: 1.698307, test loss: 1.012419, bias2: 0.884496808052063, variance: 0.1279219686985016\n",
      "Train size: [400] hidden size: [77] trial: 33, train_loss: 1.691272, test loss: 1.012774, bias2: 0.8839941024780273, variance: 0.12878035008907318\n",
      "Train size: [400] hidden size: [77] trial: 34, train_loss: 1.690612, test loss: 1.013490, bias2: 0.8847091197967529, variance: 0.1287812888622284\n",
      "Train size: [400] hidden size: [77] trial: 35, train_loss: 1.686668, test loss: 1.013521, bias2: 0.8845930695533752, variance: 0.12892811000347137\n",
      "Train size: [400] hidden size: [77] trial: 36, train_loss: 1.681709, test loss: 1.013950, bias2: 0.8852789402008057, variance: 0.1286710798740387\n",
      "Train size: [400] hidden size: [77] trial: 37, train_loss: 1.681408, test loss: 1.015355, bias2: 0.8863309621810913, variance: 0.12902449071407318\n",
      "Train size: [400] hidden size: [77] trial: 38, train_loss: 1.680696, test loss: 1.014818, bias2: 0.8857777118682861, variance: 0.12904071807861328\n",
      "Train size: [400] hidden size: [77] trial: 39, train_loss: 1.680987, test loss: 1.014307, bias2: 0.8850147724151611, variance: 0.12929226458072662\n",
      "Train size: [400] hidden size: [77] trial: 40, train_loss: 1.678846, test loss: 1.014435, bias2: 0.8858957290649414, variance: 0.1285397708415985\n",
      "Train size: [400] hidden size: [77] trial: 41, train_loss: 1.681150, test loss: 1.014397, bias2: 0.886280357837677, variance: 0.1281168907880783\n",
      "Train size: [400] hidden size: [77] trial: 42, train_loss: 1.677955, test loss: 1.013749, bias2: 0.8865954875946045, variance: 0.1271533966064453\n",
      "Train size: [400] hidden size: [77] trial: 43, train_loss: 1.675830, test loss: 1.013455, bias2: 0.8864770531654358, variance: 0.1269778609275818\n",
      "Train size: [400] hidden size: [77] trial: 44, train_loss: 1.678818, test loss: 1.014013, bias2: 0.8859490752220154, variance: 0.12806372344493866\n",
      "Train size: [400] hidden size: [77] trial: 45, train_loss: 1.680605, test loss: 1.013257, bias2: 0.8856670260429382, variance: 0.12758998572826385\n",
      "Train size: [400] hidden size: [77] trial: 46, train_loss: 1.676865, test loss: 1.013833, bias2: 0.8841975927352905, variance: 0.12963545322418213\n",
      "Train size: [400] hidden size: [77] trial: 47, train_loss: 1.675720, test loss: 1.013983, bias2: 0.8841269612312317, variance: 0.12985557317733765\n",
      "Train size: [400] hidden size: [77] trial: 48, train_loss: 1.674538, test loss: 1.014800, bias2: 0.8855371475219727, variance: 0.12926247715950012\n",
      "Train size: [400] hidden size: [77] trial: 49, train_loss: 1.673063, test loss: 1.015052, bias2: 0.8857108354568481, variance: 0.129341259598732\n",
      "##################################################\n",
      "Train size: [400] hidden size: [89] trial: 0, train_loss: 1.660023, test loss: 1.045402, bias2: 1.0454021692276, variance: 1.6543327818752118e-09\n",
      "Train size: [400] hidden size: [89] trial: 1, train_loss: 1.682934, test loss: 1.027135, bias2: 0.9324634671211243, variance: 0.09467189013957977\n",
      "Train size: [400] hidden size: [89] trial: 2, train_loss: 1.647263, test loss: 1.042295, bias2: 0.9158984422683716, variance: 0.1263965517282486\n",
      "Train size: [400] hidden size: [89] trial: 3, train_loss: 1.626964, test loss: 1.037280, bias2: 0.9038965702056885, variance: 0.13338300585746765\n",
      "Train size: [400] hidden size: [89] trial: 4, train_loss: 1.639281, test loss: 1.031561, bias2: 0.8920551538467407, variance: 0.13950574398040771\n",
      "Train size: [400] hidden size: [89] trial: 5, train_loss: 1.624694, test loss: 1.035289, bias2: 0.8921469449996948, variance: 0.1431419551372528\n",
      "Train size: [400] hidden size: [89] trial: 6, train_loss: 1.613509, test loss: 1.034565, bias2: 0.8935678005218506, variance: 0.1409974992275238\n",
      "Train size: [400] hidden size: [89] trial: 7, train_loss: 1.576475, test loss: 1.031127, bias2: 0.8875171542167664, variance: 0.14360983669757843\n",
      "Train size: [400] hidden size: [89] trial: 8, train_loss: 1.576101, test loss: 1.035451, bias2: 0.8871004581451416, variance: 0.14835068583488464\n",
      "Train size: [400] hidden size: [89] trial: 9, train_loss: 1.581874, test loss: 1.034587, bias2: 0.890501856803894, variance: 0.14408518373966217\n",
      "Train size: [400] hidden size: [89] trial: 10, train_loss: 1.595284, test loss: 1.029939, bias2: 0.8871920704841614, variance: 0.14274664223194122\n",
      "Train size: [400] hidden size: [89] trial: 11, train_loss: 1.575744, test loss: 1.026183, bias2: 0.8835415244102478, variance: 0.14264138042926788\n",
      "Train size: [400] hidden size: [89] trial: 12, train_loss: 1.583992, test loss: 1.026266, bias2: 0.8773099780082703, variance: 0.14895552396774292\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [89] trial: 13, train_loss: 1.573609, test loss: 1.025975, bias2: 0.8742152452468872, variance: 0.15176020562648773\n",
      "Train size: [400] hidden size: [89] trial: 14, train_loss: 1.571952, test loss: 1.022201, bias2: 0.8725693225860596, variance: 0.14963187277317047\n",
      "Train size: [400] hidden size: [89] trial: 15, train_loss: 1.567045, test loss: 1.023444, bias2: 0.8683705925941467, variance: 0.15507382154464722\n",
      "Train size: [400] hidden size: [89] trial: 16, train_loss: 1.570032, test loss: 1.022663, bias2: 0.8690983057022095, variance: 0.1535644829273224\n",
      "Train size: [400] hidden size: [89] trial: 17, train_loss: 1.570480, test loss: 1.020274, bias2: 0.8671630024909973, variance: 0.1531110256910324\n",
      "Train size: [400] hidden size: [89] trial: 18, train_loss: 1.576081, test loss: 1.022226, bias2: 0.869767427444458, variance: 0.15245899558067322\n",
      "Train size: [400] hidden size: [89] trial: 19, train_loss: 1.575271, test loss: 1.025213, bias2: 0.8706213235855103, variance: 0.15459167957305908\n",
      "Train size: [400] hidden size: [89] trial: 20, train_loss: 1.580156, test loss: 1.023530, bias2: 0.8688895106315613, variance: 0.15464048087596893\n",
      "Train size: [400] hidden size: [89] trial: 21, train_loss: 1.580698, test loss: 1.021578, bias2: 0.8684123158454895, variance: 0.15316540002822876\n",
      "Train size: [400] hidden size: [89] trial: 22, train_loss: 1.581304, test loss: 1.021583, bias2: 0.8682194352149963, variance: 0.15336374938488007\n",
      "Train size: [400] hidden size: [89] trial: 23, train_loss: 1.583713, test loss: 1.024389, bias2: 0.8690464496612549, variance: 0.15534260869026184\n",
      "Train size: [400] hidden size: [89] trial: 24, train_loss: 1.585073, test loss: 1.024732, bias2: 0.8690071105957031, variance: 0.15572522580623627\n",
      "Train size: [400] hidden size: [89] trial: 25, train_loss: 1.591313, test loss: 1.024803, bias2: 0.8694514036178589, variance: 0.15535126626491547\n",
      "Train size: [400] hidden size: [89] trial: 26, train_loss: 1.589958, test loss: 1.024638, bias2: 0.866447925567627, variance: 0.15819022059440613\n",
      "Train size: [400] hidden size: [89] trial: 27, train_loss: 1.589537, test loss: 1.024095, bias2: 0.8661002516746521, variance: 0.15799444913864136\n",
      "Train size: [400] hidden size: [89] trial: 28, train_loss: 1.586285, test loss: 1.024013, bias2: 0.8669999837875366, variance: 0.157012939453125\n",
      "Train size: [400] hidden size: [89] trial: 29, train_loss: 1.590171, test loss: 1.024488, bias2: 0.8677164316177368, variance: 0.15677133202552795\n",
      "Train size: [400] hidden size: [89] trial: 30, train_loss: 1.590656, test loss: 1.023762, bias2: 0.8684990406036377, variance: 0.15526247024536133\n",
      "Train size: [400] hidden size: [89] trial: 31, train_loss: 1.594234, test loss: 1.022288, bias2: 0.8669028878211975, variance: 0.1553846001625061\n",
      "Train size: [400] hidden size: [89] trial: 32, train_loss: 1.599388, test loss: 1.021949, bias2: 0.8644790053367615, variance: 0.15747006237506866\n",
      "Train size: [400] hidden size: [89] trial: 33, train_loss: 1.603737, test loss: 1.023377, bias2: 0.8660889863967896, variance: 0.15728792548179626\n",
      "Train size: [400] hidden size: [89] trial: 34, train_loss: 1.604951, test loss: 1.023706, bias2: 0.8660361170768738, variance: 0.15766972303390503\n",
      "Train size: [400] hidden size: [89] trial: 35, train_loss: 1.604327, test loss: 1.023275, bias2: 0.8654448986053467, variance: 0.15783022344112396\n",
      "Train size: [400] hidden size: [89] trial: 36, train_loss: 1.600211, test loss: 1.022088, bias2: 0.8636536002159119, variance: 0.1584339588880539\n",
      "Train size: [400] hidden size: [89] trial: 37, train_loss: 1.597486, test loss: 1.022137, bias2: 0.8646590113639832, variance: 0.15747790038585663\n",
      "Train size: [400] hidden size: [89] trial: 38, train_loss: 1.598089, test loss: 1.020525, bias2: 0.8638579845428467, variance: 0.15666748583316803\n",
      "Train size: [400] hidden size: [89] trial: 39, train_loss: 1.599136, test loss: 1.021392, bias2: 0.864896297454834, variance: 0.15649567544460297\n",
      "Train size: [400] hidden size: [89] trial: 40, train_loss: 1.602081, test loss: 1.021499, bias2: 0.8659502267837524, variance: 0.1555483639240265\n",
      "Train size: [400] hidden size: [89] trial: 41, train_loss: 1.598703, test loss: 1.021627, bias2: 0.8662253618240356, variance: 0.1554015576839447\n",
      "Train size: [400] hidden size: [89] trial: 42, train_loss: 1.600764, test loss: 1.021832, bias2: 0.865286648273468, variance: 0.1565456986427307\n",
      "Train size: [400] hidden size: [89] trial: 43, train_loss: 1.598711, test loss: 1.022379, bias2: 0.8654418587684631, variance: 0.1569374054670334\n",
      "Train size: [400] hidden size: [89] trial: 44, train_loss: 1.601466, test loss: 1.022830, bias2: 0.8653541207313538, variance: 0.15747590363025665\n",
      "Train size: [400] hidden size: [89] trial: 45, train_loss: 1.597622, test loss: 1.022641, bias2: 0.8647600412368774, variance: 0.15788088738918304\n",
      "Train size: [400] hidden size: [89] trial: 46, train_loss: 1.598426, test loss: 1.023419, bias2: 0.8663450479507446, variance: 0.15707412362098694\n",
      "Train size: [400] hidden size: [89] trial: 47, train_loss: 1.596633, test loss: 1.023312, bias2: 0.8666800260543823, variance: 0.15663209557533264\n",
      "Train size: [400] hidden size: [89] trial: 48, train_loss: 1.592266, test loss: 1.022523, bias2: 0.8647679090499878, variance: 0.15775524079799652\n",
      "Train size: [400] hidden size: [89] trial: 49, train_loss: 1.594071, test loss: 1.022610, bias2: 0.864719808101654, variance: 0.15789039433002472\n",
      "##################################################\n",
      "Train size: [400] hidden size: [102] trial: 0, train_loss: 1.603232, test loss: 0.960973, bias2: 0.9609733819961548, variance: 8.758233027705842e-10\n",
      "Train size: [400] hidden size: [102] trial: 1, train_loss: 1.589413, test loss: 0.998358, bias2: 0.910243809223175, variance: 0.08811457455158234\n",
      "Train size: [400] hidden size: [102] trial: 2, train_loss: 1.520053, test loss: 1.008738, bias2: 0.8850870132446289, variance: 0.12365112453699112\n",
      "Train size: [400] hidden size: [102] trial: 3, train_loss: 1.496365, test loss: 1.022661, bias2: 0.8949494957923889, variance: 0.12771110236644745\n",
      "Train size: [400] hidden size: [102] trial: 4, train_loss: 1.472834, test loss: 1.026199, bias2: 0.8881725072860718, variance: 0.13802644610404968\n",
      "Train size: [400] hidden size: [102] trial: 5, train_loss: 1.484286, test loss: 1.024818, bias2: 0.8796435594558716, variance: 0.14517450332641602\n",
      "Train size: [400] hidden size: [102] trial: 6, train_loss: 1.513054, test loss: 1.028965, bias2: 0.8822619318962097, variance: 0.14670294523239136\n",
      "Train size: [400] hidden size: [102] trial: 7, train_loss: 1.526680, test loss: 1.033856, bias2: 0.877048671245575, variance: 0.15680687129497528\n",
      "Train size: [400] hidden size: [102] trial: 8, train_loss: 1.544393, test loss: 1.032108, bias2: 0.8752200603485107, variance: 0.15688803791999817\n",
      "Train size: [400] hidden size: [102] trial: 9, train_loss: 1.529976, test loss: 1.031005, bias2: 0.8712796568870544, variance: 0.1597248911857605\n",
      "Train size: [400] hidden size: [102] trial: 10, train_loss: 1.543267, test loss: 1.026594, bias2: 0.8605726957321167, variance: 0.16602084040641785\n",
      "Train size: [400] hidden size: [102] trial: 11, train_loss: 1.535309, test loss: 1.021355, bias2: 0.8542568683624268, variance: 0.16709767282009125\n",
      "Train size: [400] hidden size: [102] trial: 12, train_loss: 1.534825, test loss: 1.019417, bias2: 0.8544455170631409, variance: 0.16497178375720978\n",
      "Train size: [400] hidden size: [102] trial: 13, train_loss: 1.533542, test loss: 1.024958, bias2: 0.8580953478813171, variance: 0.16686300933361053\n",
      "Train size: [400] hidden size: [102] trial: 14, train_loss: 1.532521, test loss: 1.025123, bias2: 0.8622522354125977, variance: 0.1628706455230713\n",
      "Train size: [400] hidden size: [102] trial: 15, train_loss: 1.532445, test loss: 1.026148, bias2: 0.8597389459609985, variance: 0.16640926897525787\n",
      "Train size: [400] hidden size: [102] trial: 16, train_loss: 1.534496, test loss: 1.025589, bias2: 0.8591850996017456, variance: 0.16640403866767883\n",
      "Train size: [400] hidden size: [102] trial: 17, train_loss: 1.529362, test loss: 1.021601, bias2: 0.8575442433357239, variance: 0.16405649483203888\n",
      "Train size: [400] hidden size: [102] trial: 18, train_loss: 1.540888, test loss: 1.020690, bias2: 0.8561820387840271, variance: 0.1645084023475647\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [102] trial: 19, train_loss: 1.547941, test loss: 1.018590, bias2: 0.8548806309700012, variance: 0.1637098342180252\n",
      "Train size: [400] hidden size: [102] trial: 20, train_loss: 1.550287, test loss: 1.018855, bias2: 0.8571826815605164, variance: 0.16167277097702026\n",
      "Train size: [400] hidden size: [102] trial: 21, train_loss: 1.547893, test loss: 1.020806, bias2: 0.8591601848602295, variance: 0.16164563596248627\n",
      "Train size: [400] hidden size: [102] trial: 22, train_loss: 1.548749, test loss: 1.019421, bias2: 0.8556080460548401, variance: 0.1638125777244568\n",
      "Train size: [400] hidden size: [102] trial: 23, train_loss: 1.550735, test loss: 1.019113, bias2: 0.8541169762611389, variance: 0.1649964600801468\n",
      "Train size: [400] hidden size: [102] trial: 24, train_loss: 1.553293, test loss: 1.020055, bias2: 0.8554521799087524, variance: 0.16460248827934265\n",
      "Train size: [400] hidden size: [102] trial: 25, train_loss: 1.553043, test loss: 1.020555, bias2: 0.8561198115348816, variance: 0.1644354611635208\n",
      "Train size: [400] hidden size: [102] trial: 26, train_loss: 1.560309, test loss: 1.020321, bias2: 0.8545270562171936, variance: 0.16579429805278778\n",
      "Train size: [400] hidden size: [102] trial: 27, train_loss: 1.560655, test loss: 1.020385, bias2: 0.8531392812728882, variance: 0.1672457605600357\n",
      "Train size: [400] hidden size: [102] trial: 28, train_loss: 1.559622, test loss: 1.019874, bias2: 0.851180911064148, variance: 0.1686929315328598\n",
      "Train size: [400] hidden size: [102] trial: 29, train_loss: 1.565540, test loss: 1.021408, bias2: 0.851069986820221, variance: 0.17033761739730835\n",
      "Train size: [400] hidden size: [102] trial: 30, train_loss: 1.558695, test loss: 1.020790, bias2: 0.8498210310935974, variance: 0.17096883058547974\n",
      "Train size: [400] hidden size: [102] trial: 31, train_loss: 1.558732, test loss: 1.019493, bias2: 0.8494271039962769, variance: 0.1700655221939087\n",
      "Train size: [400] hidden size: [102] trial: 32, train_loss: 1.560406, test loss: 1.018817, bias2: 0.8487884998321533, variance: 0.1700284630060196\n",
      "Train size: [400] hidden size: [102] trial: 33, train_loss: 1.565331, test loss: 1.019273, bias2: 0.8479910492897034, variance: 0.17128176987171173\n",
      "Train size: [400] hidden size: [102] trial: 34, train_loss: 1.563889, test loss: 1.019743, bias2: 0.8484194874763489, variance: 0.17132334411144257\n",
      "Train size: [400] hidden size: [102] trial: 35, train_loss: 1.567792, test loss: 1.018490, bias2: 0.8473579287528992, variance: 0.17113204300403595\n",
      "Train size: [400] hidden size: [102] trial: 36, train_loss: 1.570166, test loss: 1.017922, bias2: 0.846381664276123, variance: 0.17154014110565186\n",
      "Train size: [400] hidden size: [102] trial: 37, train_loss: 1.569281, test loss: 1.018371, bias2: 0.8469223976135254, variance: 0.17144834995269775\n",
      "Train size: [400] hidden size: [102] trial: 38, train_loss: 1.568702, test loss: 1.018834, bias2: 0.8466848731040955, variance: 0.17214863002300262\n",
      "Train size: [400] hidden size: [102] trial: 39, train_loss: 1.568290, test loss: 1.018654, bias2: 0.8474069833755493, variance: 0.17124661803245544\n",
      "Train size: [400] hidden size: [102] trial: 40, train_loss: 1.566665, test loss: 1.019940, bias2: 0.8483221530914307, variance: 0.17161798477172852\n",
      "Train size: [400] hidden size: [102] trial: 41, train_loss: 1.567108, test loss: 1.018971, bias2: 0.8469358682632446, variance: 0.1720345914363861\n",
      "Train size: [400] hidden size: [102] trial: 42, train_loss: 1.566382, test loss: 1.019158, bias2: 0.8473087549209595, variance: 0.17184971272945404\n",
      "Train size: [400] hidden size: [102] trial: 43, train_loss: 1.565644, test loss: 1.018679, bias2: 0.8466780185699463, variance: 0.17200133204460144\n",
      "Train size: [400] hidden size: [102] trial: 44, train_loss: 1.565030, test loss: 1.017743, bias2: 0.8462005853652954, variance: 0.17154206335544586\n",
      "Train size: [400] hidden size: [102] trial: 45, train_loss: 1.561447, test loss: 1.018473, bias2: 0.8467377424240112, variance: 0.17173564434051514\n",
      "Train size: [400] hidden size: [102] trial: 46, train_loss: 1.560713, test loss: 1.018218, bias2: 0.8459970355033875, variance: 0.17222075164318085\n",
      "Train size: [400] hidden size: [102] trial: 47, train_loss: 1.559082, test loss: 1.018157, bias2: 0.8455288410186768, variance: 0.17262816429138184\n",
      "Train size: [400] hidden size: [102] trial: 48, train_loss: 1.560086, test loss: 1.018388, bias2: 0.8460271954536438, variance: 0.17236095666885376\n",
      "Train size: [400] hidden size: [102] trial: 49, train_loss: 1.559349, test loss: 1.018933, bias2: 0.8460106253623962, variance: 0.17292208969593048\n",
      "##################################################\n",
      "Train size: [400] hidden size: [118] trial: 0, train_loss: 1.447768, test loss: 1.005142, bias2: 1.005142092704773, variance: 5.838822203507732e-10\n",
      "Train size: [400] hidden size: [118] trial: 1, train_loss: 1.522293, test loss: 1.004212, bias2: 0.8804535269737244, variance: 0.12375839054584503\n",
      "Train size: [400] hidden size: [118] trial: 2, train_loss: 1.472560, test loss: 1.018292, bias2: 0.8573387861251831, variance: 0.16095362603664398\n",
      "Train size: [400] hidden size: [118] trial: 3, train_loss: 1.463775, test loss: 1.029530, bias2: 0.8512448072433472, variance: 0.17828485369682312\n",
      "Train size: [400] hidden size: [118] trial: 4, train_loss: 1.463144, test loss: 1.031311, bias2: 0.8435158133506775, variance: 0.18779510259628296\n",
      "Train size: [400] hidden size: [118] trial: 5, train_loss: 1.461015, test loss: 1.028952, bias2: 0.8344228267669678, variance: 0.19452950358390808\n",
      "Train size: [400] hidden size: [118] trial: 6, train_loss: 1.452190, test loss: 1.033416, bias2: 0.8342660665512085, variance: 0.19914986193180084\n",
      "Train size: [400] hidden size: [118] trial: 7, train_loss: 1.452807, test loss: 1.024123, bias2: 0.8305152654647827, variance: 0.19360770285129547\n",
      "Train size: [400] hidden size: [118] trial: 8, train_loss: 1.480501, test loss: 1.017650, bias2: 0.8146137595176697, variance: 0.2030361443758011\n",
      "Train size: [400] hidden size: [118] trial: 9, train_loss: 1.485931, test loss: 1.018243, bias2: 0.818150520324707, variance: 0.20009253919124603\n",
      "Train size: [400] hidden size: [118] trial: 10, train_loss: 1.474473, test loss: 1.015824, bias2: 0.8182335495948792, variance: 0.19759078323841095\n",
      "Train size: [400] hidden size: [118] trial: 11, train_loss: 1.483445, test loss: 1.018052, bias2: 0.8208854794502258, variance: 0.19716601073741913\n",
      "Train size: [400] hidden size: [118] trial: 12, train_loss: 1.487418, test loss: 1.021748, bias2: 0.8237883448600769, variance: 0.19795985519886017\n",
      "Train size: [400] hidden size: [118] trial: 13, train_loss: 1.491026, test loss: 1.022321, bias2: 0.8260838985443115, variance: 0.1962367296218872\n",
      "Train size: [400] hidden size: [118] trial: 14, train_loss: 1.481259, test loss: 1.021626, bias2: 0.8275424242019653, variance: 0.19408342242240906\n",
      "Train size: [400] hidden size: [118] trial: 15, train_loss: 1.485792, test loss: 1.024677, bias2: 0.8274938464164734, variance: 0.1971835494041443\n",
      "Train size: [400] hidden size: [118] trial: 16, train_loss: 1.481288, test loss: 1.026885, bias2: 0.8271597623825073, variance: 0.19972476363182068\n",
      "Train size: [400] hidden size: [118] trial: 17, train_loss: 1.481287, test loss: 1.024189, bias2: 0.827384352684021, variance: 0.19680486619472504\n",
      "Train size: [400] hidden size: [118] trial: 18, train_loss: 1.472635, test loss: 1.020778, bias2: 0.8257352113723755, variance: 0.19504281878471375\n",
      "Train size: [400] hidden size: [118] trial: 19, train_loss: 1.471884, test loss: 1.022921, bias2: 0.8249924182891846, variance: 0.1979285627603531\n",
      "Train size: [400] hidden size: [118] trial: 20, train_loss: 1.468658, test loss: 1.020726, bias2: 0.8244972825050354, variance: 0.19622844457626343\n",
      "Train size: [400] hidden size: [118] trial: 21, train_loss: 1.465449, test loss: 1.021943, bias2: 0.8250797390937805, variance: 0.19686289131641388\n",
      "Train size: [400] hidden size: [118] trial: 22, train_loss: 1.470980, test loss: 1.020912, bias2: 0.8226913213729858, variance: 0.19822072982788086\n",
      "Train size: [400] hidden size: [118] trial: 23, train_loss: 1.473000, test loss: 1.021167, bias2: 0.8226349949836731, variance: 0.19853229820728302\n",
      "Train size: [400] hidden size: [118] trial: 24, train_loss: 1.476297, test loss: 1.019730, bias2: 0.8176525831222534, variance: 0.20207783579826355\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [118] trial: 25, train_loss: 1.472720, test loss: 1.019214, bias2: 0.8189616799354553, variance: 0.20025259256362915\n",
      "Train size: [400] hidden size: [118] trial: 26, train_loss: 1.474427, test loss: 1.020025, bias2: 0.820227861404419, variance: 0.19979751110076904\n",
      "Train size: [400] hidden size: [118] trial: 27, train_loss: 1.470750, test loss: 1.020723, bias2: 0.8217166066169739, variance: 0.19900627434253693\n",
      "Train size: [400] hidden size: [118] trial: 28, train_loss: 1.467643, test loss: 1.021870, bias2: 0.8218317031860352, variance: 0.20003782212734222\n",
      "Train size: [400] hidden size: [118] trial: 29, train_loss: 1.468236, test loss: 1.020594, bias2: 0.8201947212219238, variance: 0.20039892196655273\n",
      "Train size: [400] hidden size: [118] trial: 30, train_loss: 1.470902, test loss: 1.023366, bias2: 0.8205755949020386, variance: 0.20279017090797424\n",
      "Train size: [400] hidden size: [118] trial: 31, train_loss: 1.473222, test loss: 1.023268, bias2: 0.8218023777008057, variance: 0.20146523416042328\n",
      "Train size: [400] hidden size: [118] trial: 32, train_loss: 1.479038, test loss: 1.025974, bias2: 0.8228794932365417, variance: 0.20309489965438843\n",
      "Train size: [400] hidden size: [118] trial: 33, train_loss: 1.483126, test loss: 1.026565, bias2: 0.8227401375770569, variance: 0.20382456481456757\n",
      "Train size: [400] hidden size: [118] trial: 34, train_loss: 1.484337, test loss: 1.026888, bias2: 0.8228254914283752, variance: 0.20406202971935272\n",
      "Train size: [400] hidden size: [118] trial: 35, train_loss: 1.486664, test loss: 1.025470, bias2: 0.8218746781349182, variance: 0.20359556376934052\n",
      "Train size: [400] hidden size: [118] trial: 36, train_loss: 1.483568, test loss: 1.025041, bias2: 0.8214960098266602, variance: 0.2035447508096695\n",
      "Train size: [400] hidden size: [118] trial: 37, train_loss: 1.476467, test loss: 1.023789, bias2: 0.821250319480896, variance: 0.20253869891166687\n",
      "Train size: [400] hidden size: [118] trial: 38, train_loss: 1.477811, test loss: 1.023597, bias2: 0.819869875907898, variance: 0.2037266492843628\n",
      "Train size: [400] hidden size: [118] trial: 39, train_loss: 1.478420, test loss: 1.023625, bias2: 0.8200723528862, variance: 0.20355291664600372\n",
      "Train size: [400] hidden size: [118] trial: 40, train_loss: 1.474042, test loss: 1.024098, bias2: 0.8198754191398621, variance: 0.20422212779521942\n",
      "Train size: [400] hidden size: [118] trial: 41, train_loss: 1.469911, test loss: 1.024441, bias2: 0.8209943771362305, variance: 0.20344701409339905\n",
      "Train size: [400] hidden size: [118] trial: 42, train_loss: 1.467521, test loss: 1.024489, bias2: 0.8189986944198608, variance: 0.2054898887872696\n",
      "Train size: [400] hidden size: [118] trial: 43, train_loss: 1.469599, test loss: 1.025169, bias2: 0.8201813697814941, variance: 0.20498766005039215\n",
      "Train size: [400] hidden size: [118] trial: 44, train_loss: 1.464976, test loss: 1.025328, bias2: 0.820075511932373, variance: 0.20525239408016205\n",
      "Train size: [400] hidden size: [118] trial: 45, train_loss: 1.467142, test loss: 1.026010, bias2: 0.8216433525085449, variance: 0.2043665498495102\n",
      "Train size: [400] hidden size: [118] trial: 46, train_loss: 1.469768, test loss: 1.025624, bias2: 0.8206119537353516, variance: 0.20501157641410828\n",
      "Train size: [400] hidden size: [118] trial: 47, train_loss: 1.469309, test loss: 1.025054, bias2: 0.8204644918441772, variance: 0.20458999276161194\n",
      "Train size: [400] hidden size: [118] trial: 48, train_loss: 1.470521, test loss: 1.024436, bias2: 0.8199361562728882, variance: 0.20449963212013245\n",
      "Train size: [400] hidden size: [118] trial: 49, train_loss: 1.471755, test loss: 1.024754, bias2: 0.8201980590820312, variance: 0.20455636084079742\n",
      "##################################################\n",
      "Train size: [400] hidden size: [136] trial: 0, train_loss: 1.373167, test loss: 0.967344, bias2: 0.9673437476158142, variance: 4.087175486944261e-09\n",
      "Train size: [400] hidden size: [136] trial: 1, train_loss: 1.349703, test loss: 1.000064, bias2: 0.8749827146530151, variance: 0.12508156895637512\n",
      "Train size: [400] hidden size: [136] trial: 2, train_loss: 1.366924, test loss: 1.014135, bias2: 0.8643916845321655, variance: 0.14974355697631836\n",
      "Train size: [400] hidden size: [136] trial: 3, train_loss: 1.350127, test loss: 1.015180, bias2: 0.8540515303611755, variance: 0.16112832725048065\n",
      "Train size: [400] hidden size: [136] trial: 4, train_loss: 1.382009, test loss: 1.020839, bias2: 0.8430404663085938, variance: 0.17779836058616638\n",
      "Train size: [400] hidden size: [136] trial: 5, train_loss: 1.367528, test loss: 1.006917, bias2: 0.8233870267868042, variance: 0.18353043496608734\n",
      "Train size: [400] hidden size: [136] trial: 6, train_loss: 1.384455, test loss: 0.997405, bias2: 0.8107701539993286, variance: 0.18663495779037476\n",
      "Train size: [400] hidden size: [136] trial: 7, train_loss: 1.361259, test loss: 0.997945, bias2: 0.8083449602127075, variance: 0.18960019946098328\n",
      "Train size: [400] hidden size: [136] trial: 8, train_loss: 1.399789, test loss: 0.995973, bias2: 0.8039063215255737, variance: 0.19206684827804565\n",
      "Train size: [400] hidden size: [136] trial: 9, train_loss: 1.409111, test loss: 1.002239, bias2: 0.8061800599098206, variance: 0.19605855643749237\n",
      "Train size: [400] hidden size: [136] trial: 10, train_loss: 1.422754, test loss: 1.006416, bias2: 0.8056129217147827, variance: 0.2008027732372284\n",
      "Train size: [400] hidden size: [136] trial: 11, train_loss: 1.409920, test loss: 1.006963, bias2: 0.8026384711265564, variance: 0.20432442426681519\n",
      "Train size: [400] hidden size: [136] trial: 12, train_loss: 1.402394, test loss: 1.006220, bias2: 0.7986350655555725, variance: 0.2075853943824768\n",
      "Train size: [400] hidden size: [136] trial: 13, train_loss: 1.401721, test loss: 1.007382, bias2: 0.7994858026504517, variance: 0.2078963667154312\n",
      "Train size: [400] hidden size: [136] trial: 14, train_loss: 1.399496, test loss: 1.004840, bias2: 0.796913743019104, variance: 0.207925945520401\n",
      "Train size: [400] hidden size: [136] trial: 15, train_loss: 1.401185, test loss: 1.005765, bias2: 0.7989370822906494, variance: 0.20682749152183533\n",
      "Train size: [400] hidden size: [136] trial: 16, train_loss: 1.407619, test loss: 1.009603, bias2: 0.8012430667877197, variance: 0.20836006104946136\n",
      "Train size: [400] hidden size: [136] trial: 17, train_loss: 1.422362, test loss: 1.013242, bias2: 0.8059102296829224, variance: 0.20733162760734558\n",
      "Train size: [400] hidden size: [136] trial: 18, train_loss: 1.416515, test loss: 1.012742, bias2: 0.8039077520370483, variance: 0.2088342010974884\n",
      "Train size: [400] hidden size: [136] trial: 19, train_loss: 1.412325, test loss: 1.011666, bias2: 0.8031302690505981, variance: 0.2085355818271637\n",
      "Train size: [400] hidden size: [136] trial: 20, train_loss: 1.417077, test loss: 1.010393, bias2: 0.8033227920532227, variance: 0.2070704698562622\n",
      "Train size: [400] hidden size: [136] trial: 21, train_loss: 1.425194, test loss: 1.013156, bias2: 0.8012365698814392, variance: 0.21191948652267456\n",
      "Train size: [400] hidden size: [136] trial: 22, train_loss: 1.414379, test loss: 1.012294, bias2: 0.8005737066268921, variance: 0.21172037720680237\n",
      "Train size: [400] hidden size: [136] trial: 23, train_loss: 1.423803, test loss: 1.015742, bias2: 0.8015360236167908, variance: 0.2142055481672287\n",
      "Train size: [400] hidden size: [136] trial: 24, train_loss: 1.414710, test loss: 1.016951, bias2: 0.8016851544380188, variance: 0.21526628732681274\n",
      "Train size: [400] hidden size: [136] trial: 25, train_loss: 1.409274, test loss: 1.016555, bias2: 0.7996628284454346, variance: 0.21689261496067047\n",
      "Train size: [400] hidden size: [136] trial: 26, train_loss: 1.419508, test loss: 1.018114, bias2: 0.8012251853942871, variance: 0.2168886959552765\n",
      "Train size: [400] hidden size: [136] trial: 27, train_loss: 1.422586, test loss: 1.017969, bias2: 0.8012984991073608, variance: 0.21667028963565826\n",
      "Train size: [400] hidden size: [136] trial: 28, train_loss: 1.419695, test loss: 1.017926, bias2: 0.7984687685966492, variance: 0.21945708990097046\n",
      "Train size: [400] hidden size: [136] trial: 29, train_loss: 1.419814, test loss: 1.019162, bias2: 0.7980620861053467, variance: 0.2210996150970459\n",
      "Train size: [400] hidden size: [136] trial: 30, train_loss: 1.417054, test loss: 1.019703, bias2: 0.7978153228759766, variance: 0.22188785672187805\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [136] trial: 31, train_loss: 1.414660, test loss: 1.018635, bias2: 0.7974971532821655, variance: 0.22113777697086334\n",
      "Train size: [400] hidden size: [136] trial: 32, train_loss: 1.409997, test loss: 1.016479, bias2: 0.7961612939834595, variance: 0.22031748294830322\n",
      "Train size: [400] hidden size: [136] trial: 33, train_loss: 1.410325, test loss: 1.018316, bias2: 0.795348048210144, variance: 0.22296811640262604\n",
      "Train size: [400] hidden size: [136] trial: 34, train_loss: 1.407384, test loss: 1.020708, bias2: 0.7983841300010681, variance: 0.22232381999492645\n",
      "Train size: [400] hidden size: [136] trial: 35, train_loss: 1.409382, test loss: 1.021204, bias2: 0.7988081574440002, variance: 0.22239534556865692\n",
      "Train size: [400] hidden size: [136] trial: 36, train_loss: 1.407665, test loss: 1.019944, bias2: 0.7985426187515259, variance: 0.22140160202980042\n",
      "Train size: [400] hidden size: [136] trial: 37, train_loss: 1.402656, test loss: 1.020605, bias2: 0.8004717230796814, variance: 0.2201337367296219\n",
      "Train size: [400] hidden size: [136] trial: 38, train_loss: 1.403687, test loss: 1.020036, bias2: 0.7992040514945984, variance: 0.22083227336406708\n",
      "Train size: [400] hidden size: [136] trial: 39, train_loss: 1.409823, test loss: 1.020011, bias2: 0.7986701726913452, variance: 0.22134122252464294\n",
      "Train size: [400] hidden size: [136] trial: 40, train_loss: 1.413068, test loss: 1.020655, bias2: 0.7992140054702759, variance: 0.2214406579732895\n",
      "Train size: [400] hidden size: [136] trial: 41, train_loss: 1.409727, test loss: 1.022028, bias2: 0.799734354019165, variance: 0.22229400277137756\n",
      "Train size: [400] hidden size: [136] trial: 42, train_loss: 1.410788, test loss: 1.022090, bias2: 0.7988512516021729, variance: 0.22323846817016602\n",
      "Train size: [400] hidden size: [136] trial: 43, train_loss: 1.407386, test loss: 1.021031, bias2: 0.7984092831611633, variance: 0.22262173891067505\n",
      "Train size: [400] hidden size: [136] trial: 44, train_loss: 1.406426, test loss: 1.020084, bias2: 0.7964743375778198, variance: 0.2236095815896988\n",
      "Train size: [400] hidden size: [136] trial: 45, train_loss: 1.405038, test loss: 1.018997, bias2: 0.7959091067314148, variance: 0.22308821976184845\n",
      "Train size: [400] hidden size: [136] trial: 46, train_loss: 1.406631, test loss: 1.019546, bias2: 0.7967792749404907, variance: 0.22276708483695984\n",
      "Train size: [400] hidden size: [136] trial: 47, train_loss: 1.405489, test loss: 1.018482, bias2: 0.7959479689598083, variance: 0.22253374755382538\n",
      "Train size: [400] hidden size: [136] trial: 48, train_loss: 1.407127, test loss: 1.018239, bias2: 0.7949484586715698, variance: 0.223290354013443\n",
      "Train size: [400] hidden size: [136] trial: 49, train_loss: 1.411050, test loss: 1.018660, bias2: 0.7956022620201111, variance: 0.2230575531721115\n",
      "##################################################\n",
      "Train size: [400] hidden size: [156] trial: 0, train_loss: 1.422309, test loss: 1.035897, bias2: 1.035897135734558, variance: 3.8925479506346505e-10\n",
      "Train size: [400] hidden size: [156] trial: 1, train_loss: 1.431977, test loss: 1.038021, bias2: 0.882593035697937, variance: 0.15542802214622498\n",
      "Train size: [400] hidden size: [156] trial: 2, train_loss: 1.497812, test loss: 1.051243, bias2: 0.8515506982803345, variance: 0.1996924877166748\n",
      "Train size: [400] hidden size: [156] trial: 3, train_loss: 1.474992, test loss: 1.037798, bias2: 0.8246663808822632, variance: 0.21313177049160004\n",
      "Train size: [400] hidden size: [156] trial: 4, train_loss: 1.444792, test loss: 1.041325, bias2: 0.8154049515724182, variance: 0.22592048346996307\n",
      "Train size: [400] hidden size: [156] trial: 5, train_loss: 1.434486, test loss: 1.044211, bias2: 0.8163838386535645, variance: 0.22782708704471588\n",
      "Train size: [400] hidden size: [156] trial: 6, train_loss: 1.428617, test loss: 1.038352, bias2: 0.8036089539527893, variance: 0.23474343121051788\n",
      "Train size: [400] hidden size: [156] trial: 7, train_loss: 1.413641, test loss: 1.039623, bias2: 0.8018054366111755, variance: 0.23781783878803253\n",
      "Train size: [400] hidden size: [156] trial: 8, train_loss: 1.422824, test loss: 1.027336, bias2: 0.7866054773330688, variance: 0.24073030054569244\n",
      "Train size: [400] hidden size: [156] trial: 9, train_loss: 1.420799, test loss: 1.028944, bias2: 0.7871217727661133, variance: 0.2418227195739746\n",
      "Train size: [400] hidden size: [156] trial: 10, train_loss: 1.415188, test loss: 1.027260, bias2: 0.7847290635108948, variance: 0.24253089725971222\n",
      "Train size: [400] hidden size: [156] trial: 11, train_loss: 1.407789, test loss: 1.028097, bias2: 0.7821870446205139, variance: 0.24590963125228882\n",
      "Train size: [400] hidden size: [156] trial: 12, train_loss: 1.408152, test loss: 1.030419, bias2: 0.7781487703323364, variance: 0.2522701025009155\n",
      "Train size: [400] hidden size: [156] trial: 13, train_loss: 1.413258, test loss: 1.034546, bias2: 0.7795528769493103, variance: 0.25499314069747925\n",
      "Train size: [400] hidden size: [156] trial: 14, train_loss: 1.408780, test loss: 1.034985, bias2: 0.7799022197723389, variance: 0.2550829350948334\n",
      "Train size: [400] hidden size: [156] trial: 15, train_loss: 1.410078, test loss: 1.035937, bias2: 0.7794381380081177, variance: 0.25649914145469666\n",
      "Train size: [400] hidden size: [156] trial: 16, train_loss: 1.421749, test loss: 1.033108, bias2: 0.7770689129829407, variance: 0.25603896379470825\n",
      "Train size: [400] hidden size: [156] trial: 17, train_loss: 1.413748, test loss: 1.032635, bias2: 0.7756993770599365, variance: 0.25693535804748535\n",
      "Train size: [400] hidden size: [156] trial: 18, train_loss: 1.409373, test loss: 1.030926, bias2: 0.7725571990013123, variance: 0.25836843252182007\n",
      "Train size: [400] hidden size: [156] trial: 19, train_loss: 1.406562, test loss: 1.028671, bias2: 0.7706629037857056, variance: 0.2580077350139618\n",
      "Train size: [400] hidden size: [156] trial: 20, train_loss: 1.405601, test loss: 1.029144, bias2: 0.7719934582710266, variance: 0.25715070962905884\n",
      "Train size: [400] hidden size: [156] trial: 21, train_loss: 1.402421, test loss: 1.029383, bias2: 0.7671920657157898, variance: 0.26219063997268677\n",
      "Train size: [400] hidden size: [156] trial: 22, train_loss: 1.402240, test loss: 1.029854, bias2: 0.7676454782485962, variance: 0.26220881938934326\n",
      "Train size: [400] hidden size: [156] trial: 23, train_loss: 1.401528, test loss: 1.030730, bias2: 0.7693041563034058, variance: 0.2614254653453827\n",
      "Train size: [400] hidden size: [156] trial: 24, train_loss: 1.405265, test loss: 1.030931, bias2: 0.7672440409660339, variance: 0.26368647813796997\n",
      "Train size: [400] hidden size: [156] trial: 25, train_loss: 1.405405, test loss: 1.029848, bias2: 0.7653886675834656, variance: 0.26445919275283813\n",
      "Train size: [400] hidden size: [156] trial: 26, train_loss: 1.405138, test loss: 1.031933, bias2: 0.7650223970413208, variance: 0.2669103145599365\n",
      "Train size: [400] hidden size: [156] trial: 27, train_loss: 1.397936, test loss: 1.030700, bias2: 0.7636755704879761, variance: 0.2670241594314575\n",
      "Train size: [400] hidden size: [156] trial: 28, train_loss: 1.391049, test loss: 1.031158, bias2: 0.7670012712478638, variance: 0.26415637135505676\n",
      "Train size: [400] hidden size: [156] trial: 29, train_loss: 1.390286, test loss: 1.028455, bias2: 0.7644365429878235, variance: 0.26401883363723755\n",
      "Train size: [400] hidden size: [156] trial: 30, train_loss: 1.391856, test loss: 1.026838, bias2: 0.7630784511566162, variance: 0.2637597620487213\n",
      "Train size: [400] hidden size: [156] trial: 31, train_loss: 1.398931, test loss: 1.025954, bias2: 0.7621615529060364, variance: 0.2637922167778015\n",
      "Train size: [400] hidden size: [156] trial: 32, train_loss: 1.396538, test loss: 1.023723, bias2: 0.760783314704895, variance: 0.26294007897377014\n",
      "Train size: [400] hidden size: [156] trial: 33, train_loss: 1.393904, test loss: 1.023584, bias2: 0.760593593120575, variance: 0.2629907727241516\n",
      "Train size: [400] hidden size: [156] trial: 34, train_loss: 1.394038, test loss: 1.023973, bias2: 0.7598880529403687, variance: 0.2640845477581024\n",
      "Train size: [400] hidden size: [156] trial: 35, train_loss: 1.394804, test loss: 1.023156, bias2: 0.7601383924484253, variance: 0.2630174160003662\n",
      "Train size: [400] hidden size: [156] trial: 36, train_loss: 1.395860, test loss: 1.024131, bias2: 0.7609204053878784, variance: 0.263210266828537\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [156] trial: 37, train_loss: 1.394129, test loss: 1.024207, bias2: 0.7609661817550659, variance: 0.2632404863834381\n",
      "Train size: [400] hidden size: [156] trial: 38, train_loss: 1.395285, test loss: 1.025696, bias2: 0.761780858039856, variance: 0.26391473412513733\n",
      "Train size: [400] hidden size: [156] trial: 39, train_loss: 1.394873, test loss: 1.026030, bias2: 0.763541579246521, variance: 0.26248809695243835\n",
      "Train size: [400] hidden size: [156] trial: 40, train_loss: 1.393719, test loss: 1.025566, bias2: 0.7628577947616577, variance: 0.2627086639404297\n",
      "Train size: [400] hidden size: [156] trial: 41, train_loss: 1.391584, test loss: 1.028809, bias2: 0.7639282941818237, variance: 0.26488080620765686\n",
      "Train size: [400] hidden size: [156] trial: 42, train_loss: 1.389439, test loss: 1.028040, bias2: 0.7635864019393921, variance: 0.2644535005092621\n",
      "Train size: [400] hidden size: [156] trial: 43, train_loss: 1.390409, test loss: 1.028075, bias2: 0.7634912729263306, variance: 0.26458415389060974\n",
      "Train size: [400] hidden size: [156] trial: 44, train_loss: 1.388827, test loss: 1.028446, bias2: 0.7635141611099243, variance: 0.2649320065975189\n",
      "Train size: [400] hidden size: [156] trial: 45, train_loss: 1.388424, test loss: 1.028354, bias2: 0.7625526785850525, variance: 0.2658018469810486\n",
      "Train size: [400] hidden size: [156] trial: 46, train_loss: 1.387863, test loss: 1.028033, bias2: 0.7627180814743042, variance: 0.2653147280216217\n",
      "Train size: [400] hidden size: [156] trial: 47, train_loss: 1.388184, test loss: 1.028892, bias2: 0.7623589634895325, variance: 0.2665325999259949\n",
      "Train size: [400] hidden size: [156] trial: 48, train_loss: 1.387652, test loss: 1.028928, bias2: 0.762258768081665, variance: 0.2666691243648529\n",
      "Train size: [400] hidden size: [156] trial: 49, train_loss: 1.387239, test loss: 1.028542, bias2: 0.7622673511505127, variance: 0.2662747800350189\n",
      "##################################################\n",
      "Train size: [400] hidden size: [180] trial: 0, train_loss: 1.076920, test loss: 0.977803, bias2: 0.9778029322624207, variance: 7.785095901269301e-10\n",
      "Train size: [400] hidden size: [180] trial: 1, train_loss: 1.241165, test loss: 1.014620, bias2: 0.8511917591094971, variance: 0.16342797875404358\n",
      "Train size: [400] hidden size: [180] trial: 2, train_loss: 1.236663, test loss: 1.032637, bias2: 0.8134209513664246, variance: 0.21921654045581818\n",
      "Train size: [400] hidden size: [180] trial: 3, train_loss: 1.239909, test loss: 1.018672, bias2: 0.7784700393676758, variance: 0.2402021735906601\n",
      "Train size: [400] hidden size: [180] trial: 4, train_loss: 1.261862, test loss: 1.013232, bias2: 0.758699893951416, variance: 0.2545325756072998\n",
      "Train size: [400] hidden size: [180] trial: 5, train_loss: 1.258714, test loss: 1.022654, bias2: 0.7439374923706055, variance: 0.27871689200401306\n",
      "Train size: [400] hidden size: [180] trial: 6, train_loss: 1.244077, test loss: 1.019691, bias2: 0.7368168234825134, variance: 0.2828744053840637\n",
      "Train size: [400] hidden size: [180] trial: 7, train_loss: 1.233946, test loss: 1.024549, bias2: 0.7341047525405884, variance: 0.2904437780380249\n",
      "Train size: [400] hidden size: [180] trial: 8, train_loss: 1.239841, test loss: 1.022415, bias2: 0.7339123487472534, variance: 0.28850269317626953\n",
      "Train size: [400] hidden size: [180] trial: 9, train_loss: 1.249984, test loss: 1.012577, bias2: 0.726746678352356, variance: 0.2858307361602783\n",
      "Train size: [400] hidden size: [180] trial: 10, train_loss: 1.241755, test loss: 1.004055, bias2: 0.7219149470329285, variance: 0.28214019536972046\n",
      "Train size: [400] hidden size: [180] trial: 11, train_loss: 1.240780, test loss: 1.004601, bias2: 0.7225773930549622, variance: 0.28202348947525024\n",
      "Train size: [400] hidden size: [180] trial: 12, train_loss: 1.243985, test loss: 1.012116, bias2: 0.7284360527992249, variance: 0.2836797833442688\n",
      "Train size: [400] hidden size: [180] trial: 13, train_loss: 1.257502, test loss: 1.014163, bias2: 0.7292469143867493, variance: 0.28491657972335815\n",
      "Train size: [400] hidden size: [180] trial: 14, train_loss: 1.268618, test loss: 1.015688, bias2: 0.7304199934005737, variance: 0.2852684557437897\n",
      "Train size: [400] hidden size: [180] trial: 15, train_loss: 1.275078, test loss: 1.011998, bias2: 0.726223886013031, variance: 0.28577369451522827\n",
      "Train size: [400] hidden size: [180] trial: 16, train_loss: 1.273368, test loss: 1.014348, bias2: 0.7266206741333008, variance: 0.2877274751663208\n",
      "Train size: [400] hidden size: [180] trial: 17, train_loss: 1.278124, test loss: 1.015377, bias2: 0.7241032123565674, variance: 0.2912733554840088\n",
      "Train size: [400] hidden size: [180] trial: 18, train_loss: 1.275059, test loss: 1.019178, bias2: 0.7273054122924805, variance: 0.2918722629547119\n",
      "Train size: [400] hidden size: [180] trial: 19, train_loss: 1.266546, test loss: 1.022240, bias2: 0.7280450463294983, variance: 0.29419511556625366\n",
      "Train size: [400] hidden size: [180] trial: 20, train_loss: 1.261262, test loss: 1.020093, bias2: 0.7265169620513916, variance: 0.29357588291168213\n",
      "Train size: [400] hidden size: [180] trial: 21, train_loss: 1.262153, test loss: 1.015747, bias2: 0.7241532206535339, variance: 0.29159384965896606\n",
      "Train size: [400] hidden size: [180] trial: 22, train_loss: 1.268038, test loss: 1.017611, bias2: 0.7229273319244385, variance: 0.2946838140487671\n",
      "Train size: [400] hidden size: [180] trial: 23, train_loss: 1.264207, test loss: 1.019496, bias2: 0.7207807302474976, variance: 0.2987149953842163\n",
      "Train size: [400] hidden size: [180] trial: 24, train_loss: 1.264158, test loss: 1.020639, bias2: 0.7213962078094482, variance: 0.29924288392066956\n",
      "Train size: [400] hidden size: [180] trial: 25, train_loss: 1.264311, test loss: 1.020940, bias2: 0.722338080406189, variance: 0.29860201478004456\n",
      "Train size: [400] hidden size: [180] trial: 26, train_loss: 1.270140, test loss: 1.021859, bias2: 0.7229610085487366, variance: 0.29889851808547974\n",
      "Train size: [400] hidden size: [180] trial: 27, train_loss: 1.271943, test loss: 1.020871, bias2: 0.7249448299407959, variance: 0.2959260046482086\n",
      "Train size: [400] hidden size: [180] trial: 28, train_loss: 1.270046, test loss: 1.021129, bias2: 0.7249401807785034, variance: 0.2961888015270233\n",
      "Train size: [400] hidden size: [180] trial: 29, train_loss: 1.277652, test loss: 1.023578, bias2: 0.7274577021598816, variance: 0.29612070322036743\n",
      "Train size: [400] hidden size: [180] trial: 30, train_loss: 1.277392, test loss: 1.024851, bias2: 0.7290546894073486, variance: 0.29579678177833557\n",
      "Train size: [400] hidden size: [180] trial: 31, train_loss: 1.279145, test loss: 1.026224, bias2: 0.7306708693504333, variance: 0.2955532670021057\n",
      "Train size: [400] hidden size: [180] trial: 32, train_loss: 1.282696, test loss: 1.025633, bias2: 0.7318247556686401, variance: 0.2938086688518524\n",
      "Train size: [400] hidden size: [180] trial: 33, train_loss: 1.279173, test loss: 1.025932, bias2: 0.7326302528381348, variance: 0.2933017313480377\n",
      "Train size: [400] hidden size: [180] trial: 34, train_loss: 1.275756, test loss: 1.025094, bias2: 0.7326562404632568, variance: 0.2924377918243408\n",
      "Train size: [400] hidden size: [180] trial: 35, train_loss: 1.275755, test loss: 1.026632, bias2: 0.7320860624313354, variance: 0.2945460379123688\n",
      "Train size: [400] hidden size: [180] trial: 36, train_loss: 1.273944, test loss: 1.027562, bias2: 0.7332421541213989, variance: 0.29431965947151184\n",
      "Train size: [400] hidden size: [180] trial: 37, train_loss: 1.273679, test loss: 1.028982, bias2: 0.7340966463088989, variance: 0.29488539695739746\n",
      "Train size: [400] hidden size: [180] trial: 38, train_loss: 1.277360, test loss: 1.030021, bias2: 0.734277606010437, variance: 0.295743852853775\n",
      "Train size: [400] hidden size: [180] trial: 39, train_loss: 1.277340, test loss: 1.028354, bias2: 0.733108401298523, variance: 0.29524585604667664\n",
      "Train size: [400] hidden size: [180] trial: 40, train_loss: 1.279042, test loss: 1.028427, bias2: 0.7336137890815735, variance: 0.294813334941864\n",
      "Train size: [400] hidden size: [180] trial: 41, train_loss: 1.280034, test loss: 1.029551, bias2: 0.7316805720329285, variance: 0.29787081480026245\n",
      "Train size: [400] hidden size: [180] trial: 42, train_loss: 1.277609, test loss: 1.028302, bias2: 0.730463445186615, variance: 0.2978389859199524\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [180] trial: 43, train_loss: 1.278752, test loss: 1.028297, bias2: 0.7300477623939514, variance: 0.2982495427131653\n",
      "Train size: [400] hidden size: [180] trial: 44, train_loss: 1.277787, test loss: 1.028025, bias2: 0.7297415137290955, variance: 0.29828399419784546\n",
      "Train size: [400] hidden size: [180] trial: 45, train_loss: 1.275803, test loss: 1.027612, bias2: 0.7290486097335815, variance: 0.2985636293888092\n",
      "Train size: [400] hidden size: [180] trial: 46, train_loss: 1.276444, test loss: 1.027978, bias2: 0.7289865612983704, variance: 0.29899126291275024\n",
      "Train size: [400] hidden size: [180] trial: 47, train_loss: 1.276975, test loss: 1.027281, bias2: 0.7288104295730591, variance: 0.29847097396850586\n",
      "Train size: [400] hidden size: [180] trial: 48, train_loss: 1.277643, test loss: 1.029617, bias2: 0.7310903668403625, variance: 0.29852694272994995\n",
      "Train size: [400] hidden size: [180] trial: 49, train_loss: 1.279063, test loss: 1.031064, bias2: 0.7321776151657104, variance: 0.2988865077495575\n",
      "##################################################\n",
      "Train size: [400] hidden size: [207] trial: 0, train_loss: 1.167787, test loss: 1.052451, bias2: 1.052451252937317, variance: -3.8925479506346505e-10\n",
      "Train size: [400] hidden size: [207] trial: 1, train_loss: 1.267636, test loss: 1.056560, bias2: 0.8917179703712463, variance: 0.164842426776886\n",
      "Train size: [400] hidden size: [207] trial: 2, train_loss: 1.213860, test loss: 1.068175, bias2: 0.8412433862686157, variance: 0.22693189978599548\n",
      "Train size: [400] hidden size: [207] trial: 3, train_loss: 1.221356, test loss: 1.071577, bias2: 0.8126286864280701, variance: 0.25894874334335327\n",
      "Train size: [400] hidden size: [207] trial: 4, train_loss: 1.262682, test loss: 1.074759, bias2: 0.7946813106536865, variance: 0.28007733821868896\n",
      "Train size: [400] hidden size: [207] trial: 5, train_loss: 1.278331, test loss: 1.068415, bias2: 0.7835298776626587, variance: 0.28488507866859436\n",
      "Train size: [400] hidden size: [207] trial: 6, train_loss: 1.239046, test loss: 1.057978, bias2: 0.7690449953079224, variance: 0.28893259167671204\n",
      "Train size: [400] hidden size: [207] trial: 7, train_loss: 1.224375, test loss: 1.052313, bias2: 0.7580479979515076, variance: 0.2942654490470886\n",
      "Train size: [400] hidden size: [207] trial: 8, train_loss: 1.236661, test loss: 1.058752, bias2: 0.7519700527191162, variance: 0.3067823350429535\n",
      "Train size: [400] hidden size: [207] trial: 9, train_loss: 1.236227, test loss: 1.057231, bias2: 0.7471354007720947, variance: 0.3100953996181488\n",
      "Train size: [400] hidden size: [207] trial: 10, train_loss: 1.231185, test loss: 1.053782, bias2: 0.7410829067230225, variance: 0.31269893050193787\n",
      "Train size: [400] hidden size: [207] trial: 11, train_loss: 1.235473, test loss: 1.049658, bias2: 0.7409088611602783, variance: 0.30874860286712646\n",
      "Train size: [400] hidden size: [207] trial: 12, train_loss: 1.230415, test loss: 1.050441, bias2: 0.7384127378463745, variance: 0.3120279014110565\n",
      "Train size: [400] hidden size: [207] trial: 13, train_loss: 1.232819, test loss: 1.042488, bias2: 0.7337145209312439, variance: 0.30877333879470825\n",
      "Train size: [400] hidden size: [207] trial: 14, train_loss: 1.227667, test loss: 1.042177, bias2: 0.7360747456550598, variance: 0.30610185861587524\n",
      "Train size: [400] hidden size: [207] trial: 15, train_loss: 1.232691, test loss: 1.041449, bias2: 0.7283238768577576, variance: 0.3131254315376282\n",
      "Train size: [400] hidden size: [207] trial: 16, train_loss: 1.236341, test loss: 1.045708, bias2: 0.7283902168273926, variance: 0.3173178434371948\n",
      "Train size: [400] hidden size: [207] trial: 17, train_loss: 1.239265, test loss: 1.047745, bias2: 0.7233168482780457, variance: 0.32442861795425415\n",
      "Train size: [400] hidden size: [207] trial: 18, train_loss: 1.227801, test loss: 1.048724, bias2: 0.7227903604507446, variance: 0.3259335458278656\n",
      "Train size: [400] hidden size: [207] trial: 19, train_loss: 1.222801, test loss: 1.047265, bias2: 0.7233123779296875, variance: 0.3239530324935913\n",
      "Train size: [400] hidden size: [207] trial: 20, train_loss: 1.221391, test loss: 1.049885, bias2: 0.724459171295166, variance: 0.3254255950450897\n",
      "Train size: [400] hidden size: [207] trial: 21, train_loss: 1.215176, test loss: 1.047220, bias2: 0.7218756675720215, variance: 0.3253444731235504\n",
      "Train size: [400] hidden size: [207] trial: 22, train_loss: 1.215838, test loss: 1.045536, bias2: 0.7198678851127625, variance: 0.3256680369377136\n",
      "Train size: [400] hidden size: [207] trial: 23, train_loss: 1.214723, test loss: 1.045492, bias2: 0.7203947305679321, variance: 0.32509681582450867\n",
      "Train size: [400] hidden size: [207] trial: 24, train_loss: 1.216678, test loss: 1.045183, bias2: 0.7197794318199158, variance: 0.32540351152420044\n",
      "Train size: [400] hidden size: [207] trial: 25, train_loss: 1.210065, test loss: 1.046001, bias2: 0.7192971706390381, variance: 0.32670387625694275\n",
      "Train size: [400] hidden size: [207] trial: 26, train_loss: 1.207219, test loss: 1.044177, bias2: 0.718859851360321, variance: 0.3253169655799866\n",
      "Train size: [400] hidden size: [207] trial: 27, train_loss: 1.202460, test loss: 1.045082, bias2: 0.7173329591751099, variance: 0.3277488648891449\n",
      "Train size: [400] hidden size: [207] trial: 28, train_loss: 1.203863, test loss: 1.043718, bias2: 0.7146627902984619, variance: 0.3290553092956543\n",
      "Train size: [400] hidden size: [207] trial: 29, train_loss: 1.198669, test loss: 1.043771, bias2: 0.7139659523963928, variance: 0.3298047184944153\n",
      "Train size: [400] hidden size: [207] trial: 30, train_loss: 1.192342, test loss: 1.043399, bias2: 0.7144579887390137, variance: 0.32894137501716614\n",
      "Train size: [400] hidden size: [207] trial: 31, train_loss: 1.187427, test loss: 1.041568, bias2: 0.7119598984718323, variance: 0.3296082615852356\n",
      "Train size: [400] hidden size: [207] trial: 32, train_loss: 1.191011, test loss: 1.042175, bias2: 0.7135263085365295, variance: 0.3286486268043518\n",
      "Train size: [400] hidden size: [207] trial: 33, train_loss: 1.189003, test loss: 1.040409, bias2: 0.7130732536315918, variance: 0.3273358643054962\n",
      "Train size: [400] hidden size: [207] trial: 34, train_loss: 1.186985, test loss: 1.041740, bias2: 0.7133110165596008, variance: 0.3284289240837097\n",
      "Train size: [400] hidden size: [207] trial: 35, train_loss: 1.189616, test loss: 1.042236, bias2: 0.7109252214431763, variance: 0.3313112258911133\n",
      "Train size: [400] hidden size: [207] trial: 36, train_loss: 1.189949, test loss: 1.041950, bias2: 0.7104414105415344, variance: 0.3315085768699646\n",
      "Train size: [400] hidden size: [207] trial: 37, train_loss: 1.188820, test loss: 1.039968, bias2: 0.7087266445159912, variance: 0.3312417268753052\n",
      "Train size: [400] hidden size: [207] trial: 38, train_loss: 1.191197, test loss: 1.037576, bias2: 0.7047147750854492, variance: 0.3328615128993988\n",
      "Train size: [400] hidden size: [207] trial: 39, train_loss: 1.189483, test loss: 1.037016, bias2: 0.7043592929840088, variance: 0.33265653252601624\n",
      "Train size: [400] hidden size: [207] trial: 40, train_loss: 1.189386, test loss: 1.036875, bias2: 0.7040668725967407, variance: 0.33280766010284424\n",
      "Train size: [400] hidden size: [207] trial: 41, train_loss: 1.192323, test loss: 1.035063, bias2: 0.7022985219955444, variance: 0.3327641189098358\n",
      "Train size: [400] hidden size: [207] trial: 42, train_loss: 1.190507, test loss: 1.033899, bias2: 0.7004431486129761, variance: 0.3334555923938751\n",
      "Train size: [400] hidden size: [207] trial: 43, train_loss: 1.189532, test loss: 1.034435, bias2: 0.7006105184555054, variance: 0.3338242769241333\n",
      "Train size: [400] hidden size: [207] trial: 44, train_loss: 1.190279, test loss: 1.034836, bias2: 0.7011160850524902, variance: 0.33371976017951965\n",
      "Train size: [400] hidden size: [207] trial: 45, train_loss: 1.186274, test loss: 1.034788, bias2: 0.7000454664230347, variance: 0.3347420394420624\n",
      "Train size: [400] hidden size: [207] trial: 46, train_loss: 1.186482, test loss: 1.035541, bias2: 0.7018731832504272, variance: 0.33366790413856506\n",
      "Train size: [400] hidden size: [207] trial: 47, train_loss: 1.187971, test loss: 1.035400, bias2: 0.7024717330932617, variance: 0.33292874693870544\n",
      "Train size: [400] hidden size: [207] trial: 48, train_loss: 1.184909, test loss: 1.035630, bias2: 0.7021869421005249, variance: 0.33344292640686035\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [207] trial: 49, train_loss: 1.186754, test loss: 1.036116, bias2: 0.7034380435943604, variance: 0.33267757296562195\n",
      "##################################################\n",
      "Train size: [400] hidden size: [239] trial: 0, train_loss: 0.883688, test loss: 0.992201, bias2: 0.9922007918357849, variance: 2.724783731977709e-09\n",
      "Train size: [400] hidden size: [239] trial: 1, train_loss: 0.981769, test loss: 1.055809, bias2: 0.8600282669067383, variance: 0.19578027725219727\n",
      "Train size: [400] hidden size: [239] trial: 2, train_loss: 1.027156, test loss: 1.062963, bias2: 0.813934862613678, variance: 0.2490280270576477\n",
      "Train size: [400] hidden size: [239] trial: 3, train_loss: 1.055059, test loss: 1.052233, bias2: 0.7821205258369446, variance: 0.2701123356819153\n",
      "Train size: [400] hidden size: [239] trial: 4, train_loss: 1.068212, test loss: 1.079115, bias2: 0.7895178198814392, variance: 0.28959745168685913\n",
      "Train size: [400] hidden size: [239] trial: 5, train_loss: 1.075184, test loss: 1.056060, bias2: 0.7562696933746338, variance: 0.29979076981544495\n",
      "Train size: [400] hidden size: [239] trial: 6, train_loss: 1.097551, test loss: 1.053562, bias2: 0.7479194402694702, variance: 0.3056429922580719\n",
      "Train size: [400] hidden size: [239] trial: 7, train_loss: 1.120362, test loss: 1.054444, bias2: 0.7380356788635254, variance: 0.31640851497650146\n",
      "Train size: [400] hidden size: [239] trial: 8, train_loss: 1.113826, test loss: 1.046824, bias2: 0.7259265780448914, variance: 0.32089728116989136\n",
      "Train size: [400] hidden size: [239] trial: 9, train_loss: 1.114741, test loss: 1.054833, bias2: 0.7212249040603638, variance: 0.3336080014705658\n",
      "Train size: [400] hidden size: [239] trial: 10, train_loss: 1.098383, test loss: 1.056570, bias2: 0.7188630104064941, variance: 0.33770695328712463\n",
      "Train size: [400] hidden size: [239] trial: 11, train_loss: 1.097846, test loss: 1.056530, bias2: 0.7164803743362427, variance: 0.34004947543144226\n",
      "Train size: [400] hidden size: [239] trial: 12, train_loss: 1.103194, test loss: 1.060127, bias2: 0.7199159860610962, variance: 0.3402111530303955\n",
      "Train size: [400] hidden size: [239] trial: 13, train_loss: 1.095646, test loss: 1.055177, bias2: 0.7171635627746582, variance: 0.33801376819610596\n",
      "Train size: [400] hidden size: [239] trial: 14, train_loss: 1.104199, test loss: 1.065265, bias2: 0.7226118445396423, variance: 0.34265345335006714\n",
      "Train size: [400] hidden size: [239] trial: 15, train_loss: 1.111830, test loss: 1.067433, bias2: 0.7194739580154419, variance: 0.3479595184326172\n",
      "Train size: [400] hidden size: [239] trial: 16, train_loss: 1.106072, test loss: 1.064306, bias2: 0.7158461809158325, variance: 0.34845975041389465\n",
      "Train size: [400] hidden size: [239] trial: 17, train_loss: 1.099963, test loss: 1.063721, bias2: 0.7104630470275879, variance: 0.3532577455043793\n",
      "Train size: [400] hidden size: [239] trial: 18, train_loss: 1.095248, test loss: 1.060071, bias2: 0.7035398483276367, variance: 0.3565309941768646\n",
      "Train size: [400] hidden size: [239] trial: 19, train_loss: 1.096393, test loss: 1.061499, bias2: 0.7027863264083862, variance: 0.3587130606174469\n",
      "Train size: [400] hidden size: [239] trial: 20, train_loss: 1.093871, test loss: 1.063033, bias2: 0.7021363973617554, variance: 0.36089667677879333\n",
      "Train size: [400] hidden size: [239] trial: 21, train_loss: 1.091195, test loss: 1.061160, bias2: 0.7003709077835083, variance: 0.36078938841819763\n",
      "Train size: [400] hidden size: [239] trial: 22, train_loss: 1.094060, test loss: 1.061022, bias2: 0.6984049081802368, variance: 0.3626171350479126\n",
      "Train size: [400] hidden size: [239] trial: 23, train_loss: 1.100854, test loss: 1.062224, bias2: 0.6998051404953003, variance: 0.36241841316223145\n",
      "Train size: [400] hidden size: [239] trial: 24, train_loss: 1.100376, test loss: 1.065531, bias2: 0.7012555003166199, variance: 0.36427515745162964\n",
      "Train size: [400] hidden size: [239] trial: 25, train_loss: 1.104807, test loss: 1.064765, bias2: 0.6987816095352173, variance: 0.3659832179546356\n",
      "Train size: [400] hidden size: [239] trial: 26, train_loss: 1.101706, test loss: 1.062892, bias2: 0.6965737342834473, variance: 0.366318017244339\n",
      "Train size: [400] hidden size: [239] trial: 27, train_loss: 1.104355, test loss: 1.062586, bias2: 0.6943264007568359, variance: 0.36825987696647644\n",
      "Train size: [400] hidden size: [239] trial: 28, train_loss: 1.108390, test loss: 1.060203, bias2: 0.6918736696243286, variance: 0.36832940578460693\n",
      "Train size: [400] hidden size: [239] trial: 29, train_loss: 1.110598, test loss: 1.057321, bias2: 0.688962459564209, variance: 0.3683582842350006\n",
      "Train size: [400] hidden size: [239] trial: 30, train_loss: 1.109076, test loss: 1.054352, bias2: 0.6857433915138245, variance: 0.3686085343360901\n",
      "Train size: [400] hidden size: [239] trial: 31, train_loss: 1.114136, test loss: 1.053042, bias2: 0.6848719120025635, variance: 0.36816954612731934\n",
      "Train size: [400] hidden size: [239] trial: 32, train_loss: 1.106878, test loss: 1.053867, bias2: 0.6875247955322266, variance: 0.3663426637649536\n",
      "Train size: [400] hidden size: [239] trial: 33, train_loss: 1.106340, test loss: 1.052332, bias2: 0.6890991926193237, variance: 0.36323273181915283\n",
      "Train size: [400] hidden size: [239] trial: 34, train_loss: 1.107438, test loss: 1.052886, bias2: 0.6880886554718018, variance: 0.36479711532592773\n",
      "Train size: [400] hidden size: [239] trial: 35, train_loss: 1.107403, test loss: 1.051898, bias2: 0.6865108013153076, variance: 0.3653866946697235\n",
      "Train size: [400] hidden size: [239] trial: 36, train_loss: 1.107227, test loss: 1.051690, bias2: 0.6860365867614746, variance: 0.3656534254550934\n",
      "Train size: [400] hidden size: [239] trial: 37, train_loss: 1.108738, test loss: 1.052918, bias2: 0.6862488985061646, variance: 0.36666855216026306\n",
      "Train size: [400] hidden size: [239] trial: 38, train_loss: 1.110099, test loss: 1.051104, bias2: 0.686705470085144, variance: 0.3643984794616699\n",
      "Train size: [400] hidden size: [239] trial: 39, train_loss: 1.109421, test loss: 1.053338, bias2: 0.6885879039764404, variance: 0.3647497892379761\n",
      "Train size: [400] hidden size: [239] trial: 40, train_loss: 1.112519, test loss: 1.053590, bias2: 0.6887931823730469, variance: 0.3647972643375397\n",
      "Train size: [400] hidden size: [239] trial: 41, train_loss: 1.112773, test loss: 1.054829, bias2: 0.6905391216278076, variance: 0.364289790391922\n",
      "Train size: [400] hidden size: [239] trial: 42, train_loss: 1.115460, test loss: 1.054536, bias2: 0.6914970874786377, variance: 0.3630385100841522\n",
      "Train size: [400] hidden size: [239] trial: 43, train_loss: 1.116407, test loss: 1.054824, bias2: 0.6906708478927612, variance: 0.36415329575538635\n",
      "Train size: [400] hidden size: [239] trial: 44, train_loss: 1.113580, test loss: 1.054786, bias2: 0.6911107301712036, variance: 0.3636750876903534\n",
      "Train size: [400] hidden size: [239] trial: 45, train_loss: 1.113990, test loss: 1.054360, bias2: 0.6892648935317993, variance: 0.3650952875614166\n",
      "Train size: [400] hidden size: [239] trial: 46, train_loss: 1.112426, test loss: 1.053423, bias2: 0.6888747215270996, variance: 0.36454811692237854\n",
      "Train size: [400] hidden size: [239] trial: 47, train_loss: 1.111666, test loss: 1.052578, bias2: 0.6882697939872742, variance: 0.36430805921554565\n",
      "Train size: [400] hidden size: [239] trial: 48, train_loss: 1.110830, test loss: 1.050996, bias2: 0.686420202255249, variance: 0.3645760118961334\n",
      "Train size: [400] hidden size: [239] trial: 49, train_loss: 1.110899, test loss: 1.049100, bias2: 0.6849261522293091, variance: 0.3641737401485443\n",
      "##################################################\n",
      "Train size: [400] hidden size: [275] trial: 0, train_loss: 0.964439, test loss: 1.019878, bias2: 1.0198783874511719, variance: 2.3355288814030928e-09\n",
      "Train size: [400] hidden size: [275] trial: 1, train_loss: 0.998438, test loss: 1.058959, bias2: 0.8621596693992615, variance: 0.19679920375347137\n",
      "Train size: [400] hidden size: [275] trial: 2, train_loss: 1.011774, test loss: 1.058678, bias2: 0.7780786752700806, variance: 0.280599445104599\n",
      "Train size: [400] hidden size: [275] trial: 3, train_loss: 1.026046, test loss: 1.064353, bias2: 0.7469371557235718, variance: 0.3174159824848175\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [275] trial: 4, train_loss: 1.000940, test loss: 1.064253, bias2: 0.7310243844985962, variance: 0.333228200674057\n",
      "Train size: [400] hidden size: [275] trial: 5, train_loss: 1.023978, test loss: 1.092793, bias2: 0.7350202798843384, variance: 0.3577730655670166\n",
      "Train size: [400] hidden size: [275] trial: 6, train_loss: 1.028083, test loss: 1.073707, bias2: 0.7084489464759827, variance: 0.3652579188346863\n",
      "Train size: [400] hidden size: [275] trial: 7, train_loss: 1.030350, test loss: 1.078809, bias2: 0.7077350616455078, variance: 0.37107405066490173\n",
      "Train size: [400] hidden size: [275] trial: 8, train_loss: 1.027189, test loss: 1.074504, bias2: 0.7065573930740356, variance: 0.3679470717906952\n",
      "Train size: [400] hidden size: [275] trial: 9, train_loss: 1.014877, test loss: 1.071793, bias2: 0.6939167976379395, variance: 0.37787654995918274\n",
      "Train size: [400] hidden size: [275] trial: 10, train_loss: 1.005586, test loss: 1.076656, bias2: 0.6923176050186157, variance: 0.38433825969696045\n",
      "Train size: [400] hidden size: [275] trial: 11, train_loss: 1.012920, test loss: 1.073799, bias2: 0.6913992166519165, variance: 0.38239941000938416\n",
      "Train size: [400] hidden size: [275] trial: 12, train_loss: 1.000659, test loss: 1.071478, bias2: 0.687981128692627, variance: 0.383497029542923\n",
      "Train size: [400] hidden size: [275] trial: 13, train_loss: 1.001070, test loss: 1.072033, bias2: 0.6889851689338684, variance: 0.3830476403236389\n",
      "Train size: [400] hidden size: [275] trial: 14, train_loss: 1.016315, test loss: 1.069440, bias2: 0.6868249177932739, variance: 0.38261470198631287\n",
      "Train size: [400] hidden size: [275] trial: 15, train_loss: 1.015312, test loss: 1.071015, bias2: 0.6840013265609741, variance: 0.38701388239860535\n",
      "Train size: [400] hidden size: [275] trial: 16, train_loss: 1.017536, test loss: 1.070739, bias2: 0.6768467426300049, variance: 0.3938923180103302\n",
      "Train size: [400] hidden size: [275] trial: 17, train_loss: 1.018389, test loss: 1.071789, bias2: 0.6745867133140564, variance: 0.39720267057418823\n",
      "Train size: [400] hidden size: [275] trial: 18, train_loss: 1.018901, test loss: 1.065128, bias2: 0.6683381795883179, variance: 0.3967895805835724\n",
      "Train size: [400] hidden size: [275] trial: 19, train_loss: 1.020341, test loss: 1.065337, bias2: 0.666951060295105, variance: 0.3983863294124603\n",
      "Train size: [400] hidden size: [275] trial: 20, train_loss: 1.017257, test loss: 1.064244, bias2: 0.661092221736908, variance: 0.40315181016921997\n",
      "Train size: [400] hidden size: [275] trial: 21, train_loss: 1.017117, test loss: 1.063417, bias2: 0.6627839803695679, variance: 0.40063318610191345\n",
      "Train size: [400] hidden size: [275] trial: 22, train_loss: 1.013908, test loss: 1.058840, bias2: 0.6613353490829468, variance: 0.39750441908836365\n",
      "Train size: [400] hidden size: [275] trial: 23, train_loss: 1.021475, test loss: 1.061771, bias2: 0.6622496843338013, variance: 0.3995215594768524\n",
      "Train size: [400] hidden size: [275] trial: 24, train_loss: 1.017357, test loss: 1.058989, bias2: 0.6594916582107544, variance: 0.3994978666305542\n",
      "Train size: [400] hidden size: [275] trial: 25, train_loss: 1.020765, test loss: 1.055322, bias2: 0.6556943655014038, variance: 0.3996281325817108\n",
      "Train size: [400] hidden size: [275] trial: 26, train_loss: 1.018654, test loss: 1.055931, bias2: 0.6557645797729492, variance: 0.40016600489616394\n",
      "Train size: [400] hidden size: [275] trial: 27, train_loss: 1.018639, test loss: 1.053897, bias2: 0.6541156768798828, variance: 0.399781733751297\n",
      "Train size: [400] hidden size: [275] trial: 28, train_loss: 1.014907, test loss: 1.052147, bias2: 0.6507265567779541, variance: 0.40142011642456055\n",
      "Train size: [400] hidden size: [275] trial: 29, train_loss: 1.020000, test loss: 1.051523, bias2: 0.6503432989120483, variance: 0.401179701089859\n",
      "Train size: [400] hidden size: [275] trial: 30, train_loss: 1.021836, test loss: 1.052620, bias2: 0.6504992842674255, variance: 0.40212100744247437\n",
      "Train size: [400] hidden size: [275] trial: 31, train_loss: 1.024407, test loss: 1.052342, bias2: 0.6489189863204956, variance: 0.4034230709075928\n",
      "Train size: [400] hidden size: [275] trial: 32, train_loss: 1.025215, test loss: 1.053525, bias2: 0.6481163501739502, variance: 0.4054085314273834\n",
      "Train size: [400] hidden size: [275] trial: 33, train_loss: 1.022011, test loss: 1.053981, bias2: 0.6482071876525879, variance: 0.4057735502719879\n",
      "Train size: [400] hidden size: [275] trial: 34, train_loss: 1.021637, test loss: 1.053294, bias2: 0.6475602984428406, variance: 0.4057338833808899\n",
      "Train size: [400] hidden size: [275] trial: 35, train_loss: 1.021611, test loss: 1.051196, bias2: 0.6455198526382446, variance: 0.4056761562824249\n",
      "Train size: [400] hidden size: [275] trial: 36, train_loss: 1.020421, test loss: 1.053875, bias2: 0.6464381217956543, variance: 0.4074367582798004\n",
      "Train size: [400] hidden size: [275] trial: 37, train_loss: 1.021815, test loss: 1.056169, bias2: 0.6468976736068726, variance: 0.4092709720134735\n",
      "Train size: [400] hidden size: [275] trial: 38, train_loss: 1.025817, test loss: 1.053424, bias2: 0.6447024345397949, variance: 0.40872180461883545\n",
      "Train size: [400] hidden size: [275] trial: 39, train_loss: 1.026681, test loss: 1.054836, bias2: 0.644744873046875, variance: 0.410090833902359\n",
      "Train size: [400] hidden size: [275] trial: 40, train_loss: 1.024548, test loss: 1.055564, bias2: 0.6445568203926086, variance: 0.41100698709487915\n",
      "Train size: [400] hidden size: [275] trial: 41, train_loss: 1.025317, test loss: 1.055705, bias2: 0.6423782110214233, variance: 0.41332706809043884\n",
      "Train size: [400] hidden size: [275] trial: 42, train_loss: 1.022741, test loss: 1.055185, bias2: 0.6428819894790649, variance: 0.41230320930480957\n",
      "Train size: [400] hidden size: [275] trial: 43, train_loss: 1.023544, test loss: 1.054961, bias2: 0.6419590711593628, variance: 0.4130016565322876\n",
      "Train size: [400] hidden size: [275] trial: 44, train_loss: 1.022253, test loss: 1.053849, bias2: 0.6406528949737549, variance: 0.4131965637207031\n",
      "Train size: [400] hidden size: [275] trial: 45, train_loss: 1.018339, test loss: 1.053562, bias2: 0.6379856467247009, variance: 0.4155767560005188\n",
      "Train size: [400] hidden size: [275] trial: 46, train_loss: 1.017814, test loss: 1.053399, bias2: 0.6385588645935059, variance: 0.41484060883522034\n",
      "Train size: [400] hidden size: [275] trial: 47, train_loss: 1.017318, test loss: 1.052635, bias2: 0.6389327049255371, variance: 0.4137023389339447\n",
      "Train size: [400] hidden size: [275] trial: 48, train_loss: 1.017180, test loss: 1.052792, bias2: 0.6398000717163086, variance: 0.41299203038215637\n",
      "Train size: [400] hidden size: [275] trial: 49, train_loss: 1.018725, test loss: 1.053244, bias2: 0.6401827335357666, variance: 0.4130607545375824\n",
      "##################################################\n",
      "Train size: [400] hidden size: [316] trial: 0, train_loss: 1.002881, test loss: 1.037895, bias2: 1.037894606590271, variance: 4.281802912231569e-09\n",
      "Train size: [400] hidden size: [316] trial: 1, train_loss: 0.935459, test loss: 1.098770, bias2: 0.8349283933639526, variance: 0.2638412415981293\n",
      "Train size: [400] hidden size: [316] trial: 2, train_loss: 0.957383, test loss: 1.097548, bias2: 0.7390767335891724, variance: 0.3584713041782379\n",
      "Train size: [400] hidden size: [316] trial: 3, train_loss: 0.936190, test loss: 1.081624, bias2: 0.6962994337081909, variance: 0.3853248655796051\n",
      "Train size: [400] hidden size: [316] trial: 4, train_loss: 0.964357, test loss: 1.077683, bias2: 0.6738972067832947, variance: 0.40378624200820923\n",
      "Train size: [400] hidden size: [316] trial: 5, train_loss: 0.964620, test loss: 1.065461, bias2: 0.6690436601638794, variance: 0.3964172899723053\n",
      "Train size: [400] hidden size: [316] trial: 6, train_loss: 0.969214, test loss: 1.066146, bias2: 0.6731542348861694, variance: 0.39299193024635315\n",
      "Train size: [400] hidden size: [316] trial: 7, train_loss: 0.959017, test loss: 1.066047, bias2: 0.6697000861167908, variance: 0.3963471055030823\n",
      "Train size: [400] hidden size: [316] trial: 8, train_loss: 0.955095, test loss: 1.064920, bias2: 0.6614574790000916, variance: 0.4034622311592102\n",
      "Train size: [400] hidden size: [316] trial: 9, train_loss: 0.946401, test loss: 1.063117, bias2: 0.6536154747009277, variance: 0.4095015525817871\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [316] trial: 10, train_loss: 0.938674, test loss: 1.057835, bias2: 0.6463170647621155, variance: 0.4115181565284729\n",
      "Train size: [400] hidden size: [316] trial: 11, train_loss: 0.936283, test loss: 1.056240, bias2: 0.64787757396698, variance: 0.40836262702941895\n",
      "Train size: [400] hidden size: [316] trial: 12, train_loss: 0.941195, test loss: 1.059006, bias2: 0.6489049196243286, variance: 0.4101013243198395\n",
      "Train size: [400] hidden size: [316] trial: 13, train_loss: 0.933179, test loss: 1.058463, bias2: 0.6450061798095703, variance: 0.4134570062160492\n",
      "Train size: [400] hidden size: [316] trial: 14, train_loss: 0.934673, test loss: 1.059773, bias2: 0.641028881072998, variance: 0.41874420642852783\n",
      "Train size: [400] hidden size: [316] trial: 15, train_loss: 0.929959, test loss: 1.063742, bias2: 0.6430743932723999, variance: 0.4206681549549103\n",
      "Train size: [400] hidden size: [316] trial: 16, train_loss: 0.926496, test loss: 1.064831, bias2: 0.6444751620292664, variance: 0.42035549879074097\n",
      "Train size: [400] hidden size: [316] trial: 17, train_loss: 0.926190, test loss: 1.061978, bias2: 0.6406558156013489, variance: 0.42132192850112915\n",
      "Train size: [400] hidden size: [316] trial: 18, train_loss: 0.923436, test loss: 1.061486, bias2: 0.6362472772598267, variance: 0.4252389371395111\n",
      "Train size: [400] hidden size: [316] trial: 19, train_loss: 0.930682, test loss: 1.067003, bias2: 0.6365143060684204, variance: 0.43048909306526184\n",
      "Train size: [400] hidden size: [316] trial: 20, train_loss: 0.925937, test loss: 1.067454, bias2: 0.6387471556663513, variance: 0.4287063479423523\n",
      "Train size: [400] hidden size: [316] trial: 21, train_loss: 0.925349, test loss: 1.068056, bias2: 0.6346169710159302, variance: 0.4334387481212616\n",
      "Train size: [400] hidden size: [316] trial: 22, train_loss: 0.931816, test loss: 1.064512, bias2: 0.6295676231384277, variance: 0.43494465947151184\n",
      "Train size: [400] hidden size: [316] trial: 23, train_loss: 0.928988, test loss: 1.063063, bias2: 0.6282780170440674, variance: 0.43478456139564514\n",
      "Train size: [400] hidden size: [316] trial: 24, train_loss: 0.923736, test loss: 1.065694, bias2: 0.630707323551178, variance: 0.4349868893623352\n",
      "Train size: [400] hidden size: [316] trial: 25, train_loss: 0.925748, test loss: 1.065802, bias2: 0.632104754447937, variance: 0.4336971938610077\n",
      "Train size: [400] hidden size: [316] trial: 26, train_loss: 0.929764, test loss: 1.064347, bias2: 0.628176212310791, variance: 0.4361708462238312\n",
      "Train size: [400] hidden size: [316] trial: 27, train_loss: 0.934460, test loss: 1.060715, bias2: 0.6258800029754639, variance: 0.43483495712280273\n",
      "Train size: [400] hidden size: [316] trial: 28, train_loss: 0.928790, test loss: 1.060645, bias2: 0.6273380517959595, variance: 0.4333072900772095\n",
      "Train size: [400] hidden size: [316] trial: 29, train_loss: 0.927276, test loss: 1.061298, bias2: 0.6261001825332642, variance: 0.4351973533630371\n",
      "Train size: [400] hidden size: [316] trial: 30, train_loss: 0.930070, test loss: 1.060028, bias2: 0.6262403726577759, variance: 0.4337875545024872\n",
      "Train size: [400] hidden size: [316] trial: 31, train_loss: 0.927809, test loss: 1.059753, bias2: 0.6260278224945068, variance: 0.43372491002082825\n",
      "Train size: [400] hidden size: [316] trial: 32, train_loss: 0.928149, test loss: 1.060300, bias2: 0.6252646446228027, variance: 0.43503543734550476\n",
      "Train size: [400] hidden size: [316] trial: 33, train_loss: 0.927909, test loss: 1.060367, bias2: 0.6238846778869629, variance: 0.436482310295105\n",
      "Train size: [400] hidden size: [316] trial: 34, train_loss: 0.929647, test loss: 1.060747, bias2: 0.6222455501556396, variance: 0.4385010004043579\n",
      "Train size: [400] hidden size: [316] trial: 35, train_loss: 0.926459, test loss: 1.059214, bias2: 0.6220565438270569, variance: 0.4371578097343445\n",
      "Train size: [400] hidden size: [316] trial: 36, train_loss: 0.925450, test loss: 1.058961, bias2: 0.6198999285697937, variance: 0.43906086683273315\n",
      "Train size: [400] hidden size: [316] trial: 37, train_loss: 0.924634, test loss: 1.059935, bias2: 0.6210264563560486, variance: 0.4389081597328186\n",
      "Train size: [400] hidden size: [316] trial: 38, train_loss: 0.924444, test loss: 1.057037, bias2: 0.6202548742294312, variance: 0.4367823898792267\n",
      "Train size: [400] hidden size: [316] trial: 39, train_loss: 0.924862, test loss: 1.057676, bias2: 0.6189274191856384, variance: 0.438748300075531\n",
      "Train size: [400] hidden size: [316] trial: 40, train_loss: 0.923324, test loss: 1.058280, bias2: 0.6204350590705872, variance: 0.43784505128860474\n",
      "Train size: [400] hidden size: [316] trial: 41, train_loss: 0.922860, test loss: 1.058385, bias2: 0.6194971799850464, variance: 0.4388880729675293\n",
      "Train size: [400] hidden size: [316] trial: 42, train_loss: 0.924552, test loss: 1.061572, bias2: 0.6201177835464478, variance: 0.4414536952972412\n",
      "Train size: [400] hidden size: [316] trial: 43, train_loss: 0.921723, test loss: 1.060446, bias2: 0.6198965311050415, variance: 0.44054946303367615\n",
      "Train size: [400] hidden size: [316] trial: 44, train_loss: 0.921163, test loss: 1.061203, bias2: 0.6196221113204956, variance: 0.441581130027771\n",
      "Train size: [400] hidden size: [316] trial: 45, train_loss: 0.923548, test loss: 1.061298, bias2: 0.6203905344009399, variance: 0.4409073293209076\n",
      "Train size: [400] hidden size: [316] trial: 46, train_loss: 0.921766, test loss: 1.060002, bias2: 0.6195453405380249, variance: 0.4404565095901489\n",
      "Train size: [400] hidden size: [316] trial: 47, train_loss: 0.924134, test loss: 1.060648, bias2: 0.6185745596885681, variance: 0.44207292795181274\n",
      "Train size: [400] hidden size: [316] trial: 48, train_loss: 0.925840, test loss: 1.060595, bias2: 0.6163606643676758, variance: 0.4442342519760132\n",
      "Train size: [400] hidden size: [316] trial: 49, train_loss: 0.925093, test loss: 1.059920, bias2: 0.6147768497467041, variance: 0.44514355063438416\n",
      "##################################################\n",
      "Train size: [400] hidden size: [364] trial: 0, train_loss: 0.884017, test loss: 1.144251, bias2: 1.1442513465881348, variance: 6.228076721015441e-09\n",
      "Train size: [400] hidden size: [364] trial: 1, train_loss: 0.875215, test loss: 1.143337, bias2: 0.880961537361145, variance: 0.2623756229877472\n",
      "Train size: [400] hidden size: [364] trial: 2, train_loss: 0.894857, test loss: 1.113877, bias2: 0.7575034499168396, variance: 0.35637325048446655\n",
      "Train size: [400] hidden size: [364] trial: 3, train_loss: 0.876146, test loss: 1.098616, bias2: 0.7015731930732727, variance: 0.3970431685447693\n",
      "Train size: [400] hidden size: [364] trial: 4, train_loss: 0.858321, test loss: 1.062715, bias2: 0.6572253704071045, variance: 0.40548989176750183\n",
      "Train size: [400] hidden size: [364] trial: 5, train_loss: 0.871609, test loss: 1.064206, bias2: 0.6484600901603699, variance: 0.41574591398239136\n",
      "Train size: [400] hidden size: [364] trial: 6, train_loss: 0.862422, test loss: 1.075014, bias2: 0.6258817911148071, variance: 0.4491325616836548\n",
      "Train size: [400] hidden size: [364] trial: 7, train_loss: 0.839520, test loss: 1.066789, bias2: 0.6166425943374634, variance: 0.45014676451683044\n",
      "Train size: [400] hidden size: [364] trial: 8, train_loss: 0.832224, test loss: 1.077842, bias2: 0.6099579334259033, variance: 0.46788379549980164\n",
      "Train size: [400] hidden size: [364] trial: 9, train_loss: 0.837168, test loss: 1.082570, bias2: 0.6060739755630493, variance: 0.47649598121643066\n",
      "Train size: [400] hidden size: [364] trial: 10, train_loss: 0.831176, test loss: 1.080608, bias2: 0.6073430776596069, variance: 0.4732649624347687\n",
      "Train size: [400] hidden size: [364] trial: 11, train_loss: 0.839714, test loss: 1.071040, bias2: 0.598263144493103, variance: 0.47277703881263733\n",
      "Train size: [400] hidden size: [364] trial: 12, train_loss: 0.842703, test loss: 1.072659, bias2: 0.5970531702041626, variance: 0.47560593485832214\n",
      "Train size: [400] hidden size: [364] trial: 13, train_loss: 0.847344, test loss: 1.075305, bias2: 0.5913167595863342, variance: 0.4839882254600525\n",
      "Train size: [400] hidden size: [364] trial: 14, train_loss: 0.849319, test loss: 1.074503, bias2: 0.5923705101013184, variance: 0.4821324050426483\n",
      "Train size: [400] hidden size: [364] trial: 15, train_loss: 0.852810, test loss: 1.076836, bias2: 0.592474102973938, variance: 0.4843623638153076\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [364] trial: 16, train_loss: 0.853785, test loss: 1.072297, bias2: 0.5864219665527344, variance: 0.48587486147880554\n",
      "Train size: [400] hidden size: [364] trial: 17, train_loss: 0.845765, test loss: 1.073960, bias2: 0.5856860876083374, variance: 0.4882742464542389\n",
      "Train size: [400] hidden size: [364] trial: 18, train_loss: 0.843974, test loss: 1.077309, bias2: 0.58539879322052, variance: 0.49191030859947205\n",
      "Train size: [400] hidden size: [364] trial: 19, train_loss: 0.839451, test loss: 1.074677, bias2: 0.5812023878097534, variance: 0.4934745132923126\n",
      "Train size: [400] hidden size: [364] trial: 20, train_loss: 0.839653, test loss: 1.072964, bias2: 0.5771636962890625, variance: 0.49580028653144836\n",
      "Train size: [400] hidden size: [364] trial: 21, train_loss: 0.836341, test loss: 1.069014, bias2: 0.5730940103530884, variance: 0.49592018127441406\n",
      "Train size: [400] hidden size: [364] trial: 22, train_loss: 0.836530, test loss: 1.070748, bias2: 0.5729936361312866, variance: 0.49775466322898865\n",
      "Train size: [400] hidden size: [364] trial: 23, train_loss: 0.838753, test loss: 1.070187, bias2: 0.5725076794624329, variance: 0.4976791739463806\n",
      "Train size: [400] hidden size: [364] trial: 24, train_loss: 0.838550, test loss: 1.066530, bias2: 0.5703691244125366, variance: 0.4961608946323395\n",
      "Train size: [400] hidden size: [364] trial: 25, train_loss: 0.840357, test loss: 1.063928, bias2: 0.5662105083465576, variance: 0.4977174699306488\n",
      "Train size: [400] hidden size: [364] trial: 26, train_loss: 0.835834, test loss: 1.061516, bias2: 0.5673832893371582, variance: 0.4941326379776001\n",
      "Train size: [400] hidden size: [364] trial: 27, train_loss: 0.841109, test loss: 1.062968, bias2: 0.5684159994125366, variance: 0.49455204606056213\n",
      "Train size: [400] hidden size: [364] trial: 28, train_loss: 0.840488, test loss: 1.059598, bias2: 0.5675758719444275, variance: 0.4920223355293274\n",
      "Train size: [400] hidden size: [364] trial: 29, train_loss: 0.834628, test loss: 1.056837, bias2: 0.5647881031036377, variance: 0.4920487701892853\n",
      "Train size: [400] hidden size: [364] trial: 30, train_loss: 0.831272, test loss: 1.056877, bias2: 0.5634920001029968, variance: 0.4933854937553406\n",
      "Train size: [400] hidden size: [364] trial: 31, train_loss: 0.831191, test loss: 1.060376, bias2: 0.5650100708007812, variance: 0.4953659772872925\n",
      "Train size: [400] hidden size: [364] trial: 32, train_loss: 0.831624, test loss: 1.061167, bias2: 0.5659224987030029, variance: 0.4952445328235626\n",
      "Train size: [400] hidden size: [364] trial: 33, train_loss: 0.831345, test loss: 1.060170, bias2: 0.5651869177818298, variance: 0.4949827790260315\n",
      "Train size: [400] hidden size: [364] trial: 34, train_loss: 0.829546, test loss: 1.059316, bias2: 0.5654796957969666, variance: 0.49383634328842163\n",
      "Train size: [400] hidden size: [364] trial: 35, train_loss: 0.827727, test loss: 1.058718, bias2: 0.5665243864059448, variance: 0.49219322204589844\n",
      "Train size: [400] hidden size: [364] trial: 36, train_loss: 0.826626, test loss: 1.059172, bias2: 0.5692558884620667, variance: 0.4899159073829651\n",
      "Train size: [400] hidden size: [364] trial: 37, train_loss: 0.824503, test loss: 1.059802, bias2: 0.5697361826896667, variance: 0.49006563425064087\n",
      "Train size: [400] hidden size: [364] trial: 38, train_loss: 0.822581, test loss: 1.057256, bias2: 0.5692344307899475, variance: 0.4880219101905823\n",
      "Train size: [400] hidden size: [364] trial: 39, train_loss: 0.822902, test loss: 1.054809, bias2: 0.5680893063545227, variance: 0.4867200255393982\n",
      "Train size: [400] hidden size: [364] trial: 40, train_loss: 0.819774, test loss: 1.055997, bias2: 0.5679721832275391, variance: 0.4880248010158539\n",
      "Train size: [400] hidden size: [364] trial: 41, train_loss: 0.818806, test loss: 1.056324, bias2: 0.5677089691162109, variance: 0.48861536383628845\n",
      "Train size: [400] hidden size: [364] trial: 42, train_loss: 0.815706, test loss: 1.057013, bias2: 0.5689017176628113, variance: 0.488111674785614\n",
      "Train size: [400] hidden size: [364] trial: 43, train_loss: 0.816202, test loss: 1.056516, bias2: 0.5703903436660767, variance: 0.4861259460449219\n",
      "Train size: [400] hidden size: [364] trial: 44, train_loss: 0.818371, test loss: 1.056365, bias2: 0.569226861000061, variance: 0.487138032913208\n",
      "Train size: [400] hidden size: [364] trial: 45, train_loss: 0.819626, test loss: 1.056338, bias2: 0.5685405135154724, variance: 0.48779720067977905\n",
      "Train size: [400] hidden size: [364] trial: 46, train_loss: 0.819471, test loss: 1.057726, bias2: 0.5700716972351074, variance: 0.4876546859741211\n",
      "Train size: [400] hidden size: [364] trial: 47, train_loss: 0.817676, test loss: 1.056085, bias2: 0.5694088339805603, variance: 0.4866756796836853\n",
      "Train size: [400] hidden size: [364] trial: 48, train_loss: 0.818132, test loss: 1.056193, bias2: 0.5690961480140686, variance: 0.48709672689437866\n",
      "Train size: [400] hidden size: [364] trial: 49, train_loss: 0.818034, test loss: 1.057149, bias2: 0.5691399574279785, variance: 0.48800864815711975\n",
      "##################################################\n",
      "Train size: [400] hidden size: [419] trial: 0, train_loss: 0.756790, test loss: 1.014144, bias2: 1.014143705368042, variance: 7.785095901269301e-10\n",
      "Train size: [400] hidden size: [419] trial: 1, train_loss: 0.672358, test loss: 1.011683, bias2: 0.757328450679779, variance: 0.25435465574264526\n",
      "Train size: [400] hidden size: [419] trial: 2, train_loss: 0.688548, test loss: 0.998573, bias2: 0.6844609975814819, variance: 0.3141123950481415\n",
      "Train size: [400] hidden size: [419] trial: 3, train_loss: 0.709719, test loss: 0.997099, bias2: 0.6393461227416992, variance: 0.35775259137153625\n",
      "Train size: [400] hidden size: [419] trial: 4, train_loss: 0.731931, test loss: 1.001288, bias2: 0.6082125902175903, variance: 0.3930758237838745\n",
      "Train size: [400] hidden size: [419] trial: 5, train_loss: 0.754068, test loss: 1.021725, bias2: 0.60300213098526, variance: 0.4187226891517639\n",
      "Train size: [400] hidden size: [419] trial: 6, train_loss: 0.755336, test loss: 1.034263, bias2: 0.600976824760437, variance: 0.4332859218120575\n",
      "Train size: [400] hidden size: [419] trial: 7, train_loss: 0.749166, test loss: 1.037766, bias2: 0.5935883522033691, variance: 0.44417762756347656\n",
      "Train size: [400] hidden size: [419] trial: 8, train_loss: 0.750165, test loss: 1.038551, bias2: 0.5867114663124084, variance: 0.45183998346328735\n",
      "Train size: [400] hidden size: [419] trial: 9, train_loss: 0.743687, test loss: 1.029495, bias2: 0.5724407434463501, variance: 0.45705416798591614\n",
      "Train size: [400] hidden size: [419] trial: 10, train_loss: 0.734508, test loss: 1.028624, bias2: 0.5717778205871582, variance: 0.4568463861942291\n",
      "Train size: [400] hidden size: [419] trial: 11, train_loss: 0.741917, test loss: 1.035765, bias2: 0.5687110424041748, variance: 0.46705350279808044\n",
      "Train size: [400] hidden size: [419] trial: 12, train_loss: 0.745537, test loss: 1.043034, bias2: 0.5712307691574097, variance: 0.4718034565448761\n",
      "Train size: [400] hidden size: [419] trial: 13, train_loss: 0.746628, test loss: 1.053610, bias2: 0.5759583711624146, variance: 0.4776512086391449\n",
      "Train size: [400] hidden size: [419] trial: 14, train_loss: 0.747590, test loss: 1.046843, bias2: 0.5677912831306458, variance: 0.47905153036117554\n",
      "Train size: [400] hidden size: [419] trial: 15, train_loss: 0.744184, test loss: 1.045968, bias2: 0.5677267909049988, variance: 0.4782407879829407\n",
      "Train size: [400] hidden size: [419] trial: 16, train_loss: 0.746757, test loss: 1.046740, bias2: 0.5656917095184326, variance: 0.48104873299598694\n",
      "Train size: [400] hidden size: [419] trial: 17, train_loss: 0.744256, test loss: 1.051179, bias2: 0.5674451589584351, variance: 0.4837338924407959\n",
      "Train size: [400] hidden size: [419] trial: 18, train_loss: 0.745731, test loss: 1.049522, bias2: 0.5650414228439331, variance: 0.4844801723957062\n",
      "Train size: [400] hidden size: [419] trial: 19, train_loss: 0.747022, test loss: 1.052846, bias2: 0.5706853866577148, variance: 0.4821602404117584\n",
      "Train size: [400] hidden size: [419] trial: 20, train_loss: 0.741833, test loss: 1.051966, bias2: 0.5700377225875854, variance: 0.48192858695983887\n",
      "Train size: [400] hidden size: [419] trial: 21, train_loss: 0.741852, test loss: 1.047954, bias2: 0.5654787421226501, variance: 0.4824754595756531\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [419] trial: 22, train_loss: 0.744317, test loss: 1.045566, bias2: 0.5644556283950806, variance: 0.48111000657081604\n",
      "Train size: [400] hidden size: [419] trial: 23, train_loss: 0.745644, test loss: 1.045550, bias2: 0.5637069940567017, variance: 0.48184260725975037\n",
      "Train size: [400] hidden size: [419] trial: 24, train_loss: 0.743286, test loss: 1.041680, bias2: 0.5583370327949524, variance: 0.4833431839942932\n",
      "Train size: [400] hidden size: [419] trial: 25, train_loss: 0.742585, test loss: 1.039602, bias2: 0.5543109178543091, variance: 0.485291451215744\n",
      "Train size: [400] hidden size: [419] trial: 26, train_loss: 0.742519, test loss: 1.039609, bias2: 0.555356502532959, variance: 0.4842524528503418\n",
      "Train size: [400] hidden size: [419] trial: 27, train_loss: 0.741510, test loss: 1.038138, bias2: 0.5532639026641846, variance: 0.4848744869232178\n",
      "Train size: [400] hidden size: [419] trial: 28, train_loss: 0.735631, test loss: 1.037107, bias2: 0.5522846579551697, variance: 0.4848223328590393\n",
      "Train size: [400] hidden size: [419] trial: 29, train_loss: 0.735584, test loss: 1.035525, bias2: 0.5503765344619751, variance: 0.485148549079895\n",
      "Train size: [400] hidden size: [419] trial: 30, train_loss: 0.735256, test loss: 1.035196, bias2: 0.5497313141822815, variance: 0.48546499013900757\n",
      "Train size: [400] hidden size: [419] trial: 31, train_loss: 0.735800, test loss: 1.037534, bias2: 0.5500000715255737, variance: 0.48753413558006287\n",
      "Train size: [400] hidden size: [419] trial: 32, train_loss: 0.732714, test loss: 1.039017, bias2: 0.5528117418289185, variance: 0.4862048327922821\n",
      "Train size: [400] hidden size: [419] trial: 33, train_loss: 0.734057, test loss: 1.042398, bias2: 0.5533285140991211, variance: 0.4890691339969635\n",
      "Train size: [400] hidden size: [419] trial: 34, train_loss: 0.732638, test loss: 1.039893, bias2: 0.5534892082214355, variance: 0.48640385270118713\n",
      "Train size: [400] hidden size: [419] trial: 35, train_loss: 0.731370, test loss: 1.041790, bias2: 0.5536914467811584, variance: 0.4880982041358948\n",
      "Train size: [400] hidden size: [419] trial: 36, train_loss: 0.731681, test loss: 1.043879, bias2: 0.5533729791641235, variance: 0.49050602316856384\n",
      "Train size: [400] hidden size: [419] trial: 37, train_loss: 0.732520, test loss: 1.041132, bias2: 0.5519782304763794, variance: 0.4891541302204132\n",
      "Train size: [400] hidden size: [419] trial: 38, train_loss: 0.734198, test loss: 1.042918, bias2: 0.5521907210350037, variance: 0.4907272458076477\n",
      "Train size: [400] hidden size: [419] trial: 39, train_loss: 0.733003, test loss: 1.044311, bias2: 0.5522912740707397, variance: 0.4920198619365692\n",
      "Train size: [400] hidden size: [419] trial: 40, train_loss: 0.732605, test loss: 1.043262, bias2: 0.551925539970398, variance: 0.49133625626564026\n",
      "Train size: [400] hidden size: [419] trial: 41, train_loss: 0.732464, test loss: 1.045739, bias2: 0.554430365562439, variance: 0.4913083612918854\n",
      "Train size: [400] hidden size: [419] trial: 42, train_loss: 0.734265, test loss: 1.045800, bias2: 0.5549452304840088, variance: 0.49085506796836853\n",
      "Train size: [400] hidden size: [419] trial: 43, train_loss: 0.733755, test loss: 1.045335, bias2: 0.553412914276123, variance: 0.491922527551651\n",
      "Train size: [400] hidden size: [419] trial: 44, train_loss: 0.736075, test loss: 1.046389, bias2: 0.5522197484970093, variance: 0.4941693842411041\n",
      "Train size: [400] hidden size: [419] trial: 45, train_loss: 0.735995, test loss: 1.048024, bias2: 0.5535203814506531, variance: 0.49450355768203735\n",
      "Train size: [400] hidden size: [419] trial: 46, train_loss: 0.736679, test loss: 1.047429, bias2: 0.5520825982093811, variance: 0.4953461289405823\n",
      "Train size: [400] hidden size: [419] trial: 47, train_loss: 0.738135, test loss: 1.048072, bias2: 0.5499323606491089, variance: 0.498139888048172\n",
      "Train size: [400] hidden size: [419] trial: 48, train_loss: 0.737549, test loss: 1.048438, bias2: 0.5502362847328186, variance: 0.49820154905319214\n",
      "Train size: [400] hidden size: [419] trial: 49, train_loss: 0.737633, test loss: 1.048117, bias2: 0.5493130683898926, variance: 0.49880358576774597\n",
      "##################################################\n",
      "Train size: [400] hidden size: [483] trial: 0, train_loss: 0.611398, test loss: 1.037037, bias2: 1.0370368957519531, variance: -3.5032932110823367e-09\n",
      "Train size: [400] hidden size: [483] trial: 1, train_loss: 0.639317, test loss: 1.011612, bias2: 0.7597107291221619, variance: 0.25190144777297974\n",
      "Train size: [400] hidden size: [483] trial: 2, train_loss: 0.697215, test loss: 1.034372, bias2: 0.6713601350784302, variance: 0.3630114495754242\n",
      "Train size: [400] hidden size: [483] trial: 3, train_loss: 0.693544, test loss: 1.029563, bias2: 0.6252919435501099, variance: 0.4042714536190033\n",
      "Train size: [400] hidden size: [483] trial: 4, train_loss: 0.680945, test loss: 1.022561, bias2: 0.5907134413719177, variance: 0.43184715509414673\n",
      "Train size: [400] hidden size: [483] trial: 5, train_loss: 0.683268, test loss: 1.023914, bias2: 0.5685988664627075, variance: 0.45531490445137024\n",
      "Train size: [400] hidden size: [483] trial: 6, train_loss: 0.681312, test loss: 1.038519, bias2: 0.5642117261886597, variance: 0.47430726885795593\n",
      "Train size: [400] hidden size: [483] trial: 7, train_loss: 0.670590, test loss: 1.035188, bias2: 0.5508919954299927, variance: 0.4842958450317383\n",
      "Train size: [400] hidden size: [483] trial: 8, train_loss: 0.676814, test loss: 1.026851, bias2: 0.5357442498207092, variance: 0.49110716581344604\n",
      "Train size: [400] hidden size: [483] trial: 9, train_loss: 0.670201, test loss: 1.027467, bias2: 0.5298225283622742, variance: 0.4976443648338318\n",
      "Train size: [400] hidden size: [483] trial: 10, train_loss: 0.664476, test loss: 1.028432, bias2: 0.5272181630134583, variance: 0.5012134909629822\n",
      "Train size: [400] hidden size: [483] trial: 11, train_loss: 0.666653, test loss: 1.031495, bias2: 0.5239510536193848, variance: 0.5075441598892212\n",
      "Train size: [400] hidden size: [483] trial: 12, train_loss: 0.666230, test loss: 1.037404, bias2: 0.5196211934089661, variance: 0.5177823901176453\n",
      "Train size: [400] hidden size: [483] trial: 13, train_loss: 0.667923, test loss: 1.032428, bias2: 0.5130926966667175, variance: 0.5193350911140442\n",
      "Train size: [400] hidden size: [483] trial: 14, train_loss: 0.667865, test loss: 1.032078, bias2: 0.5118555426597595, variance: 0.5202226042747498\n",
      "Train size: [400] hidden size: [483] trial: 15, train_loss: 0.670107, test loss: 1.028206, bias2: 0.5070579051971436, variance: 0.5211480855941772\n",
      "Train size: [400] hidden size: [483] trial: 16, train_loss: 0.669493, test loss: 1.033418, bias2: 0.5075714588165283, variance: 0.5258466005325317\n",
      "Train size: [400] hidden size: [483] trial: 17, train_loss: 0.663026, test loss: 1.031288, bias2: 0.5065448880195618, variance: 0.5247430205345154\n",
      "Train size: [400] hidden size: [483] trial: 18, train_loss: 0.664161, test loss: 1.032892, bias2: 0.5087791681289673, variance: 0.5241130590438843\n",
      "Train size: [400] hidden size: [483] trial: 19, train_loss: 0.663461, test loss: 1.030406, bias2: 0.5043818354606628, variance: 0.5260239243507385\n",
      "Train size: [400] hidden size: [483] trial: 20, train_loss: 0.662835, test loss: 1.033639, bias2: 0.5076186060905457, variance: 0.5260202288627625\n",
      "Train size: [400] hidden size: [483] trial: 21, train_loss: 0.660824, test loss: 1.031212, bias2: 0.5033733248710632, variance: 0.527838408946991\n",
      "Train size: [400] hidden size: [483] trial: 22, train_loss: 0.662431, test loss: 1.029747, bias2: 0.5029085278511047, variance: 0.5268382430076599\n",
      "Train size: [400] hidden size: [483] trial: 23, train_loss: 0.664030, test loss: 1.027964, bias2: 0.5014392733573914, variance: 0.52652508020401\n",
      "Train size: [400] hidden size: [483] trial: 24, train_loss: 0.661304, test loss: 1.030142, bias2: 0.5042391419410706, variance: 0.525903046131134\n",
      "Train size: [400] hidden size: [483] trial: 25, train_loss: 0.656943, test loss: 1.030381, bias2: 0.5025933384895325, variance: 0.5277878642082214\n",
      "Train size: [400] hidden size: [483] trial: 26, train_loss: 0.656863, test loss: 1.028583, bias2: 0.5027744770050049, variance: 0.5258090496063232\n",
      "Train size: [400] hidden size: [483] trial: 27, train_loss: 0.655395, test loss: 1.028874, bias2: 0.5034765601158142, variance: 0.5253971219062805\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [483] trial: 28, train_loss: 0.653225, test loss: 1.029556, bias2: 0.5053702592849731, variance: 0.5241855382919312\n",
      "Train size: [400] hidden size: [483] trial: 29, train_loss: 0.654128, test loss: 1.032633, bias2: 0.5057094097137451, variance: 0.5269232988357544\n",
      "Train size: [400] hidden size: [483] trial: 30, train_loss: 0.653383, test loss: 1.031889, bias2: 0.5034427046775818, variance: 0.5284462571144104\n",
      "Train size: [400] hidden size: [483] trial: 31, train_loss: 0.651122, test loss: 1.031123, bias2: 0.5037863254547119, variance: 0.527336597442627\n",
      "Train size: [400] hidden size: [483] trial: 32, train_loss: 0.649825, test loss: 1.030513, bias2: 0.5034295320510864, variance: 0.5270830392837524\n",
      "Train size: [400] hidden size: [483] trial: 33, train_loss: 0.649570, test loss: 1.031826, bias2: 0.50334632396698, variance: 0.5284796953201294\n",
      "Train size: [400] hidden size: [483] trial: 34, train_loss: 0.654144, test loss: 1.036482, bias2: 0.5054887533187866, variance: 0.5309929847717285\n",
      "Train size: [400] hidden size: [483] trial: 35, train_loss: 0.653909, test loss: 1.035361, bias2: 0.5037314891815186, variance: 0.5316290855407715\n",
      "Train size: [400] hidden size: [483] trial: 36, train_loss: 0.653176, test loss: 1.033273, bias2: 0.5019187331199646, variance: 0.531353771686554\n",
      "Train size: [400] hidden size: [483] trial: 37, train_loss: 0.650451, test loss: 1.032892, bias2: 0.5025010704994202, variance: 0.5303911566734314\n",
      "Train size: [400] hidden size: [483] trial: 38, train_loss: 0.652821, test loss: 1.032460, bias2: 0.5025566220283508, variance: 0.5299031138420105\n",
      "Train size: [400] hidden size: [483] trial: 39, train_loss: 0.653516, test loss: 1.030454, bias2: 0.5004214644432068, variance: 0.5300325751304626\n",
      "Train size: [400] hidden size: [483] trial: 40, train_loss: 0.652596, test loss: 1.029170, bias2: 0.5000349879264832, variance: 0.5291352868080139\n",
      "Train size: [400] hidden size: [483] trial: 41, train_loss: 0.653363, test loss: 1.028411, bias2: 0.49972623586654663, variance: 0.5286845564842224\n",
      "Train size: [400] hidden size: [483] trial: 42, train_loss: 0.653832, test loss: 1.027508, bias2: 0.49947822093963623, variance: 0.5280299186706543\n",
      "Train size: [400] hidden size: [483] trial: 43, train_loss: 0.653822, test loss: 1.027521, bias2: 0.5000393390655518, variance: 0.5274820327758789\n",
      "Train size: [400] hidden size: [483] trial: 44, train_loss: 0.652499, test loss: 1.028114, bias2: 0.5011547803878784, variance: 0.5269590616226196\n",
      "Train size: [400] hidden size: [483] trial: 45, train_loss: 0.651691, test loss: 1.026570, bias2: 0.5006085634231567, variance: 0.5259616374969482\n",
      "Train size: [400] hidden size: [483] trial: 46, train_loss: 0.652814, test loss: 1.027858, bias2: 0.5018327236175537, variance: 0.5260257720947266\n",
      "Train size: [400] hidden size: [483] trial: 47, train_loss: 0.652717, test loss: 1.030708, bias2: 0.504301130771637, variance: 0.5264068245887756\n",
      "Train size: [400] hidden size: [483] trial: 48, train_loss: 0.653123, test loss: 1.030543, bias2: 0.5026260614395142, variance: 0.5279167890548706\n",
      "Train size: [400] hidden size: [483] trial: 49, train_loss: 0.653624, test loss: 1.030429, bias2: 0.5028344988822937, variance: 0.527594268321991\n",
      "##################################################\n",
      "Train size: [400] hidden size: [556] trial: 0, train_loss: 0.591709, test loss: 0.996164, bias2: 0.9961641430854797, variance: 1.1677644407015464e-09\n",
      "Train size: [400] hidden size: [556] trial: 1, train_loss: 0.613474, test loss: 1.002001, bias2: 0.7489286661148071, variance: 0.253072053194046\n",
      "Train size: [400] hidden size: [556] trial: 2, train_loss: 0.610078, test loss: 1.001028, bias2: 0.6630529165267944, variance: 0.3379746973514557\n",
      "Train size: [400] hidden size: [556] trial: 3, train_loss: 0.599728, test loss: 0.985951, bias2: 0.6150423884391785, variance: 0.3709084987640381\n",
      "Train size: [400] hidden size: [556] trial: 4, train_loss: 0.605467, test loss: 0.972131, bias2: 0.5806002020835876, variance: 0.3915303945541382\n",
      "Train size: [400] hidden size: [556] trial: 5, train_loss: 0.588574, test loss: 0.984581, bias2: 0.5721279382705688, variance: 0.4124528467655182\n",
      "Train size: [400] hidden size: [556] trial: 6, train_loss: 0.593173, test loss: 0.978753, bias2: 0.5531418919563293, variance: 0.4256107807159424\n",
      "Train size: [400] hidden size: [556] trial: 7, train_loss: 0.592706, test loss: 0.989392, bias2: 0.5506616830825806, variance: 0.4387301802635193\n",
      "Train size: [400] hidden size: [556] trial: 8, train_loss: 0.593368, test loss: 0.990415, bias2: 0.5391758680343628, variance: 0.4512389600276947\n",
      "Train size: [400] hidden size: [556] trial: 9, train_loss: 0.591768, test loss: 0.985953, bias2: 0.524171769618988, variance: 0.4617815613746643\n",
      "Train size: [400] hidden size: [556] trial: 10, train_loss: 0.593231, test loss: 0.992899, bias2: 0.5224610567092896, variance: 0.4704377353191376\n",
      "Train size: [400] hidden size: [556] trial: 11, train_loss: 0.595772, test loss: 0.998283, bias2: 0.5143735408782959, variance: 0.4839094281196594\n",
      "Train size: [400] hidden size: [556] trial: 12, train_loss: 0.591477, test loss: 0.992509, bias2: 0.5030684471130371, variance: 0.48944008350372314\n",
      "Train size: [400] hidden size: [556] trial: 13, train_loss: 0.592780, test loss: 0.988473, bias2: 0.4952586889266968, variance: 0.49321383237838745\n",
      "Train size: [400] hidden size: [556] trial: 14, train_loss: 0.592968, test loss: 0.986936, bias2: 0.48782917857170105, variance: 0.4991070330142975\n",
      "Train size: [400] hidden size: [556] trial: 15, train_loss: 0.594355, test loss: 0.982391, bias2: 0.48338985443115234, variance: 0.4990013837814331\n",
      "Train size: [400] hidden size: [556] trial: 16, train_loss: 0.592436, test loss: 0.981402, bias2: 0.48324334621429443, variance: 0.49815815687179565\n",
      "Train size: [400] hidden size: [556] trial: 17, train_loss: 0.591369, test loss: 0.980771, bias2: 0.47982895374298096, variance: 0.5009419322013855\n",
      "Train size: [400] hidden size: [556] trial: 18, train_loss: 0.588344, test loss: 0.978730, bias2: 0.47805696725845337, variance: 0.5006729960441589\n",
      "Train size: [400] hidden size: [556] trial: 19, train_loss: 0.587836, test loss: 0.977479, bias2: 0.4749777317047119, variance: 0.5025016069412231\n",
      "Train size: [400] hidden size: [556] trial: 20, train_loss: 0.588131, test loss: 0.979732, bias2: 0.4764891266822815, variance: 0.5032429695129395\n",
      "Train size: [400] hidden size: [556] trial: 21, train_loss: 0.590797, test loss: 0.978727, bias2: 0.47377657890319824, variance: 0.5049508810043335\n",
      "Train size: [400] hidden size: [556] trial: 22, train_loss: 0.591821, test loss: 0.983239, bias2: 0.47227609157562256, variance: 0.5109633803367615\n",
      "Train size: [400] hidden size: [556] trial: 23, train_loss: 0.592457, test loss: 0.983385, bias2: 0.4715203642845154, variance: 0.5118641257286072\n",
      "Train size: [400] hidden size: [556] trial: 24, train_loss: 0.592511, test loss: 0.984646, bias2: 0.47167038917541504, variance: 0.5129759907722473\n",
      "Train size: [400] hidden size: [556] trial: 25, train_loss: 0.590299, test loss: 0.983323, bias2: 0.4706695079803467, variance: 0.512653112411499\n",
      "Train size: [400] hidden size: [556] trial: 26, train_loss: 0.587853, test loss: 0.979689, bias2: 0.46862661838531494, variance: 0.5110625624656677\n",
      "Train size: [400] hidden size: [556] trial: 27, train_loss: 0.586021, test loss: 0.980618, bias2: 0.4692126512527466, variance: 0.5114058256149292\n",
      "Train size: [400] hidden size: [556] trial: 28, train_loss: 0.582859, test loss: 0.980141, bias2: 0.4707285761833191, variance: 0.5094122886657715\n",
      "Train size: [400] hidden size: [556] trial: 29, train_loss: 0.581104, test loss: 0.977512, bias2: 0.468140184879303, variance: 0.5093716979026794\n",
      "Train size: [400] hidden size: [556] trial: 30, train_loss: 0.580961, test loss: 0.977512, bias2: 0.4679678678512573, variance: 0.5095446109771729\n",
      "Train size: [400] hidden size: [556] trial: 31, train_loss: 0.579061, test loss: 0.980780, bias2: 0.47165173292160034, variance: 0.509128749370575\n",
      "Train size: [400] hidden size: [556] trial: 32, train_loss: 0.578675, test loss: 0.984160, bias2: 0.47518759965896606, variance: 0.5089722275733948\n",
      "Train size: [400] hidden size: [556] trial: 33, train_loss: 0.580363, test loss: 0.984435, bias2: 0.4732794165611267, variance: 0.5111551880836487\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [556] trial: 34, train_loss: 0.579821, test loss: 0.983064, bias2: 0.4713483452796936, variance: 0.5117156505584717\n",
      "Train size: [400] hidden size: [556] trial: 35, train_loss: 0.580631, test loss: 0.985644, bias2: 0.47370070219039917, variance: 0.5119435787200928\n",
      "Train size: [400] hidden size: [556] trial: 36, train_loss: 0.581461, test loss: 0.986386, bias2: 0.47419387102127075, variance: 0.5121921896934509\n",
      "Train size: [400] hidden size: [556] trial: 37, train_loss: 0.580997, test loss: 0.987188, bias2: 0.4742256999015808, variance: 0.512962281703949\n",
      "Train size: [400] hidden size: [556] trial: 38, train_loss: 0.582513, test loss: 0.990748, bias2: 0.4767889976501465, variance: 0.5139586329460144\n",
      "Train size: [400] hidden size: [556] trial: 39, train_loss: 0.580050, test loss: 0.990680, bias2: 0.4777872562408447, variance: 0.5128923654556274\n",
      "Train size: [400] hidden size: [556] trial: 40, train_loss: 0.578961, test loss: 0.993385, bias2: 0.4813741445541382, variance: 0.5120110511779785\n",
      "Train size: [400] hidden size: [556] trial: 41, train_loss: 0.577003, test loss: 0.993121, bias2: 0.4825971722602844, variance: 0.510524332523346\n",
      "Train size: [400] hidden size: [556] trial: 42, train_loss: 0.577866, test loss: 0.993389, bias2: 0.4837460517883301, variance: 0.5096425414085388\n",
      "Train size: [400] hidden size: [556] trial: 43, train_loss: 0.577387, test loss: 0.993542, bias2: 0.48379814624786377, variance: 0.5097435712814331\n",
      "Train size: [400] hidden size: [556] trial: 44, train_loss: 0.577261, test loss: 0.994286, bias2: 0.48432713747024536, variance: 0.5099587440490723\n",
      "Train size: [400] hidden size: [556] trial: 45, train_loss: 0.578779, test loss: 0.995861, bias2: 0.4848617911338806, variance: 0.5109995603561401\n",
      "Train size: [400] hidden size: [556] trial: 46, train_loss: 0.578328, test loss: 0.997402, bias2: 0.48514264822006226, variance: 0.5122592449188232\n",
      "Train size: [400] hidden size: [556] trial: 47, train_loss: 0.578712, test loss: 0.997375, bias2: 0.4855823516845703, variance: 0.5117926597595215\n",
      "Train size: [400] hidden size: [556] trial: 48, train_loss: 0.578801, test loss: 0.998324, bias2: 0.4861981272697449, variance: 0.5121263265609741\n",
      "Train size: [400] hidden size: [556] trial: 49, train_loss: 0.579098, test loss: 0.999874, bias2: 0.4862448573112488, variance: 0.5136287212371826\n",
      "##################################################\n",
      "Train size: [400] hidden size: [640] trial: 0, train_loss: 0.650782, test loss: 0.931963, bias2: 0.9319625496864319, variance: -1.1677644407015464e-09\n",
      "Train size: [400] hidden size: [640] trial: 1, train_loss: 0.590152, test loss: 0.932045, bias2: 0.6665186285972595, variance: 0.2655261158943176\n",
      "Train size: [400] hidden size: [640] trial: 2, train_loss: 0.578949, test loss: 0.984269, bias2: 0.6073852777481079, variance: 0.3768833577632904\n",
      "Train size: [400] hidden size: [640] trial: 3, train_loss: 0.573892, test loss: 0.991773, bias2: 0.5608110427856445, variance: 0.4309619963169098\n",
      "Train size: [400] hidden size: [640] trial: 4, train_loss: 0.568472, test loss: 0.985384, bias2: 0.5353567600250244, variance: 0.45002686977386475\n",
      "Train size: [400] hidden size: [640] trial: 5, train_loss: 0.554573, test loss: 0.997643, bias2: 0.5203791260719299, variance: 0.47726404666900635\n",
      "Train size: [400] hidden size: [640] trial: 6, train_loss: 0.545409, test loss: 1.000924, bias2: 0.517499566078186, variance: 0.4834239184856415\n",
      "Train size: [400] hidden size: [640] trial: 7, train_loss: 0.543376, test loss: 0.993602, bias2: 0.5082958936691284, variance: 0.48530635237693787\n",
      "Train size: [400] hidden size: [640] trial: 8, train_loss: 0.535696, test loss: 0.990325, bias2: 0.49914073944091797, variance: 0.49118441343307495\n",
      "Train size: [400] hidden size: [640] trial: 9, train_loss: 0.537435, test loss: 0.988733, bias2: 0.4901382327079773, variance: 0.49859482049942017\n",
      "Train size: [400] hidden size: [640] trial: 10, train_loss: 0.537301, test loss: 0.991317, bias2: 0.49089759588241577, variance: 0.500419557094574\n",
      "Train size: [400] hidden size: [640] trial: 11, train_loss: 0.533990, test loss: 0.996572, bias2: 0.48950910568237305, variance: 0.5070624351501465\n",
      "Train size: [400] hidden size: [640] trial: 12, train_loss: 0.534091, test loss: 0.997570, bias2: 0.4898719787597656, variance: 0.5076977610588074\n",
      "Train size: [400] hidden size: [640] trial: 13, train_loss: 0.531533, test loss: 0.994284, bias2: 0.4805825352668762, variance: 0.5137014985084534\n",
      "Train size: [400] hidden size: [640] trial: 14, train_loss: 0.529819, test loss: 0.987413, bias2: 0.47313791513442993, variance: 0.5142754316329956\n",
      "Train size: [400] hidden size: [640] trial: 15, train_loss: 0.528244, test loss: 0.985419, bias2: 0.4683701992034912, variance: 0.5170487761497498\n",
      "Train size: [400] hidden size: [640] trial: 16, train_loss: 0.523931, test loss: 0.990460, bias2: 0.4719724655151367, variance: 0.518487274646759\n",
      "Train size: [400] hidden size: [640] trial: 17, train_loss: 0.521639, test loss: 0.990023, bias2: 0.46866899728775024, variance: 0.5213541388511658\n",
      "Train size: [400] hidden size: [640] trial: 18, train_loss: 0.518439, test loss: 0.987474, bias2: 0.46618932485580444, variance: 0.5212851762771606\n",
      "Train size: [400] hidden size: [640] trial: 19, train_loss: 0.517351, test loss: 0.992360, bias2: 0.4695521593093872, variance: 0.5228075385093689\n",
      "Train size: [400] hidden size: [640] trial: 20, train_loss: 0.520674, test loss: 0.992470, bias2: 0.46604543924331665, variance: 0.5264241099357605\n",
      "Train size: [400] hidden size: [640] trial: 21, train_loss: 0.518199, test loss: 0.993600, bias2: 0.4656018614768982, variance: 0.5279982089996338\n",
      "Train size: [400] hidden size: [640] trial: 22, train_loss: 0.516123, test loss: 0.995975, bias2: 0.4661637544631958, variance: 0.5298109650611877\n",
      "Train size: [400] hidden size: [640] trial: 23, train_loss: 0.519865, test loss: 0.998654, bias2: 0.4671761393547058, variance: 0.5314778685569763\n",
      "Train size: [400] hidden size: [640] trial: 24, train_loss: 0.517042, test loss: 0.996964, bias2: 0.46607714891433716, variance: 0.5308865904808044\n",
      "Train size: [400] hidden size: [640] trial: 25, train_loss: 0.516119, test loss: 0.994622, bias2: 0.46602505445480347, variance: 0.528597354888916\n",
      "Train size: [400] hidden size: [640] trial: 26, train_loss: 0.515384, test loss: 0.991148, bias2: 0.46242934465408325, variance: 0.5287189483642578\n",
      "Train size: [400] hidden size: [640] trial: 27, train_loss: 0.517131, test loss: 0.992843, bias2: 0.46440595388412476, variance: 0.5284374952316284\n",
      "Train size: [400] hidden size: [640] trial: 28, train_loss: 0.518082, test loss: 0.995287, bias2: 0.46552908420562744, variance: 0.5297577977180481\n",
      "Train size: [400] hidden size: [640] trial: 29, train_loss: 0.516595, test loss: 0.993889, bias2: 0.46335846185684204, variance: 0.5305305123329163\n",
      "Train size: [400] hidden size: [640] trial: 30, train_loss: 0.516417, test loss: 0.995182, bias2: 0.46390730142593384, variance: 0.5312743186950684\n",
      "Train size: [400] hidden size: [640] trial: 31, train_loss: 0.518519, test loss: 0.994868, bias2: 0.4633450508117676, variance: 0.5315231084823608\n",
      "Train size: [400] hidden size: [640] trial: 32, train_loss: 0.515806, test loss: 0.993209, bias2: 0.461834192276001, variance: 0.531374454498291\n",
      "Train size: [400] hidden size: [640] trial: 33, train_loss: 0.515864, test loss: 0.991659, bias2: 0.46202683448791504, variance: 0.5296318531036377\n",
      "Train size: [400] hidden size: [640] trial: 34, train_loss: 0.517494, test loss: 0.991149, bias2: 0.4600088596343994, variance: 0.5311405658721924\n",
      "Train size: [400] hidden size: [640] trial: 35, train_loss: 0.516543, test loss: 0.992212, bias2: 0.4614967107772827, variance: 0.5307155251502991\n",
      "Train size: [400] hidden size: [640] trial: 36, train_loss: 0.515055, test loss: 0.991448, bias2: 0.46057581901550293, variance: 0.530872642993927\n",
      "Train size: [400] hidden size: [640] trial: 37, train_loss: 0.516192, test loss: 0.992850, bias2: 0.46122848987579346, variance: 0.5316210985183716\n",
      "Train size: [400] hidden size: [640] trial: 38, train_loss: 0.516084, test loss: 0.993703, bias2: 0.45925986766815186, variance: 0.534442663192749\n",
      "Train size: [400] hidden size: [640] trial: 39, train_loss: 0.515385, test loss: 0.995428, bias2: 0.4603998064994812, variance: 0.5350279211997986\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [640] trial: 40, train_loss: 0.512892, test loss: 0.995655, bias2: 0.46001410484313965, variance: 0.5356405973434448\n",
      "Train size: [400] hidden size: [640] trial: 41, train_loss: 0.511788, test loss: 0.997827, bias2: 0.46224910020828247, variance: 0.5355774760246277\n",
      "Train size: [400] hidden size: [640] trial: 42, train_loss: 0.510903, test loss: 0.998645, bias2: 0.46307748556137085, variance: 0.5355677008628845\n",
      "Train size: [400] hidden size: [640] trial: 43, train_loss: 0.511474, test loss: 0.998733, bias2: 0.46318602561950684, variance: 0.5355470776557922\n",
      "Train size: [400] hidden size: [640] trial: 44, train_loss: 0.514123, test loss: 0.999606, bias2: 0.4639260768890381, variance: 0.5356801152229309\n",
      "Train size: [400] hidden size: [640] trial: 45, train_loss: 0.512131, test loss: 0.998622, bias2: 0.4634593725204468, variance: 0.5351629853248596\n",
      "Train size: [400] hidden size: [640] trial: 46, train_loss: 0.512050, test loss: 0.997043, bias2: 0.46358007192611694, variance: 0.5334631204605103\n",
      "Train size: [400] hidden size: [640] trial: 47, train_loss: 0.511426, test loss: 0.996326, bias2: 0.4644433856010437, variance: 0.5318825244903564\n",
      "Train size: [400] hidden size: [640] trial: 48, train_loss: 0.510076, test loss: 0.997444, bias2: 0.4647957682609558, variance: 0.5326485633850098\n",
      "Train size: [400] hidden size: [640] trial: 49, train_loss: 0.509169, test loss: 0.997668, bias2: 0.46514254808425903, variance: 0.5325254797935486\n",
      "##################################################\n",
      "Train size: [400] hidden size: [737] trial: 0, train_loss: 0.381514, test loss: 0.951185, bias2: 0.9511846899986267, variance: -3.1140383605077204e-09\n",
      "Train size: [400] hidden size: [737] trial: 1, train_loss: 0.405994, test loss: 0.979753, bias2: 0.7222123146057129, variance: 0.2575405538082123\n",
      "Train size: [400] hidden size: [737] trial: 2, train_loss: 0.435345, test loss: 0.985938, bias2: 0.629780113697052, variance: 0.3561580777168274\n",
      "Train size: [400] hidden size: [737] trial: 3, train_loss: 0.440827, test loss: 0.981909, bias2: 0.5808825492858887, variance: 0.40102633833885193\n",
      "Train size: [400] hidden size: [737] trial: 4, train_loss: 0.431692, test loss: 0.972537, bias2: 0.5501115918159485, variance: 0.42242497205734253\n",
      "Train size: [400] hidden size: [737] trial: 5, train_loss: 0.421126, test loss: 0.963509, bias2: 0.5283672213554382, variance: 0.4351416826248169\n",
      "Train size: [400] hidden size: [737] trial: 6, train_loss: 0.424832, test loss: 0.959800, bias2: 0.5149561166763306, variance: 0.44484347105026245\n",
      "Train size: [400] hidden size: [737] trial: 7, train_loss: 0.436062, test loss: 0.961625, bias2: 0.5059055089950562, variance: 0.45571964979171753\n",
      "Train size: [400] hidden size: [737] trial: 8, train_loss: 0.433930, test loss: 0.968970, bias2: 0.49867498874664307, variance: 0.4702945947647095\n",
      "Train size: [400] hidden size: [737] trial: 9, train_loss: 0.433333, test loss: 0.965414, bias2: 0.48689231276512146, variance: 0.4785216152667999\n",
      "Train size: [400] hidden size: [737] trial: 10, train_loss: 0.435665, test loss: 0.968369, bias2: 0.48663514852523804, variance: 0.4817342162132263\n",
      "Train size: [400] hidden size: [737] trial: 11, train_loss: 0.435733, test loss: 0.971937, bias2: 0.48462551832199097, variance: 0.48731154203414917\n",
      "Train size: [400] hidden size: [737] trial: 12, train_loss: 0.436220, test loss: 0.968450, bias2: 0.4782860279083252, variance: 0.49016356468200684\n",
      "Train size: [400] hidden size: [737] trial: 13, train_loss: 0.437740, test loss: 0.970654, bias2: 0.47603440284729004, variance: 0.49461913108825684\n",
      "Train size: [400] hidden size: [737] trial: 14, train_loss: 0.433953, test loss: 0.969085, bias2: 0.47380587458610535, variance: 0.4952790439128876\n",
      "Train size: [400] hidden size: [737] trial: 15, train_loss: 0.434539, test loss: 0.968382, bias2: 0.47279250621795654, variance: 0.4955897331237793\n",
      "Train size: [400] hidden size: [737] trial: 16, train_loss: 0.439216, test loss: 0.970666, bias2: 0.47024005651474, variance: 0.5004263520240784\n",
      "Train size: [400] hidden size: [737] trial: 17, train_loss: 0.435949, test loss: 0.969365, bias2: 0.4667183756828308, variance: 0.5026463270187378\n",
      "Train size: [400] hidden size: [737] trial: 18, train_loss: 0.434532, test loss: 0.966055, bias2: 0.46452921628952026, variance: 0.5015254616737366\n",
      "Train size: [400] hidden size: [737] trial: 19, train_loss: 0.431080, test loss: 0.964038, bias2: 0.4613979458808899, variance: 0.5026405453681946\n",
      "Train size: [400] hidden size: [737] trial: 20, train_loss: 0.434755, test loss: 0.961021, bias2: 0.4552973508834839, variance: 0.5057238936424255\n",
      "Train size: [400] hidden size: [737] trial: 21, train_loss: 0.435277, test loss: 0.963207, bias2: 0.45630818605422974, variance: 0.5068985819816589\n",
      "Train size: [400] hidden size: [737] trial: 22, train_loss: 0.433919, test loss: 0.965073, bias2: 0.4586808681488037, variance: 0.5063923597335815\n",
      "Train size: [400] hidden size: [737] trial: 23, train_loss: 0.433166, test loss: 0.965111, bias2: 0.45894312858581543, variance: 0.5061682462692261\n",
      "Train size: [400] hidden size: [737] trial: 24, train_loss: 0.433486, test loss: 0.965186, bias2: 0.45723432302474976, variance: 0.5079518556594849\n",
      "Train size: [400] hidden size: [737] trial: 25, train_loss: 0.434953, test loss: 0.964444, bias2: 0.45779645442962646, variance: 0.5066478848457336\n",
      "Train size: [400] hidden size: [737] trial: 26, train_loss: 0.436012, test loss: 0.961799, bias2: 0.453660786151886, variance: 0.5081383585929871\n",
      "Train size: [400] hidden size: [737] trial: 27, train_loss: 0.436668, test loss: 0.961213, bias2: 0.4501032829284668, variance: 0.5111096501350403\n",
      "Train size: [400] hidden size: [737] trial: 28, train_loss: 0.435434, test loss: 0.962179, bias2: 0.4500386714935303, variance: 0.5121402740478516\n",
      "Train size: [400] hidden size: [737] trial: 29, train_loss: 0.435906, test loss: 0.959428, bias2: 0.4480867385864258, variance: 0.5113417506217957\n",
      "Train size: [400] hidden size: [737] trial: 30, train_loss: 0.436539, test loss: 0.964126, bias2: 0.4501606225967407, variance: 0.5139656662940979\n",
      "Train size: [400] hidden size: [737] trial: 31, train_loss: 0.437758, test loss: 0.963530, bias2: 0.44987380504608154, variance: 0.5136559009552002\n",
      "Train size: [400] hidden size: [737] trial: 32, train_loss: 0.438465, test loss: 0.964279, bias2: 0.44913387298583984, variance: 0.5151453018188477\n",
      "Train size: [400] hidden size: [737] trial: 33, train_loss: 0.437410, test loss: 0.964737, bias2: 0.44878989458084106, variance: 0.5159468650817871\n",
      "Train size: [400] hidden size: [737] trial: 34, train_loss: 0.436198, test loss: 0.965663, bias2: 0.44886863231658936, variance: 0.5167939066886902\n",
      "Train size: [400] hidden size: [737] trial: 35, train_loss: 0.435036, test loss: 0.963213, bias2: 0.4479435682296753, variance: 0.5152696967124939\n",
      "Train size: [400] hidden size: [737] trial: 36, train_loss: 0.433738, test loss: 0.965048, bias2: 0.45034289360046387, variance: 0.51470547914505\n",
      "Train size: [400] hidden size: [737] trial: 37, train_loss: 0.434300, test loss: 0.963044, bias2: 0.44776850938796997, variance: 0.5152750611305237\n",
      "Train size: [400] hidden size: [737] trial: 38, train_loss: 0.432491, test loss: 0.962899, bias2: 0.44748353958129883, variance: 0.5154159069061279\n",
      "Train size: [400] hidden size: [737] trial: 39, train_loss: 0.431880, test loss: 0.960375, bias2: 0.4460204243659973, variance: 0.5143541693687439\n",
      "Train size: [400] hidden size: [737] trial: 40, train_loss: 0.431196, test loss: 0.960146, bias2: 0.44625622034072876, variance: 0.5138895511627197\n",
      "Train size: [400] hidden size: [737] trial: 41, train_loss: 0.433475, test loss: 0.961336, bias2: 0.44638311862945557, variance: 0.5149533152580261\n",
      "Train size: [400] hidden size: [737] trial: 42, train_loss: 0.433080, test loss: 0.957880, bias2: 0.4445958137512207, variance: 0.5132843852043152\n",
      "Train size: [400] hidden size: [737] trial: 43, train_loss: 0.434371, test loss: 0.956405, bias2: 0.442766010761261, variance: 0.5136390328407288\n",
      "Train size: [400] hidden size: [737] trial: 44, train_loss: 0.434536, test loss: 0.956979, bias2: 0.4424743056297302, variance: 0.5145043730735779\n",
      "Train size: [400] hidden size: [737] trial: 45, train_loss: 0.435593, test loss: 0.956266, bias2: 0.4417407512664795, variance: 0.5145256519317627\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [737] trial: 46, train_loss: 0.436134, test loss: 0.954026, bias2: 0.43993353843688965, variance: 0.5140923261642456\n",
      "Train size: [400] hidden size: [737] trial: 47, train_loss: 0.436546, test loss: 0.953603, bias2: 0.4391065835952759, variance: 0.5144962668418884\n",
      "Train size: [400] hidden size: [737] trial: 48, train_loss: 0.436273, test loss: 0.951757, bias2: 0.4368754029273987, variance: 0.5148810744285583\n",
      "Train size: [400] hidden size: [737] trial: 49, train_loss: 0.435744, test loss: 0.951028, bias2: 0.4369019865989685, variance: 0.5141255259513855\n",
      "##################################################\n",
      "Train size: [400] hidden size: [848] trial: 0, train_loss: 0.397518, test loss: 0.964947, bias2: 0.9649474620819092, variance: -1.1677644407015464e-09\n",
      "Train size: [400] hidden size: [848] trial: 1, train_loss: 0.410435, test loss: 0.949519, bias2: 0.7021035552024841, variance: 0.2474154829978943\n",
      "Train size: [400] hidden size: [848] trial: 2, train_loss: 0.386698, test loss: 0.963670, bias2: 0.6211546659469604, variance: 0.3425157368183136\n",
      "Train size: [400] hidden size: [848] trial: 3, train_loss: 0.388220, test loss: 0.969563, bias2: 0.5816981792449951, variance: 0.38786521553993225\n",
      "Train size: [400] hidden size: [848] trial: 4, train_loss: 0.369601, test loss: 0.959497, bias2: 0.554279088973999, variance: 0.40521785616874695\n",
      "Train size: [400] hidden size: [848] trial: 5, train_loss: 0.368541, test loss: 0.943072, bias2: 0.5235816240310669, variance: 0.419490247964859\n",
      "Train size: [400] hidden size: [848] trial: 6, train_loss: 0.373283, test loss: 0.942683, bias2: 0.5122740864753723, variance: 0.43040889501571655\n",
      "Train size: [400] hidden size: [848] trial: 7, train_loss: 0.376321, test loss: 0.946050, bias2: 0.5033705234527588, variance: 0.44267934560775757\n",
      "Train size: [400] hidden size: [848] trial: 8, train_loss: 0.375024, test loss: 0.943005, bias2: 0.4844018220901489, variance: 0.45860356092453003\n",
      "Train size: [400] hidden size: [848] trial: 9, train_loss: 0.377696, test loss: 0.948487, bias2: 0.4821060597896576, variance: 0.46638068556785583\n",
      "Train size: [400] hidden size: [848] trial: 10, train_loss: 0.386830, test loss: 0.950138, bias2: 0.47950541973114014, variance: 0.4706326127052307\n",
      "Train size: [400] hidden size: [848] trial: 11, train_loss: 0.383277, test loss: 0.949636, bias2: 0.4727751910686493, variance: 0.4768610894680023\n",
      "Train size: [400] hidden size: [848] trial: 12, train_loss: 0.389930, test loss: 0.951378, bias2: 0.47308114171028137, variance: 0.4782966673374176\n",
      "Train size: [400] hidden size: [848] trial: 13, train_loss: 0.391834, test loss: 0.948818, bias2: 0.46441254019737244, variance: 0.48440513014793396\n",
      "Train size: [400] hidden size: [848] trial: 14, train_loss: 0.392444, test loss: 0.951490, bias2: 0.46297261118888855, variance: 0.4885174334049225\n",
      "Train size: [400] hidden size: [848] trial: 15, train_loss: 0.393387, test loss: 0.952954, bias2: 0.4623226523399353, variance: 0.490631103515625\n",
      "Train size: [400] hidden size: [848] trial: 16, train_loss: 0.391121, test loss: 0.950790, bias2: 0.4586692154407501, variance: 0.4921204745769501\n",
      "Train size: [400] hidden size: [848] trial: 17, train_loss: 0.391657, test loss: 0.950677, bias2: 0.45827341079711914, variance: 0.49240386486053467\n",
      "Train size: [400] hidden size: [848] trial: 18, train_loss: 0.389473, test loss: 0.946690, bias2: 0.4521513283252716, variance: 0.494538813829422\n",
      "Train size: [400] hidden size: [848] trial: 19, train_loss: 0.389176, test loss: 0.954360, bias2: 0.454303503036499, variance: 0.5000566840171814\n",
      "Train size: [400] hidden size: [848] trial: 20, train_loss: 0.388130, test loss: 0.952538, bias2: 0.4518699645996094, variance: 0.5006684064865112\n",
      "Train size: [400] hidden size: [848] trial: 21, train_loss: 0.387781, test loss: 0.952441, bias2: 0.4476381540298462, variance: 0.5048026442527771\n",
      "Train size: [400] hidden size: [848] trial: 22, train_loss: 0.386865, test loss: 0.951711, bias2: 0.446607768535614, variance: 0.5051034688949585\n",
      "Train size: [400] hidden size: [848] trial: 23, train_loss: 0.384352, test loss: 0.954906, bias2: 0.4482383131980896, variance: 0.5066681504249573\n",
      "Train size: [400] hidden size: [848] trial: 24, train_loss: 0.384800, test loss: 0.955014, bias2: 0.4493919014930725, variance: 0.5056223273277283\n",
      "Train size: [400] hidden size: [848] trial: 25, train_loss: 0.384864, test loss: 0.951666, bias2: 0.4464079737663269, variance: 0.5052579641342163\n",
      "Train size: [400] hidden size: [848] trial: 26, train_loss: 0.386856, test loss: 0.951663, bias2: 0.44671809673309326, variance: 0.5049450397491455\n",
      "Train size: [400] hidden size: [848] trial: 27, train_loss: 0.385425, test loss: 0.952305, bias2: 0.4475300908088684, variance: 0.5047746896743774\n",
      "Train size: [400] hidden size: [848] trial: 28, train_loss: 0.387962, test loss: 0.951292, bias2: 0.4468752145767212, variance: 0.5044165849685669\n",
      "Train size: [400] hidden size: [848] trial: 29, train_loss: 0.388555, test loss: 0.950591, bias2: 0.44574952125549316, variance: 0.5048419237136841\n",
      "Train size: [400] hidden size: [848] trial: 30, train_loss: 0.387483, test loss: 0.951906, bias2: 0.4449314475059509, variance: 0.5069747567176819\n",
      "Train size: [400] hidden size: [848] trial: 31, train_loss: 0.387481, test loss: 0.953566, bias2: 0.4450603723526001, variance: 0.5085057616233826\n",
      "Train size: [400] hidden size: [848] trial: 32, train_loss: 0.388171, test loss: 0.954793, bias2: 0.44511985778808594, variance: 0.5096726417541504\n",
      "Train size: [400] hidden size: [848] trial: 33, train_loss: 0.389328, test loss: 0.956322, bias2: 0.44436073303222656, variance: 0.5119608044624329\n",
      "Train size: [400] hidden size: [848] trial: 34, train_loss: 0.390994, test loss: 0.957397, bias2: 0.4449789524078369, variance: 0.5124176144599915\n",
      "Train size: [400] hidden size: [848] trial: 35, train_loss: 0.390172, test loss: 0.957706, bias2: 0.4457130432128906, variance: 0.5119926333427429\n",
      "Train size: [400] hidden size: [848] trial: 36, train_loss: 0.389245, test loss: 0.958348, bias2: 0.44617146253585815, variance: 0.5121763348579407\n",
      "Train size: [400] hidden size: [848] trial: 37, train_loss: 0.387391, test loss: 0.959481, bias2: 0.4479629397392273, variance: 0.5115182399749756\n",
      "Train size: [400] hidden size: [848] trial: 38, train_loss: 0.388019, test loss: 0.960125, bias2: 0.4464513063430786, variance: 0.5136739611625671\n",
      "Train size: [400] hidden size: [848] trial: 39, train_loss: 0.387299, test loss: 0.960508, bias2: 0.4461376667022705, variance: 0.5143701434135437\n",
      "Train size: [400] hidden size: [848] trial: 40, train_loss: 0.386925, test loss: 0.960157, bias2: 0.447046160697937, variance: 0.5131108164787292\n",
      "Train size: [400] hidden size: [848] trial: 41, train_loss: 0.387554, test loss: 0.960402, bias2: 0.44722485542297363, variance: 0.5131773352622986\n",
      "Train size: [400] hidden size: [848] trial: 42, train_loss: 0.388095, test loss: 0.961728, bias2: 0.44744056463241577, variance: 0.5142871141433716\n",
      "Train size: [400] hidden size: [848] trial: 43, train_loss: 0.390109, test loss: 0.962372, bias2: 0.44675928354263306, variance: 0.5156129598617554\n",
      "Train size: [400] hidden size: [848] trial: 44, train_loss: 0.389443, test loss: 0.960015, bias2: 0.44529300928115845, variance: 0.5147218108177185\n",
      "Train size: [400] hidden size: [848] trial: 45, train_loss: 0.389285, test loss: 0.958889, bias2: 0.44450563192367554, variance: 0.5143836140632629\n",
      "Train size: [400] hidden size: [848] trial: 46, train_loss: 0.389330, test loss: 0.957264, bias2: 0.4432891607284546, variance: 0.5139745473861694\n",
      "Train size: [400] hidden size: [848] trial: 47, train_loss: 0.389520, test loss: 0.954893, bias2: 0.4414975047111511, variance: 0.5133953094482422\n",
      "Train size: [400] hidden size: [848] trial: 48, train_loss: 0.388587, test loss: 0.953134, bias2: 0.4403420090675354, variance: 0.51279217004776\n",
      "Train size: [400] hidden size: [848] trial: 49, train_loss: 0.388505, test loss: 0.952700, bias2: 0.43995386362075806, variance: 0.5127463936805725\n",
      "##################################################\n",
      "Train size: [400] hidden size: [977] trial: 0, train_loss: 0.381814, test loss: 0.903353, bias2: 0.9033526182174683, variance: 3.5032932110823367e-09\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [977] trial: 1, train_loss: 0.369968, test loss: 0.917230, bias2: 0.6564136743545532, variance: 0.2608166038990021\n",
      "Train size: [400] hidden size: [977] trial: 2, train_loss: 0.347840, test loss: 0.909076, bias2: 0.5621342062950134, variance: 0.34694182872772217\n",
      "Train size: [400] hidden size: [977] trial: 3, train_loss: 0.341026, test loss: 0.890544, bias2: 0.5070899724960327, variance: 0.38345369696617126\n",
      "Train size: [400] hidden size: [977] trial: 4, train_loss: 0.354605, test loss: 0.898599, bias2: 0.4863715171813965, variance: 0.4122275710105896\n",
      "Train size: [400] hidden size: [977] trial: 5, train_loss: 0.352716, test loss: 0.897182, bias2: 0.4680178165435791, variance: 0.4291646480560303\n",
      "Train size: [400] hidden size: [977] trial: 6, train_loss: 0.353115, test loss: 0.914270, bias2: 0.47112753987312317, variance: 0.4431420862674713\n",
      "Train size: [400] hidden size: [977] trial: 7, train_loss: 0.354395, test loss: 0.916614, bias2: 0.4652214050292969, variance: 0.4513930678367615\n",
      "Train size: [400] hidden size: [977] trial: 8, train_loss: 0.353125, test loss: 0.917829, bias2: 0.46529513597488403, variance: 0.4525333642959595\n",
      "Train size: [400] hidden size: [977] trial: 9, train_loss: 0.352292, test loss: 0.915156, bias2: 0.46141529083251953, variance: 0.4537409543991089\n",
      "Train size: [400] hidden size: [977] trial: 10, train_loss: 0.350278, test loss: 0.911513, bias2: 0.45596662163734436, variance: 0.45554664731025696\n",
      "Train size: [400] hidden size: [977] trial: 11, train_loss: 0.350382, test loss: 0.910127, bias2: 0.44680702686309814, variance: 0.46332043409347534\n",
      "Train size: [400] hidden size: [977] trial: 12, train_loss: 0.351385, test loss: 0.909800, bias2: 0.44785159826278687, variance: 0.4619484543800354\n",
      "Train size: [400] hidden size: [977] trial: 13, train_loss: 0.351020, test loss: 0.913453, bias2: 0.4496210813522339, variance: 0.4638316035270691\n",
      "Train size: [400] hidden size: [977] trial: 14, train_loss: 0.347730, test loss: 0.914492, bias2: 0.4496024250984192, variance: 0.4648895859718323\n",
      "Train size: [400] hidden size: [977] trial: 15, train_loss: 0.347627, test loss: 0.914686, bias2: 0.4511902332305908, variance: 0.463495671749115\n",
      "Train size: [400] hidden size: [977] trial: 16, train_loss: 0.347072, test loss: 0.912286, bias2: 0.4475584030151367, variance: 0.464727520942688\n",
      "Train size: [400] hidden size: [977] trial: 17, train_loss: 0.346398, test loss: 0.911186, bias2: 0.4439389407634735, variance: 0.4672469198703766\n",
      "Train size: [400] hidden size: [977] trial: 18, train_loss: 0.349520, test loss: 0.907560, bias2: 0.439227819442749, variance: 0.46833258867263794\n",
      "Train size: [400] hidden size: [977] trial: 19, train_loss: 0.348206, test loss: 0.911075, bias2: 0.4396953284740448, variance: 0.4713801443576813\n",
      "Train size: [400] hidden size: [977] trial: 20, train_loss: 0.350208, test loss: 0.914493, bias2: 0.4405219852924347, variance: 0.47397080063819885\n",
      "Train size: [400] hidden size: [977] trial: 21, train_loss: 0.348428, test loss: 0.911206, bias2: 0.4368305504322052, variance: 0.4743753969669342\n",
      "Train size: [400] hidden size: [977] trial: 22, train_loss: 0.347385, test loss: 0.910627, bias2: 0.4351300895214081, variance: 0.47549644112586975\n",
      "Train size: [400] hidden size: [977] trial: 23, train_loss: 0.348935, test loss: 0.910391, bias2: 0.4308667480945587, variance: 0.4795243442058563\n",
      "Train size: [400] hidden size: [977] trial: 24, train_loss: 0.347810, test loss: 0.910709, bias2: 0.4281949996948242, variance: 0.4825136661529541\n",
      "Train size: [400] hidden size: [977] trial: 25, train_loss: 0.346785, test loss: 0.910544, bias2: 0.4276118278503418, variance: 0.4829319715499878\n",
      "Train size: [400] hidden size: [977] trial: 26, train_loss: 0.347510, test loss: 0.913230, bias2: 0.4285549819469452, variance: 0.4846750795841217\n",
      "Train size: [400] hidden size: [977] trial: 27, train_loss: 0.349342, test loss: 0.914976, bias2: 0.42794090509414673, variance: 0.48703473806381226\n",
      "Train size: [400] hidden size: [977] trial: 28, train_loss: 0.350361, test loss: 0.917500, bias2: 0.4275355339050293, variance: 0.48996496200561523\n",
      "Train size: [400] hidden size: [977] trial: 29, train_loss: 0.349419, test loss: 0.910386, bias2: 0.4222051501274109, variance: 0.48818057775497437\n",
      "Train size: [400] hidden size: [977] trial: 30, train_loss: 0.351435, test loss: 0.909007, bias2: 0.4205189645290375, variance: 0.48848840594291687\n",
      "Train size: [400] hidden size: [977] trial: 31, train_loss: 0.351105, test loss: 0.909564, bias2: 0.4204190969467163, variance: 0.489144504070282\n",
      "Train size: [400] hidden size: [977] trial: 32, train_loss: 0.350322, test loss: 0.908618, bias2: 0.41644468903541565, variance: 0.4921731650829315\n",
      "Train size: [400] hidden size: [977] trial: 33, train_loss: 0.349214, test loss: 0.908347, bias2: 0.41545671224594116, variance: 0.4928898215293884\n",
      "Train size: [400] hidden size: [977] trial: 34, train_loss: 0.348600, test loss: 0.906669, bias2: 0.4126634895801544, variance: 0.49400559067726135\n",
      "Train size: [400] hidden size: [977] trial: 35, train_loss: 0.348797, test loss: 0.908737, bias2: 0.41380101442337036, variance: 0.49493616819381714\n",
      "Train size: [400] hidden size: [977] trial: 36, train_loss: 0.347886, test loss: 0.908609, bias2: 0.4117983281612396, variance: 0.4968101680278778\n",
      "Train size: [400] hidden size: [977] trial: 37, train_loss: 0.347103, test loss: 0.909589, bias2: 0.4122634530067444, variance: 0.4973260164260864\n",
      "Train size: [400] hidden size: [977] trial: 38, train_loss: 0.347973, test loss: 0.910164, bias2: 0.411312460899353, variance: 0.4988519549369812\n",
      "Train size: [400] hidden size: [977] trial: 39, train_loss: 0.346842, test loss: 0.910795, bias2: 0.4116600751876831, variance: 0.4991353750228882\n",
      "Train size: [400] hidden size: [977] trial: 40, train_loss: 0.346657, test loss: 0.914167, bias2: 0.41415172815322876, variance: 0.5000147819519043\n",
      "Train size: [400] hidden size: [977] trial: 41, train_loss: 0.347500, test loss: 0.913542, bias2: 0.4135468304157257, variance: 0.4999949634075165\n",
      "Train size: [400] hidden size: [977] trial: 42, train_loss: 0.347564, test loss: 0.915456, bias2: 0.4154289960861206, variance: 0.500026524066925\n",
      "Train size: [400] hidden size: [977] trial: 43, train_loss: 0.347090, test loss: 0.915526, bias2: 0.4151408076286316, variance: 0.5003851056098938\n",
      "Train size: [400] hidden size: [977] trial: 44, train_loss: 0.347979, test loss: 0.914169, bias2: 0.41217589378356934, variance: 0.5019927024841309\n",
      "Train size: [400] hidden size: [977] trial: 45, train_loss: 0.347907, test loss: 0.912913, bias2: 0.411044716835022, variance: 0.5018687844276428\n",
      "Train size: [400] hidden size: [977] trial: 46, train_loss: 0.347736, test loss: 0.913234, bias2: 0.4115660786628723, variance: 0.5016675591468811\n",
      "Train size: [400] hidden size: [977] trial: 47, train_loss: 0.348887, test loss: 0.913161, bias2: 0.41016680002212524, variance: 0.5029937624931335\n",
      "Train size: [400] hidden size: [977] trial: 48, train_loss: 0.349207, test loss: 0.912286, bias2: 0.408115029335022, variance: 0.5041713714599609\n",
      "Train size: [400] hidden size: [977] trial: 49, train_loss: 0.349425, test loss: 0.912310, bias2: 0.4084773063659668, variance: 0.5038328170776367\n",
      "##################################################\n",
      "Train size: [400] hidden size: [1125] trial: 0, train_loss: 0.272387, test loss: 0.851631, bias2: 0.8516307473182678, variance: 0.0\n",
      "Train size: [400] hidden size: [1125] trial: 1, train_loss: 0.295977, test loss: 0.859932, bias2: 0.6126154661178589, variance: 0.2473161667585373\n",
      "Train size: [400] hidden size: [1125] trial: 2, train_loss: 0.287036, test loss: 0.854227, bias2: 0.5430636405944824, variance: 0.31116369366645813\n",
      "Train size: [400] hidden size: [1125] trial: 3, train_loss: 0.301307, test loss: 0.855735, bias2: 0.48482921719551086, variance: 0.37090596556663513\n",
      "Train size: [400] hidden size: [1125] trial: 4, train_loss: 0.304060, test loss: 0.871761, bias2: 0.4695582091808319, variance: 0.4022023379802704\n",
      "Train size: [400] hidden size: [1125] trial: 5, train_loss: 0.305127, test loss: 0.866448, bias2: 0.44890448451042175, variance: 0.4175432026386261\n",
      "Train size: [400] hidden size: [1125] trial: 6, train_loss: 0.308465, test loss: 0.868643, bias2: 0.4440974295139313, variance: 0.424545556306839\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [1125] trial: 7, train_loss: 0.311954, test loss: 0.878500, bias2: 0.44880935549736023, variance: 0.42969104647636414\n",
      "Train size: [400] hidden size: [1125] trial: 8, train_loss: 0.311203, test loss: 0.876481, bias2: 0.44056272506713867, variance: 0.4359182119369507\n",
      "Train size: [400] hidden size: [1125] trial: 9, train_loss: 0.306864, test loss: 0.874387, bias2: 0.4382789731025696, variance: 0.436107873916626\n",
      "Train size: [400] hidden size: [1125] trial: 10, train_loss: 0.308124, test loss: 0.879383, bias2: 0.4355563223361969, variance: 0.44382670521736145\n",
      "Train size: [400] hidden size: [1125] trial: 11, train_loss: 0.309084, test loss: 0.880316, bias2: 0.4292484223842621, variance: 0.45106759667396545\n",
      "Train size: [400] hidden size: [1125] trial: 12, train_loss: 0.311030, test loss: 0.881556, bias2: 0.4237060844898224, variance: 0.45784977078437805\n",
      "Train size: [400] hidden size: [1125] trial: 13, train_loss: 0.311281, test loss: 0.880264, bias2: 0.4197635352611542, variance: 0.460500031709671\n",
      "Train size: [400] hidden size: [1125] trial: 14, train_loss: 0.312518, test loss: 0.880835, bias2: 0.4185597598552704, variance: 0.4622757136821747\n",
      "Train size: [400] hidden size: [1125] trial: 15, train_loss: 0.314037, test loss: 0.881758, bias2: 0.41357648372650146, variance: 0.4681816101074219\n",
      "Train size: [400] hidden size: [1125] trial: 16, train_loss: 0.311804, test loss: 0.877213, bias2: 0.40928080677986145, variance: 0.4679320752620697\n",
      "Train size: [400] hidden size: [1125] trial: 17, train_loss: 0.311128, test loss: 0.875107, bias2: 0.40568915009498596, variance: 0.46941813826560974\n",
      "Train size: [400] hidden size: [1125] trial: 18, train_loss: 0.311964, test loss: 0.874583, bias2: 0.40644118189811707, variance: 0.46814224123954773\n",
      "Train size: [400] hidden size: [1125] trial: 19, train_loss: 0.310923, test loss: 0.875477, bias2: 0.4079078137874603, variance: 0.46756884455680847\n",
      "Train size: [400] hidden size: [1125] trial: 20, train_loss: 0.311007, test loss: 0.875651, bias2: 0.4095473289489746, variance: 0.4661039113998413\n",
      "Train size: [400] hidden size: [1125] trial: 21, train_loss: 0.315456, test loss: 0.877737, bias2: 0.4106425344944, variance: 0.4670943319797516\n",
      "Train size: [400] hidden size: [1125] trial: 22, train_loss: 0.316939, test loss: 0.876786, bias2: 0.40834325551986694, variance: 0.46844279766082764\n",
      "Train size: [400] hidden size: [1125] trial: 23, train_loss: 0.317567, test loss: 0.877442, bias2: 0.4042525887489319, variance: 0.47318947315216064\n",
      "Train size: [400] hidden size: [1125] trial: 24, train_loss: 0.317105, test loss: 0.879477, bias2: 0.40600043535232544, variance: 0.4734768271446228\n",
      "Train size: [400] hidden size: [1125] trial: 25, train_loss: 0.315668, test loss: 0.876097, bias2: 0.4037775993347168, variance: 0.4723193645477295\n",
      "Train size: [400] hidden size: [1125] trial: 26, train_loss: 0.315666, test loss: 0.874635, bias2: 0.4025845229625702, variance: 0.47205087542533875\n",
      "Train size: [400] hidden size: [1125] trial: 27, train_loss: 0.316079, test loss: 0.873538, bias2: 0.4010481834411621, variance: 0.47248971462249756\n",
      "Train size: [400] hidden size: [1125] trial: 28, train_loss: 0.316009, test loss: 0.875016, bias2: 0.40149539709091187, variance: 0.4735209345817566\n",
      "Train size: [400] hidden size: [1125] trial: 29, train_loss: 0.315678, test loss: 0.871540, bias2: 0.399715393781662, variance: 0.47182443737983704\n",
      "Train size: [400] hidden size: [1125] trial: 30, train_loss: 0.317162, test loss: 0.870633, bias2: 0.3983515501022339, variance: 0.47228139638900757\n",
      "Train size: [400] hidden size: [1125] trial: 31, train_loss: 0.317002, test loss: 0.869935, bias2: 0.39720916748046875, variance: 0.47272568941116333\n",
      "Train size: [400] hidden size: [1125] trial: 32, train_loss: 0.317974, test loss: 0.870620, bias2: 0.3970334529876709, variance: 0.4735862612724304\n",
      "Train size: [400] hidden size: [1125] trial: 33, train_loss: 0.318487, test loss: 0.871177, bias2: 0.3975101709365845, variance: 0.4736669063568115\n",
      "Train size: [400] hidden size: [1125] trial: 34, train_loss: 0.318462, test loss: 0.871078, bias2: 0.3961296081542969, variance: 0.4749481678009033\n",
      "Train size: [400] hidden size: [1125] trial: 35, train_loss: 0.319004, test loss: 0.872089, bias2: 0.3977813124656677, variance: 0.4743078947067261\n",
      "Train size: [400] hidden size: [1125] trial: 36, train_loss: 0.318280, test loss: 0.872969, bias2: 0.3986530900001526, variance: 0.4743156433105469\n",
      "Train size: [400] hidden size: [1125] trial: 37, train_loss: 0.317908, test loss: 0.872157, bias2: 0.39826634526252747, variance: 0.47389063239097595\n",
      "Train size: [400] hidden size: [1125] trial: 38, train_loss: 0.317770, test loss: 0.873395, bias2: 0.3988479673862457, variance: 0.47454723715782166\n",
      "Train size: [400] hidden size: [1125] trial: 39, train_loss: 0.318630, test loss: 0.876665, bias2: 0.4005679488182068, variance: 0.4760974049568176\n",
      "Train size: [400] hidden size: [1125] trial: 40, train_loss: 0.318616, test loss: 0.873413, bias2: 0.39878177642822266, variance: 0.47463077306747437\n",
      "Train size: [400] hidden size: [1125] trial: 41, train_loss: 0.318878, test loss: 0.875153, bias2: 0.3996026813983917, variance: 0.4755503237247467\n",
      "Train size: [400] hidden size: [1125] trial: 42, train_loss: 0.318774, test loss: 0.874111, bias2: 0.3983880579471588, variance: 0.47572287917137146\n",
      "Train size: [400] hidden size: [1125] trial: 43, train_loss: 0.318876, test loss: 0.873080, bias2: 0.39650699496269226, variance: 0.47657325863838196\n",
      "Train size: [400] hidden size: [1125] trial: 44, train_loss: 0.319307, test loss: 0.872642, bias2: 0.39658012986183167, variance: 0.4760614335536957\n",
      "Train size: [400] hidden size: [1125] trial: 45, train_loss: 0.319652, test loss: 0.872996, bias2: 0.3964677155017853, variance: 0.47652873396873474\n",
      "Train size: [400] hidden size: [1125] trial: 46, train_loss: 0.319338, test loss: 0.874501, bias2: 0.39658334851264954, variance: 0.47791799902915955\n",
      "Train size: [400] hidden size: [1125] trial: 47, train_loss: 0.319240, test loss: 0.874458, bias2: 0.39762231707572937, variance: 0.47683581709861755\n",
      "Train size: [400] hidden size: [1125] trial: 48, train_loss: 0.319373, test loss: 0.877176, bias2: 0.3984839916229248, variance: 0.4786922335624695\n",
      "Train size: [400] hidden size: [1125] trial: 49, train_loss: 0.320857, test loss: 0.878207, bias2: 0.39882877469062805, variance: 0.47937801480293274\n",
      "##################################################\n",
      "Train size: [400] hidden size: [1295] trial: 0, train_loss: 0.340793, test loss: 0.836018, bias2: 0.8360180258750916, variance: 3.8925479506346505e-10\n",
      "Train size: [400] hidden size: [1295] trial: 1, train_loss: 0.306912, test loss: 0.825858, bias2: 0.5983694791793823, variance: 0.22748808562755585\n",
      "Train size: [400] hidden size: [1295] trial: 2, train_loss: 0.291687, test loss: 0.863351, bias2: 0.5453646183013916, variance: 0.31798669695854187\n",
      "Train size: [400] hidden size: [1295] trial: 3, train_loss: 0.281595, test loss: 0.856477, bias2: 0.5069512128829956, variance: 0.3495261073112488\n",
      "Train size: [400] hidden size: [1295] trial: 4, train_loss: 0.280878, test loss: 0.861035, bias2: 0.48761042952537537, variance: 0.37342438101768494\n",
      "Train size: [400] hidden size: [1295] trial: 5, train_loss: 0.285021, test loss: 0.859735, bias2: 0.46312734484672546, variance: 0.39660772681236267\n",
      "Train size: [400] hidden size: [1295] trial: 6, train_loss: 0.282669, test loss: 0.856781, bias2: 0.4455138146877289, variance: 0.4112667739391327\n",
      "Train size: [400] hidden size: [1295] trial: 7, train_loss: 0.280629, test loss: 0.851360, bias2: 0.4415977895259857, variance: 0.4097622334957123\n",
      "Train size: [400] hidden size: [1295] trial: 8, train_loss: 0.278812, test loss: 0.848006, bias2: 0.4348408579826355, variance: 0.4131649136543274\n",
      "Train size: [400] hidden size: [1295] trial: 9, train_loss: 0.279607, test loss: 0.845848, bias2: 0.427432656288147, variance: 0.4184156060218811\n",
      "Train size: [400] hidden size: [1295] trial: 10, train_loss: 0.281899, test loss: 0.844433, bias2: 0.4203910529613495, variance: 0.42404189705848694\n",
      "Train size: [400] hidden size: [1295] trial: 11, train_loss: 0.278814, test loss: 0.847410, bias2: 0.4178721308708191, variance: 0.4295382499694824\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [1295] trial: 12, train_loss: 0.277064, test loss: 0.847119, bias2: 0.4182511866092682, variance: 0.42886772751808167\n",
      "Train size: [400] hidden size: [1295] trial: 13, train_loss: 0.277281, test loss: 0.847705, bias2: 0.41342127323150635, variance: 0.4342838525772095\n",
      "Train size: [400] hidden size: [1295] trial: 14, train_loss: 0.277449, test loss: 0.847885, bias2: 0.4095560908317566, variance: 0.4383288025856018\n",
      "Train size: [400] hidden size: [1295] trial: 15, train_loss: 0.278820, test loss: 0.847687, bias2: 0.40691980719566345, variance: 0.44076719880104065\n",
      "Train size: [400] hidden size: [1295] trial: 16, train_loss: 0.279601, test loss: 0.848852, bias2: 0.4075709879398346, variance: 0.4412810504436493\n",
      "Train size: [400] hidden size: [1295] trial: 17, train_loss: 0.279942, test loss: 0.850782, bias2: 0.4094621539115906, variance: 0.4413200616836548\n",
      "Train size: [400] hidden size: [1295] trial: 18, train_loss: 0.281611, test loss: 0.850747, bias2: 0.40566185116767883, variance: 0.4450855553150177\n",
      "Train size: [400] hidden size: [1295] trial: 19, train_loss: 0.284740, test loss: 0.849816, bias2: 0.4010866582393646, variance: 0.44872912764549255\n",
      "Train size: [400] hidden size: [1295] trial: 20, train_loss: 0.284047, test loss: 0.847880, bias2: 0.3998427093029022, variance: 0.44803765416145325\n",
      "Train size: [400] hidden size: [1295] trial: 21, train_loss: 0.282437, test loss: 0.851302, bias2: 0.4050174355506897, variance: 0.44628435373306274\n",
      "Train size: [400] hidden size: [1295] trial: 22, train_loss: 0.284339, test loss: 0.854238, bias2: 0.40512746572494507, variance: 0.4491102695465088\n",
      "Train size: [400] hidden size: [1295] trial: 23, train_loss: 0.285730, test loss: 0.853711, bias2: 0.40514716506004333, variance: 0.4485642611980438\n",
      "Train size: [400] hidden size: [1295] trial: 24, train_loss: 0.285875, test loss: 0.854535, bias2: 0.40580540895462036, variance: 0.44872939586639404\n",
      "Train size: [400] hidden size: [1295] trial: 25, train_loss: 0.285403, test loss: 0.852802, bias2: 0.40218234062194824, variance: 0.4506199359893799\n",
      "Train size: [400] hidden size: [1295] trial: 26, train_loss: 0.284534, test loss: 0.850490, bias2: 0.4001867175102234, variance: 0.4503030776977539\n",
      "Train size: [400] hidden size: [1295] trial: 27, train_loss: 0.283936, test loss: 0.848560, bias2: 0.3991595208644867, variance: 0.449400395154953\n",
      "Train size: [400] hidden size: [1295] trial: 28, train_loss: 0.285268, test loss: 0.848618, bias2: 0.39724859595298767, variance: 0.4513690769672394\n",
      "Train size: [400] hidden size: [1295] trial: 29, train_loss: 0.283825, test loss: 0.845152, bias2: 0.3957837224006653, variance: 0.4493684768676758\n",
      "Train size: [400] hidden size: [1295] trial: 30, train_loss: 0.283650, test loss: 0.843171, bias2: 0.3934941589832306, variance: 0.4496772587299347\n",
      "Train size: [400] hidden size: [1295] trial: 31, train_loss: 0.283691, test loss: 0.844875, bias2: 0.3946768343448639, variance: 0.4501986801624298\n",
      "Train size: [400] hidden size: [1295] trial: 32, train_loss: 0.283788, test loss: 0.844952, bias2: 0.39409318566322327, variance: 0.45085880160331726\n",
      "Train size: [400] hidden size: [1295] trial: 33, train_loss: 0.283288, test loss: 0.843412, bias2: 0.3912539482116699, variance: 0.45215821266174316\n",
      "Train size: [400] hidden size: [1295] trial: 34, train_loss: 0.283704, test loss: 0.842881, bias2: 0.39139971137046814, variance: 0.45148155093193054\n",
      "Train size: [400] hidden size: [1295] trial: 35, train_loss: 0.283742, test loss: 0.841715, bias2: 0.39061009883880615, variance: 0.45110464096069336\n",
      "Train size: [400] hidden size: [1295] trial: 36, train_loss: 0.283392, test loss: 0.842778, bias2: 0.3909784257411957, variance: 0.45179983973503113\n",
      "Train size: [400] hidden size: [1295] trial: 37, train_loss: 0.283029, test loss: 0.841482, bias2: 0.3906444311141968, variance: 0.4508371949195862\n",
      "Train size: [400] hidden size: [1295] trial: 38, train_loss: 0.283844, test loss: 0.843575, bias2: 0.3909928500652313, variance: 0.45258232951164246\n",
      "Train size: [400] hidden size: [1295] trial: 39, train_loss: 0.283941, test loss: 0.844249, bias2: 0.38978928327560425, variance: 0.45445936918258667\n",
      "Train size: [400] hidden size: [1295] trial: 40, train_loss: 0.283625, test loss: 0.844108, bias2: 0.39028069376945496, variance: 0.45382705330848694\n",
      "Train size: [400] hidden size: [1295] trial: 41, train_loss: 0.284937, test loss: 0.842936, bias2: 0.3887903392314911, variance: 0.45414599776268005\n",
      "Train size: [400] hidden size: [1295] trial: 42, train_loss: 0.285320, test loss: 0.844297, bias2: 0.38941264152526855, variance: 0.45488423109054565\n",
      "Train size: [400] hidden size: [1295] trial: 43, train_loss: 0.286044, test loss: 0.845483, bias2: 0.3902947008609772, variance: 0.4551885426044464\n",
      "Train size: [400] hidden size: [1295] trial: 44, train_loss: 0.285348, test loss: 0.845244, bias2: 0.3906400799751282, variance: 0.45460426807403564\n",
      "Train size: [400] hidden size: [1295] trial: 45, train_loss: 0.284743, test loss: 0.845738, bias2: 0.3910122811794281, variance: 0.4547257125377655\n",
      "Train size: [400] hidden size: [1295] trial: 46, train_loss: 0.285296, test loss: 0.845299, bias2: 0.39110398292541504, variance: 0.45419466495513916\n",
      "Train size: [400] hidden size: [1295] trial: 47, train_loss: 0.284729, test loss: 0.843508, bias2: 0.39063239097595215, variance: 0.4528753161430359\n",
      "Train size: [400] hidden size: [1295] trial: 48, train_loss: 0.284094, test loss: 0.845078, bias2: 0.3920718729496002, variance: 0.4530063569545746\n",
      "Train size: [400] hidden size: [1295] trial: 49, train_loss: 0.283453, test loss: 0.844642, bias2: 0.3922737240791321, variance: 0.45236796140670776\n",
      "##################################################\n",
      "Train size: [400] hidden size: [1491] trial: 0, train_loss: 0.300733, test loss: 0.780454, bias2: 0.7804537415504456, variance: -4.281802912231569e-09\n",
      "Train size: [400] hidden size: [1491] trial: 1, train_loss: 0.277786, test loss: 0.797334, bias2: 0.5663978457450867, variance: 0.2309359312057495\n",
      "Train size: [400] hidden size: [1491] trial: 2, train_loss: 0.285351, test loss: 0.803079, bias2: 0.48240718245506287, variance: 0.3206721842288971\n",
      "Train size: [400] hidden size: [1491] trial: 3, train_loss: 0.278151, test loss: 0.797533, bias2: 0.44727781414985657, variance: 0.3502548038959503\n",
      "Train size: [400] hidden size: [1491] trial: 4, train_loss: 0.274051, test loss: 0.808614, bias2: 0.4371342957019806, variance: 0.37147942185401917\n",
      "Train size: [400] hidden size: [1491] trial: 5, train_loss: 0.277616, test loss: 0.809158, bias2: 0.4232647716999054, variance: 0.3858936131000519\n",
      "Train size: [400] hidden size: [1491] trial: 6, train_loss: 0.282547, test loss: 0.814776, bias2: 0.41346612572669983, variance: 0.40131011605262756\n",
      "Train size: [400] hidden size: [1491] trial: 7, train_loss: 0.282889, test loss: 0.812445, bias2: 0.4054643213748932, variance: 0.4069805443286896\n",
      "Train size: [400] hidden size: [1491] trial: 8, train_loss: 0.276550, test loss: 0.811360, bias2: 0.3982071280479431, variance: 0.4131527543067932\n",
      "Train size: [400] hidden size: [1491] trial: 9, train_loss: 0.273445, test loss: 0.814810, bias2: 0.39957353472709656, variance: 0.41523608565330505\n",
      "Train size: [400] hidden size: [1491] trial: 10, train_loss: 0.268573, test loss: 0.816991, bias2: 0.40183767676353455, variance: 0.4151534140110016\n",
      "Train size: [400] hidden size: [1491] trial: 11, train_loss: 0.268447, test loss: 0.814926, bias2: 0.39883601665496826, variance: 0.4160900115966797\n",
      "Train size: [400] hidden size: [1491] trial: 12, train_loss: 0.267335, test loss: 0.814656, bias2: 0.3957960605621338, variance: 0.41885989904403687\n",
      "Train size: [400] hidden size: [1491] trial: 13, train_loss: 0.267332, test loss: 0.818594, bias2: 0.39635196328163147, variance: 0.42224153876304626\n",
      "Train size: [400] hidden size: [1491] trial: 14, train_loss: 0.266276, test loss: 0.818471, bias2: 0.393381267786026, variance: 0.42508968710899353\n",
      "Train size: [400] hidden size: [1491] trial: 15, train_loss: 0.265208, test loss: 0.819354, bias2: 0.3932991921901703, variance: 0.42605456709861755\n",
      "Train size: [400] hidden size: [1491] trial: 16, train_loss: 0.266049, test loss: 0.820976, bias2: 0.392715185880661, variance: 0.42826059460639954\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [1491] trial: 17, train_loss: 0.265905, test loss: 0.821401, bias2: 0.3903369903564453, variance: 0.431064248085022\n",
      "Train size: [400] hidden size: [1491] trial: 18, train_loss: 0.265912, test loss: 0.819479, bias2: 0.38815873861312866, variance: 0.4313204288482666\n",
      "Train size: [400] hidden size: [1491] trial: 19, train_loss: 0.267913, test loss: 0.815898, bias2: 0.3833259642124176, variance: 0.432571679353714\n",
      "Train size: [400] hidden size: [1491] trial: 20, train_loss: 0.266533, test loss: 0.813796, bias2: 0.38153958320617676, variance: 0.43225663900375366\n",
      "Train size: [400] hidden size: [1491] trial: 21, train_loss: 0.265413, test loss: 0.815887, bias2: 0.3830055594444275, variance: 0.432881236076355\n",
      "Train size: [400] hidden size: [1491] trial: 22, train_loss: 0.267030, test loss: 0.814660, bias2: 0.37888243794441223, variance: 0.4357771575450897\n",
      "Train size: [400] hidden size: [1491] trial: 23, train_loss: 0.267155, test loss: 0.815423, bias2: 0.3808553218841553, variance: 0.434567391872406\n",
      "Train size: [400] hidden size: [1491] trial: 24, train_loss: 0.267344, test loss: 0.816767, bias2: 0.3824525475502014, variance: 0.4343148469924927\n",
      "Train size: [400] hidden size: [1491] trial: 25, train_loss: 0.268539, test loss: 0.817014, bias2: 0.3789997100830078, variance: 0.4380147457122803\n",
      "Train size: [400] hidden size: [1491] trial: 26, train_loss: 0.268402, test loss: 0.819592, bias2: 0.38064005970954895, variance: 0.4389517605304718\n",
      "Train size: [400] hidden size: [1491] trial: 27, train_loss: 0.268366, test loss: 0.821314, bias2: 0.3825538754463196, variance: 0.43876057863235474\n",
      "Train size: [400] hidden size: [1491] trial: 28, train_loss: 0.268210, test loss: 0.823955, bias2: 0.384307861328125, variance: 0.43964684009552\n",
      "Train size: [400] hidden size: [1491] trial: 29, train_loss: 0.268016, test loss: 0.822996, bias2: 0.38454678654670715, variance: 0.43844929337501526\n",
      "Train size: [400] hidden size: [1491] trial: 30, train_loss: 0.267248, test loss: 0.821608, bias2: 0.3841035068035126, variance: 0.4375046193599701\n",
      "Train size: [400] hidden size: [1491] trial: 31, train_loss: 0.267517, test loss: 0.823328, bias2: 0.38407838344573975, variance: 0.43924981355667114\n",
      "Train size: [400] hidden size: [1491] trial: 32, train_loss: 0.266218, test loss: 0.825020, bias2: 0.38676804304122925, variance: 0.43825191259384155\n",
      "Train size: [400] hidden size: [1491] trial: 33, train_loss: 0.266008, test loss: 0.825789, bias2: 0.38693273067474365, variance: 0.4388560652732849\n",
      "Train size: [400] hidden size: [1491] trial: 34, train_loss: 0.266521, test loss: 0.825260, bias2: 0.3845651149749756, variance: 0.4406946897506714\n",
      "Train size: [400] hidden size: [1491] trial: 35, train_loss: 0.264733, test loss: 0.825634, bias2: 0.3863082826137543, variance: 0.43932583928108215\n",
      "Train size: [400] hidden size: [1491] trial: 36, train_loss: 0.264706, test loss: 0.823730, bias2: 0.3844558298587799, variance: 0.4392746388912201\n",
      "Train size: [400] hidden size: [1491] trial: 37, train_loss: 0.264802, test loss: 0.822471, bias2: 0.383764386177063, variance: 0.43870657682418823\n",
      "Train size: [400] hidden size: [1491] trial: 38, train_loss: 0.266314, test loss: 0.821424, bias2: 0.3808439373970032, variance: 0.4405803680419922\n",
      "Train size: [400] hidden size: [1491] trial: 39, train_loss: 0.265519, test loss: 0.821696, bias2: 0.3819025158882141, variance: 0.43979305028915405\n",
      "Train size: [400] hidden size: [1491] trial: 40, train_loss: 0.265614, test loss: 0.821714, bias2: 0.3798738718032837, variance: 0.44183963537216187\n",
      "Train size: [400] hidden size: [1491] trial: 41, train_loss: 0.265522, test loss: 0.821481, bias2: 0.3799006938934326, variance: 0.4415803551673889\n",
      "Train size: [400] hidden size: [1491] trial: 42, train_loss: 0.266016, test loss: 0.820552, bias2: 0.378964900970459, variance: 0.4415872097015381\n",
      "Train size: [400] hidden size: [1491] trial: 43, train_loss: 0.266597, test loss: 0.820477, bias2: 0.37817350029945374, variance: 0.442303329706192\n",
      "Train size: [400] hidden size: [1491] trial: 44, train_loss: 0.267227, test loss: 0.820849, bias2: 0.3784825801849365, variance: 0.4423660635948181\n",
      "Train size: [400] hidden size: [1491] trial: 45, train_loss: 0.267290, test loss: 0.821841, bias2: 0.37898463010787964, variance: 0.4428562521934509\n",
      "Train size: [400] hidden size: [1491] trial: 46, train_loss: 0.266925, test loss: 0.819425, bias2: 0.37702512741088867, variance: 0.44239962100982666\n",
      "Train size: [400] hidden size: [1491] trial: 47, train_loss: 0.266567, test loss: 0.819336, bias2: 0.3772754371166229, variance: 0.4420609176158905\n",
      "Train size: [400] hidden size: [1491] trial: 48, train_loss: 0.266467, test loss: 0.820662, bias2: 0.3773064911365509, variance: 0.44335511326789856\n",
      "Train size: [400] hidden size: [1491] trial: 49, train_loss: 0.266323, test loss: 0.821916, bias2: 0.37808912992477417, variance: 0.44382667541503906\n",
      "##################################################\n",
      "Train size: [400] hidden size: [1717] trial: 0, train_loss: 0.234451, test loss: 0.807138, bias2: 0.807137668132782, variance: -2.3355288814030928e-09\n",
      "Train size: [400] hidden size: [1717] trial: 1, train_loss: 0.257214, test loss: 0.787286, bias2: 0.5619274377822876, variance: 0.22535841166973114\n",
      "Train size: [400] hidden size: [1717] trial: 2, train_loss: 0.259581, test loss: 0.765467, bias2: 0.468189001083374, variance: 0.29727816581726074\n",
      "Train size: [400] hidden size: [1717] trial: 3, train_loss: 0.250811, test loss: 0.792050, bias2: 0.45857661962509155, variance: 0.3334731459617615\n",
      "Train size: [400] hidden size: [1717] trial: 4, train_loss: 0.253575, test loss: 0.802845, bias2: 0.44044363498687744, variance: 0.36240124702453613\n",
      "Train size: [400] hidden size: [1717] trial: 5, train_loss: 0.253756, test loss: 0.798754, bias2: 0.4267352521419525, variance: 0.3720192015171051\n",
      "Train size: [400] hidden size: [1717] trial: 6, train_loss: 0.249295, test loss: 0.801542, bias2: 0.42379507422447205, variance: 0.37774714827537537\n",
      "Train size: [400] hidden size: [1717] trial: 7, train_loss: 0.246116, test loss: 0.800634, bias2: 0.4188741147518158, variance: 0.38176003098487854\n",
      "Train size: [400] hidden size: [1717] trial: 8, train_loss: 0.244752, test loss: 0.796162, bias2: 0.4142303466796875, variance: 0.3819320797920227\n",
      "Train size: [400] hidden size: [1717] trial: 9, train_loss: 0.246437, test loss: 0.798995, bias2: 0.4098150432109833, variance: 0.3891797959804535\n",
      "Train size: [400] hidden size: [1717] trial: 10, train_loss: 0.246953, test loss: 0.800902, bias2: 0.40244290232658386, variance: 0.39845892786979675\n",
      "Train size: [400] hidden size: [1717] trial: 11, train_loss: 0.247861, test loss: 0.799064, bias2: 0.3988398313522339, variance: 0.40022462606430054\n",
      "Train size: [400] hidden size: [1717] trial: 12, train_loss: 0.247732, test loss: 0.791812, bias2: 0.38617539405822754, variance: 0.4056370258331299\n",
      "Train size: [400] hidden size: [1717] trial: 13, train_loss: 0.251063, test loss: 0.796978, bias2: 0.38751596212387085, variance: 0.409462034702301\n",
      "Train size: [400] hidden size: [1717] trial: 14, train_loss: 0.253060, test loss: 0.796142, bias2: 0.3853070139884949, variance: 0.4108351469039917\n",
      "Train size: [400] hidden size: [1717] trial: 15, train_loss: 0.253154, test loss: 0.798842, bias2: 0.38538292050361633, variance: 0.41345903277397156\n",
      "Train size: [400] hidden size: [1717] trial: 16, train_loss: 0.250474, test loss: 0.798767, bias2: 0.3862604796886444, variance: 0.4125063717365265\n",
      "Train size: [400] hidden size: [1717] trial: 17, train_loss: 0.250558, test loss: 0.798444, bias2: 0.38525763154029846, variance: 0.413186639547348\n",
      "Train size: [400] hidden size: [1717] trial: 18, train_loss: 0.249528, test loss: 0.798774, bias2: 0.3839443624019623, variance: 0.41482964158058167\n",
      "Train size: [400] hidden size: [1717] trial: 19, train_loss: 0.251173, test loss: 0.798328, bias2: 0.3818023204803467, variance: 0.4165254235267639\n",
      "Train size: [400] hidden size: [1717] trial: 20, train_loss: 0.251860, test loss: 0.796750, bias2: 0.3812154531478882, variance: 0.41553449630737305\n",
      "Train size: [400] hidden size: [1717] trial: 21, train_loss: 0.250737, test loss: 0.795800, bias2: 0.3784174621105194, variance: 0.4173826277256012\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [1717] trial: 22, train_loss: 0.250883, test loss: 0.791710, bias2: 0.37610703706741333, variance: 0.41560304164886475\n",
      "Train size: [400] hidden size: [1717] trial: 23, train_loss: 0.250547, test loss: 0.793080, bias2: 0.3741644620895386, variance: 0.4189158082008362\n",
      "Train size: [400] hidden size: [1717] trial: 24, train_loss: 0.249579, test loss: 0.792033, bias2: 0.37306201457977295, variance: 0.41897112131118774\n",
      "Train size: [400] hidden size: [1717] trial: 25, train_loss: 0.249168, test loss: 0.790897, bias2: 0.37267589569091797, variance: 0.41822075843811035\n",
      "Train size: [400] hidden size: [1717] trial: 26, train_loss: 0.250255, test loss: 0.793097, bias2: 0.37362390756607056, variance: 0.4194726347923279\n",
      "Train size: [400] hidden size: [1717] trial: 27, train_loss: 0.249385, test loss: 0.797088, bias2: 0.37781479954719543, variance: 0.4192735254764557\n",
      "Train size: [400] hidden size: [1717] trial: 28, train_loss: 0.249882, test loss: 0.796652, bias2: 0.3766948878765106, variance: 0.4199574887752533\n",
      "Train size: [400] hidden size: [1717] trial: 29, train_loss: 0.248919, test loss: 0.797973, bias2: 0.37778013944625854, variance: 0.4201925992965698\n",
      "Train size: [400] hidden size: [1717] trial: 30, train_loss: 0.248756, test loss: 0.798509, bias2: 0.37843194603919983, variance: 0.4200766384601593\n",
      "Train size: [400] hidden size: [1717] trial: 31, train_loss: 0.248739, test loss: 0.800044, bias2: 0.3778073787689209, variance: 0.4222365617752075\n",
      "Train size: [400] hidden size: [1717] trial: 32, train_loss: 0.249003, test loss: 0.797655, bias2: 0.37598419189453125, variance: 0.42167043685913086\n",
      "Train size: [400] hidden size: [1717] trial: 33, train_loss: 0.249078, test loss: 0.796685, bias2: 0.37469300627708435, variance: 0.4219925105571747\n",
      "Train size: [400] hidden size: [1717] trial: 34, train_loss: 0.249327, test loss: 0.794404, bias2: 0.3730887472629547, variance: 0.42131564021110535\n",
      "Train size: [400] hidden size: [1717] trial: 35, train_loss: 0.250077, test loss: 0.795074, bias2: 0.3733290433883667, variance: 0.4217451214790344\n",
      "Train size: [400] hidden size: [1717] trial: 36, train_loss: 0.250428, test loss: 0.795180, bias2: 0.3732798099517822, variance: 0.4219006299972534\n",
      "Train size: [400] hidden size: [1717] trial: 37, train_loss: 0.249400, test loss: 0.793894, bias2: 0.37276455760002136, variance: 0.4211297333240509\n",
      "Train size: [400] hidden size: [1717] trial: 38, train_loss: 0.250145, test loss: 0.796095, bias2: 0.3727428913116455, variance: 0.42335259914398193\n",
      "Train size: [400] hidden size: [1717] trial: 39, train_loss: 0.249563, test loss: 0.794961, bias2: 0.37186577916145325, variance: 0.4230951964855194\n",
      "Train size: [400] hidden size: [1717] trial: 40, train_loss: 0.249627, test loss: 0.793968, bias2: 0.3707141876220703, variance: 0.4232534170150757\n",
      "Train size: [400] hidden size: [1717] trial: 41, train_loss: 0.249287, test loss: 0.794227, bias2: 0.3704591989517212, variance: 0.4237680435180664\n",
      "Train size: [400] hidden size: [1717] trial: 42, train_loss: 0.248984, test loss: 0.792617, bias2: 0.3687281608581543, variance: 0.42388880252838135\n",
      "Train size: [400] hidden size: [1717] trial: 43, train_loss: 0.248027, test loss: 0.793984, bias2: 0.3700474500656128, variance: 0.42393678426742554\n",
      "Train size: [400] hidden size: [1717] trial: 44, train_loss: 0.247126, test loss: 0.794299, bias2: 0.3708439767360687, variance: 0.4234550893306732\n",
      "Train size: [400] hidden size: [1717] trial: 45, train_loss: 0.246691, test loss: 0.795989, bias2: 0.3718937933444977, variance: 0.4240953028202057\n",
      "Train size: [400] hidden size: [1717] trial: 46, train_loss: 0.246577, test loss: 0.793883, bias2: 0.3701406419277191, variance: 0.4237422049045563\n",
      "Train size: [400] hidden size: [1717] trial: 47, train_loss: 0.246750, test loss: 0.793686, bias2: 0.36957186460494995, variance: 0.4241138696670532\n",
      "Train size: [400] hidden size: [1717] trial: 48, train_loss: 0.246611, test loss: 0.794222, bias2: 0.36910802125930786, variance: 0.42511433362960815\n",
      "Train size: [400] hidden size: [1717] trial: 49, train_loss: 0.246910, test loss: 0.794026, bias2: 0.36803165078163147, variance: 0.42599400877952576\n",
      "##################################################\n",
      "Train size: [400] hidden size: [1977] trial: 0, train_loss: 0.246621, test loss: 0.912076, bias2: 0.9120757579803467, variance: 4.6710577628061856e-09\n",
      "Train size: [400] hidden size: [1977] trial: 1, train_loss: 0.233296, test loss: 0.849697, bias2: 0.6293652057647705, variance: 0.22033177316188812\n",
      "Train size: [400] hidden size: [1977] trial: 2, train_loss: 0.229451, test loss: 0.824427, bias2: 0.5459834337234497, variance: 0.27844369411468506\n",
      "Train size: [400] hidden size: [1977] trial: 3, train_loss: 0.229713, test loss: 0.812606, bias2: 0.49597856402397156, variance: 0.3166278898715973\n",
      "Train size: [400] hidden size: [1977] trial: 4, train_loss: 0.224333, test loss: 0.799079, bias2: 0.4678935110569, variance: 0.3311857283115387\n",
      "Train size: [400] hidden size: [1977] trial: 5, train_loss: 0.228065, test loss: 0.796455, bias2: 0.4550021290779114, variance: 0.34145259857177734\n",
      "Train size: [400] hidden size: [1977] trial: 6, train_loss: 0.231096, test loss: 0.786268, bias2: 0.43390336632728577, variance: 0.352365106344223\n",
      "Train size: [400] hidden size: [1977] trial: 7, train_loss: 0.230422, test loss: 0.779955, bias2: 0.41976383328437805, variance: 0.3601911962032318\n",
      "Train size: [400] hidden size: [1977] trial: 8, train_loss: 0.231678, test loss: 0.781130, bias2: 0.419379860162735, variance: 0.3617500960826874\n",
      "Train size: [400] hidden size: [1977] trial: 9, train_loss: 0.230103, test loss: 0.771598, bias2: 0.40996259450912476, variance: 0.3616354465484619\n",
      "Train size: [400] hidden size: [1977] trial: 10, train_loss: 0.228261, test loss: 0.771960, bias2: 0.4073008894920349, variance: 0.36465948820114136\n",
      "Train size: [400] hidden size: [1977] trial: 11, train_loss: 0.225970, test loss: 0.777584, bias2: 0.4083611071109772, variance: 0.369223028421402\n",
      "Train size: [400] hidden size: [1977] trial: 12, train_loss: 0.224894, test loss: 0.777734, bias2: 0.4074464738368988, variance: 0.3702875077724457\n",
      "Train size: [400] hidden size: [1977] trial: 13, train_loss: 0.224807, test loss: 0.773809, bias2: 0.3998381197452545, variance: 0.37397047877311707\n",
      "Train size: [400] hidden size: [1977] trial: 14, train_loss: 0.225749, test loss: 0.771491, bias2: 0.3956504166126251, variance: 0.37584105134010315\n",
      "Train size: [400] hidden size: [1977] trial: 15, train_loss: 0.225875, test loss: 0.772590, bias2: 0.3969119191169739, variance: 0.3756778836250305\n",
      "Train size: [400] hidden size: [1977] trial: 16, train_loss: 0.227227, test loss: 0.770490, bias2: 0.39234980940818787, variance: 0.3781401216983795\n",
      "Train size: [400] hidden size: [1977] trial: 17, train_loss: 0.227565, test loss: 0.771768, bias2: 0.38885796070098877, variance: 0.3829103112220764\n",
      "Train size: [400] hidden size: [1977] trial: 18, train_loss: 0.227539, test loss: 0.770347, bias2: 0.3848152160644531, variance: 0.3855316638946533\n",
      "Train size: [400] hidden size: [1977] trial: 19, train_loss: 0.227743, test loss: 0.768829, bias2: 0.3816995322704315, variance: 0.38712945580482483\n",
      "Train size: [400] hidden size: [1977] trial: 20, train_loss: 0.228974, test loss: 0.767137, bias2: 0.3782564103603363, variance: 0.38888105750083923\n",
      "Train size: [400] hidden size: [1977] trial: 21, train_loss: 0.230144, test loss: 0.767984, bias2: 0.3779847025871277, variance: 0.3899994492530823\n",
      "Train size: [400] hidden size: [1977] trial: 22, train_loss: 0.230757, test loss: 0.771195, bias2: 0.379352331161499, variance: 0.39184266328811646\n",
      "Train size: [400] hidden size: [1977] trial: 23, train_loss: 0.230347, test loss: 0.769850, bias2: 0.37587490677833557, variance: 0.3939753472805023\n",
      "Train size: [400] hidden size: [1977] trial: 24, train_loss: 0.229909, test loss: 0.771307, bias2: 0.3767256736755371, variance: 0.39458167552948\n",
      "Train size: [400] hidden size: [1977] trial: 25, train_loss: 0.229362, test loss: 0.771653, bias2: 0.3768519163131714, variance: 0.39480096101760864\n",
      "Train size: [400] hidden size: [1977] trial: 26, train_loss: 0.229511, test loss: 0.772897, bias2: 0.3785742223262787, variance: 0.3943232595920563\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [1977] trial: 27, train_loss: 0.228874, test loss: 0.773057, bias2: 0.3778328001499176, variance: 0.3952242434024811\n",
      "Train size: [400] hidden size: [1977] trial: 28, train_loss: 0.228200, test loss: 0.775803, bias2: 0.37984806299209595, variance: 0.3959553837776184\n",
      "Train size: [400] hidden size: [1977] trial: 29, train_loss: 0.228454, test loss: 0.776583, bias2: 0.37983351945877075, variance: 0.39674943685531616\n",
      "Train size: [400] hidden size: [1977] trial: 30, train_loss: 0.228497, test loss: 0.774704, bias2: 0.3771570920944214, variance: 0.39754682779312134\n",
      "Train size: [400] hidden size: [1977] trial: 31, train_loss: 0.228268, test loss: 0.774861, bias2: 0.37670034170150757, variance: 0.39816033840179443\n",
      "Train size: [400] hidden size: [1977] trial: 32, train_loss: 0.227526, test loss: 0.775790, bias2: 0.3769770562648773, variance: 0.39881274104118347\n",
      "Train size: [400] hidden size: [1977] trial: 33, train_loss: 0.227849, test loss: 0.774529, bias2: 0.37489619851112366, variance: 0.3996332585811615\n",
      "Train size: [400] hidden size: [1977] trial: 34, train_loss: 0.228497, test loss: 0.776270, bias2: 0.376286119222641, variance: 0.39998385310173035\n",
      "Train size: [400] hidden size: [1977] trial: 35, train_loss: 0.228586, test loss: 0.776553, bias2: 0.3754141628742218, variance: 0.40113887190818787\n",
      "Train size: [400] hidden size: [1977] trial: 36, train_loss: 0.228045, test loss: 0.776280, bias2: 0.37483012676239014, variance: 0.40145009756088257\n",
      "Train size: [400] hidden size: [1977] trial: 37, train_loss: 0.227428, test loss: 0.777652, bias2: 0.3760148584842682, variance: 0.40163764357566833\n",
      "Train size: [400] hidden size: [1977] trial: 38, train_loss: 0.227141, test loss: 0.779792, bias2: 0.3779238164424896, variance: 0.4018685519695282\n",
      "Train size: [400] hidden size: [1977] trial: 39, train_loss: 0.226982, test loss: 0.780831, bias2: 0.37867534160614014, variance: 0.4021560549736023\n",
      "Train size: [400] hidden size: [1977] trial: 40, train_loss: 0.227514, test loss: 0.779001, bias2: 0.3761720359325409, variance: 0.40282902121543884\n",
      "Train size: [400] hidden size: [1977] trial: 41, train_loss: 0.227501, test loss: 0.779157, bias2: 0.37564778327941895, variance: 0.40350890159606934\n",
      "Train size: [400] hidden size: [1977] trial: 42, train_loss: 0.227260, test loss: 0.780020, bias2: 0.37595897912979126, variance: 0.40406060218811035\n",
      "Train size: [400] hidden size: [1977] trial: 43, train_loss: 0.227150, test loss: 0.779332, bias2: 0.3748196065425873, variance: 0.4045127332210541\n",
      "Train size: [400] hidden size: [1977] trial: 44, train_loss: 0.227391, test loss: 0.779863, bias2: 0.3756248950958252, variance: 0.40423840284347534\n",
      "Train size: [400] hidden size: [1977] trial: 45, train_loss: 0.226853, test loss: 0.779381, bias2: 0.3753308057785034, variance: 0.4040501117706299\n",
      "Train size: [400] hidden size: [1977] trial: 46, train_loss: 0.226831, test loss: 0.777868, bias2: 0.37439215183258057, variance: 0.4034753441810608\n",
      "Train size: [400] hidden size: [1977] trial: 47, train_loss: 0.227075, test loss: 0.777203, bias2: 0.3733980357646942, variance: 0.40380534529685974\n",
      "Train size: [400] hidden size: [1977] trial: 48, train_loss: 0.227054, test loss: 0.778507, bias2: 0.3747090995311737, variance: 0.4037981927394867\n",
      "Train size: [400] hidden size: [1977] trial: 49, train_loss: 0.227118, test loss: 0.779487, bias2: 0.37519848346710205, variance: 0.40428900718688965\n",
      "##################################################\n",
      "Train size: [400] hidden size: [2276] trial: 0, train_loss: 0.224631, test loss: 0.747852, bias2: 0.7478522062301636, variance: 5.449567463955418e-09\n",
      "Train size: [400] hidden size: [2276] trial: 1, train_loss: 0.215217, test loss: 0.753799, bias2: 0.5508680939674377, variance: 0.20293103158473969\n",
      "Train size: [400] hidden size: [2276] trial: 2, train_loss: 0.222208, test loss: 0.750091, bias2: 0.45891597867012024, variance: 0.29117539525032043\n",
      "Train size: [400] hidden size: [2276] trial: 3, train_loss: 0.220216, test loss: 0.760130, bias2: 0.44573646783828735, variance: 0.3143931031227112\n",
      "Train size: [400] hidden size: [2276] trial: 4, train_loss: 0.216260, test loss: 0.757820, bias2: 0.43053096532821655, variance: 0.3272888660430908\n",
      "Train size: [400] hidden size: [2276] trial: 5, train_loss: 0.211690, test loss: 0.742285, bias2: 0.4073712229728699, variance: 0.3349132537841797\n",
      "Train size: [400] hidden size: [2276] trial: 6, train_loss: 0.210234, test loss: 0.737081, bias2: 0.39497771859169006, variance: 0.34210333228111267\n",
      "Train size: [400] hidden size: [2276] trial: 7, train_loss: 0.208416, test loss: 0.744982, bias2: 0.3988792300224304, variance: 0.34610307216644287\n",
      "Train size: [400] hidden size: [2276] trial: 8, train_loss: 0.208961, test loss: 0.741143, bias2: 0.39365237951278687, variance: 0.3474908471107483\n",
      "Train size: [400] hidden size: [2276] trial: 9, train_loss: 0.207356, test loss: 0.747108, bias2: 0.39476123452186584, variance: 0.35234716534614563\n",
      "Train size: [400] hidden size: [2276] trial: 10, train_loss: 0.209936, test loss: 0.749351, bias2: 0.39190393686294556, variance: 0.35744673013687134\n",
      "Train size: [400] hidden size: [2276] trial: 11, train_loss: 0.210165, test loss: 0.753782, bias2: 0.39256155490875244, variance: 0.36122018098831177\n",
      "Train size: [400] hidden size: [2276] trial: 12, train_loss: 0.211630, test loss: 0.754315, bias2: 0.38729652762413025, variance: 0.3670184314250946\n",
      "Train size: [400] hidden size: [2276] trial: 13, train_loss: 0.212454, test loss: 0.753677, bias2: 0.3845503032207489, variance: 0.3691271245479584\n",
      "Train size: [400] hidden size: [2276] trial: 14, train_loss: 0.215309, test loss: 0.758000, bias2: 0.3828903138637543, variance: 0.3751101791858673\n",
      "Train size: [400] hidden size: [2276] trial: 15, train_loss: 0.216843, test loss: 0.755441, bias2: 0.3791000545024872, variance: 0.3763406574726105\n",
      "Train size: [400] hidden size: [2276] trial: 16, train_loss: 0.216477, test loss: 0.757341, bias2: 0.37840282917022705, variance: 0.3789384365081787\n",
      "Train size: [400] hidden size: [2276] trial: 17, train_loss: 0.214990, test loss: 0.757336, bias2: 0.3775099515914917, variance: 0.3798263669013977\n",
      "Train size: [400] hidden size: [2276] trial: 18, train_loss: 0.214231, test loss: 0.757714, bias2: 0.3774855136871338, variance: 0.3802288770675659\n",
      "Train size: [400] hidden size: [2276] trial: 19, train_loss: 0.214251, test loss: 0.755882, bias2: 0.3746338188648224, variance: 0.38124802708625793\n",
      "Train size: [400] hidden size: [2276] trial: 20, train_loss: 0.215819, test loss: 0.757598, bias2: 0.37516602873802185, variance: 0.38243159651756287\n",
      "Train size: [400] hidden size: [2276] trial: 21, train_loss: 0.216151, test loss: 0.757893, bias2: 0.3749340772628784, variance: 0.382959246635437\n",
      "Train size: [400] hidden size: [2276] trial: 22, train_loss: 0.216401, test loss: 0.759947, bias2: 0.37403762340545654, variance: 0.3859092593193054\n",
      "Train size: [400] hidden size: [2276] trial: 23, train_loss: 0.216760, test loss: 0.759786, bias2: 0.37313976883888245, variance: 0.3866458237171173\n",
      "Train size: [400] hidden size: [2276] trial: 24, train_loss: 0.218478, test loss: 0.760640, bias2: 0.37100961804389954, variance: 0.3896302878856659\n",
      "Train size: [400] hidden size: [2276] trial: 25, train_loss: 0.217419, test loss: 0.758755, bias2: 0.3701043128967285, variance: 0.3886508345603943\n",
      "Train size: [400] hidden size: [2276] trial: 26, train_loss: 0.217336, test loss: 0.759098, bias2: 0.3698527216911316, variance: 0.38924533128738403\n",
      "Train size: [400] hidden size: [2276] trial: 27, train_loss: 0.219308, test loss: 0.759812, bias2: 0.36983874440193176, variance: 0.38997307419776917\n",
      "Train size: [400] hidden size: [2276] trial: 28, train_loss: 0.218438, test loss: 0.760523, bias2: 0.37053632736206055, variance: 0.38998711109161377\n",
      "Train size: [400] hidden size: [2276] trial: 29, train_loss: 0.217666, test loss: 0.760972, bias2: 0.37100949883461, variance: 0.38996216654777527\n",
      "Train size: [400] hidden size: [2276] trial: 30, train_loss: 0.217526, test loss: 0.764428, bias2: 0.3732491433620453, variance: 0.39117875695228577\n",
      "Train size: [400] hidden size: [2276] trial: 31, train_loss: 0.217650, test loss: 0.763167, bias2: 0.3720754086971283, variance: 0.3910917341709137\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [2276] trial: 32, train_loss: 0.216224, test loss: 0.763640, bias2: 0.3725545108318329, variance: 0.3910849988460541\n",
      "Train size: [400] hidden size: [2276] trial: 33, train_loss: 0.215211, test loss: 0.763349, bias2: 0.3714842200279236, variance: 0.3918642997741699\n",
      "Train size: [400] hidden size: [2276] trial: 34, train_loss: 0.215148, test loss: 0.761414, bias2: 0.3695369362831116, variance: 0.39187687635421753\n",
      "Train size: [400] hidden size: [2276] trial: 35, train_loss: 0.215751, test loss: 0.762007, bias2: 0.3681149184703827, variance: 0.3938925564289093\n",
      "Train size: [400] hidden size: [2276] trial: 36, train_loss: 0.215439, test loss: 0.763674, bias2: 0.36886951327323914, variance: 0.3948046863079071\n",
      "Train size: [400] hidden size: [2276] trial: 37, train_loss: 0.215997, test loss: 0.763657, bias2: 0.3671415150165558, variance: 0.39651569724082947\n",
      "Train size: [400] hidden size: [2276] trial: 38, train_loss: 0.215186, test loss: 0.763113, bias2: 0.3666068911552429, variance: 0.39650654792785645\n",
      "Train size: [400] hidden size: [2276] trial: 39, train_loss: 0.215660, test loss: 0.764112, bias2: 0.36734461784362793, variance: 0.396767795085907\n",
      "Train size: [400] hidden size: [2276] trial: 40, train_loss: 0.215712, test loss: 0.762133, bias2: 0.3660302758216858, variance: 0.3961032032966614\n",
      "Train size: [400] hidden size: [2276] trial: 41, train_loss: 0.215498, test loss: 0.761467, bias2: 0.36515793204307556, variance: 0.3963092267513275\n",
      "Train size: [400] hidden size: [2276] trial: 42, train_loss: 0.215284, test loss: 0.762515, bias2: 0.36623120307922363, variance: 0.39628344774246216\n",
      "Train size: [400] hidden size: [2276] trial: 43, train_loss: 0.215802, test loss: 0.763231, bias2: 0.36609068512916565, variance: 0.39714065194129944\n",
      "Train size: [400] hidden size: [2276] trial: 44, train_loss: 0.215604, test loss: 0.763541, bias2: 0.3665943443775177, variance: 0.39694663882255554\n",
      "Train size: [400] hidden size: [2276] trial: 45, train_loss: 0.215662, test loss: 0.764236, bias2: 0.3660604953765869, variance: 0.3981751799583435\n",
      "Train size: [400] hidden size: [2276] trial: 46, train_loss: 0.215752, test loss: 0.763576, bias2: 0.3654380440711975, variance: 0.3981374502182007\n",
      "Train size: [400] hidden size: [2276] trial: 47, train_loss: 0.215408, test loss: 0.763206, bias2: 0.3656967580318451, variance: 0.3975089490413666\n",
      "Train size: [400] hidden size: [2276] trial: 48, train_loss: 0.215574, test loss: 0.763363, bias2: 0.36625587940216064, variance: 0.39710718393325806\n",
      "Train size: [400] hidden size: [2276] trial: 49, train_loss: 0.215307, test loss: 0.763808, bias2: 0.3670911192893982, variance: 0.39671725034713745\n",
      "##################################################\n",
      "Train size: [400] hidden size: [2621] trial: 0, train_loss: 0.212603, test loss: 0.799566, bias2: 0.7995664477348328, variance: 1.1677644407015464e-09\n",
      "Train size: [400] hidden size: [2621] trial: 1, train_loss: 0.212953, test loss: 0.765325, bias2: 0.572767972946167, variance: 0.1925572007894516\n",
      "Train size: [400] hidden size: [2621] trial: 2, train_loss: 0.218065, test loss: 0.772582, bias2: 0.514845609664917, variance: 0.2577362656593323\n",
      "Train size: [400] hidden size: [2621] trial: 3, train_loss: 0.222347, test loss: 0.762386, bias2: 0.4710697829723358, variance: 0.2913157045841217\n",
      "Train size: [400] hidden size: [2621] trial: 4, train_loss: 0.220155, test loss: 0.758438, bias2: 0.4536961317062378, variance: 0.3047419786453247\n",
      "Train size: [400] hidden size: [2621] trial: 5, train_loss: 0.215957, test loss: 0.755926, bias2: 0.43983861804008484, variance: 0.3160874545574188\n",
      "Train size: [400] hidden size: [2621] trial: 6, train_loss: 0.211791, test loss: 0.755175, bias2: 0.4239959716796875, variance: 0.33117932081222534\n",
      "Train size: [400] hidden size: [2621] trial: 7, train_loss: 0.209122, test loss: 0.746732, bias2: 0.414061963558197, variance: 0.3326701521873474\n",
      "Train size: [400] hidden size: [2621] trial: 8, train_loss: 0.209871, test loss: 0.748981, bias2: 0.4079986810684204, variance: 0.3409825563430786\n",
      "Train size: [400] hidden size: [2621] trial: 9, train_loss: 0.206998, test loss: 0.749822, bias2: 0.40139999985694885, variance: 0.3484216034412384\n",
      "Train size: [400] hidden size: [2621] trial: 10, train_loss: 0.207498, test loss: 0.746875, bias2: 0.3908940553665161, variance: 0.3559809923171997\n",
      "Train size: [400] hidden size: [2621] trial: 11, train_loss: 0.205648, test loss: 0.746237, bias2: 0.3873630166053772, variance: 0.35887348651885986\n",
      "Train size: [400] hidden size: [2621] trial: 12, train_loss: 0.204793, test loss: 0.748982, bias2: 0.38696151971817017, variance: 0.3620208501815796\n",
      "Train size: [400] hidden size: [2621] trial: 13, train_loss: 0.204293, test loss: 0.749185, bias2: 0.385731041431427, variance: 0.3634541630744934\n",
      "Train size: [400] hidden size: [2621] trial: 14, train_loss: 0.205168, test loss: 0.749479, bias2: 0.38188254833221436, variance: 0.3675963282585144\n",
      "Train size: [400] hidden size: [2621] trial: 15, train_loss: 0.205219, test loss: 0.746915, bias2: 0.3780120313167572, variance: 0.36890336871147156\n",
      "Train size: [400] hidden size: [2621] trial: 16, train_loss: 0.205206, test loss: 0.747422, bias2: 0.377025306224823, variance: 0.37039655447006226\n",
      "Train size: [400] hidden size: [2621] trial: 17, train_loss: 0.206497, test loss: 0.750332, bias2: 0.37697625160217285, variance: 0.373355507850647\n",
      "Train size: [400] hidden size: [2621] trial: 18, train_loss: 0.207275, test loss: 0.753864, bias2: 0.378052294254303, variance: 0.37581151723861694\n",
      "Train size: [400] hidden size: [2621] trial: 19, train_loss: 0.208036, test loss: 0.751767, bias2: 0.37424707412719727, variance: 0.37751972675323486\n",
      "Train size: [400] hidden size: [2621] trial: 20, train_loss: 0.207264, test loss: 0.747934, bias2: 0.37219756841659546, variance: 0.37573617696762085\n",
      "Train size: [400] hidden size: [2621] trial: 21, train_loss: 0.208308, test loss: 0.744787, bias2: 0.36786019802093506, variance: 0.37692707777023315\n",
      "Train size: [400] hidden size: [2621] trial: 22, train_loss: 0.207843, test loss: 0.745340, bias2: 0.36747246980667114, variance: 0.37786781787872314\n",
      "Train size: [400] hidden size: [2621] trial: 23, train_loss: 0.207417, test loss: 0.741477, bias2: 0.36464187502861023, variance: 0.37683549523353577\n",
      "Train size: [400] hidden size: [2621] trial: 24, train_loss: 0.205967, test loss: 0.742614, bias2: 0.3646484613418579, variance: 0.3779653310775757\n",
      "Train size: [400] hidden size: [2621] trial: 25, train_loss: 0.205706, test loss: 0.742413, bias2: 0.3637675940990448, variance: 0.3786458671092987\n",
      "Train size: [400] hidden size: [2621] trial: 26, train_loss: 0.205309, test loss: 0.743051, bias2: 0.3634379804134369, variance: 0.3796127736568451\n",
      "Train size: [400] hidden size: [2621] trial: 27, train_loss: 0.204538, test loss: 0.742631, bias2: 0.3629351258277893, variance: 0.3796960115432739\n",
      "Train size: [400] hidden size: [2621] trial: 28, train_loss: 0.204410, test loss: 0.741238, bias2: 0.3627832233905792, variance: 0.37845489382743835\n",
      "Train size: [400] hidden size: [2621] trial: 29, train_loss: 0.204619, test loss: 0.738404, bias2: 0.36019861698150635, variance: 0.37820500135421753\n",
      "Train size: [400] hidden size: [2621] trial: 30, train_loss: 0.204432, test loss: 0.737503, bias2: 0.3598850667476654, variance: 0.3776175081729889\n",
      "Train size: [400] hidden size: [2621] trial: 31, train_loss: 0.204019, test loss: 0.739072, bias2: 0.36135849356651306, variance: 0.3777138292789459\n",
      "Train size: [400] hidden size: [2621] trial: 32, train_loss: 0.203351, test loss: 0.739624, bias2: 0.3617023527622223, variance: 0.37792208790779114\n",
      "Train size: [400] hidden size: [2621] trial: 33, train_loss: 0.203743, test loss: 0.740586, bias2: 0.3626929819583893, variance: 0.3778931200504303\n",
      "Train size: [400] hidden size: [2621] trial: 34, train_loss: 0.203977, test loss: 0.739445, bias2: 0.36068230867385864, variance: 0.37876296043395996\n",
      "Train size: [400] hidden size: [2621] trial: 35, train_loss: 0.204186, test loss: 0.738070, bias2: 0.3603564500808716, variance: 0.3777132034301758\n",
      "Train size: [400] hidden size: [2621] trial: 36, train_loss: 0.204762, test loss: 0.736364, bias2: 0.3592648208141327, variance: 0.37709882855415344\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [2621] trial: 37, train_loss: 0.204709, test loss: 0.737271, bias2: 0.3587976396083832, variance: 0.37847378849983215\n",
      "Train size: [400] hidden size: [2621] trial: 38, train_loss: 0.204404, test loss: 0.736547, bias2: 0.3591158986091614, variance: 0.3774312734603882\n",
      "Train size: [400] hidden size: [2621] trial: 39, train_loss: 0.204617, test loss: 0.736381, bias2: 0.35821568965911865, variance: 0.3781653046607971\n",
      "Train size: [400] hidden size: [2621] trial: 40, train_loss: 0.204471, test loss: 0.737964, bias2: 0.3586551249027252, variance: 0.3793084919452667\n",
      "Train size: [400] hidden size: [2621] trial: 41, train_loss: 0.204417, test loss: 0.737371, bias2: 0.35854676365852356, variance: 0.37882426381111145\n",
      "Train size: [400] hidden size: [2621] trial: 42, train_loss: 0.204000, test loss: 0.738551, bias2: 0.35992348194122314, variance: 0.37862730026245117\n",
      "Train size: [400] hidden size: [2621] trial: 43, train_loss: 0.203900, test loss: 0.737504, bias2: 0.3584114909172058, variance: 0.3790924549102783\n",
      "Train size: [400] hidden size: [2621] trial: 44, train_loss: 0.203083, test loss: 0.737216, bias2: 0.35900428891181946, variance: 0.37821200489997864\n",
      "Train size: [400] hidden size: [2621] trial: 45, train_loss: 0.202888, test loss: 0.735898, bias2: 0.35774141550064087, variance: 0.3781569004058838\n",
      "Train size: [400] hidden size: [2621] trial: 46, train_loss: 0.202728, test loss: 0.737004, bias2: 0.3579414486885071, variance: 0.3790621757507324\n",
      "Train size: [400] hidden size: [2621] trial: 47, train_loss: 0.203492, test loss: 0.737767, bias2: 0.356831431388855, variance: 0.3809359669685364\n",
      "Train size: [400] hidden size: [2621] trial: 48, train_loss: 0.203677, test loss: 0.736479, bias2: 0.3557110130786896, variance: 0.3807678520679474\n",
      "Train size: [400] hidden size: [2621] trial: 49, train_loss: 0.203477, test loss: 0.734654, bias2: 0.3543738126754761, variance: 0.380280077457428\n",
      "##################################################\n",
      "Train size: [400] hidden size: [3017] trial: 0, train_loss: 0.169280, test loss: 0.713180, bias2: 0.7131798267364502, variance: 3.8925479506346505e-10\n",
      "Train size: [400] hidden size: [3017] trial: 1, train_loss: 0.201979, test loss: 0.744840, bias2: 0.5706508159637451, variance: 0.17418964207172394\n",
      "Train size: [400] hidden size: [3017] trial: 2, train_loss: 0.204963, test loss: 0.733748, bias2: 0.4816788136959076, variance: 0.2520689070224762\n",
      "Train size: [400] hidden size: [3017] trial: 3, train_loss: 0.196286, test loss: 0.725917, bias2: 0.45162445306777954, variance: 0.2742924690246582\n",
      "Train size: [400] hidden size: [3017] trial: 4, train_loss: 0.191004, test loss: 0.713186, bias2: 0.4236097037792206, variance: 0.2895762622356415\n",
      "Train size: [400] hidden size: [3017] trial: 5, train_loss: 0.193526, test loss: 0.713004, bias2: 0.4006440341472626, variance: 0.3123597204685211\n",
      "Train size: [400] hidden size: [3017] trial: 6, train_loss: 0.190812, test loss: 0.719361, bias2: 0.39341822266578674, variance: 0.32594242691993713\n",
      "Train size: [400] hidden size: [3017] trial: 7, train_loss: 0.191609, test loss: 0.724724, bias2: 0.3872958719730377, variance: 0.3374278247356415\n",
      "Train size: [400] hidden size: [3017] trial: 8, train_loss: 0.192500, test loss: 0.726640, bias2: 0.37888041138648987, variance: 0.347759872674942\n",
      "Train size: [400] hidden size: [3017] trial: 9, train_loss: 0.192884, test loss: 0.719430, bias2: 0.36852583289146423, variance: 0.3509044945240021\n",
      "Train size: [400] hidden size: [3017] trial: 10, train_loss: 0.192121, test loss: 0.715075, bias2: 0.3644495904445648, variance: 0.35062524676322937\n",
      "Train size: [400] hidden size: [3017] trial: 11, train_loss: 0.192363, test loss: 0.720093, bias2: 0.3649732768535614, variance: 0.3551194369792938\n",
      "Train size: [400] hidden size: [3017] trial: 12, train_loss: 0.192004, test loss: 0.722980, bias2: 0.36699214577674866, variance: 0.35598835349082947\n",
      "Train size: [400] hidden size: [3017] trial: 13, train_loss: 0.192287, test loss: 0.723589, bias2: 0.3658018708229065, variance: 0.35778695344924927\n",
      "Train size: [400] hidden size: [3017] trial: 14, train_loss: 0.192930, test loss: 0.725667, bias2: 0.36711224913597107, variance: 0.3585543930530548\n",
      "Train size: [400] hidden size: [3017] trial: 15, train_loss: 0.192010, test loss: 0.721804, bias2: 0.36371496319770813, variance: 0.35808905959129333\n",
      "Train size: [400] hidden size: [3017] trial: 16, train_loss: 0.190749, test loss: 0.723656, bias2: 0.36373835802078247, variance: 0.35991811752319336\n",
      "Train size: [400] hidden size: [3017] trial: 17, train_loss: 0.190493, test loss: 0.721492, bias2: 0.36279094219207764, variance: 0.35870105028152466\n",
      "Train size: [400] hidden size: [3017] trial: 18, train_loss: 0.191049, test loss: 0.724886, bias2: 0.36459651589393616, variance: 0.3602893054485321\n",
      "Train size: [400] hidden size: [3017] trial: 19, train_loss: 0.191628, test loss: 0.725874, bias2: 0.3625253140926361, variance: 0.36334851384162903\n",
      "Train size: [400] hidden size: [3017] trial: 20, train_loss: 0.189634, test loss: 0.726377, bias2: 0.36388328671455383, variance: 0.36249396204948425\n",
      "Train size: [400] hidden size: [3017] trial: 21, train_loss: 0.191140, test loss: 0.723438, bias2: 0.3615846633911133, variance: 0.3618529438972473\n",
      "Train size: [400] hidden size: [3017] trial: 22, train_loss: 0.190918, test loss: 0.723965, bias2: 0.35970473289489746, variance: 0.36426055431365967\n",
      "Train size: [400] hidden size: [3017] trial: 23, train_loss: 0.190587, test loss: 0.723551, bias2: 0.3595062792301178, variance: 0.3640446364879608\n",
      "Train size: [400] hidden size: [3017] trial: 24, train_loss: 0.190609, test loss: 0.719975, bias2: 0.3571471869945526, variance: 0.36282822489738464\n",
      "Train size: [400] hidden size: [3017] trial: 25, train_loss: 0.190544, test loss: 0.719032, bias2: 0.3563275635242462, variance: 0.36270472407341003\n",
      "Train size: [400] hidden size: [3017] trial: 26, train_loss: 0.191075, test loss: 0.720326, bias2: 0.35504767298698425, variance: 0.3652787506580353\n",
      "Train size: [400] hidden size: [3017] trial: 27, train_loss: 0.190502, test loss: 0.724437, bias2: 0.3576299846172333, variance: 0.36680731177330017\n",
      "Train size: [400] hidden size: [3017] trial: 28, train_loss: 0.190194, test loss: 0.725162, bias2: 0.3568391799926758, variance: 0.3683229088783264\n",
      "Train size: [400] hidden size: [3017] trial: 29, train_loss: 0.190803, test loss: 0.723784, bias2: 0.35500368475914, variance: 0.3687799274921417\n",
      "Train size: [400] hidden size: [3017] trial: 30, train_loss: 0.191370, test loss: 0.727331, bias2: 0.35720834136009216, variance: 0.37012234330177307\n",
      "Train size: [400] hidden size: [3017] trial: 31, train_loss: 0.190729, test loss: 0.728283, bias2: 0.3577118515968323, variance: 0.3705707788467407\n",
      "Train size: [400] hidden size: [3017] trial: 32, train_loss: 0.191315, test loss: 0.725745, bias2: 0.35554465651512146, variance: 0.37020036578178406\n",
      "Train size: [400] hidden size: [3017] trial: 33, train_loss: 0.190990, test loss: 0.725446, bias2: 0.3552256226539612, variance: 0.3702201843261719\n",
      "Train size: [400] hidden size: [3017] trial: 34, train_loss: 0.190928, test loss: 0.724454, bias2: 0.3549336791038513, variance: 0.3695199489593506\n",
      "Train size: [400] hidden size: [3017] trial: 35, train_loss: 0.191486, test loss: 0.724567, bias2: 0.3544416129589081, variance: 0.3701254427433014\n",
      "Train size: [400] hidden size: [3017] trial: 36, train_loss: 0.191193, test loss: 0.722212, bias2: 0.35399046540260315, variance: 0.36822107434272766\n",
      "Train size: [400] hidden size: [3017] trial: 37, train_loss: 0.191177, test loss: 0.722696, bias2: 0.35399192571640015, variance: 0.36870449781417847\n",
      "Train size: [400] hidden size: [3017] trial: 38, train_loss: 0.190752, test loss: 0.722489, bias2: 0.35321828722953796, variance: 0.36927083134651184\n",
      "Train size: [400] hidden size: [3017] trial: 39, train_loss: 0.190688, test loss: 0.722710, bias2: 0.35403260588645935, variance: 0.3686775267124176\n",
      "Train size: [400] hidden size: [3017] trial: 40, train_loss: 0.190632, test loss: 0.722730, bias2: 0.3547303378582001, variance: 0.36799952387809753\n",
      "Train size: [400] hidden size: [3017] trial: 41, train_loss: 0.191103, test loss: 0.723829, bias2: 0.3557761609554291, variance: 0.3680526912212372\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [3017] trial: 42, train_loss: 0.190819, test loss: 0.722971, bias2: 0.3562313914299011, variance: 0.36673951148986816\n",
      "Train size: [400] hidden size: [3017] trial: 43, train_loss: 0.190561, test loss: 0.724002, bias2: 0.35661858320236206, variance: 0.36738306283950806\n",
      "Train size: [400] hidden size: [3017] trial: 44, train_loss: 0.190559, test loss: 0.724197, bias2: 0.3563983738422394, variance: 0.3677981197834015\n",
      "Train size: [400] hidden size: [3017] trial: 45, train_loss: 0.190377, test loss: 0.724579, bias2: 0.35695165395736694, variance: 0.3676273226737976\n",
      "Train size: [400] hidden size: [3017] trial: 46, train_loss: 0.190375, test loss: 0.725198, bias2: 0.3570237457752228, variance: 0.3681739866733551\n",
      "Train size: [400] hidden size: [3017] trial: 47, train_loss: 0.190607, test loss: 0.724506, bias2: 0.35574525594711304, variance: 0.36876070499420166\n",
      "Train size: [400] hidden size: [3017] trial: 48, train_loss: 0.190924, test loss: 0.723666, bias2: 0.3549477756023407, variance: 0.3687179386615753\n",
      "Train size: [400] hidden size: [3017] trial: 49, train_loss: 0.190729, test loss: 0.724646, bias2: 0.35566872358322144, variance: 0.36897772550582886\n",
      "##################################################\n",
      "Train size: [400] hidden size: [3474] trial: 0, train_loss: 0.165519, test loss: 0.704626, bias2: 0.7046257853507996, variance: -1.7516466055411684e-09\n",
      "Train size: [400] hidden size: [3474] trial: 1, train_loss: 0.179845, test loss: 0.700128, bias2: 0.5397814512252808, variance: 0.16034692525863647\n",
      "Train size: [400] hidden size: [3474] trial: 2, train_loss: 0.178567, test loss: 0.703681, bias2: 0.48885178565979004, variance: 0.2148291915655136\n",
      "Train size: [400] hidden size: [3474] trial: 3, train_loss: 0.180011, test loss: 0.707047, bias2: 0.4577489495277405, variance: 0.2492978572845459\n",
      "Train size: [400] hidden size: [3474] trial: 4, train_loss: 0.184760, test loss: 0.703838, bias2: 0.42891237139701843, variance: 0.274926096200943\n",
      "Train size: [400] hidden size: [3474] trial: 5, train_loss: 0.184895, test loss: 0.700745, bias2: 0.4045720398426056, variance: 0.29617252945899963\n",
      "Train size: [400] hidden size: [3474] trial: 6, train_loss: 0.186627, test loss: 0.698307, bias2: 0.39479386806488037, variance: 0.30351322889328003\n",
      "Train size: [400] hidden size: [3474] trial: 7, train_loss: 0.188969, test loss: 0.696348, bias2: 0.38328373432159424, variance: 0.31306391954421997\n",
      "Train size: [400] hidden size: [3474] trial: 8, train_loss: 0.189396, test loss: 0.695706, bias2: 0.3739561438560486, variance: 0.32174962759017944\n",
      "Train size: [400] hidden size: [3474] trial: 9, train_loss: 0.191578, test loss: 0.699818, bias2: 0.37429067492485046, variance: 0.3255276381969452\n",
      "Train size: [400] hidden size: [3474] trial: 10, train_loss: 0.190315, test loss: 0.709959, bias2: 0.37610533833503723, variance: 0.33385351300239563\n",
      "Train size: [400] hidden size: [3474] trial: 11, train_loss: 0.192641, test loss: 0.712562, bias2: 0.37618306279182434, variance: 0.3363786041736603\n",
      "Train size: [400] hidden size: [3474] trial: 12, train_loss: 0.193219, test loss: 0.711887, bias2: 0.3711799681186676, variance: 0.34070727229118347\n",
      "Train size: [400] hidden size: [3474] trial: 13, train_loss: 0.193079, test loss: 0.714341, bias2: 0.368949294090271, variance: 0.34539222717285156\n",
      "Train size: [400] hidden size: [3474] trial: 14, train_loss: 0.190634, test loss: 0.717052, bias2: 0.37080681324005127, variance: 0.34624558687210083\n",
      "Train size: [400] hidden size: [3474] trial: 15, train_loss: 0.189649, test loss: 0.714249, bias2: 0.3668600022792816, variance: 0.34738871455192566\n",
      "Train size: [400] hidden size: [3474] trial: 16, train_loss: 0.189148, test loss: 0.711644, bias2: 0.3650626838207245, variance: 0.34658095240592957\n",
      "Train size: [400] hidden size: [3474] trial: 17, train_loss: 0.189264, test loss: 0.708762, bias2: 0.36316075921058655, variance: 0.3456009328365326\n",
      "Train size: [400] hidden size: [3474] trial: 18, train_loss: 0.190964, test loss: 0.704849, bias2: 0.357275128364563, variance: 0.347573459148407\n",
      "Train size: [400] hidden size: [3474] trial: 19, train_loss: 0.191825, test loss: 0.702753, bias2: 0.3551998734474182, variance: 0.3475533127784729\n",
      "Train size: [400] hidden size: [3474] trial: 20, train_loss: 0.192444, test loss: 0.703719, bias2: 0.3544108271598816, variance: 0.3493083715438843\n",
      "Train size: [400] hidden size: [3474] trial: 21, train_loss: 0.191867, test loss: 0.704749, bias2: 0.35409441590309143, variance: 0.35065439343452454\n",
      "Train size: [400] hidden size: [3474] trial: 22, train_loss: 0.191664, test loss: 0.705971, bias2: 0.35616055130958557, variance: 0.34981009364128113\n",
      "Train size: [400] hidden size: [3474] trial: 23, train_loss: 0.190149, test loss: 0.706908, bias2: 0.35620760917663574, variance: 0.35070037841796875\n",
      "Train size: [400] hidden size: [3474] trial: 24, train_loss: 0.191106, test loss: 0.708871, bias2: 0.3568888008594513, variance: 0.35198214650154114\n",
      "Train size: [400] hidden size: [3474] trial: 25, train_loss: 0.190782, test loss: 0.708033, bias2: 0.3548165559768677, variance: 0.35321658849716187\n",
      "Train size: [400] hidden size: [3474] trial: 26, train_loss: 0.190597, test loss: 0.706624, bias2: 0.35428881645202637, variance: 0.3523353934288025\n",
      "Train size: [400] hidden size: [3474] trial: 27, train_loss: 0.190067, test loss: 0.706600, bias2: 0.3548005223274231, variance: 0.3517991304397583\n",
      "Train size: [400] hidden size: [3474] trial: 28, train_loss: 0.190294, test loss: 0.705750, bias2: 0.3541801869869232, variance: 0.35156992077827454\n",
      "Train size: [400] hidden size: [3474] trial: 29, train_loss: 0.190052, test loss: 0.708423, bias2: 0.3545522689819336, variance: 0.3538709282875061\n",
      "Train size: [400] hidden size: [3474] trial: 30, train_loss: 0.189676, test loss: 0.707689, bias2: 0.3549049496650696, variance: 0.35278403759002686\n",
      "Train size: [400] hidden size: [3474] trial: 31, train_loss: 0.189848, test loss: 0.707007, bias2: 0.3542591631412506, variance: 0.3527476489543915\n",
      "Train size: [400] hidden size: [3474] trial: 32, train_loss: 0.189421, test loss: 0.707164, bias2: 0.35474148392677307, variance: 0.3524229824542999\n",
      "Train size: [400] hidden size: [3474] trial: 33, train_loss: 0.189871, test loss: 0.707514, bias2: 0.3551565706729889, variance: 0.35235777497291565\n",
      "Train size: [400] hidden size: [3474] trial: 34, train_loss: 0.189769, test loss: 0.708513, bias2: 0.35624638199806213, variance: 0.3522661626338959\n",
      "Train size: [400] hidden size: [3474] trial: 35, train_loss: 0.189853, test loss: 0.707951, bias2: 0.35537993907928467, variance: 0.3525707721710205\n",
      "Train size: [400] hidden size: [3474] trial: 36, train_loss: 0.189981, test loss: 0.707143, bias2: 0.35387203097343445, variance: 0.3532712757587433\n",
      "Train size: [400] hidden size: [3474] trial: 37, train_loss: 0.190065, test loss: 0.705169, bias2: 0.3513339161872864, variance: 0.3538350462913513\n",
      "Train size: [400] hidden size: [3474] trial: 38, train_loss: 0.190347, test loss: 0.705177, bias2: 0.350240021944046, variance: 0.35493704676628113\n",
      "Train size: [400] hidden size: [3474] trial: 39, train_loss: 0.189674, test loss: 0.704626, bias2: 0.3496970534324646, variance: 0.3549293875694275\n",
      "Train size: [400] hidden size: [3474] trial: 40, train_loss: 0.189745, test loss: 0.705886, bias2: 0.3501410186290741, variance: 0.3557448089122772\n",
      "Train size: [400] hidden size: [3474] trial: 41, train_loss: 0.189615, test loss: 0.704984, bias2: 0.3486955165863037, variance: 0.35628896951675415\n",
      "Train size: [400] hidden size: [3474] trial: 42, train_loss: 0.189571, test loss: 0.706744, bias2: 0.349310040473938, variance: 0.35743415355682373\n",
      "Train size: [400] hidden size: [3474] trial: 43, train_loss: 0.190398, test loss: 0.707606, bias2: 0.34962528944015503, variance: 0.35798102617263794\n",
      "Train size: [400] hidden size: [3474] trial: 44, train_loss: 0.190562, test loss: 0.708100, bias2: 0.3498273193836212, variance: 0.3582729399204254\n",
      "Train size: [400] hidden size: [3474] trial: 45, train_loss: 0.190568, test loss: 0.707301, bias2: 0.3489028513431549, variance: 0.35839781165122986\n",
      "Train size: [400] hidden size: [3474] trial: 46, train_loss: 0.191029, test loss: 0.706393, bias2: 0.3475291430950165, variance: 0.35886338353157043\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [3474] trial: 47, train_loss: 0.191038, test loss: 0.707953, bias2: 0.3489408791065216, variance: 0.35901185870170593\n",
      "Train size: [400] hidden size: [3474] trial: 48, train_loss: 0.191070, test loss: 0.707529, bias2: 0.3482643663883209, variance: 0.3592648208141327\n",
      "Train size: [400] hidden size: [3474] trial: 49, train_loss: 0.190699, test loss: 0.706772, bias2: 0.34776127338409424, variance: 0.3590104579925537\n",
      "##################################################\n",
      "Train size: [400] hidden size: [4000] trial: 0, train_loss: 0.196249, test loss: 0.662564, bias2: 0.662563681602478, variance: -1.5570191802538602e-09\n",
      "Train size: [400] hidden size: [4000] trial: 1, train_loss: 0.184437, test loss: 0.694877, bias2: 0.5287377834320068, variance: 0.16613896191120148\n",
      "Train size: [400] hidden size: [4000] trial: 2, train_loss: 0.176556, test loss: 0.710292, bias2: 0.48354876041412354, variance: 0.22674338519573212\n",
      "Train size: [400] hidden size: [4000] trial: 3, train_loss: 0.173568, test loss: 0.724148, bias2: 0.4662395119667053, variance: 0.2579081058502197\n",
      "Train size: [400] hidden size: [4000] trial: 4, train_loss: 0.177743, test loss: 0.705683, bias2: 0.43119552731513977, variance: 0.2744879424571991\n",
      "Train size: [400] hidden size: [4000] trial: 5, train_loss: 0.180344, test loss: 0.686133, bias2: 0.40378740429878235, variance: 0.28234604001045227\n",
      "Train size: [400] hidden size: [4000] trial: 6, train_loss: 0.178584, test loss: 0.692144, bias2: 0.39831629395484924, variance: 0.2938275635242462\n",
      "Train size: [400] hidden size: [4000] trial: 7, train_loss: 0.175594, test loss: 0.690969, bias2: 0.3887680470943451, variance: 0.30220094323158264\n",
      "Train size: [400] hidden size: [4000] trial: 8, train_loss: 0.175873, test loss: 0.686219, bias2: 0.38081541657447815, variance: 0.3054034411907196\n",
      "Train size: [400] hidden size: [4000] trial: 9, train_loss: 0.177916, test loss: 0.690992, bias2: 0.37742069363594055, variance: 0.31357088685035706\n",
      "Train size: [400] hidden size: [4000] trial: 10, train_loss: 0.176156, test loss: 0.689956, bias2: 0.3763469457626343, variance: 0.3136094808578491\n",
      "Train size: [400] hidden size: [4000] trial: 11, train_loss: 0.176352, test loss: 0.688821, bias2: 0.37411829829216003, variance: 0.31470224261283875\n",
      "Train size: [400] hidden size: [4000] trial: 12, train_loss: 0.177615, test loss: 0.692686, bias2: 0.37323418259620667, variance: 0.31945136189460754\n",
      "Train size: [400] hidden size: [4000] trial: 13, train_loss: 0.178571, test loss: 0.695459, bias2: 0.3740006685256958, variance: 0.32145822048187256\n",
      "Train size: [400] hidden size: [4000] trial: 14, train_loss: 0.177350, test loss: 0.697414, bias2: 0.37525132298469543, variance: 0.3221624791622162\n",
      "Train size: [400] hidden size: [4000] trial: 15, train_loss: 0.177420, test loss: 0.699609, bias2: 0.3753361999988556, variance: 0.3242723047733307\n",
      "Train size: [400] hidden size: [4000] trial: 16, train_loss: 0.177284, test loss: 0.700473, bias2: 0.37399962544441223, variance: 0.326473206281662\n",
      "Train size: [400] hidden size: [4000] trial: 17, train_loss: 0.177446, test loss: 0.702730, bias2: 0.37216073274612427, variance: 0.3305695056915283\n",
      "Train size: [400] hidden size: [4000] trial: 18, train_loss: 0.176742, test loss: 0.704648, bias2: 0.37194234132766724, variance: 0.33270519971847534\n",
      "Train size: [400] hidden size: [4000] trial: 19, train_loss: 0.176587, test loss: 0.700191, bias2: 0.36857885122299194, variance: 0.33161187171936035\n",
      "Train size: [400] hidden size: [4000] trial: 20, train_loss: 0.176863, test loss: 0.696912, bias2: 0.3647911846637726, variance: 0.3321206271648407\n",
      "Train size: [400] hidden size: [4000] trial: 21, train_loss: 0.176965, test loss: 0.699886, bias2: 0.36639752984046936, variance: 0.33348819613456726\n",
      "Train size: [400] hidden size: [4000] trial: 22, train_loss: 0.177961, test loss: 0.697678, bias2: 0.36265477538108826, variance: 0.3350233733654022\n",
      "Train size: [400] hidden size: [4000] trial: 23, train_loss: 0.177712, test loss: 0.696135, bias2: 0.36043474078178406, variance: 0.335700660943985\n",
      "Train size: [400] hidden size: [4000] trial: 24, train_loss: 0.177886, test loss: 0.695575, bias2: 0.35940104722976685, variance: 0.33617353439331055\n",
      "Train size: [400] hidden size: [4000] trial: 25, train_loss: 0.178691, test loss: 0.697180, bias2: 0.3600199520587921, variance: 0.33715978264808655\n",
      "Train size: [400] hidden size: [4000] trial: 26, train_loss: 0.178463, test loss: 0.697317, bias2: 0.35914698243141174, variance: 0.3381703794002533\n",
      "Train size: [400] hidden size: [4000] trial: 27, train_loss: 0.180078, test loss: 0.698840, bias2: 0.35749658942222595, variance: 0.3413437306880951\n",
      "Train size: [400] hidden size: [4000] trial: 28, train_loss: 0.180858, test loss: 0.699701, bias2: 0.3569621443748474, variance: 0.3427387475967407\n",
      "Train size: [400] hidden size: [4000] trial: 29, train_loss: 0.180568, test loss: 0.703004, bias2: 0.3582814633846283, variance: 0.34472253918647766\n",
      "Train size: [400] hidden size: [4000] trial: 30, train_loss: 0.180333, test loss: 0.701974, bias2: 0.3555090129375458, variance: 0.3464645445346832\n",
      "Train size: [400] hidden size: [4000] trial: 31, train_loss: 0.180881, test loss: 0.699799, bias2: 0.35268673300743103, variance: 0.34711208939552307\n",
      "Train size: [400] hidden size: [4000] trial: 32, train_loss: 0.180982, test loss: 0.699918, bias2: 0.3526245653629303, variance: 0.3472937047481537\n",
      "Train size: [400] hidden size: [4000] trial: 33, train_loss: 0.181623, test loss: 0.700363, bias2: 0.352142333984375, variance: 0.3482203483581543\n",
      "Train size: [400] hidden size: [4000] trial: 34, train_loss: 0.181384, test loss: 0.700860, bias2: 0.35252365469932556, variance: 0.34833601117134094\n",
      "Train size: [400] hidden size: [4000] trial: 35, train_loss: 0.182170, test loss: 0.702133, bias2: 0.3518233597278595, variance: 0.35030993819236755\n",
      "Train size: [400] hidden size: [4000] trial: 36, train_loss: 0.182316, test loss: 0.704247, bias2: 0.35264164209365845, variance: 0.35160571336746216\n",
      "Train size: [400] hidden size: [4000] trial: 37, train_loss: 0.181707, test loss: 0.702441, bias2: 0.35177019238471985, variance: 0.35067078471183777\n",
      "Train size: [400] hidden size: [4000] trial: 38, train_loss: 0.182306, test loss: 0.701862, bias2: 0.3491421639919281, variance: 0.35271987318992615\n",
      "Train size: [400] hidden size: [4000] trial: 39, train_loss: 0.182019, test loss: 0.701828, bias2: 0.34868940711021423, variance: 0.35313865542411804\n",
      "Train size: [400] hidden size: [4000] trial: 40, train_loss: 0.181687, test loss: 0.699906, bias2: 0.3471226990222931, variance: 0.3527829349040985\n",
      "Train size: [400] hidden size: [4000] trial: 41, train_loss: 0.181599, test loss: 0.700065, bias2: 0.3467531204223633, variance: 0.35331207513809204\n",
      "Train size: [400] hidden size: [4000] trial: 42, train_loss: 0.181621, test loss: 0.699974, bias2: 0.3464518189430237, variance: 0.35352253913879395\n",
      "Train size: [400] hidden size: [4000] trial: 43, train_loss: 0.181313, test loss: 0.699247, bias2: 0.345694899559021, variance: 0.35355186462402344\n",
      "Train size: [400] hidden size: [4000] trial: 44, train_loss: 0.181028, test loss: 0.698168, bias2: 0.3446240723133087, variance: 0.3535436689853668\n",
      "Train size: [400] hidden size: [4000] trial: 45, train_loss: 0.181095, test loss: 0.698797, bias2: 0.34359851479530334, variance: 0.355198472738266\n",
      "Train size: [400] hidden size: [4000] trial: 46, train_loss: 0.181044, test loss: 0.698865, bias2: 0.34364354610443115, variance: 0.35522180795669556\n",
      "Train size: [400] hidden size: [4000] trial: 47, train_loss: 0.180955, test loss: 0.698976, bias2: 0.3437930643558502, variance: 0.35518333315849304\n",
      "Train size: [400] hidden size: [4000] trial: 48, train_loss: 0.180972, test loss: 0.697839, bias2: 0.3432411551475525, variance: 0.35459792613983154\n",
      "Train size: [400] hidden size: [4000] trial: 49, train_loss: 0.180911, test loss: 0.697733, bias2: 0.34267711639404297, variance: 0.35505592823028564\n",
      "##################################################\n"
     ]
    }
   ],
   "source": [
    "run_exps_ridge(train_sizes, N_Ds, P_Ns, beta, test_size, feature_dim, num_classes, num_trials, coef,\n",
    "             outdir, 'ensembleNNK=2_output.csv', SNR= SNR, K = 2, F_norm = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run_exps_ridge(train_sizes, N_Ds, P_Ns, trainset, test_size, feature_dim, num_classes, num_trials, coef,\n",
    "#              outdir, 'ensembleNNK=4_output.csv', K = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "K2_df = pd.read_csv(os.path.join(outdir, 'ensembleNNK=2_output.csv'))\n",
    "K1_df = pd.read_csv(os.path.join(outdir, 'singleNN_output.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "font = {\n",
    "        'size'   : 18}\n",
    "matplotlib.rc('font', **font)\n",
    "figsize = (16, 5)\n",
    "import seaborn as sns\n",
    "sns.set_style('darkgrid')\n",
    "\n",
    "def plot_bias_var(df, N_D, ymin=0, ymax=1.0):\n",
    "    fig1, axes1 = plt.subplots(1, 3, figsize=figsize)\n",
    "    axes1[0].set_xscale('log')\n",
    "    axes1[1].set_xscale('log')\n",
    "    axes1[2].set_xscale('log')\n",
    "    cur_df = df[df['train_size']/feature_dim==N_D]\n",
    "    test_loss = cur_df['test_loss']\n",
    "    bias2 = cur_df['bias2']\n",
    "    var = cur_df['variance']\n",
    "    P_N = cur_df['hidden_size']/cur_df['train_size']\n",
    "    axes1[0].plot(P_N, test_loss)\n",
    "    axes1[0].set_xlabel(\"P/N\")\n",
    "    axes1[0].set_ylabel(\"Test Loss\")\n",
    "    axes1[0].set_ylim(ymin, ymax)\n",
    "    axes1[1].plot(P_N, bias2)\n",
    "    axes1[1].set_xlabel(\"P/N\")\n",
    "    axes1[1].set_ylabel(\"Bias Square\")\n",
    "    axes1[1].set_ylim(ymin, ymax)\n",
    "    axes1[2].plot(P_N, var)\n",
    "    axes1[2].set_xlabel(\"P/N\")\n",
    "    axes1[2].set_ylabel(\"Variance\")\n",
    "    axes1[2].set_ylim(ymin, ymax)\n",
    "    fig1.suptitle(\"Bias-Variance Decomposition (N/D={:.2f})\".format(N_D))\n",
    "    plt.show()\n",
    "def plot_single_vs_ensemble(dfs_list, Ks_list, N_D, feature_dim, ymin=0, ymax=1.0):\n",
    "    assert len(dfs_list) == len(Ks_list)\n",
    "    fig1, axes1 = plt.subplots(1, 3, figsize=figsize)\n",
    "    for i in range(3):\n",
    "        axes1[i].set_xscale('log')\n",
    "    dfs_list = [df[df['train_size']/feature_dim==N_D] for df in dfs_list]\n",
    "    for cur_df, K in zip(dfs_list, Ks_list):\n",
    "        test_loss = cur_df['test_loss']\n",
    "        bias2 = cur_df['bias2']\n",
    "        var = cur_df['variance']\n",
    "        P_N = cur_df['hidden_size']/cur_df['train_size']\n",
    "        axes1[0].plot(P_N, test_loss, label='K={}'.format(K))\n",
    "        axes1[1].plot(P_N, bias2, label='K={}'.format(K))\n",
    "        axes1[2].plot(P_N, var, label='K={}'.format(K))\n",
    "    \n",
    "    axes1[0].set_xlabel(\"P/N\")\n",
    "    axes1[0].set_ylabel(\"Test Loss\")\n",
    "    axes1[0].set_ylim(ymin, ymax)\n",
    "    \n",
    "    axes1[1].set_xlabel(\"P/N\")\n",
    "    axes1[1].set_ylabel(\"Bias Square\")\n",
    "    axes1[1].set_ylim(ymin, ymax)\n",
    "    \n",
    "    axes1[2].set_xlabel(\"P/N\")\n",
    "    axes1[2].set_ylabel(\"Variance\")\n",
    "    axes1[2].set_ylim(ymin, ymax)\n",
    "    fig1.suptitle(\"Bias-Variance Decomposition (N/D={:.2f})\".format(N_D))\n",
    "    plt.legend()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x360 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_single_vs_ensemble([K1_df, K2_df], [1, 2], N_Ds[0], feature_dim, ymax=2.0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# newoutdir = 'synthetic_coef_{}'.format(0.01)\n",
    "# if not os.path.exists(newoutdir):\n",
    "#     os.makedirs(newoutdir)\n",
    "# run_exps_ridge(train_sizes, N_Ds, P_Ns, trainset, test_size, feature_dim, num_classes, num_trials, 0.05,\n",
    "#          newoutdir, 'singleNN_output.csv', K = 1)\n",
    "# run_exps_ridge(train_sizes, N_Ds, P_Ns, trainset, test_size, feature_dim, num_classes, num_trials, 0.05,\n",
    "#          newoutdir, 'ensembleNNK=2_output.csv', K = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K2_df = pd.read_csv(os.path.join(newoutdir, 'ensembleNNK=2_output.csv'))\n",
    "# K1_df = pd.read_csv(os.path.join(newoutdir, 'singleNN_output.csv'))\n",
    "# plot_single_vs_ensemble([K1_df, K2_df], [1, 2], N_Ds[0], feature_dim, ymax=2.0)\n",
    "# plot_single_vs_ensemble([K1_df, K2_df], [1, 2], N_Ds[1], feature_dim, ymax=2.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
