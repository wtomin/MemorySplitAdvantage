{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Feature Model on Synthetic Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "class RF_NonLinear_Model(nn.Module):\n",
    "    def __init__(self, p, d, o, coef):\n",
    "        \"\"\"RF_models\n",
    "        \n",
    "        Args:\n",
    "            p (int): the hidden size\n",
    "            d (int): the input feature dimension\n",
    "            o (int): the output dimension\n",
    "            coef (floatl): the ridge regression penalty coefficient\n",
    "        \"\"\"\n",
    "        super(RF_NonLinear_Model, self).__init__()\n",
    "\n",
    "        self.fc1 = nn.Linear(d, p, bias=False)\n",
    "        stdv = 1\n",
    "        self.fc1.weight.data.normal_(mean=0.0, std = stdv) # Gaussian initialization\n",
    "        self.fc2 = nn.Linear(p, o, bias=False)\n",
    "        self.p = p\n",
    "        self.d = d\n",
    "        self.o = o \n",
    "        self.coef = coef\n",
    "\n",
    "    def forward(self, x):\n",
    "        z = 1/np.sqrt(self.d) * F.relu(1/np.sqrt(self.d)* torch.mm(x, self.fc1.weight.data.t()))\n",
    "        out = np.sqrt(self.d) * torch.mm(self.fc2.weight.data, z.t())\n",
    "        return out.t()\n",
    "    def optimize_second_layer(self, x, y):\n",
    "        N = x.size(0)\n",
    "        z = 1/np.sqrt(self.d) * F.relu(1/np.sqrt(self.d)* torch.mm(x, self.fc1.weight.data.t()))\n",
    "        identity = torch.eye(self.p)\n",
    "        identity = identity.to(x.device)\n",
    "        beta = torch.mm(z.t(), z) + self.coef*self.p*N/(self.d**2) * identity\n",
    "        beta = torch.mm(z, torch.inverse(beta))\n",
    "        a = 1/np.sqrt(self.d) * torch.mm(y.t(), beta) \n",
    "        self.fc2.weight = torch.nn.Parameter(a)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import queue\n",
    "class Ensemble_Two_Layer_NN(object):\n",
    "    def __init__(self, n_classifiers, p, d=784, o=10, coef=1e-1):\n",
    "        \"\"\"Ensemble_Two_Layer_NN\n",
    "        \n",
    "        Args:\n",
    "            p (int): the hidden size\n",
    "            d (int, optional): the input feature dimension\n",
    "            o (int, optional): the output dimension\n",
    "            coef (float, optional): the ridge regression penalty coefficient\n",
    "        \"\"\"\n",
    "        self.n_classifiers = n_classifiers\n",
    "        self.p = p\n",
    "        self.d = d \n",
    "        self.o = o \n",
    "        self.coef = coef\n",
    "        self.learners = queue.LifoQueue(maxsize = self.n_classifiers)\n",
    "        self.MODEL_TYPE = RF_NonLinear_Model\n",
    "    def __len__(self):\n",
    "        return len(self.learners.queue)\n",
    "    \n",
    "    def train_one_classifier(self, x, y):\n",
    "        model = self.MODEL_TYPE(self.p, self.d, self.o, self.coef)\n",
    "        if x.is_cuda:\n",
    "            model.cuda()\n",
    "        rho = 1/self.n_classifiers\n",
    "        model.optimize_second_layer(x, y)\n",
    "        self.learners.put([model, rho])\n",
    "    def put_model_rho(self, model, rho):\n",
    "        self.learners.put([model, rho])\n",
    "    def get_init_model(self, cuda=True):\n",
    "        model = self.MODEL_TYPE(self.p, self.d, self.o, self.coef)\n",
    "        if cuda:\n",
    "            model.cuda()\n",
    "        return model\n",
    "    def cuda(self):\n",
    "        if len(self) == 0:\n",
    "            return \n",
    "        else:\n",
    "            for model, rho in self.learners.queue:\n",
    "                model.cuda()\n",
    "            return\n",
    "    def train(self):\n",
    "        if len(self)!=0:\n",
    "            for model, rho in self.learners.queue:\n",
    "                model.train()\n",
    "    def eval(self):\n",
    "        if len(self)!=0:\n",
    "            for model, rho in self.learners.queue:\n",
    "                model.eval()\n",
    "    def forward(self, x):\n",
    "        Bs = x.size(0)\n",
    "        if len(self) == 0:\n",
    "            zeros = torch.zeros(Bs, self.o)\n",
    "            zeros = zeros.to(x.device)\n",
    "            return zeros\n",
    "        else:\n",
    "            outputs = torch.zeros(Bs, self.o)\n",
    "            outputs = outputs.to(x.device) \n",
    "            for model, rho in self.learners.queue:\n",
    "                output = model(x)\n",
    "                outputs += rho*output\n",
    "            return outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import numpy as np\n",
    "from typing import Type, Any, Callable, Union, List, Optional\n",
    "\n",
    "def sample_true_distribution(feature_dim, output_dim, norm = 1):\n",
    "    beta = np.random.multivariate_normal(np.zeros([feature_dim]), np.eye(feature_dim)/feature_dim, \n",
    "        size=(output_dim)).T\n",
    "    beta = beta/np.linalg.norm(beta, ord=2) * norm # F norm = norm\n",
    "    beta = beta.astype('float32')\n",
    "    return beta\n",
    "def random_draw_samples(beta, feature_dim, output_dim, num_samples):\n",
    "    data = np.random.multivariate_normal(\n",
    "        np.zeros([feature_dim])  , \n",
    "        np.eye(feature_dim), \n",
    "        size=(num_samples)) #X ~ N(0,1)\n",
    "    data = data.astype('float32')\n",
    "    targets = np.matmul(data, beta)\n",
    "    targets = targets.astype('float32')\n",
    "    return data, targets\n",
    "\n",
    "def sample_nosie_to_data(data, targets, output_dim, variance):\n",
    "\n",
    "    noises = np.random.multivariate_normal(\n",
    "        np.zeros([output_dim]), \n",
    "        np.eye(output_dim)* (variance),\n",
    "        size = (len(targets)))\n",
    "    noises = noises.astype('float32')\n",
    "    return data, targets + noises\n",
    "def sample_dataset(feature_dim, output_dim, F_norm, SNR, num_samples, beta=None):\n",
    "\n",
    "    if beta is None:\n",
    "        beta = sample_true_distribution(feature_dim, output_dim, F_norm)\n",
    "    data, targets = random_draw_samples(beta, feature_dim, output_dim, num_samples)\n",
    "    if SNR !=0:\n",
    "        variance = F_norm * SNR\n",
    "        data, targets = sample_nosie_to_data(data, targets, output_dim, variance)\n",
    "    return torch.from_numpy(data), torch.from_numpy(targets)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "import copy \n",
    "\n",
    "# def get_subsample_dataset(trainset, subset):\n",
    "#     trainsubset = copy.deepcopy(trainset)\n",
    "#     trainsubset.data = [trainsubset.data[index] for index in subset]\n",
    "#     trainsubset.targets = [trainsubset.targets[index] for index in subset]\n",
    "#     return trainsubset\n",
    "def fix_width_number(width, n_classifiers):\n",
    "    return max(1, width//n_classifiers)\n",
    "\n",
    "# Training\n",
    "def train(net, train_beta, train_size, feature_dim, output_dim, F_norm, SNR):\n",
    "    net.train()\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    trainset = sample_dataset(feature_dim, output_dim, F_norm, SNR, train_size, beta = train_beta)\n",
    "    trainset = TensorDataset(*trainset)\n",
    "    trainloader = torch.utils.data.DataLoader(trainset, batch_size=len(trainset), shuffle=True)\n",
    "    trainloader = iter(trainloader)\n",
    "    inputs, targets = next(trainloader)\n",
    "    Bs = inputs.size(0)\n",
    "    inputs = inputs.reshape(Bs, -1)\n",
    "    inputs, targets = inputs.cuda(), targets.cuda()\n",
    "    for _ in range(net.n_classifiers):\n",
    "        net.train_one_classifier(inputs, targets)\n",
    "    outputs = net.forward(inputs)\n",
    "    loss = criterion(outputs, targets)\n",
    "    train_loss = loss.item() * outputs.numel()\n",
    "    total = targets.size(0)\n",
    "    return train_loss/ total\n",
    "\n",
    "# Test\n",
    "def test(net, testloader):\n",
    "    net.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs, targets) in enumerate(testloader):\n",
    "            inputs, targets = inputs.cuda(), targets.cuda()\n",
    "            Bs = inputs.size(0)\n",
    "            inputs = inputs.reshape(Bs, -1)\n",
    "            outputs = net.forward(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            test_loss += loss.item() * outputs.numel()\n",
    "            total += targets.size(0)\n",
    "    return test_loss / total\n",
    "\n",
    "def compute_bias_variance(net, testloader, trial, OUTPUST_SUM, OUTPUTS_SUMNORMSQUARED):\n",
    "    net.eval()\n",
    "    bias2 = 0\n",
    "    variance = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs, targets) in enumerate(testloader):\n",
    "            inputs, targets = inputs.cuda(), targets.cuda()\n",
    "            Bs = inputs.size(0)\n",
    "            inputs = inputs.reshape(Bs, -1)\n",
    "            outputs = net.forward(inputs)\n",
    "            OUTPUST_SUM[total:(total + targets.size(0)), :] += outputs\n",
    "            OUTPUTS_SUMNORMSQUARED[total:total + targets.size(0)] += outputs.norm(dim=1) ** 2.0\n",
    "\n",
    "            bias2 += (OUTPUST_SUM[total:total + targets.size(0), :] / (trial + 1) - targets).norm() ** 2.0\n",
    "            variance += OUTPUTS_SUMNORMSQUARED[total:total + targets.size(0)].sum()/(trial + 1) - (OUTPUST_SUM[total:total + targets.size(0), :]/(trial + 1)).norm() ** 2.0\n",
    "            total += targets.size(0)\n",
    "\n",
    "    return bias2 / total, variance / total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the synthetic dataset:\n",
    "$y=X\\beta + \\epsilon_\\mu, ||\\beta|| = F, \\epsilon_{mu} ~ \\mathcal{N}(0, 1), SNR = F/\\tau$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "feature_dim = 400\n",
    "num_classes = 1\n",
    "SNR = 1\n",
    "test_size = 10000\n",
    "beta = sample_true_distribution(feature_dim, num_classes, norm = 1)\n",
    "#trainset = Synthetic_Dataset(feature_dim=feature_dim, output_dim=1, num_samples=50000, seed=10, SNR = SNR)\n",
    "testset = sample_dataset(feature_dim, num_classes, F_norm = 1, SNR =0., num_samples=test_size, beta = beta)\n",
    "testset = TensorDataset(*testset)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=100, shuffle=False, num_workers=4)\n",
    "# loss definition\n",
    "criterion = nn.MSELoss(reduction='mean').cuda()\n",
    "\n",
    "num_trials = 50\n",
    "coef = 0.1\n",
    "N_Ds = [1]\n",
    "train_sizes = [int(np.around(x*feature_dim)) for x in N_Ds]\n",
    "\n",
    "P_Ns = 10** np.linspace(-2, 1, 50)\n",
    "\n",
    "outdir = 'synthetic_coef_{}'.format(coef)\n",
    "if not os.path.exists(outdir):\n",
    "    os.makedirs(outdir)\n",
    "\n",
    "def run_exps_ridge(train_sizes, N_Ds, P_Ns, train_beta, test_size, feature_dim, num_classes, num_trials, coef,\n",
    "             outdir, save_csv, SNR, K = 1, F_norm= 1):\n",
    "    df = pd.DataFrame()\n",
    "    # When training single NN\n",
    "    for train_size in train_sizes:\n",
    "        hidden_sizes = P_Ns * train_size\n",
    "        hidden_sizes = np.unique([int(np.around(x)) for x in hidden_sizes])\n",
    "        for hidden_size in hidden_sizes:\n",
    "            TRAIN_LOSS_SUM = 0.0\n",
    "            TEST_LOSS_SUM = 0.0\n",
    "            #permute_index = np.random.permutation(len(trainset))\n",
    "            OUTPUST_SUM = torch.Tensor(test_size, num_classes).zero_().cuda()\n",
    "            OUTPUTS_SUMNORMSQUARED = torch.Tensor(test_size).zero_().cuda()\n",
    "            for trial in range(num_trials):\n",
    "                net = Ensemble_Two_Layer_NN(n_classifiers = K, p = fix_width_number(hidden_size, K), d=feature_dim, o=num_classes, coef=coef)\n",
    "                net.cuda()\n",
    "                train_loss = train(net, train_beta, train_size, feature_dim, num_classes, F_norm, SNR)\n",
    "                test_loss = test(net, testloader)\n",
    "\n",
    "                TRAIN_LOSS_SUM += train_loss\n",
    "                TEST_LOSS_SUM += test_loss\n",
    "\n",
    "                # compute bias and variance\n",
    "                bias2, variance = compute_bias_variance(net, testloader, trial, OUTPUST_SUM, OUTPUTS_SUMNORMSQUARED)\n",
    "                variance_unbias = variance * num_trials / (num_trials - 1.0)\n",
    "                bias2_unbias = TEST_LOSS_SUM / (trial + 1) - variance_unbias\n",
    "                print('Train size: [{}] hidden size: [{}] trial: {}, train_loss: {:.6f}, test loss: {:.6f}, bias2: {}, variance: {}'.format(\n",
    "                    train_size, hidden_size,\n",
    "                    trial, TRAIN_LOSS_SUM / (trial + 1),  TEST_LOSS_SUM / (trial + 1),\n",
    "                    bias2_unbias, variance_unbias))\n",
    "                torch.cuda.empty_cache()\n",
    "            print('#'*50)\n",
    "            df = df.append({'train_size': train_size, 'hidden_size':hidden_size, \n",
    "                            'train_loss': TRAIN_LOSS_SUM / (trial + 1), \n",
    "                            'test_loss': TEST_LOSS_SUM / (trial + 1), \n",
    "                           'variance': variance_unbias.item(),\n",
    "                           'bias2': bias2_unbias.item()}, ignore_index=True)\n",
    "            df.to_csv(os.path.join(outdir, save_csv))\n",
    "    df.to_csv(os.path.join(outdir, save_csv))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [4] trial: 0, train_loss: 1.873188, test loss: 1.010338, bias2: 1.0103384256362915, variance: -1.2164212345733283e-11\n",
      "Train size: [400] hidden size: [4] trial: 1, train_loss: 1.872133, test loss: 1.013576, bias2: 1.0052107572555542, variance: 0.008365447632968426\n",
      "Train size: [400] hidden size: [4] trial: 2, train_loss: 1.933110, test loss: 1.015678, bias2: 1.006278157234192, variance: 0.00939978752285242\n",
      "Train size: [400] hidden size: [4] trial: 3, train_loss: 1.922342, test loss: 1.019024, bias2: 1.00632643699646, variance: 0.01269767340272665\n",
      "Train size: [400] hidden size: [4] trial: 4, train_loss: 1.953800, test loss: 1.022892, bias2: 1.008689522743225, variance: 0.014202233403921127\n",
      "Train size: [400] hidden size: [4] trial: 5, train_loss: 1.954054, test loss: 1.033255, bias2: 1.0084874629974365, variance: 0.02476736716926098\n",
      "Train size: [400] hidden size: [4] trial: 6, train_loss: 1.957506, test loss: 1.051093, bias2: 1.0047799348831177, variance: 0.046312619000673294\n",
      "Train size: [400] hidden size: [4] trial: 7, train_loss: 1.949019, test loss: 1.047775, bias2: 1.0040162801742554, variance: 0.043758463114500046\n",
      "Train size: [400] hidden size: [4] trial: 8, train_loss: 1.947344, test loss: 1.042013, bias2: 1.000745177268982, variance: 0.041267503052949905\n",
      "Train size: [400] hidden size: [4] trial: 9, train_loss: 1.956620, test loss: 1.040976, bias2: 1.0008305311203003, variance: 0.04014573618769646\n",
      "Train size: [400] hidden size: [4] trial: 10, train_loss: 1.969985, test loss: 1.038685, bias2: 1.0007240772247314, variance: 0.03796137124300003\n",
      "Train size: [400] hidden size: [4] trial: 11, train_loss: 1.960080, test loss: 1.037440, bias2: 0.9990932941436768, variance: 0.038346316665410995\n",
      "Train size: [400] hidden size: [4] trial: 12, train_loss: 1.947370, test loss: 1.036872, bias2: 0.9991185069084167, variance: 0.03775341436266899\n",
      "Train size: [400] hidden size: [4] trial: 13, train_loss: 1.944265, test loss: 1.035509, bias2: 0.9981653690338135, variance: 0.03734312579035759\n",
      "Train size: [400] hidden size: [4] trial: 14, train_loss: 1.935803, test loss: 1.033709, bias2: 0.9972842931747437, variance: 0.036424897611141205\n",
      "Train size: [400] hidden size: [4] trial: 15, train_loss: 1.941862, test loss: 1.034710, bias2: 0.9953107833862305, variance: 0.03939928859472275\n",
      "Train size: [400] hidden size: [4] trial: 16, train_loss: 1.934501, test loss: 1.032069, bias2: 0.9925203919410706, variance: 0.03954823687672615\n",
      "Train size: [400] hidden size: [4] trial: 17, train_loss: 1.947449, test loss: 1.031469, bias2: 0.9931572675704956, variance: 0.03831150382757187\n",
      "Train size: [400] hidden size: [4] trial: 18, train_loss: 1.938197, test loss: 1.032130, bias2: 0.989767849445343, variance: 0.042362410575151443\n",
      "Train size: [400] hidden size: [4] trial: 19, train_loss: 1.938451, test loss: 1.031252, bias2: 0.9906092882156372, variance: 0.040643006563186646\n",
      "Train size: [400] hidden size: [4] trial: 20, train_loss: 1.942068, test loss: 1.031915, bias2: 0.9919036626815796, variance: 0.040011752396821976\n",
      "Train size: [400] hidden size: [4] trial: 21, train_loss: 1.947082, test loss: 1.030506, bias2: 0.9909691214561462, variance: 0.03953655809164047\n",
      "Train size: [400] hidden size: [4] trial: 22, train_loss: 1.936925, test loss: 1.030275, bias2: 0.9908740520477295, variance: 0.03940096125006676\n",
      "Train size: [400] hidden size: [4] trial: 23, train_loss: 1.930643, test loss: 1.029754, bias2: 0.9906335473060608, variance: 0.03912051394581795\n",
      "Train size: [400] hidden size: [4] trial: 24, train_loss: 1.933659, test loss: 1.029031, bias2: 0.9907742738723755, variance: 0.03825712203979492\n",
      "Train size: [400] hidden size: [4] trial: 25, train_loss: 1.929699, test loss: 1.027905, bias2: 0.9903075098991394, variance: 0.03759785741567612\n",
      "Train size: [400] hidden size: [4] trial: 26, train_loss: 1.927730, test loss: 1.028444, bias2: 0.9902822375297546, variance: 0.03816124424338341\n",
      "Train size: [400] hidden size: [4] trial: 27, train_loss: 1.926939, test loss: 1.027655, bias2: 0.9904375672340393, variance: 0.037217769771814346\n",
      "Train size: [400] hidden size: [4] trial: 28, train_loss: 1.927394, test loss: 1.027016, bias2: 0.9907970428466797, variance: 0.03621898218989372\n",
      "Train size: [400] hidden size: [4] trial: 29, train_loss: 1.936129, test loss: 1.026823, bias2: 0.9911959171295166, variance: 0.03562739118933678\n",
      "Train size: [400] hidden size: [4] trial: 30, train_loss: 1.941924, test loss: 1.026327, bias2: 0.9912310242652893, variance: 0.03509586676955223\n",
      "Train size: [400] hidden size: [4] trial: 31, train_loss: 1.940421, test loss: 1.026471, bias2: 0.9912662506103516, variance: 0.03520441800355911\n",
      "Train size: [400] hidden size: [4] trial: 32, train_loss: 1.936380, test loss: 1.025628, bias2: 0.9912052154541016, variance: 0.03442249819636345\n",
      "Train size: [400] hidden size: [4] trial: 33, train_loss: 1.943619, test loss: 1.025129, bias2: 0.9915892481803894, variance: 0.03353957459330559\n",
      "Train size: [400] hidden size: [4] trial: 34, train_loss: 1.944263, test loss: 1.025006, bias2: 0.9912246465682983, variance: 0.03378155454993248\n",
      "Train size: [400] hidden size: [4] trial: 35, train_loss: 1.947157, test loss: 1.024959, bias2: 0.9916272759437561, variance: 0.033331308513879776\n",
      "Train size: [400] hidden size: [4] trial: 36, train_loss: 1.944122, test loss: 1.024584, bias2: 0.9915662407875061, variance: 0.033018190413713455\n",
      "Train size: [400] hidden size: [4] trial: 37, train_loss: 1.939607, test loss: 1.024825, bias2: 0.9921706914901733, variance: 0.03265415504574776\n",
      "Train size: [400] hidden size: [4] trial: 38, train_loss: 1.945316, test loss: 1.024332, bias2: 0.9922442436218262, variance: 0.0320875383913517\n",
      "Train size: [400] hidden size: [4] trial: 39, train_loss: 1.947554, test loss: 1.024148, bias2: 0.9921339154243469, variance: 0.03201454505324364\n",
      "Train size: [400] hidden size: [4] trial: 40, train_loss: 1.947133, test loss: 1.023602, bias2: 0.9921011924743652, variance: 0.03150031343102455\n",
      "Train size: [400] hidden size: [4] trial: 41, train_loss: 1.941550, test loss: 1.023524, bias2: 0.9924390316009521, variance: 0.03108503296971321\n",
      "Train size: [400] hidden size: [4] trial: 42, train_loss: 1.940576, test loss: 1.023368, bias2: 0.9928467273712158, variance: 0.03052125684916973\n",
      "Train size: [400] hidden size: [4] trial: 43, train_loss: 1.946005, test loss: 1.023363, bias2: 0.9931210875511169, variance: 0.030242010951042175\n",
      "Train size: [400] hidden size: [4] trial: 44, train_loss: 1.947183, test loss: 1.024229, bias2: 0.993152916431427, variance: 0.03107577934861183\n",
      "Train size: [400] hidden size: [4] trial: 45, train_loss: 1.944058, test loss: 1.024285, bias2: 0.9936301708221436, variance: 0.030655261129140854\n",
      "Train size: [400] hidden size: [4] trial: 46, train_loss: 1.944124, test loss: 1.024526, bias2: 0.9939743876457214, variance: 0.03055182471871376\n",
      "Train size: [400] hidden size: [4] trial: 47, train_loss: 1.939293, test loss: 1.024508, bias2: 0.9942803382873535, variance: 0.030227765440940857\n",
      "Train size: [400] hidden size: [4] trial: 48, train_loss: 1.938306, test loss: 1.024330, bias2: 0.9944084882736206, variance: 0.029921194538474083\n",
      "Train size: [400] hidden size: [4] trial: 49, train_loss: 1.936679, test loss: 1.024180, bias2: 0.9944340586662292, variance: 0.029745986685156822\n",
      "##################################################\n",
      "Train size: [400] hidden size: [5] trial: 0, train_loss: 2.226363, test loss: 1.013389, bias2: 1.013388991355896, variance: 2.7977689609492984e-10\n",
      "Train size: [400] hidden size: [5] trial: 1, train_loss: 2.054454, test loss: 1.011871, bias2: 1.0006966590881348, variance: 0.011174274608492851\n",
      "Train size: [400] hidden size: [5] trial: 2, train_loss: 2.014141, test loss: 1.013991, bias2: 1.0001622438430786, variance: 0.013829264789819717\n",
      "Train size: [400] hidden size: [5] trial: 3, train_loss: 2.059222, test loss: 1.010570, bias2: 0.9910808205604553, variance: 0.019488617777824402\n",
      "Train size: [400] hidden size: [5] trial: 4, train_loss: 2.107990, test loss: 1.016275, bias2: 0.9934219717979431, variance: 0.022852715104818344\n",
      "Train size: [400] hidden size: [5] trial: 5, train_loss: 2.096219, test loss: 1.018048, bias2: 0.995384931564331, variance: 0.022663380950689316\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [5] trial: 6, train_loss: 2.079584, test loss: 1.016961, bias2: 0.9929576516151428, variance: 0.024003690108656883\n",
      "Train size: [400] hidden size: [5] trial: 7, train_loss: 2.052676, test loss: 1.017833, bias2: 0.9923009872436523, variance: 0.025532495230436325\n",
      "Train size: [400] hidden size: [5] trial: 8, train_loss: 2.025000, test loss: 1.016222, bias2: 0.9916982054710388, variance: 0.024523913860321045\n",
      "Train size: [400] hidden size: [5] trial: 9, train_loss: 2.025075, test loss: 1.015962, bias2: 0.9922941327095032, variance: 0.023667994886636734\n",
      "Train size: [400] hidden size: [5] trial: 10, train_loss: 2.016794, test loss: 1.014742, bias2: 0.9913386106491089, variance: 0.023403288796544075\n",
      "Train size: [400] hidden size: [5] trial: 11, train_loss: 2.005108, test loss: 1.018529, bias2: 0.9930344820022583, variance: 0.02549406886100769\n",
      "Train size: [400] hidden size: [5] trial: 12, train_loss: 2.024300, test loss: 1.023911, bias2: 0.9914436936378479, variance: 0.03246694058179855\n",
      "Train size: [400] hidden size: [5] trial: 13, train_loss: 2.033522, test loss: 1.024297, bias2: 0.992138683795929, variance: 0.03215830773115158\n",
      "Train size: [400] hidden size: [5] trial: 14, train_loss: 2.026415, test loss: 1.024716, bias2: 0.9915401339530945, variance: 0.03317589685320854\n",
      "Train size: [400] hidden size: [5] trial: 15, train_loss: 2.016689, test loss: 1.027385, bias2: 0.9933713674545288, variance: 0.03401317447423935\n",
      "Train size: [400] hidden size: [5] trial: 16, train_loss: 2.010104, test loss: 1.025156, bias2: 0.9916330575942993, variance: 0.0335225947201252\n",
      "Train size: [400] hidden size: [5] trial: 17, train_loss: 2.010625, test loss: 1.025473, bias2: 0.9927518367767334, variance: 0.032720692455768585\n",
      "Train size: [400] hidden size: [5] trial: 18, train_loss: 2.015162, test loss: 1.025279, bias2: 0.9912569522857666, variance: 0.03402223438024521\n",
      "Train size: [400] hidden size: [5] trial: 19, train_loss: 2.009836, test loss: 1.024663, bias2: 0.9897598624229431, variance: 0.03490360081195831\n",
      "Train size: [400] hidden size: [5] trial: 20, train_loss: 2.008490, test loss: 1.024905, bias2: 0.9903706312179565, variance: 0.034534793347120285\n",
      "Train size: [400] hidden size: [5] trial: 21, train_loss: 2.006432, test loss: 1.026129, bias2: 0.9900898337364197, variance: 0.03603951632976532\n",
      "Train size: [400] hidden size: [5] trial: 22, train_loss: 2.005919, test loss: 1.025242, bias2: 0.9902485013008118, variance: 0.03499394282698631\n",
      "Train size: [400] hidden size: [5] trial: 23, train_loss: 2.010724, test loss: 1.025424, bias2: 0.990653932094574, variance: 0.03476971760392189\n",
      "Train size: [400] hidden size: [5] trial: 24, train_loss: 2.005346, test loss: 1.024543, bias2: 0.9901394844055176, variance: 0.03440353646874428\n",
      "Train size: [400] hidden size: [5] trial: 25, train_loss: 2.019299, test loss: 1.025624, bias2: 0.9910426139831543, variance: 0.03458166867494583\n",
      "Train size: [400] hidden size: [5] trial: 26, train_loss: 2.022299, test loss: 1.024542, bias2: 0.9905229806900024, variance: 0.03401949256658554\n",
      "Train size: [400] hidden size: [5] trial: 27, train_loss: 2.030051, test loss: 1.024195, bias2: 0.9901334643363953, variance: 0.0340617410838604\n",
      "Train size: [400] hidden size: [5] trial: 28, train_loss: 2.021545, test loss: 1.025089, bias2: 0.9900795817375183, variance: 0.035009805113077164\n",
      "Train size: [400] hidden size: [5] trial: 29, train_loss: 2.023084, test loss: 1.024357, bias2: 0.9901372194290161, variance: 0.03421963378787041\n",
      "Train size: [400] hidden size: [5] trial: 30, train_loss: 2.021035, test loss: 1.024412, bias2: 0.9906080365180969, variance: 0.03380436822772026\n",
      "Train size: [400] hidden size: [5] trial: 31, train_loss: 2.027501, test loss: 1.023777, bias2: 0.9907737970352173, variance: 0.033003468066453934\n",
      "Train size: [400] hidden size: [5] trial: 32, train_loss: 2.025973, test loss: 1.023299, bias2: 0.99091637134552, variance: 0.03238258138298988\n",
      "Train size: [400] hidden size: [5] trial: 33, train_loss: 2.024137, test loss: 1.023101, bias2: 0.9900916218757629, variance: 0.03300924599170685\n",
      "Train size: [400] hidden size: [5] trial: 34, train_loss: 2.026259, test loss: 1.022931, bias2: 0.9901386499404907, variance: 0.032792240381240845\n",
      "Train size: [400] hidden size: [5] trial: 35, train_loss: 2.026702, test loss: 1.022873, bias2: 0.9900621771812439, variance: 0.032810721546411514\n",
      "Train size: [400] hidden size: [5] trial: 36, train_loss: 2.019771, test loss: 1.022463, bias2: 0.9904111623764038, variance: 0.03205215930938721\n",
      "Train size: [400] hidden size: [5] trial: 37, train_loss: 2.017247, test loss: 1.022217, bias2: 0.9904810190200806, variance: 0.03173555061221123\n",
      "Train size: [400] hidden size: [5] trial: 38, train_loss: 2.009405, test loss: 1.022006, bias2: 0.990341305732727, variance: 0.03166482225060463\n",
      "Train size: [400] hidden size: [5] trial: 39, train_loss: 2.006558, test loss: 1.021888, bias2: 0.9903217554092407, variance: 0.03156639635562897\n",
      "Train size: [400] hidden size: [5] trial: 40, train_loss: 2.004822, test loss: 1.022370, bias2: 0.9902299046516418, variance: 0.03214041143655777\n",
      "Train size: [400] hidden size: [5] trial: 41, train_loss: 2.005505, test loss: 1.022014, bias2: 0.9903252720832825, variance: 0.031688980758190155\n",
      "Train size: [400] hidden size: [5] trial: 42, train_loss: 2.002739, test loss: 1.021799, bias2: 0.99006587266922, variance: 0.03173309937119484\n",
      "Train size: [400] hidden size: [5] trial: 43, train_loss: 1.994117, test loss: 1.021356, bias2: 0.9899325370788574, variance: 0.03142367675900459\n",
      "Train size: [400] hidden size: [5] trial: 44, train_loss: 1.991738, test loss: 1.021198, bias2: 0.989936113357544, variance: 0.031261950731277466\n",
      "Train size: [400] hidden size: [5] trial: 45, train_loss: 1.989930, test loss: 1.021689, bias2: 0.9900575280189514, variance: 0.03163152560591698\n",
      "Train size: [400] hidden size: [5] trial: 46, train_loss: 1.989104, test loss: 1.021369, bias2: 0.989916980266571, variance: 0.031452253460884094\n",
      "Train size: [400] hidden size: [5] trial: 47, train_loss: 1.990088, test loss: 1.021560, bias2: 0.9898761510848999, variance: 0.03168405219912529\n",
      "Train size: [400] hidden size: [5] trial: 48, train_loss: 1.992258, test loss: 1.021429, bias2: 0.9897820949554443, variance: 0.03164646029472351\n",
      "Train size: [400] hidden size: [5] trial: 49, train_loss: 1.995553, test loss: 1.021042, bias2: 0.9888545274734497, variance: 0.03218759596347809\n",
      "##################################################\n",
      "Train size: [400] hidden size: [6] trial: 0, train_loss: 1.915273, test loss: 1.059013, bias2: 1.0590132474899292, variance: 9.731369876586626e-11\n",
      "Train size: [400] hidden size: [6] trial: 1, train_loss: 1.935711, test loss: 1.033417, bias2: 1.0147738456726074, variance: 0.018643587827682495\n",
      "Train size: [400] hidden size: [6] trial: 2, train_loss: 2.028959, test loss: 1.032625, bias2: 1.0075432062149048, variance: 0.025082213804125786\n",
      "Train size: [400] hidden size: [6] trial: 3, train_loss: 2.015089, test loss: 1.031567, bias2: 1.0007309913635254, variance: 0.03083563782274723\n",
      "Train size: [400] hidden size: [6] trial: 4, train_loss: 2.024119, test loss: 1.033340, bias2: 1.0012922286987305, variance: 0.03204740583896637\n",
      "Train size: [400] hidden size: [6] trial: 5, train_loss: 2.031366, test loss: 1.030061, bias2: 1.0004637241363525, variance: 0.029597654938697815\n",
      "Train size: [400] hidden size: [6] trial: 6, train_loss: 2.021753, test loss: 1.030348, bias2: 1.0003113746643066, variance: 0.0300366822630167\n",
      "Train size: [400] hidden size: [6] trial: 7, train_loss: 2.017265, test loss: 1.028371, bias2: 0.9994354844093323, variance: 0.028935251757502556\n",
      "Train size: [400] hidden size: [6] trial: 8, train_loss: 2.033426, test loss: 1.025975, bias2: 0.9927780628204346, variance: 0.033196695148944855\n",
      "Train size: [400] hidden size: [6] trial: 9, train_loss: 2.038508, test loss: 1.025454, bias2: 0.9933242797851562, variance: 0.032129496335983276\n",
      "Train size: [400] hidden size: [6] trial: 10, train_loss: 2.039393, test loss: 1.027586, bias2: 0.9906150698661804, variance: 0.036970797926187515\n",
      "Train size: [400] hidden size: [6] trial: 11, train_loss: 2.020814, test loss: 1.027713, bias2: 0.9900428056716919, variance: 0.037670016288757324\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [6] trial: 12, train_loss: 2.024855, test loss: 1.027278, bias2: 0.9895469546318054, variance: 0.037730872631073\n",
      "Train size: [400] hidden size: [6] trial: 13, train_loss: 2.008937, test loss: 1.029316, bias2: 0.9904427528381348, variance: 0.03887283056974411\n",
      "Train size: [400] hidden size: [6] trial: 14, train_loss: 2.007208, test loss: 1.031327, bias2: 0.9913281202316284, variance: 0.039998866617679596\n",
      "Train size: [400] hidden size: [6] trial: 15, train_loss: 2.012604, test loss: 1.033236, bias2: 0.9917299747467041, variance: 0.041505783796310425\n",
      "Train size: [400] hidden size: [6] trial: 16, train_loss: 2.019094, test loss: 1.033535, bias2: 0.993302047252655, variance: 0.04023308679461479\n",
      "Train size: [400] hidden size: [6] trial: 17, train_loss: 2.018945, test loss: 1.033127, bias2: 0.9941985607147217, variance: 0.03892827406525612\n",
      "Train size: [400] hidden size: [6] trial: 18, train_loss: 2.018125, test loss: 1.033093, bias2: 0.9934868812561035, variance: 0.03960574418306351\n",
      "Train size: [400] hidden size: [6] trial: 19, train_loss: 2.017591, test loss: 1.032304, bias2: 0.9935507774353027, variance: 0.03875303268432617\n",
      "Train size: [400] hidden size: [6] trial: 20, train_loss: 2.010609, test loss: 1.031593, bias2: 0.9920737743377686, variance: 0.03951966017484665\n",
      "Train size: [400] hidden size: [6] trial: 21, train_loss: 2.015582, test loss: 1.030997, bias2: 0.9919404983520508, variance: 0.039057016372680664\n",
      "Train size: [400] hidden size: [6] trial: 22, train_loss: 2.021338, test loss: 1.030328, bias2: 0.992416262626648, variance: 0.03791152685880661\n",
      "Train size: [400] hidden size: [6] trial: 23, train_loss: 2.016483, test loss: 1.029867, bias2: 0.9924145936965942, variance: 0.03745267167687416\n",
      "Train size: [400] hidden size: [6] trial: 24, train_loss: 2.004359, test loss: 1.029417, bias2: 0.9928684234619141, variance: 0.03654906526207924\n",
      "Train size: [400] hidden size: [6] trial: 25, train_loss: 2.006753, test loss: 1.028758, bias2: 0.9916259050369263, variance: 0.0371326245367527\n",
      "Train size: [400] hidden size: [6] trial: 26, train_loss: 2.010313, test loss: 1.028274, bias2: 0.991367518901825, variance: 0.03690655156970024\n",
      "Train size: [400] hidden size: [6] trial: 27, train_loss: 2.004319, test loss: 1.028543, bias2: 0.9917561411857605, variance: 0.03678683191537857\n",
      "Train size: [400] hidden size: [6] trial: 28, train_loss: 1.997626, test loss: 1.028266, bias2: 0.9915940761566162, variance: 0.036671653389930725\n",
      "Train size: [400] hidden size: [6] trial: 29, train_loss: 1.992707, test loss: 1.028509, bias2: 0.9918403625488281, variance: 0.03666901960968971\n",
      "Train size: [400] hidden size: [6] trial: 30, train_loss: 1.993782, test loss: 1.028236, bias2: 0.9921475052833557, variance: 0.03608878701925278\n",
      "Train size: [400] hidden size: [6] trial: 31, train_loss: 1.994818, test loss: 1.027561, bias2: 0.99187171459198, variance: 0.03568971902132034\n",
      "Train size: [400] hidden size: [6] trial: 32, train_loss: 2.002082, test loss: 1.027112, bias2: 0.9921461343765259, variance: 0.0349661223590374\n",
      "Train size: [400] hidden size: [6] trial: 33, train_loss: 1.997044, test loss: 1.026974, bias2: 0.9918535947799683, variance: 0.03512025624513626\n",
      "Train size: [400] hidden size: [6] trial: 34, train_loss: 1.997054, test loss: 1.026657, bias2: 0.9911876320838928, variance: 0.03546970337629318\n",
      "Train size: [400] hidden size: [6] trial: 35, train_loss: 1.994784, test loss: 1.027960, bias2: 0.9911948442459106, variance: 0.036765240132808685\n",
      "Train size: [400] hidden size: [6] trial: 36, train_loss: 1.988536, test loss: 1.028087, bias2: 0.9915697574615479, variance: 0.036517489701509476\n",
      "Train size: [400] hidden size: [6] trial: 37, train_loss: 1.982282, test loss: 1.028873, bias2: 0.9921894669532776, variance: 0.03668315336108208\n",
      "Train size: [400] hidden size: [6] trial: 38, train_loss: 1.988236, test loss: 1.029160, bias2: 0.9918819069862366, variance: 0.037278588861227036\n",
      "Train size: [400] hidden size: [6] trial: 39, train_loss: 1.986201, test loss: 1.029189, bias2: 0.9919163584709167, variance: 0.037272755056619644\n",
      "Train size: [400] hidden size: [6] trial: 40, train_loss: 1.985421, test loss: 1.028808, bias2: 0.9922691583633423, variance: 0.036538947373628616\n",
      "Train size: [400] hidden size: [6] trial: 41, train_loss: 1.985851, test loss: 1.028423, bias2: 0.9921875596046448, variance: 0.03623576834797859\n",
      "Train size: [400] hidden size: [6] trial: 42, train_loss: 1.991108, test loss: 1.027734, bias2: 0.9914951920509338, variance: 0.03623909503221512\n",
      "Train size: [400] hidden size: [6] trial: 43, train_loss: 1.988394, test loss: 1.027881, bias2: 0.9913910627365112, variance: 0.03649007901549339\n",
      "Train size: [400] hidden size: [6] trial: 44, train_loss: 1.981258, test loss: 1.027746, bias2: 0.9916327595710754, variance: 0.03611283004283905\n",
      "Train size: [400] hidden size: [6] trial: 45, train_loss: 1.987731, test loss: 1.027403, bias2: 0.9914624691009521, variance: 0.035940997302532196\n",
      "Train size: [400] hidden size: [6] trial: 46, train_loss: 1.989690, test loss: 1.028106, bias2: 0.9908992052078247, variance: 0.0372069887816906\n",
      "Train size: [400] hidden size: [6] trial: 47, train_loss: 1.988824, test loss: 1.028617, bias2: 0.991025447845459, variance: 0.03759179264307022\n",
      "Train size: [400] hidden size: [6] trial: 48, train_loss: 1.989461, test loss: 1.028314, bias2: 0.9898784160614014, variance: 0.038435447961091995\n",
      "Train size: [400] hidden size: [6] trial: 49, train_loss: 1.989406, test loss: 1.027941, bias2: 0.9900137186050415, variance: 0.037927646189928055\n",
      "##################################################\n",
      "Train size: [400] hidden size: [7] trial: 0, train_loss: 2.018064, test loss: 1.022247, bias2: 1.0222468376159668, variance: -2.2503794661066223e-10\n",
      "Train size: [400] hidden size: [7] trial: 1, train_loss: 1.937378, test loss: 1.029548, bias2: 1.0124176740646362, variance: 0.017130276188254356\n",
      "Train size: [400] hidden size: [7] trial: 2, train_loss: 1.925715, test loss: 1.030103, bias2: 1.0020036697387695, variance: 0.0280997846275568\n",
      "Train size: [400] hidden size: [7] trial: 3, train_loss: 1.953007, test loss: 1.034711, bias2: 0.9984031319618225, variance: 0.03630772978067398\n",
      "Train size: [400] hidden size: [7] trial: 4, train_loss: 1.945806, test loss: 1.033681, bias2: 0.9958374500274658, variance: 0.03784323111176491\n",
      "Train size: [400] hidden size: [7] trial: 5, train_loss: 1.927855, test loss: 1.031893, bias2: 0.9933647513389587, variance: 0.038527894765138626\n",
      "Train size: [400] hidden size: [7] trial: 6, train_loss: 1.930522, test loss: 1.029722, bias2: 0.9895458817481995, variance: 0.04017595946788788\n",
      "Train size: [400] hidden size: [7] trial: 7, train_loss: 1.949381, test loss: 1.028008, bias2: 0.9845218062400818, variance: 0.04348663240671158\n",
      "Train size: [400] hidden size: [7] trial: 8, train_loss: 1.979530, test loss: 1.031048, bias2: 0.9866530895233154, variance: 0.0443946048617363\n",
      "Train size: [400] hidden size: [7] trial: 9, train_loss: 1.978465, test loss: 1.028588, bias2: 0.9867832064628601, variance: 0.0418047159910202\n",
      "Train size: [400] hidden size: [7] trial: 10, train_loss: 1.975731, test loss: 1.027234, bias2: 0.9861927628517151, variance: 0.041040726006031036\n",
      "Train size: [400] hidden size: [7] trial: 11, train_loss: 1.988584, test loss: 1.029739, bias2: 0.983940839767456, variance: 0.04579852893948555\n",
      "Train size: [400] hidden size: [7] trial: 12, train_loss: 1.994722, test loss: 1.028520, bias2: 0.9829939603805542, variance: 0.045526400208473206\n",
      "Train size: [400] hidden size: [7] trial: 13, train_loss: 1.983064, test loss: 1.028478, bias2: 0.9816069602966309, variance: 0.046870727092027664\n",
      "Train size: [400] hidden size: [7] trial: 14, train_loss: 1.981473, test loss: 1.028550, bias2: 0.9832291603088379, variance: 0.045320842415094376\n",
      "Train size: [400] hidden size: [7] trial: 15, train_loss: 1.972357, test loss: 1.029360, bias2: 0.9838925004005432, variance: 0.045467205345630646\n",
      "Train size: [400] hidden size: [7] trial: 16, train_loss: 1.979498, test loss: 1.029160, bias2: 0.9851183295249939, variance: 0.04404119402170181\n",
      "Train size: [400] hidden size: [7] trial: 17, train_loss: 1.973022, test loss: 1.028415, bias2: 0.985515832901001, variance: 0.04289928078651428\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [7] trial: 18, train_loss: 1.972172, test loss: 1.028868, bias2: 0.9859683513641357, variance: 0.042899589985609055\n",
      "Train size: [400] hidden size: [7] trial: 19, train_loss: 1.968317, test loss: 1.031457, bias2: 0.987251341342926, variance: 0.04420595243573189\n",
      "Train size: [400] hidden size: [7] trial: 20, train_loss: 1.967017, test loss: 1.032222, bias2: 0.9856501817703247, variance: 0.04657182842493057\n",
      "Train size: [400] hidden size: [7] trial: 21, train_loss: 1.964687, test loss: 1.032731, bias2: 0.9835095405578613, variance: 0.04922172799706459\n",
      "Train size: [400] hidden size: [7] trial: 22, train_loss: 1.964362, test loss: 1.032705, bias2: 0.9839402437210083, variance: 0.04876480624079704\n",
      "Train size: [400] hidden size: [7] trial: 23, train_loss: 1.967186, test loss: 1.032927, bias2: 0.9830776453018188, variance: 0.04984918236732483\n",
      "Train size: [400] hidden size: [7] trial: 24, train_loss: 1.967226, test loss: 1.033948, bias2: 0.983888566493988, variance: 0.05005925893783569\n",
      "Train size: [400] hidden size: [7] trial: 25, train_loss: 1.967841, test loss: 1.033757, bias2: 0.9847273230552673, variance: 0.049029506742954254\n",
      "Train size: [400] hidden size: [7] trial: 26, train_loss: 1.960093, test loss: 1.033221, bias2: 0.9853504300117493, variance: 0.047870587557554245\n",
      "Train size: [400] hidden size: [7] trial: 27, train_loss: 1.956593, test loss: 1.032005, bias2: 0.9847521781921387, variance: 0.047253113240003586\n",
      "Train size: [400] hidden size: [7] trial: 28, train_loss: 1.956492, test loss: 1.032609, bias2: 0.9851617217063904, variance: 0.047447752207517624\n",
      "Train size: [400] hidden size: [7] trial: 29, train_loss: 1.953510, test loss: 1.032245, bias2: 0.9849148988723755, variance: 0.04732990637421608\n",
      "Train size: [400] hidden size: [7] trial: 30, train_loss: 1.956955, test loss: 1.031710, bias2: 0.9850736856460571, variance: 0.04663684219121933\n",
      "Train size: [400] hidden size: [7] trial: 31, train_loss: 1.960842, test loss: 1.032062, bias2: 0.9858811497688293, variance: 0.04618077352643013\n",
      "Train size: [400] hidden size: [7] trial: 32, train_loss: 1.966189, test loss: 1.033579, bias2: 0.9862624406814575, variance: 0.04731665551662445\n",
      "Train size: [400] hidden size: [7] trial: 33, train_loss: 1.961146, test loss: 1.033938, bias2: 0.9862096309661865, variance: 0.047728195786476135\n",
      "Train size: [400] hidden size: [7] trial: 34, train_loss: 1.962403, test loss: 1.034283, bias2: 0.9864685535430908, variance: 0.04781484976410866\n",
      "Train size: [400] hidden size: [7] trial: 35, train_loss: 1.965449, test loss: 1.034641, bias2: 0.9862911105155945, variance: 0.048349782824516296\n",
      "Train size: [400] hidden size: [7] trial: 36, train_loss: 1.962293, test loss: 1.034155, bias2: 0.9867148995399475, variance: 0.04743964597582817\n",
      "Train size: [400] hidden size: [7] trial: 37, train_loss: 1.963489, test loss: 1.033943, bias2: 0.986412525177002, variance: 0.047530192881822586\n",
      "Train size: [400] hidden size: [7] trial: 38, train_loss: 1.964682, test loss: 1.033731, bias2: 0.9863489866256714, variance: 0.04738149791955948\n",
      "Train size: [400] hidden size: [7] trial: 39, train_loss: 1.966185, test loss: 1.033327, bias2: 0.986096203327179, variance: 0.04723100736737251\n",
      "Train size: [400] hidden size: [7] trial: 40, train_loss: 1.966207, test loss: 1.032751, bias2: 0.9852580428123474, variance: 0.04749279096722603\n",
      "Train size: [400] hidden size: [7] trial: 41, train_loss: 1.965013, test loss: 1.032458, bias2: 0.984855592250824, variance: 0.047602832317352295\n",
      "Train size: [400] hidden size: [7] trial: 42, train_loss: 1.963063, test loss: 1.031930, bias2: 0.9844822883605957, variance: 0.047447316348552704\n",
      "Train size: [400] hidden size: [7] trial: 43, train_loss: 1.961230, test loss: 1.032341, bias2: 0.9848368167877197, variance: 0.04750441014766693\n",
      "Train size: [400] hidden size: [7] trial: 44, train_loss: 1.956960, test loss: 1.032432, bias2: 0.9840990304946899, variance: 0.04833327233791351\n",
      "Train size: [400] hidden size: [7] trial: 45, train_loss: 1.955161, test loss: 1.032384, bias2: 0.9844661355018616, variance: 0.04791804030537605\n",
      "Train size: [400] hidden size: [7] trial: 46, train_loss: 1.955755, test loss: 1.032228, bias2: 0.984699010848999, variance: 0.04752850905060768\n",
      "Train size: [400] hidden size: [7] trial: 47, train_loss: 1.954103, test loss: 1.031963, bias2: 0.9850434064865112, variance: 0.04691968113183975\n",
      "Train size: [400] hidden size: [7] trial: 48, train_loss: 1.953553, test loss: 1.032705, bias2: 0.9855764508247375, variance: 0.04712825268507004\n",
      "Train size: [400] hidden size: [7] trial: 49, train_loss: 1.957886, test loss: 1.032532, bias2: 0.985630989074707, variance: 0.046900972723960876\n",
      "##################################################\n",
      "Train size: [400] hidden size: [8] trial: 0, train_loss: 2.195546, test loss: 1.025274, bias2: 1.0252737998962402, variance: -4.865684938293313e-11\n",
      "Train size: [400] hidden size: [8] trial: 1, train_loss: 2.097568, test loss: 1.026192, bias2: 1.0028027296066284, variance: 0.0233894195407629\n",
      "Train size: [400] hidden size: [8] trial: 2, train_loss: 2.137773, test loss: 1.021327, bias2: 0.9950745701789856, variance: 0.026252828538417816\n",
      "Train size: [400] hidden size: [8] trial: 3, train_loss: 2.184888, test loss: 1.021542, bias2: 0.9976244568824768, variance: 0.02391728013753891\n",
      "Train size: [400] hidden size: [8] trial: 4, train_loss: 2.159438, test loss: 1.027572, bias2: 1.0003100633621216, variance: 0.027262426912784576\n",
      "Train size: [400] hidden size: [8] trial: 5, train_loss: 2.132566, test loss: 1.031884, bias2: 1.0019506216049194, variance: 0.029933102428913116\n",
      "Train size: [400] hidden size: [8] trial: 6, train_loss: 2.109338, test loss: 1.032708, bias2: 1.0002775192260742, variance: 0.032430749386548996\n",
      "Train size: [400] hidden size: [8] trial: 7, train_loss: 2.086969, test loss: 1.032404, bias2: 0.9942716956138611, variance: 0.03813226521015167\n",
      "Train size: [400] hidden size: [8] trial: 8, train_loss: 2.079635, test loss: 1.030378, bias2: 0.991528332233429, variance: 0.03884943574666977\n",
      "Train size: [400] hidden size: [8] trial: 9, train_loss: 2.070820, test loss: 1.032803, bias2: 0.9893761873245239, variance: 0.0434265062212944\n",
      "Train size: [400] hidden size: [8] trial: 10, train_loss: 2.067505, test loss: 1.030961, bias2: 0.989433228969574, variance: 0.041527558118104935\n",
      "Train size: [400] hidden size: [8] trial: 11, train_loss: 2.058375, test loss: 1.030486, bias2: 0.9876869320869446, variance: 0.04279904440045357\n",
      "Train size: [400] hidden size: [8] trial: 12, train_loss: 2.061114, test loss: 1.031734, bias2: 0.9882687926292419, variance: 0.04346557334065437\n",
      "Train size: [400] hidden size: [8] trial: 13, train_loss: 2.035356, test loss: 1.032872, bias2: 0.9899259805679321, variance: 0.04294619709253311\n",
      "Train size: [400] hidden size: [8] trial: 14, train_loss: 2.022214, test loss: 1.032726, bias2: 0.9902172684669495, variance: 0.04250854253768921\n",
      "Train size: [400] hidden size: [8] trial: 15, train_loss: 2.025112, test loss: 1.032852, bias2: 0.9906880259513855, variance: 0.042163655161857605\n",
      "Train size: [400] hidden size: [8] trial: 16, train_loss: 2.017323, test loss: 1.034043, bias2: 0.988583505153656, variance: 0.04545978084206581\n",
      "Train size: [400] hidden size: [8] trial: 17, train_loss: 2.009672, test loss: 1.033838, bias2: 0.9874436259269714, variance: 0.04639415070414543\n",
      "Train size: [400] hidden size: [8] trial: 18, train_loss: 2.017910, test loss: 1.034137, bias2: 0.9868505001068115, variance: 0.0472869873046875\n",
      "Train size: [400] hidden size: [8] trial: 19, train_loss: 2.022067, test loss: 1.035884, bias2: 0.9868226051330566, variance: 0.049061425030231476\n",
      "Train size: [400] hidden size: [8] trial: 20, train_loss: 2.014572, test loss: 1.034476, bias2: 0.9871441721916199, variance: 0.04733162000775337\n",
      "Train size: [400] hidden size: [8] trial: 21, train_loss: 2.019405, test loss: 1.034306, bias2: 0.9852337837219238, variance: 0.04907238483428955\n",
      "Train size: [400] hidden size: [8] trial: 22, train_loss: 2.020696, test loss: 1.033816, bias2: 0.9858123064041138, variance: 0.04800416901707649\n",
      "Train size: [400] hidden size: [8] trial: 23, train_loss: 2.016186, test loss: 1.034431, bias2: 0.9857288599014282, variance: 0.04870209842920303\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [8] trial: 24, train_loss: 2.013677, test loss: 1.036005, bias2: 0.9855073094367981, variance: 0.050498079508543015\n",
      "Train size: [400] hidden size: [8] trial: 25, train_loss: 2.006526, test loss: 1.035540, bias2: 0.9853724837303162, variance: 0.0501672625541687\n",
      "Train size: [400] hidden size: [8] trial: 26, train_loss: 1.999472, test loss: 1.034872, bias2: 0.986007571220398, variance: 0.04886398836970329\n",
      "Train size: [400] hidden size: [8] trial: 27, train_loss: 1.993694, test loss: 1.035408, bias2: 0.9863241910934448, variance: 0.04908420890569687\n",
      "Train size: [400] hidden size: [8] trial: 28, train_loss: 1.982124, test loss: 1.036426, bias2: 0.9868281483650208, variance: 0.049597810953855515\n",
      "Train size: [400] hidden size: [8] trial: 29, train_loss: 1.980796, test loss: 1.035088, bias2: 0.9861201643943787, variance: 0.04896814376115799\n",
      "Train size: [400] hidden size: [8] trial: 30, train_loss: 1.986524, test loss: 1.036186, bias2: 0.9861196279525757, variance: 0.05006611347198486\n",
      "Train size: [400] hidden size: [8] trial: 31, train_loss: 1.985021, test loss: 1.036023, bias2: 0.9867761135101318, variance: 0.04924652352929115\n",
      "Train size: [400] hidden size: [8] trial: 32, train_loss: 1.987937, test loss: 1.035452, bias2: 0.9857854247093201, variance: 0.04966649040579796\n",
      "Train size: [400] hidden size: [8] trial: 33, train_loss: 1.996243, test loss: 1.036154, bias2: 0.9860765337944031, variance: 0.05007759854197502\n",
      "Train size: [400] hidden size: [8] trial: 34, train_loss: 1.992282, test loss: 1.036351, bias2: 0.9870325326919556, variance: 0.04931844770908356\n",
      "Train size: [400] hidden size: [8] trial: 35, train_loss: 1.987534, test loss: 1.035576, bias2: 0.9862409234046936, variance: 0.049335312098264694\n",
      "Train size: [400] hidden size: [8] trial: 36, train_loss: 1.983580, test loss: 1.036314, bias2: 0.9859139919281006, variance: 0.050400510430336\n",
      "Train size: [400] hidden size: [8] trial: 37, train_loss: 1.978284, test loss: 1.036059, bias2: 0.9863398671150208, variance: 0.049719054251909256\n",
      "Train size: [400] hidden size: [8] trial: 38, train_loss: 1.978187, test loss: 1.036463, bias2: 0.9853754639625549, variance: 0.05108789727091789\n",
      "Train size: [400] hidden size: [8] trial: 39, train_loss: 1.979067, test loss: 1.035583, bias2: 0.9851793050765991, variance: 0.05040385201573372\n",
      "Train size: [400] hidden size: [8] trial: 40, train_loss: 1.975002, test loss: 1.035467, bias2: 0.9855025410652161, variance: 0.04996402934193611\n",
      "Train size: [400] hidden size: [8] trial: 41, train_loss: 1.969360, test loss: 1.035374, bias2: 0.9848974347114563, variance: 0.05047646909952164\n",
      "Train size: [400] hidden size: [8] trial: 42, train_loss: 1.973365, test loss: 1.035832, bias2: 0.9858294129371643, variance: 0.05000260844826698\n",
      "Train size: [400] hidden size: [8] trial: 43, train_loss: 1.975079, test loss: 1.035643, bias2: 0.9854617714881897, variance: 0.05018119141459465\n",
      "Train size: [400] hidden size: [8] trial: 44, train_loss: 1.968409, test loss: 1.036797, bias2: 0.985840380191803, variance: 0.05095618963241577\n",
      "Train size: [400] hidden size: [8] trial: 45, train_loss: 1.966204, test loss: 1.036624, bias2: 0.9860303997993469, variance: 0.050593648105859756\n",
      "Train size: [400] hidden size: [8] trial: 46, train_loss: 1.968585, test loss: 1.036670, bias2: 0.9852159023284912, variance: 0.051453977823257446\n",
      "Train size: [400] hidden size: [8] trial: 47, train_loss: 1.961927, test loss: 1.036049, bias2: 0.9849460124969482, variance: 0.051103375852108\n",
      "Train size: [400] hidden size: [8] trial: 48, train_loss: 1.961605, test loss: 1.035467, bias2: 0.9851115942001343, variance: 0.050354935228824615\n",
      "Train size: [400] hidden size: [8] trial: 49, train_loss: 1.958413, test loss: 1.035713, bias2: 0.9853858351707458, variance: 0.050326742231845856\n",
      "##################################################\n",
      "Train size: [400] hidden size: [9] trial: 0, train_loss: 1.876107, test loss: 1.008508, bias2: 1.0085080862045288, variance: 3.6492638771923325e-11\n",
      "Train size: [400] hidden size: [9] trial: 1, train_loss: 1.882371, test loss: 1.024806, bias2: 0.9939167499542236, variance: 0.03088953159749508\n",
      "Train size: [400] hidden size: [9] trial: 2, train_loss: 1.944305, test loss: 1.031718, bias2: 0.9950934648513794, variance: 0.03662445768713951\n",
      "Train size: [400] hidden size: [9] trial: 3, train_loss: 1.963082, test loss: 1.036018, bias2: 0.9980615973472595, variance: 0.03795652836561203\n",
      "Train size: [400] hidden size: [9] trial: 4, train_loss: 1.944551, test loss: 1.048470, bias2: 0.9950942993164062, variance: 0.05337533727288246\n",
      "Train size: [400] hidden size: [9] trial: 5, train_loss: 1.953722, test loss: 1.041904, bias2: 0.9893476366996765, variance: 0.05255671963095665\n",
      "Train size: [400] hidden size: [9] trial: 6, train_loss: 1.939074, test loss: 1.042009, bias2: 0.9866273403167725, variance: 0.05538162961602211\n",
      "Train size: [400] hidden size: [9] trial: 7, train_loss: 1.922976, test loss: 1.037105, bias2: 0.9777921438217163, variance: 0.05931258201599121\n",
      "Train size: [400] hidden size: [9] trial: 8, train_loss: 1.908209, test loss: 1.039353, bias2: 0.9786072969436646, variance: 0.06074550002813339\n",
      "Train size: [400] hidden size: [9] trial: 9, train_loss: 1.899310, test loss: 1.042278, bias2: 0.9767845869064331, variance: 0.0654933750629425\n",
      "Train size: [400] hidden size: [9] trial: 10, train_loss: 1.922704, test loss: 1.041152, bias2: 0.9741256237030029, variance: 0.067026287317276\n",
      "Train size: [400] hidden size: [9] trial: 11, train_loss: 1.916936, test loss: 1.038784, bias2: 0.9746932983398438, variance: 0.06409096717834473\n",
      "Train size: [400] hidden size: [9] trial: 12, train_loss: 1.897317, test loss: 1.037331, bias2: 0.9743937849998474, variance: 0.06293684244155884\n",
      "Train size: [400] hidden size: [9] trial: 13, train_loss: 1.915062, test loss: 1.036379, bias2: 0.9766608476638794, variance: 0.059718579053878784\n",
      "Train size: [400] hidden size: [9] trial: 14, train_loss: 1.916859, test loss: 1.039131, bias2: 0.976524829864502, variance: 0.06260588765144348\n",
      "Train size: [400] hidden size: [9] trial: 15, train_loss: 1.922172, test loss: 1.040474, bias2: 0.9756999015808105, variance: 0.0647740513086319\n",
      "Train size: [400] hidden size: [9] trial: 16, train_loss: 1.915887, test loss: 1.039039, bias2: 0.9754849076271057, variance: 0.06355377286672592\n",
      "Train size: [400] hidden size: [9] trial: 17, train_loss: 1.928169, test loss: 1.039941, bias2: 0.976719081401825, variance: 0.0632215067744255\n",
      "Train size: [400] hidden size: [9] trial: 18, train_loss: 1.925729, test loss: 1.038392, bias2: 0.9772942066192627, variance: 0.06109822541475296\n",
      "Train size: [400] hidden size: [9] trial: 19, train_loss: 1.916037, test loss: 1.039326, bias2: 0.9756075143814087, variance: 0.06371840834617615\n",
      "Train size: [400] hidden size: [9] trial: 20, train_loss: 1.913606, test loss: 1.038138, bias2: 0.9756733775138855, variance: 0.062464166432619095\n",
      "Train size: [400] hidden size: [9] trial: 21, train_loss: 1.909268, test loss: 1.037357, bias2: 0.9768203496932983, variance: 0.06053686514496803\n",
      "Train size: [400] hidden size: [9] trial: 22, train_loss: 1.895266, test loss: 1.036462, bias2: 0.9753156900405884, variance: 0.061146050691604614\n",
      "Train size: [400] hidden size: [9] trial: 23, train_loss: 1.896724, test loss: 1.038089, bias2: 0.9745196104049683, variance: 0.0635693222284317\n",
      "Train size: [400] hidden size: [9] trial: 24, train_loss: 1.897049, test loss: 1.037587, bias2: 0.9751158952713013, variance: 0.06247112900018692\n",
      "Train size: [400] hidden size: [9] trial: 25, train_loss: 1.892369, test loss: 1.037295, bias2: 0.9758424758911133, variance: 0.061452172696590424\n",
      "Train size: [400] hidden size: [9] trial: 26, train_loss: 1.894871, test loss: 1.037018, bias2: 0.9760165810585022, variance: 0.06100136414170265\n",
      "Train size: [400] hidden size: [9] trial: 27, train_loss: 1.905128, test loss: 1.035900, bias2: 0.9753848910331726, variance: 0.06051525101065636\n",
      "Train size: [400] hidden size: [9] trial: 28, train_loss: 1.905280, test loss: 1.035707, bias2: 0.9762265086174011, variance: 0.05948047712445259\n",
      "Train size: [400] hidden size: [9] trial: 29, train_loss: 1.908500, test loss: 1.034581, bias2: 0.975910484790802, variance: 0.05867091938853264\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [9] trial: 30, train_loss: 1.907459, test loss: 1.034934, bias2: 0.9762591123580933, variance: 0.05867454409599304\n",
      "Train size: [400] hidden size: [9] trial: 31, train_loss: 1.904419, test loss: 1.035461, bias2: 0.9767045974731445, variance: 0.058756232261657715\n",
      "Train size: [400] hidden size: [9] trial: 32, train_loss: 1.903607, test loss: 1.035378, bias2: 0.9766167402267456, variance: 0.0587616041302681\n",
      "Train size: [400] hidden size: [9] trial: 33, train_loss: 1.906299, test loss: 1.034642, bias2: 0.9767010807991028, variance: 0.057940881699323654\n",
      "Train size: [400] hidden size: [9] trial: 34, train_loss: 1.901792, test loss: 1.034016, bias2: 0.9764869213104248, variance: 0.057529594749212265\n",
      "Train size: [400] hidden size: [9] trial: 35, train_loss: 1.896781, test loss: 1.034591, bias2: 0.9775692224502563, variance: 0.057022083550691605\n",
      "Train size: [400] hidden size: [9] trial: 36, train_loss: 1.902500, test loss: 1.034895, bias2: 0.978361964225769, variance: 0.056533463299274445\n",
      "Train size: [400] hidden size: [9] trial: 37, train_loss: 1.896940, test loss: 1.034906, bias2: 0.9791114926338196, variance: 0.05579442158341408\n",
      "Train size: [400] hidden size: [9] trial: 38, train_loss: 1.897817, test loss: 1.035092, bias2: 0.9797078967094421, variance: 0.055384449660778046\n",
      "Train size: [400] hidden size: [9] trial: 39, train_loss: 1.898513, test loss: 1.035029, bias2: 0.9793737530708313, variance: 0.05565483495593071\n",
      "Train size: [400] hidden size: [9] trial: 40, train_loss: 1.902420, test loss: 1.034810, bias2: 0.9788662791252136, variance: 0.05594364181160927\n",
      "Train size: [400] hidden size: [9] trial: 41, train_loss: 1.901371, test loss: 1.034672, bias2: 0.9789380431175232, variance: 0.055733878165483475\n",
      "Train size: [400] hidden size: [9] trial: 42, train_loss: 1.901296, test loss: 1.034058, bias2: 0.9787851572036743, variance: 0.05527328699827194\n",
      "Train size: [400] hidden size: [9] trial: 43, train_loss: 1.903220, test loss: 1.033822, bias2: 0.978338360786438, variance: 0.055484041571617126\n",
      "Train size: [400] hidden size: [9] trial: 44, train_loss: 1.897984, test loss: 1.033783, bias2: 0.9783247709274292, variance: 0.05545830726623535\n",
      "Train size: [400] hidden size: [9] trial: 45, train_loss: 1.895505, test loss: 1.033997, bias2: 0.97821044921875, variance: 0.05578684061765671\n",
      "Train size: [400] hidden size: [9] trial: 46, train_loss: 1.897920, test loss: 1.034787, bias2: 0.9780682921409607, variance: 0.056718554347753525\n",
      "Train size: [400] hidden size: [9] trial: 47, train_loss: 1.898256, test loss: 1.035422, bias2: 0.9787936210632324, variance: 0.056627847254276276\n",
      "Train size: [400] hidden size: [9] trial: 48, train_loss: 1.899034, test loss: 1.035581, bias2: 0.9793266654014587, variance: 0.05625458061695099\n",
      "Train size: [400] hidden size: [9] trial: 49, train_loss: 1.903516, test loss: 1.035757, bias2: 0.9792893528938293, variance: 0.056467581540346146\n",
      "##################################################\n",
      "Train size: [400] hidden size: [11] trial: 0, train_loss: 1.988792, test loss: 1.039954, bias2: 1.039954423904419, variance: 7.298527893162543e-10\n",
      "Train size: [400] hidden size: [11] trial: 1, train_loss: 1.921424, test loss: 1.035763, bias2: 1.008607268333435, variance: 0.027156062424182892\n",
      "Train size: [400] hidden size: [11] trial: 2, train_loss: 1.897258, test loss: 1.051874, bias2: 1.0020407438278198, variance: 0.0498335026204586\n",
      "Train size: [400] hidden size: [11] trial: 3, train_loss: 1.858879, test loss: 1.051371, bias2: 0.9924218654632568, variance: 0.05894937738776207\n",
      "Train size: [400] hidden size: [11] trial: 4, train_loss: 1.841943, test loss: 1.048862, bias2: 0.9872574806213379, variance: 0.06160417199134827\n",
      "Train size: [400] hidden size: [11] trial: 5, train_loss: 1.863136, test loss: 1.044747, bias2: 0.9862020015716553, variance: 0.05854538083076477\n",
      "Train size: [400] hidden size: [11] trial: 6, train_loss: 1.870901, test loss: 1.045392, bias2: 0.9876664876937866, variance: 0.0577259361743927\n",
      "Train size: [400] hidden size: [11] trial: 7, train_loss: 1.859433, test loss: 1.043555, bias2: 0.9859641790390015, variance: 0.05759108066558838\n",
      "Train size: [400] hidden size: [11] trial: 8, train_loss: 1.862805, test loss: 1.043473, bias2: 0.9851661324501038, variance: 0.0583067312836647\n",
      "Train size: [400] hidden size: [11] trial: 9, train_loss: 1.887830, test loss: 1.044995, bias2: 0.9836670756340027, variance: 0.06132823973894119\n",
      "Train size: [400] hidden size: [11] trial: 10, train_loss: 1.875879, test loss: 1.042698, bias2: 0.9843807816505432, variance: 0.05831702798604965\n",
      "Train size: [400] hidden size: [11] trial: 11, train_loss: 1.884023, test loss: 1.043475, bias2: 0.98292076587677, variance: 0.06055401638150215\n",
      "Train size: [400] hidden size: [11] trial: 12, train_loss: 1.880903, test loss: 1.042941, bias2: 0.9794556498527527, variance: 0.06348498165607452\n",
      "Train size: [400] hidden size: [11] trial: 13, train_loss: 1.870771, test loss: 1.042060, bias2: 0.9787817001342773, variance: 0.063277967274189\n",
      "Train size: [400] hidden size: [11] trial: 14, train_loss: 1.862792, test loss: 1.041618, bias2: 0.9800510406494141, variance: 0.06156683340668678\n",
      "Train size: [400] hidden size: [11] trial: 15, train_loss: 1.856051, test loss: 1.042110, bias2: 0.9782710671424866, variance: 0.0638393685221672\n",
      "Train size: [400] hidden size: [11] trial: 16, train_loss: 1.857973, test loss: 1.043250, bias2: 0.9777984619140625, variance: 0.06545162200927734\n",
      "Train size: [400] hidden size: [11] trial: 17, train_loss: 1.853010, test loss: 1.043444, bias2: 0.9770724773406982, variance: 0.06637132912874222\n",
      "Train size: [400] hidden size: [11] trial: 18, train_loss: 1.860297, test loss: 1.044196, bias2: 0.9764481782913208, variance: 0.06774821132421494\n",
      "Train size: [400] hidden size: [11] trial: 19, train_loss: 1.858717, test loss: 1.044497, bias2: 0.9772363901138306, variance: 0.06726016849279404\n",
      "Train size: [400] hidden size: [11] trial: 20, train_loss: 1.869130, test loss: 1.043840, bias2: 0.9763959646224976, variance: 0.06744422763586044\n",
      "Train size: [400] hidden size: [11] trial: 21, train_loss: 1.864043, test loss: 1.041578, bias2: 0.9739634990692139, variance: 0.06761482357978821\n",
      "Train size: [400] hidden size: [11] trial: 22, train_loss: 1.872243, test loss: 1.040532, bias2: 0.9737837314605713, variance: 0.06674787402153015\n",
      "Train size: [400] hidden size: [11] trial: 23, train_loss: 1.866817, test loss: 1.040648, bias2: 0.9746400713920593, variance: 0.06600829213857651\n",
      "Train size: [400] hidden size: [11] trial: 24, train_loss: 1.872447, test loss: 1.041031, bias2: 0.9735647439956665, variance: 0.0674661248922348\n",
      "Train size: [400] hidden size: [11] trial: 25, train_loss: 1.878585, test loss: 1.041307, bias2: 0.9732029438018799, variance: 0.06810427457094193\n",
      "Train size: [400] hidden size: [11] trial: 26, train_loss: 1.882000, test loss: 1.040919, bias2: 0.9730663299560547, variance: 0.06785287708044052\n",
      "Train size: [400] hidden size: [11] trial: 27, train_loss: 1.889589, test loss: 1.040786, bias2: 0.9736506342887878, variance: 0.06713540852069855\n",
      "Train size: [400] hidden size: [11] trial: 28, train_loss: 1.891285, test loss: 1.040040, bias2: 0.9730704426765442, variance: 0.06696967035531998\n",
      "Train size: [400] hidden size: [11] trial: 29, train_loss: 1.887946, test loss: 1.040781, bias2: 0.9718471169471741, variance: 0.0689341202378273\n",
      "Train size: [400] hidden size: [11] trial: 30, train_loss: 1.892823, test loss: 1.040039, bias2: 0.9713128209114075, variance: 0.06872658431529999\n",
      "Train size: [400] hidden size: [11] trial: 31, train_loss: 1.890904, test loss: 1.039598, bias2: 0.9717667102813721, variance: 0.06783101707696915\n",
      "Train size: [400] hidden size: [11] trial: 32, train_loss: 1.891313, test loss: 1.040532, bias2: 0.9722854495048523, variance: 0.06824629753828049\n",
      "Train size: [400] hidden size: [11] trial: 33, train_loss: 1.889561, test loss: 1.041134, bias2: 0.9724746942520142, variance: 0.06865908950567245\n",
      "Train size: [400] hidden size: [11] trial: 34, train_loss: 1.888500, test loss: 1.041396, bias2: 0.9728818535804749, variance: 0.06851378828287125\n",
      "Train size: [400] hidden size: [11] trial: 35, train_loss: 1.887152, test loss: 1.040665, bias2: 0.9713301062583923, variance: 0.06933505088090897\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [11] trial: 36, train_loss: 1.884030, test loss: 1.040579, bias2: 0.9708268642425537, variance: 0.06975211948156357\n",
      "Train size: [400] hidden size: [11] trial: 37, train_loss: 1.889652, test loss: 1.040419, bias2: 0.9711500406265259, variance: 0.06926873326301575\n",
      "Train size: [400] hidden size: [11] trial: 38, train_loss: 1.888124, test loss: 1.041069, bias2: 0.9703706502914429, variance: 0.07069805264472961\n",
      "Train size: [400] hidden size: [11] trial: 39, train_loss: 1.890907, test loss: 1.040278, bias2: 0.9695018529891968, variance: 0.07077620923519135\n",
      "Train size: [400] hidden size: [11] trial: 40, train_loss: 1.891036, test loss: 1.041885, bias2: 0.9698728919029236, variance: 0.07201223820447922\n",
      "Train size: [400] hidden size: [11] trial: 41, train_loss: 1.894873, test loss: 1.042502, bias2: 0.9697483777999878, variance: 0.07275381684303284\n",
      "Train size: [400] hidden size: [11] trial: 42, train_loss: 1.894110, test loss: 1.042713, bias2: 0.9690598249435425, variance: 0.07365356385707855\n",
      "Train size: [400] hidden size: [11] trial: 43, train_loss: 1.895801, test loss: 1.043291, bias2: 0.969828724861145, variance: 0.07346213608980179\n",
      "Train size: [400] hidden size: [11] trial: 44, train_loss: 1.896097, test loss: 1.043767, bias2: 0.9695398807525635, variance: 0.07422759383916855\n",
      "Train size: [400] hidden size: [11] trial: 45, train_loss: 1.897005, test loss: 1.045166, bias2: 0.970302164554596, variance: 0.07486408203840256\n",
      "Train size: [400] hidden size: [11] trial: 46, train_loss: 1.900974, test loss: 1.044590, bias2: 0.9699975252151489, variance: 0.07459244132041931\n",
      "Train size: [400] hidden size: [11] trial: 47, train_loss: 1.908998, test loss: 1.044994, bias2: 0.9703705310821533, variance: 0.07462380826473236\n",
      "Train size: [400] hidden size: [11] trial: 48, train_loss: 1.907192, test loss: 1.044618, bias2: 0.970780074596405, variance: 0.07383816689252853\n",
      "Train size: [400] hidden size: [11] trial: 49, train_loss: 1.904254, test loss: 1.044498, bias2: 0.9711989164352417, variance: 0.07329884171485901\n",
      "##################################################\n",
      "Train size: [400] hidden size: [12] trial: 0, train_loss: 1.772915, test loss: 1.029737, bias2: 1.029736876487732, variance: 1.2164212345733283e-11\n",
      "Train size: [400] hidden size: [12] trial: 1, train_loss: 1.891533, test loss: 1.029846, bias2: 1.0137817859649658, variance: 0.016064506024122238\n",
      "Train size: [400] hidden size: [12] trial: 2, train_loss: 1.957093, test loss: 1.031381, bias2: 0.9947080016136169, variance: 0.03667265549302101\n",
      "Train size: [400] hidden size: [12] trial: 3, train_loss: 1.999708, test loss: 1.028779, bias2: 0.9842300415039062, variance: 0.04454900696873665\n",
      "Train size: [400] hidden size: [12] trial: 4, train_loss: 1.986625, test loss: 1.029630, bias2: 0.97916579246521, variance: 0.05046460032463074\n",
      "Train size: [400] hidden size: [12] trial: 5, train_loss: 1.963073, test loss: 1.026480, bias2: 0.9704238176345825, variance: 0.05605664104223251\n",
      "Train size: [400] hidden size: [12] trial: 6, train_loss: 1.928612, test loss: 1.028747, bias2: 0.9691945314407349, variance: 0.05955267697572708\n",
      "Train size: [400] hidden size: [12] trial: 7, train_loss: 1.928140, test loss: 1.031442, bias2: 0.9708760380744934, variance: 0.06056636944413185\n",
      "Train size: [400] hidden size: [12] trial: 8, train_loss: 1.917695, test loss: 1.032882, bias2: 0.9665514230728149, variance: 0.06633066385984421\n",
      "Train size: [400] hidden size: [12] trial: 9, train_loss: 1.903385, test loss: 1.040788, bias2: 0.9699685573577881, variance: 0.07081988453865051\n",
      "Train size: [400] hidden size: [12] trial: 10, train_loss: 1.917903, test loss: 1.042365, bias2: 0.9691474437713623, variance: 0.07321715354919434\n",
      "Train size: [400] hidden size: [12] trial: 11, train_loss: 1.927904, test loss: 1.043294, bias2: 0.9678472280502319, variance: 0.0754462331533432\n",
      "Train size: [400] hidden size: [12] trial: 12, train_loss: 1.925547, test loss: 1.046625, bias2: 0.9699928760528564, variance: 0.07663165032863617\n",
      "Train size: [400] hidden size: [12] trial: 13, train_loss: 1.919031, test loss: 1.045706, bias2: 0.9687994718551636, variance: 0.07690633088350296\n",
      "Train size: [400] hidden size: [12] trial: 14, train_loss: 1.927273, test loss: 1.042975, bias2: 0.9650304317474365, variance: 0.07794426381587982\n",
      "Train size: [400] hidden size: [12] trial: 15, train_loss: 1.919954, test loss: 1.042144, bias2: 0.9643723368644714, variance: 0.07777147740125656\n",
      "Train size: [400] hidden size: [12] trial: 16, train_loss: 1.918002, test loss: 1.043746, bias2: 0.9628427028656006, variance: 0.0809037908911705\n",
      "Train size: [400] hidden size: [12] trial: 17, train_loss: 1.916274, test loss: 1.044796, bias2: 0.9600669145584106, variance: 0.08472856879234314\n",
      "Train size: [400] hidden size: [12] trial: 18, train_loss: 1.929891, test loss: 1.044172, bias2: 0.9604207873344421, variance: 0.08375101536512375\n",
      "Train size: [400] hidden size: [12] trial: 19, train_loss: 1.934776, test loss: 1.045252, bias2: 0.9622190594673157, variance: 0.08303292095661163\n",
      "Train size: [400] hidden size: [12] trial: 20, train_loss: 1.935489, test loss: 1.048371, bias2: 0.9622509479522705, variance: 0.0861203670501709\n",
      "Train size: [400] hidden size: [12] trial: 21, train_loss: 1.933233, test loss: 1.048048, bias2: 0.963483452796936, variance: 0.08456423878669739\n",
      "Train size: [400] hidden size: [12] trial: 22, train_loss: 1.936595, test loss: 1.046718, bias2: 0.9629038572311401, variance: 0.08381462097167969\n",
      "Train size: [400] hidden size: [12] trial: 23, train_loss: 1.933066, test loss: 1.045527, bias2: 0.9604544043540955, variance: 0.08507224172353745\n",
      "Train size: [400] hidden size: [12] trial: 24, train_loss: 1.932037, test loss: 1.044411, bias2: 0.9607800841331482, variance: 0.08363122493028641\n",
      "Train size: [400] hidden size: [12] trial: 25, train_loss: 1.934113, test loss: 1.044217, bias2: 0.9614599943161011, variance: 0.0827566608786583\n",
      "Train size: [400] hidden size: [12] trial: 26, train_loss: 1.941035, test loss: 1.044723, bias2: 0.9615667462348938, variance: 0.08315582573413849\n",
      "Train size: [400] hidden size: [12] trial: 27, train_loss: 1.939865, test loss: 1.044439, bias2: 0.9602779150009155, variance: 0.08416150510311127\n",
      "Train size: [400] hidden size: [12] trial: 28, train_loss: 1.941630, test loss: 1.044909, bias2: 0.9599767923355103, variance: 0.08493245393037796\n",
      "Train size: [400] hidden size: [12] trial: 29, train_loss: 1.939395, test loss: 1.044560, bias2: 0.9606595039367676, variance: 0.08390071243047714\n",
      "Train size: [400] hidden size: [12] trial: 30, train_loss: 1.940850, test loss: 1.043600, bias2: 0.9605273604393005, variance: 0.08307305723428726\n",
      "Train size: [400] hidden size: [12] trial: 31, train_loss: 1.935885, test loss: 1.042917, bias2: 0.9607149958610535, variance: 0.08220163732767105\n",
      "Train size: [400] hidden size: [12] trial: 32, train_loss: 1.933282, test loss: 1.043837, bias2: 0.9613462090492249, variance: 0.08249123394489288\n",
      "Train size: [400] hidden size: [12] trial: 33, train_loss: 1.934773, test loss: 1.043699, bias2: 0.961098849773407, variance: 0.08260053396224976\n",
      "Train size: [400] hidden size: [12] trial: 34, train_loss: 1.937792, test loss: 1.042671, bias2: 0.9612085819244385, variance: 0.08146238327026367\n",
      "Train size: [400] hidden size: [12] trial: 35, train_loss: 1.939234, test loss: 1.043111, bias2: 0.9617739915847778, variance: 0.08133676648139954\n",
      "Train size: [400] hidden size: [12] trial: 36, train_loss: 1.942070, test loss: 1.043539, bias2: 0.9615130424499512, variance: 0.08202579617500305\n",
      "Train size: [400] hidden size: [12] trial: 37, train_loss: 1.942366, test loss: 1.043294, bias2: 0.961823046207428, variance: 0.0814712643623352\n",
      "Train size: [400] hidden size: [12] trial: 38, train_loss: 1.949405, test loss: 1.043630, bias2: 0.961594820022583, variance: 0.08203539997339249\n",
      "Train size: [400] hidden size: [12] trial: 39, train_loss: 1.953113, test loss: 1.043591, bias2: 0.9617002010345459, variance: 0.08189106732606888\n",
      "Train size: [400] hidden size: [12] trial: 40, train_loss: 1.950854, test loss: 1.044640, bias2: 0.9622387886047363, variance: 0.08240129053592682\n",
      "Train size: [400] hidden size: [12] trial: 41, train_loss: 1.951899, test loss: 1.046220, bias2: 0.9631713628768921, variance: 0.08304844796657562\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [12] trial: 42, train_loss: 1.953644, test loss: 1.046146, bias2: 0.9635574817657471, variance: 0.08258821070194244\n",
      "Train size: [400] hidden size: [12] trial: 43, train_loss: 1.948878, test loss: 1.046640, bias2: 0.9642429351806641, variance: 0.0823967456817627\n",
      "Train size: [400] hidden size: [12] trial: 44, train_loss: 1.945842, test loss: 1.046535, bias2: 0.9641438722610474, variance: 0.08239088207483292\n",
      "Train size: [400] hidden size: [12] trial: 45, train_loss: 1.947446, test loss: 1.046730, bias2: 0.9635717868804932, variance: 0.08315850794315338\n",
      "Train size: [400] hidden size: [12] trial: 46, train_loss: 1.943746, test loss: 1.047254, bias2: 0.9638417363166809, variance: 0.08341176807880402\n",
      "Train size: [400] hidden size: [12] trial: 47, train_loss: 1.940731, test loss: 1.046846, bias2: 0.9638140201568604, variance: 0.08303210139274597\n",
      "Train size: [400] hidden size: [12] trial: 48, train_loss: 1.943697, test loss: 1.047132, bias2: 0.9633458852767944, variance: 0.08378647267818451\n",
      "Train size: [400] hidden size: [12] trial: 49, train_loss: 1.943748, test loss: 1.045874, bias2: 0.9625897407531738, variance: 0.08328428119421005\n",
      "##################################################\n",
      "Train size: [400] hidden size: [14] trial: 0, train_loss: 1.868757, test loss: 1.026361, bias2: 1.0263612270355225, variance: 3.8925479506346505e-10\n",
      "Train size: [400] hidden size: [14] trial: 1, train_loss: 2.074568, test loss: 1.047483, bias2: 1.0034769773483276, variance: 0.0440063402056694\n",
      "Train size: [400] hidden size: [14] trial: 2, train_loss: 2.044914, test loss: 1.057568, bias2: 0.9901542663574219, variance: 0.0674140527844429\n",
      "Train size: [400] hidden size: [14] trial: 3, train_loss: 2.068129, test loss: 1.062991, bias2: 0.9861000776290894, variance: 0.07689045369625092\n",
      "Train size: [400] hidden size: [14] trial: 4, train_loss: 2.047918, test loss: 1.057820, bias2: 0.9830302000045776, variance: 0.07478951662778854\n",
      "Train size: [400] hidden size: [14] trial: 5, train_loss: 2.031876, test loss: 1.052731, bias2: 0.9794578552246094, variance: 0.0732731819152832\n",
      "Train size: [400] hidden size: [14] trial: 6, train_loss: 2.009573, test loss: 1.061354, bias2: 0.984214186668396, variance: 0.07713936269283295\n",
      "Train size: [400] hidden size: [14] trial: 7, train_loss: 1.999933, test loss: 1.060573, bias2: 0.9831922054290771, variance: 0.07738053053617477\n",
      "Train size: [400] hidden size: [14] trial: 8, train_loss: 1.985570, test loss: 1.054274, bias2: 0.9797921776771545, variance: 0.074482262134552\n",
      "Train size: [400] hidden size: [14] trial: 9, train_loss: 1.988041, test loss: 1.054250, bias2: 0.9764735102653503, variance: 0.07777637243270874\n",
      "Train size: [400] hidden size: [14] trial: 10, train_loss: 1.968040, test loss: 1.055538, bias2: 0.9706942439079285, variance: 0.08484414964914322\n",
      "Train size: [400] hidden size: [14] trial: 11, train_loss: 1.965594, test loss: 1.054964, bias2: 0.9710499048233032, variance: 0.0839138999581337\n",
      "Train size: [400] hidden size: [14] trial: 12, train_loss: 1.958618, test loss: 1.053014, bias2: 0.9698222279548645, variance: 0.08319190889596939\n",
      "Train size: [400] hidden size: [14] trial: 13, train_loss: 1.940248, test loss: 1.052982, bias2: 0.9675930738449097, variance: 0.08538869023323059\n",
      "Train size: [400] hidden size: [14] trial: 14, train_loss: 1.947762, test loss: 1.052386, bias2: 0.9672489166259766, variance: 0.08513710647821426\n",
      "Train size: [400] hidden size: [14] trial: 15, train_loss: 1.931011, test loss: 1.051079, bias2: 0.9669988751411438, variance: 0.08407970517873764\n",
      "Train size: [400] hidden size: [14] trial: 16, train_loss: 1.944312, test loss: 1.050113, bias2: 0.9681340456008911, variance: 0.08197867125272751\n",
      "Train size: [400] hidden size: [14] trial: 17, train_loss: 1.959023, test loss: 1.050757, bias2: 0.9664584398269653, variance: 0.08429883420467377\n",
      "Train size: [400] hidden size: [14] trial: 18, train_loss: 1.955745, test loss: 1.050817, bias2: 0.965540885925293, variance: 0.08527614176273346\n",
      "Train size: [400] hidden size: [14] trial: 19, train_loss: 1.945787, test loss: 1.049591, bias2: 0.966560959815979, variance: 0.08302973210811615\n",
      "Train size: [400] hidden size: [14] trial: 20, train_loss: 1.943150, test loss: 1.048027, bias2: 0.9649075269699097, variance: 0.08311974257230759\n",
      "Train size: [400] hidden size: [14] trial: 21, train_loss: 1.933309, test loss: 1.047667, bias2: 0.9630692601203918, variance: 0.08459825813770294\n",
      "Train size: [400] hidden size: [14] trial: 22, train_loss: 1.947807, test loss: 1.048814, bias2: 0.9612041115760803, variance: 0.08761005103588104\n",
      "Train size: [400] hidden size: [14] trial: 23, train_loss: 1.941717, test loss: 1.048680, bias2: 0.9606994390487671, variance: 0.08798036724328995\n",
      "Train size: [400] hidden size: [14] trial: 24, train_loss: 1.939573, test loss: 1.048228, bias2: 0.9621361494064331, variance: 0.08609186857938766\n",
      "Train size: [400] hidden size: [14] trial: 25, train_loss: 1.936134, test loss: 1.047471, bias2: 0.9609156847000122, variance: 0.08655574172735214\n",
      "Train size: [400] hidden size: [14] trial: 26, train_loss: 1.930683, test loss: 1.046103, bias2: 0.9584571123123169, variance: 0.08764556050300598\n",
      "Train size: [400] hidden size: [14] trial: 27, train_loss: 1.938944, test loss: 1.045591, bias2: 0.9588053226470947, variance: 0.0867854431271553\n",
      "Train size: [400] hidden size: [14] trial: 28, train_loss: 1.933482, test loss: 1.044633, bias2: 0.9582456946372986, variance: 0.08638747781515121\n",
      "Train size: [400] hidden size: [14] trial: 29, train_loss: 1.927865, test loss: 1.045049, bias2: 0.9586566090583801, variance: 0.08639272302389145\n",
      "Train size: [400] hidden size: [14] trial: 30, train_loss: 1.932464, test loss: 1.045738, bias2: 0.9585269093513489, variance: 0.08721081912517548\n",
      "Train size: [400] hidden size: [14] trial: 31, train_loss: 1.930203, test loss: 1.047575, bias2: 0.9597633481025696, variance: 0.08781131356954575\n",
      "Train size: [400] hidden size: [14] trial: 32, train_loss: 1.932102, test loss: 1.047342, bias2: 0.9598581194877625, variance: 0.0874834805727005\n",
      "Train size: [400] hidden size: [14] trial: 33, train_loss: 1.931965, test loss: 1.048334, bias2: 0.9598910808563232, variance: 0.08844301104545593\n",
      "Train size: [400] hidden size: [14] trial: 34, train_loss: 1.929900, test loss: 1.049203, bias2: 0.9600481986999512, variance: 0.08915483206510544\n",
      "Train size: [400] hidden size: [14] trial: 35, train_loss: 1.931144, test loss: 1.050647, bias2: 0.9599035978317261, variance: 0.09074390679597855\n",
      "Train size: [400] hidden size: [14] trial: 36, train_loss: 1.928362, test loss: 1.051648, bias2: 0.9581552147865295, variance: 0.09349231421947479\n",
      "Train size: [400] hidden size: [14] trial: 37, train_loss: 1.930482, test loss: 1.051905, bias2: 0.958411455154419, variance: 0.09349358826875687\n",
      "Train size: [400] hidden size: [14] trial: 38, train_loss: 1.929115, test loss: 1.050873, bias2: 0.9579864740371704, variance: 0.09288658946752548\n",
      "Train size: [400] hidden size: [14] trial: 39, train_loss: 1.924929, test loss: 1.051335, bias2: 0.9581934809684753, variance: 0.09314163774251938\n",
      "Train size: [400] hidden size: [14] trial: 40, train_loss: 1.925736, test loss: 1.050962, bias2: 0.9594443440437317, variance: 0.09151798486709595\n",
      "Train size: [400] hidden size: [14] trial: 41, train_loss: 1.928084, test loss: 1.050274, bias2: 0.9600616693496704, variance: 0.09021235257387161\n",
      "Train size: [400] hidden size: [14] trial: 42, train_loss: 1.929315, test loss: 1.050370, bias2: 0.9605752825737, variance: 0.08979492634534836\n",
      "Train size: [400] hidden size: [14] trial: 43, train_loss: 1.928338, test loss: 1.051047, bias2: 0.9601038098335266, variance: 0.09094352275133133\n",
      "Train size: [400] hidden size: [14] trial: 44, train_loss: 1.920805, test loss: 1.051561, bias2: 0.9600009918212891, variance: 0.091559998691082\n",
      "Train size: [400] hidden size: [14] trial: 45, train_loss: 1.930227, test loss: 1.052507, bias2: 0.9606368541717529, variance: 0.09187030792236328\n",
      "Train size: [400] hidden size: [14] trial: 46, train_loss: 1.925352, test loss: 1.052355, bias2: 0.9601837396621704, variance: 0.09217144548892975\n",
      "Train size: [400] hidden size: [14] trial: 47, train_loss: 1.928429, test loss: 1.053701, bias2: 0.9595643877983093, variance: 0.09413618594408035\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [14] trial: 48, train_loss: 1.932046, test loss: 1.053715, bias2: 0.9600530862808228, variance: 0.09366229176521301\n",
      "Train size: [400] hidden size: [14] trial: 49, train_loss: 1.929322, test loss: 1.053264, bias2: 0.960527777671814, variance: 0.09273625910282135\n",
      "##################################################\n",
      "Train size: [400] hidden size: [16] trial: 0, train_loss: 1.884857, test loss: 1.121086, bias2: 1.1210864782333374, variance: 0.0\n",
      "Train size: [400] hidden size: [16] trial: 1, train_loss: 1.938207, test loss: 1.098607, bias2: 1.0409209728240967, variance: 0.05768585950136185\n",
      "Train size: [400] hidden size: [16] trial: 2, train_loss: 1.891131, test loss: 1.079681, bias2: 1.0047228336334229, variance: 0.07495862245559692\n",
      "Train size: [400] hidden size: [16] trial: 3, train_loss: 1.898568, test loss: 1.085562, bias2: 0.9878390431404114, variance: 0.09772273153066635\n",
      "Train size: [400] hidden size: [16] trial: 4, train_loss: 1.912710, test loss: 1.074971, bias2: 0.9739933609962463, variance: 0.10097771883010864\n",
      "Train size: [400] hidden size: [16] trial: 5, train_loss: 1.911687, test loss: 1.070330, bias2: 0.9699241518974304, variance: 0.10040562599897385\n",
      "Train size: [400] hidden size: [16] trial: 6, train_loss: 1.911527, test loss: 1.069180, bias2: 0.9662508964538574, variance: 0.10292886197566986\n",
      "Train size: [400] hidden size: [16] trial: 7, train_loss: 1.905891, test loss: 1.065529, bias2: 0.9554947018623352, variance: 0.11003441363573074\n",
      "Train size: [400] hidden size: [16] trial: 8, train_loss: 1.932650, test loss: 1.068490, bias2: 0.9553000926971436, variance: 0.11318980157375336\n",
      "Train size: [400] hidden size: [16] trial: 9, train_loss: 1.926718, test loss: 1.067676, bias2: 0.9513585567474365, variance: 0.11631704866886139\n",
      "Train size: [400] hidden size: [16] trial: 10, train_loss: 1.915420, test loss: 1.064012, bias2: 0.9494262933731079, variance: 0.11458573490381241\n",
      "Train size: [400] hidden size: [16] trial: 11, train_loss: 1.913366, test loss: 1.061395, bias2: 0.9510360360145569, variance: 0.11035890877246857\n",
      "Train size: [400] hidden size: [16] trial: 12, train_loss: 1.904135, test loss: 1.060496, bias2: 0.9527686238288879, variance: 0.10772757232189178\n",
      "Train size: [400] hidden size: [16] trial: 13, train_loss: 1.915074, test loss: 1.057712, bias2: 0.9522033929824829, variance: 0.10550843179225922\n",
      "Train size: [400] hidden size: [16] trial: 14, train_loss: 1.910373, test loss: 1.057935, bias2: 0.9502028226852417, variance: 0.10773205757141113\n",
      "Train size: [400] hidden size: [16] trial: 15, train_loss: 1.916482, test loss: 1.053918, bias2: 0.9493348002433777, variance: 0.10458344966173172\n",
      "Train size: [400] hidden size: [16] trial: 16, train_loss: 1.922014, test loss: 1.053317, bias2: 0.9485915899276733, variance: 0.10472501814365387\n",
      "Train size: [400] hidden size: [16] trial: 17, train_loss: 1.914836, test loss: 1.052052, bias2: 0.9490743279457092, variance: 0.10297791659832001\n",
      "Train size: [400] hidden size: [16] trial: 18, train_loss: 1.925430, test loss: 1.052836, bias2: 0.948906660079956, variance: 0.10392889380455017\n",
      "Train size: [400] hidden size: [16] trial: 19, train_loss: 1.928358, test loss: 1.051437, bias2: 0.9492711424827576, variance: 0.10216598957777023\n",
      "Train size: [400] hidden size: [16] trial: 20, train_loss: 1.931780, test loss: 1.049213, bias2: 0.9476274847984314, variance: 0.10158602148294449\n",
      "Train size: [400] hidden size: [16] trial: 21, train_loss: 1.929754, test loss: 1.048788, bias2: 0.9478558897972107, variance: 0.10093195736408234\n",
      "Train size: [400] hidden size: [16] trial: 22, train_loss: 1.923799, test loss: 1.048126, bias2: 0.9469546675682068, variance: 0.10117153078317642\n",
      "Train size: [400] hidden size: [16] trial: 23, train_loss: 1.915452, test loss: 1.048855, bias2: 0.9481497406959534, variance: 0.1007051020860672\n",
      "Train size: [400] hidden size: [16] trial: 24, train_loss: 1.917974, test loss: 1.048109, bias2: 0.9490928053855896, variance: 0.0990167111158371\n",
      "Train size: [400] hidden size: [16] trial: 25, train_loss: 1.911539, test loss: 1.050219, bias2: 0.9507912993431091, variance: 0.09942811727523804\n",
      "Train size: [400] hidden size: [16] trial: 26, train_loss: 1.916216, test loss: 1.049287, bias2: 0.9495466947555542, variance: 0.09974071383476257\n",
      "Train size: [400] hidden size: [16] trial: 27, train_loss: 1.911852, test loss: 1.051561, bias2: 0.9503214955329895, variance: 0.10123951733112335\n",
      "Train size: [400] hidden size: [16] trial: 28, train_loss: 1.915667, test loss: 1.051696, bias2: 0.9513840675354004, variance: 0.10031189769506454\n",
      "Train size: [400] hidden size: [16] trial: 29, train_loss: 1.916189, test loss: 1.051222, bias2: 0.9512019157409668, variance: 0.10001982003450394\n",
      "Train size: [400] hidden size: [16] trial: 30, train_loss: 1.915451, test loss: 1.051524, bias2: 0.9509409666061401, variance: 0.10058257728815079\n",
      "Train size: [400] hidden size: [16] trial: 31, train_loss: 1.922448, test loss: 1.053776, bias2: 0.9524857997894287, variance: 0.10128998756408691\n",
      "Train size: [400] hidden size: [16] trial: 32, train_loss: 1.918592, test loss: 1.054686, bias2: 0.9526563286781311, variance: 0.10202949494123459\n",
      "Train size: [400] hidden size: [16] trial: 33, train_loss: 1.920968, test loss: 1.054341, bias2: 0.9524563550949097, variance: 0.10188422352075577\n",
      "Train size: [400] hidden size: [16] trial: 34, train_loss: 1.919039, test loss: 1.054474, bias2: 0.9528694152832031, variance: 0.10160472244024277\n",
      "Train size: [400] hidden size: [16] trial: 35, train_loss: 1.916548, test loss: 1.056110, bias2: 0.9536011815071106, variance: 0.10250846296548843\n",
      "Train size: [400] hidden size: [16] trial: 36, train_loss: 1.915301, test loss: 1.056191, bias2: 0.9532495141029358, variance: 0.10294109582901001\n",
      "Train size: [400] hidden size: [16] trial: 37, train_loss: 1.915747, test loss: 1.055927, bias2: 0.9542680978775024, variance: 0.10165895521640778\n",
      "Train size: [400] hidden size: [16] trial: 38, train_loss: 1.912809, test loss: 1.056155, bias2: 0.9547513127326965, variance: 0.1014038696885109\n",
      "Train size: [400] hidden size: [16] trial: 39, train_loss: 1.912633, test loss: 1.055593, bias2: 0.9543457627296448, variance: 0.10124772787094116\n",
      "Train size: [400] hidden size: [16] trial: 40, train_loss: 1.906175, test loss: 1.055384, bias2: 0.9538092017173767, variance: 0.10157518833875656\n",
      "Train size: [400] hidden size: [16] trial: 41, train_loss: 1.902047, test loss: 1.056092, bias2: 0.9536081552505493, variance: 0.10248348116874695\n",
      "Train size: [400] hidden size: [16] trial: 42, train_loss: 1.903114, test loss: 1.055345, bias2: 0.9537161588668823, variance: 0.10162892192602158\n",
      "Train size: [400] hidden size: [16] trial: 43, train_loss: 1.909069, test loss: 1.055620, bias2: 0.9536912441253662, variance: 0.10192916542291641\n",
      "Train size: [400] hidden size: [16] trial: 44, train_loss: 1.903904, test loss: 1.056794, bias2: 0.9537136554718018, variance: 0.10308005660772324\n",
      "Train size: [400] hidden size: [16] trial: 45, train_loss: 1.905224, test loss: 1.056613, bias2: 0.9540667533874512, variance: 0.10254621505737305\n",
      "Train size: [400] hidden size: [16] trial: 46, train_loss: 1.906883, test loss: 1.057669, bias2: 0.9548022150993347, variance: 0.10286637395620346\n",
      "Train size: [400] hidden size: [16] trial: 47, train_loss: 1.903942, test loss: 1.059001, bias2: 0.9550532102584839, variance: 0.10394763946533203\n",
      "Train size: [400] hidden size: [16] trial: 48, train_loss: 1.904848, test loss: 1.058130, bias2: 0.953454315662384, variance: 0.10467571020126343\n",
      "Train size: [400] hidden size: [16] trial: 49, train_loss: 1.908492, test loss: 1.058022, bias2: 0.9531203508377075, variance: 0.10490116477012634\n",
      "##################################################\n",
      "Train size: [400] hidden size: [19] trial: 0, train_loss: 1.673559, test loss: 1.054185, bias2: 1.0541852712631226, variance: 7.785095901269301e-10\n",
      "Train size: [400] hidden size: [19] trial: 1, train_loss: 1.758524, test loss: 1.024967, bias2: 0.9818451404571533, variance: 0.04312146455049515\n",
      "Train size: [400] hidden size: [19] trial: 2, train_loss: 1.858631, test loss: 1.025539, bias2: 0.9588902592658997, variance: 0.06664852797985077\n",
      "Train size: [400] hidden size: [19] trial: 3, train_loss: 1.856362, test loss: 1.031780, bias2: 0.9591994881629944, variance: 0.07258061319589615\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [19] trial: 4, train_loss: 1.854125, test loss: 1.036020, bias2: 0.9568495154380798, variance: 0.07917026430368423\n",
      "Train size: [400] hidden size: [19] trial: 5, train_loss: 1.853311, test loss: 1.057545, bias2: 0.9618873596191406, variance: 0.09565773606300354\n",
      "Train size: [400] hidden size: [19] trial: 6, train_loss: 1.870694, test loss: 1.068073, bias2: 0.966884195804596, variance: 0.10118885338306427\n",
      "Train size: [400] hidden size: [19] trial: 7, train_loss: 1.876595, test loss: 1.065453, bias2: 0.9638341069221497, variance: 0.10161896795034409\n",
      "Train size: [400] hidden size: [19] trial: 8, train_loss: 1.880485, test loss: 1.073438, bias2: 0.9525700807571411, variance: 0.12086822092533112\n",
      "Train size: [400] hidden size: [19] trial: 9, train_loss: 1.869476, test loss: 1.075892, bias2: 0.9530947804450989, variance: 0.12279743701219559\n",
      "Train size: [400] hidden size: [19] trial: 10, train_loss: 1.865335, test loss: 1.073313, bias2: 0.9530602693557739, variance: 0.12025260925292969\n",
      "Train size: [400] hidden size: [19] trial: 11, train_loss: 1.869475, test loss: 1.078074, bias2: 0.9555083513259888, variance: 0.12256596982479095\n",
      "Train size: [400] hidden size: [19] trial: 12, train_loss: 1.868928, test loss: 1.077736, bias2: 0.9571204781532288, variance: 0.12061532586812973\n",
      "Train size: [400] hidden size: [19] trial: 13, train_loss: 1.863558, test loss: 1.080832, bias2: 0.9534450769424438, variance: 0.12738646566867828\n",
      "Train size: [400] hidden size: [19] trial: 14, train_loss: 1.854233, test loss: 1.079569, bias2: 0.9533066153526306, variance: 0.1262621283531189\n",
      "Train size: [400] hidden size: [19] trial: 15, train_loss: 1.857444, test loss: 1.082226, bias2: 0.9526392817497253, variance: 0.12958641350269318\n",
      "Train size: [400] hidden size: [19] trial: 16, train_loss: 1.862791, test loss: 1.084122, bias2: 0.9541651010513306, variance: 0.12995684146881104\n",
      "Train size: [400] hidden size: [19] trial: 17, train_loss: 1.872325, test loss: 1.082191, bias2: 0.9501906037330627, variance: 0.13200052082538605\n",
      "Train size: [400] hidden size: [19] trial: 18, train_loss: 1.865356, test loss: 1.083117, bias2: 0.9508981704711914, variance: 0.1322183609008789\n",
      "Train size: [400] hidden size: [19] trial: 19, train_loss: 1.846594, test loss: 1.082633, bias2: 0.9519208669662476, variance: 0.13071206212043762\n",
      "Train size: [400] hidden size: [19] trial: 20, train_loss: 1.843596, test loss: 1.082074, bias2: 0.9484006762504578, variance: 0.13367335498332977\n",
      "Train size: [400] hidden size: [19] trial: 21, train_loss: 1.844738, test loss: 1.083121, bias2: 0.9486966133117676, variance: 0.13442468643188477\n",
      "Train size: [400] hidden size: [19] trial: 22, train_loss: 1.846451, test loss: 1.083183, bias2: 0.9463395476341248, variance: 0.1368432641029358\n",
      "Train size: [400] hidden size: [19] trial: 23, train_loss: 1.843036, test loss: 1.083855, bias2: 0.9463633894920349, variance: 0.1374913901090622\n",
      "Train size: [400] hidden size: [19] trial: 24, train_loss: 1.842910, test loss: 1.083585, bias2: 0.9470723867416382, variance: 0.13651297986507416\n",
      "Train size: [400] hidden size: [19] trial: 25, train_loss: 1.840924, test loss: 1.083615, bias2: 0.9457473754882812, variance: 0.1378680318593979\n",
      "Train size: [400] hidden size: [19] trial: 26, train_loss: 1.849802, test loss: 1.084315, bias2: 0.9459716081619263, variance: 0.13834348320960999\n",
      "Train size: [400] hidden size: [19] trial: 27, train_loss: 1.845276, test loss: 1.083770, bias2: 0.9471347332000732, variance: 0.1366351991891861\n",
      "Train size: [400] hidden size: [19] trial: 28, train_loss: 1.840505, test loss: 1.083930, bias2: 0.9466391801834106, variance: 0.13729046285152435\n",
      "Train size: [400] hidden size: [19] trial: 29, train_loss: 1.847850, test loss: 1.083013, bias2: 0.9480249881744385, variance: 0.13498784601688385\n",
      "Train size: [400] hidden size: [19] trial: 30, train_loss: 1.844808, test loss: 1.080892, bias2: 0.9472139477729797, variance: 0.13367800414562225\n",
      "Train size: [400] hidden size: [19] trial: 31, train_loss: 1.841149, test loss: 1.079193, bias2: 0.9443918466567993, variance: 0.13480138778686523\n",
      "Train size: [400] hidden size: [19] trial: 32, train_loss: 1.846452, test loss: 1.079709, bias2: 0.9446249008178711, variance: 0.1350841373205185\n",
      "Train size: [400] hidden size: [19] trial: 33, train_loss: 1.843616, test loss: 1.079140, bias2: 0.9456251859664917, variance: 0.1335146129131317\n",
      "Train size: [400] hidden size: [19] trial: 34, train_loss: 1.844337, test loss: 1.079023, bias2: 0.9447426795959473, variance: 0.13428018987178802\n",
      "Train size: [400] hidden size: [19] trial: 35, train_loss: 1.853567, test loss: 1.079698, bias2: 0.9461869597434998, variance: 0.13351112604141235\n",
      "Train size: [400] hidden size: [19] trial: 36, train_loss: 1.855040, test loss: 1.082746, bias2: 0.9460898637771606, variance: 0.13665606081485748\n",
      "Train size: [400] hidden size: [19] trial: 37, train_loss: 1.852481, test loss: 1.082314, bias2: 0.9465371966362, variance: 0.1357770562171936\n",
      "Train size: [400] hidden size: [19] trial: 38, train_loss: 1.851892, test loss: 1.082233, bias2: 0.945380449295044, variance: 0.13685263693332672\n",
      "Train size: [400] hidden size: [19] trial: 39, train_loss: 1.849714, test loss: 1.081569, bias2: 0.9438621997833252, variance: 0.13770699501037598\n",
      "Train size: [400] hidden size: [19] trial: 40, train_loss: 1.850596, test loss: 1.082683, bias2: 0.9435809850692749, variance: 0.13910186290740967\n",
      "Train size: [400] hidden size: [19] trial: 41, train_loss: 1.850711, test loss: 1.081613, bias2: 0.9436509609222412, variance: 0.1379624754190445\n",
      "Train size: [400] hidden size: [19] trial: 42, train_loss: 1.851753, test loss: 1.080681, bias2: 0.9442750811576843, variance: 0.13640612363815308\n",
      "Train size: [400] hidden size: [19] trial: 43, train_loss: 1.852386, test loss: 1.080415, bias2: 0.9448791742324829, variance: 0.13553619384765625\n",
      "Train size: [400] hidden size: [19] trial: 44, train_loss: 1.853387, test loss: 1.080993, bias2: 0.9450845718383789, variance: 0.13590863347053528\n",
      "Train size: [400] hidden size: [19] trial: 45, train_loss: 1.849510, test loss: 1.081063, bias2: 0.9454123973846436, variance: 0.1356504112482071\n",
      "Train size: [400] hidden size: [19] trial: 46, train_loss: 1.847918, test loss: 1.080900, bias2: 0.9467003345489502, variance: 0.13419999182224274\n",
      "Train size: [400] hidden size: [19] trial: 47, train_loss: 1.851527, test loss: 1.080475, bias2: 0.9465806484222412, variance: 0.13389478623867035\n",
      "Train size: [400] hidden size: [19] trial: 48, train_loss: 1.850330, test loss: 1.080096, bias2: 0.9466167092323303, variance: 0.1334793120622635\n",
      "Train size: [400] hidden size: [19] trial: 49, train_loss: 1.851111, test loss: 1.079962, bias2: 0.9469150900840759, variance: 0.1330464631319046\n",
      "##################################################\n",
      "Train size: [400] hidden size: [22] trial: 0, train_loss: 1.920516, test loss: 1.065850, bias2: 1.0658504962921143, variance: 4.865685077071191e-10\n",
      "Train size: [400] hidden size: [22] trial: 1, train_loss: 1.887330, test loss: 1.077280, bias2: 0.9963440299034119, variance: 0.08093579858541489\n",
      "Train size: [400] hidden size: [22] trial: 2, train_loss: 1.882025, test loss: 1.077236, bias2: 0.9749897122383118, variance: 0.1022464781999588\n",
      "Train size: [400] hidden size: [22] trial: 3, train_loss: 1.794548, test loss: 1.072254, bias2: 0.950928270816803, variance: 0.12132542580366135\n",
      "Train size: [400] hidden size: [22] trial: 4, train_loss: 1.758066, test loss: 1.074143, bias2: 0.9419900178909302, variance: 0.13215316832065582\n",
      "Train size: [400] hidden size: [22] trial: 5, train_loss: 1.837932, test loss: 1.082512, bias2: 0.9350866079330444, variance: 0.1474258005619049\n",
      "Train size: [400] hidden size: [22] trial: 6, train_loss: 1.866814, test loss: 1.088835, bias2: 0.9339412450790405, variance: 0.15489408373832703\n",
      "Train size: [400] hidden size: [22] trial: 7, train_loss: 1.872335, test loss: 1.097777, bias2: 0.9337491989135742, variance: 0.16402742266654968\n",
      "Train size: [400] hidden size: [22] trial: 8, train_loss: 1.874801, test loss: 1.092960, bias2: 0.9362803101539612, variance: 0.1566799432039261\n",
      "Train size: [400] hidden size: [22] trial: 9, train_loss: 1.853699, test loss: 1.097203, bias2: 0.9357054829597473, variance: 0.16149799525737762\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [22] trial: 10, train_loss: 1.858650, test loss: 1.093162, bias2: 0.9344061613082886, variance: 0.158756285905838\n",
      "Train size: [400] hidden size: [22] trial: 11, train_loss: 1.867590, test loss: 1.087667, bias2: 0.9302675724029541, variance: 0.15739916265010834\n",
      "Train size: [400] hidden size: [22] trial: 12, train_loss: 1.872367, test loss: 1.086814, bias2: 0.9301156997680664, variance: 0.15669788420200348\n",
      "Train size: [400] hidden size: [22] trial: 13, train_loss: 1.874776, test loss: 1.086406, bias2: 0.9297446012496948, variance: 0.1566615253686905\n",
      "Train size: [400] hidden size: [22] trial: 14, train_loss: 1.870588, test loss: 1.085118, bias2: 0.9309920072555542, variance: 0.15412546694278717\n",
      "Train size: [400] hidden size: [22] trial: 15, train_loss: 1.869892, test loss: 1.084688, bias2: 0.9328709244728088, variance: 0.15181690454483032\n",
      "Train size: [400] hidden size: [22] trial: 16, train_loss: 1.861875, test loss: 1.082258, bias2: 0.9337219595909119, variance: 0.14853636920452118\n",
      "Train size: [400] hidden size: [22] trial: 17, train_loss: 1.867682, test loss: 1.079835, bias2: 0.9320403337478638, variance: 0.14779426157474518\n",
      "Train size: [400] hidden size: [22] trial: 18, train_loss: 1.871032, test loss: 1.079937, bias2: 0.9312729835510254, variance: 0.14866387844085693\n",
      "Train size: [400] hidden size: [22] trial: 19, train_loss: 1.878448, test loss: 1.081525, bias2: 0.9279410243034363, variance: 0.1535840630531311\n",
      "Train size: [400] hidden size: [22] trial: 20, train_loss: 1.870018, test loss: 1.078950, bias2: 0.9280909895896912, variance: 0.15085940062999725\n",
      "Train size: [400] hidden size: [22] trial: 21, train_loss: 1.868866, test loss: 1.077584, bias2: 0.9289053678512573, variance: 0.14867839217185974\n",
      "Train size: [400] hidden size: [22] trial: 22, train_loss: 1.864657, test loss: 1.077633, bias2: 0.9286789298057556, variance: 0.14895397424697876\n",
      "Train size: [400] hidden size: [22] trial: 23, train_loss: 1.860290, test loss: 1.074831, bias2: 0.9266276955604553, variance: 0.14820320904254913\n",
      "Train size: [400] hidden size: [22] trial: 24, train_loss: 1.854575, test loss: 1.075662, bias2: 0.9261739253997803, variance: 0.14948785305023193\n",
      "Train size: [400] hidden size: [22] trial: 25, train_loss: 1.847006, test loss: 1.075504, bias2: 0.926067054271698, variance: 0.14943735301494598\n",
      "Train size: [400] hidden size: [22] trial: 26, train_loss: 1.848418, test loss: 1.077066, bias2: 0.9257025122642517, variance: 0.15136390924453735\n",
      "Train size: [400] hidden size: [22] trial: 27, train_loss: 1.844887, test loss: 1.076264, bias2: 0.9256526231765747, variance: 0.15061131119728088\n",
      "Train size: [400] hidden size: [22] trial: 28, train_loss: 1.841473, test loss: 1.073722, bias2: 0.9232966899871826, variance: 0.15042565762996674\n",
      "Train size: [400] hidden size: [22] trial: 29, train_loss: 1.844255, test loss: 1.072007, bias2: 0.922260046005249, variance: 0.14974664151668549\n",
      "Train size: [400] hidden size: [22] trial: 30, train_loss: 1.849889, test loss: 1.072707, bias2: 0.9226434230804443, variance: 0.15006400644779205\n",
      "Train size: [400] hidden size: [22] trial: 31, train_loss: 1.850313, test loss: 1.071251, bias2: 0.9233272075653076, variance: 0.14792393147945404\n",
      "Train size: [400] hidden size: [22] trial: 32, train_loss: 1.855125, test loss: 1.073662, bias2: 0.9242664575576782, variance: 0.14939583837985992\n",
      "Train size: [400] hidden size: [22] trial: 33, train_loss: 1.855101, test loss: 1.074416, bias2: 0.9260555505752563, variance: 0.1483602523803711\n",
      "Train size: [400] hidden size: [22] trial: 34, train_loss: 1.850792, test loss: 1.075148, bias2: 0.9264488220214844, variance: 0.14869962632656097\n",
      "Train size: [400] hidden size: [22] trial: 35, train_loss: 1.846862, test loss: 1.076527, bias2: 0.925064742565155, variance: 0.15146251022815704\n",
      "Train size: [400] hidden size: [22] trial: 36, train_loss: 1.845566, test loss: 1.075707, bias2: 0.925388753414154, variance: 0.15031783282756805\n",
      "Train size: [400] hidden size: [22] trial: 37, train_loss: 1.843207, test loss: 1.076396, bias2: 0.9240193367004395, variance: 0.15237663686275482\n",
      "Train size: [400] hidden size: [22] trial: 38, train_loss: 1.848002, test loss: 1.075895, bias2: 0.9240244626998901, variance: 0.15187039971351624\n",
      "Train size: [400] hidden size: [22] trial: 39, train_loss: 1.843428, test loss: 1.076056, bias2: 0.9253174662590027, variance: 0.15073828399181366\n",
      "Train size: [400] hidden size: [22] trial: 40, train_loss: 1.849455, test loss: 1.075173, bias2: 0.9255181550979614, variance: 0.14965461194515228\n",
      "Train size: [400] hidden size: [22] trial: 41, train_loss: 1.843470, test loss: 1.075228, bias2: 0.926411509513855, variance: 0.14881619811058044\n",
      "Train size: [400] hidden size: [22] trial: 42, train_loss: 1.842782, test loss: 1.075805, bias2: 0.9278861880302429, variance: 0.14791876077651978\n",
      "Train size: [400] hidden size: [22] trial: 43, train_loss: 1.844223, test loss: 1.076844, bias2: 0.9288018941879272, variance: 0.14804229140281677\n",
      "Train size: [400] hidden size: [22] trial: 44, train_loss: 1.840083, test loss: 1.076240, bias2: 0.928252637386322, variance: 0.14798764884471893\n",
      "Train size: [400] hidden size: [22] trial: 45, train_loss: 1.844849, test loss: 1.076242, bias2: 0.9265305399894714, variance: 0.14971096813678741\n",
      "Train size: [400] hidden size: [22] trial: 46, train_loss: 1.848001, test loss: 1.077355, bias2: 0.9272240400314331, variance: 0.1501304805278778\n",
      "Train size: [400] hidden size: [22] trial: 47, train_loss: 1.850685, test loss: 1.077182, bias2: 0.9274338483810425, variance: 0.14974799752235413\n",
      "Train size: [400] hidden size: [22] trial: 48, train_loss: 1.850277, test loss: 1.078253, bias2: 0.9269955158233643, variance: 0.15125712752342224\n",
      "Train size: [400] hidden size: [22] trial: 49, train_loss: 1.845212, test loss: 1.079099, bias2: 0.9255321621894836, variance: 0.153567373752594\n",
      "##################################################\n",
      "Train size: [400] hidden size: [25] trial: 0, train_loss: 1.783553, test loss: 1.102423, bias2: 1.1024234294891357, variance: 0.0\n",
      "Train size: [400] hidden size: [25] trial: 1, train_loss: 1.772312, test loss: 1.110845, bias2: 1.0281572341918945, variance: 0.08268805593252182\n",
      "Train size: [400] hidden size: [25] trial: 2, train_loss: 1.756523, test loss: 1.120636, bias2: 0.9989224076271057, variance: 0.12171357125043869\n",
      "Train size: [400] hidden size: [25] trial: 3, train_loss: 1.769884, test loss: 1.132276, bias2: 0.9950990080833435, variance: 0.13717679679393768\n",
      "Train size: [400] hidden size: [25] trial: 4, train_loss: 1.772794, test loss: 1.111693, bias2: 0.9824484586715698, variance: 0.1292445808649063\n",
      "Train size: [400] hidden size: [25] trial: 5, train_loss: 1.767229, test loss: 1.113930, bias2: 0.9762653112411499, variance: 0.1376645565032959\n",
      "Train size: [400] hidden size: [25] trial: 6, train_loss: 1.766686, test loss: 1.116514, bias2: 0.9638588428497314, variance: 0.1526554971933365\n",
      "Train size: [400] hidden size: [25] trial: 7, train_loss: 1.778638, test loss: 1.111796, bias2: 0.9636073112487793, variance: 0.14818879961967468\n",
      "Train size: [400] hidden size: [25] trial: 8, train_loss: 1.779266, test loss: 1.104734, bias2: 0.9562917947769165, variance: 0.14844226837158203\n",
      "Train size: [400] hidden size: [25] trial: 9, train_loss: 1.763400, test loss: 1.107876, bias2: 0.9471219182014465, variance: 0.16075415909290314\n",
      "Train size: [400] hidden size: [25] trial: 10, train_loss: 1.756920, test loss: 1.103351, bias2: 0.944564163684845, variance: 0.1587868183851242\n",
      "Train size: [400] hidden size: [25] trial: 11, train_loss: 1.776332, test loss: 1.100648, bias2: 0.9445972442626953, variance: 0.15605081617832184\n",
      "Train size: [400] hidden size: [25] trial: 12, train_loss: 1.763734, test loss: 1.098407, bias2: 0.9405308961868286, variance: 0.1578756719827652\n",
      "Train size: [400] hidden size: [25] trial: 13, train_loss: 1.765844, test loss: 1.095149, bias2: 0.9409308433532715, variance: 0.15421822667121887\n",
      "Train size: [400] hidden size: [25] trial: 14, train_loss: 1.760622, test loss: 1.094453, bias2: 0.9429948329925537, variance: 0.15145829319953918\n",
      "Train size: [400] hidden size: [25] trial: 15, train_loss: 1.769506, test loss: 1.090865, bias2: 0.9421051144599915, variance: 0.14875978231430054\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [25] trial: 16, train_loss: 1.771851, test loss: 1.087657, bias2: 0.9414093494415283, variance: 0.1462475210428238\n",
      "Train size: [400] hidden size: [25] trial: 17, train_loss: 1.781334, test loss: 1.088899, bias2: 0.9424029588699341, variance: 0.14649644494056702\n",
      "Train size: [400] hidden size: [25] trial: 18, train_loss: 1.784004, test loss: 1.088477, bias2: 0.9412253499031067, variance: 0.1472518891096115\n",
      "Train size: [400] hidden size: [25] trial: 19, train_loss: 1.779058, test loss: 1.088964, bias2: 0.9402554035186768, variance: 0.14870870113372803\n",
      "Train size: [400] hidden size: [25] trial: 20, train_loss: 1.778240, test loss: 1.089747, bias2: 0.9404556751251221, variance: 0.14929163455963135\n",
      "Train size: [400] hidden size: [25] trial: 21, train_loss: 1.776688, test loss: 1.087055, bias2: 0.9390733242034912, variance: 0.14798139035701752\n",
      "Train size: [400] hidden size: [25] trial: 22, train_loss: 1.778061, test loss: 1.086117, bias2: 0.939354658126831, variance: 0.14676186442375183\n",
      "Train size: [400] hidden size: [25] trial: 23, train_loss: 1.777718, test loss: 1.086684, bias2: 0.9386293292045593, variance: 0.14805489778518677\n",
      "Train size: [400] hidden size: [25] trial: 24, train_loss: 1.788938, test loss: 1.086725, bias2: 0.939263105392456, variance: 0.14746226370334625\n",
      "Train size: [400] hidden size: [25] trial: 25, train_loss: 1.784597, test loss: 1.085420, bias2: 0.9384488463401794, variance: 0.14697150886058807\n",
      "Train size: [400] hidden size: [25] trial: 26, train_loss: 1.798021, test loss: 1.084142, bias2: 0.9384583830833435, variance: 0.14568348228931427\n",
      "Train size: [400] hidden size: [25] trial: 27, train_loss: 1.796095, test loss: 1.084629, bias2: 0.9381122589111328, variance: 0.1465165615081787\n",
      "Train size: [400] hidden size: [25] trial: 28, train_loss: 1.800817, test loss: 1.085013, bias2: 0.935562789440155, variance: 0.14945010840892792\n",
      "Train size: [400] hidden size: [25] trial: 29, train_loss: 1.797832, test loss: 1.085319, bias2: 0.9353032112121582, variance: 0.15001608431339264\n",
      "Train size: [400] hidden size: [25] trial: 30, train_loss: 1.795755, test loss: 1.084756, bias2: 0.9343337416648865, variance: 0.1504219025373459\n",
      "Train size: [400] hidden size: [25] trial: 31, train_loss: 1.800367, test loss: 1.087547, bias2: 0.9337780475616455, variance: 0.153769388794899\n",
      "Train size: [400] hidden size: [25] trial: 32, train_loss: 1.793522, test loss: 1.086449, bias2: 0.9333806037902832, variance: 0.1530679613351822\n",
      "Train size: [400] hidden size: [25] trial: 33, train_loss: 1.799232, test loss: 1.085545, bias2: 0.9331322908401489, variance: 0.1524125635623932\n",
      "Train size: [400] hidden size: [25] trial: 34, train_loss: 1.802716, test loss: 1.086818, bias2: 0.933475136756897, variance: 0.15334275364875793\n",
      "Train size: [400] hidden size: [25] trial: 35, train_loss: 1.802559, test loss: 1.089163, bias2: 0.9328020811080933, variance: 0.15636099874973297\n",
      "Train size: [400] hidden size: [25] trial: 36, train_loss: 1.801300, test loss: 1.088110, bias2: 0.9324091672897339, variance: 0.1557011604309082\n",
      "Train size: [400] hidden size: [25] trial: 37, train_loss: 1.800737, test loss: 1.089773, bias2: 0.9320417642593384, variance: 0.157730832695961\n",
      "Train size: [400] hidden size: [25] trial: 38, train_loss: 1.802128, test loss: 1.089993, bias2: 0.9326337575912476, variance: 0.15735898911952972\n",
      "Train size: [400] hidden size: [25] trial: 39, train_loss: 1.804477, test loss: 1.090451, bias2: 0.9328532218933105, variance: 0.15759778022766113\n",
      "Train size: [400] hidden size: [25] trial: 40, train_loss: 1.812473, test loss: 1.091595, bias2: 0.9324239492416382, variance: 0.15917064249515533\n",
      "Train size: [400] hidden size: [25] trial: 41, train_loss: 1.809455, test loss: 1.091189, bias2: 0.9325242042541504, variance: 0.15866434574127197\n",
      "Train size: [400] hidden size: [25] trial: 42, train_loss: 1.810598, test loss: 1.090682, bias2: 0.9315117597579956, variance: 0.15917037427425385\n",
      "Train size: [400] hidden size: [25] trial: 43, train_loss: 1.812950, test loss: 1.089310, bias2: 0.9309044480323792, variance: 0.1584051102399826\n",
      "Train size: [400] hidden size: [25] trial: 44, train_loss: 1.814383, test loss: 1.089528, bias2: 0.9304433465003967, variance: 0.15908484160900116\n",
      "Train size: [400] hidden size: [25] trial: 45, train_loss: 1.816361, test loss: 1.089468, bias2: 0.9294458031654358, variance: 0.16002245247364044\n",
      "Train size: [400] hidden size: [25] trial: 46, train_loss: 1.811421, test loss: 1.090843, bias2: 0.9301723837852478, variance: 0.1606704592704773\n",
      "Train size: [400] hidden size: [25] trial: 47, train_loss: 1.807792, test loss: 1.090002, bias2: 0.9285371899604797, variance: 0.1614644080400467\n",
      "Train size: [400] hidden size: [25] trial: 48, train_loss: 1.808049, test loss: 1.090232, bias2: 0.9288318157196045, variance: 0.16140034794807434\n",
      "Train size: [400] hidden size: [25] trial: 49, train_loss: 1.810672, test loss: 1.090491, bias2: 0.9283467531204224, variance: 0.16214393079280853\n",
      "##################################################\n",
      "Train size: [400] hidden size: [29] trial: 0, train_loss: 1.881296, test loss: 1.113999, bias2: 1.1139990091323853, variance: 5.838822203507732e-10\n",
      "Train size: [400] hidden size: [29] trial: 1, train_loss: 1.783146, test loss: 1.090277, bias2: 1.0266671180725098, variance: 0.06360958516597748\n",
      "Train size: [400] hidden size: [29] trial: 2, train_loss: 1.735181, test loss: 1.072539, bias2: 0.9811195731163025, variance: 0.09141986072063446\n",
      "Train size: [400] hidden size: [29] trial: 3, train_loss: 1.732753, test loss: 1.089763, bias2: 0.9624389410018921, variance: 0.12732437252998352\n",
      "Train size: [400] hidden size: [29] trial: 4, train_loss: 1.754729, test loss: 1.086988, bias2: 0.953991711139679, variance: 0.13299663364887238\n",
      "Train size: [400] hidden size: [29] trial: 5, train_loss: 1.781720, test loss: 1.096177, bias2: 0.9450002312660217, variance: 0.15117625892162323\n",
      "Train size: [400] hidden size: [29] trial: 6, train_loss: 1.786269, test loss: 1.091786, bias2: 0.9451361298561096, variance: 0.1466502696275711\n",
      "Train size: [400] hidden size: [29] trial: 7, train_loss: 1.767743, test loss: 1.094546, bias2: 0.9457610845565796, variance: 0.1487848460674286\n",
      "Train size: [400] hidden size: [29] trial: 8, train_loss: 1.771969, test loss: 1.094932, bias2: 0.9426013231277466, variance: 0.15233014523983002\n",
      "Train size: [400] hidden size: [29] trial: 9, train_loss: 1.769716, test loss: 1.090861, bias2: 0.936070442199707, variance: 0.1547902524471283\n",
      "Train size: [400] hidden size: [29] trial: 10, train_loss: 1.772181, test loss: 1.092812, bias2: 0.9360359311103821, variance: 0.15677575767040253\n",
      "Train size: [400] hidden size: [29] trial: 11, train_loss: 1.774330, test loss: 1.095450, bias2: 0.9343522787094116, variance: 0.1610974222421646\n",
      "Train size: [400] hidden size: [29] trial: 12, train_loss: 1.764967, test loss: 1.090191, bias2: 0.9306629300117493, variance: 0.1595284342765808\n",
      "Train size: [400] hidden size: [29] trial: 13, train_loss: 1.763899, test loss: 1.089339, bias2: 0.9284957647323608, variance: 0.16084326803684235\n",
      "Train size: [400] hidden size: [29] trial: 14, train_loss: 1.763951, test loss: 1.091712, bias2: 0.9263572096824646, variance: 0.1653551608324051\n",
      "Train size: [400] hidden size: [29] trial: 15, train_loss: 1.772758, test loss: 1.091209, bias2: 0.923090398311615, variance: 0.16811878979206085\n",
      "Train size: [400] hidden size: [29] trial: 16, train_loss: 1.779683, test loss: 1.090514, bias2: 0.9222304821014404, variance: 0.1682833433151245\n",
      "Train size: [400] hidden size: [29] trial: 17, train_loss: 1.778388, test loss: 1.088994, bias2: 0.9214491844177246, variance: 0.16754519939422607\n",
      "Train size: [400] hidden size: [29] trial: 18, train_loss: 1.786021, test loss: 1.090951, bias2: 0.920685887336731, variance: 0.1702652871608734\n",
      "Train size: [400] hidden size: [29] trial: 19, train_loss: 1.785875, test loss: 1.087954, bias2: 0.9197797775268555, variance: 0.1681741178035736\n",
      "Train size: [400] hidden size: [29] trial: 20, train_loss: 1.792401, test loss: 1.089197, bias2: 0.9205625057220459, variance: 0.16863402724266052\n",
      "Train size: [400] hidden size: [29] trial: 21, train_loss: 1.794212, test loss: 1.093606, bias2: 0.9186115264892578, variance: 0.17499448359012604\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [29] trial: 22, train_loss: 1.786958, test loss: 1.094095, bias2: 0.9199475049972534, variance: 0.17414721846580505\n",
      "Train size: [400] hidden size: [29] trial: 23, train_loss: 1.786164, test loss: 1.094142, bias2: 0.9186868667602539, variance: 0.17545495927333832\n",
      "Train size: [400] hidden size: [29] trial: 24, train_loss: 1.791020, test loss: 1.093864, bias2: 0.917701244354248, variance: 0.1761629432439804\n",
      "Train size: [400] hidden size: [29] trial: 25, train_loss: 1.786396, test loss: 1.092735, bias2: 0.9145858287811279, variance: 0.17814943194389343\n",
      "Train size: [400] hidden size: [29] trial: 26, train_loss: 1.787839, test loss: 1.091948, bias2: 0.9130297899246216, variance: 0.17891791462898254\n",
      "Train size: [400] hidden size: [29] trial: 27, train_loss: 1.783836, test loss: 1.092601, bias2: 0.9129753708839417, variance: 0.17962521314620972\n",
      "Train size: [400] hidden size: [29] trial: 28, train_loss: 1.779939, test loss: 1.091832, bias2: 0.9133188724517822, variance: 0.17851269245147705\n",
      "Train size: [400] hidden size: [29] trial: 29, train_loss: 1.784004, test loss: 1.092319, bias2: 0.9116433262825012, variance: 0.1806759089231491\n",
      "Train size: [400] hidden size: [29] trial: 30, train_loss: 1.788653, test loss: 1.092371, bias2: 0.9115294814109802, variance: 0.18084128201007843\n",
      "Train size: [400] hidden size: [29] trial: 31, train_loss: 1.786663, test loss: 1.094700, bias2: 0.9116186499595642, variance: 0.18308095633983612\n",
      "Train size: [400] hidden size: [29] trial: 32, train_loss: 1.780271, test loss: 1.093701, bias2: 0.9103278517723083, variance: 0.18337363004684448\n",
      "Train size: [400] hidden size: [29] trial: 33, train_loss: 1.779775, test loss: 1.094703, bias2: 0.9091107845306396, variance: 0.1855916678905487\n",
      "Train size: [400] hidden size: [29] trial: 34, train_loss: 1.782265, test loss: 1.092805, bias2: 0.9076173901557922, variance: 0.18518753349781036\n",
      "Train size: [400] hidden size: [29] trial: 35, train_loss: 1.778974, test loss: 1.092794, bias2: 0.9063444137573242, variance: 0.1864500194787979\n",
      "Train size: [400] hidden size: [29] trial: 36, train_loss: 1.780262, test loss: 1.091459, bias2: 0.9040841460227966, variance: 0.1873752623796463\n",
      "Train size: [400] hidden size: [29] trial: 37, train_loss: 1.781155, test loss: 1.090961, bias2: 0.9031195640563965, variance: 0.18784141540527344\n",
      "Train size: [400] hidden size: [29] trial: 38, train_loss: 1.778857, test loss: 1.091047, bias2: 0.9038399457931519, variance: 0.1872071921825409\n",
      "Train size: [400] hidden size: [29] trial: 39, train_loss: 1.779937, test loss: 1.091848, bias2: 0.9041467905044556, variance: 0.18770122528076172\n",
      "Train size: [400] hidden size: [29] trial: 40, train_loss: 1.773467, test loss: 1.089921, bias2: 0.9048280715942383, variance: 0.18509256839752197\n",
      "Train size: [400] hidden size: [29] trial: 41, train_loss: 1.773433, test loss: 1.089670, bias2: 0.9037677049636841, variance: 0.18590211868286133\n",
      "Train size: [400] hidden size: [29] trial: 42, train_loss: 1.773401, test loss: 1.090140, bias2: 0.9056531190872192, variance: 0.18448641896247864\n",
      "Train size: [400] hidden size: [29] trial: 43, train_loss: 1.779271, test loss: 1.090357, bias2: 0.9048997759819031, variance: 0.1854567974805832\n",
      "Train size: [400] hidden size: [29] trial: 44, train_loss: 1.772331, test loss: 1.091538, bias2: 0.9049421548843384, variance: 0.18659579753875732\n",
      "Train size: [400] hidden size: [29] trial: 45, train_loss: 1.780877, test loss: 1.092329, bias2: 0.906291663646698, variance: 0.1860368847846985\n",
      "Train size: [400] hidden size: [29] trial: 46, train_loss: 1.775635, test loss: 1.092895, bias2: 0.9069974422454834, variance: 0.18589724600315094\n",
      "Train size: [400] hidden size: [29] trial: 47, train_loss: 1.774192, test loss: 1.091921, bias2: 0.9058421850204468, variance: 0.18607863783836365\n",
      "Train size: [400] hidden size: [29] trial: 48, train_loss: 1.771880, test loss: 1.091534, bias2: 0.9064809679985046, variance: 0.1850532740354538\n",
      "Train size: [400] hidden size: [29] trial: 49, train_loss: 1.770558, test loss: 1.091614, bias2: 0.9058369994163513, variance: 0.1857765167951584\n",
      "##################################################\n",
      "Train size: [400] hidden size: [33] trial: 0, train_loss: 1.974927, test loss: 1.133330, bias2: 1.1333304643630981, variance: 9.731370154142382e-10\n",
      "Train size: [400] hidden size: [33] trial: 1, train_loss: 1.926732, test loss: 1.114990, bias2: 1.0254539251327515, variance: 0.08953585475683212\n",
      "Train size: [400] hidden size: [33] trial: 2, train_loss: 1.877539, test loss: 1.118419, bias2: 0.9962676763534546, variance: 0.12215173244476318\n",
      "Train size: [400] hidden size: [33] trial: 3, train_loss: 1.799155, test loss: 1.099217, bias2: 0.958672285079956, variance: 0.1405448615550995\n",
      "Train size: [400] hidden size: [33] trial: 4, train_loss: 1.789419, test loss: 1.095333, bias2: 0.9349275827407837, variance: 0.16040538251399994\n",
      "Train size: [400] hidden size: [33] trial: 5, train_loss: 1.827971, test loss: 1.099806, bias2: 0.9270974397659302, variance: 0.17270837724208832\n",
      "Train size: [400] hidden size: [33] trial: 6, train_loss: 1.801528, test loss: 1.102265, bias2: 0.9245515465736389, variance: 0.17771321535110474\n",
      "Train size: [400] hidden size: [33] trial: 7, train_loss: 1.792448, test loss: 1.102428, bias2: 0.9152969121932983, variance: 0.18713118135929108\n",
      "Train size: [400] hidden size: [33] trial: 8, train_loss: 1.784159, test loss: 1.105650, bias2: 0.9122473001480103, variance: 0.19340267777442932\n",
      "Train size: [400] hidden size: [33] trial: 9, train_loss: 1.786224, test loss: 1.103354, bias2: 0.9020938873291016, variance: 0.20125994086265564\n",
      "Train size: [400] hidden size: [33] trial: 10, train_loss: 1.799915, test loss: 1.111155, bias2: 0.9024155139923096, variance: 0.20873941481113434\n",
      "Train size: [400] hidden size: [33] trial: 11, train_loss: 1.787339, test loss: 1.109536, bias2: 0.9084368348121643, variance: 0.2010994553565979\n",
      "Train size: [400] hidden size: [33] trial: 12, train_loss: 1.786184, test loss: 1.106801, bias2: 0.9075455665588379, variance: 0.1992550790309906\n",
      "Train size: [400] hidden size: [33] trial: 13, train_loss: 1.779168, test loss: 1.105674, bias2: 0.9071580767631531, variance: 0.19851605594158173\n",
      "Train size: [400] hidden size: [33] trial: 14, train_loss: 1.764445, test loss: 1.104657, bias2: 0.9014238119125366, variance: 0.20323289930820465\n",
      "Train size: [400] hidden size: [33] trial: 15, train_loss: 1.760441, test loss: 1.100221, bias2: 0.8950755000114441, variance: 0.20514540374279022\n",
      "Train size: [400] hidden size: [33] trial: 16, train_loss: 1.764332, test loss: 1.100830, bias2: 0.8931611776351929, variance: 0.20766890048980713\n",
      "Train size: [400] hidden size: [33] trial: 17, train_loss: 1.761803, test loss: 1.101457, bias2: 0.8949665427207947, variance: 0.2064909189939499\n",
      "Train size: [400] hidden size: [33] trial: 18, train_loss: 1.773754, test loss: 1.104144, bias2: 0.8929486870765686, variance: 0.2111949324607849\n",
      "Train size: [400] hidden size: [33] trial: 19, train_loss: 1.768032, test loss: 1.101237, bias2: 0.8911005854606628, variance: 0.21013660728931427\n",
      "Train size: [400] hidden size: [33] trial: 20, train_loss: 1.764791, test loss: 1.099882, bias2: 0.8886040449142456, variance: 0.21127846837043762\n",
      "Train size: [400] hidden size: [33] trial: 21, train_loss: 1.764571, test loss: 1.097254, bias2: 0.8870976567268372, variance: 0.2101568579673767\n",
      "Train size: [400] hidden size: [33] trial: 22, train_loss: 1.761514, test loss: 1.097604, bias2: 0.886969804763794, variance: 0.21063436567783356\n",
      "Train size: [400] hidden size: [33] trial: 23, train_loss: 1.773218, test loss: 1.099419, bias2: 0.888238251209259, variance: 0.2111806422472\n",
      "Train size: [400] hidden size: [33] trial: 24, train_loss: 1.769218, test loss: 1.100248, bias2: 0.8900777101516724, variance: 0.21017052233219147\n",
      "Train size: [400] hidden size: [33] trial: 25, train_loss: 1.776900, test loss: 1.102618, bias2: 0.892737627029419, variance: 0.20987984538078308\n",
      "Train size: [400] hidden size: [33] trial: 26, train_loss: 1.772716, test loss: 1.107258, bias2: 0.8929962515830994, variance: 0.21426159143447876\n",
      "Train size: [400] hidden size: [33] trial: 27, train_loss: 1.776898, test loss: 1.109706, bias2: 0.8920524716377258, variance: 0.2176540493965149\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [33] trial: 28, train_loss: 1.776876, test loss: 1.107170, bias2: 0.8902997970581055, variance: 0.21686992049217224\n",
      "Train size: [400] hidden size: [33] trial: 29, train_loss: 1.780531, test loss: 1.104539, bias2: 0.8884462118148804, variance: 0.21609283983707428\n",
      "Train size: [400] hidden size: [33] trial: 30, train_loss: 1.779187, test loss: 1.105706, bias2: 0.8915073871612549, variance: 0.21419896185398102\n",
      "Train size: [400] hidden size: [33] trial: 31, train_loss: 1.776831, test loss: 1.104280, bias2: 0.8907828330993652, variance: 0.21349692344665527\n",
      "Train size: [400] hidden size: [33] trial: 32, train_loss: 1.770571, test loss: 1.105691, bias2: 0.8928768038749695, variance: 0.21281439065933228\n",
      "Train size: [400] hidden size: [33] trial: 33, train_loss: 1.773723, test loss: 1.105346, bias2: 0.8932361006736755, variance: 0.21210938692092896\n",
      "Train size: [400] hidden size: [33] trial: 34, train_loss: 1.774399, test loss: 1.104928, bias2: 0.8928207755088806, variance: 0.2121071219444275\n",
      "Train size: [400] hidden size: [33] trial: 35, train_loss: 1.773284, test loss: 1.106154, bias2: 0.893531322479248, variance: 0.21262308955192566\n",
      "Train size: [400] hidden size: [33] trial: 36, train_loss: 1.770862, test loss: 1.104867, bias2: 0.8919680118560791, variance: 0.21289898455142975\n",
      "Train size: [400] hidden size: [33] trial: 37, train_loss: 1.772483, test loss: 1.104672, bias2: 0.8932209014892578, variance: 0.2114509493112564\n",
      "Train size: [400] hidden size: [33] trial: 38, train_loss: 1.774569, test loss: 1.104594, bias2: 0.8936538100242615, variance: 0.21094030141830444\n",
      "Train size: [400] hidden size: [33] trial: 39, train_loss: 1.776865, test loss: 1.103045, bias2: 0.8940180540084839, variance: 0.20902667939662933\n",
      "Train size: [400] hidden size: [33] trial: 40, train_loss: 1.772920, test loss: 1.102276, bias2: 0.8931995630264282, variance: 0.20907685160636902\n",
      "Train size: [400] hidden size: [33] trial: 41, train_loss: 1.769000, test loss: 1.103575, bias2: 0.8925369381904602, variance: 0.21103815734386444\n",
      "Train size: [400] hidden size: [33] trial: 42, train_loss: 1.774023, test loss: 1.103972, bias2: 0.8943569660186768, variance: 0.20961523056030273\n",
      "Train size: [400] hidden size: [33] trial: 43, train_loss: 1.773011, test loss: 1.104577, bias2: 0.8955624103546143, variance: 0.20901426672935486\n",
      "Train size: [400] hidden size: [33] trial: 44, train_loss: 1.771848, test loss: 1.106390, bias2: 0.8941885232925415, variance: 0.21220098435878754\n",
      "Train size: [400] hidden size: [33] trial: 45, train_loss: 1.769256, test loss: 1.106363, bias2: 0.8953856229782104, variance: 0.2109769880771637\n",
      "Train size: [400] hidden size: [33] trial: 46, train_loss: 1.774990, test loss: 1.106644, bias2: 0.8957236409187317, variance: 0.21092039346694946\n",
      "Train size: [400] hidden size: [33] trial: 47, train_loss: 1.776122, test loss: 1.106433, bias2: 0.8948976397514343, variance: 0.2115355134010315\n",
      "Train size: [400] hidden size: [33] trial: 48, train_loss: 1.773907, test loss: 1.107938, bias2: 0.8947329521179199, variance: 0.21320533752441406\n",
      "Train size: [400] hidden size: [33] trial: 49, train_loss: 1.771296, test loss: 1.110316, bias2: 0.893366813659668, variance: 0.21694955229759216\n",
      "##################################################\n",
      "Train size: [400] hidden size: [38] trial: 0, train_loss: 2.153658, test loss: 1.137592, bias2: 1.1375924348831177, variance: 1.0704507280578923e-09\n",
      "Train size: [400] hidden size: [38] trial: 1, train_loss: 1.893932, test loss: 1.136186, bias2: 1.0101476907730103, variance: 0.1260378360748291\n",
      "Train size: [400] hidden size: [38] trial: 2, train_loss: 1.818698, test loss: 1.154318, bias2: 0.989385724067688, variance: 0.1649320125579834\n",
      "Train size: [400] hidden size: [38] trial: 3, train_loss: 1.821835, test loss: 1.162713, bias2: 0.9692521691322327, variance: 0.19346053898334503\n",
      "Train size: [400] hidden size: [38] trial: 4, train_loss: 1.807187, test loss: 1.155705, bias2: 0.962284505367279, variance: 0.19342069327831268\n",
      "Train size: [400] hidden size: [38] trial: 5, train_loss: 1.807120, test loss: 1.140337, bias2: 0.9426903128623962, variance: 0.19764666259288788\n",
      "Train size: [400] hidden size: [38] trial: 6, train_loss: 1.774002, test loss: 1.145616, bias2: 0.9336603283882141, variance: 0.2119554728269577\n",
      "Train size: [400] hidden size: [38] trial: 7, train_loss: 1.774539, test loss: 1.137953, bias2: 0.9325127601623535, variance: 0.20544053614139557\n",
      "Train size: [400] hidden size: [38] trial: 8, train_loss: 1.754705, test loss: 1.130487, bias2: 0.920669436454773, variance: 0.20981715619564056\n",
      "Train size: [400] hidden size: [38] trial: 9, train_loss: 1.744114, test loss: 1.140312, bias2: 0.9211485385894775, variance: 0.2191639095544815\n",
      "Train size: [400] hidden size: [38] trial: 10, train_loss: 1.729516, test loss: 1.139970, bias2: 0.9257472157478333, variance: 0.21422284841537476\n",
      "Train size: [400] hidden size: [38] trial: 11, train_loss: 1.725225, test loss: 1.142045, bias2: 0.9277276992797852, variance: 0.21431684494018555\n",
      "Train size: [400] hidden size: [38] trial: 12, train_loss: 1.721187, test loss: 1.142230, bias2: 0.9266952872276306, variance: 0.2155342847108841\n",
      "Train size: [400] hidden size: [38] trial: 13, train_loss: 1.719601, test loss: 1.142833, bias2: 0.9206042289733887, variance: 0.2222292274236679\n",
      "Train size: [400] hidden size: [38] trial: 14, train_loss: 1.734379, test loss: 1.141371, bias2: 0.9193586707115173, variance: 0.22201187908649445\n",
      "Train size: [400] hidden size: [38] trial: 15, train_loss: 1.741891, test loss: 1.136621, bias2: 0.9159505367279053, variance: 0.22067047655582428\n",
      "Train size: [400] hidden size: [38] trial: 16, train_loss: 1.742240, test loss: 1.136476, bias2: 0.9128667712211609, variance: 0.2236090451478958\n",
      "Train size: [400] hidden size: [38] trial: 17, train_loss: 1.744656, test loss: 1.135003, bias2: 0.9128287434577942, variance: 0.22217421233654022\n",
      "Train size: [400] hidden size: [38] trial: 18, train_loss: 1.750753, test loss: 1.137000, bias2: 0.9116856455802917, variance: 0.2253144234418869\n",
      "Train size: [400] hidden size: [38] trial: 19, train_loss: 1.761822, test loss: 1.134184, bias2: 0.9087706804275513, variance: 0.22541283071041107\n",
      "Train size: [400] hidden size: [38] trial: 20, train_loss: 1.760691, test loss: 1.136139, bias2: 0.9091452360153198, variance: 0.22699414193630219\n",
      "Train size: [400] hidden size: [38] trial: 21, train_loss: 1.761089, test loss: 1.137097, bias2: 0.9095696210861206, variance: 0.22752714157104492\n",
      "Train size: [400] hidden size: [38] trial: 22, train_loss: 1.750341, test loss: 1.134396, bias2: 0.9048848152160645, variance: 0.22951152920722961\n",
      "Train size: [400] hidden size: [38] trial: 23, train_loss: 1.754243, test loss: 1.134005, bias2: 0.904144823551178, variance: 0.2298598736524582\n",
      "Train size: [400] hidden size: [38] trial: 24, train_loss: 1.757984, test loss: 1.134292, bias2: 0.9047845005989075, variance: 0.22950725257396698\n",
      "Train size: [400] hidden size: [38] trial: 25, train_loss: 1.762595, test loss: 1.131638, bias2: 0.9067288637161255, variance: 0.2249089479446411\n",
      "Train size: [400] hidden size: [38] trial: 26, train_loss: 1.763060, test loss: 1.132276, bias2: 0.9058821201324463, variance: 0.22639347612857819\n",
      "Train size: [400] hidden size: [38] trial: 27, train_loss: 1.764118, test loss: 1.132255, bias2: 0.907261848449707, variance: 0.22499272227287292\n",
      "Train size: [400] hidden size: [38] trial: 28, train_loss: 1.761347, test loss: 1.131447, bias2: 0.9080628752708435, variance: 0.2233843207359314\n",
      "Train size: [400] hidden size: [38] trial: 29, train_loss: 1.765668, test loss: 1.133141, bias2: 0.9058971405029297, variance: 0.22724400460720062\n",
      "Train size: [400] hidden size: [38] trial: 30, train_loss: 1.763856, test loss: 1.133099, bias2: 0.9045988917350769, variance: 0.22849969565868378\n",
      "Train size: [400] hidden size: [38] trial: 31, train_loss: 1.766469, test loss: 1.134620, bias2: 0.9054650068283081, variance: 0.2291552871465683\n",
      "Train size: [400] hidden size: [38] trial: 32, train_loss: 1.759669, test loss: 1.135324, bias2: 0.9062532186508179, variance: 0.22907043993473053\n",
      "Train size: [400] hidden size: [38] trial: 33, train_loss: 1.757902, test loss: 1.134118, bias2: 0.9032100439071655, variance: 0.2309075891971588\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [38] trial: 34, train_loss: 1.761004, test loss: 1.133101, bias2: 0.9033804535865784, variance: 0.22972087562084198\n",
      "Train size: [400] hidden size: [38] trial: 35, train_loss: 1.756439, test loss: 1.131511, bias2: 0.9017601013183594, variance: 0.2297506034374237\n",
      "Train size: [400] hidden size: [38] trial: 36, train_loss: 1.756934, test loss: 1.131511, bias2: 0.9010517597198486, variance: 0.23045897483825684\n",
      "Train size: [400] hidden size: [38] trial: 37, train_loss: 1.758108, test loss: 1.132681, bias2: 0.9017865061759949, variance: 0.23089486360549927\n",
      "Train size: [400] hidden size: [38] trial: 38, train_loss: 1.758084, test loss: 1.132730, bias2: 0.9027853012084961, variance: 0.22994448244571686\n",
      "Train size: [400] hidden size: [38] trial: 39, train_loss: 1.761229, test loss: 1.134657, bias2: 0.904534637928009, variance: 0.23012273013591766\n",
      "Train size: [400] hidden size: [38] trial: 40, train_loss: 1.760265, test loss: 1.134767, bias2: 0.9038887619972229, variance: 0.2308778315782547\n",
      "Train size: [400] hidden size: [38] trial: 41, train_loss: 1.757450, test loss: 1.135012, bias2: 0.9040012359619141, variance: 0.2310110479593277\n",
      "Train size: [400] hidden size: [38] trial: 42, train_loss: 1.757673, test loss: 1.135801, bias2: 0.9046369791030884, variance: 0.23116423189640045\n",
      "Train size: [400] hidden size: [38] trial: 43, train_loss: 1.754468, test loss: 1.134478, bias2: 0.9039171934127808, variance: 0.2305610328912735\n",
      "Train size: [400] hidden size: [38] trial: 44, train_loss: 1.757852, test loss: 1.133322, bias2: 0.90386563539505, variance: 0.22945648431777954\n",
      "Train size: [400] hidden size: [38] trial: 45, train_loss: 1.755708, test loss: 1.132605, bias2: 0.9042190313339233, variance: 0.2283865213394165\n",
      "Train size: [400] hidden size: [38] trial: 46, train_loss: 1.754081, test loss: 1.131520, bias2: 0.9053946733474731, variance: 0.22612513601779938\n",
      "Train size: [400] hidden size: [38] trial: 47, train_loss: 1.752129, test loss: 1.130558, bias2: 0.9044924974441528, variance: 0.2260657548904419\n",
      "Train size: [400] hidden size: [38] trial: 48, train_loss: 1.752350, test loss: 1.129139, bias2: 0.9039621949195862, variance: 0.22517722845077515\n",
      "Train size: [400] hidden size: [38] trial: 49, train_loss: 1.753042, test loss: 1.130192, bias2: 0.9021155834197998, variance: 0.22807671129703522\n",
      "##################################################\n",
      "Train size: [400] hidden size: [44] trial: 0, train_loss: 1.855612, test loss: 1.157009, bias2: 1.1570091247558594, variance: 9.731370154142382e-10\n",
      "Train size: [400] hidden size: [44] trial: 1, train_loss: 1.895486, test loss: 1.135442, bias2: 0.9653432369232178, variance: 0.1700991541147232\n",
      "Train size: [400] hidden size: [44] trial: 2, train_loss: 1.796252, test loss: 1.148978, bias2: 0.9225980043411255, variance: 0.22637951374053955\n",
      "Train size: [400] hidden size: [44] trial: 3, train_loss: 1.803953, test loss: 1.172750, bias2: 0.9057879447937012, variance: 0.2669622600078583\n",
      "Train size: [400] hidden size: [44] trial: 4, train_loss: 1.762279, test loss: 1.161090, bias2: 0.88894122838974, variance: 0.2721490263938904\n",
      "Train size: [400] hidden size: [44] trial: 5, train_loss: 1.747549, test loss: 1.157545, bias2: 0.8808709383010864, variance: 0.27667438983917236\n",
      "Train size: [400] hidden size: [44] trial: 6, train_loss: 1.727761, test loss: 1.160838, bias2: 0.8737953901290894, variance: 0.28704285621643066\n",
      "Train size: [400] hidden size: [44] trial: 7, train_loss: 1.738830, test loss: 1.157194, bias2: 0.8673434257507324, variance: 0.2898510992527008\n",
      "Train size: [400] hidden size: [44] trial: 8, train_loss: 1.759973, test loss: 1.161768, bias2: 0.8705141544342041, variance: 0.2912537157535553\n",
      "Train size: [400] hidden size: [44] trial: 9, train_loss: 1.733109, test loss: 1.160430, bias2: 0.8761150240898132, variance: 0.284315288066864\n",
      "Train size: [400] hidden size: [44] trial: 10, train_loss: 1.727393, test loss: 1.163912, bias2: 0.8686805963516235, variance: 0.29523107409477234\n",
      "Train size: [400] hidden size: [44] trial: 11, train_loss: 1.729744, test loss: 1.161770, bias2: 0.8659064769744873, variance: 0.29586365818977356\n",
      "Train size: [400] hidden size: [44] trial: 12, train_loss: 1.724625, test loss: 1.160762, bias2: 0.8636586666107178, variance: 0.29710304737091064\n",
      "Train size: [400] hidden size: [44] trial: 13, train_loss: 1.714002, test loss: 1.163198, bias2: 0.8638746738433838, variance: 0.29932352900505066\n",
      "Train size: [400] hidden size: [44] trial: 14, train_loss: 1.714488, test loss: 1.159607, bias2: 0.8645220994949341, variance: 0.29508495330810547\n",
      "Train size: [400] hidden size: [44] trial: 15, train_loss: 1.720181, test loss: 1.160213, bias2: 0.8660664558410645, variance: 0.29414689540863037\n",
      "Train size: [400] hidden size: [44] trial: 16, train_loss: 1.719674, test loss: 1.155286, bias2: 0.8646496534347534, variance: 0.29063618183135986\n",
      "Train size: [400] hidden size: [44] trial: 17, train_loss: 1.710394, test loss: 1.152336, bias2: 0.8620317578315735, variance: 0.29030412435531616\n",
      "Train size: [400] hidden size: [44] trial: 18, train_loss: 1.702265, test loss: 1.153962, bias2: 0.8641159534454346, variance: 0.2898459732532501\n",
      "Train size: [400] hidden size: [44] trial: 19, train_loss: 1.694908, test loss: 1.152319, bias2: 0.8641773462295532, variance: 0.2881418764591217\n",
      "Train size: [400] hidden size: [44] trial: 20, train_loss: 1.700683, test loss: 1.151141, bias2: 0.8608999252319336, variance: 0.29024097323417664\n",
      "Train size: [400] hidden size: [44] trial: 21, train_loss: 1.710431, test loss: 1.147195, bias2: 0.8610036969184875, variance: 0.2861911654472351\n",
      "Train size: [400] hidden size: [44] trial: 22, train_loss: 1.707360, test loss: 1.149091, bias2: 0.8628052473068237, variance: 0.28628531098365784\n",
      "Train size: [400] hidden size: [44] trial: 23, train_loss: 1.711938, test loss: 1.151565, bias2: 0.8640605807304382, variance: 0.28750425577163696\n",
      "Train size: [400] hidden size: [44] trial: 24, train_loss: 1.707023, test loss: 1.156495, bias2: 0.8655096292495728, variance: 0.2909855544567108\n",
      "Train size: [400] hidden size: [44] trial: 25, train_loss: 1.705708, test loss: 1.157076, bias2: 0.8636661767959595, variance: 0.29341015219688416\n",
      "Train size: [400] hidden size: [44] trial: 26, train_loss: 1.696555, test loss: 1.154773, bias2: 0.8611130118370056, variance: 0.29366010427474976\n",
      "Train size: [400] hidden size: [44] trial: 27, train_loss: 1.691898, test loss: 1.152932, bias2: 0.8591482043266296, variance: 0.2937842011451721\n",
      "Train size: [400] hidden size: [44] trial: 28, train_loss: 1.691255, test loss: 1.156730, bias2: 0.8584713935852051, variance: 0.2982586622238159\n",
      "Train size: [400] hidden size: [44] trial: 29, train_loss: 1.693209, test loss: 1.155407, bias2: 0.8579842448234558, variance: 0.29742270708084106\n",
      "Train size: [400] hidden size: [44] trial: 30, train_loss: 1.693747, test loss: 1.155784, bias2: 0.8592767715454102, variance: 0.29650744795799255\n",
      "Train size: [400] hidden size: [44] trial: 31, train_loss: 1.691121, test loss: 1.156914, bias2: 0.8582718372344971, variance: 0.29864180088043213\n",
      "Train size: [400] hidden size: [44] trial: 32, train_loss: 1.689827, test loss: 1.158003, bias2: 0.8588322401046753, variance: 0.2991710603237152\n",
      "Train size: [400] hidden size: [44] trial: 33, train_loss: 1.685725, test loss: 1.156457, bias2: 0.8570736646652222, variance: 0.2993834316730499\n",
      "Train size: [400] hidden size: [44] trial: 34, train_loss: 1.687686, test loss: 1.155926, bias2: 0.8549410104751587, variance: 0.30098533630371094\n",
      "Train size: [400] hidden size: [44] trial: 35, train_loss: 1.689607, test loss: 1.154981, bias2: 0.8557398915290833, variance: 0.29924100637435913\n",
      "Train size: [400] hidden size: [44] trial: 36, train_loss: 1.688387, test loss: 1.156535, bias2: 0.8573487997055054, variance: 0.2991863191127777\n",
      "Train size: [400] hidden size: [44] trial: 37, train_loss: 1.686735, test loss: 1.155728, bias2: 0.853421688079834, variance: 0.3023059070110321\n",
      "Train size: [400] hidden size: [44] trial: 38, train_loss: 1.684695, test loss: 1.155843, bias2: 0.853812575340271, variance: 0.30203020572662354\n",
      "Train size: [400] hidden size: [44] trial: 39, train_loss: 1.682085, test loss: 1.153534, bias2: 0.8521015644073486, variance: 0.3014321029186249\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [44] trial: 40, train_loss: 1.685425, test loss: 1.151371, bias2: 0.8509425520896912, variance: 0.30042868852615356\n",
      "Train size: [400] hidden size: [44] trial: 41, train_loss: 1.688442, test loss: 1.152780, bias2: 0.8510324954986572, variance: 0.30174732208251953\n",
      "Train size: [400] hidden size: [44] trial: 42, train_loss: 1.687701, test loss: 1.150552, bias2: 0.8520292043685913, variance: 0.2985225021839142\n",
      "Train size: [400] hidden size: [44] trial: 43, train_loss: 1.689880, test loss: 1.149960, bias2: 0.8528539538383484, variance: 0.2971060872077942\n",
      "Train size: [400] hidden size: [44] trial: 44, train_loss: 1.687283, test loss: 1.148966, bias2: 0.8531256318092346, variance: 0.2958407998085022\n",
      "Train size: [400] hidden size: [44] trial: 45, train_loss: 1.686688, test loss: 1.149569, bias2: 0.8519578576087952, variance: 0.29761070013046265\n",
      "Train size: [400] hidden size: [44] trial: 46, train_loss: 1.687675, test loss: 1.148233, bias2: 0.8525961637496948, variance: 0.295636922121048\n",
      "Train size: [400] hidden size: [44] trial: 47, train_loss: 1.683618, test loss: 1.146825, bias2: 0.8512529134750366, variance: 0.2955721914768219\n",
      "Train size: [400] hidden size: [44] trial: 48, train_loss: 1.679413, test loss: 1.149744, bias2: 0.8507687449455261, variance: 0.29897528886795044\n",
      "Train size: [400] hidden size: [44] trial: 49, train_loss: 1.683563, test loss: 1.149382, bias2: 0.8504753708839417, variance: 0.2989066243171692\n",
      "##################################################\n",
      "Train size: [400] hidden size: [51] trial: 0, train_loss: 1.857943, test loss: 1.200029, bias2: 1.2000293731689453, variance: 1.3623918659888545e-09\n",
      "Train size: [400] hidden size: [51] trial: 1, train_loss: 1.676412, test loss: 1.200041, bias2: 0.9779475927352905, variance: 0.22209319472312927\n",
      "Train size: [400] hidden size: [51] trial: 2, train_loss: 1.612307, test loss: 1.168049, bias2: 0.920307993888855, variance: 0.2477407455444336\n",
      "Train size: [400] hidden size: [51] trial: 3, train_loss: 1.619399, test loss: 1.141236, bias2: 0.8687999248504639, variance: 0.272436261177063\n",
      "Train size: [400] hidden size: [51] trial: 4, train_loss: 1.619421, test loss: 1.141021, bias2: 0.8505245447158813, variance: 0.29049643874168396\n",
      "Train size: [400] hidden size: [51] trial: 5, train_loss: 1.648790, test loss: 1.140558, bias2: 0.8434659242630005, variance: 0.2970925271511078\n",
      "Train size: [400] hidden size: [51] trial: 6, train_loss: 1.670980, test loss: 1.149571, bias2: 0.8501704931259155, variance: 0.2994008958339691\n",
      "Train size: [400] hidden size: [51] trial: 7, train_loss: 1.679607, test loss: 1.169593, bias2: 0.8507874011993408, variance: 0.3188055455684662\n",
      "Train size: [400] hidden size: [51] trial: 8, train_loss: 1.681994, test loss: 1.172834, bias2: 0.8522128462791443, variance: 0.3206215500831604\n",
      "Train size: [400] hidden size: [51] trial: 9, train_loss: 1.677890, test loss: 1.163281, bias2: 0.8341951370239258, variance: 0.3290860950946808\n",
      "Train size: [400] hidden size: [51] trial: 10, train_loss: 1.669390, test loss: 1.157887, bias2: 0.8295565843582153, variance: 0.32833078503608704\n",
      "Train size: [400] hidden size: [51] trial: 11, train_loss: 1.660474, test loss: 1.154273, bias2: 0.8396677374839783, variance: 0.3146054148674011\n",
      "Train size: [400] hidden size: [51] trial: 12, train_loss: 1.673002, test loss: 1.160272, bias2: 0.8387953639030457, variance: 0.3214762806892395\n",
      "Train size: [400] hidden size: [51] trial: 13, train_loss: 1.674802, test loss: 1.161236, bias2: 0.8349961042404175, variance: 0.32624027132987976\n",
      "Train size: [400] hidden size: [51] trial: 14, train_loss: 1.682653, test loss: 1.153414, bias2: 0.8365782499313354, variance: 0.31683531403541565\n",
      "Train size: [400] hidden size: [51] trial: 15, train_loss: 1.672529, test loss: 1.147492, bias2: 0.8331411480903625, variance: 0.31435126066207886\n",
      "Train size: [400] hidden size: [51] trial: 16, train_loss: 1.672468, test loss: 1.156329, bias2: 0.8345978856086731, variance: 0.32173091173171997\n",
      "Train size: [400] hidden size: [51] trial: 17, train_loss: 1.672241, test loss: 1.156964, bias2: 0.8354476690292358, variance: 0.32151666283607483\n",
      "Train size: [400] hidden size: [51] trial: 18, train_loss: 1.666365, test loss: 1.153034, bias2: 0.8354873657226562, variance: 0.31754693388938904\n",
      "Train size: [400] hidden size: [51] trial: 19, train_loss: 1.668704, test loss: 1.158788, bias2: 0.838411271572113, variance: 0.3203762173652649\n",
      "Train size: [400] hidden size: [51] trial: 20, train_loss: 1.662024, test loss: 1.158039, bias2: 0.8373485803604126, variance: 0.3206906020641327\n",
      "Train size: [400] hidden size: [51] trial: 21, train_loss: 1.668364, test loss: 1.156037, bias2: 0.8352596163749695, variance: 0.3207772374153137\n",
      "Train size: [400] hidden size: [51] trial: 22, train_loss: 1.662983, test loss: 1.159462, bias2: 0.8339262008666992, variance: 0.32553526759147644\n",
      "Train size: [400] hidden size: [51] trial: 23, train_loss: 1.660016, test loss: 1.159680, bias2: 0.8335655927658081, variance: 0.32611432671546936\n",
      "Train size: [400] hidden size: [51] trial: 24, train_loss: 1.661052, test loss: 1.159364, bias2: 0.83597332239151, variance: 0.32339030504226685\n",
      "Train size: [400] hidden size: [51] trial: 25, train_loss: 1.661305, test loss: 1.161866, bias2: 0.8374015092849731, variance: 0.3244647979736328\n",
      "Train size: [400] hidden size: [51] trial: 26, train_loss: 1.660148, test loss: 1.162362, bias2: 0.8357386589050293, variance: 0.326623797416687\n",
      "Train size: [400] hidden size: [51] trial: 27, train_loss: 1.653782, test loss: 1.161190, bias2: 0.8364334106445312, variance: 0.3247568607330322\n",
      "Train size: [400] hidden size: [51] trial: 28, train_loss: 1.655945, test loss: 1.162150, bias2: 0.8371317386627197, variance: 0.32501843571662903\n",
      "Train size: [400] hidden size: [51] trial: 29, train_loss: 1.656266, test loss: 1.162183, bias2: 0.8381167054176331, variance: 0.3240665793418884\n",
      "Train size: [400] hidden size: [51] trial: 30, train_loss: 1.656968, test loss: 1.161769, bias2: 0.8402209281921387, variance: 0.3215477168560028\n",
      "Train size: [400] hidden size: [51] trial: 31, train_loss: 1.656815, test loss: 1.160714, bias2: 0.8417899012565613, variance: 0.3189240097999573\n",
      "Train size: [400] hidden size: [51] trial: 32, train_loss: 1.653640, test loss: 1.160007, bias2: 0.8416140079498291, variance: 0.31839266419410706\n",
      "Train size: [400] hidden size: [51] trial: 33, train_loss: 1.655454, test loss: 1.161731, bias2: 0.8429098129272461, variance: 0.31882110238075256\n",
      "Train size: [400] hidden size: [51] trial: 34, train_loss: 1.655784, test loss: 1.162133, bias2: 0.8452717065811157, variance: 0.3168611526489258\n",
      "Train size: [400] hidden size: [51] trial: 35, train_loss: 1.661910, test loss: 1.163073, bias2: 0.845702052116394, variance: 0.3173709809780121\n",
      "Train size: [400] hidden size: [51] trial: 36, train_loss: 1.664595, test loss: 1.162550, bias2: 0.8465737104415894, variance: 0.31597664952278137\n",
      "Train size: [400] hidden size: [51] trial: 37, train_loss: 1.660400, test loss: 1.161110, bias2: 0.8449069261550903, variance: 0.3162032663822174\n",
      "Train size: [400] hidden size: [51] trial: 38, train_loss: 1.659887, test loss: 1.160784, bias2: 0.8440948128700256, variance: 0.31668907403945923\n",
      "Train size: [400] hidden size: [51] trial: 39, train_loss: 1.661978, test loss: 1.162907, bias2: 0.8449206352233887, variance: 0.317986398935318\n",
      "Train size: [400] hidden size: [51] trial: 40, train_loss: 1.660579, test loss: 1.163854, bias2: 0.8450409173965454, variance: 0.31881317496299744\n",
      "Train size: [400] hidden size: [51] trial: 41, train_loss: 1.658750, test loss: 1.165479, bias2: 0.846088171005249, variance: 0.3193911015987396\n",
      "Train size: [400] hidden size: [51] trial: 42, train_loss: 1.658913, test loss: 1.164569, bias2: 0.8457121849060059, variance: 0.3188563585281372\n",
      "Train size: [400] hidden size: [51] trial: 43, train_loss: 1.655431, test loss: 1.165966, bias2: 0.8462046384811401, variance: 0.3197614848613739\n",
      "Train size: [400] hidden size: [51] trial: 44, train_loss: 1.654796, test loss: 1.166177, bias2: 0.8455612659454346, variance: 0.32061541080474854\n",
      "Train size: [400] hidden size: [51] trial: 45, train_loss: 1.653119, test loss: 1.167200, bias2: 0.8450047969818115, variance: 0.3221946954727173\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [51] trial: 46, train_loss: 1.653009, test loss: 1.166349, bias2: 0.8452012538909912, variance: 0.3211474120616913\n",
      "Train size: [400] hidden size: [51] trial: 47, train_loss: 1.649938, test loss: 1.165705, bias2: 0.8428529500961304, variance: 0.32285168766975403\n",
      "Train size: [400] hidden size: [51] trial: 48, train_loss: 1.649711, test loss: 1.165932, bias2: 0.841825544834137, variance: 0.3241061568260193\n",
      "Train size: [400] hidden size: [51] trial: 49, train_loss: 1.645066, test loss: 1.166713, bias2: 0.8420159816741943, variance: 0.32469674944877625\n",
      "##################################################\n",
      "Train size: [400] hidden size: [58] trial: 0, train_loss: 1.741705, test loss: 1.140476, bias2: 1.1404756307601929, variance: -2.1409014561157846e-09\n",
      "Train size: [400] hidden size: [58] trial: 1, train_loss: 1.753433, test loss: 1.114124, bias2: 0.9634265899658203, variance: 0.15069708228111267\n",
      "Train size: [400] hidden size: [58] trial: 2, train_loss: 1.699725, test loss: 1.144262, bias2: 0.9112032651901245, variance: 0.23305831849575043\n",
      "Train size: [400] hidden size: [58] trial: 3, train_loss: 1.671356, test loss: 1.161630, bias2: 0.8916194438934326, variance: 0.2700108289718628\n",
      "Train size: [400] hidden size: [58] trial: 4, train_loss: 1.680799, test loss: 1.169162, bias2: 0.8817757368087769, variance: 0.28738608956336975\n",
      "Train size: [400] hidden size: [58] trial: 5, train_loss: 1.690013, test loss: 1.167061, bias2: 0.8548330664634705, variance: 0.31222766637802124\n",
      "Train size: [400] hidden size: [58] trial: 6, train_loss: 1.673704, test loss: 1.167494, bias2: 0.8463239669799805, variance: 0.32116982340812683\n",
      "Train size: [400] hidden size: [58] trial: 7, train_loss: 1.654274, test loss: 1.179003, bias2: 0.849040150642395, variance: 0.3299630582332611\n",
      "Train size: [400] hidden size: [58] trial: 8, train_loss: 1.649802, test loss: 1.181800, bias2: 0.8377360105514526, variance: 0.3440643846988678\n",
      "Train size: [400] hidden size: [58] trial: 9, train_loss: 1.653249, test loss: 1.185617, bias2: 0.8355085253715515, variance: 0.3501080870628357\n",
      "Train size: [400] hidden size: [58] trial: 10, train_loss: 1.663324, test loss: 1.188583, bias2: 0.8357048034667969, variance: 0.3528781235218048\n",
      "Train size: [400] hidden size: [58] trial: 11, train_loss: 1.651604, test loss: 1.197157, bias2: 0.8423968553543091, variance: 0.3547600507736206\n",
      "Train size: [400] hidden size: [58] trial: 12, train_loss: 1.653384, test loss: 1.184628, bias2: 0.8324246406555176, variance: 0.35220304131507874\n",
      "Train size: [400] hidden size: [58] trial: 13, train_loss: 1.647873, test loss: 1.189302, bias2: 0.8315656185150146, variance: 0.35773614048957825\n",
      "Train size: [400] hidden size: [58] trial: 14, train_loss: 1.643040, test loss: 1.190776, bias2: 0.8256064653396606, variance: 0.36516904830932617\n",
      "Train size: [400] hidden size: [58] trial: 15, train_loss: 1.642407, test loss: 1.188240, bias2: 0.8201941251754761, variance: 0.3680454194545746\n",
      "Train size: [400] hidden size: [58] trial: 16, train_loss: 1.650025, test loss: 1.186550, bias2: 0.8135659694671631, variance: 0.37298426032066345\n",
      "Train size: [400] hidden size: [58] trial: 17, train_loss: 1.654918, test loss: 1.186111, bias2: 0.8164564371109009, variance: 0.36965444684028625\n",
      "Train size: [400] hidden size: [58] trial: 18, train_loss: 1.658134, test loss: 1.183606, bias2: 0.8152673244476318, variance: 0.3683392107486725\n",
      "Train size: [400] hidden size: [58] trial: 19, train_loss: 1.656846, test loss: 1.184499, bias2: 0.8131718635559082, variance: 0.37132728099823\n",
      "Train size: [400] hidden size: [58] trial: 20, train_loss: 1.647094, test loss: 1.191169, bias2: 0.81319260597229, variance: 0.37797650694847107\n",
      "Train size: [400] hidden size: [58] trial: 21, train_loss: 1.658783, test loss: 1.189465, bias2: 0.8139406442642212, variance: 0.3755249083042145\n",
      "Train size: [400] hidden size: [58] trial: 22, train_loss: 1.664438, test loss: 1.191301, bias2: 0.8136478662490845, variance: 0.37765300273895264\n",
      "Train size: [400] hidden size: [58] trial: 23, train_loss: 1.662145, test loss: 1.192574, bias2: 0.8129190802574158, variance: 0.3796551823616028\n",
      "Train size: [400] hidden size: [58] trial: 24, train_loss: 1.662815, test loss: 1.194959, bias2: 0.8146959543228149, variance: 0.38026344776153564\n",
      "Train size: [400] hidden size: [58] trial: 25, train_loss: 1.661676, test loss: 1.194488, bias2: 0.8134778738021851, variance: 0.38101038336753845\n",
      "Train size: [400] hidden size: [58] trial: 26, train_loss: 1.658923, test loss: 1.191227, bias2: 0.8133901953697205, variance: 0.3778366446495056\n",
      "Train size: [400] hidden size: [58] trial: 27, train_loss: 1.654917, test loss: 1.191102, bias2: 0.8112505674362183, variance: 0.3798515796661377\n",
      "Train size: [400] hidden size: [58] trial: 28, train_loss: 1.652035, test loss: 1.192100, bias2: 0.8079361915588379, variance: 0.38416406512260437\n",
      "Train size: [400] hidden size: [58] trial: 29, train_loss: 1.648978, test loss: 1.197926, bias2: 0.8077490925788879, variance: 0.3901767134666443\n",
      "Train size: [400] hidden size: [58] trial: 30, train_loss: 1.646371, test loss: 1.199106, bias2: 0.8080187439918518, variance: 0.3910868763923645\n",
      "Train size: [400] hidden size: [58] trial: 31, train_loss: 1.648368, test loss: 1.198934, bias2: 0.8105868101119995, variance: 0.3883475363254547\n",
      "Train size: [400] hidden size: [58] trial: 32, train_loss: 1.647912, test loss: 1.200770, bias2: 0.8087427020072937, variance: 0.3920270800590515\n",
      "Train size: [400] hidden size: [58] trial: 33, train_loss: 1.645334, test loss: 1.202035, bias2: 0.808518648147583, variance: 0.39351677894592285\n",
      "Train size: [400] hidden size: [58] trial: 34, train_loss: 1.645564, test loss: 1.203703, bias2: 0.808458685874939, variance: 0.395244836807251\n",
      "Train size: [400] hidden size: [58] trial: 35, train_loss: 1.643238, test loss: 1.203379, bias2: 0.8078613877296448, variance: 0.39551788568496704\n",
      "Train size: [400] hidden size: [58] trial: 36, train_loss: 1.648881, test loss: 1.201956, bias2: 0.8079834580421448, variance: 0.39397233724594116\n",
      "Train size: [400] hidden size: [58] trial: 37, train_loss: 1.649703, test loss: 1.200815, bias2: 0.80726158618927, variance: 0.39355385303497314\n",
      "Train size: [400] hidden size: [58] trial: 38, train_loss: 1.652642, test loss: 1.202315, bias2: 0.8080482482910156, variance: 0.3942665755748749\n",
      "Train size: [400] hidden size: [58] trial: 39, train_loss: 1.650257, test loss: 1.200650, bias2: 0.8097482919692993, variance: 0.39090144634246826\n",
      "Train size: [400] hidden size: [58] trial: 40, train_loss: 1.652055, test loss: 1.198284, bias2: 0.8082871437072754, variance: 0.38999664783477783\n",
      "Train size: [400] hidden size: [58] trial: 41, train_loss: 1.653207, test loss: 1.198256, bias2: 0.8060483932495117, variance: 0.39220747351646423\n",
      "Train size: [400] hidden size: [58] trial: 42, train_loss: 1.651485, test loss: 1.199322, bias2: 0.8066785335540771, variance: 0.39264336228370667\n",
      "Train size: [400] hidden size: [58] trial: 43, train_loss: 1.650174, test loss: 1.198140, bias2: 0.8051258325576782, variance: 0.3930138349533081\n",
      "Train size: [400] hidden size: [58] trial: 44, train_loss: 1.652504, test loss: 1.198115, bias2: 0.806145191192627, variance: 0.39197012782096863\n",
      "Train size: [400] hidden size: [58] trial: 45, train_loss: 1.652603, test loss: 1.197574, bias2: 0.8083440661430359, variance: 0.3892297148704529\n",
      "Train size: [400] hidden size: [58] trial: 46, train_loss: 1.646483, test loss: 1.195880, bias2: 0.8079943656921387, variance: 0.3878856897354126\n",
      "Train size: [400] hidden size: [58] trial: 47, train_loss: 1.652407, test loss: 1.195911, bias2: 0.810188889503479, variance: 0.3857226073741913\n",
      "Train size: [400] hidden size: [58] trial: 48, train_loss: 1.651087, test loss: 1.195375, bias2: 0.8097962737083435, variance: 0.38557833433151245\n",
      "Train size: [400] hidden size: [58] trial: 49, train_loss: 1.650733, test loss: 1.194518, bias2: 0.8097518086433411, variance: 0.3847658038139343\n",
      "##################################################\n",
      "Train size: [400] hidden size: [67] trial: 0, train_loss: 1.662327, test loss: 1.223536, bias2: 1.2235356569290161, variance: -3.8925479506346505e-10\n",
      "Train size: [400] hidden size: [67] trial: 1, train_loss: 1.694846, test loss: 1.231810, bias2: 1.0077139139175415, variance: 0.2240956723690033\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [67] trial: 2, train_loss: 1.708260, test loss: 1.210954, bias2: 0.9206035137176514, variance: 0.2903508245944977\n",
      "Train size: [400] hidden size: [67] trial: 3, train_loss: 1.682777, test loss: 1.215346, bias2: 0.9032639861106873, variance: 0.3120822310447693\n",
      "Train size: [400] hidden size: [67] trial: 4, train_loss: 1.672856, test loss: 1.245632, bias2: 0.8842436075210571, variance: 0.3613879382610321\n",
      "Train size: [400] hidden size: [67] trial: 5, train_loss: 1.639261, test loss: 1.239313, bias2: 0.8729450702667236, variance: 0.3663676083087921\n",
      "Train size: [400] hidden size: [67] trial: 6, train_loss: 1.604264, test loss: 1.232830, bias2: 0.8559252023696899, variance: 0.37690484523773193\n",
      "Train size: [400] hidden size: [67] trial: 7, train_loss: 1.609003, test loss: 1.229522, bias2: 0.8485839366912842, variance: 0.3809375762939453\n",
      "Train size: [400] hidden size: [67] trial: 8, train_loss: 1.593861, test loss: 1.217105, bias2: 0.8377559185028076, variance: 0.3793487548828125\n",
      "Train size: [400] hidden size: [67] trial: 9, train_loss: 1.603305, test loss: 1.210131, bias2: 0.8322639465332031, variance: 0.3778672516345978\n",
      "Train size: [400] hidden size: [67] trial: 10, train_loss: 1.590239, test loss: 1.203536, bias2: 0.8243825435638428, variance: 0.3791534900665283\n",
      "Train size: [400] hidden size: [67] trial: 11, train_loss: 1.589144, test loss: 1.201061, bias2: 0.8251947164535522, variance: 0.3758666217327118\n",
      "Train size: [400] hidden size: [67] trial: 12, train_loss: 1.588830, test loss: 1.200087, bias2: 0.8241057395935059, variance: 0.3759814500808716\n",
      "Train size: [400] hidden size: [67] trial: 13, train_loss: 1.587543, test loss: 1.204831, bias2: 0.8264274597167969, variance: 0.3784036338329315\n",
      "Train size: [400] hidden size: [67] trial: 14, train_loss: 1.588654, test loss: 1.205338, bias2: 0.8269398212432861, variance: 0.3783981502056122\n",
      "Train size: [400] hidden size: [67] trial: 15, train_loss: 1.580646, test loss: 1.201287, bias2: 0.8248403072357178, variance: 0.3764462172985077\n",
      "Train size: [400] hidden size: [67] trial: 16, train_loss: 1.571816, test loss: 1.201919, bias2: 0.8237780332565308, variance: 0.37814095616340637\n",
      "Train size: [400] hidden size: [67] trial: 17, train_loss: 1.570223, test loss: 1.201528, bias2: 0.825725257396698, variance: 0.37580233812332153\n",
      "Train size: [400] hidden size: [67] trial: 18, train_loss: 1.571840, test loss: 1.207885, bias2: 0.8213560581207275, variance: 0.3865292966365814\n",
      "Train size: [400] hidden size: [67] trial: 19, train_loss: 1.570294, test loss: 1.211664, bias2: 0.8247542381286621, variance: 0.3869093656539917\n",
      "Train size: [400] hidden size: [67] trial: 20, train_loss: 1.570129, test loss: 1.210571, bias2: 0.8201920390129089, variance: 0.3903791308403015\n",
      "Train size: [400] hidden size: [67] trial: 21, train_loss: 1.577198, test loss: 1.207851, bias2: 0.8165011405944824, variance: 0.391350120306015\n",
      "Train size: [400] hidden size: [67] trial: 22, train_loss: 1.573301, test loss: 1.209730, bias2: 0.819307804107666, variance: 0.3904224634170532\n",
      "Train size: [400] hidden size: [67] trial: 23, train_loss: 1.584379, test loss: 1.206679, bias2: 0.8175011873245239, variance: 0.3891775608062744\n",
      "Train size: [400] hidden size: [67] trial: 24, train_loss: 1.581821, test loss: 1.206273, bias2: 0.8156729936599731, variance: 0.3906001150608063\n",
      "Train size: [400] hidden size: [67] trial: 25, train_loss: 1.578855, test loss: 1.205465, bias2: 0.8168757557868958, variance: 0.3885888457298279\n",
      "Train size: [400] hidden size: [67] trial: 26, train_loss: 1.581034, test loss: 1.207831, bias2: 0.8135632276535034, variance: 0.39426741003990173\n",
      "Train size: [400] hidden size: [67] trial: 27, train_loss: 1.586128, test loss: 1.206636, bias2: 0.8152557015419006, variance: 0.3913804888725281\n",
      "Train size: [400] hidden size: [67] trial: 28, train_loss: 1.587765, test loss: 1.208728, bias2: 0.815741240978241, variance: 0.39298683404922485\n",
      "Train size: [400] hidden size: [67] trial: 29, train_loss: 1.582242, test loss: 1.210886, bias2: 0.8130322694778442, variance: 0.39785340428352356\n",
      "Train size: [400] hidden size: [67] trial: 30, train_loss: 1.585670, test loss: 1.210859, bias2: 0.8107136487960815, variance: 0.4001455008983612\n",
      "Train size: [400] hidden size: [67] trial: 31, train_loss: 1.585314, test loss: 1.209410, bias2: 0.8115386962890625, variance: 0.3978711664676666\n",
      "Train size: [400] hidden size: [67] trial: 32, train_loss: 1.585044, test loss: 1.210993, bias2: 0.8145301938056946, variance: 0.396462619304657\n",
      "Train size: [400] hidden size: [67] trial: 33, train_loss: 1.581487, test loss: 1.210658, bias2: 0.8149402141571045, variance: 0.3957175314426422\n",
      "Train size: [400] hidden size: [67] trial: 34, train_loss: 1.577915, test loss: 1.212504, bias2: 0.8136351704597473, variance: 0.3988686203956604\n",
      "Train size: [400] hidden size: [67] trial: 35, train_loss: 1.578447, test loss: 1.209319, bias2: 0.8117678165435791, variance: 0.39755114912986755\n",
      "Train size: [400] hidden size: [67] trial: 36, train_loss: 1.583286, test loss: 1.211352, bias2: 0.812472939491272, variance: 0.3988795280456543\n",
      "Train size: [400] hidden size: [67] trial: 37, train_loss: 1.582165, test loss: 1.207871, bias2: 0.8138195872306824, variance: 0.39405184984207153\n",
      "Train size: [400] hidden size: [67] trial: 38, train_loss: 1.582235, test loss: 1.211111, bias2: 0.8119474649429321, variance: 0.39916369318962097\n",
      "Train size: [400] hidden size: [67] trial: 39, train_loss: 1.582937, test loss: 1.211954, bias2: 0.8096252679824829, variance: 0.402328759431839\n",
      "Train size: [400] hidden size: [67] trial: 40, train_loss: 1.584545, test loss: 1.210555, bias2: 0.8101588487625122, variance: 0.4003959000110626\n",
      "Train size: [400] hidden size: [67] trial: 41, train_loss: 1.589950, test loss: 1.211779, bias2: 0.8107052445411682, variance: 0.4010741114616394\n",
      "Train size: [400] hidden size: [67] trial: 42, train_loss: 1.591307, test loss: 1.213821, bias2: 0.811852216720581, variance: 0.4019683301448822\n",
      "Train size: [400] hidden size: [67] trial: 43, train_loss: 1.596991, test loss: 1.213574, bias2: 0.8129189014434814, variance: 0.4006553888320923\n",
      "Train size: [400] hidden size: [67] trial: 44, train_loss: 1.598612, test loss: 1.215512, bias2: 0.8145332336425781, variance: 0.40097835659980774\n",
      "Train size: [400] hidden size: [67] trial: 45, train_loss: 1.596621, test loss: 1.216768, bias2: 0.8132165670394897, variance: 0.4035514295101166\n",
      "Train size: [400] hidden size: [67] trial: 46, train_loss: 1.600298, test loss: 1.216664, bias2: 0.8136054277420044, variance: 0.40305840969085693\n",
      "Train size: [400] hidden size: [67] trial: 47, train_loss: 1.599584, test loss: 1.216296, bias2: 0.8133325576782227, variance: 0.4029635488986969\n",
      "Train size: [400] hidden size: [67] trial: 48, train_loss: 1.600326, test loss: 1.216695, bias2: 0.8131296634674072, variance: 0.40356525778770447\n",
      "Train size: [400] hidden size: [67] trial: 49, train_loss: 1.602743, test loss: 1.217800, bias2: 0.8109935522079468, variance: 0.40680620074272156\n",
      "##################################################\n",
      "Train size: [400] hidden size: [77] trial: 0, train_loss: 1.632204, test loss: 1.139850, bias2: 1.1398502588272095, variance: -7.785095901269301e-10\n",
      "Train size: [400] hidden size: [77] trial: 1, train_loss: 1.579746, test loss: 1.200902, bias2: 0.9612767696380615, variance: 0.23962554335594177\n",
      "Train size: [400] hidden size: [77] trial: 2, train_loss: 1.547097, test loss: 1.229876, bias2: 0.8990563154220581, variance: 0.3308199346065521\n",
      "Train size: [400] hidden size: [77] trial: 3, train_loss: 1.503730, test loss: 1.231939, bias2: 0.8609673380851746, variance: 0.3709719777107239\n",
      "Train size: [400] hidden size: [77] trial: 4, train_loss: 1.515986, test loss: 1.209837, bias2: 0.8237788677215576, variance: 0.38605859875679016\n",
      "Train size: [400] hidden size: [77] trial: 5, train_loss: 1.540271, test loss: 1.238313, bias2: 0.8290693759918213, variance: 0.4092436730861664\n",
      "Train size: [400] hidden size: [77] trial: 6, train_loss: 1.544719, test loss: 1.244054, bias2: 0.818882405757904, variance: 0.42517155408859253\n",
      "Train size: [400] hidden size: [77] trial: 7, train_loss: 1.525031, test loss: 1.253378, bias2: 0.8131144046783447, variance: 0.4402635395526886\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [77] trial: 8, train_loss: 1.533654, test loss: 1.253233, bias2: 0.8109139204025269, variance: 0.4423189163208008\n",
      "Train size: [400] hidden size: [77] trial: 9, train_loss: 1.505025, test loss: 1.255682, bias2: 0.7994312047958374, variance: 0.45625102519989014\n",
      "Train size: [400] hidden size: [77] trial: 10, train_loss: 1.512015, test loss: 1.250915, bias2: 0.7943611145019531, variance: 0.45655420422554016\n",
      "Train size: [400] hidden size: [77] trial: 11, train_loss: 1.498192, test loss: 1.254920, bias2: 0.7992023825645447, variance: 0.45571738481521606\n",
      "Train size: [400] hidden size: [77] trial: 12, train_loss: 1.499052, test loss: 1.253081, bias2: 0.7979516983032227, variance: 0.45512938499450684\n",
      "Train size: [400] hidden size: [77] trial: 13, train_loss: 1.499010, test loss: 1.251347, bias2: 0.7973570823669434, variance: 0.45399031043052673\n",
      "Train size: [400] hidden size: [77] trial: 14, train_loss: 1.499654, test loss: 1.244966, bias2: 0.7934814095497131, variance: 0.4514846205711365\n",
      "Train size: [400] hidden size: [77] trial: 15, train_loss: 1.498152, test loss: 1.245595, bias2: 0.7912352085113525, variance: 0.4543593227863312\n",
      "Train size: [400] hidden size: [77] trial: 16, train_loss: 1.495182, test loss: 1.244694, bias2: 0.7915279865264893, variance: 0.4531664550304413\n",
      "Train size: [400] hidden size: [77] trial: 17, train_loss: 1.490255, test loss: 1.247597, bias2: 0.7932009100914001, variance: 0.4543958306312561\n",
      "Train size: [400] hidden size: [77] trial: 18, train_loss: 1.485829, test loss: 1.243229, bias2: 0.7886334657669067, variance: 0.45459508895874023\n",
      "Train size: [400] hidden size: [77] trial: 19, train_loss: 1.490533, test loss: 1.239897, bias2: 0.7881330251693726, variance: 0.4517643451690674\n",
      "Train size: [400] hidden size: [77] trial: 20, train_loss: 1.484847, test loss: 1.238232, bias2: 0.789199948310852, variance: 0.4490325152873993\n",
      "Train size: [400] hidden size: [77] trial: 21, train_loss: 1.492482, test loss: 1.236388, bias2: 0.7876383066177368, variance: 0.4487494230270386\n",
      "Train size: [400] hidden size: [77] trial: 22, train_loss: 1.502134, test loss: 1.240769, bias2: 0.7865052819252014, variance: 0.45426350831985474\n",
      "Train size: [400] hidden size: [77] trial: 23, train_loss: 1.504880, test loss: 1.242971, bias2: 0.7839992642402649, variance: 0.45897191762924194\n",
      "Train size: [400] hidden size: [77] trial: 24, train_loss: 1.506057, test loss: 1.239662, bias2: 0.781076192855835, variance: 0.4585854709148407\n",
      "Train size: [400] hidden size: [77] trial: 25, train_loss: 1.504807, test loss: 1.236384, bias2: 0.7826889157295227, variance: 0.4536955952644348\n",
      "Train size: [400] hidden size: [77] trial: 26, train_loss: 1.499113, test loss: 1.240998, bias2: 0.7849751114845276, variance: 0.4560226798057556\n",
      "Train size: [400] hidden size: [77] trial: 27, train_loss: 1.489494, test loss: 1.236940, bias2: 0.7849215865135193, variance: 0.4520185589790344\n",
      "Train size: [400] hidden size: [77] trial: 28, train_loss: 1.491878, test loss: 1.236235, bias2: 0.7876135110855103, variance: 0.44862139225006104\n",
      "Train size: [400] hidden size: [77] trial: 29, train_loss: 1.496522, test loss: 1.239074, bias2: 0.7875016927719116, variance: 0.4515722095966339\n",
      "Train size: [400] hidden size: [77] trial: 30, train_loss: 1.497227, test loss: 1.238926, bias2: 0.7876728773117065, variance: 0.45125317573547363\n",
      "Train size: [400] hidden size: [77] trial: 31, train_loss: 1.492870, test loss: 1.239892, bias2: 0.7865525484085083, variance: 0.453339546918869\n",
      "Train size: [400] hidden size: [77] trial: 32, train_loss: 1.494297, test loss: 1.236421, bias2: 0.7841512560844421, variance: 0.4522692561149597\n",
      "Train size: [400] hidden size: [77] trial: 33, train_loss: 1.492273, test loss: 1.233669, bias2: 0.779885470867157, variance: 0.45378345251083374\n",
      "Train size: [400] hidden size: [77] trial: 34, train_loss: 1.491139, test loss: 1.236888, bias2: 0.7814048528671265, variance: 0.45548272132873535\n",
      "Train size: [400] hidden size: [77] trial: 35, train_loss: 1.487780, test loss: 1.238633, bias2: 0.7820634841918945, variance: 0.45656904578208923\n",
      "Train size: [400] hidden size: [77] trial: 36, train_loss: 1.492866, test loss: 1.237117, bias2: 0.7801597714424133, variance: 0.45695775747299194\n",
      "Train size: [400] hidden size: [77] trial: 37, train_loss: 1.488375, test loss: 1.235901, bias2: 0.7792483568191528, variance: 0.4566531181335449\n",
      "Train size: [400] hidden size: [77] trial: 38, train_loss: 1.490948, test loss: 1.236030, bias2: 0.7795162200927734, variance: 0.4565141499042511\n",
      "Train size: [400] hidden size: [77] trial: 39, train_loss: 1.489090, test loss: 1.234362, bias2: 0.7795827388763428, variance: 0.4547788202762604\n",
      "Train size: [400] hidden size: [77] trial: 40, train_loss: 1.485957, test loss: 1.235371, bias2: 0.7775090932846069, variance: 0.4578620195388794\n",
      "Train size: [400] hidden size: [77] trial: 41, train_loss: 1.487681, test loss: 1.235421, bias2: 0.7775843739509583, variance: 0.4578363299369812\n",
      "Train size: [400] hidden size: [77] trial: 42, train_loss: 1.485230, test loss: 1.234299, bias2: 0.7740066051483154, variance: 0.4602926969528198\n",
      "Train size: [400] hidden size: [77] trial: 43, train_loss: 1.487925, test loss: 1.235438, bias2: 0.7731071710586548, variance: 0.4623306691646576\n",
      "Train size: [400] hidden size: [77] trial: 44, train_loss: 1.485572, test loss: 1.235093, bias2: 0.7699376344680786, variance: 0.465155690908432\n",
      "Train size: [400] hidden size: [77] trial: 45, train_loss: 1.482729, test loss: 1.237791, bias2: 0.7708569765090942, variance: 0.4669336974620819\n",
      "Train size: [400] hidden size: [77] trial: 46, train_loss: 1.486912, test loss: 1.235838, bias2: 0.7708715200424194, variance: 0.4649660587310791\n",
      "Train size: [400] hidden size: [77] trial: 47, train_loss: 1.479314, test loss: 1.235432, bias2: 0.7693626880645752, variance: 0.4660697281360626\n",
      "Train size: [400] hidden size: [77] trial: 48, train_loss: 1.482564, test loss: 1.233991, bias2: 0.7702279090881348, variance: 0.4637626111507416\n",
      "Train size: [400] hidden size: [77] trial: 49, train_loss: 1.485588, test loss: 1.232236, bias2: 0.7698072195053101, variance: 0.46242842078208923\n",
      "##################################################\n",
      "Train size: [400] hidden size: [89] trial: 0, train_loss: 1.538901, test loss: 1.338688, bias2: 1.3386878967285156, variance: 7.785095901269301e-10\n",
      "Train size: [400] hidden size: [89] trial: 1, train_loss: 1.487451, test loss: 1.340177, bias2: 1.0587525367736816, variance: 0.2814246416091919\n",
      "Train size: [400] hidden size: [89] trial: 2, train_loss: 1.472437, test loss: 1.288793, bias2: 0.9272323846817017, variance: 0.3615601062774658\n",
      "Train size: [400] hidden size: [89] trial: 3, train_loss: 1.421030, test loss: 1.320630, bias2: 0.9062294960021973, variance: 0.41440072655677795\n",
      "Train size: [400] hidden size: [89] trial: 4, train_loss: 1.429825, test loss: 1.314631, bias2: 0.8560380935668945, variance: 0.45859289169311523\n",
      "Train size: [400] hidden size: [89] trial: 5, train_loss: 1.434463, test loss: 1.305071, bias2: 0.8445814251899719, variance: 0.4604896903038025\n",
      "Train size: [400] hidden size: [89] trial: 6, train_loss: 1.432535, test loss: 1.292560, bias2: 0.8298795223236084, variance: 0.4626799523830414\n",
      "Train size: [400] hidden size: [89] trial: 7, train_loss: 1.411900, test loss: 1.272553, bias2: 0.8147990703582764, variance: 0.4577536880970001\n",
      "Train size: [400] hidden size: [89] trial: 8, train_loss: 1.408281, test loss: 1.272265, bias2: 0.8174799680709839, variance: 0.45478472113609314\n",
      "Train size: [400] hidden size: [89] trial: 9, train_loss: 1.404916, test loss: 1.266381, bias2: 0.8024039268493652, variance: 0.46397721767425537\n",
      "Train size: [400] hidden size: [89] trial: 10, train_loss: 1.438994, test loss: 1.265014, bias2: 0.7998709678649902, variance: 0.46514347195625305\n",
      "Train size: [400] hidden size: [89] trial: 11, train_loss: 1.438622, test loss: 1.257658, bias2: 0.7923154830932617, variance: 0.4653424024581909\n",
      "Train size: [400] hidden size: [89] trial: 12, train_loss: 1.423528, test loss: 1.255693, bias2: 0.7836620807647705, variance: 0.47203120589256287\n",
      "Train size: [400] hidden size: [89] trial: 13, train_loss: 1.432617, test loss: 1.261483, bias2: 0.7786744832992554, variance: 0.48280811309814453\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [89] trial: 14, train_loss: 1.437592, test loss: 1.265379, bias2: 0.7757608294487, variance: 0.48961836099624634\n",
      "Train size: [400] hidden size: [89] trial: 15, train_loss: 1.435322, test loss: 1.266644, bias2: 0.7740836143493652, variance: 0.4925605058670044\n",
      "Train size: [400] hidden size: [89] trial: 16, train_loss: 1.440134, test loss: 1.266984, bias2: 0.7708311080932617, variance: 0.49615320563316345\n",
      "Train size: [400] hidden size: [89] trial: 17, train_loss: 1.435887, test loss: 1.273751, bias2: 0.7744721174240112, variance: 0.49927935004234314\n",
      "Train size: [400] hidden size: [89] trial: 18, train_loss: 1.443808, test loss: 1.268881, bias2: 0.7748913764953613, variance: 0.4939897060394287\n",
      "Train size: [400] hidden size: [89] trial: 19, train_loss: 1.446684, test loss: 1.262296, bias2: 0.7684204578399658, variance: 0.4938758313655853\n",
      "Train size: [400] hidden size: [89] trial: 20, train_loss: 1.446054, test loss: 1.266003, bias2: 0.7727447748184204, variance: 0.4932583272457123\n",
      "Train size: [400] hidden size: [89] trial: 21, train_loss: 1.443730, test loss: 1.264122, bias2: 0.765394926071167, variance: 0.4987275302410126\n",
      "Train size: [400] hidden size: [89] trial: 22, train_loss: 1.457211, test loss: 1.265422, bias2: 0.7607661485671997, variance: 0.5046558380126953\n",
      "Train size: [400] hidden size: [89] trial: 23, train_loss: 1.462608, test loss: 1.264460, bias2: 0.7582061886787415, variance: 0.5062533020973206\n",
      "Train size: [400] hidden size: [89] trial: 24, train_loss: 1.461966, test loss: 1.263789, bias2: 0.758829653263092, variance: 0.5049590468406677\n",
      "Train size: [400] hidden size: [89] trial: 25, train_loss: 1.460315, test loss: 1.258451, bias2: 0.7588961124420166, variance: 0.499555379152298\n",
      "Train size: [400] hidden size: [89] trial: 26, train_loss: 1.462819, test loss: 1.260831, bias2: 0.7567331790924072, variance: 0.5040980577468872\n",
      "Train size: [400] hidden size: [89] trial: 27, train_loss: 1.464314, test loss: 1.262206, bias2: 0.7569835782051086, variance: 0.5052228569984436\n",
      "Train size: [400] hidden size: [89] trial: 28, train_loss: 1.459104, test loss: 1.259949, bias2: 0.7543021440505981, variance: 0.5056464672088623\n",
      "Train size: [400] hidden size: [89] trial: 29, train_loss: 1.458212, test loss: 1.262458, bias2: 0.7507320046424866, variance: 0.5117256045341492\n",
      "Train size: [400] hidden size: [89] trial: 30, train_loss: 1.451768, test loss: 1.264091, bias2: 0.7519360184669495, variance: 0.5121549963951111\n",
      "Train size: [400] hidden size: [89] trial: 31, train_loss: 1.450142, test loss: 1.259702, bias2: 0.7473943829536438, variance: 0.5123074650764465\n",
      "Train size: [400] hidden size: [89] trial: 32, train_loss: 1.451443, test loss: 1.259702, bias2: 0.7498062252998352, variance: 0.509895384311676\n",
      "Train size: [400] hidden size: [89] trial: 33, train_loss: 1.458048, test loss: 1.261484, bias2: 0.7532592415809631, variance: 0.5082243084907532\n",
      "Train size: [400] hidden size: [89] trial: 34, train_loss: 1.456236, test loss: 1.264428, bias2: 0.7544668912887573, variance: 0.5099608898162842\n",
      "Train size: [400] hidden size: [89] trial: 35, train_loss: 1.451163, test loss: 1.265190, bias2: 0.7533629536628723, variance: 0.5118266940116882\n",
      "Train size: [400] hidden size: [89] trial: 36, train_loss: 1.448270, test loss: 1.267384, bias2: 0.7513542175292969, variance: 0.5160295963287354\n",
      "Train size: [400] hidden size: [89] trial: 37, train_loss: 1.445566, test loss: 1.267689, bias2: 0.7505640387535095, variance: 0.5171247124671936\n",
      "Train size: [400] hidden size: [89] trial: 38, train_loss: 1.443067, test loss: 1.267813, bias2: 0.7512577772140503, variance: 0.5165550708770752\n",
      "Train size: [400] hidden size: [89] trial: 39, train_loss: 1.441943, test loss: 1.265392, bias2: 0.7520048022270203, variance: 0.5133876204490662\n",
      "Train size: [400] hidden size: [89] trial: 40, train_loss: 1.442269, test loss: 1.266348, bias2: 0.7484488487243652, variance: 0.5178993940353394\n",
      "Train size: [400] hidden size: [89] trial: 41, train_loss: 1.438451, test loss: 1.268915, bias2: 0.7468302845954895, variance: 0.5220842957496643\n",
      "Train size: [400] hidden size: [89] trial: 42, train_loss: 1.440133, test loss: 1.268794, bias2: 0.7461963295936584, variance: 0.5225980877876282\n",
      "Train size: [400] hidden size: [89] trial: 43, train_loss: 1.440696, test loss: 1.265620, bias2: 0.7435848116874695, variance: 0.522035539150238\n",
      "Train size: [400] hidden size: [89] trial: 44, train_loss: 1.437806, test loss: 1.267978, bias2: 0.7445732355117798, variance: 0.523404598236084\n",
      "Train size: [400] hidden size: [89] trial: 45, train_loss: 1.437651, test loss: 1.267360, bias2: 0.7411185503005981, variance: 0.5262410640716553\n",
      "Train size: [400] hidden size: [89] trial: 46, train_loss: 1.436979, test loss: 1.267155, bias2: 0.7421216368675232, variance: 0.525033175945282\n",
      "Train size: [400] hidden size: [89] trial: 47, train_loss: 1.436647, test loss: 1.267017, bias2: 0.7420166730880737, variance: 0.5250004529953003\n",
      "Train size: [400] hidden size: [89] trial: 48, train_loss: 1.438784, test loss: 1.268174, bias2: 0.7420702576637268, variance: 0.5261037945747375\n",
      "Train size: [400] hidden size: [89] trial: 49, train_loss: 1.434783, test loss: 1.270362, bias2: 0.7416130900382996, variance: 0.5287489295005798\n",
      "##################################################\n",
      "Train size: [400] hidden size: [102] trial: 0, train_loss: 1.427589, test loss: 1.282962, bias2: 1.2829618453979492, variance: 0.0\n",
      "Train size: [400] hidden size: [102] trial: 1, train_loss: 1.343027, test loss: 1.336233, bias2: 1.0156711339950562, variance: 0.32056161761283875\n",
      "Train size: [400] hidden size: [102] trial: 2, train_loss: 1.345349, test loss: 1.371265, bias2: 0.9235879182815552, variance: 0.4476766586303711\n",
      "Train size: [400] hidden size: [102] trial: 3, train_loss: 1.336663, test loss: 1.309895, bias2: 0.8382887244224548, variance: 0.4716060757637024\n",
      "Train size: [400] hidden size: [102] trial: 4, train_loss: 1.366833, test loss: 1.340252, bias2: 0.795717179775238, variance: 0.5445348620414734\n",
      "Train size: [400] hidden size: [102] trial: 5, train_loss: 1.396399, test loss: 1.325548, bias2: 0.7686094045639038, variance: 0.5569387674331665\n",
      "Train size: [400] hidden size: [102] trial: 6, train_loss: 1.405150, test loss: 1.332259, bias2: 0.7683936357498169, variance: 0.5638657808303833\n",
      "Train size: [400] hidden size: [102] trial: 7, train_loss: 1.383063, test loss: 1.326947, bias2: 0.7551850080490112, variance: 0.5717624425888062\n",
      "Train size: [400] hidden size: [102] trial: 8, train_loss: 1.387409, test loss: 1.323406, bias2: 0.7367396354675293, variance: 0.5866659879684448\n",
      "Train size: [400] hidden size: [102] trial: 9, train_loss: 1.370177, test loss: 1.313994, bias2: 0.7277078628540039, variance: 0.5862864255905151\n",
      "Train size: [400] hidden size: [102] trial: 10, train_loss: 1.374070, test loss: 1.311933, bias2: 0.7202335596084595, variance: 0.5916990041732788\n",
      "Train size: [400] hidden size: [102] trial: 11, train_loss: 1.381217, test loss: 1.312389, bias2: 0.7173831462860107, variance: 0.5950055122375488\n",
      "Train size: [400] hidden size: [102] trial: 12, train_loss: 1.381870, test loss: 1.315708, bias2: 0.7151366472244263, variance: 0.600571870803833\n",
      "Train size: [400] hidden size: [102] trial: 13, train_loss: 1.373269, test loss: 1.309915, bias2: 0.7078843712806702, variance: 0.6020309329032898\n",
      "Train size: [400] hidden size: [102] trial: 14, train_loss: 1.380453, test loss: 1.305434, bias2: 0.7040562629699707, variance: 0.6013778448104858\n",
      "Train size: [400] hidden size: [102] trial: 15, train_loss: 1.375670, test loss: 1.313877, bias2: 0.7055994868278503, variance: 0.6082772612571716\n",
      "Train size: [400] hidden size: [102] trial: 16, train_loss: 1.371221, test loss: 1.321990, bias2: 0.7037490606307983, variance: 0.6182410717010498\n",
      "Train size: [400] hidden size: [102] trial: 17, train_loss: 1.370261, test loss: 1.320004, bias2: 0.7031818628311157, variance: 0.6168220043182373\n",
      "Train size: [400] hidden size: [102] trial: 18, train_loss: 1.374163, test loss: 1.315283, bias2: 0.7006970047950745, variance: 0.6145864129066467\n",
      "Train size: [400] hidden size: [102] trial: 19, train_loss: 1.364799, test loss: 1.313812, bias2: 0.7029481530189514, variance: 0.6108636260032654\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [102] trial: 20, train_loss: 1.368824, test loss: 1.318578, bias2: 0.7005598545074463, variance: 0.6180177927017212\n",
      "Train size: [400] hidden size: [102] trial: 21, train_loss: 1.366121, test loss: 1.322016, bias2: 0.6985630989074707, variance: 0.6234530210494995\n",
      "Train size: [400] hidden size: [102] trial: 22, train_loss: 1.367647, test loss: 1.325290, bias2: 0.6960392594337463, variance: 0.6292509436607361\n",
      "Train size: [400] hidden size: [102] trial: 23, train_loss: 1.366996, test loss: 1.325680, bias2: 0.6971191763877869, variance: 0.6285613179206848\n",
      "Train size: [400] hidden size: [102] trial: 24, train_loss: 1.373097, test loss: 1.322742, bias2: 0.6986117362976074, variance: 0.6241302490234375\n",
      "Train size: [400] hidden size: [102] trial: 25, train_loss: 1.378122, test loss: 1.325970, bias2: 0.704435408115387, variance: 0.6215344071388245\n",
      "Train size: [400] hidden size: [102] trial: 26, train_loss: 1.383158, test loss: 1.329475, bias2: 0.7056074738502502, variance: 0.6238676905632019\n",
      "Train size: [400] hidden size: [102] trial: 27, train_loss: 1.384415, test loss: 1.331287, bias2: 0.70851731300354, variance: 0.622769832611084\n",
      "Train size: [400] hidden size: [102] trial: 28, train_loss: 1.378268, test loss: 1.326259, bias2: 0.7027171850204468, variance: 0.6235413551330566\n",
      "Train size: [400] hidden size: [102] trial: 29, train_loss: 1.377518, test loss: 1.328008, bias2: 0.7055204510688782, variance: 0.6224873661994934\n",
      "Train size: [400] hidden size: [102] trial: 30, train_loss: 1.380269, test loss: 1.326493, bias2: 0.704390823841095, variance: 0.6221025586128235\n",
      "Train size: [400] hidden size: [102] trial: 31, train_loss: 1.378858, test loss: 1.323444, bias2: 0.7055889368057251, variance: 0.6178551912307739\n",
      "Train size: [400] hidden size: [102] trial: 32, train_loss: 1.373507, test loss: 1.321286, bias2: 0.7051278948783875, variance: 0.6161584258079529\n",
      "Train size: [400] hidden size: [102] trial: 33, train_loss: 1.371734, test loss: 1.321729, bias2: 0.7054453492164612, variance: 0.6162835955619812\n",
      "Train size: [400] hidden size: [102] trial: 34, train_loss: 1.377497, test loss: 1.329377, bias2: 0.7063124775886536, variance: 0.6230648159980774\n",
      "Train size: [400] hidden size: [102] trial: 35, train_loss: 1.382054, test loss: 1.334993, bias2: 0.7073619365692139, variance: 0.627631425857544\n",
      "Train size: [400] hidden size: [102] trial: 36, train_loss: 1.383221, test loss: 1.334871, bias2: 0.7034982442855835, variance: 0.6313726902008057\n",
      "Train size: [400] hidden size: [102] trial: 37, train_loss: 1.382211, test loss: 1.332699, bias2: 0.7020284533500671, variance: 0.6306708455085754\n",
      "Train size: [400] hidden size: [102] trial: 38, train_loss: 1.381279, test loss: 1.330627, bias2: 0.7022154927253723, variance: 0.6284111142158508\n",
      "Train size: [400] hidden size: [102] trial: 39, train_loss: 1.382666, test loss: 1.330802, bias2: 0.7036756873130798, variance: 0.627126157283783\n",
      "Train size: [400] hidden size: [102] trial: 40, train_loss: 1.381645, test loss: 1.328389, bias2: 0.7041580080986023, variance: 0.6242310404777527\n",
      "Train size: [400] hidden size: [102] trial: 41, train_loss: 1.379535, test loss: 1.329350, bias2: 0.7046772241592407, variance: 0.6246728897094727\n",
      "Train size: [400] hidden size: [102] trial: 42, train_loss: 1.375972, test loss: 1.328508, bias2: 0.7017727494239807, variance: 0.626735508441925\n",
      "Train size: [400] hidden size: [102] trial: 43, train_loss: 1.370089, test loss: 1.324969, bias2: 0.7010027766227722, variance: 0.6239660382270813\n",
      "Train size: [400] hidden size: [102] trial: 44, train_loss: 1.368342, test loss: 1.323425, bias2: 0.7011339664459229, variance: 0.6222912073135376\n",
      "Train size: [400] hidden size: [102] trial: 45, train_loss: 1.371414, test loss: 1.322644, bias2: 0.7014535069465637, variance: 0.6211901307106018\n",
      "Train size: [400] hidden size: [102] trial: 46, train_loss: 1.370996, test loss: 1.323590, bias2: 0.7024494409561157, variance: 0.6211410760879517\n",
      "Train size: [400] hidden size: [102] trial: 47, train_loss: 1.375453, test loss: 1.326245, bias2: 0.7039836049079895, variance: 0.6222609877586365\n",
      "Train size: [400] hidden size: [102] trial: 48, train_loss: 1.374453, test loss: 1.326717, bias2: 0.7039073705673218, variance: 0.6228091716766357\n",
      "Train size: [400] hidden size: [102] trial: 49, train_loss: 1.371375, test loss: 1.326609, bias2: 0.7035413384437561, variance: 0.6230674386024475\n",
      "##################################################\n",
      "Train size: [400] hidden size: [118] trial: 0, train_loss: 1.217290, test loss: 1.566433, bias2: 1.5664327144622803, variance: 7.785096123313906e-09\n",
      "Train size: [400] hidden size: [118] trial: 1, train_loss: 1.330546, test loss: 1.458040, bias2: 1.0883843898773193, variance: 0.3696554899215698\n",
      "Train size: [400] hidden size: [118] trial: 2, train_loss: 1.337160, test loss: 1.418704, bias2: 0.921075701713562, variance: 0.49762842059135437\n",
      "Train size: [400] hidden size: [118] trial: 3, train_loss: 1.277507, test loss: 1.360641, bias2: 0.8592809438705444, variance: 0.501360297203064\n",
      "Train size: [400] hidden size: [118] trial: 4, train_loss: 1.256346, test loss: 1.360609, bias2: 0.8120316863059998, variance: 0.5485774874687195\n",
      "Train size: [400] hidden size: [118] trial: 5, train_loss: 1.272427, test loss: 1.377908, bias2: 0.7972103953361511, variance: 0.580697238445282\n",
      "Train size: [400] hidden size: [118] trial: 6, train_loss: 1.269189, test loss: 1.380022, bias2: 0.7935813665390015, variance: 0.5864400863647461\n",
      "Train size: [400] hidden size: [118] trial: 7, train_loss: 1.294142, test loss: 1.370132, bias2: 0.781764566898346, variance: 0.5883675217628479\n",
      "Train size: [400] hidden size: [118] trial: 8, train_loss: 1.295708, test loss: 1.373904, bias2: 0.7747973203659058, variance: 0.5991066694259644\n",
      "Train size: [400] hidden size: [118] trial: 9, train_loss: 1.278186, test loss: 1.377825, bias2: 0.7622974514961243, variance: 0.6155275702476501\n",
      "Train size: [400] hidden size: [118] trial: 10, train_loss: 1.273823, test loss: 1.365232, bias2: 0.75777268409729, variance: 0.6074589490890503\n",
      "Train size: [400] hidden size: [118] trial: 11, train_loss: 1.271022, test loss: 1.356295, bias2: 0.7419720888137817, variance: 0.6143230199813843\n",
      "Train size: [400] hidden size: [118] trial: 12, train_loss: 1.254326, test loss: 1.360907, bias2: 0.7415263056755066, variance: 0.6193804144859314\n",
      "Train size: [400] hidden size: [118] trial: 13, train_loss: 1.257205, test loss: 1.364689, bias2: 0.7298828363418579, variance: 0.6348061561584473\n",
      "Train size: [400] hidden size: [118] trial: 14, train_loss: 1.264939, test loss: 1.362520, bias2: 0.7238854765892029, variance: 0.6386346220970154\n",
      "Train size: [400] hidden size: [118] trial: 15, train_loss: 1.255322, test loss: 1.369354, bias2: 0.7201477289199829, variance: 0.6492066383361816\n",
      "Train size: [400] hidden size: [118] trial: 16, train_loss: 1.267087, test loss: 1.377276, bias2: 0.7231938242912292, variance: 0.6540820002555847\n",
      "Train size: [400] hidden size: [118] trial: 17, train_loss: 1.257597, test loss: 1.375401, bias2: 0.7222995162010193, variance: 0.6531016230583191\n",
      "Train size: [400] hidden size: [118] trial: 18, train_loss: 1.253482, test loss: 1.376158, bias2: 0.7173344492912292, variance: 0.6588237881660461\n",
      "Train size: [400] hidden size: [118] trial: 19, train_loss: 1.259190, test loss: 1.378150, bias2: 0.713813841342926, variance: 0.6643365025520325\n",
      "Train size: [400] hidden size: [118] trial: 20, train_loss: 1.259561, test loss: 1.381863, bias2: 0.7098422646522522, variance: 0.6720210909843445\n",
      "Train size: [400] hidden size: [118] trial: 21, train_loss: 1.257222, test loss: 1.381533, bias2: 0.7033753991127014, variance: 0.67815762758255\n",
      "Train size: [400] hidden size: [118] trial: 22, train_loss: 1.264546, test loss: 1.376174, bias2: 0.7029363512992859, variance: 0.6732377409934998\n",
      "Train size: [400] hidden size: [118] trial: 23, train_loss: 1.263071, test loss: 1.371453, bias2: 0.7002208828926086, variance: 0.6712319254875183\n",
      "Train size: [400] hidden size: [118] trial: 24, train_loss: 1.267642, test loss: 1.371634, bias2: 0.7021194696426392, variance: 0.6695147752761841\n",
      "Train size: [400] hidden size: [118] trial: 25, train_loss: 1.266451, test loss: 1.370446, bias2: 0.7051645517349243, variance: 0.6652818918228149\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [118] trial: 26, train_loss: 1.263275, test loss: 1.367143, bias2: 0.7048063278198242, variance: 0.662337064743042\n",
      "Train size: [400] hidden size: [118] trial: 27, train_loss: 1.266381, test loss: 1.371462, bias2: 0.7045270800590515, variance: 0.6669345498085022\n",
      "Train size: [400] hidden size: [118] trial: 28, train_loss: 1.269774, test loss: 1.370502, bias2: 0.7038813829421997, variance: 0.6666209697723389\n",
      "Train size: [400] hidden size: [118] trial: 29, train_loss: 1.267805, test loss: 1.369720, bias2: 0.7028586864471436, variance: 0.6668610572814941\n",
      "Train size: [400] hidden size: [118] trial: 30, train_loss: 1.274634, test loss: 1.370675, bias2: 0.7002062797546387, variance: 0.6704686880111694\n",
      "Train size: [400] hidden size: [118] trial: 31, train_loss: 1.276248, test loss: 1.367481, bias2: 0.6996148824691772, variance: 0.6678663492202759\n",
      "Train size: [400] hidden size: [118] trial: 32, train_loss: 1.273414, test loss: 1.366652, bias2: 0.6968916058540344, variance: 0.6697601675987244\n",
      "Train size: [400] hidden size: [118] trial: 33, train_loss: 1.276747, test loss: 1.365923, bias2: 0.6966577768325806, variance: 0.6692647933959961\n",
      "Train size: [400] hidden size: [118] trial: 34, train_loss: 1.274856, test loss: 1.368352, bias2: 0.692068874835968, variance: 0.6762828230857849\n",
      "Train size: [400] hidden size: [118] trial: 35, train_loss: 1.274794, test loss: 1.367006, bias2: 0.6909233331680298, variance: 0.6760823726654053\n",
      "Train size: [400] hidden size: [118] trial: 36, train_loss: 1.272896, test loss: 1.369223, bias2: 0.6898467540740967, variance: 0.679376482963562\n",
      "Train size: [400] hidden size: [118] trial: 37, train_loss: 1.270730, test loss: 1.366855, bias2: 0.6912682056427002, variance: 0.6755869388580322\n",
      "Train size: [400] hidden size: [118] trial: 38, train_loss: 1.268464, test loss: 1.368322, bias2: 0.6888924241065979, variance: 0.6794291138648987\n",
      "Train size: [400] hidden size: [118] trial: 39, train_loss: 1.268520, test loss: 1.367426, bias2: 0.6862320303916931, variance: 0.6811941266059875\n",
      "Train size: [400] hidden size: [118] trial: 40, train_loss: 1.263250, test loss: 1.366843, bias2: 0.6862190365791321, variance: 0.6806244254112244\n",
      "Train size: [400] hidden size: [118] trial: 41, train_loss: 1.263446, test loss: 1.368026, bias2: 0.6816408038139343, variance: 0.6863849759101868\n",
      "Train size: [400] hidden size: [118] trial: 42, train_loss: 1.261443, test loss: 1.368489, bias2: 0.6814122200012207, variance: 0.6870771646499634\n",
      "Train size: [400] hidden size: [118] trial: 43, train_loss: 1.261256, test loss: 1.366887, bias2: 0.6829209327697754, variance: 0.6839660406112671\n",
      "Train size: [400] hidden size: [118] trial: 44, train_loss: 1.261032, test loss: 1.365357, bias2: 0.68447345495224, variance: 0.6808831095695496\n",
      "Train size: [400] hidden size: [118] trial: 45, train_loss: 1.260069, test loss: 1.364432, bias2: 0.6853225231170654, variance: 0.6791096925735474\n",
      "Train size: [400] hidden size: [118] trial: 46, train_loss: 1.263068, test loss: 1.365105, bias2: 0.6837143898010254, variance: 0.6813908815383911\n",
      "Train size: [400] hidden size: [118] trial: 47, train_loss: 1.262973, test loss: 1.365821, bias2: 0.6832905411720276, variance: 0.6825303435325623\n",
      "Train size: [400] hidden size: [118] trial: 48, train_loss: 1.265885, test loss: 1.362804, bias2: 0.6823796033859253, variance: 0.6804242134094238\n",
      "Train size: [400] hidden size: [118] trial: 49, train_loss: 1.266727, test loss: 1.362864, bias2: 0.6823448538780212, variance: 0.6805194020271301\n",
      "##################################################\n",
      "Train size: [400] hidden size: [136] trial: 0, train_loss: 1.125345, test loss: 1.368033, bias2: 1.3680329322814941, variance: 3.8925479506346505e-10\n",
      "Train size: [400] hidden size: [136] trial: 1, train_loss: 1.255872, test loss: 1.370481, bias2: 0.9956965446472168, variance: 0.3747849762439728\n",
      "Train size: [400] hidden size: [136] trial: 2, train_loss: 1.230599, test loss: 1.355914, bias2: 0.8565440773963928, variance: 0.4993698000907898\n",
      "Train size: [400] hidden size: [136] trial: 3, train_loss: 1.202271, test loss: 1.389981, bias2: 0.8098546266555786, variance: 0.5801262855529785\n",
      "Train size: [400] hidden size: [136] trial: 4, train_loss: 1.211711, test loss: 1.379434, bias2: 0.7682650685310364, variance: 0.6111685633659363\n",
      "Train size: [400] hidden size: [136] trial: 5, train_loss: 1.207141, test loss: 1.398624, bias2: 0.7599362134933472, variance: 0.6386878490447998\n",
      "Train size: [400] hidden size: [136] trial: 6, train_loss: 1.207085, test loss: 1.383212, bias2: 0.7381767630577087, variance: 0.6450356841087341\n",
      "Train size: [400] hidden size: [136] trial: 7, train_loss: 1.214699, test loss: 1.379658, bias2: 0.7210003733634949, variance: 0.6586580872535706\n",
      "Train size: [400] hidden size: [136] trial: 8, train_loss: 1.227608, test loss: 1.373300, bias2: 0.7153979539871216, variance: 0.6579016447067261\n",
      "Train size: [400] hidden size: [136] trial: 9, train_loss: 1.225850, test loss: 1.376675, bias2: 0.7123116850852966, variance: 0.6643633246421814\n",
      "Train size: [400] hidden size: [136] trial: 10, train_loss: 1.223997, test loss: 1.366960, bias2: 0.7072823643684387, variance: 0.6596773266792297\n",
      "Train size: [400] hidden size: [136] trial: 11, train_loss: 1.224303, test loss: 1.352535, bias2: 0.7018337845802307, variance: 0.6507015824317932\n",
      "Train size: [400] hidden size: [136] trial: 12, train_loss: 1.216345, test loss: 1.363714, bias2: 0.6966724395751953, variance: 0.6670418977737427\n",
      "Train size: [400] hidden size: [136] trial: 13, train_loss: 1.214478, test loss: 1.363064, bias2: 0.684710681438446, variance: 0.6783531308174133\n",
      "Train size: [400] hidden size: [136] trial: 14, train_loss: 1.210760, test loss: 1.360634, bias2: 0.6744457483291626, variance: 0.6861884593963623\n",
      "Train size: [400] hidden size: [136] trial: 15, train_loss: 1.204902, test loss: 1.360863, bias2: 0.6744504570960999, variance: 0.6864121556282043\n",
      "Train size: [400] hidden size: [136] trial: 16, train_loss: 1.201644, test loss: 1.361046, bias2: 0.6712545156478882, variance: 0.6897919178009033\n",
      "Train size: [400] hidden size: [136] trial: 17, train_loss: 1.204069, test loss: 1.365138, bias2: 0.6645610928535461, variance: 0.7005766034126282\n",
      "Train size: [400] hidden size: [136] trial: 18, train_loss: 1.207423, test loss: 1.374570, bias2: 0.6685313582420349, variance: 0.7060388922691345\n",
      "Train size: [400] hidden size: [136] trial: 19, train_loss: 1.206934, test loss: 1.383562, bias2: 0.6700775027275085, variance: 0.7134842276573181\n",
      "Train size: [400] hidden size: [136] trial: 20, train_loss: 1.212730, test loss: 1.391241, bias2: 0.6689510941505432, variance: 0.7222893834114075\n",
      "Train size: [400] hidden size: [136] trial: 21, train_loss: 1.217989, test loss: 1.396494, bias2: 0.669442355632782, variance: 0.7270516753196716\n",
      "Train size: [400] hidden size: [136] trial: 22, train_loss: 1.220244, test loss: 1.391694, bias2: 0.6679388880729675, variance: 0.7237547039985657\n",
      "Train size: [400] hidden size: [136] trial: 23, train_loss: 1.223076, test loss: 1.390005, bias2: 0.6623166799545288, variance: 0.727688193321228\n",
      "Train size: [400] hidden size: [136] trial: 24, train_loss: 1.218916, test loss: 1.389650, bias2: 0.658939003944397, variance: 0.7307112216949463\n",
      "Train size: [400] hidden size: [136] trial: 25, train_loss: 1.217171, test loss: 1.397132, bias2: 0.6567375063896179, variance: 0.7403944134712219\n",
      "Train size: [400] hidden size: [136] trial: 26, train_loss: 1.221166, test loss: 1.398766, bias2: 0.6574323773384094, variance: 0.7413333058357239\n",
      "Train size: [400] hidden size: [136] trial: 27, train_loss: 1.222084, test loss: 1.397833, bias2: 0.6554834246635437, variance: 0.7423490881919861\n",
      "Train size: [400] hidden size: [136] trial: 28, train_loss: 1.218346, test loss: 1.399289, bias2: 0.6545864939689636, variance: 0.7447027564048767\n",
      "Train size: [400] hidden size: [136] trial: 29, train_loss: 1.220780, test loss: 1.401148, bias2: 0.6542835831642151, variance: 0.7468648552894592\n",
      "Train size: [400] hidden size: [136] trial: 30, train_loss: 1.224795, test loss: 1.395541, bias2: 0.6508659720420837, variance: 0.74467533826828\n",
      "Train size: [400] hidden size: [136] trial: 31, train_loss: 1.222592, test loss: 1.394015, bias2: 0.6472001671791077, variance: 0.7468145489692688\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [136] trial: 32, train_loss: 1.221127, test loss: 1.390703, bias2: 0.644737184047699, variance: 0.7459655404090881\n",
      "Train size: [400] hidden size: [136] trial: 33, train_loss: 1.218077, test loss: 1.392886, bias2: 0.6459167003631592, variance: 0.7469691038131714\n",
      "Train size: [400] hidden size: [136] trial: 34, train_loss: 1.215215, test loss: 1.393424, bias2: 0.6464259624481201, variance: 0.7469979524612427\n",
      "Train size: [400] hidden size: [136] trial: 35, train_loss: 1.212006, test loss: 1.393140, bias2: 0.643906831741333, variance: 0.7492334842681885\n",
      "Train size: [400] hidden size: [136] trial: 36, train_loss: 1.209934, test loss: 1.389196, bias2: 0.6423226594924927, variance: 0.7468734979629517\n",
      "Train size: [400] hidden size: [136] trial: 37, train_loss: 1.209726, test loss: 1.387696, bias2: 0.6414347290992737, variance: 0.7462612986564636\n",
      "Train size: [400] hidden size: [136] trial: 38, train_loss: 1.211283, test loss: 1.386015, bias2: 0.640145480632782, variance: 0.7458699345588684\n",
      "Train size: [400] hidden size: [136] trial: 39, train_loss: 1.208527, test loss: 1.383520, bias2: 0.6392090916633606, variance: 0.7443111538887024\n",
      "Train size: [400] hidden size: [136] trial: 40, train_loss: 1.210237, test loss: 1.382087, bias2: 0.6388243436813354, variance: 0.743262767791748\n",
      "Train size: [400] hidden size: [136] trial: 41, train_loss: 1.211014, test loss: 1.384330, bias2: 0.637429416179657, variance: 0.7469004988670349\n",
      "Train size: [400] hidden size: [136] trial: 42, train_loss: 1.208751, test loss: 1.385308, bias2: 0.6369605660438538, variance: 0.7483471035957336\n",
      "Train size: [400] hidden size: [136] trial: 43, train_loss: 1.205110, test loss: 1.384929, bias2: 0.6368033289909363, variance: 0.7481257319450378\n",
      "Train size: [400] hidden size: [136] trial: 44, train_loss: 1.203181, test loss: 1.385891, bias2: 0.6364808678627014, variance: 0.7494098544120789\n",
      "Train size: [400] hidden size: [136] trial: 45, train_loss: 1.203927, test loss: 1.385901, bias2: 0.6368154883384705, variance: 0.7490854859352112\n",
      "Train size: [400] hidden size: [136] trial: 46, train_loss: 1.201227, test loss: 1.387433, bias2: 0.6364294290542603, variance: 0.7510031461715698\n",
      "Train size: [400] hidden size: [136] trial: 47, train_loss: 1.201610, test loss: 1.384091, bias2: 0.6332108378410339, variance: 0.7508801817893982\n",
      "Train size: [400] hidden size: [136] trial: 48, train_loss: 1.200460, test loss: 1.385400, bias2: 0.6323812007904053, variance: 0.7530187368392944\n",
      "Train size: [400] hidden size: [136] trial: 49, train_loss: 1.197328, test loss: 1.386474, bias2: 0.6333655118942261, variance: 0.7531087398529053\n",
      "##################################################\n",
      "Train size: [400] hidden size: [156] trial: 0, train_loss: 1.174235, test loss: 1.296533, bias2: 1.2965325117111206, variance: -4.6710577628061856e-09\n",
      "Train size: [400] hidden size: [156] trial: 1, train_loss: 1.096148, test loss: 1.436562, bias2: 0.910574197769165, variance: 0.5259882211685181\n",
      "Train size: [400] hidden size: [156] trial: 2, train_loss: 1.045205, test loss: 1.374113, bias2: 0.7567065954208374, variance: 0.6174060106277466\n",
      "Train size: [400] hidden size: [156] trial: 3, train_loss: 1.040872, test loss: 1.380717, bias2: 0.7339103817939758, variance: 0.646806538105011\n",
      "Train size: [400] hidden size: [156] trial: 4, train_loss: 1.047434, test loss: 1.377925, bias2: 0.6948990821838379, variance: 0.683025598526001\n",
      "Train size: [400] hidden size: [156] trial: 5, train_loss: 1.067114, test loss: 1.407886, bias2: 0.6748539209365845, variance: 0.7330317497253418\n",
      "Train size: [400] hidden size: [156] trial: 6, train_loss: 1.061524, test loss: 1.400630, bias2: 0.6516836285591125, variance: 0.7489460110664368\n",
      "Train size: [400] hidden size: [156] trial: 7, train_loss: 1.062977, test loss: 1.398700, bias2: 0.6455101370811462, variance: 0.7531898617744446\n",
      "Train size: [400] hidden size: [156] trial: 8, train_loss: 1.070676, test loss: 1.402691, bias2: 0.649937629699707, variance: 0.752753496170044\n",
      "Train size: [400] hidden size: [156] trial: 9, train_loss: 1.088790, test loss: 1.400314, bias2: 0.6393894553184509, variance: 0.7609243988990784\n",
      "Train size: [400] hidden size: [156] trial: 10, train_loss: 1.088055, test loss: 1.404350, bias2: 0.6338406205177307, variance: 0.770509660243988\n",
      "Train size: [400] hidden size: [156] trial: 11, train_loss: 1.102648, test loss: 1.408812, bias2: 0.6347119212150574, variance: 0.7741003632545471\n",
      "Train size: [400] hidden size: [156] trial: 12, train_loss: 1.098228, test loss: 1.413131, bias2: 0.6332772970199585, variance: 0.7798538208007812\n",
      "Train size: [400] hidden size: [156] trial: 13, train_loss: 1.097580, test loss: 1.409310, bias2: 0.6303223967552185, variance: 0.778987467288971\n",
      "Train size: [400] hidden size: [156] trial: 14, train_loss: 1.092408, test loss: 1.404222, bias2: 0.6227990388870239, variance: 0.78142249584198\n",
      "Train size: [400] hidden size: [156] trial: 15, train_loss: 1.101189, test loss: 1.405030, bias2: 0.6273133158683777, variance: 0.777716338634491\n",
      "Train size: [400] hidden size: [156] trial: 16, train_loss: 1.094650, test loss: 1.405069, bias2: 0.6288694739341736, variance: 0.7761998772621155\n",
      "Train size: [400] hidden size: [156] trial: 17, train_loss: 1.092410, test loss: 1.412261, bias2: 0.6299819350242615, variance: 0.782278835773468\n",
      "Train size: [400] hidden size: [156] trial: 18, train_loss: 1.093514, test loss: 1.407781, bias2: 0.6226683855056763, variance: 0.7851130962371826\n",
      "Train size: [400] hidden size: [156] trial: 19, train_loss: 1.096111, test loss: 1.414191, bias2: 0.6178495287895203, variance: 0.7963412404060364\n",
      "Train size: [400] hidden size: [156] trial: 20, train_loss: 1.096895, test loss: 1.422839, bias2: 0.6132268309593201, variance: 0.8096123337745667\n",
      "Train size: [400] hidden size: [156] trial: 21, train_loss: 1.100905, test loss: 1.427855, bias2: 0.6166369915008545, variance: 0.8112177848815918\n",
      "Train size: [400] hidden size: [156] trial: 22, train_loss: 1.105457, test loss: 1.426002, bias2: 0.6152411699295044, variance: 0.8107603788375854\n",
      "Train size: [400] hidden size: [156] trial: 23, train_loss: 1.099675, test loss: 1.425684, bias2: 0.6166685819625854, variance: 0.8090149164199829\n",
      "Train size: [400] hidden size: [156] trial: 24, train_loss: 1.102864, test loss: 1.423939, bias2: 0.6154372096061707, variance: 0.8085020184516907\n",
      "Train size: [400] hidden size: [156] trial: 25, train_loss: 1.110499, test loss: 1.423642, bias2: 0.616369366645813, variance: 0.8072729110717773\n",
      "Train size: [400] hidden size: [156] trial: 26, train_loss: 1.104979, test loss: 1.424805, bias2: 0.6218435764312744, variance: 0.8029614686965942\n",
      "Train size: [400] hidden size: [156] trial: 27, train_loss: 1.104695, test loss: 1.421912, bias2: 0.622046709060669, variance: 0.7998650074005127\n",
      "Train size: [400] hidden size: [156] trial: 28, train_loss: 1.107506, test loss: 1.419286, bias2: 0.6210810542106628, variance: 0.7982051968574524\n",
      "Train size: [400] hidden size: [156] trial: 29, train_loss: 1.106248, test loss: 1.421951, bias2: 0.6211240887641907, variance: 0.8008268475532532\n",
      "Train size: [400] hidden size: [156] trial: 30, train_loss: 1.105634, test loss: 1.421511, bias2: 0.6202998161315918, variance: 0.8012109994888306\n",
      "Train size: [400] hidden size: [156] trial: 31, train_loss: 1.100352, test loss: 1.422865, bias2: 0.6227731108665466, variance: 0.8000920414924622\n",
      "Train size: [400] hidden size: [156] trial: 32, train_loss: 1.103905, test loss: 1.421086, bias2: 0.6236658096313477, variance: 0.7974206209182739\n",
      "Train size: [400] hidden size: [156] trial: 33, train_loss: 1.107080, test loss: 1.423691, bias2: 0.6187472343444824, variance: 0.804943323135376\n",
      "Train size: [400] hidden size: [156] trial: 34, train_loss: 1.109059, test loss: 1.424759, bias2: 0.6191025972366333, variance: 0.8056559562683105\n",
      "Train size: [400] hidden size: [156] trial: 35, train_loss: 1.110233, test loss: 1.424839, bias2: 0.6177434325218201, variance: 0.8070959448814392\n",
      "Train size: [400] hidden size: [156] trial: 36, train_loss: 1.106888, test loss: 1.422014, bias2: 0.6153900027275085, variance: 0.8066242337226868\n",
      "Train size: [400] hidden size: [156] trial: 37, train_loss: 1.108838, test loss: 1.418376, bias2: 0.6167093515396118, variance: 0.801666259765625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [156] trial: 38, train_loss: 1.101104, test loss: 1.421942, bias2: 0.6149997711181641, variance: 0.8069418668746948\n",
      "Train size: [400] hidden size: [156] trial: 39, train_loss: 1.102952, test loss: 1.419952, bias2: 0.613219678401947, variance: 0.806732714176178\n",
      "Train size: [400] hidden size: [156] trial: 40, train_loss: 1.100505, test loss: 1.417715, bias2: 0.6099201440811157, variance: 0.8077946901321411\n",
      "Train size: [400] hidden size: [156] trial: 41, train_loss: 1.097827, test loss: 1.420416, bias2: 0.609295666217804, variance: 0.8111204504966736\n",
      "Train size: [400] hidden size: [156] trial: 42, train_loss: 1.096292, test loss: 1.418526, bias2: 0.6094858050346375, variance: 0.8090406060218811\n",
      "Train size: [400] hidden size: [156] trial: 43, train_loss: 1.100014, test loss: 1.416580, bias2: 0.6084858775138855, variance: 0.8080945611000061\n",
      "Train size: [400] hidden size: [156] trial: 44, train_loss: 1.099482, test loss: 1.411047, bias2: 0.6075415015220642, variance: 0.8035054802894592\n",
      "Train size: [400] hidden size: [156] trial: 45, train_loss: 1.101075, test loss: 1.411839, bias2: 0.6075002551078796, variance: 0.8043391108512878\n",
      "Train size: [400] hidden size: [156] trial: 46, train_loss: 1.099694, test loss: 1.409156, bias2: 0.6079660654067993, variance: 0.8011897802352905\n",
      "Train size: [400] hidden size: [156] trial: 47, train_loss: 1.099951, test loss: 1.410890, bias2: 0.609275758266449, variance: 0.8016137480735779\n",
      "Train size: [400] hidden size: [156] trial: 48, train_loss: 1.100207, test loss: 1.411994, bias2: 0.6103540062904358, variance: 0.8016400933265686\n",
      "Train size: [400] hidden size: [156] trial: 49, train_loss: 1.098070, test loss: 1.409594, bias2: 0.610130250453949, variance: 0.7994640469551086\n",
      "##################################################\n",
      "Train size: [400] hidden size: [180] trial: 0, train_loss: 1.031609, test loss: 1.454135, bias2: 1.4541352987289429, variance: -4.6710577628061856e-09\n",
      "Train size: [400] hidden size: [180] trial: 1, train_loss: 1.007719, test loss: 1.508294, bias2: 1.0650644302368164, variance: 0.443229079246521\n",
      "Train size: [400] hidden size: [180] trial: 2, train_loss: 1.013765, test loss: 1.491765, bias2: 0.8971421122550964, variance: 0.5946231484413147\n",
      "Train size: [400] hidden size: [180] trial: 3, train_loss: 0.994428, test loss: 1.489786, bias2: 0.8250849843025208, variance: 0.6647009253501892\n",
      "Train size: [400] hidden size: [180] trial: 4, train_loss: 1.014140, test loss: 1.471563, bias2: 0.7774052619934082, variance: 0.6941574811935425\n",
      "Train size: [400] hidden size: [180] trial: 5, train_loss: 0.996174, test loss: 1.447852, bias2: 0.7389997839927673, variance: 0.7088518738746643\n",
      "Train size: [400] hidden size: [180] trial: 6, train_loss: 0.986008, test loss: 1.465571, bias2: 0.7373455166816711, variance: 0.7282252907752991\n",
      "Train size: [400] hidden size: [180] trial: 7, train_loss: 0.998788, test loss: 1.475356, bias2: 0.714208722114563, variance: 0.7611476182937622\n",
      "Train size: [400] hidden size: [180] trial: 8, train_loss: 0.975413, test loss: 1.444498, bias2: 0.6855866312980652, variance: 0.758911669254303\n",
      "Train size: [400] hidden size: [180] trial: 9, train_loss: 0.968361, test loss: 1.434269, bias2: 0.6773489117622375, variance: 0.7569199204444885\n",
      "Train size: [400] hidden size: [180] trial: 10, train_loss: 0.965471, test loss: 1.432321, bias2: 0.672800600528717, variance: 0.7595203518867493\n",
      "Train size: [400] hidden size: [180] trial: 11, train_loss: 0.967761, test loss: 1.429617, bias2: 0.6596046090126038, variance: 0.7700129151344299\n",
      "Train size: [400] hidden size: [180] trial: 12, train_loss: 0.982417, test loss: 1.428559, bias2: 0.6566043496131897, variance: 0.7719542384147644\n",
      "Train size: [400] hidden size: [180] trial: 13, train_loss: 0.986998, test loss: 1.419370, bias2: 0.653278648853302, variance: 0.7660912871360779\n",
      "Train size: [400] hidden size: [180] trial: 14, train_loss: 0.980960, test loss: 1.413517, bias2: 0.6426222324371338, variance: 0.7708948850631714\n",
      "Train size: [400] hidden size: [180] trial: 15, train_loss: 0.980394, test loss: 1.414791, bias2: 0.6385970115661621, variance: 0.7761937379837036\n",
      "Train size: [400] hidden size: [180] trial: 16, train_loss: 0.978480, test loss: 1.421270, bias2: 0.6289278268814087, variance: 0.7923417091369629\n",
      "Train size: [400] hidden size: [180] trial: 17, train_loss: 0.976372, test loss: 1.412168, bias2: 0.6247662305831909, variance: 0.7874014377593994\n",
      "Train size: [400] hidden size: [180] trial: 18, train_loss: 0.975436, test loss: 1.411454, bias2: 0.6236721873283386, variance: 0.787781298160553\n",
      "Train size: [400] hidden size: [180] trial: 19, train_loss: 0.973453, test loss: 1.416504, bias2: 0.6242762207984924, variance: 0.7922280430793762\n",
      "Train size: [400] hidden size: [180] trial: 20, train_loss: 0.980330, test loss: 1.409092, bias2: 0.6230000257492065, variance: 0.7860919237136841\n",
      "Train size: [400] hidden size: [180] trial: 21, train_loss: 0.973116, test loss: 1.405588, bias2: 0.6183948516845703, variance: 0.7871932983398438\n",
      "Train size: [400] hidden size: [180] trial: 22, train_loss: 0.970409, test loss: 1.411626, bias2: 0.6111570596694946, variance: 0.8004690408706665\n",
      "Train size: [400] hidden size: [180] trial: 23, train_loss: 0.973913, test loss: 1.406923, bias2: 0.6057493090629578, variance: 0.8011733889579773\n",
      "Train size: [400] hidden size: [180] trial: 24, train_loss: 0.977708, test loss: 1.411669, bias2: 0.606304407119751, variance: 0.805364727973938\n",
      "Train size: [400] hidden size: [180] trial: 25, train_loss: 0.980826, test loss: 1.417258, bias2: 0.6031309366226196, variance: 0.8141273260116577\n",
      "Train size: [400] hidden size: [180] trial: 26, train_loss: 0.988610, test loss: 1.420975, bias2: 0.6056546568870544, variance: 0.8153204321861267\n",
      "Train size: [400] hidden size: [180] trial: 27, train_loss: 0.990371, test loss: 1.423078, bias2: 0.6082573533058167, variance: 0.8148209452629089\n",
      "Train size: [400] hidden size: [180] trial: 28, train_loss: 0.997560, test loss: 1.422519, bias2: 0.6084993481636047, variance: 0.8140200972557068\n",
      "Train size: [400] hidden size: [180] trial: 29, train_loss: 0.994267, test loss: 1.423705, bias2: 0.6093234419822693, variance: 0.8143813014030457\n",
      "Train size: [400] hidden size: [180] trial: 30, train_loss: 0.996781, test loss: 1.423568, bias2: 0.6117234230041504, variance: 0.8118447065353394\n",
      "Train size: [400] hidden size: [180] trial: 31, train_loss: 1.006572, test loss: 1.431150, bias2: 0.6155075430870056, variance: 0.8156421780586243\n",
      "Train size: [400] hidden size: [180] trial: 32, train_loss: 1.005471, test loss: 1.426380, bias2: 0.6106297969818115, variance: 0.8157507181167603\n",
      "Train size: [400] hidden size: [180] trial: 33, train_loss: 1.003799, test loss: 1.421645, bias2: 0.6072672009468079, variance: 0.8143782019615173\n",
      "Train size: [400] hidden size: [180] trial: 34, train_loss: 1.002349, test loss: 1.421111, bias2: 0.6066048741340637, variance: 0.8145063519477844\n",
      "Train size: [400] hidden size: [180] trial: 35, train_loss: 0.999464, test loss: 1.424328, bias2: 0.6083826422691345, variance: 0.8159449696540833\n",
      "Train size: [400] hidden size: [180] trial: 36, train_loss: 1.001483, test loss: 1.420881, bias2: 0.6061269640922546, variance: 0.81475430727005\n",
      "Train size: [400] hidden size: [180] trial: 37, train_loss: 1.002058, test loss: 1.421968, bias2: 0.6062654852867126, variance: 0.8157020211219788\n",
      "Train size: [400] hidden size: [180] trial: 38, train_loss: 1.000035, test loss: 1.420614, bias2: 0.6021713614463806, variance: 0.8184428811073303\n",
      "Train size: [400] hidden size: [180] trial: 39, train_loss: 0.996837, test loss: 1.420011, bias2: 0.6030821800231934, variance: 0.8169292211532593\n",
      "Train size: [400] hidden size: [180] trial: 40, train_loss: 0.993617, test loss: 1.420909, bias2: 0.6033451557159424, variance: 0.8175636529922485\n",
      "Train size: [400] hidden size: [180] trial: 41, train_loss: 0.992787, test loss: 1.418892, bias2: 0.6023306846618652, variance: 0.8165613412857056\n",
      "Train size: [400] hidden size: [180] trial: 42, train_loss: 0.994351, test loss: 1.419541, bias2: 0.6000250577926636, variance: 0.819515585899353\n",
      "Train size: [400] hidden size: [180] trial: 43, train_loss: 0.989791, test loss: 1.416235, bias2: 0.5968950390815735, variance: 0.8193395733833313\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [180] trial: 44, train_loss: 0.988374, test loss: 1.413833, bias2: 0.5952622890472412, variance: 0.8185707330703735\n",
      "Train size: [400] hidden size: [180] trial: 45, train_loss: 0.990539, test loss: 1.413820, bias2: 0.5935812592506409, variance: 0.8202390074729919\n",
      "Train size: [400] hidden size: [180] trial: 46, train_loss: 0.991324, test loss: 1.414824, bias2: 0.5934234261512756, variance: 0.8214003443717957\n",
      "Train size: [400] hidden size: [180] trial: 47, train_loss: 0.991109, test loss: 1.416279, bias2: 0.5929503440856934, variance: 0.8233284950256348\n",
      "Train size: [400] hidden size: [180] trial: 48, train_loss: 0.992574, test loss: 1.413153, bias2: 0.5906087756156921, variance: 0.8225446343421936\n",
      "Train size: [400] hidden size: [180] trial: 49, train_loss: 0.992005, test loss: 1.412547, bias2: 0.5905547738075256, variance: 0.8219920992851257\n",
      "##################################################\n",
      "Train size: [400] hidden size: [207] trial: 0, train_loss: 0.901819, test loss: 1.602655, bias2: 1.6026548147201538, variance: 7.785095901269301e-10\n",
      "Train size: [400] hidden size: [207] trial: 1, train_loss: 0.903522, test loss: 1.529224, bias2: 1.0459973812103271, variance: 0.48322683572769165\n",
      "Train size: [400] hidden size: [207] trial: 2, train_loss: 0.918936, test loss: 1.540296, bias2: 0.8781850934028625, variance: 0.6621107459068298\n",
      "Train size: [400] hidden size: [207] trial: 3, train_loss: 0.902757, test loss: 1.516341, bias2: 0.7576351165771484, variance: 0.7587053775787354\n",
      "Train size: [400] hidden size: [207] trial: 4, train_loss: 0.891334, test loss: 1.497039, bias2: 0.6998234391212463, variance: 0.79721599817276\n",
      "Train size: [400] hidden size: [207] trial: 5, train_loss: 0.896333, test loss: 1.479125, bias2: 0.6552066206932068, variance: 0.8239182829856873\n",
      "Train size: [400] hidden size: [207] trial: 6, train_loss: 0.892520, test loss: 1.455554, bias2: 0.6321940422058105, variance: 0.8233603239059448\n",
      "Train size: [400] hidden size: [207] trial: 7, train_loss: 0.893109, test loss: 1.476793, bias2: 0.6292774677276611, variance: 0.8475151062011719\n",
      "Train size: [400] hidden size: [207] trial: 8, train_loss: 0.897123, test loss: 1.469029, bias2: 0.6170121431350708, variance: 0.8520163297653198\n",
      "Train size: [400] hidden size: [207] trial: 9, train_loss: 0.897073, test loss: 1.457247, bias2: 0.6067640781402588, variance: 0.8504830598831177\n",
      "Train size: [400] hidden size: [207] trial: 10, train_loss: 0.895818, test loss: 1.445588, bias2: 0.5910847783088684, variance: 0.8545036911964417\n",
      "Train size: [400] hidden size: [207] trial: 11, train_loss: 0.882409, test loss: 1.445482, bias2: 0.5876277089118958, variance: 0.8578545451164246\n",
      "Train size: [400] hidden size: [207] trial: 12, train_loss: 0.874487, test loss: 1.442736, bias2: 0.5837382078170776, variance: 0.8589978218078613\n",
      "Train size: [400] hidden size: [207] trial: 13, train_loss: 0.879975, test loss: 1.458216, bias2: 0.5809361934661865, variance: 0.8772792816162109\n",
      "Train size: [400] hidden size: [207] trial: 14, train_loss: 0.882308, test loss: 1.456160, bias2: 0.581866443157196, variance: 0.8742931485176086\n",
      "Train size: [400] hidden size: [207] trial: 15, train_loss: 0.885183, test loss: 1.455061, bias2: 0.5834000706672668, variance: 0.8716607689857483\n",
      "Train size: [400] hidden size: [207] trial: 16, train_loss: 0.878419, test loss: 1.451562, bias2: 0.580019474029541, variance: 0.8715424537658691\n",
      "Train size: [400] hidden size: [207] trial: 17, train_loss: 0.877540, test loss: 1.444210, bias2: 0.5791938304901123, variance: 0.865015983581543\n",
      "Train size: [400] hidden size: [207] trial: 18, train_loss: 0.883333, test loss: 1.440494, bias2: 0.5741952657699585, variance: 0.8662987947463989\n",
      "Train size: [400] hidden size: [207] trial: 19, train_loss: 0.881642, test loss: 1.451025, bias2: 0.5741853713989258, variance: 0.8768391609191895\n",
      "Train size: [400] hidden size: [207] trial: 20, train_loss: 0.875148, test loss: 1.454583, bias2: 0.5729468464851379, variance: 0.8816364407539368\n",
      "Train size: [400] hidden size: [207] trial: 21, train_loss: 0.869397, test loss: 1.448941, bias2: 0.5626229047775269, variance: 0.886318564414978\n",
      "Train size: [400] hidden size: [207] trial: 22, train_loss: 0.870490, test loss: 1.446948, bias2: 0.5635758638381958, variance: 0.8833717107772827\n",
      "Train size: [400] hidden size: [207] trial: 23, train_loss: 0.872505, test loss: 1.442013, bias2: 0.5588680505752563, variance: 0.8831449747085571\n",
      "Train size: [400] hidden size: [207] trial: 24, train_loss: 0.868821, test loss: 1.445334, bias2: 0.562912106513977, variance: 0.8824214935302734\n",
      "Train size: [400] hidden size: [207] trial: 25, train_loss: 0.867075, test loss: 1.440400, bias2: 0.5641646981239319, variance: 0.8762354254722595\n",
      "Train size: [400] hidden size: [207] trial: 26, train_loss: 0.865509, test loss: 1.439547, bias2: 0.5660906434059143, variance: 0.8734565377235413\n",
      "Train size: [400] hidden size: [207] trial: 27, train_loss: 0.868402, test loss: 1.440614, bias2: 0.5649943351745605, variance: 0.8756198883056641\n",
      "Train size: [400] hidden size: [207] trial: 28, train_loss: 0.872129, test loss: 1.442455, bias2: 0.5608388781547546, variance: 0.8816160559654236\n",
      "Train size: [400] hidden size: [207] trial: 29, train_loss: 0.872316, test loss: 1.439533, bias2: 0.5626307129859924, variance: 0.8769026398658752\n",
      "Train size: [400] hidden size: [207] trial: 30, train_loss: 0.875176, test loss: 1.443928, bias2: 0.5622947216033936, variance: 0.8816328048706055\n",
      "Train size: [400] hidden size: [207] trial: 31, train_loss: 0.874759, test loss: 1.443119, bias2: 0.5638639330863953, variance: 0.879255473613739\n",
      "Train size: [400] hidden size: [207] trial: 32, train_loss: 0.871040, test loss: 1.438626, bias2: 0.5626851320266724, variance: 0.875941276550293\n",
      "Train size: [400] hidden size: [207] trial: 33, train_loss: 0.871735, test loss: 1.435981, bias2: 0.5586243867874146, variance: 0.8773571252822876\n",
      "Train size: [400] hidden size: [207] trial: 34, train_loss: 0.874594, test loss: 1.437500, bias2: 0.5542367696762085, variance: 0.8832628726959229\n",
      "Train size: [400] hidden size: [207] trial: 35, train_loss: 0.876013, test loss: 1.440194, bias2: 0.5534213185310364, variance: 0.8867729306221008\n",
      "Train size: [400] hidden size: [207] trial: 36, train_loss: 0.873016, test loss: 1.442871, bias2: 0.5563163161277771, variance: 0.8865541815757751\n",
      "Train size: [400] hidden size: [207] trial: 37, train_loss: 0.876454, test loss: 1.448565, bias2: 0.5552585124969482, variance: 0.8933063745498657\n",
      "Train size: [400] hidden size: [207] trial: 38, train_loss: 0.877717, test loss: 1.449203, bias2: 0.5535327196121216, variance: 0.8956702947616577\n",
      "Train size: [400] hidden size: [207] trial: 39, train_loss: 0.877088, test loss: 1.449929, bias2: 0.5545410513877869, variance: 0.8953883051872253\n",
      "Train size: [400] hidden size: [207] trial: 40, train_loss: 0.877499, test loss: 1.446327, bias2: 0.5546043515205383, variance: 0.8917228579521179\n",
      "Train size: [400] hidden size: [207] trial: 41, train_loss: 0.874701, test loss: 1.448045, bias2: 0.5547442436218262, variance: 0.8933007717132568\n",
      "Train size: [400] hidden size: [207] trial: 42, train_loss: 0.873590, test loss: 1.448347, bias2: 0.553734302520752, variance: 0.8946130275726318\n",
      "Train size: [400] hidden size: [207] trial: 43, train_loss: 0.875242, test loss: 1.445992, bias2: 0.5519054532051086, variance: 0.8940864205360413\n",
      "Train size: [400] hidden size: [207] trial: 44, train_loss: 0.873396, test loss: 1.443754, bias2: 0.551774799823761, variance: 0.8919788002967834\n",
      "Train size: [400] hidden size: [207] trial: 45, train_loss: 0.875871, test loss: 1.442574, bias2: 0.549037754535675, variance: 0.8935362696647644\n",
      "Train size: [400] hidden size: [207] trial: 46, train_loss: 0.875896, test loss: 1.441817, bias2: 0.5519503355026245, variance: 0.8898667097091675\n",
      "Train size: [400] hidden size: [207] trial: 47, train_loss: 0.874749, test loss: 1.440318, bias2: 0.5495721697807312, variance: 0.8907461762428284\n",
      "Train size: [400] hidden size: [207] trial: 48, train_loss: 0.878690, test loss: 1.441100, bias2: 0.5514701008796692, variance: 0.8896303772926331\n",
      "Train size: [400] hidden size: [207] trial: 49, train_loss: 0.876861, test loss: 1.438865, bias2: 0.5516183972358704, variance: 0.8872470259666443\n",
      "##################################################\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [239] trial: 0, train_loss: 0.854961, test loss: 1.607034, bias2: 1.6070342063903809, variance: -4.6710577628061856e-09\n",
      "Train size: [400] hidden size: [239] trial: 1, train_loss: 0.797583, test loss: 1.508613, bias2: 1.0258750915527344, variance: 0.4827379882335663\n",
      "Train size: [400] hidden size: [239] trial: 2, train_loss: 0.806089, test loss: 1.521725, bias2: 0.8392072916030884, variance: 0.6825175285339355\n",
      "Train size: [400] hidden size: [239] trial: 3, train_loss: 0.784885, test loss: 1.523511, bias2: 0.7493507266044617, variance: 0.7741600871086121\n",
      "Train size: [400] hidden size: [239] trial: 4, train_loss: 0.801821, test loss: 1.501518, bias2: 0.702480137348175, variance: 0.799037754535675\n",
      "Train size: [400] hidden size: [239] trial: 5, train_loss: 0.791862, test loss: 1.489814, bias2: 0.6701051592826843, variance: 0.8197090029716492\n",
      "Train size: [400] hidden size: [239] trial: 6, train_loss: 0.780267, test loss: 1.492346, bias2: 0.6526858806610107, variance: 0.8396602869033813\n",
      "Train size: [400] hidden size: [239] trial: 7, train_loss: 0.774956, test loss: 1.480225, bias2: 0.6422452330589294, variance: 0.8379796147346497\n",
      "Train size: [400] hidden size: [239] trial: 8, train_loss: 0.775028, test loss: 1.483429, bias2: 0.6339110136032104, variance: 0.8495181798934937\n",
      "Train size: [400] hidden size: [239] trial: 9, train_loss: 0.780564, test loss: 1.470378, bias2: 0.6122379302978516, variance: 0.8581401109695435\n",
      "Train size: [400] hidden size: [239] trial: 10, train_loss: 0.791253, test loss: 1.481627, bias2: 0.6069117188453674, variance: 0.8747149109840393\n",
      "Train size: [400] hidden size: [239] trial: 11, train_loss: 0.778169, test loss: 1.483691, bias2: 0.6097303628921509, variance: 0.8739608526229858\n",
      "Train size: [400] hidden size: [239] trial: 12, train_loss: 0.787955, test loss: 1.473904, bias2: 0.5988384485244751, variance: 0.8750652074813843\n",
      "Train size: [400] hidden size: [239] trial: 13, train_loss: 0.790984, test loss: 1.466378, bias2: 0.5910027623176575, variance: 0.8753747344017029\n",
      "Train size: [400] hidden size: [239] trial: 14, train_loss: 0.792046, test loss: 1.470349, bias2: 0.5853766202926636, variance: 0.884972095489502\n",
      "Train size: [400] hidden size: [239] trial: 15, train_loss: 0.800451, test loss: 1.467332, bias2: 0.5861807465553284, variance: 0.8811511397361755\n",
      "Train size: [400] hidden size: [239] trial: 16, train_loss: 0.791033, test loss: 1.454044, bias2: 0.5817114114761353, variance: 0.8723330497741699\n",
      "Train size: [400] hidden size: [239] trial: 17, train_loss: 0.795381, test loss: 1.438596, bias2: 0.5715092420578003, variance: 0.8670871257781982\n",
      "Train size: [400] hidden size: [239] trial: 18, train_loss: 0.797647, test loss: 1.442150, bias2: 0.5660922527313232, variance: 0.8760577440261841\n",
      "Train size: [400] hidden size: [239] trial: 19, train_loss: 0.801640, test loss: 1.435314, bias2: 0.5546181797981262, variance: 0.8806958794593811\n",
      "Train size: [400] hidden size: [239] trial: 20, train_loss: 0.804251, test loss: 1.430568, bias2: 0.5445601344108582, variance: 0.8860074877738953\n",
      "Train size: [400] hidden size: [239] trial: 21, train_loss: 0.801360, test loss: 1.429475, bias2: 0.5399855971336365, variance: 0.8894898295402527\n",
      "Train size: [400] hidden size: [239] trial: 22, train_loss: 0.802898, test loss: 1.435557, bias2: 0.5380591154098511, variance: 0.8974981307983398\n",
      "Train size: [400] hidden size: [239] trial: 23, train_loss: 0.803324, test loss: 1.439596, bias2: 0.5361632108688354, variance: 0.9034332036972046\n",
      "Train size: [400] hidden size: [239] trial: 24, train_loss: 0.802623, test loss: 1.443354, bias2: 0.5323718190193176, variance: 0.9109817147254944\n",
      "Train size: [400] hidden size: [239] trial: 25, train_loss: 0.803086, test loss: 1.438787, bias2: 0.530117928981781, variance: 0.9086694121360779\n",
      "Train size: [400] hidden size: [239] trial: 26, train_loss: 0.804037, test loss: 1.441163, bias2: 0.5287282466888428, variance: 0.9124352931976318\n",
      "Train size: [400] hidden size: [239] trial: 27, train_loss: 0.807055, test loss: 1.439184, bias2: 0.5252069234848022, variance: 0.9139771461486816\n",
      "Train size: [400] hidden size: [239] trial: 28, train_loss: 0.806688, test loss: 1.441200, bias2: 0.5243144631385803, variance: 0.9168856739997864\n",
      "Train size: [400] hidden size: [239] trial: 29, train_loss: 0.806896, test loss: 1.445387, bias2: 0.5228712558746338, variance: 0.9225157499313354\n",
      "Train size: [400] hidden size: [239] trial: 30, train_loss: 0.804899, test loss: 1.442682, bias2: 0.5175842046737671, variance: 0.9250977039337158\n",
      "Train size: [400] hidden size: [239] trial: 31, train_loss: 0.810311, test loss: 1.441616, bias2: 0.5154524445533752, variance: 0.9261639714241028\n",
      "Train size: [400] hidden size: [239] trial: 32, train_loss: 0.811645, test loss: 1.438981, bias2: 0.5161702036857605, variance: 0.9228107333183289\n",
      "Train size: [400] hidden size: [239] trial: 33, train_loss: 0.807818, test loss: 1.436956, bias2: 0.5158411860466003, variance: 0.9211143851280212\n",
      "Train size: [400] hidden size: [239] trial: 34, train_loss: 0.810929, test loss: 1.436248, bias2: 0.513755202293396, variance: 0.9224929809570312\n",
      "Train size: [400] hidden size: [239] trial: 35, train_loss: 0.809790, test loss: 1.435226, bias2: 0.512830913066864, variance: 0.9223954081535339\n",
      "Train size: [400] hidden size: [239] trial: 36, train_loss: 0.808870, test loss: 1.433540, bias2: 0.5099495649337769, variance: 0.9235904216766357\n",
      "Train size: [400] hidden size: [239] trial: 37, train_loss: 0.811019, test loss: 1.433484, bias2: 0.511705219745636, variance: 0.9217788577079773\n",
      "Train size: [400] hidden size: [239] trial: 38, train_loss: 0.805765, test loss: 1.435895, bias2: 0.5130931735038757, variance: 0.9228014349937439\n",
      "Train size: [400] hidden size: [239] trial: 39, train_loss: 0.804087, test loss: 1.433151, bias2: 0.5123551487922668, variance: 0.9207959771156311\n",
      "Train size: [400] hidden size: [239] trial: 40, train_loss: 0.803547, test loss: 1.432775, bias2: 0.5115310549736023, variance: 0.9212436079978943\n",
      "Train size: [400] hidden size: [239] trial: 41, train_loss: 0.803289, test loss: 1.434334, bias2: 0.5118502378463745, variance: 0.9224836826324463\n",
      "Train size: [400] hidden size: [239] trial: 42, train_loss: 0.804244, test loss: 1.431074, bias2: 0.5093518495559692, variance: 0.9217220544815063\n",
      "Train size: [400] hidden size: [239] trial: 43, train_loss: 0.802503, test loss: 1.426653, bias2: 0.5080801844596863, variance: 0.918572723865509\n",
      "Train size: [400] hidden size: [239] trial: 44, train_loss: 0.801215, test loss: 1.427364, bias2: 0.5078449249267578, variance: 0.9195194244384766\n",
      "Train size: [400] hidden size: [239] trial: 45, train_loss: 0.800636, test loss: 1.432377, bias2: 0.5082547664642334, variance: 0.9241218566894531\n",
      "Train size: [400] hidden size: [239] trial: 46, train_loss: 0.801373, test loss: 1.434250, bias2: 0.5088889598846436, variance: 0.9253612756729126\n",
      "Train size: [400] hidden size: [239] trial: 47, train_loss: 0.802046, test loss: 1.435485, bias2: 0.5082390904426575, variance: 0.9272461533546448\n",
      "Train size: [400] hidden size: [239] trial: 48, train_loss: 0.802099, test loss: 1.436040, bias2: 0.5080872178077698, variance: 0.9279524683952332\n",
      "Train size: [400] hidden size: [239] trial: 49, train_loss: 0.804254, test loss: 1.436351, bias2: 0.508757472038269, variance: 0.9275929927825928\n",
      "##################################################\n",
      "Train size: [400] hidden size: [275] trial: 0, train_loss: 0.753669, test loss: 1.601109, bias2: 1.601109266281128, variance: 3.1140383605077204e-09\n",
      "Train size: [400] hidden size: [275] trial: 1, train_loss: 0.727710, test loss: 1.546258, bias2: 0.9425912499427795, variance: 0.6036671996116638\n",
      "Train size: [400] hidden size: [275] trial: 2, train_loss: 0.738246, test loss: 1.509239, bias2: 0.7783977389335632, variance: 0.730841338634491\n",
      "Train size: [400] hidden size: [275] trial: 3, train_loss: 0.729955, test loss: 1.455883, bias2: 0.6997783184051514, variance: 0.756104588508606\n",
      "Train size: [400] hidden size: [275] trial: 4, train_loss: 0.744752, test loss: 1.476936, bias2: 0.6576634049415588, variance: 0.8192726969718933\n",
      "Train size: [400] hidden size: [275] trial: 5, train_loss: 0.736547, test loss: 1.488211, bias2: 0.6350843906402588, variance: 0.8531262874603271\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [275] trial: 6, train_loss: 0.733911, test loss: 1.473861, bias2: 0.610905647277832, variance: 0.86295485496521\n",
      "Train size: [400] hidden size: [275] trial: 7, train_loss: 0.723819, test loss: 1.464278, bias2: 0.5930711627006531, variance: 0.8712067008018494\n",
      "Train size: [400] hidden size: [275] trial: 8, train_loss: 0.715991, test loss: 1.472652, bias2: 0.5799276828765869, variance: 0.8927243947982788\n",
      "Train size: [400] hidden size: [275] trial: 9, train_loss: 0.712376, test loss: 1.463172, bias2: 0.5598878264427185, variance: 0.90328449010849\n",
      "Train size: [400] hidden size: [275] trial: 10, train_loss: 0.715969, test loss: 1.449883, bias2: 0.5555017590522766, variance: 0.8943814635276794\n",
      "Train size: [400] hidden size: [275] trial: 11, train_loss: 0.718391, test loss: 1.438546, bias2: 0.5498849153518677, variance: 0.8886607885360718\n",
      "Train size: [400] hidden size: [275] trial: 12, train_loss: 0.721567, test loss: 1.429862, bias2: 0.5434077978134155, variance: 0.8864541053771973\n",
      "Train size: [400] hidden size: [275] trial: 13, train_loss: 0.719763, test loss: 1.422376, bias2: 0.534642219543457, variance: 0.8877335786819458\n",
      "Train size: [400] hidden size: [275] trial: 14, train_loss: 0.718543, test loss: 1.414677, bias2: 0.5343322157859802, variance: 0.8803449273109436\n",
      "Train size: [400] hidden size: [275] trial: 15, train_loss: 0.712848, test loss: 1.414545, bias2: 0.5264177918434143, variance: 0.8881271481513977\n",
      "Train size: [400] hidden size: [275] trial: 16, train_loss: 0.714246, test loss: 1.419438, bias2: 0.5270724892616272, variance: 0.8923657536506653\n",
      "Train size: [400] hidden size: [275] trial: 17, train_loss: 0.711211, test loss: 1.417972, bias2: 0.5219504237174988, variance: 0.8960217833518982\n",
      "Train size: [400] hidden size: [275] trial: 18, train_loss: 0.706702, test loss: 1.418437, bias2: 0.5181952118873596, variance: 0.9002416729927063\n",
      "Train size: [400] hidden size: [275] trial: 19, train_loss: 0.706117, test loss: 1.417135, bias2: 0.5155577659606934, variance: 0.9015767574310303\n",
      "Train size: [400] hidden size: [275] trial: 20, train_loss: 0.704466, test loss: 1.419542, bias2: 0.5143581628799438, variance: 0.9051839113235474\n",
      "Train size: [400] hidden size: [275] trial: 21, train_loss: 0.706753, test loss: 1.422675, bias2: 0.5159648060798645, variance: 0.9067098498344421\n",
      "Train size: [400] hidden size: [275] trial: 22, train_loss: 0.710535, test loss: 1.419006, bias2: 0.5140100121498108, variance: 0.9049956202507019\n",
      "Train size: [400] hidden size: [275] trial: 23, train_loss: 0.706042, test loss: 1.422526, bias2: 0.5120575428009033, variance: 0.910468578338623\n",
      "Train size: [400] hidden size: [275] trial: 24, train_loss: 0.709776, test loss: 1.421001, bias2: 0.511496901512146, variance: 0.9095044136047363\n",
      "Train size: [400] hidden size: [275] trial: 25, train_loss: 0.710357, test loss: 1.422777, bias2: 0.5135160684585571, variance: 0.9092614650726318\n",
      "Train size: [400] hidden size: [275] trial: 26, train_loss: 0.707277, test loss: 1.418524, bias2: 0.5109752416610718, variance: 0.9075486660003662\n",
      "Train size: [400] hidden size: [275] trial: 27, train_loss: 0.702099, test loss: 1.416564, bias2: 0.5115511417388916, variance: 0.905012845993042\n",
      "Train size: [400] hidden size: [275] trial: 28, train_loss: 0.705051, test loss: 1.415872, bias2: 0.5109995007514954, variance: 0.904872715473175\n",
      "Train size: [400] hidden size: [275] trial: 29, train_loss: 0.702501, test loss: 1.413340, bias2: 0.5079294443130493, variance: 0.9054102897644043\n",
      "Train size: [400] hidden size: [275] trial: 30, train_loss: 0.699024, test loss: 1.415450, bias2: 0.5081479549407959, variance: 0.9073021411895752\n",
      "Train size: [400] hidden size: [275] trial: 31, train_loss: 0.700533, test loss: 1.414982, bias2: 0.5079740881919861, variance: 0.9070077538490295\n",
      "Train size: [400] hidden size: [275] trial: 32, train_loss: 0.702754, test loss: 1.417055, bias2: 0.5055674910545349, variance: 0.911487877368927\n",
      "Train size: [400] hidden size: [275] trial: 33, train_loss: 0.705174, test loss: 1.418129, bias2: 0.5058026909828186, variance: 0.9123262763023376\n",
      "Train size: [400] hidden size: [275] trial: 34, train_loss: 0.703625, test loss: 1.414667, bias2: 0.5056513547897339, variance: 0.9090152978897095\n",
      "Train size: [400] hidden size: [275] trial: 35, train_loss: 0.703880, test loss: 1.413978, bias2: 0.5066730976104736, variance: 0.9073045253753662\n",
      "Train size: [400] hidden size: [275] trial: 36, train_loss: 0.697595, test loss: 1.409310, bias2: 0.5044859647750854, variance: 0.9048236608505249\n",
      "Train size: [400] hidden size: [275] trial: 37, train_loss: 0.697642, test loss: 1.405218, bias2: 0.5022546648979187, variance: 0.902962863445282\n",
      "Train size: [400] hidden size: [275] trial: 38, train_loss: 0.696441, test loss: 1.403446, bias2: 0.502631425857544, variance: 0.9008148908615112\n",
      "Train size: [400] hidden size: [275] trial: 39, train_loss: 0.695205, test loss: 1.399355, bias2: 0.5007667541503906, variance: 0.8985885381698608\n",
      "Train size: [400] hidden size: [275] trial: 40, train_loss: 0.696387, test loss: 1.397175, bias2: 0.49926793575286865, variance: 0.897907018661499\n",
      "Train size: [400] hidden size: [275] trial: 41, train_loss: 0.694839, test loss: 1.399796, bias2: 0.498821496963501, variance: 0.9009748697280884\n",
      "Train size: [400] hidden size: [275] trial: 42, train_loss: 0.697580, test loss: 1.401890, bias2: 0.49753350019454956, variance: 0.9043561816215515\n",
      "Train size: [400] hidden size: [275] trial: 43, train_loss: 0.696542, test loss: 1.400269, bias2: 0.49560075998306274, variance: 0.9046680331230164\n",
      "Train size: [400] hidden size: [275] trial: 44, train_loss: 0.695232, test loss: 1.396209, bias2: 0.49453169107437134, variance: 0.901677668094635\n",
      "Train size: [400] hidden size: [275] trial: 45, train_loss: 0.694634, test loss: 1.395591, bias2: 0.4953436851501465, variance: 0.9002472162246704\n",
      "Train size: [400] hidden size: [275] trial: 46, train_loss: 0.697534, test loss: 1.396304, bias2: 0.489859938621521, variance: 0.9064444303512573\n",
      "Train size: [400] hidden size: [275] trial: 47, train_loss: 0.700064, test loss: 1.398574, bias2: 0.49125081300735474, variance: 0.9073230624198914\n",
      "Train size: [400] hidden size: [275] trial: 48, train_loss: 0.699260, test loss: 1.397980, bias2: 0.48993980884552, variance: 0.9080401659011841\n",
      "Train size: [400] hidden size: [275] trial: 49, train_loss: 0.699135, test loss: 1.397209, bias2: 0.4886704683303833, variance: 0.9085381031036377\n",
      "##################################################\n",
      "Train size: [400] hidden size: [316] trial: 0, train_loss: 0.664227, test loss: 1.499123, bias2: 1.4991228580474854, variance: 0.0\n",
      "Train size: [400] hidden size: [316] trial: 1, train_loss: 0.632798, test loss: 1.397286, bias2: 0.9258947372436523, variance: 0.47139132022857666\n",
      "Train size: [400] hidden size: [316] trial: 2, train_loss: 0.635890, test loss: 1.446628, bias2: 0.7955281138420105, variance: 0.6510995030403137\n",
      "Train size: [400] hidden size: [316] trial: 3, train_loss: 0.617359, test loss: 1.420455, bias2: 0.7070077061653137, variance: 0.7134469151496887\n",
      "Train size: [400] hidden size: [316] trial: 4, train_loss: 0.611540, test loss: 1.413025, bias2: 0.6578095555305481, variance: 0.755215585231781\n",
      "Train size: [400] hidden size: [316] trial: 5, train_loss: 0.604747, test loss: 1.404589, bias2: 0.61561518907547, variance: 0.7889735102653503\n",
      "Train size: [400] hidden size: [316] trial: 6, train_loss: 0.625782, test loss: 1.389709, bias2: 0.5785403847694397, variance: 0.8111681342124939\n",
      "Train size: [400] hidden size: [316] trial: 7, train_loss: 0.629506, test loss: 1.378657, bias2: 0.5608230829238892, variance: 0.8178342580795288\n",
      "Train size: [400] hidden size: [316] trial: 8, train_loss: 0.630616, test loss: 1.383080, bias2: 0.5601344704627991, variance: 0.8229455351829529\n",
      "Train size: [400] hidden size: [316] trial: 9, train_loss: 0.633216, test loss: 1.386692, bias2: 0.555265486240387, variance: 0.831426203250885\n",
      "Train size: [400] hidden size: [316] trial: 10, train_loss: 0.639674, test loss: 1.376299, bias2: 0.5387784242630005, variance: 0.8375210762023926\n",
      "Train size: [400] hidden size: [316] trial: 11, train_loss: 0.641492, test loss: 1.362655, bias2: 0.5190154910087585, variance: 0.8436394333839417\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [316] trial: 12, train_loss: 0.635111, test loss: 1.360910, bias2: 0.5152584910392761, variance: 0.8456510901451111\n",
      "Train size: [400] hidden size: [316] trial: 13, train_loss: 0.632015, test loss: 1.364405, bias2: 0.5128983855247498, variance: 0.8515062928199768\n",
      "Train size: [400] hidden size: [316] trial: 14, train_loss: 0.629542, test loss: 1.360649, bias2: 0.5045483708381653, variance: 0.8561007380485535\n",
      "Train size: [400] hidden size: [316] trial: 15, train_loss: 0.623064, test loss: 1.359359, bias2: 0.5039954781532288, variance: 0.8553633093833923\n",
      "Train size: [400] hidden size: [316] trial: 16, train_loss: 0.625809, test loss: 1.360355, bias2: 0.499747633934021, variance: 0.8606072664260864\n",
      "Train size: [400] hidden size: [316] trial: 17, train_loss: 0.624726, test loss: 1.354639, bias2: 0.49368607997894287, variance: 0.8609530925750732\n",
      "Train size: [400] hidden size: [316] trial: 18, train_loss: 0.630692, test loss: 1.355723, bias2: 0.4887639284133911, variance: 0.8669594526290894\n",
      "Train size: [400] hidden size: [316] trial: 19, train_loss: 0.634698, test loss: 1.355153, bias2: 0.4887382984161377, variance: 0.8664151430130005\n",
      "Train size: [400] hidden size: [316] trial: 20, train_loss: 0.640692, test loss: 1.355814, bias2: 0.4868178963661194, variance: 0.8689964413642883\n",
      "Train size: [400] hidden size: [316] trial: 21, train_loss: 0.634709, test loss: 1.357646, bias2: 0.48875510692596436, variance: 0.8688905239105225\n",
      "Train size: [400] hidden size: [316] trial: 22, train_loss: 0.629978, test loss: 1.355762, bias2: 0.48439985513687134, variance: 0.8713626265525818\n",
      "Train size: [400] hidden size: [316] trial: 23, train_loss: 0.625454, test loss: 1.352809, bias2: 0.480892539024353, variance: 0.8719161748886108\n",
      "Train size: [400] hidden size: [316] trial: 24, train_loss: 0.621199, test loss: 1.348583, bias2: 0.47776079177856445, variance: 0.8708226680755615\n",
      "Train size: [400] hidden size: [316] trial: 25, train_loss: 0.620609, test loss: 1.345535, bias2: 0.4728444814682007, variance: 0.8726906776428223\n",
      "Train size: [400] hidden size: [316] trial: 26, train_loss: 0.618444, test loss: 1.348721, bias2: 0.47463297843933105, variance: 0.8740881681442261\n",
      "Train size: [400] hidden size: [316] trial: 27, train_loss: 0.616673, test loss: 1.349756, bias2: 0.4710020422935486, variance: 0.8787543177604675\n",
      "Train size: [400] hidden size: [316] trial: 28, train_loss: 0.613992, test loss: 1.349081, bias2: 0.47249096632003784, variance: 0.876589834690094\n",
      "Train size: [400] hidden size: [316] trial: 29, train_loss: 0.611274, test loss: 1.352877, bias2: 0.47589927911758423, variance: 0.8769778609275818\n",
      "Train size: [400] hidden size: [316] trial: 30, train_loss: 0.609491, test loss: 1.351451, bias2: 0.47414225339889526, variance: 0.8773091435432434\n",
      "Train size: [400] hidden size: [316] trial: 31, train_loss: 0.609916, test loss: 1.351607, bias2: 0.47299444675445557, variance: 0.8786120414733887\n",
      "Train size: [400] hidden size: [316] trial: 32, train_loss: 0.609244, test loss: 1.351845, bias2: 0.47125959396362305, variance: 0.8805850744247437\n",
      "Train size: [400] hidden size: [316] trial: 33, train_loss: 0.608361, test loss: 1.354755, bias2: 0.4696117639541626, variance: 0.8851433992385864\n",
      "Train size: [400] hidden size: [316] trial: 34, train_loss: 0.610696, test loss: 1.357224, bias2: 0.4701768159866333, variance: 0.8870474100112915\n",
      "Train size: [400] hidden size: [316] trial: 35, train_loss: 0.607289, test loss: 1.357230, bias2: 0.47205257415771484, variance: 0.8851771354675293\n",
      "Train size: [400] hidden size: [316] trial: 36, train_loss: 0.608473, test loss: 1.364624, bias2: 0.4736294746398926, variance: 0.8909949064254761\n",
      "Train size: [400] hidden size: [316] trial: 37, train_loss: 0.607571, test loss: 1.364674, bias2: 0.47276216745376587, variance: 0.8919121623039246\n",
      "Train size: [400] hidden size: [316] trial: 38, train_loss: 0.605503, test loss: 1.362880, bias2: 0.46886056661605835, variance: 0.8940194249153137\n",
      "Train size: [400] hidden size: [316] trial: 39, train_loss: 0.603730, test loss: 1.363329, bias2: 0.46758341789245605, variance: 0.8957459926605225\n",
      "Train size: [400] hidden size: [316] trial: 40, train_loss: 0.604787, test loss: 1.364714, bias2: 0.46528929471969604, variance: 0.8994244933128357\n",
      "Train size: [400] hidden size: [316] trial: 41, train_loss: 0.603615, test loss: 1.361863, bias2: 0.46511518955230713, variance: 0.8967474699020386\n",
      "Train size: [400] hidden size: [316] trial: 42, train_loss: 0.602123, test loss: 1.360275, bias2: 0.4614836573600769, variance: 0.898791491985321\n",
      "Train size: [400] hidden size: [316] trial: 43, train_loss: 0.600874, test loss: 1.359072, bias2: 0.46133852005004883, variance: 0.8977339267730713\n",
      "Train size: [400] hidden size: [316] trial: 44, train_loss: 0.601686, test loss: 1.358810, bias2: 0.46008098125457764, variance: 0.8987293243408203\n",
      "Train size: [400] hidden size: [316] trial: 45, train_loss: 0.601770, test loss: 1.358622, bias2: 0.45977967977523804, variance: 0.8988425135612488\n",
      "Train size: [400] hidden size: [316] trial: 46, train_loss: 0.602183, test loss: 1.357171, bias2: 0.4579163193702698, variance: 0.899255096912384\n",
      "Train size: [400] hidden size: [316] trial: 47, train_loss: 0.602394, test loss: 1.360150, bias2: 0.45692962408065796, variance: 0.9032207131385803\n",
      "Train size: [400] hidden size: [316] trial: 48, train_loss: 0.602729, test loss: 1.360551, bias2: 0.457960307598114, variance: 0.9025905728340149\n",
      "Train size: [400] hidden size: [316] trial: 49, train_loss: 0.602071, test loss: 1.359525, bias2: 0.4563848376274109, variance: 0.9031397700309753\n",
      "##################################################\n",
      "Train size: [400] hidden size: [364] trial: 0, train_loss: 0.595116, test loss: 1.290952, bias2: 1.2909517288208008, variance: 2.3355288814030928e-09\n",
      "Train size: [400] hidden size: [364] trial: 1, train_loss: 0.557641, test loss: 1.311298, bias2: 0.8896777033805847, variance: 0.42162007093429565\n",
      "Train size: [400] hidden size: [364] trial: 2, train_loss: 0.548661, test loss: 1.307485, bias2: 0.7378472685813904, variance: 0.5696372389793396\n",
      "Train size: [400] hidden size: [364] trial: 3, train_loss: 0.532771, test loss: 1.308265, bias2: 0.6400570273399353, variance: 0.6682080626487732\n",
      "Train size: [400] hidden size: [364] trial: 4, train_loss: 0.505520, test loss: 1.289104, bias2: 0.5808285474777222, variance: 0.7082751989364624\n",
      "Train size: [400] hidden size: [364] trial: 5, train_loss: 0.499983, test loss: 1.292467, bias2: 0.5547059774398804, variance: 0.7377609014511108\n",
      "Train size: [400] hidden size: [364] trial: 6, train_loss: 0.517999, test loss: 1.290081, bias2: 0.5319844484329224, variance: 0.7580965757369995\n",
      "Train size: [400] hidden size: [364] trial: 7, train_loss: 0.521004, test loss: 1.295712, bias2: 0.5270209908485413, variance: 0.7686914801597595\n",
      "Train size: [400] hidden size: [364] trial: 8, train_loss: 0.533068, test loss: 1.305559, bias2: 0.5166825652122498, variance: 0.788876473903656\n",
      "Train size: [400] hidden size: [364] trial: 9, train_loss: 0.529682, test loss: 1.319449, bias2: 0.5139752626419067, variance: 0.805473804473877\n",
      "Train size: [400] hidden size: [364] trial: 10, train_loss: 0.525238, test loss: 1.321549, bias2: 0.5114445686340332, variance: 0.810104489326477\n",
      "Train size: [400] hidden size: [364] trial: 11, train_loss: 0.529072, test loss: 1.318423, bias2: 0.5041489005088806, variance: 0.8142741322517395\n",
      "Train size: [400] hidden size: [364] trial: 12, train_loss: 0.526756, test loss: 1.319330, bias2: 0.4984942078590393, variance: 0.8208360075950623\n",
      "Train size: [400] hidden size: [364] trial: 13, train_loss: 0.519969, test loss: 1.311516, bias2: 0.4898897409439087, variance: 0.8216266632080078\n",
      "Train size: [400] hidden size: [364] trial: 14, train_loss: 0.524668, test loss: 1.318902, bias2: 0.4846060872077942, variance: 0.8342954516410828\n",
      "Train size: [400] hidden size: [364] trial: 15, train_loss: 0.524742, test loss: 1.321196, bias2: 0.4811755418777466, variance: 0.8400200605392456\n",
      "Train size: [400] hidden size: [364] trial: 16, train_loss: 0.525603, test loss: 1.321432, bias2: 0.48154157400131226, variance: 0.8398907780647278\n",
      "Train size: [400] hidden size: [364] trial: 17, train_loss: 0.523904, test loss: 1.323646, bias2: 0.47791045904159546, variance: 0.8457357287406921\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [364] trial: 18, train_loss: 0.522419, test loss: 1.324242, bias2: 0.4757152199745178, variance: 0.8485265374183655\n",
      "Train size: [400] hidden size: [364] trial: 19, train_loss: 0.520560, test loss: 1.320931, bias2: 0.47721409797668457, variance: 0.8437172174453735\n",
      "Train size: [400] hidden size: [364] trial: 20, train_loss: 0.518724, test loss: 1.321330, bias2: 0.47590208053588867, variance: 0.8454279899597168\n",
      "Train size: [400] hidden size: [364] trial: 21, train_loss: 0.519017, test loss: 1.321026, bias2: 0.47779399156570435, variance: 0.8432318568229675\n",
      "Train size: [400] hidden size: [364] trial: 22, train_loss: 0.518447, test loss: 1.318253, bias2: 0.47467517852783203, variance: 0.8435782194137573\n",
      "Train size: [400] hidden size: [364] trial: 23, train_loss: 0.521799, test loss: 1.317934, bias2: 0.4701622724533081, variance: 0.8477715253829956\n",
      "Train size: [400] hidden size: [364] trial: 24, train_loss: 0.523989, test loss: 1.323357, bias2: 0.47078216075897217, variance: 0.8525747060775757\n",
      "Train size: [400] hidden size: [364] trial: 25, train_loss: 0.524766, test loss: 1.320384, bias2: 0.46441835165023804, variance: 0.8559659123420715\n",
      "Train size: [400] hidden size: [364] trial: 26, train_loss: 0.526622, test loss: 1.324540, bias2: 0.46684277057647705, variance: 0.8576968908309937\n",
      "Train size: [400] hidden size: [364] trial: 27, train_loss: 0.527990, test loss: 1.327282, bias2: 0.466924250125885, variance: 0.8603577017784119\n",
      "Train size: [400] hidden size: [364] trial: 28, train_loss: 0.524469, test loss: 1.324099, bias2: 0.46269261837005615, variance: 0.8614062070846558\n",
      "Train size: [400] hidden size: [364] trial: 29, train_loss: 0.525323, test loss: 1.329420, bias2: 0.4628314971923828, variance: 0.8665889501571655\n",
      "Train size: [400] hidden size: [364] trial: 30, train_loss: 0.527162, test loss: 1.326651, bias2: 0.45987391471862793, variance: 0.8667773008346558\n",
      "Train size: [400] hidden size: [364] trial: 31, train_loss: 0.526090, test loss: 1.326310, bias2: 0.4589788317680359, variance: 0.8673314452171326\n",
      "Train size: [400] hidden size: [364] trial: 32, train_loss: 0.524349, test loss: 1.326441, bias2: 0.46031248569488525, variance: 0.8661280870437622\n",
      "Train size: [400] hidden size: [364] trial: 33, train_loss: 0.524498, test loss: 1.323931, bias2: 0.46195244789123535, variance: 0.8619787693023682\n",
      "Train size: [400] hidden size: [364] trial: 34, train_loss: 0.525157, test loss: 1.326882, bias2: 0.45985740423202515, variance: 0.8670249581336975\n",
      "Train size: [400] hidden size: [364] trial: 35, train_loss: 0.526408, test loss: 1.327529, bias2: 0.4594157338142395, variance: 0.8681129813194275\n",
      "Train size: [400] hidden size: [364] trial: 36, train_loss: 0.527350, test loss: 1.326432, bias2: 0.4585142135620117, variance: 0.8679178953170776\n",
      "Train size: [400] hidden size: [364] trial: 37, train_loss: 0.529829, test loss: 1.324721, bias2: 0.4544541835784912, variance: 0.8702670335769653\n",
      "Train size: [400] hidden size: [364] trial: 38, train_loss: 0.530566, test loss: 1.324060, bias2: 0.452289342880249, variance: 0.8717707395553589\n",
      "Train size: [400] hidden size: [364] trial: 39, train_loss: 0.530627, test loss: 1.323163, bias2: 0.452484667301178, variance: 0.8706788420677185\n",
      "Train size: [400] hidden size: [364] trial: 40, train_loss: 0.533149, test loss: 1.321998, bias2: 0.4495049715042114, variance: 0.872492790222168\n",
      "Train size: [400] hidden size: [364] trial: 41, train_loss: 0.533945, test loss: 1.323258, bias2: 0.45062685012817383, variance: 0.8726315498352051\n",
      "Train size: [400] hidden size: [364] trial: 42, train_loss: 0.534472, test loss: 1.322850, bias2: 0.4509071111679077, variance: 0.8719426393508911\n",
      "Train size: [400] hidden size: [364] trial: 43, train_loss: 0.535052, test loss: 1.325942, bias2: 0.45144200325012207, variance: 0.8744999170303345\n",
      "Train size: [400] hidden size: [364] trial: 44, train_loss: 0.533822, test loss: 1.325002, bias2: 0.45111507177352905, variance: 0.8738871216773987\n",
      "Train size: [400] hidden size: [364] trial: 45, train_loss: 0.532449, test loss: 1.321343, bias2: 0.448947548866272, variance: 0.872395396232605\n",
      "Train size: [400] hidden size: [364] trial: 46, train_loss: 0.531334, test loss: 1.323654, bias2: 0.45181381702423096, variance: 0.8718407154083252\n",
      "Train size: [400] hidden size: [364] trial: 47, train_loss: 0.531056, test loss: 1.323436, bias2: 0.45205068588256836, variance: 0.8713855743408203\n",
      "Train size: [400] hidden size: [364] trial: 48, train_loss: 0.531017, test loss: 1.320946, bias2: 0.4504033327102661, variance: 0.8705428838729858\n",
      "Train size: [400] hidden size: [364] trial: 49, train_loss: 0.530317, test loss: 1.321019, bias2: 0.4486313462257385, variance: 0.8723872303962708\n",
      "##################################################\n",
      "Train size: [400] hidden size: [419] trial: 0, train_loss: 0.450863, test loss: 1.328144, bias2: 1.3281437158584595, variance: 2.3355288814030928e-09\n",
      "Train size: [400] hidden size: [419] trial: 1, train_loss: 0.454216, test loss: 1.288040, bias2: 0.8122549653053284, variance: 0.4757848381996155\n",
      "Train size: [400] hidden size: [419] trial: 2, train_loss: 0.451311, test loss: 1.261894, bias2: 0.659346342086792, variance: 0.6025477647781372\n",
      "Train size: [400] hidden size: [419] trial: 3, train_loss: 0.445062, test loss: 1.255316, bias2: 0.5967177152633667, variance: 0.6585979461669922\n",
      "Train size: [400] hidden size: [419] trial: 4, train_loss: 0.453526, test loss: 1.286408, bias2: 0.5738825798034668, variance: 0.712525486946106\n",
      "Train size: [400] hidden size: [419] trial: 5, train_loss: 0.446318, test loss: 1.270958, bias2: 0.5504432320594788, variance: 0.720514714717865\n",
      "Train size: [400] hidden size: [419] trial: 6, train_loss: 0.447244, test loss: 1.268424, bias2: 0.5293196439743042, variance: 0.7391039133071899\n",
      "Train size: [400] hidden size: [419] trial: 7, train_loss: 0.457013, test loss: 1.275422, bias2: 0.5195721387863159, variance: 0.7558498382568359\n",
      "Train size: [400] hidden size: [419] trial: 8, train_loss: 0.456895, test loss: 1.257921, bias2: 0.5008462071418762, variance: 0.7570751309394836\n",
      "Train size: [400] hidden size: [419] trial: 9, train_loss: 0.445818, test loss: 1.241135, bias2: 0.4847893714904785, variance: 0.7563461065292358\n",
      "Train size: [400] hidden size: [419] trial: 10, train_loss: 0.447902, test loss: 1.252459, bias2: 0.47791439294815063, variance: 0.7745446562767029\n",
      "Train size: [400] hidden size: [419] trial: 11, train_loss: 0.449243, test loss: 1.256947, bias2: 0.4735803008079529, variance: 0.783366858959198\n",
      "Train size: [400] hidden size: [419] trial: 12, train_loss: 0.448548, test loss: 1.249202, bias2: 0.4606900215148926, variance: 0.7885117530822754\n",
      "Train size: [400] hidden size: [419] trial: 13, train_loss: 0.449541, test loss: 1.254910, bias2: 0.4586191177368164, variance: 0.7962911128997803\n",
      "Train size: [400] hidden size: [419] trial: 14, train_loss: 0.453191, test loss: 1.254494, bias2: 0.45370835065841675, variance: 0.8007860779762268\n",
      "Train size: [400] hidden size: [419] trial: 15, train_loss: 0.452734, test loss: 1.256798, bias2: 0.453630268573761, variance: 0.8031681180000305\n",
      "Train size: [400] hidden size: [419] trial: 16, train_loss: 0.452156, test loss: 1.255689, bias2: 0.4529569745063782, variance: 0.8027321696281433\n",
      "Train size: [400] hidden size: [419] trial: 17, train_loss: 0.451157, test loss: 1.254762, bias2: 0.4542001485824585, variance: 0.8005620241165161\n",
      "Train size: [400] hidden size: [419] trial: 18, train_loss: 0.453686, test loss: 1.253569, bias2: 0.4491901397705078, variance: 0.8043787479400635\n",
      "Train size: [400] hidden size: [419] trial: 19, train_loss: 0.455734, test loss: 1.251574, bias2: 0.44651567935943604, variance: 0.8050585985183716\n",
      "Train size: [400] hidden size: [419] trial: 20, train_loss: 0.455142, test loss: 1.248363, bias2: 0.4437042474746704, variance: 0.8046585321426392\n",
      "Train size: [400] hidden size: [419] trial: 21, train_loss: 0.450718, test loss: 1.243525, bias2: 0.44096869230270386, variance: 0.8025566935539246\n",
      "Train size: [400] hidden size: [419] trial: 22, train_loss: 0.447780, test loss: 1.238467, bias2: 0.43548059463500977, variance: 0.8029863834381104\n",
      "Train size: [400] hidden size: [419] trial: 23, train_loss: 0.449065, test loss: 1.238804, bias2: 0.43208855390548706, variance: 0.8067154288291931\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [419] trial: 24, train_loss: 0.447175, test loss: 1.238413, bias2: 0.4313451051712036, variance: 0.8070676326751709\n",
      "Train size: [400] hidden size: [419] trial: 25, train_loss: 0.448903, test loss: 1.238625, bias2: 0.43050307035446167, variance: 0.8081217408180237\n",
      "Train size: [400] hidden size: [419] trial: 26, train_loss: 0.450122, test loss: 1.242286, bias2: 0.4337993860244751, variance: 0.808487057685852\n",
      "Train size: [400] hidden size: [419] trial: 27, train_loss: 0.450391, test loss: 1.237423, bias2: 0.4320579171180725, variance: 0.8053645491600037\n",
      "Train size: [400] hidden size: [419] trial: 28, train_loss: 0.452762, test loss: 1.238556, bias2: 0.43093574047088623, variance: 0.8076198101043701\n",
      "Train size: [400] hidden size: [419] trial: 29, train_loss: 0.452448, test loss: 1.235193, bias2: 0.42869096994400024, variance: 0.8065020442008972\n",
      "Train size: [400] hidden size: [419] trial: 30, train_loss: 0.451003, test loss: 1.233996, bias2: 0.428851842880249, variance: 0.8051439523696899\n",
      "Train size: [400] hidden size: [419] trial: 31, train_loss: 0.448548, test loss: 1.233216, bias2: 0.4268608093261719, variance: 0.8063549995422363\n",
      "Train size: [400] hidden size: [419] trial: 32, train_loss: 0.452841, test loss: 1.234770, bias2: 0.4280667304992676, variance: 0.8067035675048828\n",
      "Train size: [400] hidden size: [419] trial: 33, train_loss: 0.452797, test loss: 1.235911, bias2: 0.42816829681396484, variance: 0.8077428340911865\n",
      "Train size: [400] hidden size: [419] trial: 34, train_loss: 0.450610, test loss: 1.235855, bias2: 0.4285910129547119, variance: 0.8072642087936401\n",
      "Train size: [400] hidden size: [419] trial: 35, train_loss: 0.450856, test loss: 1.236642, bias2: 0.4295792579650879, variance: 0.8070623874664307\n",
      "Train size: [400] hidden size: [419] trial: 36, train_loss: 0.454064, test loss: 1.235435, bias2: 0.42829185724258423, variance: 0.8071433901786804\n",
      "Train size: [400] hidden size: [419] trial: 37, train_loss: 0.455886, test loss: 1.235292, bias2: 0.4246408939361572, variance: 0.8106511831283569\n",
      "Train size: [400] hidden size: [419] trial: 38, train_loss: 0.455296, test loss: 1.230274, bias2: 0.4237797260284424, variance: 0.8064947128295898\n",
      "Train size: [400] hidden size: [419] trial: 39, train_loss: 0.454416, test loss: 1.227889, bias2: 0.4239059090614319, variance: 0.8039827942848206\n",
      "Train size: [400] hidden size: [419] trial: 40, train_loss: 0.454365, test loss: 1.231013, bias2: 0.42493510246276855, variance: 0.8060781955718994\n",
      "Train size: [400] hidden size: [419] trial: 41, train_loss: 0.456883, test loss: 1.231034, bias2: 0.42286545038223267, variance: 0.8081688284873962\n",
      "Train size: [400] hidden size: [419] trial: 42, train_loss: 0.457457, test loss: 1.230820, bias2: 0.4206545352935791, variance: 0.8101658821105957\n",
      "Train size: [400] hidden size: [419] trial: 43, train_loss: 0.458248, test loss: 1.230701, bias2: 0.42002880573272705, variance: 0.810672402381897\n",
      "Train size: [400] hidden size: [419] trial: 44, train_loss: 0.457326, test loss: 1.231716, bias2: 0.4217938184738159, variance: 0.8099220991134644\n",
      "Train size: [400] hidden size: [419] trial: 45, train_loss: 0.457080, test loss: 1.234045, bias2: 0.42223721742630005, variance: 0.8118078112602234\n",
      "Train size: [400] hidden size: [419] trial: 46, train_loss: 0.455898, test loss: 1.235738, bias2: 0.42432713508605957, variance: 0.811410665512085\n",
      "Train size: [400] hidden size: [419] trial: 47, train_loss: 0.455678, test loss: 1.235573, bias2: 0.4228631854057312, variance: 0.8127101063728333\n",
      "Train size: [400] hidden size: [419] trial: 48, train_loss: 0.456296, test loss: 1.235925, bias2: 0.42154496908187866, variance: 0.8143801093101501\n",
      "Train size: [400] hidden size: [419] trial: 49, train_loss: 0.456196, test loss: 1.236682, bias2: 0.42047035694122314, variance: 0.816211462020874\n",
      "##################################################\n",
      "Train size: [400] hidden size: [483] trial: 0, train_loss: 0.394601, test loss: 1.404875, bias2: 1.4048751592636108, variance: 7.0065864221646734e-09\n",
      "Train size: [400] hidden size: [483] trial: 1, train_loss: 0.424148, test loss: 1.216907, bias2: 0.7987212538719177, variance: 0.4181860089302063\n",
      "Train size: [400] hidden size: [483] trial: 2, train_loss: 0.425092, test loss: 1.224677, bias2: 0.6722280383110046, variance: 0.552448570728302\n",
      "Train size: [400] hidden size: [483] trial: 3, train_loss: 0.446283, test loss: 1.224429, bias2: 0.6068906188011169, variance: 0.6175383925437927\n",
      "Train size: [400] hidden size: [483] trial: 4, train_loss: 0.433722, test loss: 1.211714, bias2: 0.5545303225517273, variance: 0.6571837067604065\n",
      "Train size: [400] hidden size: [483] trial: 5, train_loss: 0.429786, test loss: 1.218526, bias2: 0.5245422124862671, variance: 0.6939836740493774\n",
      "Train size: [400] hidden size: [483] trial: 6, train_loss: 0.423091, test loss: 1.211180, bias2: 0.5069888234138489, variance: 0.7041907906532288\n",
      "Train size: [400] hidden size: [483] trial: 7, train_loss: 0.420982, test loss: 1.220796, bias2: 0.5105783343315125, variance: 0.7102174162864685\n",
      "Train size: [400] hidden size: [483] trial: 8, train_loss: 0.426201, test loss: 1.232453, bias2: 0.5107386708259583, variance: 0.7217145562171936\n",
      "Train size: [400] hidden size: [483] trial: 9, train_loss: 0.420888, test loss: 1.221199, bias2: 0.49387985467910767, variance: 0.727319061756134\n",
      "Train size: [400] hidden size: [483] trial: 10, train_loss: 0.420391, test loss: 1.217361, bias2: 0.48397403955459595, variance: 0.733387291431427\n",
      "Train size: [400] hidden size: [483] trial: 11, train_loss: 0.419204, test loss: 1.214332, bias2: 0.4745863080024719, variance: 0.7397459149360657\n",
      "Train size: [400] hidden size: [483] trial: 12, train_loss: 0.419874, test loss: 1.209483, bias2: 0.4678729772567749, variance: 0.7416099309921265\n",
      "Train size: [400] hidden size: [483] trial: 13, train_loss: 0.421508, test loss: 1.207840, bias2: 0.46176600456237793, variance: 0.7460737228393555\n",
      "Train size: [400] hidden size: [483] trial: 14, train_loss: 0.418429, test loss: 1.203534, bias2: 0.45264291763305664, variance: 0.7508910894393921\n",
      "Train size: [400] hidden size: [483] trial: 15, train_loss: 0.418938, test loss: 1.205199, bias2: 0.44723695516586304, variance: 0.757962167263031\n",
      "Train size: [400] hidden size: [483] trial: 16, train_loss: 0.417666, test loss: 1.208843, bias2: 0.4446108341217041, variance: 0.7642325162887573\n",
      "Train size: [400] hidden size: [483] trial: 17, train_loss: 0.418243, test loss: 1.206901, bias2: 0.4419704079627991, variance: 0.7649300694465637\n",
      "Train size: [400] hidden size: [483] trial: 18, train_loss: 0.415080, test loss: 1.201637, bias2: 0.441325843334198, variance: 0.760310709476471\n",
      "Train size: [400] hidden size: [483] trial: 19, train_loss: 0.417762, test loss: 1.202244, bias2: 0.4392586350440979, variance: 0.7629849314689636\n",
      "Train size: [400] hidden size: [483] trial: 20, train_loss: 0.416290, test loss: 1.204704, bias2: 0.43643760681152344, variance: 0.7682663202285767\n",
      "Train size: [400] hidden size: [483] trial: 21, train_loss: 0.414993, test loss: 1.211679, bias2: 0.4382551312446594, variance: 0.7734236121177673\n",
      "Train size: [400] hidden size: [483] trial: 22, train_loss: 0.416358, test loss: 1.208459, bias2: 0.43409669399261475, variance: 0.7743619680404663\n",
      "Train size: [400] hidden size: [483] trial: 23, train_loss: 0.417920, test loss: 1.203720, bias2: 0.4303288459777832, variance: 0.7733910083770752\n",
      "Train size: [400] hidden size: [483] trial: 24, train_loss: 0.415451, test loss: 1.198019, bias2: 0.4262304902076721, variance: 0.7717882990837097\n",
      "Train size: [400] hidden size: [483] trial: 25, train_loss: 0.414864, test loss: 1.199537, bias2: 0.42888087034225464, variance: 0.7706560492515564\n",
      "Train size: [400] hidden size: [483] trial: 26, train_loss: 0.416525, test loss: 1.202812, bias2: 0.4274584650993347, variance: 0.7753539681434631\n",
      "Train size: [400] hidden size: [483] trial: 27, train_loss: 0.417225, test loss: 1.201297, bias2: 0.4284345507621765, variance: 0.7728623747825623\n",
      "Train size: [400] hidden size: [483] trial: 28, train_loss: 0.416518, test loss: 1.200981, bias2: 0.42870432138442993, variance: 0.7722763419151306\n",
      "Train size: [400] hidden size: [483] trial: 29, train_loss: 0.415183, test loss: 1.201755, bias2: 0.4301944375038147, variance: 0.7715609669685364\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [483] trial: 30, train_loss: 0.414228, test loss: 1.198732, bias2: 0.42828208208084106, variance: 0.7704499363899231\n",
      "Train size: [400] hidden size: [483] trial: 31, train_loss: 0.414478, test loss: 1.199428, bias2: 0.42852920293807983, variance: 0.7708987593650818\n",
      "Train size: [400] hidden size: [483] trial: 32, train_loss: 0.415000, test loss: 1.199833, bias2: 0.4278165102005005, variance: 0.7720170021057129\n",
      "Train size: [400] hidden size: [483] trial: 33, train_loss: 0.414867, test loss: 1.197590, bias2: 0.4251387119293213, variance: 0.7724510431289673\n",
      "Train size: [400] hidden size: [483] trial: 34, train_loss: 0.414333, test loss: 1.196517, bias2: 0.42315590381622314, variance: 0.7733607292175293\n",
      "Train size: [400] hidden size: [483] trial: 35, train_loss: 0.413147, test loss: 1.197039, bias2: 0.42292970418930054, variance: 0.7741089463233948\n",
      "Train size: [400] hidden size: [483] trial: 36, train_loss: 0.412688, test loss: 1.194763, bias2: 0.4188724756240845, variance: 0.775890588760376\n",
      "Train size: [400] hidden size: [483] trial: 37, train_loss: 0.412317, test loss: 1.193322, bias2: 0.419303834438324, variance: 0.7740185856819153\n",
      "Train size: [400] hidden size: [483] trial: 38, train_loss: 0.412288, test loss: 1.190562, bias2: 0.4185982346534729, variance: 0.7719637751579285\n",
      "Train size: [400] hidden size: [483] trial: 39, train_loss: 0.413077, test loss: 1.190059, bias2: 0.4164745807647705, variance: 0.7735844850540161\n",
      "Train size: [400] hidden size: [483] trial: 40, train_loss: 0.413155, test loss: 1.187880, bias2: 0.41629523038864136, variance: 0.7715849280357361\n",
      "Train size: [400] hidden size: [483] trial: 41, train_loss: 0.414120, test loss: 1.184017, bias2: 0.41404128074645996, variance: 0.7699754238128662\n",
      "Train size: [400] hidden size: [483] trial: 42, train_loss: 0.413416, test loss: 1.183609, bias2: 0.41276901960372925, variance: 0.7708399891853333\n",
      "Train size: [400] hidden size: [483] trial: 43, train_loss: 0.411918, test loss: 1.183460, bias2: 0.4127989411354065, variance: 0.7706606984138489\n",
      "Train size: [400] hidden size: [483] trial: 44, train_loss: 0.413104, test loss: 1.182299, bias2: 0.4101734757423401, variance: 0.772125780582428\n",
      "Train size: [400] hidden size: [483] trial: 45, train_loss: 0.413034, test loss: 1.183008, bias2: 0.4083271622657776, variance: 0.7746806740760803\n",
      "Train size: [400] hidden size: [483] trial: 46, train_loss: 0.412518, test loss: 1.181338, bias2: 0.40968579053878784, variance: 0.7716525197029114\n",
      "Train size: [400] hidden size: [483] trial: 47, train_loss: 0.413559, test loss: 1.181061, bias2: 0.4090820550918579, variance: 0.7719787359237671\n",
      "Train size: [400] hidden size: [483] trial: 48, train_loss: 0.413381, test loss: 1.178330, bias2: 0.40757715702056885, variance: 0.770753026008606\n",
      "Train size: [400] hidden size: [483] trial: 49, train_loss: 0.413748, test loss: 1.178462, bias2: 0.40768516063690186, variance: 0.7707767486572266\n",
      "##################################################\n",
      "Train size: [400] hidden size: [556] trial: 0, train_loss: 0.320439, test loss: 1.132752, bias2: 1.132751703262329, variance: 5.060312613380802e-09\n",
      "Train size: [400] hidden size: [556] trial: 1, train_loss: 0.326945, test loss: 1.116047, bias2: 0.7909709215164185, variance: 0.32507583498954773\n",
      "Train size: [400] hidden size: [556] trial: 2, train_loss: 0.315069, test loss: 1.105112, bias2: 0.6725151538848877, variance: 0.43259695172309875\n",
      "Train size: [400] hidden size: [556] trial: 3, train_loss: 0.318371, test loss: 1.101013, bias2: 0.6055128574371338, variance: 0.49550020694732666\n",
      "Train size: [400] hidden size: [556] trial: 4, train_loss: 0.333174, test loss: 1.097770, bias2: 0.5440641641616821, variance: 0.5537056922912598\n",
      "Train size: [400] hidden size: [556] trial: 5, train_loss: 0.336760, test loss: 1.098737, bias2: 0.523236095905304, variance: 0.5755007863044739\n",
      "Train size: [400] hidden size: [556] trial: 6, train_loss: 0.340812, test loss: 1.103324, bias2: 0.5131151676177979, variance: 0.5902091264724731\n",
      "Train size: [400] hidden size: [556] trial: 7, train_loss: 0.342346, test loss: 1.099493, bias2: 0.5014132261276245, variance: 0.5980801582336426\n",
      "Train size: [400] hidden size: [556] trial: 8, train_loss: 0.344537, test loss: 1.102101, bias2: 0.4860023856163025, variance: 0.6160982251167297\n",
      "Train size: [400] hidden size: [556] trial: 9, train_loss: 0.345662, test loss: 1.115202, bias2: 0.4817626476287842, variance: 0.6334395408630371\n",
      "Train size: [400] hidden size: [556] trial: 10, train_loss: 0.343652, test loss: 1.099978, bias2: 0.47167372703552246, variance: 0.6283046007156372\n",
      "Train size: [400] hidden size: [556] trial: 11, train_loss: 0.347246, test loss: 1.103521, bias2: 0.464424729347229, variance: 0.639096736907959\n",
      "Train size: [400] hidden size: [556] trial: 12, train_loss: 0.355401, test loss: 1.103177, bias2: 0.4562925696372986, variance: 0.6468847393989563\n",
      "Train size: [400] hidden size: [556] trial: 13, train_loss: 0.355449, test loss: 1.100154, bias2: 0.4475017786026001, variance: 0.6526527404785156\n",
      "Train size: [400] hidden size: [556] trial: 14, train_loss: 0.351561, test loss: 1.096767, bias2: 0.43710577487945557, variance: 0.6596609354019165\n",
      "Train size: [400] hidden size: [556] trial: 15, train_loss: 0.349439, test loss: 1.100015, bias2: 0.44355177879333496, variance: 0.656463623046875\n",
      "Train size: [400] hidden size: [556] trial: 16, train_loss: 0.347760, test loss: 1.096574, bias2: 0.43859249353408813, variance: 0.6579814553260803\n",
      "Train size: [400] hidden size: [556] trial: 17, train_loss: 0.346862, test loss: 1.098650, bias2: 0.43726491928100586, variance: 0.6613848209381104\n",
      "Train size: [400] hidden size: [556] trial: 18, train_loss: 0.348116, test loss: 1.099973, bias2: 0.4361588954925537, variance: 0.6638144254684448\n",
      "Train size: [400] hidden size: [556] trial: 19, train_loss: 0.346283, test loss: 1.105847, bias2: 0.436551570892334, variance: 0.6692953109741211\n",
      "Train size: [400] hidden size: [556] trial: 20, train_loss: 0.346509, test loss: 1.106722, bias2: 0.43492257595062256, variance: 0.6717997789382935\n",
      "Train size: [400] hidden size: [556] trial: 21, train_loss: 0.345350, test loss: 1.107033, bias2: 0.43199312686920166, variance: 0.6750400066375732\n",
      "Train size: [400] hidden size: [556] trial: 22, train_loss: 0.346524, test loss: 1.106316, bias2: 0.4295211434364319, variance: 0.6767951846122742\n",
      "Train size: [400] hidden size: [556] trial: 23, train_loss: 0.345972, test loss: 1.107220, bias2: 0.4285009503364563, variance: 0.6787191033363342\n",
      "Train size: [400] hidden size: [556] trial: 24, train_loss: 0.345139, test loss: 1.104349, bias2: 0.423750102519989, variance: 0.6805985569953918\n",
      "Train size: [400] hidden size: [556] trial: 25, train_loss: 0.344077, test loss: 1.104417, bias2: 0.4219704270362854, variance: 0.682446300983429\n",
      "Train size: [400] hidden size: [556] trial: 26, train_loss: 0.346808, test loss: 1.106061, bias2: 0.4201192259788513, variance: 0.6859416365623474\n",
      "Train size: [400] hidden size: [556] trial: 27, train_loss: 0.348476, test loss: 1.110017, bias2: 0.4217519760131836, variance: 0.6882646083831787\n",
      "Train size: [400] hidden size: [556] trial: 28, train_loss: 0.348139, test loss: 1.115589, bias2: 0.4225373864173889, variance: 0.6930513978004456\n",
      "Train size: [400] hidden size: [556] trial: 29, train_loss: 0.347839, test loss: 1.116045, bias2: 0.42165476083755493, variance: 0.6943902373313904\n",
      "Train size: [400] hidden size: [556] trial: 30, train_loss: 0.347136, test loss: 1.115778, bias2: 0.42096036672592163, variance: 0.6948173642158508\n",
      "Train size: [400] hidden size: [556] trial: 31, train_loss: 0.347896, test loss: 1.118175, bias2: 0.4210830330848694, variance: 0.6970924735069275\n",
      "Train size: [400] hidden size: [556] trial: 32, train_loss: 0.349221, test loss: 1.116579, bias2: 0.4198148846626282, variance: 0.6967639327049255\n",
      "Train size: [400] hidden size: [556] trial: 33, train_loss: 0.348753, test loss: 1.114537, bias2: 0.41818952560424805, variance: 0.6963479518890381\n",
      "Train size: [400] hidden size: [556] trial: 34, train_loss: 0.348356, test loss: 1.114316, bias2: 0.4159132242202759, variance: 0.6984025239944458\n",
      "Train size: [400] hidden size: [556] trial: 35, train_loss: 0.348284, test loss: 1.113882, bias2: 0.4148164987564087, variance: 0.6990659236907959\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [556] trial: 36, train_loss: 0.350339, test loss: 1.113602, bias2: 0.4113098382949829, variance: 0.7022920846939087\n",
      "Train size: [400] hidden size: [556] trial: 37, train_loss: 0.350506, test loss: 1.115541, bias2: 0.4090615510940552, variance: 0.7064799070358276\n",
      "Train size: [400] hidden size: [556] trial: 38, train_loss: 0.348440, test loss: 1.112117, bias2: 0.40783822536468506, variance: 0.7042785882949829\n",
      "Train size: [400] hidden size: [556] trial: 39, train_loss: 0.347218, test loss: 1.111455, bias2: 0.40790867805480957, variance: 0.7035466432571411\n",
      "Train size: [400] hidden size: [556] trial: 40, train_loss: 0.348427, test loss: 1.113199, bias2: 0.40586739778518677, variance: 0.7073318362236023\n",
      "Train size: [400] hidden size: [556] trial: 41, train_loss: 0.349069, test loss: 1.112922, bias2: 0.40562134981155396, variance: 0.7073009610176086\n",
      "Train size: [400] hidden size: [556] trial: 42, train_loss: 0.348444, test loss: 1.110395, bias2: 0.4026487469673157, variance: 0.7077460885047913\n",
      "Train size: [400] hidden size: [556] trial: 43, train_loss: 0.348801, test loss: 1.109347, bias2: 0.4005082845687866, variance: 0.7088391780853271\n",
      "Train size: [400] hidden size: [556] trial: 44, train_loss: 0.348890, test loss: 1.109473, bias2: 0.4004632234573364, variance: 0.7090096473693848\n",
      "Train size: [400] hidden size: [556] trial: 45, train_loss: 0.348908, test loss: 1.107669, bias2: 0.3989354968070984, variance: 0.7087331414222717\n",
      "Train size: [400] hidden size: [556] trial: 46, train_loss: 0.347642, test loss: 1.107168, bias2: 0.39858829975128174, variance: 0.7085798978805542\n",
      "Train size: [400] hidden size: [556] trial: 47, train_loss: 0.348313, test loss: 1.108465, bias2: 0.3975364565849304, variance: 0.7109288573265076\n",
      "Train size: [400] hidden size: [556] trial: 48, train_loss: 0.349515, test loss: 1.110097, bias2: 0.39943069219589233, variance: 0.7106662392616272\n",
      "Train size: [400] hidden size: [556] trial: 49, train_loss: 0.349212, test loss: 1.111224, bias2: 0.40008431673049927, variance: 0.7111397385597229\n",
      "##################################################\n",
      "Train size: [400] hidden size: [640] trial: 0, train_loss: 0.322011, test loss: 1.071732, bias2: 1.0717319250106812, variance: 8.174350973888522e-09\n",
      "Train size: [400] hidden size: [640] trial: 1, train_loss: 0.340655, test loss: 1.067543, bias2: 0.7207704782485962, variance: 0.346772164106369\n",
      "Train size: [400] hidden size: [640] trial: 2, train_loss: 0.326938, test loss: 1.027501, bias2: 0.5983710289001465, variance: 0.4291297197341919\n",
      "Train size: [400] hidden size: [640] trial: 3, train_loss: 0.320371, test loss: 1.017415, bias2: 0.5369728207588196, variance: 0.48044246435165405\n",
      "Train size: [400] hidden size: [640] trial: 4, train_loss: 0.325088, test loss: 1.025115, bias2: 0.5021533966064453, variance: 0.5229614973068237\n",
      "Train size: [400] hidden size: [640] trial: 5, train_loss: 0.329790, test loss: 1.044625, bias2: 0.48334193229675293, variance: 0.5612832307815552\n",
      "Train size: [400] hidden size: [640] trial: 6, train_loss: 0.327951, test loss: 1.043489, bias2: 0.4638534188270569, variance: 0.5796355605125427\n",
      "Train size: [400] hidden size: [640] trial: 7, train_loss: 0.326010, test loss: 1.049607, bias2: 0.4560685157775879, variance: 0.5935385227203369\n",
      "Train size: [400] hidden size: [640] trial: 8, train_loss: 0.331584, test loss: 1.052306, bias2: 0.4505225419998169, variance: 0.6017836332321167\n",
      "Train size: [400] hidden size: [640] trial: 9, train_loss: 0.331455, test loss: 1.054282, bias2: 0.4442756772041321, variance: 0.6100067496299744\n",
      "Train size: [400] hidden size: [640] trial: 10, train_loss: 0.333248, test loss: 1.061411, bias2: 0.43996429443359375, variance: 0.6214472055435181\n",
      "Train size: [400] hidden size: [640] trial: 11, train_loss: 0.335064, test loss: 1.064189, bias2: 0.4372541904449463, variance: 0.6269350051879883\n",
      "Train size: [400] hidden size: [640] trial: 12, train_loss: 0.332987, test loss: 1.063523, bias2: 0.4332433342933655, variance: 0.6302793622016907\n",
      "Train size: [400] hidden size: [640] trial: 13, train_loss: 0.330973, test loss: 1.067946, bias2: 0.43188363313674927, variance: 0.6360625624656677\n",
      "Train size: [400] hidden size: [640] trial: 14, train_loss: 0.330145, test loss: 1.065293, bias2: 0.4248514771461487, variance: 0.640441358089447\n",
      "Train size: [400] hidden size: [640] trial: 15, train_loss: 0.326346, test loss: 1.062172, bias2: 0.42234426736831665, variance: 0.63982754945755\n",
      "Train size: [400] hidden size: [640] trial: 16, train_loss: 0.324348, test loss: 1.063848, bias2: 0.41589123010635376, variance: 0.6479571461677551\n",
      "Train size: [400] hidden size: [640] trial: 17, train_loss: 0.321806, test loss: 1.062550, bias2: 0.41628217697143555, variance: 0.6462678909301758\n",
      "Train size: [400] hidden size: [640] trial: 18, train_loss: 0.321763, test loss: 1.057330, bias2: 0.40917325019836426, variance: 0.6481565237045288\n",
      "Train size: [400] hidden size: [640] trial: 19, train_loss: 0.319745, test loss: 1.055430, bias2: 0.409002423286438, variance: 0.6464271545410156\n",
      "Train size: [400] hidden size: [640] trial: 20, train_loss: 0.317557, test loss: 1.055533, bias2: 0.4053751826286316, variance: 0.6501573920249939\n",
      "Train size: [400] hidden size: [640] trial: 21, train_loss: 0.317384, test loss: 1.055605, bias2: 0.4058389663696289, variance: 0.6497659683227539\n",
      "Train size: [400] hidden size: [640] trial: 22, train_loss: 0.317090, test loss: 1.052445, bias2: 0.40250498056411743, variance: 0.6499398350715637\n",
      "Train size: [400] hidden size: [640] trial: 23, train_loss: 0.319803, test loss: 1.052021, bias2: 0.40324389934539795, variance: 0.6487776041030884\n",
      "Train size: [400] hidden size: [640] trial: 24, train_loss: 0.318336, test loss: 1.051411, bias2: 0.4009220004081726, variance: 0.6504886746406555\n",
      "Train size: [400] hidden size: [640] trial: 25, train_loss: 0.319127, test loss: 1.049926, bias2: 0.39976656436920166, variance: 0.6501597166061401\n",
      "Train size: [400] hidden size: [640] trial: 26, train_loss: 0.319645, test loss: 1.048915, bias2: 0.39707648754119873, variance: 0.6518388986587524\n",
      "Train size: [400] hidden size: [640] trial: 27, train_loss: 0.321497, test loss: 1.046343, bias2: 0.39488571882247925, variance: 0.6514577269554138\n",
      "Train size: [400] hidden size: [640] trial: 28, train_loss: 0.322395, test loss: 1.045018, bias2: 0.3929874897003174, variance: 0.6520304679870605\n",
      "Train size: [400] hidden size: [640] trial: 29, train_loss: 0.321900, test loss: 1.044925, bias2: 0.39097052812576294, variance: 0.6539545655250549\n",
      "Train size: [400] hidden size: [640] trial: 30, train_loss: 0.319874, test loss: 1.043521, bias2: 0.3903474807739258, variance: 0.6531736850738525\n",
      "Train size: [400] hidden size: [640] trial: 31, train_loss: 0.320292, test loss: 1.044730, bias2: 0.39003098011016846, variance: 0.6546993255615234\n",
      "Train size: [400] hidden size: [640] trial: 32, train_loss: 0.319517, test loss: 1.042567, bias2: 0.38800299167633057, variance: 0.6545644998550415\n",
      "Train size: [400] hidden size: [640] trial: 33, train_loss: 0.319171, test loss: 1.046660, bias2: 0.3894399404525757, variance: 0.657219648361206\n",
      "Train size: [400] hidden size: [640] trial: 34, train_loss: 0.320534, test loss: 1.045146, bias2: 0.3870154023170471, variance: 0.6581302285194397\n",
      "Train size: [400] hidden size: [640] trial: 35, train_loss: 0.320996, test loss: 1.045808, bias2: 0.3849417567253113, variance: 0.6608663201332092\n",
      "Train size: [400] hidden size: [640] trial: 36, train_loss: 0.321132, test loss: 1.048167, bias2: 0.3862016797065735, variance: 0.6619651913642883\n",
      "Train size: [400] hidden size: [640] trial: 37, train_loss: 0.320599, test loss: 1.048644, bias2: 0.3856126070022583, variance: 0.6630313396453857\n",
      "Train size: [400] hidden size: [640] trial: 38, train_loss: 0.320548, test loss: 1.052038, bias2: 0.38663607835769653, variance: 0.6654015183448792\n",
      "Train size: [400] hidden size: [640] trial: 39, train_loss: 0.320597, test loss: 1.052497, bias2: 0.38687652349472046, variance: 0.6656201481819153\n",
      "Train size: [400] hidden size: [640] trial: 40, train_loss: 0.321194, test loss: 1.052103, bias2: 0.3865709900856018, variance: 0.6655324101448059\n",
      "Train size: [400] hidden size: [640] trial: 41, train_loss: 0.321280, test loss: 1.050306, bias2: 0.38439303636550903, variance: 0.6659134030342102\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [640] trial: 42, train_loss: 0.321804, test loss: 1.051407, bias2: 0.3840486407279968, variance: 0.6673586964607239\n",
      "Train size: [400] hidden size: [640] trial: 43, train_loss: 0.320594, test loss: 1.053688, bias2: 0.38574081659317017, variance: 0.667946994304657\n",
      "Train size: [400] hidden size: [640] trial: 44, train_loss: 0.321333, test loss: 1.054028, bias2: 0.3846902847290039, variance: 0.6693381071090698\n",
      "Train size: [400] hidden size: [640] trial: 45, train_loss: 0.322220, test loss: 1.055548, bias2: 0.38439369201660156, variance: 0.6711547374725342\n",
      "Train size: [400] hidden size: [640] trial: 46, train_loss: 0.321809, test loss: 1.056235, bias2: 0.3848285675048828, variance: 0.6714062690734863\n",
      "Train size: [400] hidden size: [640] trial: 47, train_loss: 0.320933, test loss: 1.055610, bias2: 0.3830574154853821, variance: 0.6725530028343201\n",
      "Train size: [400] hidden size: [640] trial: 48, train_loss: 0.319855, test loss: 1.054715, bias2: 0.38345932960510254, variance: 0.6712555885314941\n",
      "Train size: [400] hidden size: [640] trial: 49, train_loss: 0.319943, test loss: 1.055487, bias2: 0.3830239772796631, variance: 0.6724629402160645\n",
      "##################################################\n",
      "Train size: [400] hidden size: [737] trial: 0, train_loss: 0.321573, test loss: 0.988252, bias2: 0.9882523417472839, variance: 3.1140383605077204e-09\n",
      "Train size: [400] hidden size: [737] trial: 1, train_loss: 0.301592, test loss: 1.010910, bias2: 0.7123931050300598, variance: 0.2985174059867859\n",
      "Train size: [400] hidden size: [737] trial: 2, train_loss: 0.312774, test loss: 1.011293, bias2: 0.6131078004837036, variance: 0.398185133934021\n",
      "Train size: [400] hidden size: [737] trial: 3, train_loss: 0.309920, test loss: 1.021000, bias2: 0.5619909763336182, variance: 0.45900893211364746\n",
      "Train size: [400] hidden size: [737] trial: 4, train_loss: 0.306697, test loss: 1.017479, bias2: 0.5174975395202637, variance: 0.499981552362442\n",
      "Train size: [400] hidden size: [737] trial: 5, train_loss: 0.297093, test loss: 1.025055, bias2: 0.4850553870201111, variance: 0.5399996638298035\n",
      "Train size: [400] hidden size: [737] trial: 6, train_loss: 0.296453, test loss: 1.009153, bias2: 0.45848870277404785, variance: 0.5506641864776611\n",
      "Train size: [400] hidden size: [737] trial: 7, train_loss: 0.297365, test loss: 1.019536, bias2: 0.45362353324890137, variance: 0.5659122467041016\n",
      "Train size: [400] hidden size: [737] trial: 8, train_loss: 0.297720, test loss: 1.017287, bias2: 0.4430634379386902, variance: 0.5742233395576477\n",
      "Train size: [400] hidden size: [737] trial: 9, train_loss: 0.297469, test loss: 1.015356, bias2: 0.4382972717285156, variance: 0.5770589113235474\n",
      "Train size: [400] hidden size: [737] trial: 10, train_loss: 0.297118, test loss: 1.020017, bias2: 0.4336228370666504, variance: 0.5863940715789795\n",
      "Train size: [400] hidden size: [737] trial: 11, train_loss: 0.296880, test loss: 1.014536, bias2: 0.42300862073898315, variance: 0.5915276408195496\n",
      "Train size: [400] hidden size: [737] trial: 12, train_loss: 0.294208, test loss: 1.011540, bias2: 0.4220004081726074, variance: 0.5895392894744873\n",
      "Train size: [400] hidden size: [737] trial: 13, train_loss: 0.294685, test loss: 1.006955, bias2: 0.41413038969039917, variance: 0.592824399471283\n",
      "Train size: [400] hidden size: [737] trial: 14, train_loss: 0.295375, test loss: 1.005976, bias2: 0.4156269431114197, variance: 0.5903493762016296\n",
      "Train size: [400] hidden size: [737] trial: 15, train_loss: 0.295310, test loss: 1.004703, bias2: 0.41382718086242676, variance: 0.5908756256103516\n",
      "Train size: [400] hidden size: [737] trial: 16, train_loss: 0.295621, test loss: 1.006496, bias2: 0.4142701029777527, variance: 0.5922262072563171\n",
      "Train size: [400] hidden size: [737] trial: 17, train_loss: 0.294296, test loss: 1.006014, bias2: 0.4121495485305786, variance: 0.5938643217086792\n",
      "Train size: [400] hidden size: [737] trial: 18, train_loss: 0.296136, test loss: 1.003155, bias2: 0.4070265293121338, variance: 0.5961287021636963\n",
      "Train size: [400] hidden size: [737] trial: 19, train_loss: 0.294108, test loss: 1.005041, bias2: 0.4070844054222107, variance: 0.5979565978050232\n",
      "Train size: [400] hidden size: [737] trial: 20, train_loss: 0.294704, test loss: 1.002771, bias2: 0.4041558504104614, variance: 0.5986151695251465\n",
      "Train size: [400] hidden size: [737] trial: 21, train_loss: 0.295434, test loss: 1.005212, bias2: 0.40388017892837524, variance: 0.6013317704200745\n",
      "Train size: [400] hidden size: [737] trial: 22, train_loss: 0.296334, test loss: 1.006393, bias2: 0.39836055040359497, variance: 0.608032763004303\n",
      "Train size: [400] hidden size: [737] trial: 23, train_loss: 0.295373, test loss: 1.007649, bias2: 0.399091899394989, variance: 0.6085576415061951\n",
      "Train size: [400] hidden size: [737] trial: 24, train_loss: 0.296465, test loss: 1.009747, bias2: 0.3984531760215759, variance: 0.6112938523292542\n",
      "Train size: [400] hidden size: [737] trial: 25, train_loss: 0.294334, test loss: 1.014115, bias2: 0.39882200956344604, variance: 0.6152928471565247\n",
      "Train size: [400] hidden size: [737] trial: 26, train_loss: 0.294998, test loss: 1.012834, bias2: 0.3963550925254822, variance: 0.6164788603782654\n",
      "Train size: [400] hidden size: [737] trial: 27, train_loss: 0.295466, test loss: 1.014024, bias2: 0.39425909519195557, variance: 0.6197651624679565\n",
      "Train size: [400] hidden size: [737] trial: 28, train_loss: 0.294970, test loss: 1.013578, bias2: 0.3943268656730652, variance: 0.619251549243927\n",
      "Train size: [400] hidden size: [737] trial: 29, train_loss: 0.294217, test loss: 1.011733, bias2: 0.39257287979125977, variance: 0.6191598176956177\n",
      "Train size: [400] hidden size: [737] trial: 30, train_loss: 0.293249, test loss: 1.012607, bias2: 0.39124786853790283, variance: 0.6213595867156982\n",
      "Train size: [400] hidden size: [737] trial: 31, train_loss: 0.292439, test loss: 1.009524, bias2: 0.3884066343307495, variance: 0.621117353439331\n",
      "Train size: [400] hidden size: [737] trial: 32, train_loss: 0.293096, test loss: 1.010235, bias2: 0.3881266117095947, variance: 0.6221086978912354\n",
      "Train size: [400] hidden size: [737] trial: 33, train_loss: 0.293006, test loss: 1.009562, bias2: 0.3872496485710144, variance: 0.6223123669624329\n",
      "Train size: [400] hidden size: [737] trial: 34, train_loss: 0.292618, test loss: 1.007197, bias2: 0.38607823848724365, variance: 0.6211189031600952\n",
      "Train size: [400] hidden size: [737] trial: 35, train_loss: 0.293671, test loss: 1.007877, bias2: 0.3860763907432556, variance: 0.6218007206916809\n",
      "Train size: [400] hidden size: [737] trial: 36, train_loss: 0.293094, test loss: 1.009328, bias2: 0.3871658444404602, variance: 0.6221622824668884\n",
      "Train size: [400] hidden size: [737] trial: 37, train_loss: 0.293041, test loss: 1.012527, bias2: 0.3906451463699341, variance: 0.6218823194503784\n",
      "Train size: [400] hidden size: [737] trial: 38, train_loss: 0.292615, test loss: 1.009442, bias2: 0.38847047090530396, variance: 0.620971143245697\n",
      "Train size: [400] hidden size: [737] trial: 39, train_loss: 0.292214, test loss: 1.008146, bias2: 0.3862040042877197, variance: 0.6219418048858643\n",
      "Train size: [400] hidden size: [737] trial: 40, train_loss: 0.291780, test loss: 1.007383, bias2: 0.3846147656440735, variance: 0.6227681040763855\n",
      "Train size: [400] hidden size: [737] trial: 41, train_loss: 0.291432, test loss: 1.009372, bias2: 0.3850439190864563, variance: 0.6243279576301575\n",
      "Train size: [400] hidden size: [737] trial: 42, train_loss: 0.291979, test loss: 1.008107, bias2: 0.3847035765647888, variance: 0.6234032511711121\n",
      "Train size: [400] hidden size: [737] trial: 43, train_loss: 0.292098, test loss: 1.006277, bias2: 0.383419930934906, variance: 0.6228569149971008\n",
      "Train size: [400] hidden size: [737] trial: 44, train_loss: 0.291670, test loss: 1.005814, bias2: 0.38308268785476685, variance: 0.6227317452430725\n",
      "Train size: [400] hidden size: [737] trial: 45, train_loss: 0.291745, test loss: 1.007412, bias2: 0.383192241191864, variance: 0.6242198348045349\n",
      "Train size: [400] hidden size: [737] trial: 46, train_loss: 0.291712, test loss: 1.005240, bias2: 0.3816300630569458, variance: 0.6236096620559692\n",
      "Train size: [400] hidden size: [737] trial: 47, train_loss: 0.291929, test loss: 1.005454, bias2: 0.3805651068687439, variance: 0.6248885989189148\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [737] trial: 48, train_loss: 0.292672, test loss: 1.005354, bias2: 0.37945789098739624, variance: 0.625896155834198\n",
      "Train size: [400] hidden size: [737] trial: 49, train_loss: 0.293279, test loss: 1.004691, bias2: 0.37922215461730957, variance: 0.6254687309265137\n",
      "##################################################\n",
      "Train size: [400] hidden size: [848] trial: 0, train_loss: 0.232427, test loss: 0.937516, bias2: 0.9375160932540894, variance: 3.5032932110823367e-09\n",
      "Train size: [400] hidden size: [848] trial: 1, train_loss: 0.245556, test loss: 0.923757, bias2: 0.6318141222000122, variance: 0.2919425368309021\n",
      "Train size: [400] hidden size: [848] trial: 2, train_loss: 0.258588, test loss: 0.926405, bias2: 0.5315507650375366, variance: 0.39485403895378113\n",
      "Train size: [400] hidden size: [848] trial: 3, train_loss: 0.264707, test loss: 0.926824, bias2: 0.4906887710094452, variance: 0.43613556027412415\n",
      "Train size: [400] hidden size: [848] trial: 4, train_loss: 0.275543, test loss: 0.941512, bias2: 0.4695691168308258, variance: 0.4719424545764923\n",
      "Train size: [400] hidden size: [848] trial: 5, train_loss: 0.274490, test loss: 0.942180, bias2: 0.4481218755245209, variance: 0.49405786395072937\n",
      "Train size: [400] hidden size: [848] trial: 6, train_loss: 0.272425, test loss: 0.944975, bias2: 0.4327998757362366, variance: 0.5121750831604004\n",
      "Train size: [400] hidden size: [848] trial: 7, train_loss: 0.268897, test loss: 0.946860, bias2: 0.4328714609146118, variance: 0.5139883756637573\n",
      "Train size: [400] hidden size: [848] trial: 8, train_loss: 0.268042, test loss: 0.947532, bias2: 0.42666614055633545, variance: 0.5208654403686523\n",
      "Train size: [400] hidden size: [848] trial: 9, train_loss: 0.270440, test loss: 0.948539, bias2: 0.4178626537322998, variance: 0.5306768417358398\n",
      "Train size: [400] hidden size: [848] trial: 10, train_loss: 0.267385, test loss: 0.945680, bias2: 0.4151063561439514, variance: 0.5305734276771545\n",
      "Train size: [400] hidden size: [848] trial: 11, train_loss: 0.265044, test loss: 0.941833, bias2: 0.40893805027008057, variance: 0.5328949093818665\n",
      "Train size: [400] hidden size: [848] trial: 12, train_loss: 0.262729, test loss: 0.945206, bias2: 0.40733349323272705, variance: 0.5378729701042175\n",
      "Train size: [400] hidden size: [848] trial: 13, train_loss: 0.260482, test loss: 0.942131, bias2: 0.4077882766723633, variance: 0.5343426465988159\n",
      "Train size: [400] hidden size: [848] trial: 14, train_loss: 0.261730, test loss: 0.940219, bias2: 0.4012988209724426, variance: 0.5389196872711182\n",
      "Train size: [400] hidden size: [848] trial: 15, train_loss: 0.263248, test loss: 0.942499, bias2: 0.40156108140945435, variance: 0.5409379005432129\n",
      "Train size: [400] hidden size: [848] trial: 16, train_loss: 0.264276, test loss: 0.946120, bias2: 0.39905083179473877, variance: 0.5470694899559021\n",
      "Train size: [400] hidden size: [848] trial: 17, train_loss: 0.263403, test loss: 0.945349, bias2: 0.3953048586845398, variance: 0.5500440001487732\n",
      "Train size: [400] hidden size: [848] trial: 18, train_loss: 0.263217, test loss: 0.947594, bias2: 0.3963109850883484, variance: 0.5512834787368774\n",
      "Train size: [400] hidden size: [848] trial: 19, train_loss: 0.263029, test loss: 0.946452, bias2: 0.3917694687843323, variance: 0.5546827912330627\n",
      "Train size: [400] hidden size: [848] trial: 20, train_loss: 0.263537, test loss: 0.944777, bias2: 0.3871406316757202, variance: 0.5576364994049072\n",
      "Train size: [400] hidden size: [848] trial: 21, train_loss: 0.264096, test loss: 0.947976, bias2: 0.38581138849258423, variance: 0.5621644854545593\n",
      "Train size: [400] hidden size: [848] trial: 22, train_loss: 0.263448, test loss: 0.950314, bias2: 0.3844738006591797, variance: 0.5658398866653442\n",
      "Train size: [400] hidden size: [848] trial: 23, train_loss: 0.263589, test loss: 0.951722, bias2: 0.3839445114135742, variance: 0.5677775740623474\n",
      "Train size: [400] hidden size: [848] trial: 24, train_loss: 0.261380, test loss: 0.949699, bias2: 0.38435256481170654, variance: 0.5653467774391174\n",
      "Train size: [400] hidden size: [848] trial: 25, train_loss: 0.261730, test loss: 0.948545, bias2: 0.380959689617157, variance: 0.5675849914550781\n",
      "Train size: [400] hidden size: [848] trial: 26, train_loss: 0.261428, test loss: 0.948047, bias2: 0.38058537244796753, variance: 0.567461371421814\n",
      "Train size: [400] hidden size: [848] trial: 27, train_loss: 0.262166, test loss: 0.946015, bias2: 0.37765365839004517, variance: 0.568361759185791\n",
      "Train size: [400] hidden size: [848] trial: 28, train_loss: 0.262667, test loss: 0.945438, bias2: 0.3771361708641052, variance: 0.5683022737503052\n",
      "Train size: [400] hidden size: [848] trial: 29, train_loss: 0.264136, test loss: 0.949001, bias2: 0.3787427544593811, variance: 0.5702582001686096\n",
      "Train size: [400] hidden size: [848] trial: 30, train_loss: 0.265107, test loss: 0.950737, bias2: 0.37880152463912964, variance: 0.5719356536865234\n",
      "Train size: [400] hidden size: [848] trial: 31, train_loss: 0.264742, test loss: 0.951532, bias2: 0.37821364402770996, variance: 0.5733184814453125\n",
      "Train size: [400] hidden size: [848] trial: 32, train_loss: 0.264954, test loss: 0.948354, bias2: 0.3753308057785034, variance: 0.5730230808258057\n",
      "Train size: [400] hidden size: [848] trial: 33, train_loss: 0.264802, test loss: 0.948330, bias2: 0.3738671541213989, variance: 0.5744631290435791\n",
      "Train size: [400] hidden size: [848] trial: 34, train_loss: 0.265258, test loss: 0.948410, bias2: 0.372788667678833, variance: 0.5756209492683411\n",
      "Train size: [400] hidden size: [848] trial: 35, train_loss: 0.264520, test loss: 0.948645, bias2: 0.37405914068222046, variance: 0.5745854377746582\n",
      "Train size: [400] hidden size: [848] trial: 36, train_loss: 0.265340, test loss: 0.948324, bias2: 0.37268346548080444, variance: 0.5756405591964722\n",
      "Train size: [400] hidden size: [848] trial: 37, train_loss: 0.264551, test loss: 0.945618, bias2: 0.37063390016555786, variance: 0.5749844908714294\n",
      "Train size: [400] hidden size: [848] trial: 38, train_loss: 0.264432, test loss: 0.944635, bias2: 0.3699542284011841, variance: 0.5746808052062988\n",
      "Train size: [400] hidden size: [848] trial: 39, train_loss: 0.264583, test loss: 0.944910, bias2: 0.3699444532394409, variance: 0.5749652981758118\n",
      "Train size: [400] hidden size: [848] trial: 40, train_loss: 0.265363, test loss: 0.944311, bias2: 0.3694417476654053, variance: 0.5748693943023682\n",
      "Train size: [400] hidden size: [848] trial: 41, train_loss: 0.265413, test loss: 0.945321, bias2: 0.369428813457489, variance: 0.57589191198349\n",
      "Train size: [400] hidden size: [848] trial: 42, train_loss: 0.265003, test loss: 0.945410, bias2: 0.3711944818496704, variance: 0.5742154121398926\n",
      "Train size: [400] hidden size: [848] trial: 43, train_loss: 0.265728, test loss: 0.946649, bias2: 0.37219852209091187, variance: 0.5744500160217285\n",
      "Train size: [400] hidden size: [848] trial: 44, train_loss: 0.265608, test loss: 0.947217, bias2: 0.3730594515800476, variance: 0.5741575956344604\n",
      "Train size: [400] hidden size: [848] trial: 45, train_loss: 0.266158, test loss: 0.946580, bias2: 0.37217241525650024, variance: 0.5744076371192932\n",
      "Train size: [400] hidden size: [848] trial: 46, train_loss: 0.265942, test loss: 0.946454, bias2: 0.3724817633628845, variance: 0.573972225189209\n",
      "Train size: [400] hidden size: [848] trial: 47, train_loss: 0.265978, test loss: 0.946598, bias2: 0.37063735723495483, variance: 0.5759602189064026\n",
      "Train size: [400] hidden size: [848] trial: 48, train_loss: 0.265563, test loss: 0.944610, bias2: 0.3696008324623108, variance: 0.575009286403656\n",
      "Train size: [400] hidden size: [848] trial: 49, train_loss: 0.266145, test loss: 0.944681, bias2: 0.3683122396469116, variance: 0.5763691663742065\n",
      "##################################################\n",
      "Train size: [400] hidden size: [977] trial: 0, train_loss: 0.243649, test loss: 0.884058, bias2: 0.8840577602386475, variance: 1.5180937396053196e-08\n",
      "Train size: [400] hidden size: [977] trial: 1, train_loss: 0.238205, test loss: 0.895343, bias2: 0.6337038278579712, variance: 0.26163965463638306\n",
      "Train size: [400] hidden size: [977] trial: 2, train_loss: 0.239510, test loss: 0.930080, bias2: 0.5539031624794006, variance: 0.37617647647857666\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [977] trial: 3, train_loss: 0.243698, test loss: 0.930776, bias2: 0.5074639916419983, variance: 0.4233121871948242\n",
      "Train size: [400] hidden size: [977] trial: 4, train_loss: 0.234165, test loss: 0.923813, bias2: 0.47791945934295654, variance: 0.44589340686798096\n",
      "Train size: [400] hidden size: [977] trial: 5, train_loss: 0.237839, test loss: 0.911514, bias2: 0.45220792293548584, variance: 0.4593057632446289\n",
      "Train size: [400] hidden size: [977] trial: 6, train_loss: 0.243524, test loss: 0.921111, bias2: 0.4479365050792694, variance: 0.47317472100257874\n",
      "Train size: [400] hidden size: [977] trial: 7, train_loss: 0.248782, test loss: 0.910746, bias2: 0.4277789890766144, variance: 0.48296669125556946\n",
      "Train size: [400] hidden size: [977] trial: 8, train_loss: 0.246479, test loss: 0.906717, bias2: 0.4181915521621704, variance: 0.4885255694389343\n",
      "Train size: [400] hidden size: [977] trial: 9, train_loss: 0.247520, test loss: 0.905060, bias2: 0.4132869839668274, variance: 0.49177342653274536\n",
      "Train size: [400] hidden size: [977] trial: 10, train_loss: 0.250048, test loss: 0.904591, bias2: 0.4076708257198334, variance: 0.49692007899284363\n",
      "Train size: [400] hidden size: [977] trial: 11, train_loss: 0.251989, test loss: 0.906280, bias2: 0.4060991406440735, variance: 0.5001808404922485\n",
      "Train size: [400] hidden size: [977] trial: 12, train_loss: 0.254312, test loss: 0.905292, bias2: 0.4005976915359497, variance: 0.5046945810317993\n",
      "Train size: [400] hidden size: [977] trial: 13, train_loss: 0.252208, test loss: 0.902338, bias2: 0.39618563652038574, variance: 0.5061520338058472\n",
      "Train size: [400] hidden size: [977] trial: 14, train_loss: 0.251085, test loss: 0.900128, bias2: 0.39260542392730713, variance: 0.5075228214263916\n",
      "Train size: [400] hidden size: [977] trial: 15, train_loss: 0.250115, test loss: 0.902110, bias2: 0.39208030700683594, variance: 0.5100297331809998\n",
      "Train size: [400] hidden size: [977] trial: 16, train_loss: 0.249857, test loss: 0.907941, bias2: 0.3917731046676636, variance: 0.5161680579185486\n",
      "Train size: [400] hidden size: [977] trial: 17, train_loss: 0.250923, test loss: 0.910131, bias2: 0.38949334621429443, variance: 0.5206373333930969\n",
      "Train size: [400] hidden size: [977] trial: 18, train_loss: 0.249941, test loss: 0.911160, bias2: 0.38662290573120117, variance: 0.5245375037193298\n",
      "Train size: [400] hidden size: [977] trial: 19, train_loss: 0.248823, test loss: 0.911345, bias2: 0.38813966512680054, variance: 0.5232049226760864\n",
      "Train size: [400] hidden size: [977] trial: 20, train_loss: 0.251523, test loss: 0.910226, bias2: 0.38640111684799194, variance: 0.52382493019104\n",
      "Train size: [400] hidden size: [977] trial: 21, train_loss: 0.251738, test loss: 0.913139, bias2: 0.38839244842529297, variance: 0.524746835231781\n",
      "Train size: [400] hidden size: [977] trial: 22, train_loss: 0.251470, test loss: 0.910150, bias2: 0.3821631669998169, variance: 0.5279869437217712\n",
      "Train size: [400] hidden size: [977] trial: 23, train_loss: 0.252640, test loss: 0.908035, bias2: 0.3783629536628723, variance: 0.5296717882156372\n",
      "Train size: [400] hidden size: [977] trial: 24, train_loss: 0.252745, test loss: 0.906917, bias2: 0.37730324268341064, variance: 0.5296134948730469\n",
      "Train size: [400] hidden size: [977] trial: 25, train_loss: 0.253896, test loss: 0.909229, bias2: 0.37642836570739746, variance: 0.5328006148338318\n",
      "Train size: [400] hidden size: [977] trial: 26, train_loss: 0.253814, test loss: 0.909633, bias2: 0.37581729888916016, variance: 0.5338156223297119\n",
      "Train size: [400] hidden size: [977] trial: 27, train_loss: 0.254230, test loss: 0.911615, bias2: 0.3763720393180847, variance: 0.5352429747581482\n",
      "Train size: [400] hidden size: [977] trial: 28, train_loss: 0.254338, test loss: 0.913604, bias2: 0.3759379982948303, variance: 0.5376662611961365\n",
      "Train size: [400] hidden size: [977] trial: 29, train_loss: 0.254422, test loss: 0.914454, bias2: 0.37537795305252075, variance: 0.5390765070915222\n",
      "Train size: [400] hidden size: [977] trial: 30, train_loss: 0.253696, test loss: 0.914084, bias2: 0.373663067817688, variance: 0.540420651435852\n",
      "Train size: [400] hidden size: [977] trial: 31, train_loss: 0.252582, test loss: 0.913515, bias2: 0.3726727366447449, variance: 0.5408426523208618\n",
      "Train size: [400] hidden size: [977] trial: 32, train_loss: 0.252689, test loss: 0.914353, bias2: 0.3748820424079895, variance: 0.5394706130027771\n",
      "Train size: [400] hidden size: [977] trial: 33, train_loss: 0.252259, test loss: 0.915894, bias2: 0.375155508518219, variance: 0.5407385230064392\n",
      "Train size: [400] hidden size: [977] trial: 34, train_loss: 0.251277, test loss: 0.916035, bias2: 0.3750544786453247, variance: 0.5409807562828064\n",
      "Train size: [400] hidden size: [977] trial: 35, train_loss: 0.251390, test loss: 0.916327, bias2: 0.3741304874420166, variance: 0.5421966910362244\n",
      "Train size: [400] hidden size: [977] trial: 36, train_loss: 0.251085, test loss: 0.916361, bias2: 0.37408387660980225, variance: 0.5422773361206055\n",
      "Train size: [400] hidden size: [977] trial: 37, train_loss: 0.251582, test loss: 0.915415, bias2: 0.3728402256965637, variance: 0.542574942111969\n",
      "Train size: [400] hidden size: [977] trial: 38, train_loss: 0.251137, test loss: 0.917065, bias2: 0.37383830547332764, variance: 0.5432264804840088\n",
      "Train size: [400] hidden size: [977] trial: 39, train_loss: 0.250493, test loss: 0.917302, bias2: 0.37422722578048706, variance: 0.543074369430542\n",
      "Train size: [400] hidden size: [977] trial: 40, train_loss: 0.250402, test loss: 0.917616, bias2: 0.3741641044616699, variance: 0.5434518456459045\n",
      "Train size: [400] hidden size: [977] trial: 41, train_loss: 0.251412, test loss: 0.918111, bias2: 0.3720327615737915, variance: 0.5460778474807739\n",
      "Train size: [400] hidden size: [977] trial: 42, train_loss: 0.250235, test loss: 0.917044, bias2: 0.37174904346466064, variance: 0.5452954173088074\n",
      "Train size: [400] hidden size: [977] trial: 43, train_loss: 0.249734, test loss: 0.916564, bias2: 0.3718337416648865, variance: 0.5447306632995605\n",
      "Train size: [400] hidden size: [977] trial: 44, train_loss: 0.249194, test loss: 0.915937, bias2: 0.371131956577301, variance: 0.5448048710823059\n",
      "Train size: [400] hidden size: [977] trial: 45, train_loss: 0.248259, test loss: 0.915750, bias2: 0.37142133712768555, variance: 0.5443287491798401\n",
      "Train size: [400] hidden size: [977] trial: 46, train_loss: 0.247846, test loss: 0.915356, bias2: 0.3717076778411865, variance: 0.5436481833457947\n",
      "Train size: [400] hidden size: [977] trial: 47, train_loss: 0.246679, test loss: 0.915651, bias2: 0.3728857636451721, variance: 0.5427655577659607\n",
      "Train size: [400] hidden size: [977] trial: 48, train_loss: 0.246098, test loss: 0.915705, bias2: 0.37255537509918213, variance: 0.5431498885154724\n",
      "Train size: [400] hidden size: [977] trial: 49, train_loss: 0.246843, test loss: 0.917427, bias2: 0.372989296913147, variance: 0.5444377064704895\n",
      "##################################################\n",
      "Train size: [400] hidden size: [1125] trial: 0, train_loss: 0.184695, test loss: 0.844611, bias2: 0.8446113467216492, variance: 4.6710577628061856e-09\n",
      "Train size: [400] hidden size: [1125] trial: 1, train_loss: 0.219468, test loss: 0.822428, bias2: 0.5540218949317932, variance: 0.2684062123298645\n",
      "Train size: [400] hidden size: [1125] trial: 2, train_loss: 0.224291, test loss: 0.823898, bias2: 0.48100465536117554, variance: 0.342893123626709\n",
      "Train size: [400] hidden size: [1125] trial: 3, train_loss: 0.231864, test loss: 0.839937, bias2: 0.4442358613014221, variance: 0.39570069313049316\n",
      "Train size: [400] hidden size: [1125] trial: 4, train_loss: 0.231548, test loss: 0.837120, bias2: 0.41715338826179504, variance: 0.4199669063091278\n",
      "Train size: [400] hidden size: [1125] trial: 5, train_loss: 0.231081, test loss: 0.842870, bias2: 0.4066188335418701, variance: 0.43625152111053467\n",
      "Train size: [400] hidden size: [1125] trial: 6, train_loss: 0.229194, test loss: 0.853018, bias2: 0.40436065196990967, variance: 0.4486568570137024\n",
      "Train size: [400] hidden size: [1125] trial: 7, train_loss: 0.227704, test loss: 0.858955, bias2: 0.39917752146720886, variance: 0.45977720618247986\n",
      "Train size: [400] hidden size: [1125] trial: 8, train_loss: 0.231628, test loss: 0.863686, bias2: 0.39097583293914795, variance: 0.4727098345756531\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [1125] trial: 9, train_loss: 0.232394, test loss: 0.872328, bias2: 0.386570543050766, variance: 0.4857575595378876\n",
      "Train size: [400] hidden size: [1125] trial: 10, train_loss: 0.236262, test loss: 0.879058, bias2: 0.3813437819480896, variance: 0.49771374464035034\n",
      "Train size: [400] hidden size: [1125] trial: 11, train_loss: 0.237663, test loss: 0.886444, bias2: 0.37984830141067505, variance: 0.5065961480140686\n",
      "Train size: [400] hidden size: [1125] trial: 12, train_loss: 0.236552, test loss: 0.881026, bias2: 0.3730502128601074, variance: 0.507975697517395\n",
      "Train size: [400] hidden size: [1125] trial: 13, train_loss: 0.236151, test loss: 0.881656, bias2: 0.37136590480804443, variance: 0.5102901458740234\n",
      "Train size: [400] hidden size: [1125] trial: 14, train_loss: 0.234560, test loss: 0.884599, bias2: 0.37651342153549194, variance: 0.5080854892730713\n",
      "Train size: [400] hidden size: [1125] trial: 15, train_loss: 0.235209, test loss: 0.887842, bias2: 0.3758177161216736, variance: 0.5120240449905396\n",
      "Train size: [400] hidden size: [1125] trial: 16, train_loss: 0.235348, test loss: 0.890690, bias2: 0.37494343519210815, variance: 0.5157468914985657\n",
      "Train size: [400] hidden size: [1125] trial: 17, train_loss: 0.237815, test loss: 0.890733, bias2: 0.3745415210723877, variance: 0.5161915421485901\n",
      "Train size: [400] hidden size: [1125] trial: 18, train_loss: 0.238284, test loss: 0.889617, bias2: 0.3727119565010071, variance: 0.5169050693511963\n",
      "Train size: [400] hidden size: [1125] trial: 19, train_loss: 0.237916, test loss: 0.890417, bias2: 0.37291836738586426, variance: 0.5174989104270935\n",
      "Train size: [400] hidden size: [1125] trial: 20, train_loss: 0.238934, test loss: 0.885250, bias2: 0.36941325664520264, variance: 0.5158364772796631\n",
      "Train size: [400] hidden size: [1125] trial: 21, train_loss: 0.239124, test loss: 0.885499, bias2: 0.3689095377922058, variance: 0.5165895819664001\n",
      "Train size: [400] hidden size: [1125] trial: 22, train_loss: 0.239134, test loss: 0.890521, bias2: 0.3719504475593567, variance: 0.5185701251029968\n",
      "Train size: [400] hidden size: [1125] trial: 23, train_loss: 0.239059, test loss: 0.892696, bias2: 0.3729802966117859, variance: 0.5197151899337769\n",
      "Train size: [400] hidden size: [1125] trial: 24, train_loss: 0.239308, test loss: 0.897937, bias2: 0.37497812509536743, variance: 0.5229589939117432\n",
      "Train size: [400] hidden size: [1125] trial: 25, train_loss: 0.238746, test loss: 0.899825, bias2: 0.37491804361343384, variance: 0.5249070525169373\n",
      "Train size: [400] hidden size: [1125] trial: 26, train_loss: 0.237477, test loss: 0.898841, bias2: 0.37345415353775024, variance: 0.5253866314888\n",
      "Train size: [400] hidden size: [1125] trial: 27, train_loss: 0.237772, test loss: 0.897159, bias2: 0.3708382248878479, variance: 0.5263211131095886\n",
      "Train size: [400] hidden size: [1125] trial: 28, train_loss: 0.238347, test loss: 0.897690, bias2: 0.37018102407455444, variance: 0.5275091528892517\n",
      "Train size: [400] hidden size: [1125] trial: 29, train_loss: 0.237307, test loss: 0.898067, bias2: 0.36951518058776855, variance: 0.5285518169403076\n",
      "Train size: [400] hidden size: [1125] trial: 30, train_loss: 0.236819, test loss: 0.901745, bias2: 0.3721461296081543, variance: 0.5295987129211426\n",
      "Train size: [400] hidden size: [1125] trial: 31, train_loss: 0.235844, test loss: 0.901580, bias2: 0.3720567226409912, variance: 0.5295231342315674\n",
      "Train size: [400] hidden size: [1125] trial: 32, train_loss: 0.235350, test loss: 0.900150, bias2: 0.3732786774635315, variance: 0.526870846748352\n",
      "Train size: [400] hidden size: [1125] trial: 33, train_loss: 0.234400, test loss: 0.898458, bias2: 0.3733566403388977, variance: 0.5251018404960632\n",
      "Train size: [400] hidden size: [1125] trial: 34, train_loss: 0.234019, test loss: 0.897201, bias2: 0.3747909665107727, variance: 0.5224097967147827\n",
      "Train size: [400] hidden size: [1125] trial: 35, train_loss: 0.233927, test loss: 0.895909, bias2: 0.37353992462158203, variance: 0.5223687291145325\n",
      "Train size: [400] hidden size: [1125] trial: 36, train_loss: 0.233943, test loss: 0.897728, bias2: 0.37469691038131714, variance: 0.523030698299408\n",
      "Train size: [400] hidden size: [1125] trial: 37, train_loss: 0.234813, test loss: 0.897633, bias2: 0.37348127365112305, variance: 0.5241517424583435\n",
      "Train size: [400] hidden size: [1125] trial: 38, train_loss: 0.234717, test loss: 0.900023, bias2: 0.37388771772384644, variance: 0.5261349678039551\n",
      "Train size: [400] hidden size: [1125] trial: 39, train_loss: 0.234910, test loss: 0.899753, bias2: 0.3723658323287964, variance: 0.5273869633674622\n",
      "Train size: [400] hidden size: [1125] trial: 40, train_loss: 0.234697, test loss: 0.897661, bias2: 0.3709344267845154, variance: 0.5267266035079956\n",
      "Train size: [400] hidden size: [1125] trial: 41, train_loss: 0.235103, test loss: 0.898367, bias2: 0.3705194592475891, variance: 0.527847945690155\n",
      "Train size: [400] hidden size: [1125] trial: 42, train_loss: 0.234341, test loss: 0.896443, bias2: 0.3704320192337036, variance: 0.5260114669799805\n",
      "Train size: [400] hidden size: [1125] trial: 43, train_loss: 0.234287, test loss: 0.895076, bias2: 0.3684430718421936, variance: 0.5266330242156982\n",
      "Train size: [400] hidden size: [1125] trial: 44, train_loss: 0.233511, test loss: 0.895458, bias2: 0.36841070652008057, variance: 0.5270470380783081\n",
      "Train size: [400] hidden size: [1125] trial: 45, train_loss: 0.233273, test loss: 0.894048, bias2: 0.3687695860862732, variance: 0.5252785682678223\n",
      "Train size: [400] hidden size: [1125] trial: 46, train_loss: 0.233043, test loss: 0.893458, bias2: 0.36788809299468994, variance: 0.5255700945854187\n",
      "Train size: [400] hidden size: [1125] trial: 47, train_loss: 0.232289, test loss: 0.893172, bias2: 0.36866456270217896, variance: 0.5245073437690735\n",
      "Train size: [400] hidden size: [1125] trial: 48, train_loss: 0.231974, test loss: 0.893960, bias2: 0.3684420585632324, variance: 0.5255181193351746\n",
      "Train size: [400] hidden size: [1125] trial: 49, train_loss: 0.232022, test loss: 0.893949, bias2: 0.3674924373626709, variance: 0.5264562964439392\n",
      "##################################################\n",
      "Train size: [400] hidden size: [1295] trial: 0, train_loss: 0.206534, test loss: 0.815910, bias2: 0.8159103393554688, variance: 3.892548061656953e-09\n",
      "Train size: [400] hidden size: [1295] trial: 1, train_loss: 0.209381, test loss: 0.866792, bias2: 0.5994608402252197, variance: 0.26733145117759705\n",
      "Train size: [400] hidden size: [1295] trial: 2, train_loss: 0.216205, test loss: 0.848172, bias2: 0.4939959943294525, variance: 0.3541760742664337\n",
      "Train size: [400] hidden size: [1295] trial: 3, train_loss: 0.212844, test loss: 0.839315, bias2: 0.45322439074516296, variance: 0.3860902488231659\n",
      "Train size: [400] hidden size: [1295] trial: 4, train_loss: 0.214611, test loss: 0.856493, bias2: 0.43715551495552063, variance: 0.4193378984928131\n",
      "Train size: [400] hidden size: [1295] trial: 5, train_loss: 0.216268, test loss: 0.848200, bias2: 0.41391944885253906, variance: 0.43428027629852295\n",
      "Train size: [400] hidden size: [1295] trial: 6, train_loss: 0.222933, test loss: 0.839580, bias2: 0.39933380484580994, variance: 0.44024595618247986\n",
      "Train size: [400] hidden size: [1295] trial: 7, train_loss: 0.219569, test loss: 0.838515, bias2: 0.3910144865512848, variance: 0.4475001394748688\n",
      "Train size: [400] hidden size: [1295] trial: 8, train_loss: 0.218831, test loss: 0.842118, bias2: 0.38473206758499146, variance: 0.4573855400085449\n",
      "Train size: [400] hidden size: [1295] trial: 9, train_loss: 0.215543, test loss: 0.843945, bias2: 0.385779470205307, variance: 0.45816561579704285\n",
      "Train size: [400] hidden size: [1295] trial: 10, train_loss: 0.217154, test loss: 0.843205, bias2: 0.38552820682525635, variance: 0.4576772451400757\n",
      "Train size: [400] hidden size: [1295] trial: 11, train_loss: 0.218972, test loss: 0.840075, bias2: 0.37779495120048523, variance: 0.4622795879840851\n",
      "Train size: [400] hidden size: [1295] trial: 12, train_loss: 0.219660, test loss: 0.837856, bias2: 0.37408220767974854, variance: 0.46377354860305786\n",
      "Train size: [400] hidden size: [1295] trial: 13, train_loss: 0.217264, test loss: 0.835635, bias2: 0.37009382247924805, variance: 0.46554088592529297\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [1295] trial: 14, train_loss: 0.216150, test loss: 0.835297, bias2: 0.36821550130844116, variance: 0.4670812487602234\n",
      "Train size: [400] hidden size: [1295] trial: 15, train_loss: 0.217824, test loss: 0.839977, bias2: 0.3673536479473114, variance: 0.4726232588291168\n",
      "Train size: [400] hidden size: [1295] trial: 16, train_loss: 0.217592, test loss: 0.837441, bias2: 0.3650885224342346, variance: 0.47235286235809326\n",
      "Train size: [400] hidden size: [1295] trial: 17, train_loss: 0.217182, test loss: 0.837781, bias2: 0.36393463611602783, variance: 0.4738466143608093\n",
      "Train size: [400] hidden size: [1295] trial: 18, train_loss: 0.217767, test loss: 0.838143, bias2: 0.36204466223716736, variance: 0.4760984480381012\n",
      "Train size: [400] hidden size: [1295] trial: 19, train_loss: 0.216568, test loss: 0.836787, bias2: 0.36070817708969116, variance: 0.47607922554016113\n",
      "Train size: [400] hidden size: [1295] trial: 20, train_loss: 0.217479, test loss: 0.835196, bias2: 0.35563555359840393, variance: 0.47956040501594543\n",
      "Train size: [400] hidden size: [1295] trial: 21, train_loss: 0.216760, test loss: 0.838477, bias2: 0.3591685891151428, variance: 0.4793088436126709\n",
      "Train size: [400] hidden size: [1295] trial: 22, train_loss: 0.217896, test loss: 0.838487, bias2: 0.3573227822780609, variance: 0.4811643660068512\n",
      "Train size: [400] hidden size: [1295] trial: 23, train_loss: 0.218161, test loss: 0.843627, bias2: 0.35952726006507874, variance: 0.48410001397132874\n",
      "Train size: [400] hidden size: [1295] trial: 24, train_loss: 0.219691, test loss: 0.841378, bias2: 0.35658395290374756, variance: 0.4847942590713501\n",
      "Train size: [400] hidden size: [1295] trial: 25, train_loss: 0.219743, test loss: 0.844818, bias2: 0.3584861755371094, variance: 0.4863319396972656\n",
      "Train size: [400] hidden size: [1295] trial: 26, train_loss: 0.220005, test loss: 0.842427, bias2: 0.3543168008327484, variance: 0.4881105124950409\n",
      "Train size: [400] hidden size: [1295] trial: 27, train_loss: 0.219928, test loss: 0.843475, bias2: 0.354946106672287, variance: 0.48852911591529846\n",
      "Train size: [400] hidden size: [1295] trial: 28, train_loss: 0.218274, test loss: 0.843129, bias2: 0.356321781873703, variance: 0.4868070185184479\n",
      "Train size: [400] hidden size: [1295] trial: 29, train_loss: 0.217767, test loss: 0.843386, bias2: 0.35762470960617065, variance: 0.48576104640960693\n",
      "Train size: [400] hidden size: [1295] trial: 30, train_loss: 0.217297, test loss: 0.843618, bias2: 0.3566742539405823, variance: 0.4869440793991089\n",
      "Train size: [400] hidden size: [1295] trial: 31, train_loss: 0.216846, test loss: 0.845475, bias2: 0.3575214147567749, variance: 0.48795318603515625\n",
      "Train size: [400] hidden size: [1295] trial: 32, train_loss: 0.217202, test loss: 0.845953, bias2: 0.3567044734954834, variance: 0.48924845457077026\n",
      "Train size: [400] hidden size: [1295] trial: 33, train_loss: 0.217078, test loss: 0.846666, bias2: 0.3570232689380646, variance: 0.4896427094936371\n",
      "Train size: [400] hidden size: [1295] trial: 34, train_loss: 0.216782, test loss: 0.846430, bias2: 0.3562068045139313, variance: 0.4902232587337494\n",
      "Train size: [400] hidden size: [1295] trial: 35, train_loss: 0.216371, test loss: 0.846285, bias2: 0.3547707200050354, variance: 0.49151408672332764\n",
      "Train size: [400] hidden size: [1295] trial: 36, train_loss: 0.216948, test loss: 0.848034, bias2: 0.35559287667274475, variance: 0.49244067072868347\n",
      "Train size: [400] hidden size: [1295] trial: 37, train_loss: 0.216962, test loss: 0.846744, bias2: 0.354783296585083, variance: 0.49196046590805054\n",
      "Train size: [400] hidden size: [1295] trial: 38, train_loss: 0.217307, test loss: 0.846366, bias2: 0.3539694547653198, variance: 0.49239611625671387\n",
      "Train size: [400] hidden size: [1295] trial: 39, train_loss: 0.217193, test loss: 0.846852, bias2: 0.3536732494831085, variance: 0.4931786358356476\n",
      "Train size: [400] hidden size: [1295] trial: 40, train_loss: 0.217640, test loss: 0.847200, bias2: 0.3543115258216858, variance: 0.49288851022720337\n",
      "Train size: [400] hidden size: [1295] trial: 41, train_loss: 0.218163, test loss: 0.846448, bias2: 0.35334983468055725, variance: 0.49309834837913513\n",
      "Train size: [400] hidden size: [1295] trial: 42, train_loss: 0.217461, test loss: 0.847133, bias2: 0.35410431027412415, variance: 0.4930286705493927\n",
      "Train size: [400] hidden size: [1295] trial: 43, train_loss: 0.216974, test loss: 0.849360, bias2: 0.35607436299324036, variance: 0.49328574538230896\n",
      "Train size: [400] hidden size: [1295] trial: 44, train_loss: 0.217063, test loss: 0.848105, bias2: 0.3542027175426483, variance: 0.4939022362232208\n",
      "Train size: [400] hidden size: [1295] trial: 45, train_loss: 0.216924, test loss: 0.846674, bias2: 0.35331737995147705, variance: 0.49335622787475586\n",
      "Train size: [400] hidden size: [1295] trial: 46, train_loss: 0.217304, test loss: 0.845616, bias2: 0.35159599781036377, variance: 0.49402034282684326\n",
      "Train size: [400] hidden size: [1295] trial: 47, train_loss: 0.217534, test loss: 0.844437, bias2: 0.3513862192630768, variance: 0.493051141500473\n",
      "Train size: [400] hidden size: [1295] trial: 48, train_loss: 0.217593, test loss: 0.844702, bias2: 0.35060709714889526, variance: 0.49409496784210205\n",
      "Train size: [400] hidden size: [1295] trial: 49, train_loss: 0.218077, test loss: 0.845120, bias2: 0.35084399580955505, variance: 0.4942755401134491\n",
      "##################################################\n",
      "Train size: [400] hidden size: [1491] trial: 0, train_loss: 0.217989, test loss: 0.755227, bias2: 0.7552268505096436, variance: -3.8925479506346505e-10\n",
      "Train size: [400] hidden size: [1491] trial: 1, train_loss: 0.216575, test loss: 0.768780, bias2: 0.5344428420066833, variance: 0.23433732986450195\n",
      "Train size: [400] hidden size: [1491] trial: 2, train_loss: 0.217085, test loss: 0.807966, bias2: 0.5018821358680725, variance: 0.3060839772224426\n",
      "Train size: [400] hidden size: [1491] trial: 3, train_loss: 0.212338, test loss: 0.794494, bias2: 0.44210946559906006, variance: 0.352384090423584\n",
      "Train size: [400] hidden size: [1491] trial: 4, train_loss: 0.214796, test loss: 0.784674, bias2: 0.40425553917884827, variance: 0.3804182708263397\n",
      "Train size: [400] hidden size: [1491] trial: 5, train_loss: 0.214451, test loss: 0.793658, bias2: 0.3944215476512909, variance: 0.39923617243766785\n",
      "Train size: [400] hidden size: [1491] trial: 6, train_loss: 0.216941, test loss: 0.784703, bias2: 0.37575364112854004, variance: 0.40894919633865356\n",
      "Train size: [400] hidden size: [1491] trial: 7, train_loss: 0.218866, test loss: 0.797083, bias2: 0.37445560097694397, variance: 0.4226275384426117\n",
      "Train size: [400] hidden size: [1491] trial: 8, train_loss: 0.215744, test loss: 0.803223, bias2: 0.3779110312461853, variance: 0.425311803817749\n",
      "Train size: [400] hidden size: [1491] trial: 9, train_loss: 0.215803, test loss: 0.813220, bias2: 0.3798643946647644, variance: 0.43335509300231934\n",
      "Train size: [400] hidden size: [1491] trial: 10, train_loss: 0.214429, test loss: 0.808899, bias2: 0.376552939414978, variance: 0.4323461055755615\n",
      "Train size: [400] hidden size: [1491] trial: 11, train_loss: 0.214244, test loss: 0.808235, bias2: 0.3717312514781952, variance: 0.4365036189556122\n",
      "Train size: [400] hidden size: [1491] trial: 12, train_loss: 0.214848, test loss: 0.815993, bias2: 0.376616507768631, variance: 0.4393766224384308\n",
      "Train size: [400] hidden size: [1491] trial: 13, train_loss: 0.213307, test loss: 0.815421, bias2: 0.37244945764541626, variance: 0.4429711699485779\n",
      "Train size: [400] hidden size: [1491] trial: 14, train_loss: 0.212438, test loss: 0.811490, bias2: 0.36500227451324463, variance: 0.44648730754852295\n",
      "Train size: [400] hidden size: [1491] trial: 15, train_loss: 0.212364, test loss: 0.818092, bias2: 0.3662591278553009, variance: 0.45183315873146057\n",
      "Train size: [400] hidden size: [1491] trial: 16, train_loss: 0.210482, test loss: 0.815499, bias2: 0.3637077510356903, variance: 0.451791375875473\n",
      "Train size: [400] hidden size: [1491] trial: 17, train_loss: 0.209820, test loss: 0.817663, bias2: 0.36096832156181335, variance: 0.4566948115825653\n",
      "Train size: [400] hidden size: [1491] trial: 18, train_loss: 0.208313, test loss: 0.817625, bias2: 0.3594498634338379, variance: 0.4581755995750427\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [1491] trial: 19, train_loss: 0.208212, test loss: 0.818628, bias2: 0.3587963283061981, variance: 0.45983198285102844\n",
      "Train size: [400] hidden size: [1491] trial: 20, train_loss: 0.209700, test loss: 0.815611, bias2: 0.35499975085258484, variance: 0.46061113476753235\n",
      "Train size: [400] hidden size: [1491] trial: 21, train_loss: 0.209352, test loss: 0.816701, bias2: 0.3526296317577362, variance: 0.4640709459781647\n",
      "Train size: [400] hidden size: [1491] trial: 22, train_loss: 0.210055, test loss: 0.818384, bias2: 0.35118016600608826, variance: 0.4672043025493622\n",
      "Train size: [400] hidden size: [1491] trial: 23, train_loss: 0.211307, test loss: 0.819693, bias2: 0.35067805647850037, variance: 0.46901461482048035\n",
      "Train size: [400] hidden size: [1491] trial: 24, train_loss: 0.210786, test loss: 0.817810, bias2: 0.3515171706676483, variance: 0.46629324555397034\n",
      "Train size: [400] hidden size: [1491] trial: 25, train_loss: 0.210624, test loss: 0.821324, bias2: 0.35215508937835693, variance: 0.46916890144348145\n",
      "Train size: [400] hidden size: [1491] trial: 26, train_loss: 0.210062, test loss: 0.822036, bias2: 0.3529171049594879, variance: 0.46911874413490295\n",
      "Train size: [400] hidden size: [1491] trial: 27, train_loss: 0.211266, test loss: 0.820501, bias2: 0.3468685448169708, variance: 0.4736328423023224\n",
      "Train size: [400] hidden size: [1491] trial: 28, train_loss: 0.210186, test loss: 0.823637, bias2: 0.34920626878738403, variance: 0.47443073987960815\n",
      "Train size: [400] hidden size: [1491] trial: 29, train_loss: 0.209723, test loss: 0.823771, bias2: 0.3505300283432007, variance: 0.4732412099838257\n",
      "Train size: [400] hidden size: [1491] trial: 30, train_loss: 0.209708, test loss: 0.824801, bias2: 0.3492821156978607, variance: 0.4755185544490814\n",
      "Train size: [400] hidden size: [1491] trial: 31, train_loss: 0.209341, test loss: 0.827730, bias2: 0.3512699604034424, variance: 0.47645968198776245\n",
      "Train size: [400] hidden size: [1491] trial: 32, train_loss: 0.210011, test loss: 0.827044, bias2: 0.35200488567352295, variance: 0.4750392436981201\n",
      "Train size: [400] hidden size: [1491] trial: 33, train_loss: 0.209748, test loss: 0.827627, bias2: 0.3529163599014282, variance: 0.47471052408218384\n",
      "Train size: [400] hidden size: [1491] trial: 34, train_loss: 0.209613, test loss: 0.829709, bias2: 0.3549329340457916, variance: 0.4747762382030487\n",
      "Train size: [400] hidden size: [1491] trial: 35, train_loss: 0.208994, test loss: 0.826698, bias2: 0.3523387610912323, variance: 0.47435906529426575\n",
      "Train size: [400] hidden size: [1491] trial: 36, train_loss: 0.209822, test loss: 0.826742, bias2: 0.3507664203643799, variance: 0.4759758710861206\n",
      "Train size: [400] hidden size: [1491] trial: 37, train_loss: 0.210198, test loss: 0.826827, bias2: 0.3500756025314331, variance: 0.47675174474716187\n",
      "Train size: [400] hidden size: [1491] trial: 38, train_loss: 0.210575, test loss: 0.828861, bias2: 0.34956490993499756, variance: 0.4792957901954651\n",
      "Train size: [400] hidden size: [1491] trial: 39, train_loss: 0.210497, test loss: 0.827291, bias2: 0.3477020263671875, variance: 0.4795893430709839\n",
      "Train size: [400] hidden size: [1491] trial: 40, train_loss: 0.211346, test loss: 0.825034, bias2: 0.3459203243255615, variance: 0.47911351919174194\n",
      "Train size: [400] hidden size: [1491] trial: 41, train_loss: 0.211704, test loss: 0.824173, bias2: 0.34408876299858093, variance: 0.48008373379707336\n",
      "Train size: [400] hidden size: [1491] trial: 42, train_loss: 0.211388, test loss: 0.823729, bias2: 0.3428722321987152, variance: 0.48085638880729675\n",
      "Train size: [400] hidden size: [1491] trial: 43, train_loss: 0.211025, test loss: 0.823711, bias2: 0.34254714846611023, variance: 0.48116418719291687\n",
      "Train size: [400] hidden size: [1491] trial: 44, train_loss: 0.210729, test loss: 0.825161, bias2: 0.3434789478778839, variance: 0.481682151556015\n",
      "Train size: [400] hidden size: [1491] trial: 45, train_loss: 0.210836, test loss: 0.823359, bias2: 0.3425840139389038, variance: 0.4807747006416321\n",
      "Train size: [400] hidden size: [1491] trial: 46, train_loss: 0.211063, test loss: 0.821591, bias2: 0.3411741554737091, variance: 0.48041680455207825\n",
      "Train size: [400] hidden size: [1491] trial: 47, train_loss: 0.210546, test loss: 0.822624, bias2: 0.3419429659843445, variance: 0.4806807041168213\n",
      "Train size: [400] hidden size: [1491] trial: 48, train_loss: 0.210334, test loss: 0.825849, bias2: 0.3440708518028259, variance: 0.481778085231781\n",
      "Train size: [400] hidden size: [1491] trial: 49, train_loss: 0.209875, test loss: 0.826765, bias2: 0.34343358874320984, variance: 0.4833313524723053\n",
      "##################################################\n",
      "Train size: [400] hidden size: [1717] trial: 0, train_loss: 0.200565, test loss: 0.797820, bias2: 0.7978197336196899, variance: 3.8925479506346505e-10\n",
      "Train size: [400] hidden size: [1717] trial: 1, train_loss: 0.188107, test loss: 0.776966, bias2: 0.557910680770874, variance: 0.2190554440021515\n",
      "Train size: [400] hidden size: [1717] trial: 2, train_loss: 0.185335, test loss: 0.789080, bias2: 0.493338406085968, variance: 0.29574131965637207\n",
      "Train size: [400] hidden size: [1717] trial: 3, train_loss: 0.189992, test loss: 0.787759, bias2: 0.4667403995990753, variance: 0.3210190236568451\n",
      "Train size: [400] hidden size: [1717] trial: 4, train_loss: 0.192379, test loss: 0.807417, bias2: 0.4501410126686096, variance: 0.3572758436203003\n",
      "Train size: [400] hidden size: [1717] trial: 5, train_loss: 0.192247, test loss: 0.813490, bias2: 0.4319354295730591, variance: 0.38155460357666016\n",
      "Train size: [400] hidden size: [1717] trial: 6, train_loss: 0.189923, test loss: 0.814774, bias2: 0.42757129669189453, variance: 0.3872023820877075\n",
      "Train size: [400] hidden size: [1717] trial: 7, train_loss: 0.191747, test loss: 0.803559, bias2: 0.4093421697616577, variance: 0.39421677589416504\n",
      "Train size: [400] hidden size: [1717] trial: 8, train_loss: 0.189593, test loss: 0.802491, bias2: 0.40093207359313965, variance: 0.40155869722366333\n",
      "Train size: [400] hidden size: [1717] trial: 9, train_loss: 0.189584, test loss: 0.802929, bias2: 0.39447617530822754, variance: 0.40845298767089844\n",
      "Train size: [400] hidden size: [1717] trial: 10, train_loss: 0.191243, test loss: 0.798576, bias2: 0.38993123173713684, variance: 0.40864506363868713\n",
      "Train size: [400] hidden size: [1717] trial: 11, train_loss: 0.190090, test loss: 0.801822, bias2: 0.38691937923431396, variance: 0.41490286588668823\n",
      "Train size: [400] hidden size: [1717] trial: 12, train_loss: 0.189582, test loss: 0.806980, bias2: 0.3876747488975525, variance: 0.4193054437637329\n",
      "Train size: [400] hidden size: [1717] trial: 13, train_loss: 0.188044, test loss: 0.810590, bias2: 0.38767188787460327, variance: 0.4229181408882141\n",
      "Train size: [400] hidden size: [1717] trial: 14, train_loss: 0.187338, test loss: 0.810158, bias2: 0.38342028856277466, variance: 0.4267377257347107\n",
      "Train size: [400] hidden size: [1717] trial: 15, train_loss: 0.189710, test loss: 0.806085, bias2: 0.378250390291214, variance: 0.42783501744270325\n",
      "Train size: [400] hidden size: [1717] trial: 16, train_loss: 0.190491, test loss: 0.808173, bias2: 0.3790753185749054, variance: 0.4290980398654938\n",
      "Train size: [400] hidden size: [1717] trial: 17, train_loss: 0.190555, test loss: 0.805885, bias2: 0.37547850608825684, variance: 0.43040645122528076\n",
      "Train size: [400] hidden size: [1717] trial: 18, train_loss: 0.191827, test loss: 0.803586, bias2: 0.37368345260620117, variance: 0.4299021363258362\n",
      "Train size: [400] hidden size: [1717] trial: 19, train_loss: 0.191684, test loss: 0.801098, bias2: 0.37144213914871216, variance: 0.42965561151504517\n",
      "Train size: [400] hidden size: [1717] trial: 20, train_loss: 0.190566, test loss: 0.798436, bias2: 0.3685111701488495, variance: 0.42992451786994934\n",
      "Train size: [400] hidden size: [1717] trial: 21, train_loss: 0.191568, test loss: 0.797571, bias2: 0.3640461266040802, variance: 0.43352487683296204\n",
      "Train size: [400] hidden size: [1717] trial: 22, train_loss: 0.191343, test loss: 0.797112, bias2: 0.36126190423965454, variance: 0.4358501434326172\n",
      "Train size: [400] hidden size: [1717] trial: 23, train_loss: 0.191458, test loss: 0.800192, bias2: 0.36044639348983765, variance: 0.43974602222442627\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [1717] trial: 24, train_loss: 0.191676, test loss: 0.799553, bias2: 0.3595392107963562, variance: 0.4400135278701782\n",
      "Train size: [400] hidden size: [1717] trial: 25, train_loss: 0.192124, test loss: 0.799198, bias2: 0.3581414818763733, variance: 0.44105637073516846\n",
      "Train size: [400] hidden size: [1717] trial: 26, train_loss: 0.192692, test loss: 0.797524, bias2: 0.3555449843406677, variance: 0.44197946786880493\n",
      "Train size: [400] hidden size: [1717] trial: 27, train_loss: 0.192531, test loss: 0.798170, bias2: 0.3555694818496704, variance: 0.44260042905807495\n",
      "Train size: [400] hidden size: [1717] trial: 28, train_loss: 0.192720, test loss: 0.796267, bias2: 0.35317549109458923, variance: 0.44309118390083313\n",
      "Train size: [400] hidden size: [1717] trial: 29, train_loss: 0.192607, test loss: 0.795150, bias2: 0.3533351421356201, variance: 0.441814661026001\n",
      "Train size: [400] hidden size: [1717] trial: 30, train_loss: 0.193950, test loss: 0.795461, bias2: 0.3508774936199188, variance: 0.44458380341529846\n",
      "Train size: [400] hidden size: [1717] trial: 31, train_loss: 0.193200, test loss: 0.793406, bias2: 0.3496493697166443, variance: 0.4437562823295593\n",
      "Train size: [400] hidden size: [1717] trial: 32, train_loss: 0.193401, test loss: 0.793306, bias2: 0.3492303788661957, variance: 0.44407543540000916\n",
      "Train size: [400] hidden size: [1717] trial: 33, train_loss: 0.193845, test loss: 0.794718, bias2: 0.3492489457130432, variance: 0.4454690217971802\n",
      "Train size: [400] hidden size: [1717] trial: 34, train_loss: 0.193466, test loss: 0.798264, bias2: 0.35139667987823486, variance: 0.44686686992645264\n",
      "Train size: [400] hidden size: [1717] trial: 35, train_loss: 0.193763, test loss: 0.799008, bias2: 0.35091614723205566, variance: 0.44809144735336304\n",
      "Train size: [400] hidden size: [1717] trial: 36, train_loss: 0.194377, test loss: 0.801899, bias2: 0.35117971897125244, variance: 0.4507192373275757\n",
      "Train size: [400] hidden size: [1717] trial: 37, train_loss: 0.195050, test loss: 0.802388, bias2: 0.35050728917121887, variance: 0.45188096165657043\n",
      "Train size: [400] hidden size: [1717] trial: 38, train_loss: 0.195777, test loss: 0.800970, bias2: 0.34862083196640015, variance: 0.4523490071296692\n",
      "Train size: [400] hidden size: [1717] trial: 39, train_loss: 0.197364, test loss: 0.800482, bias2: 0.34781861305236816, variance: 0.4526635408401489\n",
      "Train size: [400] hidden size: [1717] trial: 40, train_loss: 0.197354, test loss: 0.801872, bias2: 0.34843865036964417, variance: 0.4534335434436798\n",
      "Train size: [400] hidden size: [1717] trial: 41, train_loss: 0.196890, test loss: 0.802639, bias2: 0.34835001826286316, variance: 0.45428863167762756\n",
      "Train size: [400] hidden size: [1717] trial: 42, train_loss: 0.196836, test loss: 0.802527, bias2: 0.3470270335674286, variance: 0.45550021529197693\n",
      "Train size: [400] hidden size: [1717] trial: 43, train_loss: 0.197275, test loss: 0.803329, bias2: 0.34766778349876404, variance: 0.4556609094142914\n",
      "Train size: [400] hidden size: [1717] trial: 44, train_loss: 0.197947, test loss: 0.802520, bias2: 0.3457823395729065, variance: 0.45673733949661255\n",
      "Train size: [400] hidden size: [1717] trial: 45, train_loss: 0.197711, test loss: 0.801748, bias2: 0.34512731432914734, variance: 0.4566207826137543\n",
      "Train size: [400] hidden size: [1717] trial: 46, train_loss: 0.197791, test loss: 0.801932, bias2: 0.34426215291023254, variance: 0.4576694667339325\n",
      "Train size: [400] hidden size: [1717] trial: 47, train_loss: 0.197535, test loss: 0.802337, bias2: 0.3447471261024475, variance: 0.45759016275405884\n",
      "Train size: [400] hidden size: [1717] trial: 48, train_loss: 0.197666, test loss: 0.802423, bias2: 0.3441358208656311, variance: 0.4582871198654175\n",
      "Train size: [400] hidden size: [1717] trial: 49, train_loss: 0.197535, test loss: 0.802697, bias2: 0.3445928990840912, variance: 0.4581044018268585\n",
      "##################################################\n",
      "Train size: [400] hidden size: [1977] trial: 0, train_loss: 0.216902, test loss: 0.751593, bias2: 0.751593291759491, variance: -3.8925479506346505e-10\n",
      "Train size: [400] hidden size: [1977] trial: 1, train_loss: 0.209602, test loss: 0.798774, bias2: 0.5877315998077393, variance: 0.21104231476783752\n",
      "Train size: [400] hidden size: [1977] trial: 2, train_loss: 0.192307, test loss: 0.795653, bias2: 0.5208228826522827, variance: 0.2748298943042755\n",
      "Train size: [400] hidden size: [1977] trial: 3, train_loss: 0.189687, test loss: 0.776175, bias2: 0.4671339988708496, variance: 0.30904120206832886\n",
      "Train size: [400] hidden size: [1977] trial: 4, train_loss: 0.188298, test loss: 0.771505, bias2: 0.43506327271461487, variance: 0.33644184470176697\n",
      "Train size: [400] hidden size: [1977] trial: 5, train_loss: 0.189160, test loss: 0.776403, bias2: 0.42202678322792053, variance: 0.35437652468681335\n",
      "Train size: [400] hidden size: [1977] trial: 6, train_loss: 0.192468, test loss: 0.786067, bias2: 0.417584091424942, variance: 0.3684825003147125\n",
      "Train size: [400] hidden size: [1977] trial: 7, train_loss: 0.192021, test loss: 0.785154, bias2: 0.40650537610054016, variance: 0.37864890694618225\n",
      "Train size: [400] hidden size: [1977] trial: 8, train_loss: 0.194783, test loss: 0.783728, bias2: 0.39582306146621704, variance: 0.38790446519851685\n",
      "Train size: [400] hidden size: [1977] trial: 9, train_loss: 0.193410, test loss: 0.778785, bias2: 0.38543465733528137, variance: 0.393350213766098\n",
      "Train size: [400] hidden size: [1977] trial: 10, train_loss: 0.195768, test loss: 0.792301, bias2: 0.386020302772522, variance: 0.4062803387641907\n",
      "Train size: [400] hidden size: [1977] trial: 11, train_loss: 0.196751, test loss: 0.788775, bias2: 0.3792078197002411, variance: 0.4095672070980072\n",
      "Train size: [400] hidden size: [1977] trial: 12, train_loss: 0.196541, test loss: 0.794891, bias2: 0.38384461402893066, variance: 0.41104620695114136\n",
      "Train size: [400] hidden size: [1977] trial: 13, train_loss: 0.198708, test loss: 0.787804, bias2: 0.3718544542789459, variance: 0.41594943404197693\n",
      "Train size: [400] hidden size: [1977] trial: 14, train_loss: 0.199481, test loss: 0.786007, bias2: 0.3693699240684509, variance: 0.41663658618927\n",
      "Train size: [400] hidden size: [1977] trial: 15, train_loss: 0.198990, test loss: 0.781590, bias2: 0.36499324440956116, variance: 0.416596382856369\n",
      "Train size: [400] hidden size: [1977] trial: 16, train_loss: 0.196816, test loss: 0.788740, bias2: 0.3708151578903198, variance: 0.4179248809814453\n",
      "Train size: [400] hidden size: [1977] trial: 17, train_loss: 0.197093, test loss: 0.791253, bias2: 0.3721901476383209, variance: 0.41906335949897766\n",
      "Train size: [400] hidden size: [1977] trial: 18, train_loss: 0.196373, test loss: 0.789331, bias2: 0.37084484100341797, variance: 0.4184860587120056\n",
      "Train size: [400] hidden size: [1977] trial: 19, train_loss: 0.196369, test loss: 0.792688, bias2: 0.37299761176109314, variance: 0.4196905791759491\n",
      "Train size: [400] hidden size: [1977] trial: 20, train_loss: 0.196070, test loss: 0.793008, bias2: 0.36999762058258057, variance: 0.42301028966903687\n",
      "Train size: [400] hidden size: [1977] trial: 21, train_loss: 0.196530, test loss: 0.788306, bias2: 0.3637065291404724, variance: 0.4245993494987488\n",
      "Train size: [400] hidden size: [1977] trial: 22, train_loss: 0.196024, test loss: 0.786200, bias2: 0.3607926666736603, variance: 0.42540743947029114\n",
      "Train size: [400] hidden size: [1977] trial: 23, train_loss: 0.195817, test loss: 0.783923, bias2: 0.3581240773200989, variance: 0.4257991909980774\n",
      "Train size: [400] hidden size: [1977] trial: 24, train_loss: 0.194916, test loss: 0.784253, bias2: 0.3580566644668579, variance: 0.4261965751647949\n",
      "Train size: [400] hidden size: [1977] trial: 25, train_loss: 0.193865, test loss: 0.782683, bias2: 0.35663679242134094, variance: 0.42604610323905945\n",
      "Train size: [400] hidden size: [1977] trial: 26, train_loss: 0.193887, test loss: 0.780321, bias2: 0.3541032075881958, variance: 0.4262179732322693\n",
      "Train size: [400] hidden size: [1977] trial: 27, train_loss: 0.193168, test loss: 0.781052, bias2: 0.3555990755558014, variance: 0.42545321583747864\n",
      "Train size: [400] hidden size: [1977] trial: 28, train_loss: 0.192492, test loss: 0.780646, bias2: 0.35554128885269165, variance: 0.42510443925857544\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [1977] trial: 29, train_loss: 0.192649, test loss: 0.784310, bias2: 0.35745736956596375, variance: 0.42685267329216003\n",
      "Train size: [400] hidden size: [1977] trial: 30, train_loss: 0.191560, test loss: 0.781956, bias2: 0.35569503903388977, variance: 0.4262607991695404\n",
      "Train size: [400] hidden size: [1977] trial: 31, train_loss: 0.191171, test loss: 0.778026, bias2: 0.3541651964187622, variance: 0.4238610863685608\n",
      "Train size: [400] hidden size: [1977] trial: 32, train_loss: 0.190760, test loss: 0.779202, bias2: 0.3556336462497711, variance: 0.42356809973716736\n",
      "Train size: [400] hidden size: [1977] trial: 33, train_loss: 0.189970, test loss: 0.779278, bias2: 0.35549384355545044, variance: 0.4237845540046692\n",
      "Train size: [400] hidden size: [1977] trial: 34, train_loss: 0.189997, test loss: 0.779769, bias2: 0.35583388805389404, variance: 0.4239351749420166\n",
      "Train size: [400] hidden size: [1977] trial: 35, train_loss: 0.189051, test loss: 0.779257, bias2: 0.3544889986515045, variance: 0.4247683584690094\n",
      "Train size: [400] hidden size: [1977] trial: 36, train_loss: 0.188979, test loss: 0.779876, bias2: 0.35518956184387207, variance: 0.4246866703033447\n",
      "Train size: [400] hidden size: [1977] trial: 37, train_loss: 0.188859, test loss: 0.779013, bias2: 0.3540063500404358, variance: 0.4250069856643677\n",
      "Train size: [400] hidden size: [1977] trial: 38, train_loss: 0.189138, test loss: 0.776676, bias2: 0.3514944016933441, variance: 0.42518118023872375\n",
      "Train size: [400] hidden size: [1977] trial: 39, train_loss: 0.189688, test loss: 0.776009, bias2: 0.35120314359664917, variance: 0.42480581998825073\n",
      "Train size: [400] hidden size: [1977] trial: 40, train_loss: 0.189174, test loss: 0.774316, bias2: 0.350423127412796, variance: 0.423893004655838\n",
      "Train size: [400] hidden size: [1977] trial: 41, train_loss: 0.188207, test loss: 0.773821, bias2: 0.35118621587753296, variance: 0.42263466119766235\n",
      "Train size: [400] hidden size: [1977] trial: 42, train_loss: 0.188300, test loss: 0.775896, bias2: 0.3527553975582123, variance: 0.42314091324806213\n",
      "Train size: [400] hidden size: [1977] trial: 43, train_loss: 0.187418, test loss: 0.777631, bias2: 0.35477766394615173, variance: 0.42285284399986267\n",
      "Train size: [400] hidden size: [1977] trial: 44, train_loss: 0.187398, test loss: 0.778517, bias2: 0.35487106442451477, variance: 0.42364558577537537\n",
      "Train size: [400] hidden size: [1977] trial: 45, train_loss: 0.187708, test loss: 0.777803, bias2: 0.3543155789375305, variance: 0.42348700761795044\n",
      "Train size: [400] hidden size: [1977] trial: 46, train_loss: 0.187486, test loss: 0.778818, bias2: 0.3547915518283844, variance: 0.42402616143226624\n",
      "Train size: [400] hidden size: [1977] trial: 47, train_loss: 0.187176, test loss: 0.780835, bias2: 0.3561382591724396, variance: 0.4246971309185028\n",
      "Train size: [400] hidden size: [1977] trial: 48, train_loss: 0.187246, test loss: 0.781822, bias2: 0.35687947273254395, variance: 0.4249420762062073\n",
      "Train size: [400] hidden size: [1977] trial: 49, train_loss: 0.187119, test loss: 0.780054, bias2: 0.3560754954814911, variance: 0.4239788353443146\n",
      "##################################################\n",
      "Train size: [400] hidden size: [2276] trial: 0, train_loss: 0.171323, test loss: 0.807095, bias2: 0.807095468044281, variance: -3.892548061656953e-09\n",
      "Train size: [400] hidden size: [2276] trial: 1, train_loss: 0.176229, test loss: 0.808010, bias2: 0.5740985870361328, variance: 0.23391103744506836\n",
      "Train size: [400] hidden size: [2276] trial: 2, train_loss: 0.194325, test loss: 0.790994, bias2: 0.5051483511924744, variance: 0.28584569692611694\n",
      "Train size: [400] hidden size: [2276] trial: 3, train_loss: 0.191690, test loss: 0.780688, bias2: 0.4648834764957428, variance: 0.31580498814582825\n",
      "Train size: [400] hidden size: [2276] trial: 4, train_loss: 0.186595, test loss: 0.778724, bias2: 0.4443114995956421, variance: 0.334412157535553\n",
      "Train size: [400] hidden size: [2276] trial: 5, train_loss: 0.183099, test loss: 0.770145, bias2: 0.4279727339744568, variance: 0.34217214584350586\n",
      "Train size: [400] hidden size: [2276] trial: 6, train_loss: 0.181100, test loss: 0.768188, bias2: 0.4147084057331085, variance: 0.35347917675971985\n",
      "Train size: [400] hidden size: [2276] trial: 7, train_loss: 0.180963, test loss: 0.765537, bias2: 0.40909332036972046, variance: 0.35644346475601196\n",
      "Train size: [400] hidden size: [2276] trial: 8, train_loss: 0.181162, test loss: 0.780760, bias2: 0.4071991741657257, variance: 0.3735603988170624\n",
      "Train size: [400] hidden size: [2276] trial: 9, train_loss: 0.182546, test loss: 0.773989, bias2: 0.3983016610145569, variance: 0.37568771839141846\n",
      "Train size: [400] hidden size: [2276] trial: 10, train_loss: 0.182962, test loss: 0.773855, bias2: 0.3925967514514923, variance: 0.38125792145729065\n",
      "Train size: [400] hidden size: [2276] trial: 11, train_loss: 0.183203, test loss: 0.773998, bias2: 0.3904433846473694, variance: 0.38355499505996704\n",
      "Train size: [400] hidden size: [2276] trial: 12, train_loss: 0.182849, test loss: 0.771252, bias2: 0.3844447731971741, variance: 0.38680702447891235\n",
      "Train size: [400] hidden size: [2276] trial: 13, train_loss: 0.182267, test loss: 0.769938, bias2: 0.38241100311279297, variance: 0.38752710819244385\n",
      "Train size: [400] hidden size: [2276] trial: 14, train_loss: 0.181826, test loss: 0.768789, bias2: 0.3786967396736145, variance: 0.3900919556617737\n",
      "Train size: [400] hidden size: [2276] trial: 15, train_loss: 0.181334, test loss: 0.769923, bias2: 0.37630751729011536, variance: 0.3936155140399933\n",
      "Train size: [400] hidden size: [2276] trial: 16, train_loss: 0.181681, test loss: 0.771734, bias2: 0.37766292691230774, variance: 0.394071489572525\n",
      "Train size: [400] hidden size: [2276] trial: 17, train_loss: 0.180282, test loss: 0.768097, bias2: 0.3741317391395569, variance: 0.3939657211303711\n",
      "Train size: [400] hidden size: [2276] trial: 18, train_loss: 0.180229, test loss: 0.763782, bias2: 0.3697301745414734, variance: 0.39405202865600586\n",
      "Train size: [400] hidden size: [2276] trial: 19, train_loss: 0.181535, test loss: 0.764719, bias2: 0.3662993907928467, variance: 0.3984193801879883\n",
      "Train size: [400] hidden size: [2276] trial: 20, train_loss: 0.181936, test loss: 0.759544, bias2: 0.3614957630634308, variance: 0.39804813265800476\n",
      "Train size: [400] hidden size: [2276] trial: 21, train_loss: 0.182491, test loss: 0.759333, bias2: 0.3605972230434418, variance: 0.39873597025871277\n",
      "Train size: [400] hidden size: [2276] trial: 22, train_loss: 0.183149, test loss: 0.758528, bias2: 0.3593456745147705, variance: 0.3991823196411133\n",
      "Train size: [400] hidden size: [2276] trial: 23, train_loss: 0.183539, test loss: 0.757870, bias2: 0.3590657413005829, variance: 0.3988041579723358\n",
      "Train size: [400] hidden size: [2276] trial: 24, train_loss: 0.183212, test loss: 0.758094, bias2: 0.35913875699043274, variance: 0.39895519614219666\n",
      "Train size: [400] hidden size: [2276] trial: 25, train_loss: 0.184069, test loss: 0.754691, bias2: 0.35372307896614075, variance: 0.4009683430194855\n",
      "Train size: [400] hidden size: [2276] trial: 26, train_loss: 0.184727, test loss: 0.753917, bias2: 0.35240134596824646, variance: 0.4015158712863922\n",
      "Train size: [400] hidden size: [2276] trial: 27, train_loss: 0.184422, test loss: 0.752518, bias2: 0.35224491357803345, variance: 0.4002726078033447\n",
      "Train size: [400] hidden size: [2276] trial: 28, train_loss: 0.184408, test loss: 0.748574, bias2: 0.34776026010513306, variance: 0.40081334114074707\n",
      "Train size: [400] hidden size: [2276] trial: 29, train_loss: 0.184626, test loss: 0.749490, bias2: 0.34800001978874207, variance: 0.4014897048473358\n",
      "Train size: [400] hidden size: [2276] trial: 30, train_loss: 0.184024, test loss: 0.750109, bias2: 0.35038360953330994, variance: 0.3997251093387604\n",
      "Train size: [400] hidden size: [2276] trial: 31, train_loss: 0.184664, test loss: 0.751375, bias2: 0.3511281907558441, variance: 0.40024659037590027\n",
      "Train size: [400] hidden size: [2276] trial: 32, train_loss: 0.185390, test loss: 0.749962, bias2: 0.34842050075531006, variance: 0.4015417695045471\n",
      "Train size: [400] hidden size: [2276] trial: 33, train_loss: 0.185889, test loss: 0.749870, bias2: 0.34898048639297485, variance: 0.4008893370628357\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [2276] trial: 34, train_loss: 0.185600, test loss: 0.749596, bias2: 0.3484260141849518, variance: 0.40117040276527405\n",
      "Train size: [400] hidden size: [2276] trial: 35, train_loss: 0.185663, test loss: 0.749388, bias2: 0.34805163741111755, variance: 0.40133681893348694\n",
      "Train size: [400] hidden size: [2276] trial: 36, train_loss: 0.185225, test loss: 0.749410, bias2: 0.34761619567871094, variance: 0.4017937183380127\n",
      "Train size: [400] hidden size: [2276] trial: 37, train_loss: 0.185418, test loss: 0.749141, bias2: 0.34719616174697876, variance: 0.40194523334503174\n",
      "Train size: [400] hidden size: [2276] trial: 38, train_loss: 0.185738, test loss: 0.746685, bias2: 0.3451026678085327, variance: 0.4015825390815735\n",
      "Train size: [400] hidden size: [2276] trial: 39, train_loss: 0.186695, test loss: 0.746799, bias2: 0.3439779281616211, variance: 0.40282100439071655\n",
      "Train size: [400] hidden size: [2276] trial: 40, train_loss: 0.186137, test loss: 0.747340, bias2: 0.3437323570251465, variance: 0.40360724925994873\n",
      "Train size: [400] hidden size: [2276] trial: 41, train_loss: 0.185799, test loss: 0.747594, bias2: 0.3449831008911133, variance: 0.40261054039001465\n",
      "Train size: [400] hidden size: [2276] trial: 42, train_loss: 0.185652, test loss: 0.747991, bias2: 0.34545835852622986, variance: 0.4025331437587738\n",
      "Train size: [400] hidden size: [2276] trial: 43, train_loss: 0.185237, test loss: 0.748312, bias2: 0.3461954891681671, variance: 0.4021165668964386\n",
      "Train size: [400] hidden size: [2276] trial: 44, train_loss: 0.185302, test loss: 0.748114, bias2: 0.34568873047828674, variance: 0.4024254381656647\n",
      "Train size: [400] hidden size: [2276] trial: 45, train_loss: 0.185298, test loss: 0.749591, bias2: 0.3470643162727356, variance: 0.40252625942230225\n",
      "Train size: [400] hidden size: [2276] trial: 46, train_loss: 0.185373, test loss: 0.748497, bias2: 0.3456416726112366, variance: 0.4028555750846863\n",
      "Train size: [400] hidden size: [2276] trial: 47, train_loss: 0.185175, test loss: 0.748745, bias2: 0.34570035338401794, variance: 0.403044193983078\n",
      "Train size: [400] hidden size: [2276] trial: 48, train_loss: 0.184902, test loss: 0.748420, bias2: 0.34585732221603394, variance: 0.4025631546974182\n",
      "Train size: [400] hidden size: [2276] trial: 49, train_loss: 0.184770, test loss: 0.750018, bias2: 0.3468935787677765, variance: 0.40312448143959045\n",
      "##################################################\n",
      "Train size: [400] hidden size: [2621] trial: 0, train_loss: 0.184488, test loss: 0.666306, bias2: 0.6663062572479248, variance: 4.281802912231569e-09\n",
      "Train size: [400] hidden size: [2621] trial: 1, train_loss: 0.180587, test loss: 0.673411, bias2: 0.4748626947402954, variance: 0.19854873418807983\n",
      "Train size: [400] hidden size: [2621] trial: 2, train_loss: 0.175740, test loss: 0.714238, bias2: 0.44721102714538574, variance: 0.26702743768692017\n",
      "Train size: [400] hidden size: [2621] trial: 3, train_loss: 0.174456, test loss: 0.723542, bias2: 0.42644739151000977, variance: 0.297094464302063\n",
      "Train size: [400] hidden size: [2621] trial: 4, train_loss: 0.179182, test loss: 0.725212, bias2: 0.4099246859550476, variance: 0.3152875304222107\n",
      "Train size: [400] hidden size: [2621] trial: 5, train_loss: 0.179760, test loss: 0.728040, bias2: 0.4045250117778778, variance: 0.32351455092430115\n",
      "Train size: [400] hidden size: [2621] trial: 6, train_loss: 0.175899, test loss: 0.737670, bias2: 0.40335482358932495, variance: 0.3343154788017273\n",
      "Train size: [400] hidden size: [2621] trial: 7, train_loss: 0.179313, test loss: 0.729623, bias2: 0.3916739821434021, variance: 0.3379487991333008\n",
      "Train size: [400] hidden size: [2621] trial: 8, train_loss: 0.180627, test loss: 0.724325, bias2: 0.38033175468444824, variance: 0.3439928889274597\n",
      "Train size: [400] hidden size: [2621] trial: 9, train_loss: 0.184676, test loss: 0.725992, bias2: 0.37871330976486206, variance: 0.34727853536605835\n",
      "Train size: [400] hidden size: [2621] trial: 10, train_loss: 0.184422, test loss: 0.730369, bias2: 0.37894150614738464, variance: 0.3514276444911957\n",
      "Train size: [400] hidden size: [2621] trial: 11, train_loss: 0.184115, test loss: 0.728648, bias2: 0.3763589560985565, variance: 0.3522893488407135\n",
      "Train size: [400] hidden size: [2621] trial: 12, train_loss: 0.183578, test loss: 0.729251, bias2: 0.37451499700546265, variance: 0.35473573207855225\n",
      "Train size: [400] hidden size: [2621] trial: 13, train_loss: 0.181423, test loss: 0.728700, bias2: 0.3725453019142151, variance: 0.3561546802520752\n",
      "Train size: [400] hidden size: [2621] trial: 14, train_loss: 0.182797, test loss: 0.730112, bias2: 0.3701121509075165, variance: 0.3600001037120819\n",
      "Train size: [400] hidden size: [2621] trial: 15, train_loss: 0.181615, test loss: 0.731864, bias2: 0.3708287477493286, variance: 0.36103570461273193\n",
      "Train size: [400] hidden size: [2621] trial: 16, train_loss: 0.181037, test loss: 0.734063, bias2: 0.3708864152431488, variance: 0.3631766140460968\n",
      "Train size: [400] hidden size: [2621] trial: 17, train_loss: 0.180021, test loss: 0.733468, bias2: 0.370046466588974, variance: 0.36342117190361023\n",
      "Train size: [400] hidden size: [2621] trial: 18, train_loss: 0.178475, test loss: 0.731629, bias2: 0.3665975034236908, variance: 0.3650319278240204\n",
      "Train size: [400] hidden size: [2621] trial: 19, train_loss: 0.177939, test loss: 0.728693, bias2: 0.36354905366897583, variance: 0.36514437198638916\n",
      "Train size: [400] hidden size: [2621] trial: 20, train_loss: 0.176746, test loss: 0.730776, bias2: 0.3611120283603668, variance: 0.36966440081596375\n",
      "Train size: [400] hidden size: [2621] trial: 21, train_loss: 0.177354, test loss: 0.730570, bias2: 0.36028796434402466, variance: 0.37028247117996216\n",
      "Train size: [400] hidden size: [2621] trial: 22, train_loss: 0.177971, test loss: 0.729756, bias2: 0.36054229736328125, variance: 0.36921340227127075\n",
      "Train size: [400] hidden size: [2621] trial: 23, train_loss: 0.177901, test loss: 0.727758, bias2: 0.3584057092666626, variance: 0.3693523406982422\n",
      "Train size: [400] hidden size: [2621] trial: 24, train_loss: 0.178452, test loss: 0.728683, bias2: 0.3572526276111603, variance: 0.3714299499988556\n",
      "Train size: [400] hidden size: [2621] trial: 25, train_loss: 0.177931, test loss: 0.728341, bias2: 0.355965793132782, variance: 0.3723757266998291\n",
      "Train size: [400] hidden size: [2621] trial: 26, train_loss: 0.178648, test loss: 0.727246, bias2: 0.35408419370651245, variance: 0.37316155433654785\n",
      "Train size: [400] hidden size: [2621] trial: 27, train_loss: 0.177396, test loss: 0.726577, bias2: 0.3527505099773407, variance: 0.37382665276527405\n",
      "Train size: [400] hidden size: [2621] trial: 28, train_loss: 0.177589, test loss: 0.727499, bias2: 0.352499783039093, variance: 0.37499940395355225\n",
      "Train size: [400] hidden size: [2621] trial: 29, train_loss: 0.178005, test loss: 0.727537, bias2: 0.3518851101398468, variance: 0.3756515681743622\n",
      "Train size: [400] hidden size: [2621] trial: 30, train_loss: 0.177705, test loss: 0.727488, bias2: 0.3498401641845703, variance: 0.3776475191116333\n",
      "Train size: [400] hidden size: [2621] trial: 31, train_loss: 0.177119, test loss: 0.727747, bias2: 0.350326806306839, variance: 0.3774197995662689\n",
      "Train size: [400] hidden size: [2621] trial: 32, train_loss: 0.177128, test loss: 0.728812, bias2: 0.3510761857032776, variance: 0.37773597240448\n",
      "Train size: [400] hidden size: [2621] trial: 33, train_loss: 0.177029, test loss: 0.729383, bias2: 0.3519912660121918, variance: 0.37739136815071106\n",
      "Train size: [400] hidden size: [2621] trial: 34, train_loss: 0.177572, test loss: 0.729261, bias2: 0.3508732318878174, variance: 0.3783873915672302\n",
      "Train size: [400] hidden size: [2621] trial: 35, train_loss: 0.177658, test loss: 0.731255, bias2: 0.3518997132778168, variance: 0.37935516238212585\n",
      "Train size: [400] hidden size: [2621] trial: 36, train_loss: 0.177549, test loss: 0.730844, bias2: 0.350389301776886, variance: 0.3804543614387512\n",
      "Train size: [400] hidden size: [2621] trial: 37, train_loss: 0.178264, test loss: 0.732627, bias2: 0.34972885251045227, variance: 0.38289859890937805\n",
      "Train size: [400] hidden size: [2621] trial: 38, train_loss: 0.178011, test loss: 0.732414, bias2: 0.3485736846923828, variance: 0.3838399052619934\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [2621] trial: 39, train_loss: 0.177815, test loss: 0.732564, bias2: 0.34970903396606445, variance: 0.38285547494888306\n",
      "Train size: [400] hidden size: [2621] trial: 40, train_loss: 0.177801, test loss: 0.732734, bias2: 0.349763423204422, variance: 0.38297024369239807\n",
      "Train size: [400] hidden size: [2621] trial: 41, train_loss: 0.178286, test loss: 0.731495, bias2: 0.34852656722068787, variance: 0.3829684555530548\n",
      "Train size: [400] hidden size: [2621] trial: 42, train_loss: 0.178622, test loss: 0.731444, bias2: 0.34820419549942017, variance: 0.3832399249076843\n",
      "Train size: [400] hidden size: [2621] trial: 43, train_loss: 0.178675, test loss: 0.731505, bias2: 0.34628531336784363, variance: 0.3852197229862213\n",
      "Train size: [400] hidden size: [2621] trial: 44, train_loss: 0.178941, test loss: 0.733306, bias2: 0.34659242630004883, variance: 0.38671380281448364\n",
      "Train size: [400] hidden size: [2621] trial: 45, train_loss: 0.179045, test loss: 0.733190, bias2: 0.34572336077690125, variance: 0.387466698884964\n",
      "Train size: [400] hidden size: [2621] trial: 46, train_loss: 0.179289, test loss: 0.733389, bias2: 0.34585821628570557, variance: 0.3875312805175781\n",
      "Train size: [400] hidden size: [2621] trial: 47, train_loss: 0.179374, test loss: 0.732453, bias2: 0.34462931752204895, variance: 0.3878239095211029\n",
      "Train size: [400] hidden size: [2621] trial: 48, train_loss: 0.179381, test loss: 0.732985, bias2: 0.3447915315628052, variance: 0.3881933093070984\n",
      "Train size: [400] hidden size: [2621] trial: 49, train_loss: 0.179433, test loss: 0.732836, bias2: 0.3453589379787445, variance: 0.38747677206993103\n",
      "##################################################\n",
      "Train size: [400] hidden size: [3017] trial: 0, train_loss: 0.168100, test loss: 0.648526, bias2: 0.6485257148742676, variance: -1.1677644407015464e-09\n",
      "Train size: [400] hidden size: [3017] trial: 1, train_loss: 0.161406, test loss: 0.652901, bias2: 0.4792827367782593, variance: 0.17361827194690704\n",
      "Train size: [400] hidden size: [3017] trial: 2, train_loss: 0.163368, test loss: 0.682676, bias2: 0.4324978291988373, variance: 0.25017818808555603\n",
      "Train size: [400] hidden size: [3017] trial: 3, train_loss: 0.164484, test loss: 0.693340, bias2: 0.4123997688293457, variance: 0.2809401750564575\n",
      "Train size: [400] hidden size: [3017] trial: 4, train_loss: 0.165964, test loss: 0.704329, bias2: 0.4051990211009979, variance: 0.29913046956062317\n",
      "Train size: [400] hidden size: [3017] trial: 5, train_loss: 0.168323, test loss: 0.699041, bias2: 0.3815024495124817, variance: 0.31753838062286377\n",
      "Train size: [400] hidden size: [3017] trial: 6, train_loss: 0.173776, test loss: 0.699966, bias2: 0.3729403018951416, variance: 0.32702553272247314\n",
      "Train size: [400] hidden size: [3017] trial: 7, train_loss: 0.171644, test loss: 0.692860, bias2: 0.36298123002052307, variance: 0.32987889647483826\n",
      "Train size: [400] hidden size: [3017] trial: 8, train_loss: 0.172351, test loss: 0.693379, bias2: 0.36130958795547485, variance: 0.3320697546005249\n",
      "Train size: [400] hidden size: [3017] trial: 9, train_loss: 0.172771, test loss: 0.694701, bias2: 0.35679879784584045, variance: 0.3379017412662506\n",
      "Train size: [400] hidden size: [3017] trial: 10, train_loss: 0.173087, test loss: 0.698402, bias2: 0.3567967414855957, variance: 0.3416052460670471\n",
      "Train size: [400] hidden size: [3017] trial: 11, train_loss: 0.174251, test loss: 0.703732, bias2: 0.3542245924472809, variance: 0.34950706362724304\n",
      "Train size: [400] hidden size: [3017] trial: 12, train_loss: 0.174004, test loss: 0.703639, bias2: 0.3527366816997528, variance: 0.35090258717536926\n",
      "Train size: [400] hidden size: [3017] trial: 13, train_loss: 0.174325, test loss: 0.704317, bias2: 0.3513410687446594, variance: 0.35297590494155884\n",
      "Train size: [400] hidden size: [3017] trial: 14, train_loss: 0.173406, test loss: 0.705866, bias2: 0.3495556116104126, variance: 0.3563101291656494\n",
      "Train size: [400] hidden size: [3017] trial: 15, train_loss: 0.173182, test loss: 0.706818, bias2: 0.34891757369041443, variance: 0.3579001724720001\n",
      "Train size: [400] hidden size: [3017] trial: 16, train_loss: 0.171594, test loss: 0.709832, bias2: 0.35031986236572266, variance: 0.35951244831085205\n",
      "Train size: [400] hidden size: [3017] trial: 17, train_loss: 0.170497, test loss: 0.711904, bias2: 0.35087430477142334, variance: 0.36102962493896484\n",
      "Train size: [400] hidden size: [3017] trial: 18, train_loss: 0.170881, test loss: 0.711929, bias2: 0.34907767176628113, variance: 0.36285123229026794\n",
      "Train size: [400] hidden size: [3017] trial: 19, train_loss: 0.170811, test loss: 0.718354, bias2: 0.3515128195285797, variance: 0.3668411672115326\n",
      "Train size: [400] hidden size: [3017] trial: 20, train_loss: 0.169565, test loss: 0.717745, bias2: 0.34991779923439026, variance: 0.367826908826828\n",
      "Train size: [400] hidden size: [3017] trial: 21, train_loss: 0.169734, test loss: 0.714819, bias2: 0.3465854823589325, variance: 0.36823323369026184\n",
      "Train size: [400] hidden size: [3017] trial: 22, train_loss: 0.169904, test loss: 0.714862, bias2: 0.34445810317993164, variance: 0.37040382623672485\n",
      "Train size: [400] hidden size: [3017] trial: 23, train_loss: 0.170033, test loss: 0.715224, bias2: 0.34360453486442566, variance: 0.37161973118782043\n",
      "Train size: [400] hidden size: [3017] trial: 24, train_loss: 0.169976, test loss: 0.714185, bias2: 0.34223875403404236, variance: 0.3719462454319\n",
      "Train size: [400] hidden size: [3017] trial: 25, train_loss: 0.169581, test loss: 0.715512, bias2: 0.34255075454711914, variance: 0.37296122312545776\n",
      "Train size: [400] hidden size: [3017] trial: 26, train_loss: 0.168941, test loss: 0.716405, bias2: 0.3439566195011139, variance: 0.37244847416877747\n",
      "Train size: [400] hidden size: [3017] trial: 27, train_loss: 0.169215, test loss: 0.713749, bias2: 0.3414174020290375, variance: 0.37233206629753113\n",
      "Train size: [400] hidden size: [3017] trial: 28, train_loss: 0.169375, test loss: 0.714787, bias2: 0.34231939911842346, variance: 0.37246784567832947\n",
      "Train size: [400] hidden size: [3017] trial: 29, train_loss: 0.169431, test loss: 0.714284, bias2: 0.3417256772518158, variance: 0.37255850434303284\n",
      "Train size: [400] hidden size: [3017] trial: 30, train_loss: 0.169523, test loss: 0.717771, bias2: 0.34418320655822754, variance: 0.37358808517456055\n",
      "Train size: [400] hidden size: [3017] trial: 31, train_loss: 0.169386, test loss: 0.719445, bias2: 0.34470608830451965, variance: 0.37473931908607483\n",
      "Train size: [400] hidden size: [3017] trial: 32, train_loss: 0.169851, test loss: 0.719427, bias2: 0.3441208302974701, variance: 0.3753063380718231\n",
      "Train size: [400] hidden size: [3017] trial: 33, train_loss: 0.170318, test loss: 0.719485, bias2: 0.3433827757835388, variance: 0.3761024475097656\n",
      "Train size: [400] hidden size: [3017] trial: 34, train_loss: 0.170555, test loss: 0.718913, bias2: 0.34140968322753906, variance: 0.3775033950805664\n",
      "Train size: [400] hidden size: [3017] trial: 35, train_loss: 0.170870, test loss: 0.721356, bias2: 0.3426073491573334, variance: 0.3787483870983124\n",
      "Train size: [400] hidden size: [3017] trial: 36, train_loss: 0.170479, test loss: 0.722039, bias2: 0.34402182698249817, variance: 0.37801727652549744\n",
      "Train size: [400] hidden size: [3017] trial: 37, train_loss: 0.170303, test loss: 0.721703, bias2: 0.3433988392353058, variance: 0.37830445170402527\n",
      "Train size: [400] hidden size: [3017] trial: 38, train_loss: 0.170376, test loss: 0.722662, bias2: 0.3446650803089142, variance: 0.3779967725276947\n",
      "Train size: [400] hidden size: [3017] trial: 39, train_loss: 0.170431, test loss: 0.721536, bias2: 0.3434654176235199, variance: 0.37807056307792664\n",
      "Train size: [400] hidden size: [3017] trial: 40, train_loss: 0.170221, test loss: 0.720479, bias2: 0.34258604049682617, variance: 0.3778930902481079\n",
      "Train size: [400] hidden size: [3017] trial: 41, train_loss: 0.170510, test loss: 0.721949, bias2: 0.34197282791137695, variance: 0.37997567653656006\n",
      "Train size: [400] hidden size: [3017] trial: 42, train_loss: 0.170590, test loss: 0.721083, bias2: 0.34013837575912476, variance: 0.38094431161880493\n",
      "Train size: [400] hidden size: [3017] trial: 43, train_loss: 0.170340, test loss: 0.718215, bias2: 0.3380281627178192, variance: 0.3801864683628082\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [3017] trial: 44, train_loss: 0.170019, test loss: 0.717715, bias2: 0.33827367424964905, variance: 0.37944093346595764\n",
      "Train size: [400] hidden size: [3017] trial: 45, train_loss: 0.170495, test loss: 0.719542, bias2: 0.339143842458725, variance: 0.38039836287498474\n",
      "Train size: [400] hidden size: [3017] trial: 46, train_loss: 0.171357, test loss: 0.719045, bias2: 0.3388051986694336, variance: 0.38024014234542847\n",
      "Train size: [400] hidden size: [3017] trial: 47, train_loss: 0.170796, test loss: 0.720186, bias2: 0.34011510014533997, variance: 0.3800713121891022\n",
      "Train size: [400] hidden size: [3017] trial: 48, train_loss: 0.170518, test loss: 0.721402, bias2: 0.33998265862464905, variance: 0.38141974806785583\n",
      "Train size: [400] hidden size: [3017] trial: 49, train_loss: 0.170519, test loss: 0.720646, bias2: 0.33948421478271484, variance: 0.38116204738616943\n",
      "##################################################\n",
      "Train size: [400] hidden size: [3474] trial: 0, train_loss: 0.158931, test loss: 0.681349, bias2: 0.6813490986824036, variance: 8.563605824463139e-09\n",
      "Train size: [400] hidden size: [3474] trial: 1, train_loss: 0.165452, test loss: 0.651249, bias2: 0.4777489900588989, variance: 0.17350037395954132\n",
      "Train size: [400] hidden size: [3474] trial: 2, train_loss: 0.161990, test loss: 0.699266, bias2: 0.4517410397529602, variance: 0.2475246638059616\n",
      "Train size: [400] hidden size: [3474] trial: 3, train_loss: 0.159594, test loss: 0.690685, bias2: 0.4128085970878601, variance: 0.2778761386871338\n",
      "Train size: [400] hidden size: [3474] trial: 4, train_loss: 0.159894, test loss: 0.697843, bias2: 0.4012252688407898, variance: 0.2966175675392151\n",
      "Train size: [400] hidden size: [3474] trial: 5, train_loss: 0.160664, test loss: 0.705337, bias2: 0.39145341515541077, variance: 0.3138836920261383\n",
      "Train size: [400] hidden size: [3474] trial: 6, train_loss: 0.160222, test loss: 0.701996, bias2: 0.3850562572479248, variance: 0.3169392943382263\n",
      "Train size: [400] hidden size: [3474] trial: 7, train_loss: 0.161019, test loss: 0.704520, bias2: 0.37524890899658203, variance: 0.32927143573760986\n",
      "Train size: [400] hidden size: [3474] trial: 8, train_loss: 0.162633, test loss: 0.707745, bias2: 0.37723833322525024, variance: 0.33050644397735596\n",
      "Train size: [400] hidden size: [3474] trial: 9, train_loss: 0.165224, test loss: 0.716846, bias2: 0.37761184573173523, variance: 0.3392341434955597\n",
      "Train size: [400] hidden size: [3474] trial: 10, train_loss: 0.167889, test loss: 0.717998, bias2: 0.37325406074523926, variance: 0.34474390745162964\n",
      "Train size: [400] hidden size: [3474] trial: 11, train_loss: 0.166519, test loss: 0.719874, bias2: 0.37616974115371704, variance: 0.3437044024467468\n",
      "Train size: [400] hidden size: [3474] trial: 12, train_loss: 0.165537, test loss: 0.714886, bias2: 0.37258321046829224, variance: 0.3423025608062744\n",
      "Train size: [400] hidden size: [3474] trial: 13, train_loss: 0.165588, test loss: 0.713801, bias2: 0.3682469129562378, variance: 0.3455541133880615\n",
      "Train size: [400] hidden size: [3474] trial: 14, train_loss: 0.166275, test loss: 0.712351, bias2: 0.3631172776222229, variance: 0.3492335081100464\n",
      "Train size: [400] hidden size: [3474] trial: 15, train_loss: 0.167045, test loss: 0.712527, bias2: 0.3598482012748718, variance: 0.3526788353919983\n",
      "Train size: [400] hidden size: [3474] trial: 16, train_loss: 0.168564, test loss: 0.713632, bias2: 0.3582121431827545, variance: 0.3554198443889618\n",
      "Train size: [400] hidden size: [3474] trial: 17, train_loss: 0.168564, test loss: 0.713047, bias2: 0.3557320833206177, variance: 0.3573150634765625\n",
      "Train size: [400] hidden size: [3474] trial: 18, train_loss: 0.170202, test loss: 0.716575, bias2: 0.354617178440094, variance: 0.36195796728134155\n",
      "Train size: [400] hidden size: [3474] trial: 19, train_loss: 0.171637, test loss: 0.716222, bias2: 0.35250550508499146, variance: 0.3637160062789917\n",
      "Train size: [400] hidden size: [3474] trial: 20, train_loss: 0.170921, test loss: 0.712857, bias2: 0.35063785314559937, variance: 0.36221903562545776\n",
      "Train size: [400] hidden size: [3474] trial: 21, train_loss: 0.170374, test loss: 0.714546, bias2: 0.35288283228874207, variance: 0.36166271567344666\n",
      "Train size: [400] hidden size: [3474] trial: 22, train_loss: 0.170363, test loss: 0.713289, bias2: 0.35158246755599976, variance: 0.3617069125175476\n",
      "Train size: [400] hidden size: [3474] trial: 23, train_loss: 0.170635, test loss: 0.712138, bias2: 0.3495565354824066, variance: 0.36258140206336975\n",
      "Train size: [400] hidden size: [3474] trial: 24, train_loss: 0.170012, test loss: 0.714659, bias2: 0.35113510489463806, variance: 0.36352410912513733\n",
      "Train size: [400] hidden size: [3474] trial: 25, train_loss: 0.169764, test loss: 0.714495, bias2: 0.3508641719818115, variance: 0.3636311888694763\n",
      "Train size: [400] hidden size: [3474] trial: 26, train_loss: 0.170813, test loss: 0.712678, bias2: 0.3482663929462433, variance: 0.3644119203090668\n",
      "Train size: [400] hidden size: [3474] trial: 27, train_loss: 0.170711, test loss: 0.710381, bias2: 0.34644296765327454, variance: 0.36393818259239197\n",
      "Train size: [400] hidden size: [3474] trial: 28, train_loss: 0.170869, test loss: 0.709358, bias2: 0.34422874450683594, variance: 0.36512887477874756\n",
      "Train size: [400] hidden size: [3474] trial: 29, train_loss: 0.171529, test loss: 0.709005, bias2: 0.3427569568157196, variance: 0.36624768376350403\n",
      "Train size: [400] hidden size: [3474] trial: 30, train_loss: 0.170968, test loss: 0.710253, bias2: 0.34349727630615234, variance: 0.3667556047439575\n",
      "Train size: [400] hidden size: [3474] trial: 31, train_loss: 0.171144, test loss: 0.709270, bias2: 0.34188345074653625, variance: 0.367386132478714\n",
      "Train size: [400] hidden size: [3474] trial: 32, train_loss: 0.171494, test loss: 0.710572, bias2: 0.3435761332511902, variance: 0.36699604988098145\n",
      "Train size: [400] hidden size: [3474] trial: 33, train_loss: 0.171994, test loss: 0.710708, bias2: 0.34230563044548035, variance: 0.3684028685092926\n",
      "Train size: [400] hidden size: [3474] trial: 34, train_loss: 0.172065, test loss: 0.709183, bias2: 0.341164767742157, variance: 0.36801832914352417\n",
      "Train size: [400] hidden size: [3474] trial: 35, train_loss: 0.171648, test loss: 0.707527, bias2: 0.3413066864013672, variance: 0.36622053384780884\n",
      "Train size: [400] hidden size: [3474] trial: 36, train_loss: 0.171991, test loss: 0.707232, bias2: 0.3401601314544678, variance: 0.36707180738449097\n",
      "Train size: [400] hidden size: [3474] trial: 37, train_loss: 0.171754, test loss: 0.707792, bias2: 0.3397056758403778, variance: 0.3680858910083771\n",
      "Train size: [400] hidden size: [3474] trial: 38, train_loss: 0.172290, test loss: 0.706046, bias2: 0.33851057291030884, variance: 0.3675357699394226\n",
      "Train size: [400] hidden size: [3474] trial: 39, train_loss: 0.172665, test loss: 0.704830, bias2: 0.33676543831825256, variance: 0.36806413531303406\n",
      "Train size: [400] hidden size: [3474] trial: 40, train_loss: 0.172580, test loss: 0.704883, bias2: 0.33659955859184265, variance: 0.36828359961509705\n",
      "Train size: [400] hidden size: [3474] trial: 41, train_loss: 0.172277, test loss: 0.704339, bias2: 0.33637821674346924, variance: 0.367961049079895\n",
      "Train size: [400] hidden size: [3474] trial: 42, train_loss: 0.171942, test loss: 0.704726, bias2: 0.33698850870132446, variance: 0.36773747205734253\n",
      "Train size: [400] hidden size: [3474] trial: 43, train_loss: 0.171324, test loss: 0.704792, bias2: 0.337056040763855, variance: 0.36773574352264404\n",
      "Train size: [400] hidden size: [3474] trial: 44, train_loss: 0.171428, test loss: 0.706401, bias2: 0.33778685331344604, variance: 0.3686145544052124\n",
      "Train size: [400] hidden size: [3474] trial: 45, train_loss: 0.171629, test loss: 0.705510, bias2: 0.3363598585128784, variance: 0.36915016174316406\n",
      "Train size: [400] hidden size: [3474] trial: 46, train_loss: 0.171341, test loss: 0.704836, bias2: 0.33632880449295044, variance: 0.36850714683532715\n",
      "Train size: [400] hidden size: [3474] trial: 47, train_loss: 0.171369, test loss: 0.703848, bias2: 0.3350594937801361, variance: 0.3687882125377655\n",
      "Train size: [400] hidden size: [3474] trial: 48, train_loss: 0.171523, test loss: 0.704558, bias2: 0.3344244360923767, variance: 0.37013375759124756\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [3474] trial: 49, train_loss: 0.171648, test loss: 0.705972, bias2: 0.33541324734687805, variance: 0.37055906653404236\n",
      "##################################################\n",
      "Train size: [400] hidden size: [4000] trial: 0, train_loss: 0.164026, test loss: 0.666356, bias2: 0.6663554906845093, variance: 4.6710577628061856e-09\n",
      "Train size: [400] hidden size: [4000] trial: 1, train_loss: 0.170545, test loss: 0.696273, bias2: 0.5200822949409485, variance: 0.17619077861309052\n",
      "Train size: [400] hidden size: [4000] trial: 2, train_loss: 0.161616, test loss: 0.676099, bias2: 0.44568389654159546, variance: 0.2304147332906723\n",
      "Train size: [400] hidden size: [4000] trial: 3, train_loss: 0.163345, test loss: 0.689343, bias2: 0.4290739893913269, variance: 0.26026856899261475\n",
      "Train size: [400] hidden size: [4000] trial: 4, train_loss: 0.167074, test loss: 0.682072, bias2: 0.39641448855400085, variance: 0.2856576144695282\n",
      "Train size: [400] hidden size: [4000] trial: 5, train_loss: 0.164046, test loss: 0.686468, bias2: 0.3880188763141632, variance: 0.2984495460987091\n",
      "Train size: [400] hidden size: [4000] trial: 6, train_loss: 0.168229, test loss: 0.689332, bias2: 0.3789905607700348, variance: 0.31034108996391296\n",
      "Train size: [400] hidden size: [4000] trial: 7, train_loss: 0.166806, test loss: 0.678676, bias2: 0.3657096326351166, variance: 0.31296661496162415\n",
      "Train size: [400] hidden size: [4000] trial: 8, train_loss: 0.168700, test loss: 0.679192, bias2: 0.35688745975494385, variance: 0.32230448722839355\n",
      "Train size: [400] hidden size: [4000] trial: 9, train_loss: 0.168041, test loss: 0.680909, bias2: 0.35234391689300537, variance: 0.3285646438598633\n",
      "Train size: [400] hidden size: [4000] trial: 10, train_loss: 0.167394, test loss: 0.683301, bias2: 0.3519514501094818, variance: 0.3313499987125397\n",
      "Train size: [400] hidden size: [4000] trial: 11, train_loss: 0.166291, test loss: 0.686104, bias2: 0.35111913084983826, variance: 0.3349844515323639\n",
      "Train size: [400] hidden size: [4000] trial: 12, train_loss: 0.165702, test loss: 0.680480, bias2: 0.34506282210350037, variance: 0.3354171812534332\n",
      "Train size: [400] hidden size: [4000] trial: 13, train_loss: 0.164025, test loss: 0.681269, bias2: 0.3412366807460785, variance: 0.34003207087516785\n",
      "Train size: [400] hidden size: [4000] trial: 14, train_loss: 0.164123, test loss: 0.682606, bias2: 0.339245468378067, variance: 0.3433610498905182\n",
      "Train size: [400] hidden size: [4000] trial: 15, train_loss: 0.164046, test loss: 0.686493, bias2: 0.3407769501209259, variance: 0.34571602940559387\n",
      "Train size: [400] hidden size: [4000] trial: 16, train_loss: 0.164765, test loss: 0.688064, bias2: 0.33927178382873535, variance: 0.34879177808761597\n",
      "Train size: [400] hidden size: [4000] trial: 17, train_loss: 0.163957, test loss: 0.687662, bias2: 0.3383259177207947, variance: 0.34933584928512573\n",
      "Train size: [400] hidden size: [4000] trial: 18, train_loss: 0.164572, test loss: 0.686468, bias2: 0.33873170614242554, variance: 0.3477365970611572\n",
      "Train size: [400] hidden size: [4000] trial: 19, train_loss: 0.164990, test loss: 0.687812, bias2: 0.3393433094024658, variance: 0.3484688997268677\n",
      "Train size: [400] hidden size: [4000] trial: 20, train_loss: 0.166913, test loss: 0.688045, bias2: 0.33869969844818115, variance: 0.3493450880050659\n",
      "Train size: [400] hidden size: [4000] trial: 21, train_loss: 0.167252, test loss: 0.692312, bias2: 0.34045496582984924, variance: 0.35185685753822327\n",
      "Train size: [400] hidden size: [4000] trial: 22, train_loss: 0.167270, test loss: 0.692411, bias2: 0.3384702205657959, variance: 0.3539409637451172\n",
      "Train size: [400] hidden size: [4000] trial: 23, train_loss: 0.166749, test loss: 0.694255, bias2: 0.33852601051330566, variance: 0.355729341506958\n",
      "Train size: [400] hidden size: [4000] trial: 24, train_loss: 0.166512, test loss: 0.692388, bias2: 0.338189035654068, variance: 0.3541986048221588\n",
      "Train size: [400] hidden size: [4000] trial: 25, train_loss: 0.166139, test loss: 0.692477, bias2: 0.3367709815502167, variance: 0.35570576786994934\n",
      "Train size: [400] hidden size: [4000] trial: 26, train_loss: 0.166838, test loss: 0.691664, bias2: 0.3357713520526886, variance: 0.35589298605918884\n",
      "Train size: [400] hidden size: [4000] trial: 27, train_loss: 0.167325, test loss: 0.692422, bias2: 0.3355209529399872, variance: 0.35690101981163025\n",
      "Train size: [400] hidden size: [4000] trial: 28, train_loss: 0.168462, test loss: 0.693428, bias2: 0.33413562178611755, variance: 0.35929253697395325\n",
      "Train size: [400] hidden size: [4000] trial: 29, train_loss: 0.167441, test loss: 0.693213, bias2: 0.3335462510585785, variance: 0.3596670925617218\n",
      "Train size: [400] hidden size: [4000] trial: 30, train_loss: 0.167919, test loss: 0.692623, bias2: 0.33256766200065613, variance: 0.36005493998527527\n",
      "Train size: [400] hidden size: [4000] trial: 31, train_loss: 0.167623, test loss: 0.694706, bias2: 0.3340284824371338, variance: 0.36067765951156616\n",
      "Train size: [400] hidden size: [4000] trial: 32, train_loss: 0.167271, test loss: 0.694506, bias2: 0.3329872786998749, variance: 0.361518532037735\n",
      "Train size: [400] hidden size: [4000] trial: 33, train_loss: 0.166644, test loss: 0.696496, bias2: 0.33455657958984375, variance: 0.36193913221359253\n",
      "Train size: [400] hidden size: [4000] trial: 34, train_loss: 0.166345, test loss: 0.695913, bias2: 0.3350604772567749, variance: 0.36085253953933716\n",
      "Train size: [400] hidden size: [4000] trial: 35, train_loss: 0.166495, test loss: 0.696140, bias2: 0.3352227807044983, variance: 0.3609170913696289\n",
      "Train size: [400] hidden size: [4000] trial: 36, train_loss: 0.166466, test loss: 0.696671, bias2: 0.3359278440475464, variance: 0.3607432246208191\n",
      "Train size: [400] hidden size: [4000] trial: 37, train_loss: 0.166855, test loss: 0.696715, bias2: 0.33581286668777466, variance: 0.3609020709991455\n",
      "Train size: [400] hidden size: [4000] trial: 38, train_loss: 0.166452, test loss: 0.696104, bias2: 0.3356020450592041, variance: 0.360501766204834\n",
      "Train size: [400] hidden size: [4000] trial: 39, train_loss: 0.166818, test loss: 0.696220, bias2: 0.33439505100250244, variance: 0.36182504892349243\n",
      "Train size: [400] hidden size: [4000] trial: 40, train_loss: 0.166560, test loss: 0.696249, bias2: 0.33505529165267944, variance: 0.36119353771209717\n",
      "Train size: [400] hidden size: [4000] trial: 41, train_loss: 0.166483, test loss: 0.696947, bias2: 0.3358754515647888, variance: 0.3610711693763733\n",
      "Train size: [400] hidden size: [4000] trial: 42, train_loss: 0.166850, test loss: 0.695393, bias2: 0.33418434858322144, variance: 0.36120837926864624\n",
      "Train size: [400] hidden size: [4000] trial: 43, train_loss: 0.166799, test loss: 0.693354, bias2: 0.33318522572517395, variance: 0.3601689040660858\n",
      "Train size: [400] hidden size: [4000] trial: 44, train_loss: 0.166353, test loss: 0.693707, bias2: 0.33323854207992554, variance: 0.3604680895805359\n",
      "Train size: [400] hidden size: [4000] trial: 45, train_loss: 0.166903, test loss: 0.693562, bias2: 0.33230236172676086, variance: 0.3612591326236725\n",
      "Train size: [400] hidden size: [4000] trial: 46, train_loss: 0.166847, test loss: 0.693099, bias2: 0.33213913440704346, variance: 0.360959529876709\n",
      "Train size: [400] hidden size: [4000] trial: 47, train_loss: 0.167371, test loss: 0.692531, bias2: 0.33122390508651733, variance: 0.3613075017929077\n",
      "Train size: [400] hidden size: [4000] trial: 48, train_loss: 0.166947, test loss: 0.693326, bias2: 0.33185845613479614, variance: 0.3614673614501953\n",
      "Train size: [400] hidden size: [4000] trial: 49, train_loss: 0.167313, test loss: 0.693394, bias2: 0.33205854892730713, variance: 0.3613351583480835\n",
      "##################################################\n"
     ]
    }
   ],
   "source": [
    "run_exps_ridge(train_sizes, N_Ds, P_Ns, beta, test_size, feature_dim, num_classes, num_trials, coef,\n",
    "             outdir, 'singleNN_output.csv', SNR= SNR, K = 1, F_norm = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [4] trial: 0, train_loss: 1.926988, test loss: 1.005509, bias2: 1.0055092573165894, variance: 2.5088688071495113e-11\n",
      "Train size: [400] hidden size: [4] trial: 1, train_loss: 1.909421, test loss: 1.005395, bias2: 1.004164457321167, variance: 0.0012300811940804124\n",
      "Train size: [400] hidden size: [4] trial: 2, train_loss: 1.924670, test loss: 1.007745, bias2: 1.0021342039108276, variance: 0.005610555876046419\n",
      "Train size: [400] hidden size: [4] trial: 3, train_loss: 1.924726, test loss: 1.009335, bias2: 1.0031623840332031, variance: 0.006172841880470514\n",
      "Train size: [400] hidden size: [4] trial: 4, train_loss: 1.912132, test loss: 1.006996, bias2: 1.0009149312973022, variance: 0.006081241182982922\n",
      "Train size: [400] hidden size: [4] trial: 5, train_loss: 1.905424, test loss: 1.008016, bias2: 1.0019820928573608, variance: 0.006033885292708874\n",
      "Train size: [400] hidden size: [4] trial: 6, train_loss: 1.913150, test loss: 1.008038, bias2: 1.0026092529296875, variance: 0.005428565666079521\n",
      "Train size: [400] hidden size: [4] trial: 7, train_loss: 1.916347, test loss: 1.008979, bias2: 1.0035768747329712, variance: 0.005402409005910158\n",
      "Train size: [400] hidden size: [4] trial: 8, train_loss: 1.924973, test loss: 1.009565, bias2: 1.0043684244155884, variance: 0.0051963794976472855\n",
      "Train size: [400] hidden size: [4] trial: 9, train_loss: 1.913872, test loss: 1.008927, bias2: 1.0035436153411865, variance: 0.005383895710110664\n",
      "Train size: [400] hidden size: [4] trial: 10, train_loss: 1.915436, test loss: 1.008801, bias2: 1.0030474662780762, variance: 0.005753613077104092\n",
      "Train size: [400] hidden size: [4] trial: 11, train_loss: 1.918703, test loss: 1.008650, bias2: 1.0029633045196533, variance: 0.005686466582119465\n",
      "Train size: [400] hidden size: [4] trial: 12, train_loss: 1.931979, test loss: 1.008200, bias2: 1.0025790929794312, variance: 0.005620792042464018\n",
      "Train size: [400] hidden size: [4] trial: 13, train_loss: 1.941944, test loss: 1.008157, bias2: 1.0028259754180908, variance: 0.005331065040081739\n",
      "Train size: [400] hidden size: [4] trial: 14, train_loss: 1.954402, test loss: 1.007903, bias2: 1.0026569366455078, variance: 0.005246400833129883\n",
      "Train size: [400] hidden size: [4] trial: 15, train_loss: 1.933846, test loss: 1.008666, bias2: 1.0032379627227783, variance: 0.005427861586213112\n",
      "Train size: [400] hidden size: [4] trial: 16, train_loss: 1.933285, test loss: 1.008245, bias2: 1.0020982027053833, variance: 0.006147162523120642\n",
      "Train size: [400] hidden size: [4] trial: 17, train_loss: 1.929733, test loss: 1.008085, bias2: 1.0018553733825684, variance: 0.006229456048458815\n",
      "Train size: [400] hidden size: [4] trial: 18, train_loss: 1.938645, test loss: 1.008143, bias2: 1.0021071434020996, variance: 0.006035765167325735\n",
      "Train size: [400] hidden size: [4] trial: 19, train_loss: 1.935504, test loss: 1.008219, bias2: 1.0014785528182983, variance: 0.006739987060427666\n",
      "Train size: [400] hidden size: [4] trial: 20, train_loss: 1.933670, test loss: 1.008261, bias2: 1.001579999923706, variance: 0.006680633407086134\n",
      "Train size: [400] hidden size: [4] trial: 21, train_loss: 1.938865, test loss: 1.008307, bias2: 1.0014972686767578, variance: 0.006809657905250788\n",
      "Train size: [400] hidden size: [4] trial: 22, train_loss: 1.947125, test loss: 1.008290, bias2: 1.0017211437225342, variance: 0.006568701006472111\n",
      "Train size: [400] hidden size: [4] trial: 23, train_loss: 1.948764, test loss: 1.008422, bias2: 1.00194251537323, variance: 0.006479113362729549\n",
      "Train size: [400] hidden size: [4] trial: 24, train_loss: 1.949389, test loss: 1.008383, bias2: 1.0020737648010254, variance: 0.006309186108410358\n",
      "Train size: [400] hidden size: [4] trial: 25, train_loss: 1.946751, test loss: 1.008663, bias2: 1.0022600889205933, variance: 0.006402892060577869\n",
      "Train size: [400] hidden size: [4] trial: 26, train_loss: 1.955788, test loss: 1.008689, bias2: 1.0023514032363892, variance: 0.006337124388664961\n",
      "Train size: [400] hidden size: [4] trial: 27, train_loss: 1.963102, test loss: 1.008790, bias2: 1.0025912523269653, variance: 0.006199236493557692\n",
      "Train size: [400] hidden size: [4] trial: 28, train_loss: 1.968443, test loss: 1.008806, bias2: 1.0024813413619995, variance: 0.006324895191937685\n",
      "Train size: [400] hidden size: [4] trial: 29, train_loss: 1.981008, test loss: 1.008976, bias2: 1.0025978088378906, variance: 0.0063785286620259285\n",
      "Train size: [400] hidden size: [4] trial: 30, train_loss: 1.985266, test loss: 1.008745, bias2: 1.0020980834960938, variance: 0.006646859925240278\n",
      "Train size: [400] hidden size: [4] trial: 31, train_loss: 1.979804, test loss: 1.008690, bias2: 1.0020757913589478, variance: 0.006614216137677431\n",
      "Train size: [400] hidden size: [4] trial: 32, train_loss: 1.980363, test loss: 1.008994, bias2: 1.002103328704834, variance: 0.006890829186886549\n",
      "Train size: [400] hidden size: [4] trial: 33, train_loss: 1.980056, test loss: 1.009026, bias2: 1.0022151470184326, variance: 0.00681057944893837\n",
      "Train size: [400] hidden size: [4] trial: 34, train_loss: 1.984341, test loss: 1.009205, bias2: 1.0023653507232666, variance: 0.006840008310973644\n",
      "Train size: [400] hidden size: [4] trial: 35, train_loss: 1.988769, test loss: 1.009177, bias2: 1.0022422075271606, variance: 0.006934782024472952\n",
      "Train size: [400] hidden size: [4] trial: 36, train_loss: 1.985057, test loss: 1.009181, bias2: 1.0023826360702515, variance: 0.006798760034143925\n",
      "Train size: [400] hidden size: [4] trial: 37, train_loss: 1.982603, test loss: 1.009277, bias2: 1.0025417804718018, variance: 0.006735334638506174\n",
      "Train size: [400] hidden size: [4] trial: 38, train_loss: 1.981560, test loss: 1.008993, bias2: 1.0020391941070557, variance: 0.006954165641218424\n",
      "Train size: [400] hidden size: [4] trial: 39, train_loss: 1.979092, test loss: 1.008981, bias2: 1.0020581483840942, variance: 0.006923008244484663\n",
      "Train size: [400] hidden size: [4] trial: 40, train_loss: 1.971802, test loss: 1.008677, bias2: 1.001746654510498, variance: 0.006930155213922262\n",
      "Train size: [400] hidden size: [4] trial: 41, train_loss: 1.974488, test loss: 1.008599, bias2: 1.001734733581543, variance: 0.006864562164992094\n",
      "Train size: [400] hidden size: [4] trial: 42, train_loss: 1.982026, test loss: 1.008547, bias2: 1.0017808675765991, variance: 0.0067664277739822865\n",
      "Train size: [400] hidden size: [4] trial: 43, train_loss: 1.980926, test loss: 1.008683, bias2: 1.0018784999847412, variance: 0.006804667413234711\n",
      "Train size: [400] hidden size: [4] trial: 44, train_loss: 1.979826, test loss: 1.008720, bias2: 1.0020005702972412, variance: 0.006719033233821392\n",
      "Train size: [400] hidden size: [4] trial: 45, train_loss: 1.984304, test loss: 1.008668, bias2: 1.0018380880355835, variance: 0.006829466205090284\n",
      "Train size: [400] hidden size: [4] trial: 46, train_loss: 1.989386, test loss: 1.008625, bias2: 1.001783013343811, variance: 0.0068421028554439545\n",
      "Train size: [400] hidden size: [4] trial: 47, train_loss: 1.990845, test loss: 1.008652, bias2: 1.0017973184585571, variance: 0.006854790262877941\n",
      "Train size: [400] hidden size: [4] trial: 48, train_loss: 1.988613, test loss: 1.008540, bias2: 1.0016523599624634, variance: 0.006887509487569332\n",
      "Train size: [400] hidden size: [4] trial: 49, train_loss: 1.988989, test loss: 1.008611, bias2: 1.0015231370925903, variance: 0.00708801718428731\n",
      "##################################################\n",
      "Train size: [400] hidden size: [5] trial: 0, train_loss: 2.241183, test loss: 1.001681, bias2: 1.0016812086105347, variance: 4.865684938293313e-11\n",
      "Train size: [400] hidden size: [5] trial: 1, train_loss: 2.088420, test loss: 1.005285, bias2: 1.0041084289550781, variance: 0.0011764252558350563\n",
      "Train size: [400] hidden size: [5] trial: 2, train_loss: 2.103956, test loss: 1.006700, bias2: 1.0037565231323242, variance: 0.002943083643913269\n",
      "Train size: [400] hidden size: [5] trial: 3, train_loss: 2.047113, test loss: 1.007836, bias2: 1.0042803287506104, variance: 0.00355553044937551\n",
      "Train size: [400] hidden size: [5] trial: 4, train_loss: 2.047628, test loss: 1.008110, bias2: 1.004191279411316, variance: 0.003918623086065054\n",
      "Train size: [400] hidden size: [5] trial: 5, train_loss: 2.018979, test loss: 1.009426, bias2: 1.0053422451019287, variance: 0.004083746112883091\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [5] trial: 6, train_loss: 1.982598, test loss: 1.009019, bias2: 1.0042155981063843, variance: 0.0048028863966465\n",
      "Train size: [400] hidden size: [5] trial: 7, train_loss: 1.962745, test loss: 1.008823, bias2: 1.0040282011032104, variance: 0.004794908221811056\n",
      "Train size: [400] hidden size: [5] trial: 8, train_loss: 1.971198, test loss: 1.010026, bias2: 1.0051714181900024, variance: 0.004854341968894005\n",
      "Train size: [400] hidden size: [5] trial: 9, train_loss: 1.995219, test loss: 1.009363, bias2: 1.0045764446258545, variance: 0.004786611534655094\n",
      "Train size: [400] hidden size: [5] trial: 10, train_loss: 1.997020, test loss: 1.009514, bias2: 1.0048052072525024, variance: 0.004708353895694017\n",
      "Train size: [400] hidden size: [5] trial: 11, train_loss: 1.987588, test loss: 1.008675, bias2: 1.0034862756729126, variance: 0.00518827885389328\n",
      "Train size: [400] hidden size: [5] trial: 12, train_loss: 1.993133, test loss: 1.008704, bias2: 1.0029399394989014, variance: 0.005763980094343424\n",
      "Train size: [400] hidden size: [5] trial: 13, train_loss: 1.997534, test loss: 1.008566, bias2: 1.0031250715255737, variance: 0.005440802313387394\n",
      "Train size: [400] hidden size: [5] trial: 14, train_loss: 1.995867, test loss: 1.008539, bias2: 1.0029948949813843, variance: 0.005543773993849754\n",
      "Train size: [400] hidden size: [5] trial: 15, train_loss: 1.982753, test loss: 1.008592, bias2: 1.003292441368103, variance: 0.005299366544932127\n",
      "Train size: [400] hidden size: [5] trial: 16, train_loss: 1.981260, test loss: 1.009267, bias2: 1.0036743879318237, variance: 0.005592969711869955\n",
      "Train size: [400] hidden size: [5] trial: 17, train_loss: 1.970123, test loss: 1.008955, bias2: 1.0032708644866943, variance: 0.005683674477040768\n",
      "Train size: [400] hidden size: [5] trial: 18, train_loss: 1.978948, test loss: 1.009195, bias2: 1.0036340951919556, variance: 0.005560738034546375\n",
      "Train size: [400] hidden size: [5] trial: 19, train_loss: 1.975897, test loss: 1.009495, bias2: 1.003994107246399, variance: 0.005500686354935169\n",
      "Train size: [400] hidden size: [5] trial: 20, train_loss: 1.969098, test loss: 1.008416, bias2: 1.0027806758880615, variance: 0.005635779816657305\n",
      "Train size: [400] hidden size: [5] trial: 21, train_loss: 1.975204, test loss: 1.007912, bias2: 1.0022255182266235, variance: 0.005686874035745859\n",
      "Train size: [400] hidden size: [5] trial: 22, train_loss: 1.979656, test loss: 1.007946, bias2: 1.0024687051773071, variance: 0.005477708298712969\n",
      "Train size: [400] hidden size: [5] trial: 23, train_loss: 1.979184, test loss: 1.008266, bias2: 1.002104640007019, variance: 0.006161361932754517\n",
      "Train size: [400] hidden size: [5] trial: 24, train_loss: 1.977314, test loss: 1.008334, bias2: 1.0023372173309326, variance: 0.00599717115983367\n",
      "Train size: [400] hidden size: [5] trial: 25, train_loss: 1.984059, test loss: 1.008357, bias2: 1.0024089813232422, variance: 0.005947678349912167\n",
      "Train size: [400] hidden size: [5] trial: 26, train_loss: 1.983461, test loss: 1.008332, bias2: 1.0025118589401245, variance: 0.0058197686448693275\n",
      "Train size: [400] hidden size: [5] trial: 27, train_loss: 1.973039, test loss: 1.008242, bias2: 1.0023610591888428, variance: 0.0058806538581848145\n",
      "Train size: [400] hidden size: [5] trial: 28, train_loss: 1.975953, test loss: 1.008377, bias2: 1.0024638175964355, variance: 0.005913428496569395\n",
      "Train size: [400] hidden size: [5] trial: 29, train_loss: 1.969884, test loss: 1.008276, bias2: 1.0024912357330322, variance: 0.005784438457340002\n",
      "Train size: [400] hidden size: [5] trial: 30, train_loss: 1.976111, test loss: 1.008244, bias2: 1.0024852752685547, variance: 0.005759024526923895\n",
      "Train size: [400] hidden size: [5] trial: 31, train_loss: 1.969380, test loss: 1.008306, bias2: 1.0025838613510132, variance: 0.005722023081034422\n",
      "Train size: [400] hidden size: [5] trial: 32, train_loss: 1.965870, test loss: 1.008414, bias2: 1.0027616024017334, variance: 0.00565221905708313\n",
      "Train size: [400] hidden size: [5] trial: 33, train_loss: 1.958779, test loss: 1.008145, bias2: 1.002572774887085, variance: 0.00557187432423234\n",
      "Train size: [400] hidden size: [5] trial: 34, train_loss: 1.967217, test loss: 1.008103, bias2: 1.0025460720062256, variance: 0.0055567123927176\n",
      "Train size: [400] hidden size: [5] trial: 35, train_loss: 1.963399, test loss: 1.008076, bias2: 1.002634882926941, variance: 0.005441417917609215\n",
      "Train size: [400] hidden size: [5] trial: 36, train_loss: 1.964693, test loss: 1.007939, bias2: 1.002455711364746, variance: 0.005483520217239857\n",
      "Train size: [400] hidden size: [5] trial: 37, train_loss: 1.960097, test loss: 1.008271, bias2: 1.0026707649230957, variance: 0.005599924363195896\n",
      "Train size: [400] hidden size: [5] trial: 38, train_loss: 1.959928, test loss: 1.008102, bias2: 1.0024268627166748, variance: 0.005674948915839195\n",
      "Train size: [400] hidden size: [5] trial: 39, train_loss: 1.954143, test loss: 1.008285, bias2: 1.0023990869522095, variance: 0.005885574035346508\n",
      "Train size: [400] hidden size: [5] trial: 40, train_loss: 1.954420, test loss: 1.008239, bias2: 1.0024690628051758, variance: 0.00577026791870594\n",
      "Train size: [400] hidden size: [5] trial: 41, train_loss: 1.951174, test loss: 1.007911, bias2: 1.0019298791885376, variance: 0.005981582682579756\n",
      "Train size: [400] hidden size: [5] trial: 42, train_loss: 1.948878, test loss: 1.008126, bias2: 1.002198338508606, variance: 0.005927528720349073\n",
      "Train size: [400] hidden size: [5] trial: 43, train_loss: 1.950459, test loss: 1.008647, bias2: 1.00247323513031, variance: 0.006174155976623297\n",
      "Train size: [400] hidden size: [5] trial: 44, train_loss: 1.953492, test loss: 1.008581, bias2: 1.0024176836013794, variance: 0.006163580343127251\n",
      "Train size: [400] hidden size: [5] trial: 45, train_loss: 1.959585, test loss: 1.008522, bias2: 1.0024428367614746, variance: 0.006079485174268484\n",
      "Train size: [400] hidden size: [5] trial: 46, train_loss: 1.957052, test loss: 1.008608, bias2: 1.002548336982727, variance: 0.006059946957975626\n",
      "Train size: [400] hidden size: [5] trial: 47, train_loss: 1.957552, test loss: 1.008586, bias2: 1.002569556236267, variance: 0.006016220897436142\n",
      "Train size: [400] hidden size: [5] trial: 48, train_loss: 1.958079, test loss: 1.008482, bias2: 1.0024688243865967, variance: 0.006012867204844952\n",
      "Train size: [400] hidden size: [5] trial: 49, train_loss: 1.960924, test loss: 1.008440, bias2: 1.0024993419647217, variance: 0.0059408205561339855\n",
      "##################################################\n",
      "Train size: [400] hidden size: [6] trial: 0, train_loss: 2.099843, test loss: 1.011108, bias2: 1.0111079216003418, variance: -6.690317050361827e-11\n",
      "Train size: [400] hidden size: [6] trial: 1, train_loss: 2.138603, test loss: 1.008206, bias2: 1.0049959421157837, variance: 0.00320980092510581\n",
      "Train size: [400] hidden size: [6] trial: 2, train_loss: 2.179610, test loss: 0.998445, bias2: 0.9918450117111206, variance: 0.006600106135010719\n",
      "Train size: [400] hidden size: [6] trial: 3, train_loss: 2.102132, test loss: 1.002627, bias2: 0.9964437484741211, variance: 0.006183752324432135\n",
      "Train size: [400] hidden size: [6] trial: 4, train_loss: 2.077302, test loss: 1.003340, bias2: 0.9970673322677612, variance: 0.006272787693887949\n",
      "Train size: [400] hidden size: [6] trial: 5, train_loss: 2.037717, test loss: 1.003219, bias2: 0.9967012405395508, variance: 0.0065178582444787025\n",
      "Train size: [400] hidden size: [6] trial: 6, train_loss: 2.048085, test loss: 1.003805, bias2: 0.9954044222831726, variance: 0.008400403894484043\n",
      "Train size: [400] hidden size: [6] trial: 7, train_loss: 2.032160, test loss: 1.003986, bias2: 0.9957069158554077, variance: 0.008279073052108288\n",
      "Train size: [400] hidden size: [6] trial: 8, train_loss: 2.047397, test loss: 1.004795, bias2: 0.9954777956008911, variance: 0.009316676296293736\n",
      "Train size: [400] hidden size: [6] trial: 9, train_loss: 2.049451, test loss: 1.005137, bias2: 0.9957770705223083, variance: 0.009359641931951046\n",
      "Train size: [400] hidden size: [6] trial: 10, train_loss: 2.037825, test loss: 1.005165, bias2: 0.9961481690406799, variance: 0.00901702418923378\n",
      "Train size: [400] hidden size: [6] trial: 11, train_loss: 2.034755, test loss: 1.005281, bias2: 0.9964120388031006, variance: 0.008868939243257046\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [6] trial: 12, train_loss: 2.037877, test loss: 1.004746, bias2: 0.9958992600440979, variance: 0.008846821263432503\n",
      "Train size: [400] hidden size: [6] trial: 13, train_loss: 2.026893, test loss: 1.004648, bias2: 0.9962985515594482, variance: 0.008349630050361156\n",
      "Train size: [400] hidden size: [6] trial: 14, train_loss: 2.032256, test loss: 1.004996, bias2: 0.9966527223587036, variance: 0.008343368768692017\n",
      "Train size: [400] hidden size: [6] trial: 15, train_loss: 2.035434, test loss: 1.005099, bias2: 0.9969939589500427, variance: 0.008105472661554813\n",
      "Train size: [400] hidden size: [6] trial: 16, train_loss: 2.022492, test loss: 1.005590, bias2: 0.9973664283752441, variance: 0.008223386481404305\n",
      "Train size: [400] hidden size: [6] trial: 17, train_loss: 2.015904, test loss: 1.005306, bias2: 0.9971697926521301, variance: 0.008136694319546223\n",
      "Train size: [400] hidden size: [6] trial: 18, train_loss: 2.014055, test loss: 1.005954, bias2: 0.9971294403076172, variance: 0.008824104443192482\n",
      "Train size: [400] hidden size: [6] trial: 19, train_loss: 2.010137, test loss: 1.006079, bias2: 0.9968795776367188, variance: 0.00919960718601942\n",
      "Train size: [400] hidden size: [6] trial: 20, train_loss: 2.011888, test loss: 1.006117, bias2: 0.9967504143714905, variance: 0.009366068989038467\n",
      "Train size: [400] hidden size: [6] trial: 21, train_loss: 2.011377, test loss: 1.006401, bias2: 0.9967156648635864, variance: 0.00968542043119669\n",
      "Train size: [400] hidden size: [6] trial: 22, train_loss: 2.004463, test loss: 1.007121, bias2: 0.9970417618751526, variance: 0.01007931586354971\n",
      "Train size: [400] hidden size: [6] trial: 23, train_loss: 2.000739, test loss: 1.007157, bias2: 0.9972071051597595, variance: 0.009950337931513786\n",
      "Train size: [400] hidden size: [6] trial: 24, train_loss: 2.003698, test loss: 1.007462, bias2: 0.9976588487625122, variance: 0.009803197346627712\n",
      "Train size: [400] hidden size: [6] trial: 25, train_loss: 2.001137, test loss: 1.007434, bias2: 0.997771143913269, variance: 0.009663247503340244\n",
      "Train size: [400] hidden size: [6] trial: 26, train_loss: 1.999430, test loss: 1.007496, bias2: 0.9979870319366455, variance: 0.009508613497018814\n",
      "Train size: [400] hidden size: [6] trial: 27, train_loss: 2.004189, test loss: 1.007612, bias2: 0.9979731440544128, variance: 0.00963906291872263\n",
      "Train size: [400] hidden size: [6] trial: 28, train_loss: 2.006235, test loss: 1.007858, bias2: 0.9981194138526917, variance: 0.009738652035593987\n",
      "Train size: [400] hidden size: [6] trial: 29, train_loss: 2.010857, test loss: 1.007748, bias2: 0.9981421828269958, variance: 0.009605925530195236\n",
      "Train size: [400] hidden size: [6] trial: 30, train_loss: 2.015736, test loss: 1.007913, bias2: 0.9984433054924011, variance: 0.009469463489949703\n",
      "Train size: [400] hidden size: [6] trial: 31, train_loss: 2.010271, test loss: 1.007718, bias2: 0.9983112215995789, variance: 0.009406373836100101\n",
      "Train size: [400] hidden size: [6] trial: 32, train_loss: 2.006844, test loss: 1.008274, bias2: 0.9986622929573059, variance: 0.00961169321089983\n",
      "Train size: [400] hidden size: [6] trial: 33, train_loss: 2.007970, test loss: 1.008272, bias2: 0.9986721277236938, variance: 0.009599552489817142\n",
      "Train size: [400] hidden size: [6] trial: 34, train_loss: 2.008108, test loss: 1.008676, bias2: 0.9984079003334045, variance: 0.010267549194395542\n",
      "Train size: [400] hidden size: [6] trial: 35, train_loss: 2.005630, test loss: 1.008678, bias2: 0.9985647797584534, variance: 0.010112825781106949\n",
      "Train size: [400] hidden size: [6] trial: 36, train_loss: 2.004269, test loss: 1.008541, bias2: 0.9984131455421448, variance: 0.010127942077815533\n",
      "Train size: [400] hidden size: [6] trial: 37, train_loss: 2.002944, test loss: 1.008716, bias2: 0.9984046816825867, variance: 0.010311183519661427\n",
      "Train size: [400] hidden size: [6] trial: 38, train_loss: 2.005371, test loss: 1.008545, bias2: 0.9979951977729797, variance: 0.010549347847700119\n",
      "Train size: [400] hidden size: [6] trial: 39, train_loss: 2.002597, test loss: 1.008532, bias2: 0.9980776309967041, variance: 0.010454441420733929\n",
      "Train size: [400] hidden size: [6] trial: 40, train_loss: 2.004811, test loss: 1.008372, bias2: 0.9979785084724426, variance: 0.010393058881163597\n",
      "Train size: [400] hidden size: [6] trial: 41, train_loss: 2.000164, test loss: 1.008347, bias2: 0.9980612397193909, variance: 0.010285919532179832\n",
      "Train size: [400] hidden size: [6] trial: 42, train_loss: 2.001213, test loss: 1.008181, bias2: 0.9977856874465942, variance: 0.010395769029855728\n",
      "Train size: [400] hidden size: [6] trial: 43, train_loss: 2.000203, test loss: 1.008095, bias2: 0.9978380799293518, variance: 0.010257325135171413\n",
      "Train size: [400] hidden size: [6] trial: 44, train_loss: 2.001454, test loss: 1.007960, bias2: 0.9978967905044556, variance: 0.010063273832201958\n",
      "Train size: [400] hidden size: [6] trial: 45, train_loss: 1.998605, test loss: 1.008114, bias2: 0.9979262351989746, variance: 0.010187633335590363\n",
      "Train size: [400] hidden size: [6] trial: 46, train_loss: 2.001616, test loss: 1.008606, bias2: 0.997959554195404, variance: 0.010646769776940346\n",
      "Train size: [400] hidden size: [6] trial: 47, train_loss: 1.996049, test loss: 1.008568, bias2: 0.998100757598877, variance: 0.010466809384524822\n",
      "Train size: [400] hidden size: [6] trial: 48, train_loss: 1.996558, test loss: 1.008424, bias2: 0.9980791807174683, variance: 0.010344397276639938\n",
      "Train size: [400] hidden size: [6] trial: 49, train_loss: 1.994919, test loss: 1.008406, bias2: 0.9980127811431885, variance: 0.010393262840807438\n",
      "##################################################\n",
      "Train size: [400] hidden size: [7] trial: 0, train_loss: 1.818720, test loss: 1.002950, bias2: 1.0029500722885132, variance: -2.889000497163785e-11\n",
      "Train size: [400] hidden size: [7] trial: 1, train_loss: 1.902143, test loss: 1.008174, bias2: 1.0061150789260864, variance: 0.0020592911168932915\n",
      "Train size: [400] hidden size: [7] trial: 2, train_loss: 1.892659, test loss: 1.011011, bias2: 1.0079693794250488, variance: 0.0030419330578297377\n",
      "Train size: [400] hidden size: [7] trial: 3, train_loss: 1.920466, test loss: 1.010210, bias2: 1.0060060024261475, variance: 0.004203699063509703\n",
      "Train size: [400] hidden size: [7] trial: 4, train_loss: 1.957873, test loss: 1.010028, bias2: 1.0028003454208374, variance: 0.007227267604321241\n",
      "Train size: [400] hidden size: [7] trial: 5, train_loss: 1.977714, test loss: 1.008926, bias2: 1.0022059679031372, variance: 0.006719965022057295\n",
      "Train size: [400] hidden size: [7] trial: 6, train_loss: 1.990455, test loss: 1.008717, bias2: 1.0017505884170532, variance: 0.006966396700590849\n",
      "Train size: [400] hidden size: [7] trial: 7, train_loss: 1.949804, test loss: 1.008759, bias2: 1.001933217048645, variance: 0.006825641728937626\n",
      "Train size: [400] hidden size: [7] trial: 8, train_loss: 1.963418, test loss: 1.007813, bias2: 1.0006413459777832, variance: 0.007171788718551397\n",
      "Train size: [400] hidden size: [7] trial: 9, train_loss: 1.982518, test loss: 1.008082, bias2: 1.0010426044464111, variance: 0.0070395455695688725\n",
      "Train size: [400] hidden size: [7] trial: 10, train_loss: 1.996105, test loss: 1.008460, bias2: 0.9992420077323914, variance: 0.009217445738613605\n",
      "Train size: [400] hidden size: [7] trial: 11, train_loss: 2.015087, test loss: 1.008918, bias2: 1.0001405477523804, variance: 0.008776847273111343\n",
      "Train size: [400] hidden size: [7] trial: 12, train_loss: 2.013196, test loss: 1.008961, bias2: 1.0003553628921509, variance: 0.008605645038187504\n",
      "Train size: [400] hidden size: [7] trial: 13, train_loss: 2.005447, test loss: 1.008556, bias2: 1.0002769231796265, variance: 0.008279375731945038\n",
      "Train size: [400] hidden size: [7] trial: 14, train_loss: 2.026781, test loss: 1.008332, bias2: 0.9997538924217224, variance: 0.008578146807849407\n",
      "Train size: [400] hidden size: [7] trial: 15, train_loss: 2.023503, test loss: 1.007866, bias2: 0.9986652135848999, variance: 0.009200566448271275\n",
      "Train size: [400] hidden size: [7] trial: 16, train_loss: 2.005319, test loss: 1.008000, bias2: 0.9989452958106995, variance: 0.009054340422153473\n",
      "Train size: [400] hidden size: [7] trial: 17, train_loss: 2.005353, test loss: 1.007658, bias2: 0.9988109469413757, variance: 0.00884730089455843\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [7] trial: 18, train_loss: 2.010931, test loss: 1.007540, bias2: 0.9979427456855774, variance: 0.0095974737778306\n",
      "Train size: [400] hidden size: [7] trial: 19, train_loss: 2.009693, test loss: 1.007627, bias2: 0.998199462890625, variance: 0.009427756071090698\n",
      "Train size: [400] hidden size: [7] trial: 20, train_loss: 2.001992, test loss: 1.007863, bias2: 0.998424768447876, variance: 0.009438293986022472\n",
      "Train size: [400] hidden size: [7] trial: 21, train_loss: 1.998820, test loss: 1.007129, bias2: 0.9977622628211975, variance: 0.009366358630359173\n",
      "Train size: [400] hidden size: [7] trial: 22, train_loss: 1.999821, test loss: 1.007350, bias2: 0.9975376129150391, variance: 0.00981257576495409\n",
      "Train size: [400] hidden size: [7] trial: 23, train_loss: 2.005815, test loss: 1.007381, bias2: 0.9977648854255676, variance: 0.009615838527679443\n",
      "Train size: [400] hidden size: [7] trial: 24, train_loss: 2.005601, test loss: 1.007599, bias2: 0.9978274703025818, variance: 0.009771065786480904\n",
      "Train size: [400] hidden size: [7] trial: 25, train_loss: 2.020836, test loss: 1.007610, bias2: 0.997874915599823, variance: 0.009735402651131153\n",
      "Train size: [400] hidden size: [7] trial: 26, train_loss: 2.014243, test loss: 1.007405, bias2: 0.9979149699211121, variance: 0.009489953517913818\n",
      "Train size: [400] hidden size: [7] trial: 27, train_loss: 2.009152, test loss: 1.007654, bias2: 0.9981339573860168, variance: 0.009520592167973518\n",
      "Train size: [400] hidden size: [7] trial: 28, train_loss: 2.012083, test loss: 1.007792, bias2: 0.9982434511184692, variance: 0.009548411704599857\n",
      "Train size: [400] hidden size: [7] trial: 29, train_loss: 2.007897, test loss: 1.007901, bias2: 0.9985947608947754, variance: 0.009305953979492188\n",
      "Train size: [400] hidden size: [7] trial: 30, train_loss: 2.000630, test loss: 1.008145, bias2: 0.998696506023407, variance: 0.009448709897696972\n",
      "Train size: [400] hidden size: [7] trial: 31, train_loss: 1.999708, test loss: 1.008510, bias2: 0.9989472031593323, variance: 0.009562450461089611\n",
      "Train size: [400] hidden size: [7] trial: 32, train_loss: 2.010053, test loss: 1.008503, bias2: 0.9991929531097412, variance: 0.009310376830399036\n",
      "Train size: [400] hidden size: [7] trial: 33, train_loss: 2.002474, test loss: 1.008882, bias2: 0.9993837475776672, variance: 0.009497912600636482\n",
      "Train size: [400] hidden size: [7] trial: 34, train_loss: 1.999010, test loss: 1.008659, bias2: 0.9987354874610901, variance: 0.00992389116436243\n",
      "Train size: [400] hidden size: [7] trial: 35, train_loss: 1.992625, test loss: 1.008414, bias2: 0.9981546998023987, variance: 0.0102593544870615\n",
      "Train size: [400] hidden size: [7] trial: 36, train_loss: 1.992172, test loss: 1.008131, bias2: 0.9977478384971619, variance: 0.010382839478552341\n",
      "Train size: [400] hidden size: [7] trial: 37, train_loss: 1.990041, test loss: 1.008010, bias2: 0.9977530241012573, variance: 0.01025735680013895\n",
      "Train size: [400] hidden size: [7] trial: 38, train_loss: 1.989309, test loss: 1.008002, bias2: 0.9976356625556946, variance: 0.010366284288465977\n",
      "Train size: [400] hidden size: [7] trial: 39, train_loss: 1.988750, test loss: 1.007671, bias2: 0.9973082542419434, variance: 0.010363002307713032\n",
      "Train size: [400] hidden size: [7] trial: 40, train_loss: 1.987232, test loss: 1.007442, bias2: 0.9970219135284424, variance: 0.010419702157378197\n",
      "Train size: [400] hidden size: [7] trial: 41, train_loss: 1.988737, test loss: 1.007440, bias2: 0.9970608949661255, variance: 0.01037882175296545\n",
      "Train size: [400] hidden size: [7] trial: 42, train_loss: 1.991283, test loss: 1.007138, bias2: 0.9966504573822021, variance: 0.010487538762390614\n",
      "Train size: [400] hidden size: [7] trial: 43, train_loss: 1.985970, test loss: 1.007361, bias2: 0.996857762336731, variance: 0.010503632016479969\n",
      "Train size: [400] hidden size: [7] trial: 44, train_loss: 1.986891, test loss: 1.007709, bias2: 0.9970252513885498, variance: 0.010683918371796608\n",
      "Train size: [400] hidden size: [7] trial: 45, train_loss: 1.987936, test loss: 1.007708, bias2: 0.9968213438987732, variance: 0.010886376723647118\n",
      "Train size: [400] hidden size: [7] trial: 46, train_loss: 1.990521, test loss: 1.007646, bias2: 0.9969655871391296, variance: 0.010680748149752617\n",
      "Train size: [400] hidden size: [7] trial: 47, train_loss: 1.987580, test loss: 1.007482, bias2: 0.996986985206604, variance: 0.010495404712855816\n",
      "Train size: [400] hidden size: [7] trial: 48, train_loss: 1.985933, test loss: 1.007458, bias2: 0.9971358180046082, variance: 0.010322030633687973\n",
      "Train size: [400] hidden size: [7] trial: 49, train_loss: 1.987589, test loss: 1.007440, bias2: 0.9971311092376709, variance: 0.010308491997420788\n",
      "##################################################\n",
      "Train size: [400] hidden size: [8] trial: 0, train_loss: 1.692078, test loss: 1.012617, bias2: 1.0126168727874756, variance: 8.514949162430341e-11\n",
      "Train size: [400] hidden size: [8] trial: 1, train_loss: 1.866834, test loss: 1.008037, bias2: 1.0007920265197754, variance: 0.007245129905641079\n",
      "Train size: [400] hidden size: [8] trial: 2, train_loss: 1.839712, test loss: 1.004063, bias2: 0.9950122237205505, variance: 0.009050575084984303\n",
      "Train size: [400] hidden size: [8] trial: 3, train_loss: 1.915230, test loss: 1.005786, bias2: 0.9967937469482422, variance: 0.008991964161396027\n",
      "Train size: [400] hidden size: [8] trial: 4, train_loss: 1.947130, test loss: 1.004237, bias2: 0.9938383102416992, variance: 0.010398504324257374\n",
      "Train size: [400] hidden size: [8] trial: 5, train_loss: 1.963951, test loss: 1.007763, bias2: 0.9951567649841309, variance: 0.012605811469256878\n",
      "Train size: [400] hidden size: [8] trial: 6, train_loss: 1.974596, test loss: 1.006925, bias2: 0.9946500062942505, variance: 0.012275232933461666\n",
      "Train size: [400] hidden size: [8] trial: 7, train_loss: 1.937108, test loss: 1.006839, bias2: 0.9923003315925598, variance: 0.014538570307195187\n",
      "Train size: [400] hidden size: [8] trial: 8, train_loss: 1.968389, test loss: 1.006895, bias2: 0.9926174283027649, variance: 0.01427775714546442\n",
      "Train size: [400] hidden size: [8] trial: 9, train_loss: 1.969253, test loss: 1.006201, bias2: 0.9923442602157593, variance: 0.013856538571417332\n",
      "Train size: [400] hidden size: [8] trial: 10, train_loss: 1.974108, test loss: 1.006154, bias2: 0.9927495718002319, variance: 0.013404506258666515\n",
      "Train size: [400] hidden size: [8] trial: 11, train_loss: 1.989882, test loss: 1.005555, bias2: 0.992172360420227, variance: 0.013382764533162117\n",
      "Train size: [400] hidden size: [8] trial: 12, train_loss: 1.996717, test loss: 1.005806, bias2: 0.9927033185958862, variance: 0.013102778233587742\n",
      "Train size: [400] hidden size: [8] trial: 13, train_loss: 1.993689, test loss: 1.006334, bias2: 0.992489755153656, variance: 0.013844205997884274\n",
      "Train size: [400] hidden size: [8] trial: 14, train_loss: 2.002058, test loss: 1.007170, bias2: 0.992845892906189, variance: 0.014324414543807507\n",
      "Train size: [400] hidden size: [8] trial: 15, train_loss: 2.001133, test loss: 1.007694, bias2: 0.9934256076812744, variance: 0.014268527738749981\n",
      "Train size: [400] hidden size: [8] trial: 16, train_loss: 1.999268, test loss: 1.007751, bias2: 0.9939759373664856, variance: 0.013774698600172997\n",
      "Train size: [400] hidden size: [8] trial: 17, train_loss: 2.012164, test loss: 1.008183, bias2: 0.9937407374382019, variance: 0.014441780745983124\n",
      "Train size: [400] hidden size: [8] trial: 18, train_loss: 2.014322, test loss: 1.008060, bias2: 0.992810845375061, variance: 0.015249484218657017\n",
      "Train size: [400] hidden size: [8] trial: 19, train_loss: 2.005904, test loss: 1.007776, bias2: 0.9928270578384399, variance: 0.01494872197508812\n",
      "Train size: [400] hidden size: [8] trial: 20, train_loss: 2.008662, test loss: 1.008321, bias2: 0.9937337636947632, variance: 0.014587139710783958\n",
      "Train size: [400] hidden size: [8] trial: 21, train_loss: 2.004895, test loss: 1.008589, bias2: 0.9934108853340149, variance: 0.015178012661635876\n",
      "Train size: [400] hidden size: [8] trial: 22, train_loss: 2.013587, test loss: 1.008266, bias2: 0.9934491515159607, variance: 0.014816719107329845\n",
      "Train size: [400] hidden size: [8] trial: 23, train_loss: 2.014380, test loss: 1.008292, bias2: 0.9938933253288269, variance: 0.014398294501006603\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [8] trial: 24, train_loss: 2.004655, test loss: 1.008151, bias2: 0.9938469529151917, variance: 0.014304451644420624\n",
      "Train size: [400] hidden size: [8] trial: 25, train_loss: 2.003174, test loss: 1.008298, bias2: 0.9940242767333984, variance: 0.014274015091359615\n",
      "Train size: [400] hidden size: [8] trial: 26, train_loss: 1.999448, test loss: 1.008384, bias2: 0.9940499067306519, variance: 0.01433410681784153\n",
      "Train size: [400] hidden size: [8] trial: 27, train_loss: 1.998133, test loss: 1.008677, bias2: 0.9941128492355347, variance: 0.014564257115125656\n",
      "Train size: [400] hidden size: [8] trial: 28, train_loss: 1.989744, test loss: 1.008894, bias2: 0.9943034052848816, variance: 0.01459033228456974\n",
      "Train size: [400] hidden size: [8] trial: 29, train_loss: 1.990159, test loss: 1.009119, bias2: 0.9947448372840881, variance: 0.014374296180903912\n",
      "Train size: [400] hidden size: [8] trial: 30, train_loss: 1.988046, test loss: 1.008807, bias2: 0.9944530129432678, variance: 0.014353569597005844\n",
      "Train size: [400] hidden size: [8] trial: 31, train_loss: 1.982809, test loss: 1.008419, bias2: 0.9941679835319519, variance: 0.014251316897571087\n",
      "Train size: [400] hidden size: [8] trial: 32, train_loss: 1.975666, test loss: 1.008676, bias2: 0.9945634603500366, variance: 0.014112243428826332\n",
      "Train size: [400] hidden size: [8] trial: 33, train_loss: 1.973150, test loss: 1.008343, bias2: 0.9944329261779785, variance: 0.013910272158682346\n",
      "Train size: [400] hidden size: [8] trial: 34, train_loss: 1.972961, test loss: 1.008273, bias2: 0.9945230484008789, variance: 0.013749458827078342\n",
      "Train size: [400] hidden size: [8] trial: 35, train_loss: 1.970066, test loss: 1.008401, bias2: 0.9949105381965637, variance: 0.013490976765751839\n",
      "Train size: [400] hidden size: [8] trial: 36, train_loss: 1.973048, test loss: 1.008533, bias2: 0.9949765205383301, variance: 0.013556712307035923\n",
      "Train size: [400] hidden size: [8] trial: 37, train_loss: 1.974905, test loss: 1.008117, bias2: 0.9941391348838806, variance: 0.013977560214698315\n",
      "Train size: [400] hidden size: [8] trial: 38, train_loss: 1.979771, test loss: 1.008465, bias2: 0.9943163394927979, variance: 0.014148964546620846\n",
      "Train size: [400] hidden size: [8] trial: 39, train_loss: 1.986327, test loss: 1.008787, bias2: 0.9946609735488892, variance: 0.014125972054898739\n",
      "Train size: [400] hidden size: [8] trial: 40, train_loss: 1.987605, test loss: 1.008753, bias2: 0.9947715997695923, variance: 0.013981453143060207\n",
      "Train size: [400] hidden size: [8] trial: 41, train_loss: 1.987662, test loss: 1.008777, bias2: 0.9950007796287537, variance: 0.013776001520454884\n",
      "Train size: [400] hidden size: [8] trial: 42, train_loss: 1.989660, test loss: 1.008789, bias2: 0.9950202107429504, variance: 0.013768704608082771\n",
      "Train size: [400] hidden size: [8] trial: 43, train_loss: 1.987168, test loss: 1.008812, bias2: 0.9949609637260437, variance: 0.013850633054971695\n",
      "Train size: [400] hidden size: [8] trial: 44, train_loss: 1.983036, test loss: 1.008867, bias2: 0.9949181079864502, variance: 0.013948800042271614\n",
      "Train size: [400] hidden size: [8] trial: 45, train_loss: 1.985351, test loss: 1.008983, bias2: 0.995087742805481, variance: 0.013895509764552116\n",
      "Train size: [400] hidden size: [8] trial: 46, train_loss: 1.983127, test loss: 1.008966, bias2: 0.9950932264328003, variance: 0.013872762210667133\n",
      "Train size: [400] hidden size: [8] trial: 47, train_loss: 1.980169, test loss: 1.008918, bias2: 0.995212733745575, variance: 0.01370497327297926\n",
      "Train size: [400] hidden size: [8] trial: 48, train_loss: 1.982947, test loss: 1.009020, bias2: 0.9953855276107788, variance: 0.013634794391691685\n",
      "Train size: [400] hidden size: [8] trial: 49, train_loss: 1.984338, test loss: 1.008717, bias2: 0.9951141476631165, variance: 0.013602416031062603\n",
      "##################################################\n",
      "Train size: [400] hidden size: [9] trial: 0, train_loss: 1.678971, test loss: 1.001513, bias2: 1.0015130043029785, variance: 9.731369876586626e-11\n",
      "Train size: [400] hidden size: [9] trial: 1, train_loss: 1.791808, test loss: 1.003071, bias2: 0.9960038661956787, variance: 0.007066721096634865\n",
      "Train size: [400] hidden size: [9] trial: 2, train_loss: 1.850383, test loss: 1.007625, bias2: 1.0001003742218018, variance: 0.007524693850427866\n",
      "Train size: [400] hidden size: [9] trial: 3, train_loss: 1.859292, test loss: 1.011595, bias2: 1.0013415813446045, variance: 0.010253039188683033\n",
      "Train size: [400] hidden size: [9] trial: 4, train_loss: 1.830898, test loss: 1.010963, bias2: 0.9996597766876221, variance: 0.011303429491817951\n",
      "Train size: [400] hidden size: [9] trial: 5, train_loss: 1.843672, test loss: 1.010493, bias2: 0.9990009069442749, variance: 0.011492369696497917\n",
      "Train size: [400] hidden size: [9] trial: 6, train_loss: 1.884650, test loss: 1.013497, bias2: 0.999156653881073, variance: 0.014340449124574661\n",
      "Train size: [400] hidden size: [9] trial: 7, train_loss: 1.878787, test loss: 1.013656, bias2: 1.000007152557373, variance: 0.013648574240505695\n",
      "Train size: [400] hidden size: [9] trial: 8, train_loss: 1.928609, test loss: 1.013953, bias2: 1.0002409219741821, variance: 0.013711629435420036\n",
      "Train size: [400] hidden size: [9] trial: 9, train_loss: 1.928679, test loss: 1.013838, bias2: 0.9996389150619507, variance: 0.014198774471879005\n",
      "Train size: [400] hidden size: [9] trial: 10, train_loss: 1.905297, test loss: 1.015415, bias2: 1.0010265111923218, variance: 0.01438823901116848\n",
      "Train size: [400] hidden size: [9] trial: 11, train_loss: 1.917309, test loss: 1.014620, bias2: 0.999413251876831, variance: 0.015207061544060707\n",
      "Train size: [400] hidden size: [9] trial: 12, train_loss: 1.936518, test loss: 1.013209, bias2: 0.9977663159370422, variance: 0.01544242724776268\n",
      "Train size: [400] hidden size: [9] trial: 13, train_loss: 1.941653, test loss: 1.013102, bias2: 0.9983617663383484, variance: 0.01474042423069477\n",
      "Train size: [400] hidden size: [9] trial: 14, train_loss: 1.939050, test loss: 1.012740, bias2: 0.9975776672363281, variance: 0.015162011608481407\n",
      "Train size: [400] hidden size: [9] trial: 15, train_loss: 1.961564, test loss: 1.012082, bias2: 0.9970197081565857, variance: 0.015062520280480385\n",
      "Train size: [400] hidden size: [9] trial: 16, train_loss: 1.956345, test loss: 1.011945, bias2: 0.9973064661026001, variance: 0.014638674445450306\n",
      "Train size: [400] hidden size: [9] trial: 17, train_loss: 1.947289, test loss: 1.011942, bias2: 0.9973071813583374, variance: 0.014634964987635612\n",
      "Train size: [400] hidden size: [9] trial: 18, train_loss: 1.945965, test loss: 1.012437, bias2: 0.9969768524169922, variance: 0.015460348688066006\n",
      "Train size: [400] hidden size: [9] trial: 19, train_loss: 1.931920, test loss: 1.012496, bias2: 0.9970099329948425, variance: 0.015485930256545544\n",
      "Train size: [400] hidden size: [9] trial: 20, train_loss: 1.931244, test loss: 1.012699, bias2: 0.9969989061355591, variance: 0.015699857845902443\n",
      "Train size: [400] hidden size: [9] trial: 21, train_loss: 1.931108, test loss: 1.012324, bias2: 0.9968701004981995, variance: 0.015453523024916649\n",
      "Train size: [400] hidden size: [9] trial: 22, train_loss: 1.927483, test loss: 1.011576, bias2: 0.9961823225021362, variance: 0.015393370762467384\n",
      "Train size: [400] hidden size: [9] trial: 23, train_loss: 1.942411, test loss: 1.011572, bias2: 0.9963447451591492, variance: 0.015227502211928368\n",
      "Train size: [400] hidden size: [9] trial: 24, train_loss: 1.940313, test loss: 1.011657, bias2: 0.996691107749939, variance: 0.014965745620429516\n",
      "Train size: [400] hidden size: [9] trial: 25, train_loss: 1.944910, test loss: 1.011590, bias2: 0.9969778656959534, variance: 0.014611687511205673\n",
      "Train size: [400] hidden size: [9] trial: 26, train_loss: 1.944196, test loss: 1.011959, bias2: 0.9973640441894531, variance: 0.01459505595266819\n",
      "Train size: [400] hidden size: [9] trial: 27, train_loss: 1.937335, test loss: 1.011382, bias2: 0.9969422817230225, variance: 0.014440082013607025\n",
      "Train size: [400] hidden size: [9] trial: 28, train_loss: 1.943060, test loss: 1.011648, bias2: 0.9969936013221741, variance: 0.01465457770973444\n",
      "Train size: [400] hidden size: [9] trial: 29, train_loss: 1.944226, test loss: 1.011204, bias2: 0.9966472387313843, variance: 0.014557142741978168\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [9] trial: 30, train_loss: 1.944843, test loss: 1.011437, bias2: 0.9962251782417297, variance: 0.015211661346256733\n",
      "Train size: [400] hidden size: [9] trial: 31, train_loss: 1.946895, test loss: 1.011473, bias2: 0.9962947964668274, variance: 0.01517835445702076\n",
      "Train size: [400] hidden size: [9] trial: 32, train_loss: 1.948221, test loss: 1.011342, bias2: 0.9964187741279602, variance: 0.014923259615898132\n",
      "Train size: [400] hidden size: [9] trial: 33, train_loss: 1.952717, test loss: 1.011310, bias2: 0.9960150122642517, variance: 0.01529470831155777\n",
      "Train size: [400] hidden size: [9] trial: 34, train_loss: 1.949775, test loss: 1.010853, bias2: 0.9955829977989197, variance: 0.015269569121301174\n",
      "Train size: [400] hidden size: [9] trial: 35, train_loss: 1.948721, test loss: 1.010454, bias2: 0.9952656626701355, variance: 0.015188129618763924\n",
      "Train size: [400] hidden size: [9] trial: 36, train_loss: 1.947566, test loss: 1.010648, bias2: 0.9954016804695129, variance: 0.01524631679058075\n",
      "Train size: [400] hidden size: [9] trial: 37, train_loss: 1.946530, test loss: 1.010438, bias2: 0.9953017234802246, variance: 0.015135763213038445\n",
      "Train size: [400] hidden size: [9] trial: 38, train_loss: 1.948406, test loss: 1.010252, bias2: 0.9947589635848999, variance: 0.015492535196244717\n",
      "Train size: [400] hidden size: [9] trial: 39, train_loss: 1.945230, test loss: 1.010435, bias2: 0.9950751066207886, variance: 0.015359771437942982\n",
      "Train size: [400] hidden size: [9] trial: 40, train_loss: 1.945006, test loss: 1.010468, bias2: 0.9952732920646667, variance: 0.015194623731076717\n",
      "Train size: [400] hidden size: [9] trial: 41, train_loss: 1.949201, test loss: 1.010904, bias2: 0.9949194192886353, variance: 0.015984894707798958\n",
      "Train size: [400] hidden size: [9] trial: 42, train_loss: 1.950543, test loss: 1.010752, bias2: 0.9943261742591858, variance: 0.016426173970103264\n",
      "Train size: [400] hidden size: [9] trial: 43, train_loss: 1.952783, test loss: 1.010755, bias2: 0.9945592284202576, variance: 0.016195859760046005\n",
      "Train size: [400] hidden size: [9] trial: 44, train_loss: 1.947861, test loss: 1.010933, bias2: 0.994779109954834, variance: 0.01615382917225361\n",
      "Train size: [400] hidden size: [9] trial: 45, train_loss: 1.946835, test loss: 1.011128, bias2: 0.9947850704193115, variance: 0.016342531889677048\n",
      "Train size: [400] hidden size: [9] trial: 46, train_loss: 1.945289, test loss: 1.011112, bias2: 0.9949216842651367, variance: 0.016190174967050552\n",
      "Train size: [400] hidden size: [9] trial: 47, train_loss: 1.948538, test loss: 1.011158, bias2: 0.9949556589126587, variance: 0.016202224418520927\n",
      "Train size: [400] hidden size: [9] trial: 48, train_loss: 1.947041, test loss: 1.011420, bias2: 0.9952200055122375, variance: 0.016199741512537003\n",
      "Train size: [400] hidden size: [9] trial: 49, train_loss: 1.944951, test loss: 1.011535, bias2: 0.9951233267784119, variance: 0.016411392018198967\n",
      "##################################################\n",
      "Train size: [400] hidden size: [11] trial: 0, train_loss: 1.848370, test loss: 1.015615, bias2: 1.0156148672103882, variance: 3.6492638771923325e-11\n",
      "Train size: [400] hidden size: [11] trial: 1, train_loss: 1.820625, test loss: 1.015920, bias2: 1.0077730417251587, variance: 0.0081472834572196\n",
      "Train size: [400] hidden size: [11] trial: 2, train_loss: 1.852651, test loss: 1.015908, bias2: 1.0039094686508179, variance: 0.011999060399830341\n",
      "Train size: [400] hidden size: [11] trial: 3, train_loss: 1.904631, test loss: 1.012228, bias2: 0.9981551170349121, variance: 0.014072670601308346\n",
      "Train size: [400] hidden size: [11] trial: 4, train_loss: 1.929960, test loss: 1.011414, bias2: 0.9963736534118652, variance: 0.01504062581807375\n",
      "Train size: [400] hidden size: [11] trial: 5, train_loss: 1.935410, test loss: 1.009836, bias2: 0.9935076832771301, variance: 0.016328373923897743\n",
      "Train size: [400] hidden size: [11] trial: 6, train_loss: 1.950829, test loss: 1.008553, bias2: 0.9926478862762451, variance: 0.015905488282442093\n",
      "Train size: [400] hidden size: [11] trial: 7, train_loss: 1.924430, test loss: 1.010372, bias2: 0.9944700002670288, variance: 0.01590191200375557\n",
      "Train size: [400] hidden size: [11] trial: 8, train_loss: 1.938221, test loss: 1.009859, bias2: 0.9949309825897217, variance: 0.014928461983799934\n",
      "Train size: [400] hidden size: [11] trial: 9, train_loss: 1.939939, test loss: 1.010218, bias2: 0.9958826899528503, variance: 0.0143356928601861\n",
      "Train size: [400] hidden size: [11] trial: 10, train_loss: 1.943084, test loss: 1.010563, bias2: 0.9960135817527771, variance: 0.014549441635608673\n",
      "Train size: [400] hidden size: [11] trial: 11, train_loss: 1.928952, test loss: 1.009200, bias2: 0.9939695000648499, variance: 0.015230700373649597\n",
      "Train size: [400] hidden size: [11] trial: 12, train_loss: 1.951512, test loss: 1.010023, bias2: 0.995013415813446, variance: 0.015010050497949123\n",
      "Train size: [400] hidden size: [11] trial: 13, train_loss: 1.945309, test loss: 1.010011, bias2: 0.9946991205215454, variance: 0.015312333591282368\n",
      "Train size: [400] hidden size: [11] trial: 14, train_loss: 1.943293, test loss: 1.010469, bias2: 0.9950748682022095, variance: 0.015393989160656929\n",
      "Train size: [400] hidden size: [11] trial: 15, train_loss: 1.940796, test loss: 1.012446, bias2: 0.9959457516670227, variance: 0.0165000781416893\n",
      "Train size: [400] hidden size: [11] trial: 16, train_loss: 1.937902, test loss: 1.012464, bias2: 0.9956077933311462, variance: 0.016856474801898003\n",
      "Train size: [400] hidden size: [11] trial: 17, train_loss: 1.925723, test loss: 1.012372, bias2: 0.9954133629798889, variance: 0.016959039494395256\n",
      "Train size: [400] hidden size: [11] trial: 18, train_loss: 1.934294, test loss: 1.011593, bias2: 0.9947578310966492, variance: 0.016835525631904602\n",
      "Train size: [400] hidden size: [11] trial: 19, train_loss: 1.941268, test loss: 1.011266, bias2: 0.9941126108169556, variance: 0.01715347170829773\n",
      "Train size: [400] hidden size: [11] trial: 20, train_loss: 1.946203, test loss: 1.010748, bias2: 0.9935079216957092, variance: 0.017240213230252266\n",
      "Train size: [400] hidden size: [11] trial: 21, train_loss: 1.963240, test loss: 1.010892, bias2: 0.9937119483947754, variance: 0.0171805452555418\n",
      "Train size: [400] hidden size: [11] trial: 22, train_loss: 1.957913, test loss: 1.010590, bias2: 0.9922765493392944, variance: 0.018313026055693626\n",
      "Train size: [400] hidden size: [11] trial: 23, train_loss: 1.955597, test loss: 1.010726, bias2: 0.9922051429748535, variance: 0.01852133497595787\n",
      "Train size: [400] hidden size: [11] trial: 24, train_loss: 1.947856, test loss: 1.010706, bias2: 0.9920180439949036, variance: 0.018687548115849495\n",
      "Train size: [400] hidden size: [11] trial: 25, train_loss: 1.947754, test loss: 1.010632, bias2: 0.9912101030349731, variance: 0.019421467557549477\n",
      "Train size: [400] hidden size: [11] trial: 26, train_loss: 1.944439, test loss: 1.010588, bias2: 0.9914140105247498, variance: 0.019173676148056984\n",
      "Train size: [400] hidden size: [11] trial: 27, train_loss: 1.947175, test loss: 1.010866, bias2: 0.9918544292449951, variance: 0.019011637195944786\n",
      "Train size: [400] hidden size: [11] trial: 28, train_loss: 1.948886, test loss: 1.010595, bias2: 0.9918057918548584, variance: 0.018789658322930336\n",
      "Train size: [400] hidden size: [11] trial: 29, train_loss: 1.943707, test loss: 1.010002, bias2: 0.991133451461792, variance: 0.018868345767259598\n",
      "Train size: [400] hidden size: [11] trial: 30, train_loss: 1.937040, test loss: 1.009992, bias2: 0.9912146925926208, variance: 0.018777091056108475\n",
      "Train size: [400] hidden size: [11] trial: 31, train_loss: 1.936245, test loss: 1.009636, bias2: 0.9909659624099731, variance: 0.018669962882995605\n",
      "Train size: [400] hidden size: [11] trial: 32, train_loss: 1.942297, test loss: 1.010544, bias2: 0.9909318089485168, variance: 0.019612105563282967\n",
      "Train size: [400] hidden size: [11] trial: 33, train_loss: 1.946129, test loss: 1.010266, bias2: 0.9904872179031372, variance: 0.01977837085723877\n",
      "Train size: [400] hidden size: [11] trial: 34, train_loss: 1.944279, test loss: 1.010008, bias2: 0.990361213684082, variance: 0.0196462944149971\n",
      "Train size: [400] hidden size: [11] trial: 35, train_loss: 1.942817, test loss: 1.010135, bias2: 0.9904743432998657, variance: 0.019660571590065956\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [11] trial: 36, train_loss: 1.942860, test loss: 1.009926, bias2: 0.9904873967170715, variance: 0.01943855732679367\n",
      "Train size: [400] hidden size: [11] trial: 37, train_loss: 1.951844, test loss: 1.010271, bias2: 0.9909148812294006, variance: 0.01935572177171707\n",
      "Train size: [400] hidden size: [11] trial: 38, train_loss: 1.947705, test loss: 1.010119, bias2: 0.9910950660705566, variance: 0.019024034962058067\n",
      "Train size: [400] hidden size: [11] trial: 39, train_loss: 1.947669, test loss: 1.010054, bias2: 0.9909765720367432, variance: 0.019077874720096588\n",
      "Train size: [400] hidden size: [11] trial: 40, train_loss: 1.953418, test loss: 1.010178, bias2: 0.9913793206214905, variance: 0.018799006938934326\n",
      "Train size: [400] hidden size: [11] trial: 41, train_loss: 1.955145, test loss: 1.010088, bias2: 0.9913300275802612, variance: 0.018758440390229225\n",
      "Train size: [400] hidden size: [11] trial: 42, train_loss: 1.952483, test loss: 1.010110, bias2: 0.9915810227394104, variance: 0.01852874457836151\n",
      "Train size: [400] hidden size: [11] trial: 43, train_loss: 1.948113, test loss: 1.009719, bias2: 0.9910233616828918, variance: 0.01869530789554119\n",
      "Train size: [400] hidden size: [11] trial: 44, train_loss: 1.957451, test loss: 1.009675, bias2: 0.9913052916526794, variance: 0.018369734287261963\n",
      "Train size: [400] hidden size: [11] trial: 45, train_loss: 1.953644, test loss: 1.009510, bias2: 0.9913527369499207, variance: 0.01815696246922016\n",
      "Train size: [400] hidden size: [11] trial: 46, train_loss: 1.951494, test loss: 1.009585, bias2: 0.9913913011550903, variance: 0.0181941706687212\n",
      "Train size: [400] hidden size: [11] trial: 47, train_loss: 1.948317, test loss: 1.010121, bias2: 0.9915807843208313, variance: 0.018540222197771072\n",
      "Train size: [400] hidden size: [11] trial: 48, train_loss: 1.948717, test loss: 1.010221, bias2: 0.9918087124824524, variance: 0.018412668257951736\n",
      "Train size: [400] hidden size: [11] trial: 49, train_loss: 1.950946, test loss: 1.009918, bias2: 0.9915329217910767, variance: 0.018384916707873344\n",
      "##################################################\n",
      "Train size: [400] hidden size: [12] trial: 0, train_loss: 1.682402, test loss: 0.986601, bias2: 0.9866008162498474, variance: 4.865684938293313e-11\n",
      "Train size: [400] hidden size: [12] trial: 1, train_loss: 1.675844, test loss: 0.995683, bias2: 0.983276903629303, variance: 0.012406195513904095\n",
      "Train size: [400] hidden size: [12] trial: 2, train_loss: 1.773071, test loss: 1.000413, bias2: 0.9878031015396118, variance: 0.012609469704329967\n",
      "Train size: [400] hidden size: [12] trial: 3, train_loss: 1.751392, test loss: 1.001357, bias2: 0.9861413240432739, variance: 0.015215659514069557\n",
      "Train size: [400] hidden size: [12] trial: 4, train_loss: 1.815198, test loss: 1.007983, bias2: 0.9912653565406799, variance: 0.016717949882149696\n",
      "Train size: [400] hidden size: [12] trial: 5, train_loss: 1.827911, test loss: 1.006167, bias2: 0.9899835586547852, variance: 0.01618373394012451\n",
      "Train size: [400] hidden size: [12] trial: 6, train_loss: 1.847918, test loss: 1.004898, bias2: 0.9879323840141296, variance: 0.016965674236416817\n",
      "Train size: [400] hidden size: [12] trial: 7, train_loss: 1.858545, test loss: 1.004768, bias2: 0.9885531067848206, variance: 0.016215162351727486\n",
      "Train size: [400] hidden size: [12] trial: 8, train_loss: 1.858300, test loss: 1.003145, bias2: 0.9868327975273132, variance: 0.01631256751716137\n",
      "Train size: [400] hidden size: [12] trial: 9, train_loss: 1.862684, test loss: 1.002299, bias2: 0.9854648113250732, variance: 0.016834476962685585\n",
      "Train size: [400] hidden size: [12] trial: 10, train_loss: 1.882544, test loss: 1.002249, bias2: 0.9855871796607971, variance: 0.016661344096064568\n",
      "Train size: [400] hidden size: [12] trial: 11, train_loss: 1.910939, test loss: 1.002649, bias2: 0.9863287210464478, variance: 0.01632043905556202\n",
      "Train size: [400] hidden size: [12] trial: 12, train_loss: 1.926833, test loss: 1.002699, bias2: 0.9865748882293701, variance: 0.016123898327350616\n",
      "Train size: [400] hidden size: [12] trial: 13, train_loss: 1.914362, test loss: 1.003730, bias2: 0.986912190914154, variance: 0.016818014904856682\n",
      "Train size: [400] hidden size: [12] trial: 14, train_loss: 1.905022, test loss: 1.003737, bias2: 0.986618161201477, variance: 0.017118358984589577\n",
      "Train size: [400] hidden size: [12] trial: 15, train_loss: 1.911998, test loss: 1.002968, bias2: 0.9859433174133301, variance: 0.017024535685777664\n",
      "Train size: [400] hidden size: [12] trial: 16, train_loss: 1.924175, test loss: 1.004052, bias2: 0.9868742823600769, variance: 0.01717773638665676\n",
      "Train size: [400] hidden size: [12] trial: 17, train_loss: 1.921145, test loss: 1.003349, bias2: 0.9846415519714355, variance: 0.01870764046907425\n",
      "Train size: [400] hidden size: [12] trial: 18, train_loss: 1.925092, test loss: 1.003757, bias2: 0.9848593473434448, variance: 0.01889752969145775\n",
      "Train size: [400] hidden size: [12] trial: 19, train_loss: 1.925741, test loss: 1.003600, bias2: 0.9853835701942444, variance: 0.018216446042060852\n",
      "Train size: [400] hidden size: [12] trial: 20, train_loss: 1.933147, test loss: 1.003723, bias2: 0.9848862290382385, variance: 0.01883680745959282\n",
      "Train size: [400] hidden size: [12] trial: 21, train_loss: 1.935079, test loss: 1.002803, bias2: 0.9840061664581299, variance: 0.018796825781464577\n",
      "Train size: [400] hidden size: [12] trial: 22, train_loss: 1.932262, test loss: 1.002848, bias2: 0.9835677742958069, variance: 0.01928001269698143\n",
      "Train size: [400] hidden size: [12] trial: 23, train_loss: 1.940064, test loss: 1.003811, bias2: 0.984309732913971, variance: 0.019501741975545883\n",
      "Train size: [400] hidden size: [12] trial: 24, train_loss: 1.941673, test loss: 1.004779, bias2: 0.9853121042251587, variance: 0.01946650631725788\n",
      "Train size: [400] hidden size: [12] trial: 25, train_loss: 1.939849, test loss: 1.005157, bias2: 0.9857275485992432, variance: 0.019429566338658333\n",
      "Train size: [400] hidden size: [12] trial: 26, train_loss: 1.945759, test loss: 1.005758, bias2: 0.9862842559814453, variance: 0.01947353035211563\n",
      "Train size: [400] hidden size: [12] trial: 27, train_loss: 1.942858, test loss: 1.005744, bias2: 0.9863103628158569, variance: 0.019433116540312767\n",
      "Train size: [400] hidden size: [12] trial: 28, train_loss: 1.941233, test loss: 1.005837, bias2: 0.9859695434570312, variance: 0.019867904484272003\n",
      "Train size: [400] hidden size: [12] trial: 29, train_loss: 1.943064, test loss: 1.007388, bias2: 0.9867444038391113, variance: 0.02064335346221924\n",
      "Train size: [400] hidden size: [12] trial: 30, train_loss: 1.942378, test loss: 1.007164, bias2: 0.9868438839912415, variance: 0.020320363342761993\n",
      "Train size: [400] hidden size: [12] trial: 31, train_loss: 1.942975, test loss: 1.006863, bias2: 0.9865390658378601, variance: 0.020323827862739563\n",
      "Train size: [400] hidden size: [12] trial: 32, train_loss: 1.937162, test loss: 1.006898, bias2: 0.986753523349762, variance: 0.02014477737247944\n",
      "Train size: [400] hidden size: [12] trial: 33, train_loss: 1.932776, test loss: 1.007352, bias2: 0.9871612787246704, variance: 0.02019023522734642\n",
      "Train size: [400] hidden size: [12] trial: 34, train_loss: 1.932961, test loss: 1.006955, bias2: 0.9869024753570557, variance: 0.020052103325724602\n",
      "Train size: [400] hidden size: [12] trial: 35, train_loss: 1.927489, test loss: 1.007173, bias2: 0.9872370958328247, variance: 0.019936207681894302\n",
      "Train size: [400] hidden size: [12] trial: 36, train_loss: 1.923368, test loss: 1.006720, bias2: 0.986573338508606, variance: 0.020147109404206276\n",
      "Train size: [400] hidden size: [12] trial: 37, train_loss: 1.918135, test loss: 1.006511, bias2: 0.9866437911987305, variance: 0.019867319613695145\n",
      "Train size: [400] hidden size: [12] trial: 38, train_loss: 1.922646, test loss: 1.006419, bias2: 0.9865829348564148, variance: 0.019835645332932472\n",
      "Train size: [400] hidden size: [12] trial: 39, train_loss: 1.916463, test loss: 1.006634, bias2: 0.9869570732116699, variance: 0.019676901400089264\n",
      "Train size: [400] hidden size: [12] trial: 40, train_loss: 1.913968, test loss: 1.006546, bias2: 0.986910343170166, variance: 0.019635936245322227\n",
      "Train size: [400] hidden size: [12] trial: 41, train_loss: 1.915100, test loss: 1.006673, bias2: 0.986823558807373, variance: 0.019849151372909546\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [12] trial: 42, train_loss: 1.918000, test loss: 1.006418, bias2: 0.9864505529403687, variance: 0.019967664033174515\n",
      "Train size: [400] hidden size: [12] trial: 43, train_loss: 1.916245, test loss: 1.006327, bias2: 0.9865214824676514, variance: 0.019805578514933586\n",
      "Train size: [400] hidden size: [12] trial: 44, train_loss: 1.918883, test loss: 1.006210, bias2: 0.9862952828407288, variance: 0.019914356991648674\n",
      "Train size: [400] hidden size: [12] trial: 45, train_loss: 1.921662, test loss: 1.006086, bias2: 0.986094057559967, variance: 0.019992263987660408\n",
      "Train size: [400] hidden size: [12] trial: 46, train_loss: 1.922938, test loss: 1.006052, bias2: 0.9862766861915588, variance: 0.019775206223130226\n",
      "Train size: [400] hidden size: [12] trial: 47, train_loss: 1.923296, test loss: 1.006014, bias2: 0.9862505197525024, variance: 0.019762979820370674\n",
      "Train size: [400] hidden size: [12] trial: 48, train_loss: 1.924703, test loss: 1.006163, bias2: 0.9864662289619446, variance: 0.019696751609444618\n",
      "Train size: [400] hidden size: [12] trial: 49, train_loss: 1.927575, test loss: 1.006237, bias2: 0.9866239428520203, variance: 0.01961272768676281\n",
      "##################################################\n",
      "Train size: [400] hidden size: [14] trial: 0, train_loss: 1.908496, test loss: 0.997975, bias2: 0.9979753494262695, variance: -3.8925479506346505e-10\n",
      "Train size: [400] hidden size: [14] trial: 1, train_loss: 1.950281, test loss: 1.005134, bias2: 0.9875431656837463, variance: 0.01759115792810917\n",
      "Train size: [400] hidden size: [14] trial: 2, train_loss: 1.970076, test loss: 0.998255, bias2: 0.9765440821647644, variance: 0.021710507571697235\n",
      "Train size: [400] hidden size: [14] trial: 3, train_loss: 2.001630, test loss: 1.001284, bias2: 0.9805834293365479, variance: 0.020700566470623016\n",
      "Train size: [400] hidden size: [14] trial: 4, train_loss: 1.951089, test loss: 1.014166, bias2: 0.9837961792945862, variance: 0.030370159074664116\n",
      "Train size: [400] hidden size: [14] trial: 5, train_loss: 1.956704, test loss: 1.012341, bias2: 0.9844225645065308, variance: 0.027918357402086258\n",
      "Train size: [400] hidden size: [14] trial: 6, train_loss: 1.970169, test loss: 1.011770, bias2: 0.9815369248390198, variance: 0.030232973396778107\n",
      "Train size: [400] hidden size: [14] trial: 7, train_loss: 1.948413, test loss: 1.013192, bias2: 0.9837383031845093, variance: 0.029453624039888382\n",
      "Train size: [400] hidden size: [14] trial: 8, train_loss: 1.949050, test loss: 1.010548, bias2: 0.9808428883552551, variance: 0.029704896733164787\n",
      "Train size: [400] hidden size: [14] trial: 9, train_loss: 1.960246, test loss: 1.011368, bias2: 0.9813552498817444, variance: 0.03001268394291401\n",
      "Train size: [400] hidden size: [14] trial: 10, train_loss: 1.952112, test loss: 1.010503, bias2: 0.9794676899909973, variance: 0.03103574551641941\n",
      "Train size: [400] hidden size: [14] trial: 11, train_loss: 1.945914, test loss: 1.010617, bias2: 0.9803693890571594, variance: 0.030248112976551056\n",
      "Train size: [400] hidden size: [14] trial: 12, train_loss: 1.942187, test loss: 1.009155, bias2: 0.9787709712982178, variance: 0.030384404584765434\n",
      "Train size: [400] hidden size: [14] trial: 13, train_loss: 1.935121, test loss: 1.009219, bias2: 0.9796770215034485, variance: 0.02954178862273693\n",
      "Train size: [400] hidden size: [14] trial: 14, train_loss: 1.951996, test loss: 1.010060, bias2: 0.980360746383667, variance: 0.029699591919779778\n",
      "Train size: [400] hidden size: [14] trial: 15, train_loss: 1.939715, test loss: 1.009603, bias2: 0.9803420305252075, variance: 0.029261112213134766\n",
      "Train size: [400] hidden size: [14] trial: 16, train_loss: 1.928710, test loss: 1.010849, bias2: 0.9815958738327026, variance: 0.029252856969833374\n",
      "Train size: [400] hidden size: [14] trial: 17, train_loss: 1.925409, test loss: 1.010619, bias2: 0.9820931553840637, variance: 0.028525909408926964\n",
      "Train size: [400] hidden size: [14] trial: 18, train_loss: 1.935031, test loss: 1.010297, bias2: 0.9815087914466858, variance: 0.028787819668650627\n",
      "Train size: [400] hidden size: [14] trial: 19, train_loss: 1.938026, test loss: 1.009777, bias2: 0.9812296628952026, variance: 0.028547286987304688\n",
      "Train size: [400] hidden size: [14] trial: 20, train_loss: 1.938613, test loss: 1.010421, bias2: 0.9802289605140686, variance: 0.030192049220204353\n",
      "Train size: [400] hidden size: [14] trial: 21, train_loss: 1.944836, test loss: 1.009633, bias2: 0.978342592716217, variance: 0.031290728598833084\n",
      "Train size: [400] hidden size: [14] trial: 22, train_loss: 1.948353, test loss: 1.009828, bias2: 0.9787483215332031, variance: 0.031079301610589027\n",
      "Train size: [400] hidden size: [14] trial: 23, train_loss: 1.938444, test loss: 1.009231, bias2: 0.9783364534378052, variance: 0.030894871801137924\n",
      "Train size: [400] hidden size: [14] trial: 24, train_loss: 1.942246, test loss: 1.008905, bias2: 0.978685200214386, variance: 0.030220340937376022\n",
      "Train size: [400] hidden size: [14] trial: 25, train_loss: 1.939572, test loss: 1.008446, bias2: 0.9783384799957275, variance: 0.030107025057077408\n",
      "Train size: [400] hidden size: [14] trial: 26, train_loss: 1.942219, test loss: 1.008126, bias2: 0.9777724146842957, variance: 0.030353736132383347\n",
      "Train size: [400] hidden size: [14] trial: 27, train_loss: 1.949917, test loss: 1.007775, bias2: 0.978023111820221, variance: 0.02975197322666645\n",
      "Train size: [400] hidden size: [14] trial: 28, train_loss: 1.948539, test loss: 1.007505, bias2: 0.9776995778083801, variance: 0.029805123805999756\n",
      "Train size: [400] hidden size: [14] trial: 29, train_loss: 1.940208, test loss: 1.007409, bias2: 0.9779034852981567, variance: 0.029505988582968712\n",
      "Train size: [400] hidden size: [14] trial: 30, train_loss: 1.932683, test loss: 1.007348, bias2: 0.978410005569458, variance: 0.028937550261616707\n",
      "Train size: [400] hidden size: [14] trial: 31, train_loss: 1.930713, test loss: 1.007384, bias2: 0.9784897565841675, variance: 0.028893815353512764\n",
      "Train size: [400] hidden size: [14] trial: 32, train_loss: 1.927424, test loss: 1.006997, bias2: 0.9780834317207336, variance: 0.028913548216223717\n",
      "Train size: [400] hidden size: [14] trial: 33, train_loss: 1.933666, test loss: 1.007419, bias2: 0.9786874055862427, variance: 0.028731465339660645\n",
      "Train size: [400] hidden size: [14] trial: 34, train_loss: 1.926753, test loss: 1.007529, bias2: 0.979131817817688, variance: 0.0283973328769207\n",
      "Train size: [400] hidden size: [14] trial: 35, train_loss: 1.923156, test loss: 1.007843, bias2: 0.9795828461647034, variance: 0.028260504826903343\n",
      "Train size: [400] hidden size: [14] trial: 36, train_loss: 1.923916, test loss: 1.008352, bias2: 0.9794992208480835, variance: 0.028852473944425583\n",
      "Train size: [400] hidden size: [14] trial: 37, train_loss: 1.929040, test loss: 1.008631, bias2: 0.9793827533721924, variance: 0.029248477891087532\n",
      "Train size: [400] hidden size: [14] trial: 38, train_loss: 1.930168, test loss: 1.007946, bias2: 0.9784493446350098, variance: 0.02949640341103077\n",
      "Train size: [400] hidden size: [14] trial: 39, train_loss: 1.930557, test loss: 1.007711, bias2: 0.9776260852813721, variance: 0.030084483325481415\n",
      "Train size: [400] hidden size: [14] trial: 40, train_loss: 1.936611, test loss: 1.007822, bias2: 0.9773646593093872, variance: 0.030457286164164543\n",
      "Train size: [400] hidden size: [14] trial: 41, train_loss: 1.936684, test loss: 1.007905, bias2: 0.9776405692100525, variance: 0.03026396594941616\n",
      "Train size: [400] hidden size: [14] trial: 42, train_loss: 1.937925, test loss: 1.007434, bias2: 0.977315366268158, variance: 0.03011886402964592\n",
      "Train size: [400] hidden size: [14] trial: 43, train_loss: 1.935543, test loss: 1.007350, bias2: 0.9772639870643616, variance: 0.030085979029536247\n",
      "Train size: [400] hidden size: [14] trial: 44, train_loss: 1.934547, test loss: 1.007138, bias2: 0.9768416881561279, variance: 0.03029593825340271\n",
      "Train size: [400] hidden size: [14] trial: 45, train_loss: 1.935675, test loss: 1.007363, bias2: 0.9774127006530762, variance: 0.029950745403766632\n",
      "Train size: [400] hidden size: [14] trial: 46, train_loss: 1.937825, test loss: 1.007294, bias2: 0.9776597023010254, variance: 0.029634451493620872\n",
      "Train size: [400] hidden size: [14] trial: 47, train_loss: 1.938117, test loss: 1.007240, bias2: 0.977949321269989, variance: 0.029290854930877686\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [14] trial: 48, train_loss: 1.940340, test loss: 1.007331, bias2: 0.9783313274383545, variance: 0.028999585658311844\n",
      "Train size: [400] hidden size: [14] trial: 49, train_loss: 1.936916, test loss: 1.007245, bias2: 0.9784054756164551, variance: 0.028839251026511192\n",
      "##################################################\n",
      "Train size: [400] hidden size: [16] trial: 0, train_loss: 1.849494, test loss: 1.014207, bias2: 1.0142066478729248, variance: 1.3380634100723654e-10\n",
      "Train size: [400] hidden size: [16] trial: 1, train_loss: 1.887081, test loss: 1.015712, bias2: 1.0079091787338257, variance: 0.007802724838256836\n",
      "Train size: [400] hidden size: [16] trial: 2, train_loss: 1.822992, test loss: 1.013926, bias2: 1.0002537965774536, variance: 0.013672460801899433\n",
      "Train size: [400] hidden size: [16] trial: 3, train_loss: 1.825724, test loss: 1.010298, bias2: 0.9949454665184021, variance: 0.01535257138311863\n",
      "Train size: [400] hidden size: [16] trial: 4, train_loss: 1.825658, test loss: 1.016651, bias2: 0.9973114132881165, variance: 0.019339362159371376\n",
      "Train size: [400] hidden size: [16] trial: 5, train_loss: 1.846683, test loss: 1.019268, bias2: 0.9989424347877502, variance: 0.02032526396214962\n",
      "Train size: [400] hidden size: [16] trial: 6, train_loss: 1.868147, test loss: 1.016456, bias2: 0.9934203624725342, variance: 0.023035747930407524\n",
      "Train size: [400] hidden size: [16] trial: 7, train_loss: 1.868172, test loss: 1.016186, bias2: 0.9922776818275452, variance: 0.023907965049147606\n",
      "Train size: [400] hidden size: [16] trial: 8, train_loss: 1.844854, test loss: 1.013838, bias2: 0.990486741065979, variance: 0.023351401090621948\n",
      "Train size: [400] hidden size: [16] trial: 9, train_loss: 1.869500, test loss: 1.014406, bias2: 0.9880312085151672, variance: 0.026374418288469315\n",
      "Train size: [400] hidden size: [16] trial: 10, train_loss: 1.868132, test loss: 1.014369, bias2: 0.9868308305740356, variance: 0.027537675574421883\n",
      "Train size: [400] hidden size: [16] trial: 11, train_loss: 1.872699, test loss: 1.012610, bias2: 0.984548807144165, variance: 0.028061266988515854\n",
      "Train size: [400] hidden size: [16] trial: 12, train_loss: 1.872225, test loss: 1.010676, bias2: 0.9820850491523743, variance: 0.02859049290418625\n",
      "Train size: [400] hidden size: [16] trial: 13, train_loss: 1.876972, test loss: 1.010212, bias2: 0.9816106557846069, variance: 0.02860107831656933\n",
      "Train size: [400] hidden size: [16] trial: 14, train_loss: 1.885520, test loss: 1.010454, bias2: 0.9817709922790527, variance: 0.028683077543973923\n",
      "Train size: [400] hidden size: [16] trial: 15, train_loss: 1.887637, test loss: 1.010115, bias2: 0.9800945520401001, variance: 0.030020805075764656\n",
      "Train size: [400] hidden size: [16] trial: 16, train_loss: 1.901573, test loss: 1.010031, bias2: 0.9809010624885559, variance: 0.029129795730113983\n",
      "Train size: [400] hidden size: [16] trial: 17, train_loss: 1.895038, test loss: 1.010471, bias2: 0.9822527170181274, variance: 0.02821815200150013\n",
      "Train size: [400] hidden size: [16] trial: 18, train_loss: 1.884255, test loss: 1.010245, bias2: 0.9821669459342957, variance: 0.02807765267789364\n",
      "Train size: [400] hidden size: [16] trial: 19, train_loss: 1.891323, test loss: 1.009657, bias2: 0.9816493391990662, variance: 0.028007419779896736\n",
      "Train size: [400] hidden size: [16] trial: 20, train_loss: 1.900772, test loss: 1.009372, bias2: 0.9813855290412903, variance: 0.027986610308289528\n",
      "Train size: [400] hidden size: [16] trial: 21, train_loss: 1.903058, test loss: 1.009458, bias2: 0.9821230173110962, variance: 0.027334701269865036\n",
      "Train size: [400] hidden size: [16] trial: 22, train_loss: 1.904737, test loss: 1.009608, bias2: 0.9821097254753113, variance: 0.027498643845319748\n",
      "Train size: [400] hidden size: [16] trial: 23, train_loss: 1.911023, test loss: 1.009430, bias2: 0.9817518591880798, variance: 0.027677807956933975\n",
      "Train size: [400] hidden size: [16] trial: 24, train_loss: 1.910112, test loss: 1.009615, bias2: 0.9822232723236084, variance: 0.02739131823182106\n",
      "Train size: [400] hidden size: [16] trial: 25, train_loss: 1.908270, test loss: 1.008816, bias2: 0.9815055727958679, variance: 0.02731041982769966\n",
      "Train size: [400] hidden size: [16] trial: 26, train_loss: 1.901720, test loss: 1.008645, bias2: 0.9818164706230164, variance: 0.02682836353778839\n",
      "Train size: [400] hidden size: [16] trial: 27, train_loss: 1.903780, test loss: 1.008337, bias2: 0.9813841581344604, variance: 0.02695334143936634\n",
      "Train size: [400] hidden size: [16] trial: 28, train_loss: 1.903463, test loss: 1.008874, bias2: 0.9817004799842834, variance: 0.027173586189746857\n",
      "Train size: [400] hidden size: [16] trial: 29, train_loss: 1.903758, test loss: 1.008784, bias2: 0.9814022183418274, variance: 0.02738157846033573\n",
      "Train size: [400] hidden size: [16] trial: 30, train_loss: 1.900098, test loss: 1.008768, bias2: 0.9815706610679626, variance: 0.027196917682886124\n",
      "Train size: [400] hidden size: [16] trial: 31, train_loss: 1.908191, test loss: 1.008776, bias2: 0.9819262027740479, variance: 0.026849407702684402\n",
      "Train size: [400] hidden size: [16] trial: 32, train_loss: 1.914525, test loss: 1.008766, bias2: 0.9813784956932068, variance: 0.02738792449235916\n",
      "Train size: [400] hidden size: [16] trial: 33, train_loss: 1.912778, test loss: 1.008361, bias2: 0.9811092019081116, variance: 0.02725178748369217\n",
      "Train size: [400] hidden size: [16] trial: 34, train_loss: 1.912344, test loss: 1.008838, bias2: 0.9816761016845703, variance: 0.027161462232470512\n",
      "Train size: [400] hidden size: [16] trial: 35, train_loss: 1.911718, test loss: 1.008633, bias2: 0.9814578294754028, variance: 0.027175569906830788\n",
      "Train size: [400] hidden size: [16] trial: 36, train_loss: 1.913273, test loss: 1.008576, bias2: 0.9811726212501526, variance: 0.02740328572690487\n",
      "Train size: [400] hidden size: [16] trial: 37, train_loss: 1.910026, test loss: 1.008104, bias2: 0.9802359342575073, variance: 0.027867551892995834\n",
      "Train size: [400] hidden size: [16] trial: 38, train_loss: 1.910390, test loss: 1.007709, bias2: 0.9796470999717712, variance: 0.02806159295141697\n",
      "Train size: [400] hidden size: [16] trial: 39, train_loss: 1.913003, test loss: 1.008085, bias2: 0.9796751737594604, variance: 0.028410309925675392\n",
      "Train size: [400] hidden size: [16] trial: 40, train_loss: 1.916527, test loss: 1.008109, bias2: 0.9795618057250977, variance: 0.028547042980790138\n",
      "Train size: [400] hidden size: [16] trial: 41, train_loss: 1.920322, test loss: 1.008120, bias2: 0.9794633984565735, variance: 0.028656208887696266\n",
      "Train size: [400] hidden size: [16] trial: 42, train_loss: 1.917994, test loss: 1.008033, bias2: 0.97955721616745, variance: 0.02847556211054325\n",
      "Train size: [400] hidden size: [16] trial: 43, train_loss: 1.916516, test loss: 1.008538, bias2: 0.9799500107765198, variance: 0.028588222339749336\n",
      "Train size: [400] hidden size: [16] trial: 44, train_loss: 1.917021, test loss: 1.009145, bias2: 0.9802823662757874, variance: 0.02886216714978218\n",
      "Train size: [400] hidden size: [16] trial: 45, train_loss: 1.917463, test loss: 1.008827, bias2: 0.9799054861068726, variance: 0.028921393677592278\n",
      "Train size: [400] hidden size: [16] trial: 46, train_loss: 1.922634, test loss: 1.008483, bias2: 0.9794576168060303, variance: 0.029025645926594734\n",
      "Train size: [400] hidden size: [16] trial: 47, train_loss: 1.926362, test loss: 1.008609, bias2: 0.9790413975715637, variance: 0.029567869380116463\n",
      "Train size: [400] hidden size: [16] trial: 48, train_loss: 1.922975, test loss: 1.008557, bias2: 0.9786050915718079, variance: 0.029951369389891624\n",
      "Train size: [400] hidden size: [16] trial: 49, train_loss: 1.923179, test loss: 1.008300, bias2: 0.9784084558486938, variance: 0.029891828075051308\n",
      "##################################################\n",
      "Train size: [400] hidden size: [19] trial: 0, train_loss: 1.886400, test loss: 0.997016, bias2: 0.9970155954360962, variance: -1.7029898324860682e-10\n",
      "Train size: [400] hidden size: [19] trial: 1, train_loss: 1.799984, test loss: 1.008216, bias2: 0.9923763275146484, variance: 0.015839697793126106\n",
      "Train size: [400] hidden size: [19] trial: 2, train_loss: 1.792785, test loss: 1.011459, bias2: 0.9933468699455261, variance: 0.01811174303293228\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [19] trial: 3, train_loss: 1.848218, test loss: 1.010496, bias2: 0.9839601516723633, variance: 0.02653549052774906\n",
      "Train size: [400] hidden size: [19] trial: 4, train_loss: 1.852955, test loss: 1.011847, bias2: 0.9841907620429993, variance: 0.027655990794301033\n",
      "Train size: [400] hidden size: [19] trial: 5, train_loss: 1.824316, test loss: 1.013311, bias2: 0.9871945381164551, variance: 0.0261160209774971\n",
      "Train size: [400] hidden size: [19] trial: 6, train_loss: 1.823268, test loss: 1.011938, bias2: 0.9850625395774841, variance: 0.026875300332903862\n",
      "Train size: [400] hidden size: [19] trial: 7, train_loss: 1.839288, test loss: 1.011786, bias2: 0.9855703115463257, variance: 0.026215657591819763\n",
      "Train size: [400] hidden size: [19] trial: 8, train_loss: 1.844907, test loss: 1.010013, bias2: 0.9839005470275879, variance: 0.026112545281648636\n",
      "Train size: [400] hidden size: [19] trial: 9, train_loss: 1.860490, test loss: 1.010702, bias2: 0.9845054745674133, variance: 0.02619655802845955\n",
      "Train size: [400] hidden size: [19] trial: 10, train_loss: 1.891505, test loss: 1.011396, bias2: 0.9841121435165405, variance: 0.02728426456451416\n",
      "Train size: [400] hidden size: [19] trial: 11, train_loss: 1.899753, test loss: 1.011419, bias2: 0.9841060042381287, variance: 0.027312934398651123\n",
      "Train size: [400] hidden size: [19] trial: 12, train_loss: 1.922309, test loss: 1.010849, bias2: 0.9831086993217468, variance: 0.02774006500840187\n",
      "Train size: [400] hidden size: [19] trial: 13, train_loss: 1.917773, test loss: 1.010581, bias2: 0.9821680188179016, variance: 0.02841266803443432\n",
      "Train size: [400] hidden size: [19] trial: 14, train_loss: 1.906946, test loss: 1.010142, bias2: 0.9818019270896912, variance: 0.028339935466647148\n",
      "Train size: [400] hidden size: [19] trial: 15, train_loss: 1.897419, test loss: 1.010437, bias2: 0.9824104905128479, variance: 0.028026031330227852\n",
      "Train size: [400] hidden size: [19] trial: 16, train_loss: 1.904835, test loss: 1.011066, bias2: 0.9827696681022644, variance: 0.028295839205384254\n",
      "Train size: [400] hidden size: [19] trial: 17, train_loss: 1.911835, test loss: 1.011275, bias2: 0.9823911190032959, variance: 0.028883840888738632\n",
      "Train size: [400] hidden size: [19] trial: 18, train_loss: 1.910487, test loss: 1.011161, bias2: 0.9820441603660583, variance: 0.029117152094841003\n",
      "Train size: [400] hidden size: [19] trial: 19, train_loss: 1.907750, test loss: 1.010624, bias2: 0.9806814193725586, variance: 0.02994285710155964\n",
      "Train size: [400] hidden size: [19] trial: 20, train_loss: 1.909353, test loss: 1.011203, bias2: 0.98070228099823, variance: 0.030501127243041992\n",
      "Train size: [400] hidden size: [19] trial: 21, train_loss: 1.919204, test loss: 1.010998, bias2: 0.9809441566467285, variance: 0.030053403228521347\n",
      "Train size: [400] hidden size: [19] trial: 22, train_loss: 1.920268, test loss: 1.010804, bias2: 0.9809743165969849, variance: 0.029829949140548706\n",
      "Train size: [400] hidden size: [19] trial: 23, train_loss: 1.910032, test loss: 1.010514, bias2: 0.9808394312858582, variance: 0.029674958437681198\n",
      "Train size: [400] hidden size: [19] trial: 24, train_loss: 1.907784, test loss: 1.009081, bias2: 0.9786883592605591, variance: 0.030392862856388092\n",
      "Train size: [400] hidden size: [19] trial: 25, train_loss: 1.906092, test loss: 1.008776, bias2: 0.9786466360092163, variance: 0.03012920543551445\n",
      "Train size: [400] hidden size: [19] trial: 26, train_loss: 1.916834, test loss: 1.008933, bias2: 0.9792431592941284, variance: 0.029689420014619827\n",
      "Train size: [400] hidden size: [19] trial: 27, train_loss: 1.916022, test loss: 1.007841, bias2: 0.9780319929122925, variance: 0.029808739200234413\n",
      "Train size: [400] hidden size: [19] trial: 28, train_loss: 1.909478, test loss: 1.008173, bias2: 0.9783442616462708, variance: 0.029828956350684166\n",
      "Train size: [400] hidden size: [19] trial: 29, train_loss: 1.903874, test loss: 1.008234, bias2: 0.9784573912620544, variance: 0.02977675572037697\n",
      "Train size: [400] hidden size: [19] trial: 30, train_loss: 1.909970, test loss: 1.008419, bias2: 0.9782429337501526, variance: 0.03017607517540455\n",
      "Train size: [400] hidden size: [19] trial: 31, train_loss: 1.912634, test loss: 1.008487, bias2: 0.9782825112342834, variance: 0.030204949900507927\n",
      "Train size: [400] hidden size: [19] trial: 32, train_loss: 1.906504, test loss: 1.008697, bias2: 0.9778014421463013, variance: 0.030895812436938286\n",
      "Train size: [400] hidden size: [19] trial: 33, train_loss: 1.901812, test loss: 1.009020, bias2: 0.9780664443969727, variance: 0.030953744426369667\n",
      "Train size: [400] hidden size: [19] trial: 34, train_loss: 1.899962, test loss: 1.008858, bias2: 0.9782539010047913, variance: 0.03060407191514969\n",
      "Train size: [400] hidden size: [19] trial: 35, train_loss: 1.911460, test loss: 1.009154, bias2: 0.978893518447876, variance: 0.030260661616921425\n",
      "Train size: [400] hidden size: [19] trial: 36, train_loss: 1.909027, test loss: 1.009436, bias2: 0.9790441989898682, variance: 0.030391588807106018\n",
      "Train size: [400] hidden size: [19] trial: 37, train_loss: 1.901624, test loss: 1.008879, bias2: 0.9782612919807434, variance: 0.030617903918027878\n",
      "Train size: [400] hidden size: [19] trial: 38, train_loss: 1.902248, test loss: 1.009175, bias2: 0.978420078754425, variance: 0.030754512175917625\n",
      "Train size: [400] hidden size: [19] trial: 39, train_loss: 1.903922, test loss: 1.009237, bias2: 0.9782953858375549, variance: 0.030941324308514595\n",
      "Train size: [400] hidden size: [19] trial: 40, train_loss: 1.904544, test loss: 1.009402, bias2: 0.9789021015167236, variance: 0.030499961227178574\n",
      "Train size: [400] hidden size: [19] trial: 41, train_loss: 1.897936, test loss: 1.009401, bias2: 0.9789474606513977, variance: 0.030453985556960106\n",
      "Train size: [400] hidden size: [19] trial: 42, train_loss: 1.899639, test loss: 1.009658, bias2: 0.9792306423187256, variance: 0.0304275956004858\n",
      "Train size: [400] hidden size: [19] trial: 43, train_loss: 1.903861, test loss: 1.009074, bias2: 0.9787442684173584, variance: 0.030329452827572823\n",
      "Train size: [400] hidden size: [19] trial: 44, train_loss: 1.901899, test loss: 1.008874, bias2: 0.9785468578338623, variance: 0.03032682090997696\n",
      "Train size: [400] hidden size: [19] trial: 45, train_loss: 1.896614, test loss: 1.008667, bias2: 0.9783403873443604, variance: 0.030326344072818756\n",
      "Train size: [400] hidden size: [19] trial: 46, train_loss: 1.898714, test loss: 1.008903, bias2: 0.9788474440574646, variance: 0.03005548007786274\n",
      "Train size: [400] hidden size: [19] trial: 47, train_loss: 1.898093, test loss: 1.008989, bias2: 0.9783264994621277, variance: 0.030662592500448227\n",
      "Train size: [400] hidden size: [19] trial: 48, train_loss: 1.895568, test loss: 1.009040, bias2: 0.9780982732772827, variance: 0.03094160184264183\n",
      "Train size: [400] hidden size: [19] trial: 49, train_loss: 1.900987, test loss: 1.008909, bias2: 0.9777386784553528, variance: 0.031170325353741646\n",
      "##################################################\n",
      "Train size: [400] hidden size: [22] trial: 0, train_loss: 1.598521, test loss: 0.994866, bias2: 0.9948657751083374, variance: 9.731369876586626e-11\n",
      "Train size: [400] hidden size: [22] trial: 1, train_loss: 1.779859, test loss: 1.002468, bias2: 0.9872465133666992, variance: 0.015221497975289822\n",
      "Train size: [400] hidden size: [22] trial: 2, train_loss: 1.778488, test loss: 1.001815, bias2: 0.978864848613739, variance: 0.022950224578380585\n",
      "Train size: [400] hidden size: [22] trial: 3, train_loss: 1.809085, test loss: 1.010854, bias2: 0.9767217636108398, variance: 0.034132350236177444\n",
      "Train size: [400] hidden size: [22] trial: 4, train_loss: 1.837981, test loss: 1.012686, bias2: 0.9784561395645142, variance: 0.034230221062898636\n",
      "Train size: [400] hidden size: [22] trial: 5, train_loss: 1.899411, test loss: 1.017034, bias2: 0.9817137122154236, variance: 0.035320576280355453\n",
      "Train size: [400] hidden size: [22] trial: 6, train_loss: 1.927892, test loss: 1.013467, bias2: 0.9791926145553589, variance: 0.03427460789680481\n",
      "Train size: [400] hidden size: [22] trial: 7, train_loss: 1.912268, test loss: 1.017325, bias2: 0.9829831719398499, variance: 0.03434211388230324\n",
      "Train size: [400] hidden size: [22] trial: 8, train_loss: 1.888526, test loss: 1.015356, bias2: 0.9805797934532166, variance: 0.034776266664266586\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [22] trial: 9, train_loss: 1.900421, test loss: 1.016392, bias2: 0.9796793460845947, variance: 0.036712776869535446\n",
      "Train size: [400] hidden size: [22] trial: 10, train_loss: 1.866392, test loss: 1.012075, bias2: 0.9743219017982483, variance: 0.03775278478860855\n",
      "Train size: [400] hidden size: [22] trial: 11, train_loss: 1.861971, test loss: 1.010415, bias2: 0.9726834893226624, variance: 0.037731971591711044\n",
      "Train size: [400] hidden size: [22] trial: 12, train_loss: 1.866212, test loss: 1.011779, bias2: 0.9740248918533325, variance: 0.037754278630018234\n",
      "Train size: [400] hidden size: [22] trial: 13, train_loss: 1.857480, test loss: 1.012507, bias2: 0.974590003490448, variance: 0.03791693225502968\n",
      "Train size: [400] hidden size: [22] trial: 14, train_loss: 1.854938, test loss: 1.011502, bias2: 0.973438024520874, variance: 0.0380643829703331\n",
      "Train size: [400] hidden size: [22] trial: 15, train_loss: 1.858852, test loss: 1.011676, bias2: 0.9742839932441711, variance: 0.03739173710346222\n",
      "Train size: [400] hidden size: [22] trial: 16, train_loss: 1.862229, test loss: 1.011779, bias2: 0.9741904735565186, variance: 0.037588611245155334\n",
      "Train size: [400] hidden size: [22] trial: 17, train_loss: 1.855603, test loss: 1.011863, bias2: 0.9731636643409729, variance: 0.0386992022395134\n",
      "Train size: [400] hidden size: [22] trial: 18, train_loss: 1.852546, test loss: 1.011173, bias2: 0.9724998474121094, variance: 0.03867330402135849\n",
      "Train size: [400] hidden size: [22] trial: 19, train_loss: 1.857066, test loss: 1.011132, bias2: 0.9726165533065796, variance: 0.03851582854986191\n",
      "Train size: [400] hidden size: [22] trial: 20, train_loss: 1.862674, test loss: 1.010348, bias2: 0.972133994102478, variance: 0.03821372613310814\n",
      "Train size: [400] hidden size: [22] trial: 21, train_loss: 1.861093, test loss: 1.010712, bias2: 0.9727228283882141, variance: 0.03798907622694969\n",
      "Train size: [400] hidden size: [22] trial: 22, train_loss: 1.859120, test loss: 1.010141, bias2: 0.972113311290741, variance: 0.03802816569805145\n",
      "Train size: [400] hidden size: [22] trial: 23, train_loss: 1.859019, test loss: 1.009174, bias2: 0.9704881906509399, variance: 0.03868558257818222\n",
      "Train size: [400] hidden size: [22] trial: 24, train_loss: 1.850885, test loss: 1.009267, bias2: 0.9712685346603394, variance: 0.03799867630004883\n",
      "Train size: [400] hidden size: [22] trial: 25, train_loss: 1.850106, test loss: 1.009484, bias2: 0.9712480902671814, variance: 0.038235824555158615\n",
      "Train size: [400] hidden size: [22] trial: 26, train_loss: 1.852899, test loss: 1.010338, bias2: 0.972305178642273, variance: 0.0380324125289917\n",
      "Train size: [400] hidden size: [22] trial: 27, train_loss: 1.854666, test loss: 1.011348, bias2: 0.9730639457702637, variance: 0.03828408196568489\n",
      "Train size: [400] hidden size: [22] trial: 28, train_loss: 1.849169, test loss: 1.011046, bias2: 0.9734859466552734, variance: 0.03756000101566315\n",
      "Train size: [400] hidden size: [22] trial: 29, train_loss: 1.842074, test loss: 1.010363, bias2: 0.973025918006897, variance: 0.037337325513362885\n",
      "Train size: [400] hidden size: [22] trial: 30, train_loss: 1.842121, test loss: 1.009339, bias2: 0.971676766872406, variance: 0.037661708891391754\n",
      "Train size: [400] hidden size: [22] trial: 31, train_loss: 1.839277, test loss: 1.009555, bias2: 0.9719082713127136, variance: 0.037646617740392685\n",
      "Train size: [400] hidden size: [22] trial: 32, train_loss: 1.841881, test loss: 1.009710, bias2: 0.9723325371742249, variance: 0.03737705200910568\n",
      "Train size: [400] hidden size: [22] trial: 33, train_loss: 1.843930, test loss: 1.011023, bias2: 0.9727866053581238, variance: 0.03823595494031906\n",
      "Train size: [400] hidden size: [22] trial: 34, train_loss: 1.854272, test loss: 1.011436, bias2: 0.9730336666107178, variance: 0.03840198740363121\n",
      "Train size: [400] hidden size: [22] trial: 35, train_loss: 1.853861, test loss: 1.010506, bias2: 0.9719607830047607, variance: 0.038545023649930954\n",
      "Train size: [400] hidden size: [22] trial: 36, train_loss: 1.857333, test loss: 1.010960, bias2: 0.9722105264663696, variance: 0.038749560713768005\n",
      "Train size: [400] hidden size: [22] trial: 37, train_loss: 1.858989, test loss: 1.010636, bias2: 0.9721946716308594, variance: 0.03844150900840759\n",
      "Train size: [400] hidden size: [22] trial: 38, train_loss: 1.858443, test loss: 1.010747, bias2: 0.9716034531593323, variance: 0.03914383798837662\n",
      "Train size: [400] hidden size: [22] trial: 39, train_loss: 1.856528, test loss: 1.010815, bias2: 0.9718616008758545, variance: 0.03895355015993118\n",
      "Train size: [400] hidden size: [22] trial: 40, train_loss: 1.858754, test loss: 1.010688, bias2: 0.9717459082603455, variance: 0.03894193843007088\n",
      "Train size: [400] hidden size: [22] trial: 41, train_loss: 1.857731, test loss: 1.010914, bias2: 0.9723566174507141, variance: 0.038556989282369614\n",
      "Train size: [400] hidden size: [22] trial: 42, train_loss: 1.852712, test loss: 1.010930, bias2: 0.9722288846969604, variance: 0.03870156407356262\n",
      "Train size: [400] hidden size: [22] trial: 43, train_loss: 1.855118, test loss: 1.011280, bias2: 0.9729698896408081, variance: 0.03830980509519577\n",
      "Train size: [400] hidden size: [22] trial: 44, train_loss: 1.857754, test loss: 1.011060, bias2: 0.972852885723114, variance: 0.03820665180683136\n",
      "Train size: [400] hidden size: [22] trial: 45, train_loss: 1.858551, test loss: 1.011324, bias2: 0.9729524254798889, variance: 0.03837199881672859\n",
      "Train size: [400] hidden size: [22] trial: 46, train_loss: 1.856769, test loss: 1.011185, bias2: 0.9723820090293884, variance: 0.03880305588245392\n",
      "Train size: [400] hidden size: [22] trial: 47, train_loss: 1.856920, test loss: 1.010970, bias2: 0.972290575504303, variance: 0.03867906332015991\n",
      "Train size: [400] hidden size: [22] trial: 48, train_loss: 1.856467, test loss: 1.010880, bias2: 0.9722216129302979, variance: 0.03865803778171539\n",
      "Train size: [400] hidden size: [22] trial: 49, train_loss: 1.859719, test loss: 1.010970, bias2: 0.9726482629776001, variance: 0.03832148760557175\n",
      "##################################################\n",
      "Train size: [400] hidden size: [25] trial: 0, train_loss: 1.687477, test loss: 1.020197, bias2: 1.0201969146728516, variance: -2.4328425385355956e-10\n",
      "Train size: [400] hidden size: [25] trial: 1, train_loss: 1.776066, test loss: 1.014856, bias2: 0.9965460300445557, variance: 0.018309833481907845\n",
      "Train size: [400] hidden size: [25] trial: 2, train_loss: 1.789026, test loss: 1.009744, bias2: 0.9895590543746948, variance: 0.020185332745313644\n",
      "Train size: [400] hidden size: [25] trial: 3, train_loss: 1.844471, test loss: 1.016774, bias2: 0.9917872548103333, variance: 0.024986697360873222\n",
      "Train size: [400] hidden size: [25] trial: 4, train_loss: 1.869138, test loss: 1.018062, bias2: 0.9912146925926208, variance: 0.026847517117857933\n",
      "Train size: [400] hidden size: [25] trial: 5, train_loss: 1.874948, test loss: 1.019978, bias2: 0.9903923869132996, variance: 0.02958577685058117\n",
      "Train size: [400] hidden size: [25] trial: 6, train_loss: 1.854425, test loss: 1.018044, bias2: 0.9886612892150879, variance: 0.02938237413764\n",
      "Train size: [400] hidden size: [25] trial: 7, train_loss: 1.892310, test loss: 1.015298, bias2: 0.9871600270271301, variance: 0.02813820168375969\n",
      "Train size: [400] hidden size: [25] trial: 8, train_loss: 1.878378, test loss: 1.011183, bias2: 0.9818832278251648, variance: 0.029299795627593994\n",
      "Train size: [400] hidden size: [25] trial: 9, train_loss: 1.871770, test loss: 1.011064, bias2: 0.9772195816040039, variance: 0.033844832330942154\n",
      "Train size: [400] hidden size: [25] trial: 10, train_loss: 1.870063, test loss: 1.014406, bias2: 0.9781192541122437, variance: 0.03628670424222946\n",
      "Train size: [400] hidden size: [25] trial: 11, train_loss: 1.872191, test loss: 1.012224, bias2: 0.9724292755126953, variance: 0.03979470953345299\n",
      "Train size: [400] hidden size: [25] trial: 12, train_loss: 1.861753, test loss: 1.012638, bias2: 0.9733418822288513, variance: 0.03929642215371132\n",
      "Train size: [400] hidden size: [25] trial: 13, train_loss: 1.844461, test loss: 1.011678, bias2: 0.9717759490013123, variance: 0.03990192338824272\n",
      "Train size: [400] hidden size: [25] trial: 14, train_loss: 1.847122, test loss: 1.011307, bias2: 0.9713907241821289, variance: 0.03991665691137314\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [25] trial: 15, train_loss: 1.838827, test loss: 1.011610, bias2: 0.9720054864883423, variance: 0.039604902267456055\n",
      "Train size: [400] hidden size: [25] trial: 16, train_loss: 1.846470, test loss: 1.011184, bias2: 0.9716703295707703, variance: 0.03951329365372658\n",
      "Train size: [400] hidden size: [25] trial: 17, train_loss: 1.855481, test loss: 1.011223, bias2: 0.9706658720970154, variance: 0.04055742919445038\n",
      "Train size: [400] hidden size: [25] trial: 18, train_loss: 1.852215, test loss: 1.011616, bias2: 0.9709435701370239, variance: 0.04067252576351166\n",
      "Train size: [400] hidden size: [25] trial: 19, train_loss: 1.852871, test loss: 1.010906, bias2: 0.9696024060249329, variance: 0.041303906589746475\n",
      "Train size: [400] hidden size: [25] trial: 20, train_loss: 1.851923, test loss: 1.011003, bias2: 0.9704277515411377, variance: 0.04057548567652702\n",
      "Train size: [400] hidden size: [25] trial: 21, train_loss: 1.849073, test loss: 1.010336, bias2: 0.9697562456130981, variance: 0.0405796580016613\n",
      "Train size: [400] hidden size: [25] trial: 22, train_loss: 1.848623, test loss: 1.010356, bias2: 0.969940185546875, variance: 0.040415745228528976\n",
      "Train size: [400] hidden size: [25] trial: 23, train_loss: 1.853006, test loss: 1.010072, bias2: 0.9692578911781311, variance: 0.040813956409692764\n",
      "Train size: [400] hidden size: [25] trial: 24, train_loss: 1.841691, test loss: 1.010923, bias2: 0.969515860080719, variance: 0.04140752553939819\n",
      "Train size: [400] hidden size: [25] trial: 25, train_loss: 1.844021, test loss: 1.011315, bias2: 0.9693443775177002, variance: 0.0419703833758831\n",
      "Train size: [400] hidden size: [25] trial: 26, train_loss: 1.842520, test loss: 1.010624, bias2: 0.9691104888916016, variance: 0.041513919830322266\n",
      "Train size: [400] hidden size: [25] trial: 27, train_loss: 1.852917, test loss: 1.010713, bias2: 0.9696291089057922, variance: 0.041083529591560364\n",
      "Train size: [400] hidden size: [25] trial: 28, train_loss: 1.859329, test loss: 1.010655, bias2: 0.9696412086486816, variance: 0.04101358726620674\n",
      "Train size: [400] hidden size: [25] trial: 29, train_loss: 1.860676, test loss: 1.010538, bias2: 0.9698110222816467, variance: 0.04072717949748039\n",
      "Train size: [400] hidden size: [25] trial: 30, train_loss: 1.863169, test loss: 1.010498, bias2: 0.9697735905647278, variance: 0.04072410240769386\n",
      "Train size: [400] hidden size: [25] trial: 31, train_loss: 1.859941, test loss: 1.010773, bias2: 0.9693767428398132, variance: 0.041396189481019974\n",
      "Train size: [400] hidden size: [25] trial: 32, train_loss: 1.858311, test loss: 1.011703, bias2: 0.9702090620994568, variance: 0.04149418696761131\n",
      "Train size: [400] hidden size: [25] trial: 33, train_loss: 1.866094, test loss: 1.011929, bias2: 0.9709386229515076, variance: 0.04099052771925926\n",
      "Train size: [400] hidden size: [25] trial: 34, train_loss: 1.867999, test loss: 1.011940, bias2: 0.9705924391746521, variance: 0.04134779050946236\n",
      "Train size: [400] hidden size: [25] trial: 35, train_loss: 1.869531, test loss: 1.012114, bias2: 0.9708051681518555, variance: 0.04130851477384567\n",
      "Train size: [400] hidden size: [25] trial: 36, train_loss: 1.866033, test loss: 1.012143, bias2: 0.9710105061531067, variance: 0.041132643818855286\n",
      "Train size: [400] hidden size: [25] trial: 37, train_loss: 1.860267, test loss: 1.011640, bias2: 0.9706070423126221, variance: 0.041032575070858\n",
      "Train size: [400] hidden size: [25] trial: 38, train_loss: 1.862125, test loss: 1.012050, bias2: 0.9708806276321411, variance: 0.04116925969719887\n",
      "Train size: [400] hidden size: [25] trial: 39, train_loss: 1.859273, test loss: 1.011809, bias2: 0.9711195826530457, variance: 0.04068978503346443\n",
      "Train size: [400] hidden size: [25] trial: 40, train_loss: 1.860300, test loss: 1.011837, bias2: 0.971150815486908, variance: 0.04068608209490776\n",
      "Train size: [400] hidden size: [25] trial: 41, train_loss: 1.863649, test loss: 1.012408, bias2: 0.970598042011261, variance: 0.041809484362602234\n",
      "Train size: [400] hidden size: [25] trial: 42, train_loss: 1.862202, test loss: 1.012837, bias2: 0.9713611006736755, variance: 0.04147569090127945\n",
      "Train size: [400] hidden size: [25] trial: 43, train_loss: 1.863038, test loss: 1.012608, bias2: 0.9712801575660706, variance: 0.04132755473256111\n",
      "Train size: [400] hidden size: [25] trial: 44, train_loss: 1.866547, test loss: 1.012553, bias2: 0.9714418053627014, variance: 0.041111286729574203\n",
      "Train size: [400] hidden size: [25] trial: 45, train_loss: 1.864277, test loss: 1.012443, bias2: 0.9715185761451721, variance: 0.040924109518527985\n",
      "Train size: [400] hidden size: [25] trial: 46, train_loss: 1.864094, test loss: 1.012036, bias2: 0.9705320000648499, variance: 0.04150446504354477\n",
      "Train size: [400] hidden size: [25] trial: 47, train_loss: 1.860502, test loss: 1.011428, bias2: 0.9700056910514832, variance: 0.04142197221517563\n",
      "Train size: [400] hidden size: [25] trial: 48, train_loss: 1.866274, test loss: 1.011807, bias2: 0.9699312448501587, variance: 0.04187597334384918\n",
      "Train size: [400] hidden size: [25] trial: 49, train_loss: 1.866838, test loss: 1.011638, bias2: 0.970029890537262, variance: 0.041608382016420364\n",
      "##################################################\n",
      "Train size: [400] hidden size: [29] trial: 0, train_loss: 1.952410, test loss: 1.013329, bias2: 1.0133285522460938, variance: 5.838822203507732e-10\n",
      "Train size: [400] hidden size: [29] trial: 1, train_loss: 1.901373, test loss: 1.008364, bias2: 0.9826512336730957, variance: 0.02571270801126957\n",
      "Train size: [400] hidden size: [29] trial: 2, train_loss: 1.833311, test loss: 1.010716, bias2: 0.977581262588501, variance: 0.03313447907567024\n",
      "Train size: [400] hidden size: [29] trial: 3, train_loss: 1.868848, test loss: 1.016629, bias2: 0.9797958135604858, variance: 0.036833494901657104\n",
      "Train size: [400] hidden size: [29] trial: 4, train_loss: 1.886406, test loss: 1.016079, bias2: 0.9782757759094238, variance: 0.03780306130647659\n",
      "Train size: [400] hidden size: [29] trial: 5, train_loss: 1.893967, test loss: 1.018926, bias2: 0.9804637432098389, variance: 0.03846254199743271\n",
      "Train size: [400] hidden size: [29] trial: 6, train_loss: 1.869947, test loss: 1.016691, bias2: 0.9792951941490173, variance: 0.03739601746201515\n",
      "Train size: [400] hidden size: [29] trial: 7, train_loss: 1.843420, test loss: 1.015061, bias2: 0.9773871898651123, variance: 0.03767383098602295\n",
      "Train size: [400] hidden size: [29] trial: 8, train_loss: 1.864003, test loss: 1.013244, bias2: 0.9743307828903198, variance: 0.038913238793611526\n",
      "Train size: [400] hidden size: [29] trial: 9, train_loss: 1.878649, test loss: 1.016156, bias2: 0.974324107170105, variance: 0.0418323390185833\n",
      "Train size: [400] hidden size: [29] trial: 10, train_loss: 1.876548, test loss: 1.015637, bias2: 0.9735152721405029, variance: 0.042121272534132004\n",
      "Train size: [400] hidden size: [29] trial: 11, train_loss: 1.864312, test loss: 1.017874, bias2: 0.9725471138954163, variance: 0.04532640054821968\n",
      "Train size: [400] hidden size: [29] trial: 12, train_loss: 1.841921, test loss: 1.015176, bias2: 0.9673401117324829, variance: 0.047835856676101685\n",
      "Train size: [400] hidden size: [29] trial: 13, train_loss: 1.833083, test loss: 1.014721, bias2: 0.9669044613838196, variance: 0.04781624302268028\n",
      "Train size: [400] hidden size: [29] trial: 14, train_loss: 1.825514, test loss: 1.014000, bias2: 0.9652700424194336, variance: 0.0487295500934124\n",
      "Train size: [400] hidden size: [29] trial: 15, train_loss: 1.819437, test loss: 1.013890, bias2: 0.9662095308303833, variance: 0.04768059775233269\n",
      "Train size: [400] hidden size: [29] trial: 16, train_loss: 1.820722, test loss: 1.013592, bias2: 0.9644140005111694, variance: 0.04917774721980095\n",
      "Train size: [400] hidden size: [29] trial: 17, train_loss: 1.820482, test loss: 1.015034, bias2: 0.9666104316711426, variance: 0.04842326417565346\n",
      "Train size: [400] hidden size: [29] trial: 18, train_loss: 1.840376, test loss: 1.014805, bias2: 0.9658986330032349, variance: 0.04890666902065277\n",
      "Train size: [400] hidden size: [29] trial: 19, train_loss: 1.843185, test loss: 1.015054, bias2: 0.9664188027381897, variance: 0.04863494634628296\n",
      "Train size: [400] hidden size: [29] trial: 20, train_loss: 1.839260, test loss: 1.013770, bias2: 0.9649029970169067, variance: 0.04886708781123161\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [29] trial: 21, train_loss: 1.827740, test loss: 1.013422, bias2: 0.9646201133728027, variance: 0.04880204796791077\n",
      "Train size: [400] hidden size: [29] trial: 22, train_loss: 1.834396, test loss: 1.012889, bias2: 0.9634888172149658, variance: 0.04940047487616539\n",
      "Train size: [400] hidden size: [29] trial: 23, train_loss: 1.833232, test loss: 1.012713, bias2: 0.9633563756942749, variance: 0.04935609549283981\n",
      "Train size: [400] hidden size: [29] trial: 24, train_loss: 1.829208, test loss: 1.012662, bias2: 0.9637618064880371, variance: 0.048900507390499115\n",
      "Train size: [400] hidden size: [29] trial: 25, train_loss: 1.841411, test loss: 1.013501, bias2: 0.9624866247177124, variance: 0.05101456493139267\n",
      "Train size: [400] hidden size: [29] trial: 26, train_loss: 1.841932, test loss: 1.013186, bias2: 0.9629233479499817, variance: 0.05026241019368172\n",
      "Train size: [400] hidden size: [29] trial: 27, train_loss: 1.842639, test loss: 1.012589, bias2: 0.9628899097442627, variance: 0.049698565155267715\n",
      "Train size: [400] hidden size: [29] trial: 28, train_loss: 1.840931, test loss: 1.012163, bias2: 0.9613601565361023, variance: 0.050802506506443024\n",
      "Train size: [400] hidden size: [29] trial: 29, train_loss: 1.846585, test loss: 1.011160, bias2: 0.9603772163391113, variance: 0.05078256130218506\n",
      "Train size: [400] hidden size: [29] trial: 30, train_loss: 1.853909, test loss: 1.010913, bias2: 0.960169792175293, variance: 0.05074286833405495\n",
      "Train size: [400] hidden size: [29] trial: 31, train_loss: 1.853264, test loss: 1.010434, bias2: 0.9601122140884399, variance: 0.05032191798090935\n",
      "Train size: [400] hidden size: [29] trial: 32, train_loss: 1.848385, test loss: 1.011458, bias2: 0.9610843062400818, variance: 0.05037350580096245\n",
      "Train size: [400] hidden size: [29] trial: 33, train_loss: 1.851191, test loss: 1.011057, bias2: 0.9610098600387573, variance: 0.05004727840423584\n",
      "Train size: [400] hidden size: [29] trial: 34, train_loss: 1.848206, test loss: 1.010913, bias2: 0.9606073498725891, variance: 0.05030576139688492\n",
      "Train size: [400] hidden size: [29] trial: 35, train_loss: 1.852092, test loss: 1.011474, bias2: 0.9609876871109009, variance: 0.05048597976565361\n",
      "Train size: [400] hidden size: [29] trial: 36, train_loss: 1.849056, test loss: 1.011548, bias2: 0.9609614610671997, variance: 0.05058659240603447\n",
      "Train size: [400] hidden size: [29] trial: 37, train_loss: 1.845303, test loss: 1.011776, bias2: 0.9614548683166504, variance: 0.050320882350206375\n",
      "Train size: [400] hidden size: [29] trial: 38, train_loss: 1.846933, test loss: 1.011921, bias2: 0.9615594148635864, variance: 0.050362005829811096\n",
      "Train size: [400] hidden size: [29] trial: 39, train_loss: 1.849037, test loss: 1.011738, bias2: 0.9613240957260132, variance: 0.050413839519023895\n",
      "Train size: [400] hidden size: [29] trial: 40, train_loss: 1.848092, test loss: 1.011613, bias2: 0.9611542224884033, variance: 0.050459131598472595\n",
      "Train size: [400] hidden size: [29] trial: 41, train_loss: 1.850537, test loss: 1.011548, bias2: 0.9608095288276672, variance: 0.050738509744405746\n",
      "Train size: [400] hidden size: [29] trial: 42, train_loss: 1.847714, test loss: 1.010808, bias2: 0.9600477814674377, variance: 0.050760675221681595\n",
      "Train size: [400] hidden size: [29] trial: 43, train_loss: 1.845084, test loss: 1.010921, bias2: 0.9605175256729126, variance: 0.05040359869599342\n",
      "Train size: [400] hidden size: [29] trial: 44, train_loss: 1.843053, test loss: 1.010932, bias2: 0.9607524871826172, variance: 0.05017995834350586\n",
      "Train size: [400] hidden size: [29] trial: 45, train_loss: 1.844625, test loss: 1.011086, bias2: 0.9610114097595215, variance: 0.05007435381412506\n",
      "Train size: [400] hidden size: [29] trial: 46, train_loss: 1.843808, test loss: 1.010162, bias2: 0.9598538875579834, variance: 0.050307877361774445\n",
      "Train size: [400] hidden size: [29] trial: 47, train_loss: 1.849968, test loss: 1.010039, bias2: 0.9591079950332642, variance: 0.05093144252896309\n",
      "Train size: [400] hidden size: [29] trial: 48, train_loss: 1.849477, test loss: 1.009597, bias2: 0.9586742520332336, variance: 0.05092279985547066\n",
      "Train size: [400] hidden size: [29] trial: 49, train_loss: 1.846376, test loss: 1.009677, bias2: 0.9585919380187988, variance: 0.051085203886032104\n",
      "##################################################\n",
      "Train size: [400] hidden size: [33] trial: 0, train_loss: 1.742124, test loss: 1.027351, bias2: 1.0273512601852417, variance: -3.8925479506346505e-10\n",
      "Train size: [400] hidden size: [33] trial: 1, train_loss: 1.772639, test loss: 1.002679, bias2: 0.9738456606864929, variance: 0.028832845389842987\n",
      "Train size: [400] hidden size: [33] trial: 2, train_loss: 1.825034, test loss: 0.998181, bias2: 0.9612839818000793, variance: 0.036897215992212296\n",
      "Train size: [400] hidden size: [33] trial: 3, train_loss: 1.864780, test loss: 1.001271, bias2: 0.9593818783760071, variance: 0.04188887029886246\n",
      "Train size: [400] hidden size: [33] trial: 4, train_loss: 1.864377, test loss: 1.002541, bias2: 0.9579727649688721, variance: 0.04456828534603119\n",
      "Train size: [400] hidden size: [33] trial: 5, train_loss: 1.847070, test loss: 1.005917, bias2: 0.9595752954483032, variance: 0.04634202644228935\n",
      "Train size: [400] hidden size: [33] trial: 6, train_loss: 1.841196, test loss: 0.998642, bias2: 0.9511005282402039, variance: 0.04754191264510155\n",
      "Train size: [400] hidden size: [33] trial: 7, train_loss: 1.849346, test loss: 0.998052, bias2: 0.9452065825462341, variance: 0.05284577235579491\n",
      "Train size: [400] hidden size: [33] trial: 8, train_loss: 1.847939, test loss: 1.000759, bias2: 0.9495230317115784, variance: 0.05123559758067131\n",
      "Train size: [400] hidden size: [33] trial: 9, train_loss: 1.853577, test loss: 1.002622, bias2: 0.9521043300628662, variance: 0.050517816096544266\n",
      "Train size: [400] hidden size: [33] trial: 10, train_loss: 1.861259, test loss: 1.003655, bias2: 0.9540259838104248, variance: 0.0496290922164917\n",
      "Train size: [400] hidden size: [33] trial: 11, train_loss: 1.856831, test loss: 1.002238, bias2: 0.9521867036819458, variance: 0.05005158111453056\n",
      "Train size: [400] hidden size: [33] trial: 12, train_loss: 1.856901, test loss: 1.004080, bias2: 0.952957272529602, variance: 0.05112241953611374\n",
      "Train size: [400] hidden size: [33] trial: 13, train_loss: 1.857608, test loss: 1.003372, bias2: 0.9508922696113586, variance: 0.05247943103313446\n",
      "Train size: [400] hidden size: [33] trial: 14, train_loss: 1.874645, test loss: 1.003935, bias2: 0.9520553350448608, variance: 0.05188009887933731\n",
      "Train size: [400] hidden size: [33] trial: 15, train_loss: 1.878441, test loss: 1.003492, bias2: 0.9514420628547668, variance: 0.052050068974494934\n",
      "Train size: [400] hidden size: [33] trial: 16, train_loss: 1.871023, test loss: 1.004991, bias2: 0.9531850814819336, variance: 0.05180621147155762\n",
      "Train size: [400] hidden size: [33] trial: 17, train_loss: 1.865000, test loss: 1.005187, bias2: 0.9516947269439697, variance: 0.053492315113544464\n",
      "Train size: [400] hidden size: [33] trial: 18, train_loss: 1.879464, test loss: 1.006827, bias2: 0.9526829719543457, variance: 0.05414401739835739\n",
      "Train size: [400] hidden size: [33] trial: 19, train_loss: 1.883127, test loss: 1.006543, bias2: 0.9523736238479614, variance: 0.0541694350540638\n",
      "Train size: [400] hidden size: [33] trial: 20, train_loss: 1.876617, test loss: 1.006532, bias2: 0.9523140788078308, variance: 0.054218094795942307\n",
      "Train size: [400] hidden size: [33] trial: 21, train_loss: 1.877132, test loss: 1.006161, bias2: 0.9521524310112, variance: 0.054009001702070236\n",
      "Train size: [400] hidden size: [33] trial: 22, train_loss: 1.871945, test loss: 1.006600, bias2: 0.9525451064109802, variance: 0.05405453220009804\n",
      "Train size: [400] hidden size: [33] trial: 23, train_loss: 1.868649, test loss: 1.006942, bias2: 0.9530364274978638, variance: 0.05390559881925583\n",
      "Train size: [400] hidden size: [33] trial: 24, train_loss: 1.870445, test loss: 1.007834, bias2: 0.954521656036377, variance: 0.05331195145845413\n",
      "Train size: [400] hidden size: [33] trial: 25, train_loss: 1.880125, test loss: 1.008425, bias2: 0.9551544785499573, variance: 0.053270138800144196\n",
      "Train size: [400] hidden size: [33] trial: 26, train_loss: 1.882684, test loss: 1.008620, bias2: 0.9557207822799683, variance: 0.05289886146783829\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [33] trial: 27, train_loss: 1.875269, test loss: 1.008053, bias2: 0.9549928903579712, variance: 0.053060293197631836\n",
      "Train size: [400] hidden size: [33] trial: 28, train_loss: 1.870882, test loss: 1.009139, bias2: 0.9558483362197876, variance: 0.05329051613807678\n",
      "Train size: [400] hidden size: [33] trial: 29, train_loss: 1.862975, test loss: 1.008297, bias2: 0.955391526222229, variance: 0.05290517956018448\n",
      "Train size: [400] hidden size: [33] trial: 30, train_loss: 1.867737, test loss: 1.007877, bias2: 0.9539913535118103, variance: 0.05388597771525383\n",
      "Train size: [400] hidden size: [33] trial: 31, train_loss: 1.862389, test loss: 1.008099, bias2: 0.9540237188339233, variance: 0.054075345396995544\n",
      "Train size: [400] hidden size: [33] trial: 32, train_loss: 1.855874, test loss: 1.008392, bias2: 0.9544582962989807, variance: 0.05393379554152489\n",
      "Train size: [400] hidden size: [33] trial: 33, train_loss: 1.858951, test loss: 1.007075, bias2: 0.9533388018608093, variance: 0.05373615026473999\n",
      "Train size: [400] hidden size: [33] trial: 34, train_loss: 1.850507, test loss: 1.007608, bias2: 0.9544479250907898, variance: 0.053159769624471664\n",
      "Train size: [400] hidden size: [33] trial: 35, train_loss: 1.850573, test loss: 1.008167, bias2: 0.9555895924568176, variance: 0.05257752910256386\n",
      "Train size: [400] hidden size: [33] trial: 36, train_loss: 1.851199, test loss: 1.008616, bias2: 0.9557443261146545, variance: 0.05287166312336922\n",
      "Train size: [400] hidden size: [33] trial: 37, train_loss: 1.850356, test loss: 1.009495, bias2: 0.956222653388977, variance: 0.053272247314453125\n",
      "Train size: [400] hidden size: [33] trial: 38, train_loss: 1.853555, test loss: 1.008902, bias2: 0.9556373357772827, variance: 0.053264617919921875\n",
      "Train size: [400] hidden size: [33] trial: 39, train_loss: 1.854468, test loss: 1.008961, bias2: 0.955401599407196, variance: 0.05355912074446678\n",
      "Train size: [400] hidden size: [33] trial: 40, train_loss: 1.853670, test loss: 1.008578, bias2: 0.9548563957214355, variance: 0.05372118949890137\n",
      "Train size: [400] hidden size: [33] trial: 41, train_loss: 1.858812, test loss: 1.008187, bias2: 0.9545935392379761, variance: 0.05359341576695442\n",
      "Train size: [400] hidden size: [33] trial: 42, train_loss: 1.856258, test loss: 1.007868, bias2: 0.9544961452484131, variance: 0.053371530026197433\n",
      "Train size: [400] hidden size: [33] trial: 43, train_loss: 1.857533, test loss: 1.008135, bias2: 0.9551292061805725, variance: 0.05300566181540489\n",
      "Train size: [400] hidden size: [33] trial: 44, train_loss: 1.858235, test loss: 1.008536, bias2: 0.9557541012763977, variance: 0.05278162285685539\n",
      "Train size: [400] hidden size: [33] trial: 45, train_loss: 1.857454, test loss: 1.008818, bias2: 0.9560011625289917, variance: 0.05281662195920944\n",
      "Train size: [400] hidden size: [33] trial: 46, train_loss: 1.860462, test loss: 1.008564, bias2: 0.9554920196533203, variance: 0.053072456270456314\n",
      "Train size: [400] hidden size: [33] trial: 47, train_loss: 1.860591, test loss: 1.007922, bias2: 0.9547586441040039, variance: 0.05316302925348282\n",
      "Train size: [400] hidden size: [33] trial: 48, train_loss: 1.859834, test loss: 1.007712, bias2: 0.9542955160140991, variance: 0.05341695249080658\n",
      "Train size: [400] hidden size: [33] trial: 49, train_loss: 1.858649, test loss: 1.007879, bias2: 0.9547103047370911, variance: 0.05316917598247528\n",
      "##################################################\n",
      "Train size: [400] hidden size: [38] trial: 0, train_loss: 1.856905, test loss: 0.999603, bias2: 0.9996033906936646, variance: 2.919411101753866e-10\n",
      "Train size: [400] hidden size: [38] trial: 1, train_loss: 1.784513, test loss: 1.018689, bias2: 0.9804980754852295, variance: 0.03819097951054573\n",
      "Train size: [400] hidden size: [38] trial: 2, train_loss: 1.780437, test loss: 1.029461, bias2: 0.9813223481178284, variance: 0.0481390617787838\n",
      "Train size: [400] hidden size: [38] trial: 3, train_loss: 1.831472, test loss: 1.022527, bias2: 0.963641881942749, variance: 0.05888543650507927\n",
      "Train size: [400] hidden size: [38] trial: 4, train_loss: 1.851271, test loss: 1.022727, bias2: 0.9612606763839722, variance: 0.061466000974178314\n",
      "Train size: [400] hidden size: [38] trial: 5, train_loss: 1.877924, test loss: 1.016160, bias2: 0.9534604549407959, variance: 0.0626993179321289\n",
      "Train size: [400] hidden size: [38] trial: 6, train_loss: 1.858072, test loss: 1.019928, bias2: 0.9556407332420349, variance: 0.06428688019514084\n",
      "Train size: [400] hidden size: [38] trial: 7, train_loss: 1.838434, test loss: 1.018876, bias2: 0.9578595757484436, variance: 0.06101623550057411\n",
      "Train size: [400] hidden size: [38] trial: 8, train_loss: 1.845199, test loss: 1.016855, bias2: 0.9513696432113647, variance: 0.06548548489809036\n",
      "Train size: [400] hidden size: [38] trial: 9, train_loss: 1.846658, test loss: 1.015165, bias2: 0.9487184286117554, variance: 0.06644703447818756\n",
      "Train size: [400] hidden size: [38] trial: 10, train_loss: 1.838567, test loss: 1.014436, bias2: 0.9494264721870422, variance: 0.06500966101884842\n",
      "Train size: [400] hidden size: [38] trial: 11, train_loss: 1.823564, test loss: 1.010762, bias2: 0.9448100924491882, variance: 0.06595154851675034\n",
      "Train size: [400] hidden size: [38] trial: 12, train_loss: 1.840045, test loss: 1.010772, bias2: 0.9428711533546448, variance: 0.06790108233690262\n",
      "Train size: [400] hidden size: [38] trial: 13, train_loss: 1.848570, test loss: 1.010585, bias2: 0.9420633316040039, variance: 0.0685218796133995\n",
      "Train size: [400] hidden size: [38] trial: 14, train_loss: 1.842376, test loss: 1.008480, bias2: 0.9404677748680115, variance: 0.06801207363605499\n",
      "Train size: [400] hidden size: [38] trial: 15, train_loss: 1.839942, test loss: 1.008317, bias2: 0.9403776526451111, variance: 0.06793934851884842\n",
      "Train size: [400] hidden size: [38] trial: 16, train_loss: 1.845437, test loss: 1.008057, bias2: 0.941952645778656, variance: 0.06610459834337234\n",
      "Train size: [400] hidden size: [38] trial: 17, train_loss: 1.835237, test loss: 1.009352, bias2: 0.9435848593711853, variance: 0.06576748192310333\n",
      "Train size: [400] hidden size: [38] trial: 18, train_loss: 1.831867, test loss: 1.008776, bias2: 0.9439734816551208, variance: 0.06480198353528976\n",
      "Train size: [400] hidden size: [38] trial: 19, train_loss: 1.842795, test loss: 1.007370, bias2: 0.942851722240448, variance: 0.06451839208602905\n",
      "Train size: [400] hidden size: [38] trial: 20, train_loss: 1.842089, test loss: 1.007041, bias2: 0.9423629641532898, variance: 0.06467799842357635\n",
      "Train size: [400] hidden size: [38] trial: 21, train_loss: 1.836937, test loss: 1.005961, bias2: 0.9406059980392456, variance: 0.0653546005487442\n",
      "Train size: [400] hidden size: [38] trial: 22, train_loss: 1.832304, test loss: 1.004312, bias2: 0.9384432435035706, variance: 0.0658683106303215\n",
      "Train size: [400] hidden size: [38] trial: 23, train_loss: 1.840492, test loss: 1.003954, bias2: 0.9386702179908752, variance: 0.06528335809707642\n",
      "Train size: [400] hidden size: [38] trial: 24, train_loss: 1.835942, test loss: 1.003565, bias2: 0.9374099373817444, variance: 0.06615535169839859\n",
      "Train size: [400] hidden size: [38] trial: 25, train_loss: 1.834213, test loss: 1.003695, bias2: 0.935897171497345, variance: 0.0677977129817009\n",
      "Train size: [400] hidden size: [38] trial: 26, train_loss: 1.838606, test loss: 1.003891, bias2: 0.9366981983184814, variance: 0.0671929195523262\n",
      "Train size: [400] hidden size: [38] trial: 27, train_loss: 1.834382, test loss: 1.005076, bias2: 0.9377197623252869, variance: 0.067356176674366\n",
      "Train size: [400] hidden size: [38] trial: 28, train_loss: 1.836032, test loss: 1.004721, bias2: 0.9378814697265625, variance: 0.06683918833732605\n",
      "Train size: [400] hidden size: [38] trial: 29, train_loss: 1.833009, test loss: 1.005247, bias2: 0.9392336010932922, variance: 0.06601304560899734\n",
      "Train size: [400] hidden size: [38] trial: 30, train_loss: 1.830341, test loss: 1.004785, bias2: 0.9388887882232666, variance: 0.06589590758085251\n",
      "Train size: [400] hidden size: [38] trial: 31, train_loss: 1.832258, test loss: 1.005649, bias2: 0.9395694732666016, variance: 0.06607913970947266\n",
      "Train size: [400] hidden size: [38] trial: 32, train_loss: 1.835527, test loss: 1.006956, bias2: 0.9408941268920898, variance: 0.06606210768222809\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [38] trial: 33, train_loss: 1.836823, test loss: 1.007122, bias2: 0.941176176071167, variance: 0.06594637036323547\n",
      "Train size: [400] hidden size: [38] trial: 34, train_loss: 1.829486, test loss: 1.007356, bias2: 0.942315936088562, variance: 0.06504037976264954\n",
      "Train size: [400] hidden size: [38] trial: 35, train_loss: 1.835192, test loss: 1.007307, bias2: 0.9422645568847656, variance: 0.06504286825656891\n",
      "Train size: [400] hidden size: [38] trial: 36, train_loss: 1.829972, test loss: 1.007174, bias2: 0.9424931406974792, variance: 0.06468101590871811\n",
      "Train size: [400] hidden size: [38] trial: 37, train_loss: 1.832443, test loss: 1.006813, bias2: 0.9418641924858093, variance: 0.06494911015033722\n",
      "Train size: [400] hidden size: [38] trial: 38, train_loss: 1.837194, test loss: 1.007437, bias2: 0.9419472217559814, variance: 0.06548966467380524\n",
      "Train size: [400] hidden size: [38] trial: 39, train_loss: 1.837539, test loss: 1.007529, bias2: 0.9421738982200623, variance: 0.06535474210977554\n",
      "Train size: [400] hidden size: [38] trial: 40, train_loss: 1.839915, test loss: 1.007301, bias2: 0.9422691464424133, variance: 0.06503216922283173\n",
      "Train size: [400] hidden size: [38] trial: 41, train_loss: 1.837531, test loss: 1.008303, bias2: 0.9428535103797913, variance: 0.06544988602399826\n",
      "Train size: [400] hidden size: [38] trial: 42, train_loss: 1.841244, test loss: 1.008971, bias2: 0.9440572261810303, variance: 0.06491401046514511\n",
      "Train size: [400] hidden size: [38] trial: 43, train_loss: 1.836315, test loss: 1.008342, bias2: 0.9436830878257751, variance: 0.06465870141983032\n",
      "Train size: [400] hidden size: [38] trial: 44, train_loss: 1.840045, test loss: 1.008477, bias2: 0.9438745975494385, variance: 0.06460260599851608\n",
      "Train size: [400] hidden size: [38] trial: 45, train_loss: 1.840076, test loss: 1.008552, bias2: 0.9441348910331726, variance: 0.06441668421030045\n",
      "Train size: [400] hidden size: [38] trial: 46, train_loss: 1.836799, test loss: 1.008752, bias2: 0.9439424872398376, variance: 0.06480949372053146\n",
      "Train size: [400] hidden size: [38] trial: 47, train_loss: 1.838753, test loss: 1.008250, bias2: 0.943535327911377, variance: 0.06471454352140427\n",
      "Train size: [400] hidden size: [38] trial: 48, train_loss: 1.832403, test loss: 1.008129, bias2: 0.9431596994400024, variance: 0.06496880948543549\n",
      "Train size: [400] hidden size: [38] trial: 49, train_loss: 1.833099, test loss: 1.008369, bias2: 0.9434667825698853, variance: 0.06490245461463928\n",
      "##################################################\n",
      "Train size: [400] hidden size: [44] trial: 0, train_loss: 1.749871, test loss: 1.030022, bias2: 1.0300216674804688, variance: 4.379116513852921e-10\n",
      "Train size: [400] hidden size: [44] trial: 1, train_loss: 1.717359, test loss: 1.032423, bias2: 0.9934061765670776, variance: 0.03901706263422966\n",
      "Train size: [400] hidden size: [44] trial: 2, train_loss: 1.743200, test loss: 1.021034, bias2: 0.9677098989486694, variance: 0.0533238910138607\n",
      "Train size: [400] hidden size: [44] trial: 3, train_loss: 1.737087, test loss: 1.018781, bias2: 0.9661093950271606, variance: 0.05267120897769928\n",
      "Train size: [400] hidden size: [44] trial: 4, train_loss: 1.747804, test loss: 1.013267, bias2: 0.9547424912452698, variance: 0.05852432921528816\n",
      "Train size: [400] hidden size: [44] trial: 5, train_loss: 1.775109, test loss: 1.005987, bias2: 0.9449142813682556, variance: 0.061072543263435364\n",
      "Train size: [400] hidden size: [44] trial: 6, train_loss: 1.753228, test loss: 1.008691, bias2: 0.947869062423706, variance: 0.06082199513912201\n",
      "Train size: [400] hidden size: [44] trial: 7, train_loss: 1.764981, test loss: 1.008718, bias2: 0.9425867795944214, variance: 0.06613174080848694\n",
      "Train size: [400] hidden size: [44] trial: 8, train_loss: 1.753692, test loss: 1.008691, bias2: 0.943912923336029, variance: 0.06477754563093185\n",
      "Train size: [400] hidden size: [44] trial: 9, train_loss: 1.743785, test loss: 1.007296, bias2: 0.9431605339050293, variance: 0.06413521617650986\n",
      "Train size: [400] hidden size: [44] trial: 10, train_loss: 1.752902, test loss: 1.009027, bias2: 0.9432004690170288, variance: 0.06582699716091156\n",
      "Train size: [400] hidden size: [44] trial: 11, train_loss: 1.755248, test loss: 1.011924, bias2: 0.9446059465408325, variance: 0.06731843948364258\n",
      "Train size: [400] hidden size: [44] trial: 12, train_loss: 1.762263, test loss: 1.010002, bias2: 0.9413403272628784, variance: 0.06866194307804108\n",
      "Train size: [400] hidden size: [44] trial: 13, train_loss: 1.770151, test loss: 1.012533, bias2: 0.9441940188407898, variance: 0.068339042365551\n",
      "Train size: [400] hidden size: [44] trial: 14, train_loss: 1.776775, test loss: 1.010798, bias2: 0.9415978789329529, variance: 0.06919984519481659\n",
      "Train size: [400] hidden size: [44] trial: 15, train_loss: 1.791566, test loss: 1.014111, bias2: 0.9451666474342346, variance: 0.06894451379776001\n",
      "Train size: [400] hidden size: [44] trial: 16, train_loss: 1.792322, test loss: 1.013641, bias2: 0.9463592171669006, variance: 0.0672813281416893\n",
      "Train size: [400] hidden size: [44] trial: 17, train_loss: 1.804786, test loss: 1.013640, bias2: 0.9456135034561157, variance: 0.06802690029144287\n",
      "Train size: [400] hidden size: [44] trial: 18, train_loss: 1.798193, test loss: 1.012829, bias2: 0.9459944367408752, variance: 0.06683412939310074\n",
      "Train size: [400] hidden size: [44] trial: 19, train_loss: 1.785584, test loss: 1.013373, bias2: 0.9468701481819153, variance: 0.06650274991989136\n",
      "Train size: [400] hidden size: [44] trial: 20, train_loss: 1.788922, test loss: 1.013699, bias2: 0.94720858335495, variance: 0.06649072468280792\n",
      "Train size: [400] hidden size: [44] trial: 21, train_loss: 1.795665, test loss: 1.013908, bias2: 0.9474755525588989, variance: 0.06643233448266983\n",
      "Train size: [400] hidden size: [44] trial: 22, train_loss: 1.795813, test loss: 1.013313, bias2: 0.946191668510437, variance: 0.06712135672569275\n",
      "Train size: [400] hidden size: [44] trial: 23, train_loss: 1.790356, test loss: 1.014689, bias2: 0.9465809464454651, variance: 0.06810768693685532\n",
      "Train size: [400] hidden size: [44] trial: 24, train_loss: 1.789931, test loss: 1.014875, bias2: 0.9451687335968018, variance: 0.06970617920160294\n",
      "Train size: [400] hidden size: [44] trial: 25, train_loss: 1.800678, test loss: 1.015180, bias2: 0.9444112777709961, variance: 0.07076861709356308\n",
      "Train size: [400] hidden size: [44] trial: 26, train_loss: 1.800175, test loss: 1.015509, bias2: 0.9439896941184998, variance: 0.07151883095502853\n",
      "Train size: [400] hidden size: [44] trial: 27, train_loss: 1.801703, test loss: 1.014819, bias2: 0.9432567954063416, variance: 0.07156259566545486\n",
      "Train size: [400] hidden size: [44] trial: 28, train_loss: 1.803416, test loss: 1.015150, bias2: 0.9431516528129578, variance: 0.07199852913618088\n",
      "Train size: [400] hidden size: [44] trial: 29, train_loss: 1.802520, test loss: 1.015128, bias2: 0.9435061812400818, variance: 0.07162181288003922\n",
      "Train size: [400] hidden size: [44] trial: 30, train_loss: 1.802981, test loss: 1.015870, bias2: 0.9444615840911865, variance: 0.07140814512968063\n",
      "Train size: [400] hidden size: [44] trial: 31, train_loss: 1.802584, test loss: 1.016410, bias2: 0.9449433088302612, variance: 0.07146701961755753\n",
      "Train size: [400] hidden size: [44] trial: 32, train_loss: 1.801127, test loss: 1.015887, bias2: 0.9446308016777039, variance: 0.07125632464885712\n",
      "Train size: [400] hidden size: [44] trial: 33, train_loss: 1.809658, test loss: 1.015677, bias2: 0.9442182183265686, variance: 0.07145849615335464\n",
      "Train size: [400] hidden size: [44] trial: 34, train_loss: 1.811405, test loss: 1.015841, bias2: 0.9435902833938599, variance: 0.07225062698125839\n",
      "Train size: [400] hidden size: [44] trial: 35, train_loss: 1.811600, test loss: 1.015973, bias2: 0.9441119432449341, variance: 0.07186105847358704\n",
      "Train size: [400] hidden size: [44] trial: 36, train_loss: 1.813087, test loss: 1.016526, bias2: 0.9446348547935486, variance: 0.07189087569713593\n",
      "Train size: [400] hidden size: [44] trial: 37, train_loss: 1.821287, test loss: 1.017197, bias2: 0.9447698593139648, variance: 0.07242678850889206\n",
      "Train size: [400] hidden size: [44] trial: 38, train_loss: 1.813814, test loss: 1.017199, bias2: 0.94559246301651, variance: 0.07160619646310806\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [44] trial: 39, train_loss: 1.814492, test loss: 1.017226, bias2: 0.9441931247711182, variance: 0.07303334772586823\n",
      "Train size: [400] hidden size: [44] trial: 40, train_loss: 1.813718, test loss: 1.018243, bias2: 0.9449365139007568, variance: 0.07330606132745743\n",
      "Train size: [400] hidden size: [44] trial: 41, train_loss: 1.810339, test loss: 1.017494, bias2: 0.9442223906517029, variance: 0.07327144593000412\n",
      "Train size: [400] hidden size: [44] trial: 42, train_loss: 1.807527, test loss: 1.016935, bias2: 0.9435899257659912, variance: 0.07334461808204651\n",
      "Train size: [400] hidden size: [44] trial: 43, train_loss: 1.806724, test loss: 1.017658, bias2: 0.9445546865463257, variance: 0.07310378551483154\n",
      "Train size: [400] hidden size: [44] trial: 44, train_loss: 1.803877, test loss: 1.017055, bias2: 0.9443190097808838, variance: 0.07273567467927933\n",
      "Train size: [400] hidden size: [44] trial: 45, train_loss: 1.803531, test loss: 1.016379, bias2: 0.9434471726417542, variance: 0.07293171435594559\n",
      "Train size: [400] hidden size: [44] trial: 46, train_loss: 1.801114, test loss: 1.016163, bias2: 0.9430606961250305, variance: 0.07310251146554947\n",
      "Train size: [400] hidden size: [44] trial: 47, train_loss: 1.802464, test loss: 1.016351, bias2: 0.943234920501709, variance: 0.07311604917049408\n",
      "Train size: [400] hidden size: [44] trial: 48, train_loss: 1.801866, test loss: 1.016225, bias2: 0.9427478313446045, variance: 0.07347670197486877\n",
      "Train size: [400] hidden size: [44] trial: 49, train_loss: 1.802840, test loss: 1.015947, bias2: 0.9428139925003052, variance: 0.07313331961631775\n",
      "##################################################\n",
      "Train size: [400] hidden size: [51] trial: 0, train_loss: 1.725370, test loss: 1.017167, bias2: 1.0171672105789185, variance: 5.352253640289462e-10\n",
      "Train size: [400] hidden size: [51] trial: 1, train_loss: 1.741960, test loss: 0.998039, bias2: 0.9538483619689941, variance: 0.04419071599841118\n",
      "Train size: [400] hidden size: [51] trial: 2, train_loss: 1.766710, test loss: 0.987908, bias2: 0.9307193160057068, variance: 0.05718819797039032\n",
      "Train size: [400] hidden size: [51] trial: 3, train_loss: 1.763934, test loss: 0.992584, bias2: 0.9275701642036438, variance: 0.0650133565068245\n",
      "Train size: [400] hidden size: [51] trial: 4, train_loss: 1.799677, test loss: 0.989603, bias2: 0.9202607870101929, variance: 0.06934235244989395\n",
      "Train size: [400] hidden size: [51] trial: 5, train_loss: 1.773952, test loss: 0.985145, bias2: 0.9158003330230713, variance: 0.06934505701065063\n",
      "Train size: [400] hidden size: [51] trial: 6, train_loss: 1.766128, test loss: 0.994431, bias2: 0.9252049922943115, variance: 0.06922616064548492\n",
      "Train size: [400] hidden size: [51] trial: 7, train_loss: 1.761972, test loss: 1.000838, bias2: 0.9280450344085693, variance: 0.07279334962368011\n",
      "Train size: [400] hidden size: [51] trial: 8, train_loss: 1.772876, test loss: 0.999351, bias2: 0.9238301515579224, variance: 0.0755210667848587\n",
      "Train size: [400] hidden size: [51] trial: 9, train_loss: 1.759388, test loss: 1.000127, bias2: 0.9253870248794556, variance: 0.0747404396533966\n",
      "Train size: [400] hidden size: [51] trial: 10, train_loss: 1.767966, test loss: 0.998199, bias2: 0.9216437339782715, variance: 0.07655534148216248\n",
      "Train size: [400] hidden size: [51] trial: 11, train_loss: 1.779587, test loss: 1.000561, bias2: 0.9234873056411743, variance: 0.0770733579993248\n",
      "Train size: [400] hidden size: [51] trial: 12, train_loss: 1.779368, test loss: 1.001277, bias2: 0.9245480298995972, variance: 0.0767287015914917\n",
      "Train size: [400] hidden size: [51] trial: 13, train_loss: 1.769807, test loss: 1.004324, bias2: 0.9264874458312988, variance: 0.07783673703670502\n",
      "Train size: [400] hidden size: [51] trial: 14, train_loss: 1.775015, test loss: 1.004209, bias2: 0.9263777136802673, variance: 0.07783178240060806\n",
      "Train size: [400] hidden size: [51] trial: 15, train_loss: 1.767769, test loss: 1.004106, bias2: 0.9241343140602112, variance: 0.07997173070907593\n",
      "Train size: [400] hidden size: [51] trial: 16, train_loss: 1.772921, test loss: 1.003428, bias2: 0.9216314554214478, variance: 0.08179605007171631\n",
      "Train size: [400] hidden size: [51] trial: 17, train_loss: 1.781755, test loss: 1.006839, bias2: 0.9243411421775818, variance: 0.08249767124652863\n",
      "Train size: [400] hidden size: [51] trial: 18, train_loss: 1.785779, test loss: 1.006533, bias2: 0.924492597579956, variance: 0.08204076439142227\n",
      "Train size: [400] hidden size: [51] trial: 19, train_loss: 1.786780, test loss: 1.006369, bias2: 0.9221413731575012, variance: 0.08422715216875076\n",
      "Train size: [400] hidden size: [51] trial: 20, train_loss: 1.777193, test loss: 1.006805, bias2: 0.923222541809082, variance: 0.08358278125524521\n",
      "Train size: [400] hidden size: [51] trial: 21, train_loss: 1.774840, test loss: 1.006426, bias2: 0.9220982193946838, variance: 0.08432810753583908\n",
      "Train size: [400] hidden size: [51] trial: 22, train_loss: 1.780435, test loss: 1.006873, bias2: 0.9222951531410217, variance: 0.08457810431718826\n",
      "Train size: [400] hidden size: [51] trial: 23, train_loss: 1.779068, test loss: 1.005695, bias2: 0.9197010397911072, variance: 0.08599357306957245\n",
      "Train size: [400] hidden size: [51] trial: 24, train_loss: 1.785274, test loss: 1.004139, bias2: 0.9184545874595642, variance: 0.08568447083234787\n",
      "Train size: [400] hidden size: [51] trial: 25, train_loss: 1.782192, test loss: 1.004421, bias2: 0.9188396334648132, variance: 0.08558160066604614\n",
      "Train size: [400] hidden size: [51] trial: 26, train_loss: 1.785256, test loss: 1.004786, bias2: 0.9195348024368286, variance: 0.0852515920996666\n",
      "Train size: [400] hidden size: [51] trial: 27, train_loss: 1.785089, test loss: 1.005525, bias2: 0.9198117256164551, variance: 0.08571317046880722\n",
      "Train size: [400] hidden size: [51] trial: 28, train_loss: 1.786219, test loss: 1.005765, bias2: 0.919752836227417, variance: 0.08601177483797073\n",
      "Train size: [400] hidden size: [51] trial: 29, train_loss: 1.783624, test loss: 1.006704, bias2: 0.9200588464736938, variance: 0.08664550632238388\n",
      "Train size: [400] hidden size: [51] trial: 30, train_loss: 1.785872, test loss: 1.006343, bias2: 0.9188874363899231, variance: 0.08745511621236801\n",
      "Train size: [400] hidden size: [51] trial: 31, train_loss: 1.785947, test loss: 1.005767, bias2: 0.9182690382003784, variance: 0.08749820291996002\n",
      "Train size: [400] hidden size: [51] trial: 32, train_loss: 1.777303, test loss: 1.005536, bias2: 0.919051468372345, variance: 0.08648437261581421\n",
      "Train size: [400] hidden size: [51] trial: 33, train_loss: 1.776796, test loss: 1.006059, bias2: 0.9199074506759644, variance: 0.08615123480558395\n",
      "Train size: [400] hidden size: [51] trial: 34, train_loss: 1.775864, test loss: 1.005628, bias2: 0.9201582074165344, variance: 0.08547025918960571\n",
      "Train size: [400] hidden size: [51] trial: 35, train_loss: 1.772719, test loss: 1.005759, bias2: 0.9202099442481995, variance: 0.08554906398057938\n",
      "Train size: [400] hidden size: [51] trial: 36, train_loss: 1.769717, test loss: 1.005234, bias2: 0.9189680218696594, variance: 0.08626587688922882\n",
      "Train size: [400] hidden size: [51] trial: 37, train_loss: 1.768071, test loss: 1.005238, bias2: 0.9193132519721985, variance: 0.08592456579208374\n",
      "Train size: [400] hidden size: [51] trial: 38, train_loss: 1.766402, test loss: 1.005794, bias2: 0.920295238494873, variance: 0.08549906313419342\n",
      "Train size: [400] hidden size: [51] trial: 39, train_loss: 1.770356, test loss: 1.005859, bias2: 0.9209927916526794, variance: 0.08486644178628922\n",
      "Train size: [400] hidden size: [51] trial: 40, train_loss: 1.767230, test loss: 1.006383, bias2: 0.921400785446167, variance: 0.0849824845790863\n",
      "Train size: [400] hidden size: [51] trial: 41, train_loss: 1.768951, test loss: 1.006232, bias2: 0.9213863611221313, variance: 0.08484590798616409\n",
      "Train size: [400] hidden size: [51] trial: 42, train_loss: 1.765936, test loss: 1.005688, bias2: 0.9211005568504333, variance: 0.08458741754293442\n",
      "Train size: [400] hidden size: [51] trial: 43, train_loss: 1.759870, test loss: 1.005268, bias2: 0.9195324778556824, variance: 0.08573539555072784\n",
      "Train size: [400] hidden size: [51] trial: 44, train_loss: 1.759629, test loss: 1.005357, bias2: 0.9195507764816284, variance: 0.08580662310123444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [51] trial: 45, train_loss: 1.757660, test loss: 1.006175, bias2: 0.9201167225837708, variance: 0.08605817705392838\n",
      "Train size: [400] hidden size: [51] trial: 46, train_loss: 1.758909, test loss: 1.006217, bias2: 0.9203584790229797, variance: 0.08585898578166962\n",
      "Train size: [400] hidden size: [51] trial: 47, train_loss: 1.755148, test loss: 1.006675, bias2: 0.9208213686943054, variance: 0.08585376292467117\n",
      "Train size: [400] hidden size: [51] trial: 48, train_loss: 1.753689, test loss: 1.007687, bias2: 0.9216073751449585, variance: 0.08607926219701767\n",
      "Train size: [400] hidden size: [51] trial: 49, train_loss: 1.754076, test loss: 1.007696, bias2: 0.9217378497123718, variance: 0.08595866709947586\n",
      "##################################################\n",
      "Train size: [400] hidden size: [58] trial: 0, train_loss: 1.687081, test loss: 1.013843, bias2: 1.0138429403305054, variance: 2.4328425385355956e-10\n",
      "Train size: [400] hidden size: [58] trial: 1, train_loss: 1.674834, test loss: 0.995568, bias2: 0.9495223760604858, variance: 0.046045247465372086\n",
      "Train size: [400] hidden size: [58] trial: 2, train_loss: 1.748387, test loss: 1.007573, bias2: 0.9378000497817993, variance: 0.06977307051420212\n",
      "Train size: [400] hidden size: [58] trial: 3, train_loss: 1.756710, test loss: 1.009414, bias2: 0.9333713054656982, variance: 0.07604239881038666\n",
      "Train size: [400] hidden size: [58] trial: 4, train_loss: 1.758761, test loss: 1.006734, bias2: 0.9317067265510559, variance: 0.07502681016921997\n",
      "Train size: [400] hidden size: [58] trial: 5, train_loss: 1.745996, test loss: 1.005137, bias2: 0.9290488362312317, variance: 0.07608838379383087\n",
      "Train size: [400] hidden size: [58] trial: 6, train_loss: 1.723566, test loss: 1.004973, bias2: 0.9241275191307068, variance: 0.08084563910961151\n",
      "Train size: [400] hidden size: [58] trial: 7, train_loss: 1.723431, test loss: 1.006915, bias2: 0.9248142838478088, variance: 0.08210094273090363\n",
      "Train size: [400] hidden size: [58] trial: 8, train_loss: 1.723164, test loss: 1.010066, bias2: 0.9244022369384766, variance: 0.08566358685493469\n",
      "Train size: [400] hidden size: [58] trial: 9, train_loss: 1.704359, test loss: 1.012825, bias2: 0.9240525960922241, variance: 0.08877264708280563\n",
      "Train size: [400] hidden size: [58] trial: 10, train_loss: 1.691918, test loss: 1.011467, bias2: 0.9226226806640625, variance: 0.08884391188621521\n",
      "Train size: [400] hidden size: [58] trial: 11, train_loss: 1.696771, test loss: 1.010671, bias2: 0.9196653366088867, variance: 0.09100618958473206\n",
      "Train size: [400] hidden size: [58] trial: 12, train_loss: 1.687221, test loss: 1.009427, bias2: 0.9196794629096985, variance: 0.08974794298410416\n",
      "Train size: [400] hidden size: [58] trial: 13, train_loss: 1.697142, test loss: 1.009465, bias2: 0.9188705086708069, variance: 0.09059473127126694\n",
      "Train size: [400] hidden size: [58] trial: 14, train_loss: 1.698982, test loss: 1.009942, bias2: 0.9175093173980713, variance: 0.09243223071098328\n",
      "Train size: [400] hidden size: [58] trial: 15, train_loss: 1.707877, test loss: 1.011685, bias2: 0.9186992049217224, variance: 0.09298615157604218\n",
      "Train size: [400] hidden size: [58] trial: 16, train_loss: 1.708963, test loss: 1.010679, bias2: 0.9160611033439636, variance: 0.09461768716573715\n",
      "Train size: [400] hidden size: [58] trial: 17, train_loss: 1.716657, test loss: 1.010157, bias2: 0.9162067174911499, variance: 0.09395003318786621\n",
      "Train size: [400] hidden size: [58] trial: 18, train_loss: 1.714579, test loss: 1.008265, bias2: 0.9147505164146423, variance: 0.09351400285959244\n",
      "Train size: [400] hidden size: [58] trial: 19, train_loss: 1.708172, test loss: 1.010297, bias2: 0.9138632416725159, variance: 0.09643383324146271\n",
      "Train size: [400] hidden size: [58] trial: 20, train_loss: 1.702328, test loss: 1.009209, bias2: 0.9127494096755981, variance: 0.09645986557006836\n",
      "Train size: [400] hidden size: [58] trial: 21, train_loss: 1.702128, test loss: 1.008541, bias2: 0.9123363494873047, variance: 0.0962042585015297\n",
      "Train size: [400] hidden size: [58] trial: 22, train_loss: 1.704357, test loss: 1.007137, bias2: 0.908970057964325, variance: 0.09816654771566391\n",
      "Train size: [400] hidden size: [58] trial: 23, train_loss: 1.716603, test loss: 1.007053, bias2: 0.9072163701057434, variance: 0.09983674436807632\n",
      "Train size: [400] hidden size: [58] trial: 24, train_loss: 1.713500, test loss: 1.009509, bias2: 0.909565806388855, variance: 0.09994348883628845\n",
      "Train size: [400] hidden size: [58] trial: 25, train_loss: 1.714855, test loss: 1.009786, bias2: 0.9092499613761902, variance: 0.1005355641245842\n",
      "Train size: [400] hidden size: [58] trial: 26, train_loss: 1.723198, test loss: 1.009235, bias2: 0.9088256359100342, variance: 0.10040923953056335\n",
      "Train size: [400] hidden size: [58] trial: 27, train_loss: 1.719000, test loss: 1.009690, bias2: 0.9082082509994507, variance: 0.10148132592439651\n",
      "Train size: [400] hidden size: [58] trial: 28, train_loss: 1.723366, test loss: 1.009568, bias2: 0.9079172611236572, variance: 0.10165119171142578\n",
      "Train size: [400] hidden size: [58] trial: 29, train_loss: 1.726446, test loss: 1.010197, bias2: 0.908464252948761, variance: 0.10173232108354568\n",
      "Train size: [400] hidden size: [58] trial: 30, train_loss: 1.725118, test loss: 1.009664, bias2: 0.908802330493927, variance: 0.10086186230182648\n",
      "Train size: [400] hidden size: [58] trial: 31, train_loss: 1.730203, test loss: 1.010304, bias2: 0.9094728827476501, variance: 0.10083155333995819\n",
      "Train size: [400] hidden size: [58] trial: 32, train_loss: 1.726214, test loss: 1.011278, bias2: 0.911137044429779, variance: 0.10014060884714127\n",
      "Train size: [400] hidden size: [58] trial: 33, train_loss: 1.724129, test loss: 1.011816, bias2: 0.9118510484695435, variance: 0.09996511042118073\n",
      "Train size: [400] hidden size: [58] trial: 34, train_loss: 1.721149, test loss: 1.011170, bias2: 0.9114930033683777, variance: 0.09967677295207977\n",
      "Train size: [400] hidden size: [58] trial: 35, train_loss: 1.712436, test loss: 1.012005, bias2: 0.9124022126197815, variance: 0.09960301220417023\n",
      "Train size: [400] hidden size: [58] trial: 36, train_loss: 1.713674, test loss: 1.010830, bias2: 0.9111171364784241, variance: 0.0997127890586853\n",
      "Train size: [400] hidden size: [58] trial: 37, train_loss: 1.715054, test loss: 1.011520, bias2: 0.9115483164787292, variance: 0.09997181594371796\n",
      "Train size: [400] hidden size: [58] trial: 38, train_loss: 1.714380, test loss: 1.011052, bias2: 0.9112590551376343, variance: 0.09979322552680969\n",
      "Train size: [400] hidden size: [58] trial: 39, train_loss: 1.713472, test loss: 1.010617, bias2: 0.9099052548408508, variance: 0.10071128606796265\n",
      "Train size: [400] hidden size: [58] trial: 40, train_loss: 1.716063, test loss: 1.010556, bias2: 0.9097272157669067, variance: 0.10082890838384628\n",
      "Train size: [400] hidden size: [58] trial: 41, train_loss: 1.715084, test loss: 1.009489, bias2: 0.9088178873062134, variance: 0.1006712019443512\n",
      "Train size: [400] hidden size: [58] trial: 42, train_loss: 1.712338, test loss: 1.010126, bias2: 0.9085797071456909, variance: 0.1015462726354599\n",
      "Train size: [400] hidden size: [58] trial: 43, train_loss: 1.711539, test loss: 1.009894, bias2: 0.9081006050109863, variance: 0.10179343074560165\n",
      "Train size: [400] hidden size: [58] trial: 44, train_loss: 1.711311, test loss: 1.009781, bias2: 0.9080259203910828, variance: 0.10175470262765884\n",
      "Train size: [400] hidden size: [58] trial: 45, train_loss: 1.716976, test loss: 1.010148, bias2: 0.9082678556442261, variance: 0.10188030451536179\n",
      "Train size: [400] hidden size: [58] trial: 46, train_loss: 1.715462, test loss: 1.009626, bias2: 0.9082416892051697, variance: 0.10138420760631561\n",
      "Train size: [400] hidden size: [58] trial: 47, train_loss: 1.715872, test loss: 1.009780, bias2: 0.9084985852241516, variance: 0.10128147900104523\n",
      "Train size: [400] hidden size: [58] trial: 48, train_loss: 1.715436, test loss: 1.008628, bias2: 0.9071441292762756, variance: 0.10148397833108902\n",
      "Train size: [400] hidden size: [58] trial: 49, train_loss: 1.716774, test loss: 1.008711, bias2: 0.9075043797492981, variance: 0.10120683908462524\n",
      "##################################################\n",
      "Train size: [400] hidden size: [67] trial: 0, train_loss: 1.611274, test loss: 1.003735, bias2: 1.0037347078323364, variance: 9.731369876586626e-11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [67] trial: 1, train_loss: 1.786302, test loss: 1.012200, bias2: 0.9675018787384033, variance: 0.04469825327396393\n",
      "Train size: [400] hidden size: [67] trial: 2, train_loss: 1.797933, test loss: 1.013410, bias2: 0.9452685117721558, variance: 0.06814169883728027\n",
      "Train size: [400] hidden size: [67] trial: 3, train_loss: 1.764416, test loss: 1.004275, bias2: 0.9254733324050903, variance: 0.07880163937807083\n",
      "Train size: [400] hidden size: [67] trial: 4, train_loss: 1.764055, test loss: 1.009330, bias2: 0.9301477074623108, variance: 0.0791819617152214\n",
      "Train size: [400] hidden size: [67] trial: 5, train_loss: 1.755877, test loss: 1.006902, bias2: 0.9217566251754761, variance: 0.08514510840177536\n",
      "Train size: [400] hidden size: [67] trial: 6, train_loss: 1.743308, test loss: 1.011571, bias2: 0.918721079826355, variance: 0.09285019338130951\n",
      "Train size: [400] hidden size: [67] trial: 7, train_loss: 1.750673, test loss: 1.019536, bias2: 0.9204191565513611, variance: 0.09911683946847916\n",
      "Train size: [400] hidden size: [67] trial: 8, train_loss: 1.726935, test loss: 1.022978, bias2: 0.9233124256134033, variance: 0.09966529160737991\n",
      "Train size: [400] hidden size: [67] trial: 9, train_loss: 1.714426, test loss: 1.020211, bias2: 0.9176769852638245, variance: 0.10253363847732544\n",
      "Train size: [400] hidden size: [67] trial: 10, train_loss: 1.707364, test loss: 1.020155, bias2: 0.9195746183395386, variance: 0.10058067739009857\n",
      "Train size: [400] hidden size: [67] trial: 11, train_loss: 1.730132, test loss: 1.020927, bias2: 0.9182314276695251, variance: 0.10269588977098465\n",
      "Train size: [400] hidden size: [67] trial: 12, train_loss: 1.727888, test loss: 1.019567, bias2: 0.9155828952789307, variance: 0.10398435592651367\n",
      "Train size: [400] hidden size: [67] trial: 13, train_loss: 1.712920, test loss: 1.017122, bias2: 0.9110059142112732, variance: 0.10611658543348312\n",
      "Train size: [400] hidden size: [67] trial: 14, train_loss: 1.704769, test loss: 1.016384, bias2: 0.9115539193153381, variance: 0.1048305556178093\n",
      "Train size: [400] hidden size: [67] trial: 15, train_loss: 1.688614, test loss: 1.018456, bias2: 0.9113397002220154, variance: 0.10711603611707687\n",
      "Train size: [400] hidden size: [67] trial: 16, train_loss: 1.686934, test loss: 1.020574, bias2: 0.9113712906837463, variance: 0.1092025488615036\n",
      "Train size: [400] hidden size: [67] trial: 17, train_loss: 1.696666, test loss: 1.021766, bias2: 0.9117414951324463, variance: 0.1100241020321846\n",
      "Train size: [400] hidden size: [67] trial: 18, train_loss: 1.697445, test loss: 1.020799, bias2: 0.9108753204345703, variance: 0.10992398113012314\n",
      "Train size: [400] hidden size: [67] trial: 19, train_loss: 1.692129, test loss: 1.020231, bias2: 0.9093988537788391, variance: 0.11083225905895233\n",
      "Train size: [400] hidden size: [67] trial: 20, train_loss: 1.683023, test loss: 1.018972, bias2: 0.9075484275817871, variance: 0.11142328381538391\n",
      "Train size: [400] hidden size: [67] trial: 21, train_loss: 1.687527, test loss: 1.017567, bias2: 0.9061934351921082, variance: 0.11137323826551437\n",
      "Train size: [400] hidden size: [67] trial: 22, train_loss: 1.699431, test loss: 1.017437, bias2: 0.9051121473312378, variance: 0.11232493817806244\n",
      "Train size: [400] hidden size: [67] trial: 23, train_loss: 1.697951, test loss: 1.016899, bias2: 0.9063233733177185, variance: 0.11057528108358383\n",
      "Train size: [400] hidden size: [67] trial: 24, train_loss: 1.697519, test loss: 1.015398, bias2: 0.9056858420372009, variance: 0.10971207171678543\n",
      "Train size: [400] hidden size: [67] trial: 25, train_loss: 1.696727, test loss: 1.015552, bias2: 0.9063379168510437, variance: 0.10921364277601242\n",
      "Train size: [400] hidden size: [67] trial: 26, train_loss: 1.694974, test loss: 1.015760, bias2: 0.906241238117218, variance: 0.10951881110668182\n",
      "Train size: [400] hidden size: [67] trial: 27, train_loss: 1.698454, test loss: 1.014945, bias2: 0.9059141278266907, variance: 0.10903089493513107\n",
      "Train size: [400] hidden size: [67] trial: 28, train_loss: 1.697058, test loss: 1.015484, bias2: 0.9057367444038391, variance: 0.10974673926830292\n",
      "Train size: [400] hidden size: [67] trial: 29, train_loss: 1.702683, test loss: 1.015100, bias2: 0.9046646356582642, variance: 0.11043545603752136\n",
      "Train size: [400] hidden size: [67] trial: 30, train_loss: 1.701448, test loss: 1.016716, bias2: 0.9050846695899963, variance: 0.11163169145584106\n",
      "Train size: [400] hidden size: [67] trial: 31, train_loss: 1.699188, test loss: 1.018100, bias2: 0.9056228399276733, variance: 0.11247683316469193\n",
      "Train size: [400] hidden size: [67] trial: 32, train_loss: 1.699206, test loss: 1.016859, bias2: 0.9044480919837952, variance: 0.11241070926189423\n",
      "Train size: [400] hidden size: [67] trial: 33, train_loss: 1.700482, test loss: 1.017373, bias2: 0.905103862285614, variance: 0.11226899176836014\n",
      "Train size: [400] hidden size: [67] trial: 34, train_loss: 1.703697, test loss: 1.016845, bias2: 0.9053835868835449, variance: 0.11146101355552673\n",
      "Train size: [400] hidden size: [67] trial: 35, train_loss: 1.702253, test loss: 1.017908, bias2: 0.9068912267684937, variance: 0.1110164001584053\n",
      "Train size: [400] hidden size: [67] trial: 36, train_loss: 1.701655, test loss: 1.017390, bias2: 0.9059370756149292, variance: 0.11145295947790146\n",
      "Train size: [400] hidden size: [67] trial: 37, train_loss: 1.699672, test loss: 1.017859, bias2: 0.9052702784538269, variance: 0.11258883774280548\n",
      "Train size: [400] hidden size: [67] trial: 38, train_loss: 1.693290, test loss: 1.017752, bias2: 0.9057385325431824, variance: 0.11201364547014236\n",
      "Train size: [400] hidden size: [67] trial: 39, train_loss: 1.697220, test loss: 1.017221, bias2: 0.9058748483657837, variance: 0.11134610325098038\n",
      "Train size: [400] hidden size: [67] trial: 40, train_loss: 1.695155, test loss: 1.016800, bias2: 0.9052537679672241, variance: 0.11154675483703613\n",
      "Train size: [400] hidden size: [67] trial: 41, train_loss: 1.694970, test loss: 1.017055, bias2: 0.9055427312850952, variance: 0.11151251196861267\n",
      "Train size: [400] hidden size: [67] trial: 42, train_loss: 1.699437, test loss: 1.017321, bias2: 0.9062532186508179, variance: 0.11106742173433304\n",
      "Train size: [400] hidden size: [67] trial: 43, train_loss: 1.699106, test loss: 1.017454, bias2: 0.9064084887504578, variance: 0.11104590445756912\n",
      "Train size: [400] hidden size: [67] trial: 44, train_loss: 1.700023, test loss: 1.017729, bias2: 0.9068987965583801, variance: 0.11083024740219116\n",
      "Train size: [400] hidden size: [67] trial: 45, train_loss: 1.700436, test loss: 1.017788, bias2: 0.9072699546813965, variance: 0.11051788181066513\n",
      "Train size: [400] hidden size: [67] trial: 46, train_loss: 1.700668, test loss: 1.017999, bias2: 0.907678484916687, variance: 0.11032067239284515\n",
      "Train size: [400] hidden size: [67] trial: 47, train_loss: 1.698265, test loss: 1.017678, bias2: 0.9076172113418579, variance: 0.11006056517362595\n",
      "Train size: [400] hidden size: [67] trial: 48, train_loss: 1.696026, test loss: 1.017418, bias2: 0.9075258374214172, variance: 0.10989253222942352\n",
      "Train size: [400] hidden size: [67] trial: 49, train_loss: 1.696229, test loss: 1.017433, bias2: 0.9067087769508362, variance: 0.11072460561990738\n",
      "##################################################\n",
      "Train size: [400] hidden size: [77] trial: 0, train_loss: 1.691479, test loss: 0.973813, bias2: 0.9738126397132874, variance: -1.5570191802538602e-09\n",
      "Train size: [400] hidden size: [77] trial: 1, train_loss: 1.768261, test loss: 0.975591, bias2: 0.9167727828025818, variance: 0.058817751705646515\n",
      "Train size: [400] hidden size: [77] trial: 2, train_loss: 1.761567, test loss: 0.983553, bias2: 0.906356155872345, variance: 0.07719685137271881\n",
      "Train size: [400] hidden size: [77] trial: 3, train_loss: 1.793214, test loss: 0.978936, bias2: 0.8832709193229675, variance: 0.09566498547792435\n",
      "Train size: [400] hidden size: [77] trial: 4, train_loss: 1.773493, test loss: 0.987334, bias2: 0.8775629997253418, variance: 0.10977091640233994\n",
      "Train size: [400] hidden size: [77] trial: 5, train_loss: 1.739342, test loss: 0.983982, bias2: 0.875659704208374, variance: 0.10832224041223526\n",
      "Train size: [400] hidden size: [77] trial: 6, train_loss: 1.726435, test loss: 0.991744, bias2: 0.8862786889076233, variance: 0.10546563565731049\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [77] trial: 7, train_loss: 1.708020, test loss: 0.995082, bias2: 0.8919898867607117, variance: 0.1030922383069992\n",
      "Train size: [400] hidden size: [77] trial: 8, train_loss: 1.703856, test loss: 0.998318, bias2: 0.8914551734924316, variance: 0.10686323046684265\n",
      "Train size: [400] hidden size: [77] trial: 9, train_loss: 1.708224, test loss: 1.004095, bias2: 0.8946092128753662, variance: 0.10948620736598969\n",
      "Train size: [400] hidden size: [77] trial: 10, train_loss: 1.706671, test loss: 1.005420, bias2: 0.8956747651100159, variance: 0.10974554717540741\n",
      "Train size: [400] hidden size: [77] trial: 11, train_loss: 1.707199, test loss: 1.008097, bias2: 0.8973286151885986, variance: 0.11076876521110535\n",
      "Train size: [400] hidden size: [77] trial: 12, train_loss: 1.711409, test loss: 1.008163, bias2: 0.8933707475662231, variance: 0.11479257792234421\n",
      "Train size: [400] hidden size: [77] trial: 13, train_loss: 1.707802, test loss: 1.008067, bias2: 0.8933548331260681, variance: 0.11471255868673325\n",
      "Train size: [400] hidden size: [77] trial: 14, train_loss: 1.702345, test loss: 1.007106, bias2: 0.8906013369560242, variance: 0.11650475114583969\n",
      "Train size: [400] hidden size: [77] trial: 15, train_loss: 1.711153, test loss: 1.007718, bias2: 0.8882842063903809, variance: 0.1194334328174591\n",
      "Train size: [400] hidden size: [77] trial: 16, train_loss: 1.707997, test loss: 1.007053, bias2: 0.8841750621795654, variance: 0.12287793308496475\n",
      "Train size: [400] hidden size: [77] trial: 17, train_loss: 1.708456, test loss: 1.007232, bias2: 0.8846258521080017, variance: 0.1226063147187233\n",
      "Train size: [400] hidden size: [77] trial: 18, train_loss: 1.704976, test loss: 1.009619, bias2: 0.8840108513832092, variance: 0.1256081461906433\n",
      "Train size: [400] hidden size: [77] trial: 19, train_loss: 1.704391, test loss: 1.009244, bias2: 0.882788896560669, variance: 0.12645505368709564\n",
      "Train size: [400] hidden size: [77] trial: 20, train_loss: 1.703870, test loss: 1.011006, bias2: 0.8843894600868225, variance: 0.12661665678024292\n",
      "Train size: [400] hidden size: [77] trial: 21, train_loss: 1.706444, test loss: 1.009443, bias2: 0.88277268409729, variance: 0.12666986882686615\n",
      "Train size: [400] hidden size: [77] trial: 22, train_loss: 1.700190, test loss: 1.009710, bias2: 0.8824434876441956, variance: 0.12726657092571259\n",
      "Train size: [400] hidden size: [77] trial: 23, train_loss: 1.697318, test loss: 1.011329, bias2: 0.8826809525489807, variance: 0.12864811718463898\n",
      "Train size: [400] hidden size: [77] trial: 24, train_loss: 1.697690, test loss: 1.012172, bias2: 0.8840265870094299, variance: 0.12814553081989288\n",
      "Train size: [400] hidden size: [77] trial: 25, train_loss: 1.697061, test loss: 1.011908, bias2: 0.8845636248588562, variance: 0.12734466791152954\n",
      "Train size: [400] hidden size: [77] trial: 26, train_loss: 1.694963, test loss: 1.012738, bias2: 0.8853664994239807, variance: 0.12737102806568146\n",
      "Train size: [400] hidden size: [77] trial: 27, train_loss: 1.701996, test loss: 1.012525, bias2: 0.8853667378425598, variance: 0.1271577626466751\n",
      "Train size: [400] hidden size: [77] trial: 28, train_loss: 1.700595, test loss: 1.010828, bias2: 0.8831547498703003, variance: 0.12767361104488373\n",
      "Train size: [400] hidden size: [77] trial: 29, train_loss: 1.697287, test loss: 1.011651, bias2: 0.882584810256958, variance: 0.12906619906425476\n",
      "Train size: [400] hidden size: [77] trial: 30, train_loss: 1.696900, test loss: 1.011474, bias2: 0.882338285446167, variance: 0.129135861992836\n",
      "Train size: [400] hidden size: [77] trial: 31, train_loss: 1.699978, test loss: 1.012334, bias2: 0.8829441070556641, variance: 0.12939003109931946\n",
      "Train size: [400] hidden size: [77] trial: 32, train_loss: 1.698307, test loss: 1.012419, bias2: 0.884496808052063, variance: 0.1279219686985016\n",
      "Train size: [400] hidden size: [77] trial: 33, train_loss: 1.691272, test loss: 1.012774, bias2: 0.8839941024780273, variance: 0.12878035008907318\n",
      "Train size: [400] hidden size: [77] trial: 34, train_loss: 1.690612, test loss: 1.013490, bias2: 0.8847091197967529, variance: 0.1287812888622284\n",
      "Train size: [400] hidden size: [77] trial: 35, train_loss: 1.686668, test loss: 1.013521, bias2: 0.8845930695533752, variance: 0.12892811000347137\n",
      "Train size: [400] hidden size: [77] trial: 36, train_loss: 1.681709, test loss: 1.013950, bias2: 0.8852789402008057, variance: 0.1286710798740387\n",
      "Train size: [400] hidden size: [77] trial: 37, train_loss: 1.681408, test loss: 1.015355, bias2: 0.8863309621810913, variance: 0.12902449071407318\n",
      "Train size: [400] hidden size: [77] trial: 38, train_loss: 1.680696, test loss: 1.014818, bias2: 0.8857777118682861, variance: 0.12904071807861328\n",
      "Train size: [400] hidden size: [77] trial: 39, train_loss: 1.680987, test loss: 1.014307, bias2: 0.8850147724151611, variance: 0.12929226458072662\n",
      "Train size: [400] hidden size: [77] trial: 40, train_loss: 1.678846, test loss: 1.014435, bias2: 0.8858957290649414, variance: 0.1285397708415985\n",
      "Train size: [400] hidden size: [77] trial: 41, train_loss: 1.681150, test loss: 1.014397, bias2: 0.886280357837677, variance: 0.1281168907880783\n",
      "Train size: [400] hidden size: [77] trial: 42, train_loss: 1.677955, test loss: 1.013749, bias2: 0.8865954875946045, variance: 0.1271533966064453\n",
      "Train size: [400] hidden size: [77] trial: 43, train_loss: 1.675830, test loss: 1.013455, bias2: 0.8864770531654358, variance: 0.1269778609275818\n",
      "Train size: [400] hidden size: [77] trial: 44, train_loss: 1.678818, test loss: 1.014013, bias2: 0.8859490752220154, variance: 0.12806372344493866\n",
      "Train size: [400] hidden size: [77] trial: 45, train_loss: 1.680605, test loss: 1.013257, bias2: 0.8856670260429382, variance: 0.12758998572826385\n",
      "Train size: [400] hidden size: [77] trial: 46, train_loss: 1.676865, test loss: 1.013833, bias2: 0.8841975927352905, variance: 0.12963545322418213\n",
      "Train size: [400] hidden size: [77] trial: 47, train_loss: 1.675720, test loss: 1.013983, bias2: 0.8841269612312317, variance: 0.12985557317733765\n",
      "Train size: [400] hidden size: [77] trial: 48, train_loss: 1.674538, test loss: 1.014800, bias2: 0.8855371475219727, variance: 0.12926247715950012\n",
      "Train size: [400] hidden size: [77] trial: 49, train_loss: 1.673063, test loss: 1.015052, bias2: 0.8857108354568481, variance: 0.129341259598732\n",
      "##################################################\n",
      "Train size: [400] hidden size: [89] trial: 0, train_loss: 1.660023, test loss: 1.045402, bias2: 1.0454021692276, variance: 1.6543327818752118e-09\n",
      "Train size: [400] hidden size: [89] trial: 1, train_loss: 1.682934, test loss: 1.027135, bias2: 0.9324634671211243, variance: 0.09467189013957977\n",
      "Train size: [400] hidden size: [89] trial: 2, train_loss: 1.647263, test loss: 1.042295, bias2: 0.9158984422683716, variance: 0.1263965517282486\n",
      "Train size: [400] hidden size: [89] trial: 3, train_loss: 1.626964, test loss: 1.037280, bias2: 0.9038965702056885, variance: 0.13338300585746765\n",
      "Train size: [400] hidden size: [89] trial: 4, train_loss: 1.639281, test loss: 1.031561, bias2: 0.8920551538467407, variance: 0.13950574398040771\n",
      "Train size: [400] hidden size: [89] trial: 5, train_loss: 1.624694, test loss: 1.035289, bias2: 0.8921469449996948, variance: 0.1431419551372528\n",
      "Train size: [400] hidden size: [89] trial: 6, train_loss: 1.613509, test loss: 1.034565, bias2: 0.8935678005218506, variance: 0.1409974992275238\n",
      "Train size: [400] hidden size: [89] trial: 7, train_loss: 1.576475, test loss: 1.031127, bias2: 0.8875171542167664, variance: 0.14360983669757843\n",
      "Train size: [400] hidden size: [89] trial: 8, train_loss: 1.576101, test loss: 1.035451, bias2: 0.8871004581451416, variance: 0.14835068583488464\n",
      "Train size: [400] hidden size: [89] trial: 9, train_loss: 1.581874, test loss: 1.034587, bias2: 0.890501856803894, variance: 0.14408518373966217\n",
      "Train size: [400] hidden size: [89] trial: 10, train_loss: 1.595284, test loss: 1.029939, bias2: 0.8871920704841614, variance: 0.14274664223194122\n",
      "Train size: [400] hidden size: [89] trial: 11, train_loss: 1.575744, test loss: 1.026183, bias2: 0.8835415244102478, variance: 0.14264138042926788\n",
      "Train size: [400] hidden size: [89] trial: 12, train_loss: 1.583992, test loss: 1.026266, bias2: 0.8773099780082703, variance: 0.14895552396774292\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [89] trial: 13, train_loss: 1.573609, test loss: 1.025975, bias2: 0.8742152452468872, variance: 0.15176020562648773\n",
      "Train size: [400] hidden size: [89] trial: 14, train_loss: 1.571952, test loss: 1.022201, bias2: 0.8725693225860596, variance: 0.14963187277317047\n",
      "Train size: [400] hidden size: [89] trial: 15, train_loss: 1.567045, test loss: 1.023444, bias2: 0.8683705925941467, variance: 0.15507382154464722\n",
      "Train size: [400] hidden size: [89] trial: 16, train_loss: 1.570032, test loss: 1.022663, bias2: 0.8690983057022095, variance: 0.1535644829273224\n",
      "Train size: [400] hidden size: [89] trial: 17, train_loss: 1.570480, test loss: 1.020274, bias2: 0.8671630024909973, variance: 0.1531110256910324\n",
      "Train size: [400] hidden size: [89] trial: 18, train_loss: 1.576081, test loss: 1.022226, bias2: 0.869767427444458, variance: 0.15245899558067322\n",
      "Train size: [400] hidden size: [89] trial: 19, train_loss: 1.575271, test loss: 1.025213, bias2: 0.8706213235855103, variance: 0.15459167957305908\n",
      "Train size: [400] hidden size: [89] trial: 20, train_loss: 1.580156, test loss: 1.023530, bias2: 0.8688895106315613, variance: 0.15464048087596893\n",
      "Train size: [400] hidden size: [89] trial: 21, train_loss: 1.580698, test loss: 1.021578, bias2: 0.8684123158454895, variance: 0.15316540002822876\n",
      "Train size: [400] hidden size: [89] trial: 22, train_loss: 1.581304, test loss: 1.021583, bias2: 0.8682194352149963, variance: 0.15336374938488007\n",
      "Train size: [400] hidden size: [89] trial: 23, train_loss: 1.583713, test loss: 1.024389, bias2: 0.8690464496612549, variance: 0.15534260869026184\n",
      "Train size: [400] hidden size: [89] trial: 24, train_loss: 1.585073, test loss: 1.024732, bias2: 0.8690071105957031, variance: 0.15572522580623627\n",
      "Train size: [400] hidden size: [89] trial: 25, train_loss: 1.591313, test loss: 1.024803, bias2: 0.8694514036178589, variance: 0.15535126626491547\n",
      "Train size: [400] hidden size: [89] trial: 26, train_loss: 1.589958, test loss: 1.024638, bias2: 0.866447925567627, variance: 0.15819022059440613\n",
      "Train size: [400] hidden size: [89] trial: 27, train_loss: 1.589537, test loss: 1.024095, bias2: 0.8661002516746521, variance: 0.15799444913864136\n",
      "Train size: [400] hidden size: [89] trial: 28, train_loss: 1.586285, test loss: 1.024013, bias2: 0.8669999837875366, variance: 0.157012939453125\n",
      "Train size: [400] hidden size: [89] trial: 29, train_loss: 1.590171, test loss: 1.024488, bias2: 0.8677164316177368, variance: 0.15677133202552795\n",
      "Train size: [400] hidden size: [89] trial: 30, train_loss: 1.590656, test loss: 1.023762, bias2: 0.8684990406036377, variance: 0.15526247024536133\n",
      "Train size: [400] hidden size: [89] trial: 31, train_loss: 1.594234, test loss: 1.022288, bias2: 0.8669028878211975, variance: 0.1553846001625061\n",
      "Train size: [400] hidden size: [89] trial: 32, train_loss: 1.599388, test loss: 1.021949, bias2: 0.8644790053367615, variance: 0.15747006237506866\n",
      "Train size: [400] hidden size: [89] trial: 33, train_loss: 1.603737, test loss: 1.023377, bias2: 0.8660889863967896, variance: 0.15728792548179626\n",
      "Train size: [400] hidden size: [89] trial: 34, train_loss: 1.604951, test loss: 1.023706, bias2: 0.8660361170768738, variance: 0.15766972303390503\n",
      "Train size: [400] hidden size: [89] trial: 35, train_loss: 1.604327, test loss: 1.023275, bias2: 0.8654448986053467, variance: 0.15783022344112396\n",
      "Train size: [400] hidden size: [89] trial: 36, train_loss: 1.600211, test loss: 1.022088, bias2: 0.8636536002159119, variance: 0.1584339588880539\n",
      "Train size: [400] hidden size: [89] trial: 37, train_loss: 1.597486, test loss: 1.022137, bias2: 0.8646590113639832, variance: 0.15747790038585663\n",
      "Train size: [400] hidden size: [89] trial: 38, train_loss: 1.598089, test loss: 1.020525, bias2: 0.8638579845428467, variance: 0.15666748583316803\n",
      "Train size: [400] hidden size: [89] trial: 39, train_loss: 1.599136, test loss: 1.021392, bias2: 0.864896297454834, variance: 0.15649567544460297\n",
      "Train size: [400] hidden size: [89] trial: 40, train_loss: 1.602081, test loss: 1.021499, bias2: 0.8659502267837524, variance: 0.1555483639240265\n",
      "Train size: [400] hidden size: [89] trial: 41, train_loss: 1.598703, test loss: 1.021627, bias2: 0.8662253618240356, variance: 0.1554015576839447\n",
      "Train size: [400] hidden size: [89] trial: 42, train_loss: 1.600764, test loss: 1.021832, bias2: 0.865286648273468, variance: 0.1565456986427307\n",
      "Train size: [400] hidden size: [89] trial: 43, train_loss: 1.598711, test loss: 1.022379, bias2: 0.8654418587684631, variance: 0.1569374054670334\n",
      "Train size: [400] hidden size: [89] trial: 44, train_loss: 1.601466, test loss: 1.022830, bias2: 0.8653541207313538, variance: 0.15747590363025665\n",
      "Train size: [400] hidden size: [89] trial: 45, train_loss: 1.597622, test loss: 1.022641, bias2: 0.8647600412368774, variance: 0.15788088738918304\n",
      "Train size: [400] hidden size: [89] trial: 46, train_loss: 1.598426, test loss: 1.023419, bias2: 0.8663450479507446, variance: 0.15707412362098694\n",
      "Train size: [400] hidden size: [89] trial: 47, train_loss: 1.596633, test loss: 1.023312, bias2: 0.8666800260543823, variance: 0.15663209557533264\n",
      "Train size: [400] hidden size: [89] trial: 48, train_loss: 1.592266, test loss: 1.022523, bias2: 0.8647679090499878, variance: 0.15775524079799652\n",
      "Train size: [400] hidden size: [89] trial: 49, train_loss: 1.594071, test loss: 1.022610, bias2: 0.864719808101654, variance: 0.15789039433002472\n",
      "##################################################\n",
      "Train size: [400] hidden size: [102] trial: 0, train_loss: 1.603232, test loss: 0.960973, bias2: 0.9609733819961548, variance: 8.758233027705842e-10\n",
      "Train size: [400] hidden size: [102] trial: 1, train_loss: 1.589413, test loss: 0.998358, bias2: 0.910243809223175, variance: 0.08811457455158234\n",
      "Train size: [400] hidden size: [102] trial: 2, train_loss: 1.520053, test loss: 1.008738, bias2: 0.8850870132446289, variance: 0.12365112453699112\n",
      "Train size: [400] hidden size: [102] trial: 3, train_loss: 1.496365, test loss: 1.022661, bias2: 0.8949494957923889, variance: 0.12771110236644745\n",
      "Train size: [400] hidden size: [102] trial: 4, train_loss: 1.472834, test loss: 1.026199, bias2: 0.8881725072860718, variance: 0.13802644610404968\n",
      "Train size: [400] hidden size: [102] trial: 5, train_loss: 1.484286, test loss: 1.024818, bias2: 0.8796435594558716, variance: 0.14517450332641602\n",
      "Train size: [400] hidden size: [102] trial: 6, train_loss: 1.513054, test loss: 1.028965, bias2: 0.8822619318962097, variance: 0.14670294523239136\n",
      "Train size: [400] hidden size: [102] trial: 7, train_loss: 1.526680, test loss: 1.033856, bias2: 0.877048671245575, variance: 0.15680687129497528\n",
      "Train size: [400] hidden size: [102] trial: 8, train_loss: 1.544393, test loss: 1.032108, bias2: 0.8752200603485107, variance: 0.15688803791999817\n",
      "Train size: [400] hidden size: [102] trial: 9, train_loss: 1.529976, test loss: 1.031005, bias2: 0.8712796568870544, variance: 0.1597248911857605\n",
      "Train size: [400] hidden size: [102] trial: 10, train_loss: 1.543267, test loss: 1.026594, bias2: 0.8605726957321167, variance: 0.16602084040641785\n",
      "Train size: [400] hidden size: [102] trial: 11, train_loss: 1.535309, test loss: 1.021355, bias2: 0.8542568683624268, variance: 0.16709767282009125\n",
      "Train size: [400] hidden size: [102] trial: 12, train_loss: 1.534825, test loss: 1.019417, bias2: 0.8544455170631409, variance: 0.16497178375720978\n",
      "Train size: [400] hidden size: [102] trial: 13, train_loss: 1.533542, test loss: 1.024958, bias2: 0.8580953478813171, variance: 0.16686300933361053\n",
      "Train size: [400] hidden size: [102] trial: 14, train_loss: 1.532521, test loss: 1.025123, bias2: 0.8622522354125977, variance: 0.1628706455230713\n",
      "Train size: [400] hidden size: [102] trial: 15, train_loss: 1.532445, test loss: 1.026148, bias2: 0.8597389459609985, variance: 0.16640926897525787\n",
      "Train size: [400] hidden size: [102] trial: 16, train_loss: 1.534496, test loss: 1.025589, bias2: 0.8591850996017456, variance: 0.16640403866767883\n",
      "Train size: [400] hidden size: [102] trial: 17, train_loss: 1.529362, test loss: 1.021601, bias2: 0.8575442433357239, variance: 0.16405649483203888\n",
      "Train size: [400] hidden size: [102] trial: 18, train_loss: 1.540888, test loss: 1.020690, bias2: 0.8561820387840271, variance: 0.1645084023475647\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [102] trial: 19, train_loss: 1.547941, test loss: 1.018590, bias2: 0.8548806309700012, variance: 0.1637098342180252\n",
      "Train size: [400] hidden size: [102] trial: 20, train_loss: 1.550287, test loss: 1.018855, bias2: 0.8571826815605164, variance: 0.16167277097702026\n",
      "Train size: [400] hidden size: [102] trial: 21, train_loss: 1.547893, test loss: 1.020806, bias2: 0.8591601848602295, variance: 0.16164563596248627\n",
      "Train size: [400] hidden size: [102] trial: 22, train_loss: 1.548749, test loss: 1.019421, bias2: 0.8556080460548401, variance: 0.1638125777244568\n",
      "Train size: [400] hidden size: [102] trial: 23, train_loss: 1.550735, test loss: 1.019113, bias2: 0.8541169762611389, variance: 0.1649964600801468\n",
      "Train size: [400] hidden size: [102] trial: 24, train_loss: 1.553293, test loss: 1.020055, bias2: 0.8554521799087524, variance: 0.16460248827934265\n",
      "Train size: [400] hidden size: [102] trial: 25, train_loss: 1.553043, test loss: 1.020555, bias2: 0.8561198115348816, variance: 0.1644354611635208\n",
      "Train size: [400] hidden size: [102] trial: 26, train_loss: 1.560309, test loss: 1.020321, bias2: 0.8545270562171936, variance: 0.16579429805278778\n",
      "Train size: [400] hidden size: [102] trial: 27, train_loss: 1.560655, test loss: 1.020385, bias2: 0.8531392812728882, variance: 0.1672457605600357\n",
      "Train size: [400] hidden size: [102] trial: 28, train_loss: 1.559622, test loss: 1.019874, bias2: 0.851180911064148, variance: 0.1686929315328598\n",
      "Train size: [400] hidden size: [102] trial: 29, train_loss: 1.565540, test loss: 1.021408, bias2: 0.851069986820221, variance: 0.17033761739730835\n",
      "Train size: [400] hidden size: [102] trial: 30, train_loss: 1.558695, test loss: 1.020790, bias2: 0.8498210310935974, variance: 0.17096883058547974\n",
      "Train size: [400] hidden size: [102] trial: 31, train_loss: 1.558732, test loss: 1.019493, bias2: 0.8494271039962769, variance: 0.1700655221939087\n",
      "Train size: [400] hidden size: [102] trial: 32, train_loss: 1.560406, test loss: 1.018817, bias2: 0.8487884998321533, variance: 0.1700284630060196\n",
      "Train size: [400] hidden size: [102] trial: 33, train_loss: 1.565331, test loss: 1.019273, bias2: 0.8479910492897034, variance: 0.17128176987171173\n",
      "Train size: [400] hidden size: [102] trial: 34, train_loss: 1.563889, test loss: 1.019743, bias2: 0.8484194874763489, variance: 0.17132334411144257\n",
      "Train size: [400] hidden size: [102] trial: 35, train_loss: 1.567792, test loss: 1.018490, bias2: 0.8473579287528992, variance: 0.17113204300403595\n",
      "Train size: [400] hidden size: [102] trial: 36, train_loss: 1.570166, test loss: 1.017922, bias2: 0.846381664276123, variance: 0.17154014110565186\n",
      "Train size: [400] hidden size: [102] trial: 37, train_loss: 1.569281, test loss: 1.018371, bias2: 0.8469223976135254, variance: 0.17144834995269775\n",
      "Train size: [400] hidden size: [102] trial: 38, train_loss: 1.568702, test loss: 1.018834, bias2: 0.8466848731040955, variance: 0.17214863002300262\n",
      "Train size: [400] hidden size: [102] trial: 39, train_loss: 1.568290, test loss: 1.018654, bias2: 0.8474069833755493, variance: 0.17124661803245544\n",
      "Train size: [400] hidden size: [102] trial: 40, train_loss: 1.566665, test loss: 1.019940, bias2: 0.8483221530914307, variance: 0.17161798477172852\n",
      "Train size: [400] hidden size: [102] trial: 41, train_loss: 1.567108, test loss: 1.018971, bias2: 0.8469358682632446, variance: 0.1720345914363861\n",
      "Train size: [400] hidden size: [102] trial: 42, train_loss: 1.566382, test loss: 1.019158, bias2: 0.8473087549209595, variance: 0.17184971272945404\n",
      "Train size: [400] hidden size: [102] trial: 43, train_loss: 1.565644, test loss: 1.018679, bias2: 0.8466780185699463, variance: 0.17200133204460144\n",
      "Train size: [400] hidden size: [102] trial: 44, train_loss: 1.565030, test loss: 1.017743, bias2: 0.8462005853652954, variance: 0.17154206335544586\n",
      "Train size: [400] hidden size: [102] trial: 45, train_loss: 1.561447, test loss: 1.018473, bias2: 0.8467377424240112, variance: 0.17173564434051514\n",
      "Train size: [400] hidden size: [102] trial: 46, train_loss: 1.560713, test loss: 1.018218, bias2: 0.8459970355033875, variance: 0.17222075164318085\n",
      "Train size: [400] hidden size: [102] trial: 47, train_loss: 1.559082, test loss: 1.018157, bias2: 0.8455288410186768, variance: 0.17262816429138184\n",
      "Train size: [400] hidden size: [102] trial: 48, train_loss: 1.560086, test loss: 1.018388, bias2: 0.8460271954536438, variance: 0.17236095666885376\n",
      "Train size: [400] hidden size: [102] trial: 49, train_loss: 1.559349, test loss: 1.018933, bias2: 0.8460106253623962, variance: 0.17292208969593048\n",
      "##################################################\n",
      "Train size: [400] hidden size: [118] trial: 0, train_loss: 1.447768, test loss: 1.005142, bias2: 1.005142092704773, variance: 5.838822203507732e-10\n",
      "Train size: [400] hidden size: [118] trial: 1, train_loss: 1.522293, test loss: 1.004212, bias2: 0.8804535269737244, variance: 0.12375839054584503\n",
      "Train size: [400] hidden size: [118] trial: 2, train_loss: 1.472560, test loss: 1.018292, bias2: 0.8573387861251831, variance: 0.16095362603664398\n",
      "Train size: [400] hidden size: [118] trial: 3, train_loss: 1.463775, test loss: 1.029530, bias2: 0.8512448072433472, variance: 0.17828485369682312\n",
      "Train size: [400] hidden size: [118] trial: 4, train_loss: 1.463144, test loss: 1.031311, bias2: 0.8435158133506775, variance: 0.18779510259628296\n",
      "Train size: [400] hidden size: [118] trial: 5, train_loss: 1.461015, test loss: 1.028952, bias2: 0.8344228267669678, variance: 0.19452950358390808\n",
      "Train size: [400] hidden size: [118] trial: 6, train_loss: 1.452190, test loss: 1.033416, bias2: 0.8342660665512085, variance: 0.19914986193180084\n",
      "Train size: [400] hidden size: [118] trial: 7, train_loss: 1.452807, test loss: 1.024123, bias2: 0.8305152654647827, variance: 0.19360770285129547\n",
      "Train size: [400] hidden size: [118] trial: 8, train_loss: 1.480501, test loss: 1.017650, bias2: 0.8146137595176697, variance: 0.2030361443758011\n",
      "Train size: [400] hidden size: [118] trial: 9, train_loss: 1.485931, test loss: 1.018243, bias2: 0.818150520324707, variance: 0.20009253919124603\n",
      "Train size: [400] hidden size: [118] trial: 10, train_loss: 1.474473, test loss: 1.015824, bias2: 0.8182335495948792, variance: 0.19759078323841095\n",
      "Train size: [400] hidden size: [118] trial: 11, train_loss: 1.483445, test loss: 1.018052, bias2: 0.8208854794502258, variance: 0.19716601073741913\n",
      "Train size: [400] hidden size: [118] trial: 12, train_loss: 1.487418, test loss: 1.021748, bias2: 0.8237883448600769, variance: 0.19795985519886017\n",
      "Train size: [400] hidden size: [118] trial: 13, train_loss: 1.491026, test loss: 1.022321, bias2: 0.8260838985443115, variance: 0.1962367296218872\n",
      "Train size: [400] hidden size: [118] trial: 14, train_loss: 1.481259, test loss: 1.021626, bias2: 0.8275424242019653, variance: 0.19408342242240906\n",
      "Train size: [400] hidden size: [118] trial: 15, train_loss: 1.485792, test loss: 1.024677, bias2: 0.8274938464164734, variance: 0.1971835494041443\n",
      "Train size: [400] hidden size: [118] trial: 16, train_loss: 1.481288, test loss: 1.026885, bias2: 0.8271597623825073, variance: 0.19972476363182068\n",
      "Train size: [400] hidden size: [118] trial: 17, train_loss: 1.481287, test loss: 1.024189, bias2: 0.827384352684021, variance: 0.19680486619472504\n",
      "Train size: [400] hidden size: [118] trial: 18, train_loss: 1.472635, test loss: 1.020778, bias2: 0.8257352113723755, variance: 0.19504281878471375\n",
      "Train size: [400] hidden size: [118] trial: 19, train_loss: 1.471884, test loss: 1.022921, bias2: 0.8249924182891846, variance: 0.1979285627603531\n",
      "Train size: [400] hidden size: [118] trial: 20, train_loss: 1.468658, test loss: 1.020726, bias2: 0.8244972825050354, variance: 0.19622844457626343\n",
      "Train size: [400] hidden size: [118] trial: 21, train_loss: 1.465449, test loss: 1.021943, bias2: 0.8250797390937805, variance: 0.19686289131641388\n",
      "Train size: [400] hidden size: [118] trial: 22, train_loss: 1.470980, test loss: 1.020912, bias2: 0.8226913213729858, variance: 0.19822072982788086\n",
      "Train size: [400] hidden size: [118] trial: 23, train_loss: 1.473000, test loss: 1.021167, bias2: 0.8226349949836731, variance: 0.19853229820728302\n",
      "Train size: [400] hidden size: [118] trial: 24, train_loss: 1.476297, test loss: 1.019730, bias2: 0.8176525831222534, variance: 0.20207783579826355\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [118] trial: 25, train_loss: 1.472720, test loss: 1.019214, bias2: 0.8189616799354553, variance: 0.20025259256362915\n",
      "Train size: [400] hidden size: [118] trial: 26, train_loss: 1.474427, test loss: 1.020025, bias2: 0.820227861404419, variance: 0.19979751110076904\n",
      "Train size: [400] hidden size: [118] trial: 27, train_loss: 1.470750, test loss: 1.020723, bias2: 0.8217166066169739, variance: 0.19900627434253693\n",
      "Train size: [400] hidden size: [118] trial: 28, train_loss: 1.467643, test loss: 1.021870, bias2: 0.8218317031860352, variance: 0.20003782212734222\n",
      "Train size: [400] hidden size: [118] trial: 29, train_loss: 1.468236, test loss: 1.020594, bias2: 0.8201947212219238, variance: 0.20039892196655273\n",
      "Train size: [400] hidden size: [118] trial: 30, train_loss: 1.470902, test loss: 1.023366, bias2: 0.8205755949020386, variance: 0.20279017090797424\n",
      "Train size: [400] hidden size: [118] trial: 31, train_loss: 1.473222, test loss: 1.023268, bias2: 0.8218023777008057, variance: 0.20146523416042328\n",
      "Train size: [400] hidden size: [118] trial: 32, train_loss: 1.479038, test loss: 1.025974, bias2: 0.8228794932365417, variance: 0.20309489965438843\n",
      "Train size: [400] hidden size: [118] trial: 33, train_loss: 1.483126, test loss: 1.026565, bias2: 0.8227401375770569, variance: 0.20382456481456757\n",
      "Train size: [400] hidden size: [118] trial: 34, train_loss: 1.484337, test loss: 1.026888, bias2: 0.8228254914283752, variance: 0.20406202971935272\n",
      "Train size: [400] hidden size: [118] trial: 35, train_loss: 1.486664, test loss: 1.025470, bias2: 0.8218746781349182, variance: 0.20359556376934052\n",
      "Train size: [400] hidden size: [118] trial: 36, train_loss: 1.483568, test loss: 1.025041, bias2: 0.8214960098266602, variance: 0.2035447508096695\n",
      "Train size: [400] hidden size: [118] trial: 37, train_loss: 1.476467, test loss: 1.023789, bias2: 0.821250319480896, variance: 0.20253869891166687\n",
      "Train size: [400] hidden size: [118] trial: 38, train_loss: 1.477811, test loss: 1.023597, bias2: 0.819869875907898, variance: 0.2037266492843628\n",
      "Train size: [400] hidden size: [118] trial: 39, train_loss: 1.478420, test loss: 1.023625, bias2: 0.8200723528862, variance: 0.20355291664600372\n",
      "Train size: [400] hidden size: [118] trial: 40, train_loss: 1.474042, test loss: 1.024098, bias2: 0.8198754191398621, variance: 0.20422212779521942\n",
      "Train size: [400] hidden size: [118] trial: 41, train_loss: 1.469911, test loss: 1.024441, bias2: 0.8209943771362305, variance: 0.20344701409339905\n",
      "Train size: [400] hidden size: [118] trial: 42, train_loss: 1.467521, test loss: 1.024489, bias2: 0.8189986944198608, variance: 0.2054898887872696\n",
      "Train size: [400] hidden size: [118] trial: 43, train_loss: 1.469599, test loss: 1.025169, bias2: 0.8201813697814941, variance: 0.20498766005039215\n",
      "Train size: [400] hidden size: [118] trial: 44, train_loss: 1.464976, test loss: 1.025328, bias2: 0.820075511932373, variance: 0.20525239408016205\n",
      "Train size: [400] hidden size: [118] trial: 45, train_loss: 1.467142, test loss: 1.026010, bias2: 0.8216433525085449, variance: 0.2043665498495102\n",
      "Train size: [400] hidden size: [118] trial: 46, train_loss: 1.469768, test loss: 1.025624, bias2: 0.8206119537353516, variance: 0.20501157641410828\n",
      "Train size: [400] hidden size: [118] trial: 47, train_loss: 1.469309, test loss: 1.025054, bias2: 0.8204644918441772, variance: 0.20458999276161194\n",
      "Train size: [400] hidden size: [118] trial: 48, train_loss: 1.470521, test loss: 1.024436, bias2: 0.8199361562728882, variance: 0.20449963212013245\n",
      "Train size: [400] hidden size: [118] trial: 49, train_loss: 1.471755, test loss: 1.024754, bias2: 0.8201980590820312, variance: 0.20455636084079742\n",
      "##################################################\n",
      "Train size: [400] hidden size: [136] trial: 0, train_loss: 1.373167, test loss: 0.967344, bias2: 0.9673437476158142, variance: 4.087175486944261e-09\n",
      "Train size: [400] hidden size: [136] trial: 1, train_loss: 1.349703, test loss: 1.000064, bias2: 0.8749827146530151, variance: 0.12508156895637512\n",
      "Train size: [400] hidden size: [136] trial: 2, train_loss: 1.366924, test loss: 1.014135, bias2: 0.8643916845321655, variance: 0.14974355697631836\n",
      "Train size: [400] hidden size: [136] trial: 3, train_loss: 1.350127, test loss: 1.015180, bias2: 0.8540515303611755, variance: 0.16112832725048065\n",
      "Train size: [400] hidden size: [136] trial: 4, train_loss: 1.382009, test loss: 1.020839, bias2: 0.8430404663085938, variance: 0.17779836058616638\n",
      "Train size: [400] hidden size: [136] trial: 5, train_loss: 1.367528, test loss: 1.006917, bias2: 0.8233870267868042, variance: 0.18353043496608734\n",
      "Train size: [400] hidden size: [136] trial: 6, train_loss: 1.384455, test loss: 0.997405, bias2: 0.8107701539993286, variance: 0.18663495779037476\n",
      "Train size: [400] hidden size: [136] trial: 7, train_loss: 1.361259, test loss: 0.997945, bias2: 0.8083449602127075, variance: 0.18960019946098328\n",
      "Train size: [400] hidden size: [136] trial: 8, train_loss: 1.399789, test loss: 0.995973, bias2: 0.8039063215255737, variance: 0.19206684827804565\n",
      "Train size: [400] hidden size: [136] trial: 9, train_loss: 1.409111, test loss: 1.002239, bias2: 0.8061800599098206, variance: 0.19605855643749237\n",
      "Train size: [400] hidden size: [136] trial: 10, train_loss: 1.422754, test loss: 1.006416, bias2: 0.8056129217147827, variance: 0.2008027732372284\n",
      "Train size: [400] hidden size: [136] trial: 11, train_loss: 1.409920, test loss: 1.006963, bias2: 0.8026384711265564, variance: 0.20432442426681519\n",
      "Train size: [400] hidden size: [136] trial: 12, train_loss: 1.402394, test loss: 1.006220, bias2: 0.7986350655555725, variance: 0.2075853943824768\n",
      "Train size: [400] hidden size: [136] trial: 13, train_loss: 1.401721, test loss: 1.007382, bias2: 0.7994858026504517, variance: 0.2078963667154312\n",
      "Train size: [400] hidden size: [136] trial: 14, train_loss: 1.399496, test loss: 1.004840, bias2: 0.796913743019104, variance: 0.207925945520401\n",
      "Train size: [400] hidden size: [136] trial: 15, train_loss: 1.401185, test loss: 1.005765, bias2: 0.7989370822906494, variance: 0.20682749152183533\n",
      "Train size: [400] hidden size: [136] trial: 16, train_loss: 1.407619, test loss: 1.009603, bias2: 0.8012430667877197, variance: 0.20836006104946136\n",
      "Train size: [400] hidden size: [136] trial: 17, train_loss: 1.422362, test loss: 1.013242, bias2: 0.8059102296829224, variance: 0.20733162760734558\n",
      "Train size: [400] hidden size: [136] trial: 18, train_loss: 1.416515, test loss: 1.012742, bias2: 0.8039077520370483, variance: 0.2088342010974884\n",
      "Train size: [400] hidden size: [136] trial: 19, train_loss: 1.412325, test loss: 1.011666, bias2: 0.8031302690505981, variance: 0.2085355818271637\n",
      "Train size: [400] hidden size: [136] trial: 20, train_loss: 1.417077, test loss: 1.010393, bias2: 0.8033227920532227, variance: 0.2070704698562622\n",
      "Train size: [400] hidden size: [136] trial: 21, train_loss: 1.425194, test loss: 1.013156, bias2: 0.8012365698814392, variance: 0.21191948652267456\n",
      "Train size: [400] hidden size: [136] trial: 22, train_loss: 1.414379, test loss: 1.012294, bias2: 0.8005737066268921, variance: 0.21172037720680237\n",
      "Train size: [400] hidden size: [136] trial: 23, train_loss: 1.423803, test loss: 1.015742, bias2: 0.8015360236167908, variance: 0.2142055481672287\n",
      "Train size: [400] hidden size: [136] trial: 24, train_loss: 1.414710, test loss: 1.016951, bias2: 0.8016851544380188, variance: 0.21526628732681274\n",
      "Train size: [400] hidden size: [136] trial: 25, train_loss: 1.409274, test loss: 1.016555, bias2: 0.7996628284454346, variance: 0.21689261496067047\n",
      "Train size: [400] hidden size: [136] trial: 26, train_loss: 1.419508, test loss: 1.018114, bias2: 0.8012251853942871, variance: 0.2168886959552765\n",
      "Train size: [400] hidden size: [136] trial: 27, train_loss: 1.422586, test loss: 1.017969, bias2: 0.8012984991073608, variance: 0.21667028963565826\n",
      "Train size: [400] hidden size: [136] trial: 28, train_loss: 1.419695, test loss: 1.017926, bias2: 0.7984687685966492, variance: 0.21945708990097046\n",
      "Train size: [400] hidden size: [136] trial: 29, train_loss: 1.419814, test loss: 1.019162, bias2: 0.7980620861053467, variance: 0.2210996150970459\n",
      "Train size: [400] hidden size: [136] trial: 30, train_loss: 1.417054, test loss: 1.019703, bias2: 0.7978153228759766, variance: 0.22188785672187805\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [136] trial: 31, train_loss: 1.414660, test loss: 1.018635, bias2: 0.7974971532821655, variance: 0.22113777697086334\n",
      "Train size: [400] hidden size: [136] trial: 32, train_loss: 1.409997, test loss: 1.016479, bias2: 0.7961612939834595, variance: 0.22031748294830322\n",
      "Train size: [400] hidden size: [136] trial: 33, train_loss: 1.410325, test loss: 1.018316, bias2: 0.795348048210144, variance: 0.22296811640262604\n",
      "Train size: [400] hidden size: [136] trial: 34, train_loss: 1.407384, test loss: 1.020708, bias2: 0.7983841300010681, variance: 0.22232381999492645\n",
      "Train size: [400] hidden size: [136] trial: 35, train_loss: 1.409382, test loss: 1.021204, bias2: 0.7988081574440002, variance: 0.22239534556865692\n",
      "Train size: [400] hidden size: [136] trial: 36, train_loss: 1.407665, test loss: 1.019944, bias2: 0.7985426187515259, variance: 0.22140160202980042\n",
      "Train size: [400] hidden size: [136] trial: 37, train_loss: 1.402656, test loss: 1.020605, bias2: 0.8004717230796814, variance: 0.2201337367296219\n",
      "Train size: [400] hidden size: [136] trial: 38, train_loss: 1.403687, test loss: 1.020036, bias2: 0.7992040514945984, variance: 0.22083227336406708\n",
      "Train size: [400] hidden size: [136] trial: 39, train_loss: 1.409823, test loss: 1.020011, bias2: 0.7986701726913452, variance: 0.22134122252464294\n",
      "Train size: [400] hidden size: [136] trial: 40, train_loss: 1.413068, test loss: 1.020655, bias2: 0.7992140054702759, variance: 0.2214406579732895\n",
      "Train size: [400] hidden size: [136] trial: 41, train_loss: 1.409727, test loss: 1.022028, bias2: 0.799734354019165, variance: 0.22229400277137756\n",
      "Train size: [400] hidden size: [136] trial: 42, train_loss: 1.410788, test loss: 1.022090, bias2: 0.7988512516021729, variance: 0.22323846817016602\n",
      "Train size: [400] hidden size: [136] trial: 43, train_loss: 1.407386, test loss: 1.021031, bias2: 0.7984092831611633, variance: 0.22262173891067505\n",
      "Train size: [400] hidden size: [136] trial: 44, train_loss: 1.406426, test loss: 1.020084, bias2: 0.7964743375778198, variance: 0.2236095815896988\n",
      "Train size: [400] hidden size: [136] trial: 45, train_loss: 1.405038, test loss: 1.018997, bias2: 0.7959091067314148, variance: 0.22308821976184845\n",
      "Train size: [400] hidden size: [136] trial: 46, train_loss: 1.406631, test loss: 1.019546, bias2: 0.7967792749404907, variance: 0.22276708483695984\n",
      "Train size: [400] hidden size: [136] trial: 47, train_loss: 1.405489, test loss: 1.018482, bias2: 0.7959479689598083, variance: 0.22253374755382538\n",
      "Train size: [400] hidden size: [136] trial: 48, train_loss: 1.407127, test loss: 1.018239, bias2: 0.7949484586715698, variance: 0.223290354013443\n",
      "Train size: [400] hidden size: [136] trial: 49, train_loss: 1.411050, test loss: 1.018660, bias2: 0.7956022620201111, variance: 0.2230575531721115\n",
      "##################################################\n",
      "Train size: [400] hidden size: [156] trial: 0, train_loss: 1.422309, test loss: 1.035897, bias2: 1.035897135734558, variance: 3.8925479506346505e-10\n",
      "Train size: [400] hidden size: [156] trial: 1, train_loss: 1.431977, test loss: 1.038021, bias2: 0.882593035697937, variance: 0.15542802214622498\n",
      "Train size: [400] hidden size: [156] trial: 2, train_loss: 1.497812, test loss: 1.051243, bias2: 0.8515506982803345, variance: 0.1996924877166748\n",
      "Train size: [400] hidden size: [156] trial: 3, train_loss: 1.474992, test loss: 1.037798, bias2: 0.8246663808822632, variance: 0.21313177049160004\n",
      "Train size: [400] hidden size: [156] trial: 4, train_loss: 1.444792, test loss: 1.041325, bias2: 0.8154049515724182, variance: 0.22592048346996307\n",
      "Train size: [400] hidden size: [156] trial: 5, train_loss: 1.434486, test loss: 1.044211, bias2: 0.8163838386535645, variance: 0.22782708704471588\n",
      "Train size: [400] hidden size: [156] trial: 6, train_loss: 1.428617, test loss: 1.038352, bias2: 0.8036089539527893, variance: 0.23474343121051788\n",
      "Train size: [400] hidden size: [156] trial: 7, train_loss: 1.413641, test loss: 1.039623, bias2: 0.8018054366111755, variance: 0.23781783878803253\n",
      "Train size: [400] hidden size: [156] trial: 8, train_loss: 1.422824, test loss: 1.027336, bias2: 0.7866054773330688, variance: 0.24073030054569244\n",
      "Train size: [400] hidden size: [156] trial: 9, train_loss: 1.420799, test loss: 1.028944, bias2: 0.7871217727661133, variance: 0.2418227195739746\n",
      "Train size: [400] hidden size: [156] trial: 10, train_loss: 1.415188, test loss: 1.027260, bias2: 0.7847290635108948, variance: 0.24253089725971222\n",
      "Train size: [400] hidden size: [156] trial: 11, train_loss: 1.407789, test loss: 1.028097, bias2: 0.7821870446205139, variance: 0.24590963125228882\n",
      "Train size: [400] hidden size: [156] trial: 12, train_loss: 1.408152, test loss: 1.030419, bias2: 0.7781487703323364, variance: 0.2522701025009155\n",
      "Train size: [400] hidden size: [156] trial: 13, train_loss: 1.413258, test loss: 1.034546, bias2: 0.7795528769493103, variance: 0.25499314069747925\n",
      "Train size: [400] hidden size: [156] trial: 14, train_loss: 1.408780, test loss: 1.034985, bias2: 0.7799022197723389, variance: 0.2550829350948334\n",
      "Train size: [400] hidden size: [156] trial: 15, train_loss: 1.410078, test loss: 1.035937, bias2: 0.7794381380081177, variance: 0.25649914145469666\n",
      "Train size: [400] hidden size: [156] trial: 16, train_loss: 1.421749, test loss: 1.033108, bias2: 0.7770689129829407, variance: 0.25603896379470825\n",
      "Train size: [400] hidden size: [156] trial: 17, train_loss: 1.413748, test loss: 1.032635, bias2: 0.7756993770599365, variance: 0.25693535804748535\n",
      "Train size: [400] hidden size: [156] trial: 18, train_loss: 1.409373, test loss: 1.030926, bias2: 0.7725571990013123, variance: 0.25836843252182007\n",
      "Train size: [400] hidden size: [156] trial: 19, train_loss: 1.406562, test loss: 1.028671, bias2: 0.7706629037857056, variance: 0.2580077350139618\n",
      "Train size: [400] hidden size: [156] trial: 20, train_loss: 1.405601, test loss: 1.029144, bias2: 0.7719934582710266, variance: 0.25715070962905884\n",
      "Train size: [400] hidden size: [156] trial: 21, train_loss: 1.402421, test loss: 1.029383, bias2: 0.7671920657157898, variance: 0.26219063997268677\n",
      "Train size: [400] hidden size: [156] trial: 22, train_loss: 1.402240, test loss: 1.029854, bias2: 0.7676454782485962, variance: 0.26220881938934326\n",
      "Train size: [400] hidden size: [156] trial: 23, train_loss: 1.401528, test loss: 1.030730, bias2: 0.7693041563034058, variance: 0.2614254653453827\n",
      "Train size: [400] hidden size: [156] trial: 24, train_loss: 1.405265, test loss: 1.030931, bias2: 0.7672440409660339, variance: 0.26368647813796997\n",
      "Train size: [400] hidden size: [156] trial: 25, train_loss: 1.405405, test loss: 1.029848, bias2: 0.7653886675834656, variance: 0.26445919275283813\n",
      "Train size: [400] hidden size: [156] trial: 26, train_loss: 1.405138, test loss: 1.031933, bias2: 0.7650223970413208, variance: 0.2669103145599365\n",
      "Train size: [400] hidden size: [156] trial: 27, train_loss: 1.397936, test loss: 1.030700, bias2: 0.7636755704879761, variance: 0.2670241594314575\n",
      "Train size: [400] hidden size: [156] trial: 28, train_loss: 1.391049, test loss: 1.031158, bias2: 0.7670012712478638, variance: 0.26415637135505676\n",
      "Train size: [400] hidden size: [156] trial: 29, train_loss: 1.390286, test loss: 1.028455, bias2: 0.7644365429878235, variance: 0.26401883363723755\n",
      "Train size: [400] hidden size: [156] trial: 30, train_loss: 1.391856, test loss: 1.026838, bias2: 0.7630784511566162, variance: 0.2637597620487213\n",
      "Train size: [400] hidden size: [156] trial: 31, train_loss: 1.398931, test loss: 1.025954, bias2: 0.7621615529060364, variance: 0.2637922167778015\n",
      "Train size: [400] hidden size: [156] trial: 32, train_loss: 1.396538, test loss: 1.023723, bias2: 0.760783314704895, variance: 0.26294007897377014\n",
      "Train size: [400] hidden size: [156] trial: 33, train_loss: 1.393904, test loss: 1.023584, bias2: 0.760593593120575, variance: 0.2629907727241516\n",
      "Train size: [400] hidden size: [156] trial: 34, train_loss: 1.394038, test loss: 1.023973, bias2: 0.7598880529403687, variance: 0.2640845477581024\n",
      "Train size: [400] hidden size: [156] trial: 35, train_loss: 1.394804, test loss: 1.023156, bias2: 0.7601383924484253, variance: 0.2630174160003662\n",
      "Train size: [400] hidden size: [156] trial: 36, train_loss: 1.395860, test loss: 1.024131, bias2: 0.7609204053878784, variance: 0.263210266828537\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [156] trial: 37, train_loss: 1.394129, test loss: 1.024207, bias2: 0.7609661817550659, variance: 0.2632404863834381\n",
      "Train size: [400] hidden size: [156] trial: 38, train_loss: 1.395285, test loss: 1.025696, bias2: 0.761780858039856, variance: 0.26391473412513733\n",
      "Train size: [400] hidden size: [156] trial: 39, train_loss: 1.394873, test loss: 1.026030, bias2: 0.763541579246521, variance: 0.26248809695243835\n",
      "Train size: [400] hidden size: [156] trial: 40, train_loss: 1.393719, test loss: 1.025566, bias2: 0.7628577947616577, variance: 0.2627086639404297\n",
      "Train size: [400] hidden size: [156] trial: 41, train_loss: 1.391584, test loss: 1.028809, bias2: 0.7639282941818237, variance: 0.26488080620765686\n",
      "Train size: [400] hidden size: [156] trial: 42, train_loss: 1.389439, test loss: 1.028040, bias2: 0.7635864019393921, variance: 0.2644535005092621\n",
      "Train size: [400] hidden size: [156] trial: 43, train_loss: 1.390409, test loss: 1.028075, bias2: 0.7634912729263306, variance: 0.26458415389060974\n",
      "Train size: [400] hidden size: [156] trial: 44, train_loss: 1.388827, test loss: 1.028446, bias2: 0.7635141611099243, variance: 0.2649320065975189\n",
      "Train size: [400] hidden size: [156] trial: 45, train_loss: 1.388424, test loss: 1.028354, bias2: 0.7625526785850525, variance: 0.2658018469810486\n",
      "Train size: [400] hidden size: [156] trial: 46, train_loss: 1.387863, test loss: 1.028033, bias2: 0.7627180814743042, variance: 0.2653147280216217\n",
      "Train size: [400] hidden size: [156] trial: 47, train_loss: 1.388184, test loss: 1.028892, bias2: 0.7623589634895325, variance: 0.2665325999259949\n",
      "Train size: [400] hidden size: [156] trial: 48, train_loss: 1.387652, test loss: 1.028928, bias2: 0.762258768081665, variance: 0.2666691243648529\n",
      "Train size: [400] hidden size: [156] trial: 49, train_loss: 1.387239, test loss: 1.028542, bias2: 0.7622673511505127, variance: 0.2662747800350189\n",
      "##################################################\n",
      "Train size: [400] hidden size: [180] trial: 0, train_loss: 1.076920, test loss: 0.977803, bias2: 0.9778029322624207, variance: 7.785095901269301e-10\n",
      "Train size: [400] hidden size: [180] trial: 1, train_loss: 1.241165, test loss: 1.014620, bias2: 0.8511917591094971, variance: 0.16342797875404358\n",
      "Train size: [400] hidden size: [180] trial: 2, train_loss: 1.236663, test loss: 1.032637, bias2: 0.8134209513664246, variance: 0.21921654045581818\n",
      "Train size: [400] hidden size: [180] trial: 3, train_loss: 1.239909, test loss: 1.018672, bias2: 0.7784700393676758, variance: 0.2402021735906601\n",
      "Train size: [400] hidden size: [180] trial: 4, train_loss: 1.261862, test loss: 1.013232, bias2: 0.758699893951416, variance: 0.2545325756072998\n",
      "Train size: [400] hidden size: [180] trial: 5, train_loss: 1.258714, test loss: 1.022654, bias2: 0.7439374923706055, variance: 0.27871689200401306\n",
      "Train size: [400] hidden size: [180] trial: 6, train_loss: 1.244077, test loss: 1.019691, bias2: 0.7368168234825134, variance: 0.2828744053840637\n",
      "Train size: [400] hidden size: [180] trial: 7, train_loss: 1.233946, test loss: 1.024549, bias2: 0.7341047525405884, variance: 0.2904437780380249\n",
      "Train size: [400] hidden size: [180] trial: 8, train_loss: 1.239841, test loss: 1.022415, bias2: 0.7339123487472534, variance: 0.28850269317626953\n",
      "Train size: [400] hidden size: [180] trial: 9, train_loss: 1.249984, test loss: 1.012577, bias2: 0.726746678352356, variance: 0.2858307361602783\n",
      "Train size: [400] hidden size: [180] trial: 10, train_loss: 1.241755, test loss: 1.004055, bias2: 0.7219149470329285, variance: 0.28214019536972046\n",
      "Train size: [400] hidden size: [180] trial: 11, train_loss: 1.240780, test loss: 1.004601, bias2: 0.7225773930549622, variance: 0.28202348947525024\n",
      "Train size: [400] hidden size: [180] trial: 12, train_loss: 1.243985, test loss: 1.012116, bias2: 0.7284360527992249, variance: 0.2836797833442688\n",
      "Train size: [400] hidden size: [180] trial: 13, train_loss: 1.257502, test loss: 1.014163, bias2: 0.7292469143867493, variance: 0.28491657972335815\n",
      "Train size: [400] hidden size: [180] trial: 14, train_loss: 1.268618, test loss: 1.015688, bias2: 0.7304199934005737, variance: 0.2852684557437897\n",
      "Train size: [400] hidden size: [180] trial: 15, train_loss: 1.275078, test loss: 1.011998, bias2: 0.726223886013031, variance: 0.28577369451522827\n",
      "Train size: [400] hidden size: [180] trial: 16, train_loss: 1.273368, test loss: 1.014348, bias2: 0.7266206741333008, variance: 0.2877274751663208\n",
      "Train size: [400] hidden size: [180] trial: 17, train_loss: 1.278124, test loss: 1.015377, bias2: 0.7241032123565674, variance: 0.2912733554840088\n",
      "Train size: [400] hidden size: [180] trial: 18, train_loss: 1.275059, test loss: 1.019178, bias2: 0.7273054122924805, variance: 0.2918722629547119\n",
      "Train size: [400] hidden size: [180] trial: 19, train_loss: 1.266546, test loss: 1.022240, bias2: 0.7280450463294983, variance: 0.29419511556625366\n",
      "Train size: [400] hidden size: [180] trial: 20, train_loss: 1.261262, test loss: 1.020093, bias2: 0.7265169620513916, variance: 0.29357588291168213\n",
      "Train size: [400] hidden size: [180] trial: 21, train_loss: 1.262153, test loss: 1.015747, bias2: 0.7241532206535339, variance: 0.29159384965896606\n",
      "Train size: [400] hidden size: [180] trial: 22, train_loss: 1.268038, test loss: 1.017611, bias2: 0.7229273319244385, variance: 0.2946838140487671\n",
      "Train size: [400] hidden size: [180] trial: 23, train_loss: 1.264207, test loss: 1.019496, bias2: 0.7207807302474976, variance: 0.2987149953842163\n",
      "Train size: [400] hidden size: [180] trial: 24, train_loss: 1.264158, test loss: 1.020639, bias2: 0.7213962078094482, variance: 0.29924288392066956\n",
      "Train size: [400] hidden size: [180] trial: 25, train_loss: 1.264311, test loss: 1.020940, bias2: 0.722338080406189, variance: 0.29860201478004456\n",
      "Train size: [400] hidden size: [180] trial: 26, train_loss: 1.270140, test loss: 1.021859, bias2: 0.7229610085487366, variance: 0.29889851808547974\n",
      "Train size: [400] hidden size: [180] trial: 27, train_loss: 1.271943, test loss: 1.020871, bias2: 0.7249448299407959, variance: 0.2959260046482086\n",
      "Train size: [400] hidden size: [180] trial: 28, train_loss: 1.270046, test loss: 1.021129, bias2: 0.7249401807785034, variance: 0.2961888015270233\n",
      "Train size: [400] hidden size: [180] trial: 29, train_loss: 1.277652, test loss: 1.023578, bias2: 0.7274577021598816, variance: 0.29612070322036743\n",
      "Train size: [400] hidden size: [180] trial: 30, train_loss: 1.277392, test loss: 1.024851, bias2: 0.7290546894073486, variance: 0.29579678177833557\n",
      "Train size: [400] hidden size: [180] trial: 31, train_loss: 1.279145, test loss: 1.026224, bias2: 0.7306708693504333, variance: 0.2955532670021057\n",
      "Train size: [400] hidden size: [180] trial: 32, train_loss: 1.282696, test loss: 1.025633, bias2: 0.7318247556686401, variance: 0.2938086688518524\n",
      "Train size: [400] hidden size: [180] trial: 33, train_loss: 1.279173, test loss: 1.025932, bias2: 0.7326302528381348, variance: 0.2933017313480377\n",
      "Train size: [400] hidden size: [180] trial: 34, train_loss: 1.275756, test loss: 1.025094, bias2: 0.7326562404632568, variance: 0.2924377918243408\n",
      "Train size: [400] hidden size: [180] trial: 35, train_loss: 1.275755, test loss: 1.026632, bias2: 0.7320860624313354, variance: 0.2945460379123688\n",
      "Train size: [400] hidden size: [180] trial: 36, train_loss: 1.273944, test loss: 1.027562, bias2: 0.7332421541213989, variance: 0.29431965947151184\n",
      "Train size: [400] hidden size: [180] trial: 37, train_loss: 1.273679, test loss: 1.028982, bias2: 0.7340966463088989, variance: 0.29488539695739746\n",
      "Train size: [400] hidden size: [180] trial: 38, train_loss: 1.277360, test loss: 1.030021, bias2: 0.734277606010437, variance: 0.295743852853775\n",
      "Train size: [400] hidden size: [180] trial: 39, train_loss: 1.277340, test loss: 1.028354, bias2: 0.733108401298523, variance: 0.29524585604667664\n",
      "Train size: [400] hidden size: [180] trial: 40, train_loss: 1.279042, test loss: 1.028427, bias2: 0.7336137890815735, variance: 0.294813334941864\n",
      "Train size: [400] hidden size: [180] trial: 41, train_loss: 1.280034, test loss: 1.029551, bias2: 0.7316805720329285, variance: 0.29787081480026245\n",
      "Train size: [400] hidden size: [180] trial: 42, train_loss: 1.277609, test loss: 1.028302, bias2: 0.730463445186615, variance: 0.2978389859199524\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [180] trial: 43, train_loss: 1.278752, test loss: 1.028297, bias2: 0.7300477623939514, variance: 0.2982495427131653\n",
      "Train size: [400] hidden size: [180] trial: 44, train_loss: 1.277787, test loss: 1.028025, bias2: 0.7297415137290955, variance: 0.29828399419784546\n",
      "Train size: [400] hidden size: [180] trial: 45, train_loss: 1.275803, test loss: 1.027612, bias2: 0.7290486097335815, variance: 0.2985636293888092\n",
      "Train size: [400] hidden size: [180] trial: 46, train_loss: 1.276444, test loss: 1.027978, bias2: 0.7289865612983704, variance: 0.29899126291275024\n",
      "Train size: [400] hidden size: [180] trial: 47, train_loss: 1.276975, test loss: 1.027281, bias2: 0.7288104295730591, variance: 0.29847097396850586\n",
      "Train size: [400] hidden size: [180] trial: 48, train_loss: 1.277643, test loss: 1.029617, bias2: 0.7310903668403625, variance: 0.29852694272994995\n",
      "Train size: [400] hidden size: [180] trial: 49, train_loss: 1.279063, test loss: 1.031064, bias2: 0.7321776151657104, variance: 0.2988865077495575\n",
      "##################################################\n",
      "Train size: [400] hidden size: [207] trial: 0, train_loss: 1.167787, test loss: 1.052451, bias2: 1.052451252937317, variance: -3.8925479506346505e-10\n",
      "Train size: [400] hidden size: [207] trial: 1, train_loss: 1.267636, test loss: 1.056560, bias2: 0.8917179703712463, variance: 0.164842426776886\n",
      "Train size: [400] hidden size: [207] trial: 2, train_loss: 1.213860, test loss: 1.068175, bias2: 0.8412433862686157, variance: 0.22693189978599548\n",
      "Train size: [400] hidden size: [207] trial: 3, train_loss: 1.221356, test loss: 1.071577, bias2: 0.8126286864280701, variance: 0.25894874334335327\n",
      "Train size: [400] hidden size: [207] trial: 4, train_loss: 1.262682, test loss: 1.074759, bias2: 0.7946813106536865, variance: 0.28007733821868896\n",
      "Train size: [400] hidden size: [207] trial: 5, train_loss: 1.278331, test loss: 1.068415, bias2: 0.7835298776626587, variance: 0.28488507866859436\n",
      "Train size: [400] hidden size: [207] trial: 6, train_loss: 1.239046, test loss: 1.057978, bias2: 0.7690449953079224, variance: 0.28893259167671204\n",
      "Train size: [400] hidden size: [207] trial: 7, train_loss: 1.224375, test loss: 1.052313, bias2: 0.7580479979515076, variance: 0.2942654490470886\n",
      "Train size: [400] hidden size: [207] trial: 8, train_loss: 1.236661, test loss: 1.058752, bias2: 0.7519700527191162, variance: 0.3067823350429535\n",
      "Train size: [400] hidden size: [207] trial: 9, train_loss: 1.236227, test loss: 1.057231, bias2: 0.7471354007720947, variance: 0.3100953996181488\n",
      "Train size: [400] hidden size: [207] trial: 10, train_loss: 1.231185, test loss: 1.053782, bias2: 0.7410829067230225, variance: 0.31269893050193787\n",
      "Train size: [400] hidden size: [207] trial: 11, train_loss: 1.235473, test loss: 1.049658, bias2: 0.7409088611602783, variance: 0.30874860286712646\n",
      "Train size: [400] hidden size: [207] trial: 12, train_loss: 1.230415, test loss: 1.050441, bias2: 0.7384127378463745, variance: 0.3120279014110565\n",
      "Train size: [400] hidden size: [207] trial: 13, train_loss: 1.232819, test loss: 1.042488, bias2: 0.7337145209312439, variance: 0.30877333879470825\n",
      "Train size: [400] hidden size: [207] trial: 14, train_loss: 1.227667, test loss: 1.042177, bias2: 0.7360747456550598, variance: 0.30610185861587524\n",
      "Train size: [400] hidden size: [207] trial: 15, train_loss: 1.232691, test loss: 1.041449, bias2: 0.7283238768577576, variance: 0.3131254315376282\n",
      "Train size: [400] hidden size: [207] trial: 16, train_loss: 1.236341, test loss: 1.045708, bias2: 0.7283902168273926, variance: 0.3173178434371948\n",
      "Train size: [400] hidden size: [207] trial: 17, train_loss: 1.239265, test loss: 1.047745, bias2: 0.7233168482780457, variance: 0.32442861795425415\n",
      "Train size: [400] hidden size: [207] trial: 18, train_loss: 1.227801, test loss: 1.048724, bias2: 0.7227903604507446, variance: 0.3259335458278656\n",
      "Train size: [400] hidden size: [207] trial: 19, train_loss: 1.222801, test loss: 1.047265, bias2: 0.7233123779296875, variance: 0.3239530324935913\n",
      "Train size: [400] hidden size: [207] trial: 20, train_loss: 1.221391, test loss: 1.049885, bias2: 0.724459171295166, variance: 0.3254255950450897\n",
      "Train size: [400] hidden size: [207] trial: 21, train_loss: 1.215176, test loss: 1.047220, bias2: 0.7218756675720215, variance: 0.3253444731235504\n",
      "Train size: [400] hidden size: [207] trial: 22, train_loss: 1.215838, test loss: 1.045536, bias2: 0.7198678851127625, variance: 0.3256680369377136\n",
      "Train size: [400] hidden size: [207] trial: 23, train_loss: 1.214723, test loss: 1.045492, bias2: 0.7203947305679321, variance: 0.32509681582450867\n",
      "Train size: [400] hidden size: [207] trial: 24, train_loss: 1.216678, test loss: 1.045183, bias2: 0.7197794318199158, variance: 0.32540351152420044\n",
      "Train size: [400] hidden size: [207] trial: 25, train_loss: 1.210065, test loss: 1.046001, bias2: 0.7192971706390381, variance: 0.32670387625694275\n",
      "Train size: [400] hidden size: [207] trial: 26, train_loss: 1.207219, test loss: 1.044177, bias2: 0.718859851360321, variance: 0.3253169655799866\n",
      "Train size: [400] hidden size: [207] trial: 27, train_loss: 1.202460, test loss: 1.045082, bias2: 0.7173329591751099, variance: 0.3277488648891449\n",
      "Train size: [400] hidden size: [207] trial: 28, train_loss: 1.203863, test loss: 1.043718, bias2: 0.7146627902984619, variance: 0.3290553092956543\n",
      "Train size: [400] hidden size: [207] trial: 29, train_loss: 1.198669, test loss: 1.043771, bias2: 0.7139659523963928, variance: 0.3298047184944153\n",
      "Train size: [400] hidden size: [207] trial: 30, train_loss: 1.192342, test loss: 1.043399, bias2: 0.7144579887390137, variance: 0.32894137501716614\n",
      "Train size: [400] hidden size: [207] trial: 31, train_loss: 1.187427, test loss: 1.041568, bias2: 0.7119598984718323, variance: 0.3296082615852356\n",
      "Train size: [400] hidden size: [207] trial: 32, train_loss: 1.191011, test loss: 1.042175, bias2: 0.7135263085365295, variance: 0.3286486268043518\n",
      "Train size: [400] hidden size: [207] trial: 33, train_loss: 1.189003, test loss: 1.040409, bias2: 0.7130732536315918, variance: 0.3273358643054962\n",
      "Train size: [400] hidden size: [207] trial: 34, train_loss: 1.186985, test loss: 1.041740, bias2: 0.7133110165596008, variance: 0.3284289240837097\n",
      "Train size: [400] hidden size: [207] trial: 35, train_loss: 1.189616, test loss: 1.042236, bias2: 0.7109252214431763, variance: 0.3313112258911133\n",
      "Train size: [400] hidden size: [207] trial: 36, train_loss: 1.189949, test loss: 1.041950, bias2: 0.7104414105415344, variance: 0.3315085768699646\n",
      "Train size: [400] hidden size: [207] trial: 37, train_loss: 1.188820, test loss: 1.039968, bias2: 0.7087266445159912, variance: 0.3312417268753052\n",
      "Train size: [400] hidden size: [207] trial: 38, train_loss: 1.191197, test loss: 1.037576, bias2: 0.7047147750854492, variance: 0.3328615128993988\n",
      "Train size: [400] hidden size: [207] trial: 39, train_loss: 1.189483, test loss: 1.037016, bias2: 0.7043592929840088, variance: 0.33265653252601624\n",
      "Train size: [400] hidden size: [207] trial: 40, train_loss: 1.189386, test loss: 1.036875, bias2: 0.7040668725967407, variance: 0.33280766010284424\n",
      "Train size: [400] hidden size: [207] trial: 41, train_loss: 1.192323, test loss: 1.035063, bias2: 0.7022985219955444, variance: 0.3327641189098358\n",
      "Train size: [400] hidden size: [207] trial: 42, train_loss: 1.190507, test loss: 1.033899, bias2: 0.7004431486129761, variance: 0.3334555923938751\n",
      "Train size: [400] hidden size: [207] trial: 43, train_loss: 1.189532, test loss: 1.034435, bias2: 0.7006105184555054, variance: 0.3338242769241333\n",
      "Train size: [400] hidden size: [207] trial: 44, train_loss: 1.190279, test loss: 1.034836, bias2: 0.7011160850524902, variance: 0.33371976017951965\n",
      "Train size: [400] hidden size: [207] trial: 45, train_loss: 1.186274, test loss: 1.034788, bias2: 0.7000454664230347, variance: 0.3347420394420624\n",
      "Train size: [400] hidden size: [207] trial: 46, train_loss: 1.186482, test loss: 1.035541, bias2: 0.7018731832504272, variance: 0.33366790413856506\n",
      "Train size: [400] hidden size: [207] trial: 47, train_loss: 1.187971, test loss: 1.035400, bias2: 0.7024717330932617, variance: 0.33292874693870544\n",
      "Train size: [400] hidden size: [207] trial: 48, train_loss: 1.184909, test loss: 1.035630, bias2: 0.7021869421005249, variance: 0.33344292640686035\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [207] trial: 49, train_loss: 1.186754, test loss: 1.036116, bias2: 0.7034380435943604, variance: 0.33267757296562195\n",
      "##################################################\n",
      "Train size: [400] hidden size: [239] trial: 0, train_loss: 0.883688, test loss: 0.992201, bias2: 0.9922007918357849, variance: 2.724783731977709e-09\n",
      "Train size: [400] hidden size: [239] trial: 1, train_loss: 0.981769, test loss: 1.055809, bias2: 0.8600282669067383, variance: 0.19578027725219727\n",
      "Train size: [400] hidden size: [239] trial: 2, train_loss: 1.027156, test loss: 1.062963, bias2: 0.813934862613678, variance: 0.2490280270576477\n",
      "Train size: [400] hidden size: [239] trial: 3, train_loss: 1.055059, test loss: 1.052233, bias2: 0.7821205258369446, variance: 0.2701123356819153\n",
      "Train size: [400] hidden size: [239] trial: 4, train_loss: 1.068212, test loss: 1.079115, bias2: 0.7895178198814392, variance: 0.28959745168685913\n",
      "Train size: [400] hidden size: [239] trial: 5, train_loss: 1.075184, test loss: 1.056060, bias2: 0.7562696933746338, variance: 0.29979076981544495\n",
      "Train size: [400] hidden size: [239] trial: 6, train_loss: 1.097551, test loss: 1.053562, bias2: 0.7479194402694702, variance: 0.3056429922580719\n",
      "Train size: [400] hidden size: [239] trial: 7, train_loss: 1.120362, test loss: 1.054444, bias2: 0.7380356788635254, variance: 0.31640851497650146\n",
      "Train size: [400] hidden size: [239] trial: 8, train_loss: 1.113826, test loss: 1.046824, bias2: 0.7259265780448914, variance: 0.32089728116989136\n",
      "Train size: [400] hidden size: [239] trial: 9, train_loss: 1.114741, test loss: 1.054833, bias2: 0.7212249040603638, variance: 0.3336080014705658\n",
      "Train size: [400] hidden size: [239] trial: 10, train_loss: 1.098383, test loss: 1.056570, bias2: 0.7188630104064941, variance: 0.33770695328712463\n",
      "Train size: [400] hidden size: [239] trial: 11, train_loss: 1.097846, test loss: 1.056530, bias2: 0.7164803743362427, variance: 0.34004947543144226\n",
      "Train size: [400] hidden size: [239] trial: 12, train_loss: 1.103194, test loss: 1.060127, bias2: 0.7199159860610962, variance: 0.3402111530303955\n",
      "Train size: [400] hidden size: [239] trial: 13, train_loss: 1.095646, test loss: 1.055177, bias2: 0.7171635627746582, variance: 0.33801376819610596\n",
      "Train size: [400] hidden size: [239] trial: 14, train_loss: 1.104199, test loss: 1.065265, bias2: 0.7226118445396423, variance: 0.34265345335006714\n",
      "Train size: [400] hidden size: [239] trial: 15, train_loss: 1.111830, test loss: 1.067433, bias2: 0.7194739580154419, variance: 0.3479595184326172\n",
      "Train size: [400] hidden size: [239] trial: 16, train_loss: 1.106072, test loss: 1.064306, bias2: 0.7158461809158325, variance: 0.34845975041389465\n",
      "Train size: [400] hidden size: [239] trial: 17, train_loss: 1.099963, test loss: 1.063721, bias2: 0.7104630470275879, variance: 0.3532577455043793\n",
      "Train size: [400] hidden size: [239] trial: 18, train_loss: 1.095248, test loss: 1.060071, bias2: 0.7035398483276367, variance: 0.3565309941768646\n",
      "Train size: [400] hidden size: [239] trial: 19, train_loss: 1.096393, test loss: 1.061499, bias2: 0.7027863264083862, variance: 0.3587130606174469\n",
      "Train size: [400] hidden size: [239] trial: 20, train_loss: 1.093871, test loss: 1.063033, bias2: 0.7021363973617554, variance: 0.36089667677879333\n",
      "Train size: [400] hidden size: [239] trial: 21, train_loss: 1.091195, test loss: 1.061160, bias2: 0.7003709077835083, variance: 0.36078938841819763\n",
      "Train size: [400] hidden size: [239] trial: 22, train_loss: 1.094060, test loss: 1.061022, bias2: 0.6984049081802368, variance: 0.3626171350479126\n",
      "Train size: [400] hidden size: [239] trial: 23, train_loss: 1.100854, test loss: 1.062224, bias2: 0.6998051404953003, variance: 0.36241841316223145\n",
      "Train size: [400] hidden size: [239] trial: 24, train_loss: 1.100376, test loss: 1.065531, bias2: 0.7012555003166199, variance: 0.36427515745162964\n",
      "Train size: [400] hidden size: [239] trial: 25, train_loss: 1.104807, test loss: 1.064765, bias2: 0.6987816095352173, variance: 0.3659832179546356\n",
      "Train size: [400] hidden size: [239] trial: 26, train_loss: 1.101706, test loss: 1.062892, bias2: 0.6965737342834473, variance: 0.366318017244339\n",
      "Train size: [400] hidden size: [239] trial: 27, train_loss: 1.104355, test loss: 1.062586, bias2: 0.6943264007568359, variance: 0.36825987696647644\n",
      "Train size: [400] hidden size: [239] trial: 28, train_loss: 1.108390, test loss: 1.060203, bias2: 0.6918736696243286, variance: 0.36832940578460693\n",
      "Train size: [400] hidden size: [239] trial: 29, train_loss: 1.110598, test loss: 1.057321, bias2: 0.688962459564209, variance: 0.3683582842350006\n",
      "Train size: [400] hidden size: [239] trial: 30, train_loss: 1.109076, test loss: 1.054352, bias2: 0.6857433915138245, variance: 0.3686085343360901\n",
      "Train size: [400] hidden size: [239] trial: 31, train_loss: 1.114136, test loss: 1.053042, bias2: 0.6848719120025635, variance: 0.36816954612731934\n",
      "Train size: [400] hidden size: [239] trial: 32, train_loss: 1.106878, test loss: 1.053867, bias2: 0.6875247955322266, variance: 0.3663426637649536\n",
      "Train size: [400] hidden size: [239] trial: 33, train_loss: 1.106340, test loss: 1.052332, bias2: 0.6890991926193237, variance: 0.36323273181915283\n",
      "Train size: [400] hidden size: [239] trial: 34, train_loss: 1.107438, test loss: 1.052886, bias2: 0.6880886554718018, variance: 0.36479711532592773\n",
      "Train size: [400] hidden size: [239] trial: 35, train_loss: 1.107403, test loss: 1.051898, bias2: 0.6865108013153076, variance: 0.3653866946697235\n",
      "Train size: [400] hidden size: [239] trial: 36, train_loss: 1.107227, test loss: 1.051690, bias2: 0.6860365867614746, variance: 0.3656534254550934\n",
      "Train size: [400] hidden size: [239] trial: 37, train_loss: 1.108738, test loss: 1.052918, bias2: 0.6862488985061646, variance: 0.36666855216026306\n",
      "Train size: [400] hidden size: [239] trial: 38, train_loss: 1.110099, test loss: 1.051104, bias2: 0.686705470085144, variance: 0.3643984794616699\n",
      "Train size: [400] hidden size: [239] trial: 39, train_loss: 1.109421, test loss: 1.053338, bias2: 0.6885879039764404, variance: 0.3647497892379761\n",
      "Train size: [400] hidden size: [239] trial: 40, train_loss: 1.112519, test loss: 1.053590, bias2: 0.6887931823730469, variance: 0.3647972643375397\n",
      "Train size: [400] hidden size: [239] trial: 41, train_loss: 1.112773, test loss: 1.054829, bias2: 0.6905391216278076, variance: 0.364289790391922\n",
      "Train size: [400] hidden size: [239] trial: 42, train_loss: 1.115460, test loss: 1.054536, bias2: 0.6914970874786377, variance: 0.3630385100841522\n",
      "Train size: [400] hidden size: [239] trial: 43, train_loss: 1.116407, test loss: 1.054824, bias2: 0.6906708478927612, variance: 0.36415329575538635\n",
      "Train size: [400] hidden size: [239] trial: 44, train_loss: 1.113580, test loss: 1.054786, bias2: 0.6911107301712036, variance: 0.3636750876903534\n",
      "Train size: [400] hidden size: [239] trial: 45, train_loss: 1.113990, test loss: 1.054360, bias2: 0.6892648935317993, variance: 0.3650952875614166\n",
      "Train size: [400] hidden size: [239] trial: 46, train_loss: 1.112426, test loss: 1.053423, bias2: 0.6888747215270996, variance: 0.36454811692237854\n",
      "Train size: [400] hidden size: [239] trial: 47, train_loss: 1.111666, test loss: 1.052578, bias2: 0.6882697939872742, variance: 0.36430805921554565\n",
      "Train size: [400] hidden size: [239] trial: 48, train_loss: 1.110830, test loss: 1.050996, bias2: 0.686420202255249, variance: 0.3645760118961334\n",
      "Train size: [400] hidden size: [239] trial: 49, train_loss: 1.110899, test loss: 1.049100, bias2: 0.6849261522293091, variance: 0.3641737401485443\n",
      "##################################################\n",
      "Train size: [400] hidden size: [275] trial: 0, train_loss: 0.964439, test loss: 1.019878, bias2: 1.0198783874511719, variance: 2.3355288814030928e-09\n",
      "Train size: [400] hidden size: [275] trial: 1, train_loss: 0.998438, test loss: 1.058959, bias2: 0.8621596693992615, variance: 0.19679920375347137\n",
      "Train size: [400] hidden size: [275] trial: 2, train_loss: 1.011774, test loss: 1.058678, bias2: 0.7780786752700806, variance: 0.280599445104599\n",
      "Train size: [400] hidden size: [275] trial: 3, train_loss: 1.026046, test loss: 1.064353, bias2: 0.7469371557235718, variance: 0.3174159824848175\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [275] trial: 4, train_loss: 1.000940, test loss: 1.064253, bias2: 0.7310243844985962, variance: 0.333228200674057\n",
      "Train size: [400] hidden size: [275] trial: 5, train_loss: 1.023978, test loss: 1.092793, bias2: 0.7350202798843384, variance: 0.3577730655670166\n",
      "Train size: [400] hidden size: [275] trial: 6, train_loss: 1.028083, test loss: 1.073707, bias2: 0.7084489464759827, variance: 0.3652579188346863\n",
      "Train size: [400] hidden size: [275] trial: 7, train_loss: 1.030350, test loss: 1.078809, bias2: 0.7077350616455078, variance: 0.37107405066490173\n",
      "Train size: [400] hidden size: [275] trial: 8, train_loss: 1.027189, test loss: 1.074504, bias2: 0.7065573930740356, variance: 0.3679470717906952\n",
      "Train size: [400] hidden size: [275] trial: 9, train_loss: 1.014877, test loss: 1.071793, bias2: 0.6939167976379395, variance: 0.37787654995918274\n",
      "Train size: [400] hidden size: [275] trial: 10, train_loss: 1.005586, test loss: 1.076656, bias2: 0.6923176050186157, variance: 0.38433825969696045\n",
      "Train size: [400] hidden size: [275] trial: 11, train_loss: 1.012920, test loss: 1.073799, bias2: 0.6913992166519165, variance: 0.38239941000938416\n",
      "Train size: [400] hidden size: [275] trial: 12, train_loss: 1.000659, test loss: 1.071478, bias2: 0.687981128692627, variance: 0.383497029542923\n",
      "Train size: [400] hidden size: [275] trial: 13, train_loss: 1.001070, test loss: 1.072033, bias2: 0.6889851689338684, variance: 0.3830476403236389\n",
      "Train size: [400] hidden size: [275] trial: 14, train_loss: 1.016315, test loss: 1.069440, bias2: 0.6868249177932739, variance: 0.38261470198631287\n",
      "Train size: [400] hidden size: [275] trial: 15, train_loss: 1.015312, test loss: 1.071015, bias2: 0.6840013265609741, variance: 0.38701388239860535\n",
      "Train size: [400] hidden size: [275] trial: 16, train_loss: 1.017536, test loss: 1.070739, bias2: 0.6768467426300049, variance: 0.3938923180103302\n",
      "Train size: [400] hidden size: [275] trial: 17, train_loss: 1.018389, test loss: 1.071789, bias2: 0.6745867133140564, variance: 0.39720267057418823\n",
      "Train size: [400] hidden size: [275] trial: 18, train_loss: 1.018901, test loss: 1.065128, bias2: 0.6683381795883179, variance: 0.3967895805835724\n",
      "Train size: [400] hidden size: [275] trial: 19, train_loss: 1.020341, test loss: 1.065337, bias2: 0.666951060295105, variance: 0.3983863294124603\n",
      "Train size: [400] hidden size: [275] trial: 20, train_loss: 1.017257, test loss: 1.064244, bias2: 0.661092221736908, variance: 0.40315181016921997\n",
      "Train size: [400] hidden size: [275] trial: 21, train_loss: 1.017117, test loss: 1.063417, bias2: 0.6627839803695679, variance: 0.40063318610191345\n",
      "Train size: [400] hidden size: [275] trial: 22, train_loss: 1.013908, test loss: 1.058840, bias2: 0.6613353490829468, variance: 0.39750441908836365\n",
      "Train size: [400] hidden size: [275] trial: 23, train_loss: 1.021475, test loss: 1.061771, bias2: 0.6622496843338013, variance: 0.3995215594768524\n",
      "Train size: [400] hidden size: [275] trial: 24, train_loss: 1.017357, test loss: 1.058989, bias2: 0.6594916582107544, variance: 0.3994978666305542\n",
      "Train size: [400] hidden size: [275] trial: 25, train_loss: 1.020765, test loss: 1.055322, bias2: 0.6556943655014038, variance: 0.3996281325817108\n",
      "Train size: [400] hidden size: [275] trial: 26, train_loss: 1.018654, test loss: 1.055931, bias2: 0.6557645797729492, variance: 0.40016600489616394\n",
      "Train size: [400] hidden size: [275] trial: 27, train_loss: 1.018639, test loss: 1.053897, bias2: 0.6541156768798828, variance: 0.399781733751297\n",
      "Train size: [400] hidden size: [275] trial: 28, train_loss: 1.014907, test loss: 1.052147, bias2: 0.6507265567779541, variance: 0.40142011642456055\n",
      "Train size: [400] hidden size: [275] trial: 29, train_loss: 1.020000, test loss: 1.051523, bias2: 0.6503432989120483, variance: 0.401179701089859\n",
      "Train size: [400] hidden size: [275] trial: 30, train_loss: 1.021836, test loss: 1.052620, bias2: 0.6504992842674255, variance: 0.40212100744247437\n",
      "Train size: [400] hidden size: [275] trial: 31, train_loss: 1.024407, test loss: 1.052342, bias2: 0.6489189863204956, variance: 0.4034230709075928\n",
      "Train size: [400] hidden size: [275] trial: 32, train_loss: 1.025215, test loss: 1.053525, bias2: 0.6481163501739502, variance: 0.4054085314273834\n",
      "Train size: [400] hidden size: [275] trial: 33, train_loss: 1.022011, test loss: 1.053981, bias2: 0.6482071876525879, variance: 0.4057735502719879\n",
      "Train size: [400] hidden size: [275] trial: 34, train_loss: 1.021637, test loss: 1.053294, bias2: 0.6475602984428406, variance: 0.4057338833808899\n",
      "Train size: [400] hidden size: [275] trial: 35, train_loss: 1.021611, test loss: 1.051196, bias2: 0.6455198526382446, variance: 0.4056761562824249\n",
      "Train size: [400] hidden size: [275] trial: 36, train_loss: 1.020421, test loss: 1.053875, bias2: 0.6464381217956543, variance: 0.4074367582798004\n",
      "Train size: [400] hidden size: [275] trial: 37, train_loss: 1.021815, test loss: 1.056169, bias2: 0.6468976736068726, variance: 0.4092709720134735\n",
      "Train size: [400] hidden size: [275] trial: 38, train_loss: 1.025817, test loss: 1.053424, bias2: 0.6447024345397949, variance: 0.40872180461883545\n",
      "Train size: [400] hidden size: [275] trial: 39, train_loss: 1.026681, test loss: 1.054836, bias2: 0.644744873046875, variance: 0.410090833902359\n",
      "Train size: [400] hidden size: [275] trial: 40, train_loss: 1.024548, test loss: 1.055564, bias2: 0.6445568203926086, variance: 0.41100698709487915\n",
      "Train size: [400] hidden size: [275] trial: 41, train_loss: 1.025317, test loss: 1.055705, bias2: 0.6423782110214233, variance: 0.41332706809043884\n",
      "Train size: [400] hidden size: [275] trial: 42, train_loss: 1.022741, test loss: 1.055185, bias2: 0.6428819894790649, variance: 0.41230320930480957\n",
      "Train size: [400] hidden size: [275] trial: 43, train_loss: 1.023544, test loss: 1.054961, bias2: 0.6419590711593628, variance: 0.4130016565322876\n",
      "Train size: [400] hidden size: [275] trial: 44, train_loss: 1.022253, test loss: 1.053849, bias2: 0.6406528949737549, variance: 0.4131965637207031\n",
      "Train size: [400] hidden size: [275] trial: 45, train_loss: 1.018339, test loss: 1.053562, bias2: 0.6379856467247009, variance: 0.4155767560005188\n",
      "Train size: [400] hidden size: [275] trial: 46, train_loss: 1.017814, test loss: 1.053399, bias2: 0.6385588645935059, variance: 0.41484060883522034\n",
      "Train size: [400] hidden size: [275] trial: 47, train_loss: 1.017318, test loss: 1.052635, bias2: 0.6389327049255371, variance: 0.4137023389339447\n",
      "Train size: [400] hidden size: [275] trial: 48, train_loss: 1.017180, test loss: 1.052792, bias2: 0.6398000717163086, variance: 0.41299203038215637\n",
      "Train size: [400] hidden size: [275] trial: 49, train_loss: 1.018725, test loss: 1.053244, bias2: 0.6401827335357666, variance: 0.4130607545375824\n",
      "##################################################\n",
      "Train size: [400] hidden size: [316] trial: 0, train_loss: 1.002881, test loss: 1.037895, bias2: 1.037894606590271, variance: 4.281802912231569e-09\n",
      "Train size: [400] hidden size: [316] trial: 1, train_loss: 0.935459, test loss: 1.098770, bias2: 0.8349283933639526, variance: 0.2638412415981293\n",
      "Train size: [400] hidden size: [316] trial: 2, train_loss: 0.957383, test loss: 1.097548, bias2: 0.7390767335891724, variance: 0.3584713041782379\n",
      "Train size: [400] hidden size: [316] trial: 3, train_loss: 0.936190, test loss: 1.081624, bias2: 0.6962994337081909, variance: 0.3853248655796051\n",
      "Train size: [400] hidden size: [316] trial: 4, train_loss: 0.964357, test loss: 1.077683, bias2: 0.6738972067832947, variance: 0.40378624200820923\n",
      "Train size: [400] hidden size: [316] trial: 5, train_loss: 0.964620, test loss: 1.065461, bias2: 0.6690436601638794, variance: 0.3964172899723053\n",
      "Train size: [400] hidden size: [316] trial: 6, train_loss: 0.969214, test loss: 1.066146, bias2: 0.6731542348861694, variance: 0.39299193024635315\n",
      "Train size: [400] hidden size: [316] trial: 7, train_loss: 0.959017, test loss: 1.066047, bias2: 0.6697000861167908, variance: 0.3963471055030823\n",
      "Train size: [400] hidden size: [316] trial: 8, train_loss: 0.955095, test loss: 1.064920, bias2: 0.6614574790000916, variance: 0.4034622311592102\n",
      "Train size: [400] hidden size: [316] trial: 9, train_loss: 0.946401, test loss: 1.063117, bias2: 0.6536154747009277, variance: 0.4095015525817871\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [316] trial: 10, train_loss: 0.938674, test loss: 1.057835, bias2: 0.6463170647621155, variance: 0.4115181565284729\n",
      "Train size: [400] hidden size: [316] trial: 11, train_loss: 0.936283, test loss: 1.056240, bias2: 0.64787757396698, variance: 0.40836262702941895\n",
      "Train size: [400] hidden size: [316] trial: 12, train_loss: 0.941195, test loss: 1.059006, bias2: 0.6489049196243286, variance: 0.4101013243198395\n",
      "Train size: [400] hidden size: [316] trial: 13, train_loss: 0.933179, test loss: 1.058463, bias2: 0.6450061798095703, variance: 0.4134570062160492\n",
      "Train size: [400] hidden size: [316] trial: 14, train_loss: 0.934673, test loss: 1.059773, bias2: 0.641028881072998, variance: 0.41874420642852783\n",
      "Train size: [400] hidden size: [316] trial: 15, train_loss: 0.929959, test loss: 1.063742, bias2: 0.6430743932723999, variance: 0.4206681549549103\n",
      "Train size: [400] hidden size: [316] trial: 16, train_loss: 0.926496, test loss: 1.064831, bias2: 0.6444751620292664, variance: 0.42035549879074097\n",
      "Train size: [400] hidden size: [316] trial: 17, train_loss: 0.926190, test loss: 1.061978, bias2: 0.6406558156013489, variance: 0.42132192850112915\n",
      "Train size: [400] hidden size: [316] trial: 18, train_loss: 0.923436, test loss: 1.061486, bias2: 0.6362472772598267, variance: 0.4252389371395111\n",
      "Train size: [400] hidden size: [316] trial: 19, train_loss: 0.930682, test loss: 1.067003, bias2: 0.6365143060684204, variance: 0.43048909306526184\n",
      "Train size: [400] hidden size: [316] trial: 20, train_loss: 0.925937, test loss: 1.067454, bias2: 0.6387471556663513, variance: 0.4287063479423523\n",
      "Train size: [400] hidden size: [316] trial: 21, train_loss: 0.925349, test loss: 1.068056, bias2: 0.6346169710159302, variance: 0.4334387481212616\n",
      "Train size: [400] hidden size: [316] trial: 22, train_loss: 0.931816, test loss: 1.064512, bias2: 0.6295676231384277, variance: 0.43494465947151184\n",
      "Train size: [400] hidden size: [316] trial: 23, train_loss: 0.928988, test loss: 1.063063, bias2: 0.6282780170440674, variance: 0.43478456139564514\n",
      "Train size: [400] hidden size: [316] trial: 24, train_loss: 0.923736, test loss: 1.065694, bias2: 0.630707323551178, variance: 0.4349868893623352\n",
      "Train size: [400] hidden size: [316] trial: 25, train_loss: 0.925748, test loss: 1.065802, bias2: 0.632104754447937, variance: 0.4336971938610077\n",
      "Train size: [400] hidden size: [316] trial: 26, train_loss: 0.929764, test loss: 1.064347, bias2: 0.628176212310791, variance: 0.4361708462238312\n",
      "Train size: [400] hidden size: [316] trial: 27, train_loss: 0.934460, test loss: 1.060715, bias2: 0.6258800029754639, variance: 0.43483495712280273\n",
      "Train size: [400] hidden size: [316] trial: 28, train_loss: 0.928790, test loss: 1.060645, bias2: 0.6273380517959595, variance: 0.4333072900772095\n",
      "Train size: [400] hidden size: [316] trial: 29, train_loss: 0.927276, test loss: 1.061298, bias2: 0.6261001825332642, variance: 0.4351973533630371\n",
      "Train size: [400] hidden size: [316] trial: 30, train_loss: 0.930070, test loss: 1.060028, bias2: 0.6262403726577759, variance: 0.4337875545024872\n",
      "Train size: [400] hidden size: [316] trial: 31, train_loss: 0.927809, test loss: 1.059753, bias2: 0.6260278224945068, variance: 0.43372491002082825\n",
      "Train size: [400] hidden size: [316] trial: 32, train_loss: 0.928149, test loss: 1.060300, bias2: 0.6252646446228027, variance: 0.43503543734550476\n",
      "Train size: [400] hidden size: [316] trial: 33, train_loss: 0.927909, test loss: 1.060367, bias2: 0.6238846778869629, variance: 0.436482310295105\n",
      "Train size: [400] hidden size: [316] trial: 34, train_loss: 0.929647, test loss: 1.060747, bias2: 0.6222455501556396, variance: 0.4385010004043579\n",
      "Train size: [400] hidden size: [316] trial: 35, train_loss: 0.926459, test loss: 1.059214, bias2: 0.6220565438270569, variance: 0.4371578097343445\n",
      "Train size: [400] hidden size: [316] trial: 36, train_loss: 0.925450, test loss: 1.058961, bias2: 0.6198999285697937, variance: 0.43906086683273315\n",
      "Train size: [400] hidden size: [316] trial: 37, train_loss: 0.924634, test loss: 1.059935, bias2: 0.6210264563560486, variance: 0.4389081597328186\n",
      "Train size: [400] hidden size: [316] trial: 38, train_loss: 0.924444, test loss: 1.057037, bias2: 0.6202548742294312, variance: 0.4367823898792267\n",
      "Train size: [400] hidden size: [316] trial: 39, train_loss: 0.924862, test loss: 1.057676, bias2: 0.6189274191856384, variance: 0.438748300075531\n",
      "Train size: [400] hidden size: [316] trial: 40, train_loss: 0.923324, test loss: 1.058280, bias2: 0.6204350590705872, variance: 0.43784505128860474\n",
      "Train size: [400] hidden size: [316] trial: 41, train_loss: 0.922860, test loss: 1.058385, bias2: 0.6194971799850464, variance: 0.4388880729675293\n",
      "Train size: [400] hidden size: [316] trial: 42, train_loss: 0.924552, test loss: 1.061572, bias2: 0.6201177835464478, variance: 0.4414536952972412\n",
      "Train size: [400] hidden size: [316] trial: 43, train_loss: 0.921723, test loss: 1.060446, bias2: 0.6198965311050415, variance: 0.44054946303367615\n",
      "Train size: [400] hidden size: [316] trial: 44, train_loss: 0.921163, test loss: 1.061203, bias2: 0.6196221113204956, variance: 0.441581130027771\n",
      "Train size: [400] hidden size: [316] trial: 45, train_loss: 0.923548, test loss: 1.061298, bias2: 0.6203905344009399, variance: 0.4409073293209076\n",
      "Train size: [400] hidden size: [316] trial: 46, train_loss: 0.921766, test loss: 1.060002, bias2: 0.6195453405380249, variance: 0.4404565095901489\n",
      "Train size: [400] hidden size: [316] trial: 47, train_loss: 0.924134, test loss: 1.060648, bias2: 0.6185745596885681, variance: 0.44207292795181274\n",
      "Train size: [400] hidden size: [316] trial: 48, train_loss: 0.925840, test loss: 1.060595, bias2: 0.6163606643676758, variance: 0.4442342519760132\n",
      "Train size: [400] hidden size: [316] trial: 49, train_loss: 0.925093, test loss: 1.059920, bias2: 0.6147768497467041, variance: 0.44514355063438416\n",
      "##################################################\n",
      "Train size: [400] hidden size: [364] trial: 0, train_loss: 0.884017, test loss: 1.144251, bias2: 1.1442513465881348, variance: 6.228076721015441e-09\n",
      "Train size: [400] hidden size: [364] trial: 1, train_loss: 0.875215, test loss: 1.143337, bias2: 0.880961537361145, variance: 0.2623756229877472\n",
      "Train size: [400] hidden size: [364] trial: 2, train_loss: 0.894857, test loss: 1.113877, bias2: 0.7575034499168396, variance: 0.35637325048446655\n",
      "Train size: [400] hidden size: [364] trial: 3, train_loss: 0.876146, test loss: 1.098616, bias2: 0.7015731930732727, variance: 0.3970431685447693\n",
      "Train size: [400] hidden size: [364] trial: 4, train_loss: 0.858321, test loss: 1.062715, bias2: 0.6572253704071045, variance: 0.40548989176750183\n",
      "Train size: [400] hidden size: [364] trial: 5, train_loss: 0.871609, test loss: 1.064206, bias2: 0.6484600901603699, variance: 0.41574591398239136\n",
      "Train size: [400] hidden size: [364] trial: 6, train_loss: 0.862422, test loss: 1.075014, bias2: 0.6258817911148071, variance: 0.4491325616836548\n",
      "Train size: [400] hidden size: [364] trial: 7, train_loss: 0.839520, test loss: 1.066789, bias2: 0.6166425943374634, variance: 0.45014676451683044\n",
      "Train size: [400] hidden size: [364] trial: 8, train_loss: 0.832224, test loss: 1.077842, bias2: 0.6099579334259033, variance: 0.46788379549980164\n",
      "Train size: [400] hidden size: [364] trial: 9, train_loss: 0.837168, test loss: 1.082570, bias2: 0.6060739755630493, variance: 0.47649598121643066\n",
      "Train size: [400] hidden size: [364] trial: 10, train_loss: 0.831176, test loss: 1.080608, bias2: 0.6073430776596069, variance: 0.4732649624347687\n",
      "Train size: [400] hidden size: [364] trial: 11, train_loss: 0.839714, test loss: 1.071040, bias2: 0.598263144493103, variance: 0.47277703881263733\n",
      "Train size: [400] hidden size: [364] trial: 12, train_loss: 0.842703, test loss: 1.072659, bias2: 0.5970531702041626, variance: 0.47560593485832214\n",
      "Train size: [400] hidden size: [364] trial: 13, train_loss: 0.847344, test loss: 1.075305, bias2: 0.5913167595863342, variance: 0.4839882254600525\n",
      "Train size: [400] hidden size: [364] trial: 14, train_loss: 0.849319, test loss: 1.074503, bias2: 0.5923705101013184, variance: 0.4821324050426483\n",
      "Train size: [400] hidden size: [364] trial: 15, train_loss: 0.852810, test loss: 1.076836, bias2: 0.592474102973938, variance: 0.4843623638153076\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [364] trial: 16, train_loss: 0.853785, test loss: 1.072297, bias2: 0.5864219665527344, variance: 0.48587486147880554\n",
      "Train size: [400] hidden size: [364] trial: 17, train_loss: 0.845765, test loss: 1.073960, bias2: 0.5856860876083374, variance: 0.4882742464542389\n",
      "Train size: [400] hidden size: [364] trial: 18, train_loss: 0.843974, test loss: 1.077309, bias2: 0.58539879322052, variance: 0.49191030859947205\n",
      "Train size: [400] hidden size: [364] trial: 19, train_loss: 0.839451, test loss: 1.074677, bias2: 0.5812023878097534, variance: 0.4934745132923126\n",
      "Train size: [400] hidden size: [364] trial: 20, train_loss: 0.839653, test loss: 1.072964, bias2: 0.5771636962890625, variance: 0.49580028653144836\n",
      "Train size: [400] hidden size: [364] trial: 21, train_loss: 0.836341, test loss: 1.069014, bias2: 0.5730940103530884, variance: 0.49592018127441406\n",
      "Train size: [400] hidden size: [364] trial: 22, train_loss: 0.836530, test loss: 1.070748, bias2: 0.5729936361312866, variance: 0.49775466322898865\n",
      "Train size: [400] hidden size: [364] trial: 23, train_loss: 0.838753, test loss: 1.070187, bias2: 0.5725076794624329, variance: 0.4976791739463806\n",
      "Train size: [400] hidden size: [364] trial: 24, train_loss: 0.838550, test loss: 1.066530, bias2: 0.5703691244125366, variance: 0.4961608946323395\n",
      "Train size: [400] hidden size: [364] trial: 25, train_loss: 0.840357, test loss: 1.063928, bias2: 0.5662105083465576, variance: 0.4977174699306488\n",
      "Train size: [400] hidden size: [364] trial: 26, train_loss: 0.835834, test loss: 1.061516, bias2: 0.5673832893371582, variance: 0.4941326379776001\n",
      "Train size: [400] hidden size: [364] trial: 27, train_loss: 0.841109, test loss: 1.062968, bias2: 0.5684159994125366, variance: 0.49455204606056213\n",
      "Train size: [400] hidden size: [364] trial: 28, train_loss: 0.840488, test loss: 1.059598, bias2: 0.5675758719444275, variance: 0.4920223355293274\n",
      "Train size: [400] hidden size: [364] trial: 29, train_loss: 0.834628, test loss: 1.056837, bias2: 0.5647881031036377, variance: 0.4920487701892853\n",
      "Train size: [400] hidden size: [364] trial: 30, train_loss: 0.831272, test loss: 1.056877, bias2: 0.5634920001029968, variance: 0.4933854937553406\n",
      "Train size: [400] hidden size: [364] trial: 31, train_loss: 0.831191, test loss: 1.060376, bias2: 0.5650100708007812, variance: 0.4953659772872925\n",
      "Train size: [400] hidden size: [364] trial: 32, train_loss: 0.831624, test loss: 1.061167, bias2: 0.5659224987030029, variance: 0.4952445328235626\n",
      "Train size: [400] hidden size: [364] trial: 33, train_loss: 0.831345, test loss: 1.060170, bias2: 0.5651869177818298, variance: 0.4949827790260315\n",
      "Train size: [400] hidden size: [364] trial: 34, train_loss: 0.829546, test loss: 1.059316, bias2: 0.5654796957969666, variance: 0.49383634328842163\n",
      "Train size: [400] hidden size: [364] trial: 35, train_loss: 0.827727, test loss: 1.058718, bias2: 0.5665243864059448, variance: 0.49219322204589844\n",
      "Train size: [400] hidden size: [364] trial: 36, train_loss: 0.826626, test loss: 1.059172, bias2: 0.5692558884620667, variance: 0.4899159073829651\n",
      "Train size: [400] hidden size: [364] trial: 37, train_loss: 0.824503, test loss: 1.059802, bias2: 0.5697361826896667, variance: 0.49006563425064087\n",
      "Train size: [400] hidden size: [364] trial: 38, train_loss: 0.822581, test loss: 1.057256, bias2: 0.5692344307899475, variance: 0.4880219101905823\n",
      "Train size: [400] hidden size: [364] trial: 39, train_loss: 0.822902, test loss: 1.054809, bias2: 0.5680893063545227, variance: 0.4867200255393982\n",
      "Train size: [400] hidden size: [364] trial: 40, train_loss: 0.819774, test loss: 1.055997, bias2: 0.5679721832275391, variance: 0.4880248010158539\n",
      "Train size: [400] hidden size: [364] trial: 41, train_loss: 0.818806, test loss: 1.056324, bias2: 0.5677089691162109, variance: 0.48861536383628845\n",
      "Train size: [400] hidden size: [364] trial: 42, train_loss: 0.815706, test loss: 1.057013, bias2: 0.5689017176628113, variance: 0.488111674785614\n",
      "Train size: [400] hidden size: [364] trial: 43, train_loss: 0.816202, test loss: 1.056516, bias2: 0.5703903436660767, variance: 0.4861259460449219\n",
      "Train size: [400] hidden size: [364] trial: 44, train_loss: 0.818371, test loss: 1.056365, bias2: 0.569226861000061, variance: 0.487138032913208\n",
      "Train size: [400] hidden size: [364] trial: 45, train_loss: 0.819626, test loss: 1.056338, bias2: 0.5685405135154724, variance: 0.48779720067977905\n",
      "Train size: [400] hidden size: [364] trial: 46, train_loss: 0.819471, test loss: 1.057726, bias2: 0.5700716972351074, variance: 0.4876546859741211\n",
      "Train size: [400] hidden size: [364] trial: 47, train_loss: 0.817676, test loss: 1.056085, bias2: 0.5694088339805603, variance: 0.4866756796836853\n",
      "Train size: [400] hidden size: [364] trial: 48, train_loss: 0.818132, test loss: 1.056193, bias2: 0.5690961480140686, variance: 0.48709672689437866\n",
      "Train size: [400] hidden size: [364] trial: 49, train_loss: 0.818034, test loss: 1.057149, bias2: 0.5691399574279785, variance: 0.48800864815711975\n",
      "##################################################\n",
      "Train size: [400] hidden size: [419] trial: 0, train_loss: 0.756790, test loss: 1.014144, bias2: 1.014143705368042, variance: 7.785095901269301e-10\n",
      "Train size: [400] hidden size: [419] trial: 1, train_loss: 0.672358, test loss: 1.011683, bias2: 0.757328450679779, variance: 0.25435465574264526\n",
      "Train size: [400] hidden size: [419] trial: 2, train_loss: 0.688548, test loss: 0.998573, bias2: 0.6844609975814819, variance: 0.3141123950481415\n",
      "Train size: [400] hidden size: [419] trial: 3, train_loss: 0.709719, test loss: 0.997099, bias2: 0.6393461227416992, variance: 0.35775259137153625\n",
      "Train size: [400] hidden size: [419] trial: 4, train_loss: 0.731931, test loss: 1.001288, bias2: 0.6082125902175903, variance: 0.3930758237838745\n",
      "Train size: [400] hidden size: [419] trial: 5, train_loss: 0.754068, test loss: 1.021725, bias2: 0.60300213098526, variance: 0.4187226891517639\n",
      "Train size: [400] hidden size: [419] trial: 6, train_loss: 0.755336, test loss: 1.034263, bias2: 0.600976824760437, variance: 0.4332859218120575\n",
      "Train size: [400] hidden size: [419] trial: 7, train_loss: 0.749166, test loss: 1.037766, bias2: 0.5935883522033691, variance: 0.44417762756347656\n",
      "Train size: [400] hidden size: [419] trial: 8, train_loss: 0.750165, test loss: 1.038551, bias2: 0.5867114663124084, variance: 0.45183998346328735\n",
      "Train size: [400] hidden size: [419] trial: 9, train_loss: 0.743687, test loss: 1.029495, bias2: 0.5724407434463501, variance: 0.45705416798591614\n",
      "Train size: [400] hidden size: [419] trial: 10, train_loss: 0.734508, test loss: 1.028624, bias2: 0.5717778205871582, variance: 0.4568463861942291\n",
      "Train size: [400] hidden size: [419] trial: 11, train_loss: 0.741917, test loss: 1.035765, bias2: 0.5687110424041748, variance: 0.46705350279808044\n",
      "Train size: [400] hidden size: [419] trial: 12, train_loss: 0.745537, test loss: 1.043034, bias2: 0.5712307691574097, variance: 0.4718034565448761\n",
      "Train size: [400] hidden size: [419] trial: 13, train_loss: 0.746628, test loss: 1.053610, bias2: 0.5759583711624146, variance: 0.4776512086391449\n",
      "Train size: [400] hidden size: [419] trial: 14, train_loss: 0.747590, test loss: 1.046843, bias2: 0.5677912831306458, variance: 0.47905153036117554\n",
      "Train size: [400] hidden size: [419] trial: 15, train_loss: 0.744184, test loss: 1.045968, bias2: 0.5677267909049988, variance: 0.4782407879829407\n",
      "Train size: [400] hidden size: [419] trial: 16, train_loss: 0.746757, test loss: 1.046740, bias2: 0.5656917095184326, variance: 0.48104873299598694\n",
      "Train size: [400] hidden size: [419] trial: 17, train_loss: 0.744256, test loss: 1.051179, bias2: 0.5674451589584351, variance: 0.4837338924407959\n",
      "Train size: [400] hidden size: [419] trial: 18, train_loss: 0.745731, test loss: 1.049522, bias2: 0.5650414228439331, variance: 0.4844801723957062\n",
      "Train size: [400] hidden size: [419] trial: 19, train_loss: 0.747022, test loss: 1.052846, bias2: 0.5706853866577148, variance: 0.4821602404117584\n",
      "Train size: [400] hidden size: [419] trial: 20, train_loss: 0.741833, test loss: 1.051966, bias2: 0.5700377225875854, variance: 0.48192858695983887\n",
      "Train size: [400] hidden size: [419] trial: 21, train_loss: 0.741852, test loss: 1.047954, bias2: 0.5654787421226501, variance: 0.4824754595756531\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [419] trial: 22, train_loss: 0.744317, test loss: 1.045566, bias2: 0.5644556283950806, variance: 0.48111000657081604\n",
      "Train size: [400] hidden size: [419] trial: 23, train_loss: 0.745644, test loss: 1.045550, bias2: 0.5637069940567017, variance: 0.48184260725975037\n",
      "Train size: [400] hidden size: [419] trial: 24, train_loss: 0.743286, test loss: 1.041680, bias2: 0.5583370327949524, variance: 0.4833431839942932\n",
      "Train size: [400] hidden size: [419] trial: 25, train_loss: 0.742585, test loss: 1.039602, bias2: 0.5543109178543091, variance: 0.485291451215744\n",
      "Train size: [400] hidden size: [419] trial: 26, train_loss: 0.742519, test loss: 1.039609, bias2: 0.555356502532959, variance: 0.4842524528503418\n",
      "Train size: [400] hidden size: [419] trial: 27, train_loss: 0.741510, test loss: 1.038138, bias2: 0.5532639026641846, variance: 0.4848744869232178\n",
      "Train size: [400] hidden size: [419] trial: 28, train_loss: 0.735631, test loss: 1.037107, bias2: 0.5522846579551697, variance: 0.4848223328590393\n",
      "Train size: [400] hidden size: [419] trial: 29, train_loss: 0.735584, test loss: 1.035525, bias2: 0.5503765344619751, variance: 0.485148549079895\n",
      "Train size: [400] hidden size: [419] trial: 30, train_loss: 0.735256, test loss: 1.035196, bias2: 0.5497313141822815, variance: 0.48546499013900757\n",
      "Train size: [400] hidden size: [419] trial: 31, train_loss: 0.735800, test loss: 1.037534, bias2: 0.5500000715255737, variance: 0.48753413558006287\n",
      "Train size: [400] hidden size: [419] trial: 32, train_loss: 0.732714, test loss: 1.039017, bias2: 0.5528117418289185, variance: 0.4862048327922821\n",
      "Train size: [400] hidden size: [419] trial: 33, train_loss: 0.734057, test loss: 1.042398, bias2: 0.5533285140991211, variance: 0.4890691339969635\n",
      "Train size: [400] hidden size: [419] trial: 34, train_loss: 0.732638, test loss: 1.039893, bias2: 0.5534892082214355, variance: 0.48640385270118713\n",
      "Train size: [400] hidden size: [419] trial: 35, train_loss: 0.731370, test loss: 1.041790, bias2: 0.5536914467811584, variance: 0.4880982041358948\n",
      "Train size: [400] hidden size: [419] trial: 36, train_loss: 0.731681, test loss: 1.043879, bias2: 0.5533729791641235, variance: 0.49050602316856384\n",
      "Train size: [400] hidden size: [419] trial: 37, train_loss: 0.732520, test loss: 1.041132, bias2: 0.5519782304763794, variance: 0.4891541302204132\n",
      "Train size: [400] hidden size: [419] trial: 38, train_loss: 0.734198, test loss: 1.042918, bias2: 0.5521907210350037, variance: 0.4907272458076477\n",
      "Train size: [400] hidden size: [419] trial: 39, train_loss: 0.733003, test loss: 1.044311, bias2: 0.5522912740707397, variance: 0.4920198619365692\n",
      "Train size: [400] hidden size: [419] trial: 40, train_loss: 0.732605, test loss: 1.043262, bias2: 0.551925539970398, variance: 0.49133625626564026\n",
      "Train size: [400] hidden size: [419] trial: 41, train_loss: 0.732464, test loss: 1.045739, bias2: 0.554430365562439, variance: 0.4913083612918854\n",
      "Train size: [400] hidden size: [419] trial: 42, train_loss: 0.734265, test loss: 1.045800, bias2: 0.5549452304840088, variance: 0.49085506796836853\n",
      "Train size: [400] hidden size: [419] trial: 43, train_loss: 0.733755, test loss: 1.045335, bias2: 0.553412914276123, variance: 0.491922527551651\n",
      "Train size: [400] hidden size: [419] trial: 44, train_loss: 0.736075, test loss: 1.046389, bias2: 0.5522197484970093, variance: 0.4941693842411041\n",
      "Train size: [400] hidden size: [419] trial: 45, train_loss: 0.735995, test loss: 1.048024, bias2: 0.5535203814506531, variance: 0.49450355768203735\n",
      "Train size: [400] hidden size: [419] trial: 46, train_loss: 0.736679, test loss: 1.047429, bias2: 0.5520825982093811, variance: 0.4953461289405823\n",
      "Train size: [400] hidden size: [419] trial: 47, train_loss: 0.738135, test loss: 1.048072, bias2: 0.5499323606491089, variance: 0.498139888048172\n",
      "Train size: [400] hidden size: [419] trial: 48, train_loss: 0.737549, test loss: 1.048438, bias2: 0.5502362847328186, variance: 0.49820154905319214\n",
      "Train size: [400] hidden size: [419] trial: 49, train_loss: 0.737633, test loss: 1.048117, bias2: 0.5493130683898926, variance: 0.49880358576774597\n",
      "##################################################\n",
      "Train size: [400] hidden size: [483] trial: 0, train_loss: 0.611398, test loss: 1.037037, bias2: 1.0370368957519531, variance: -3.5032932110823367e-09\n",
      "Train size: [400] hidden size: [483] trial: 1, train_loss: 0.639317, test loss: 1.011612, bias2: 0.7597107291221619, variance: 0.25190144777297974\n",
      "Train size: [400] hidden size: [483] trial: 2, train_loss: 0.697215, test loss: 1.034372, bias2: 0.6713601350784302, variance: 0.3630114495754242\n",
      "Train size: [400] hidden size: [483] trial: 3, train_loss: 0.693544, test loss: 1.029563, bias2: 0.6252919435501099, variance: 0.4042714536190033\n",
      "Train size: [400] hidden size: [483] trial: 4, train_loss: 0.680945, test loss: 1.022561, bias2: 0.5907134413719177, variance: 0.43184715509414673\n",
      "Train size: [400] hidden size: [483] trial: 5, train_loss: 0.683268, test loss: 1.023914, bias2: 0.5685988664627075, variance: 0.45531490445137024\n",
      "Train size: [400] hidden size: [483] trial: 6, train_loss: 0.681312, test loss: 1.038519, bias2: 0.5642117261886597, variance: 0.47430726885795593\n",
      "Train size: [400] hidden size: [483] trial: 7, train_loss: 0.670590, test loss: 1.035188, bias2: 0.5508919954299927, variance: 0.4842958450317383\n",
      "Train size: [400] hidden size: [483] trial: 8, train_loss: 0.676814, test loss: 1.026851, bias2: 0.5357442498207092, variance: 0.49110716581344604\n",
      "Train size: [400] hidden size: [483] trial: 9, train_loss: 0.670201, test loss: 1.027467, bias2: 0.5298225283622742, variance: 0.4976443648338318\n",
      "Train size: [400] hidden size: [483] trial: 10, train_loss: 0.664476, test loss: 1.028432, bias2: 0.5272181630134583, variance: 0.5012134909629822\n",
      "Train size: [400] hidden size: [483] trial: 11, train_loss: 0.666653, test loss: 1.031495, bias2: 0.5239510536193848, variance: 0.5075441598892212\n",
      "Train size: [400] hidden size: [483] trial: 12, train_loss: 0.666230, test loss: 1.037404, bias2: 0.5196211934089661, variance: 0.5177823901176453\n",
      "Train size: [400] hidden size: [483] trial: 13, train_loss: 0.667923, test loss: 1.032428, bias2: 0.5130926966667175, variance: 0.5193350911140442\n",
      "Train size: [400] hidden size: [483] trial: 14, train_loss: 0.667865, test loss: 1.032078, bias2: 0.5118555426597595, variance: 0.5202226042747498\n",
      "Train size: [400] hidden size: [483] trial: 15, train_loss: 0.670107, test loss: 1.028206, bias2: 0.5070579051971436, variance: 0.5211480855941772\n",
      "Train size: [400] hidden size: [483] trial: 16, train_loss: 0.669493, test loss: 1.033418, bias2: 0.5075714588165283, variance: 0.5258466005325317\n",
      "Train size: [400] hidden size: [483] trial: 17, train_loss: 0.663026, test loss: 1.031288, bias2: 0.5065448880195618, variance: 0.5247430205345154\n",
      "Train size: [400] hidden size: [483] trial: 18, train_loss: 0.664161, test loss: 1.032892, bias2: 0.5087791681289673, variance: 0.5241130590438843\n",
      "Train size: [400] hidden size: [483] trial: 19, train_loss: 0.663461, test loss: 1.030406, bias2: 0.5043818354606628, variance: 0.5260239243507385\n",
      "Train size: [400] hidden size: [483] trial: 20, train_loss: 0.662835, test loss: 1.033639, bias2: 0.5076186060905457, variance: 0.5260202288627625\n",
      "Train size: [400] hidden size: [483] trial: 21, train_loss: 0.660824, test loss: 1.031212, bias2: 0.5033733248710632, variance: 0.527838408946991\n",
      "Train size: [400] hidden size: [483] trial: 22, train_loss: 0.662431, test loss: 1.029747, bias2: 0.5029085278511047, variance: 0.5268382430076599\n",
      "Train size: [400] hidden size: [483] trial: 23, train_loss: 0.664030, test loss: 1.027964, bias2: 0.5014392733573914, variance: 0.52652508020401\n",
      "Train size: [400] hidden size: [483] trial: 24, train_loss: 0.661304, test loss: 1.030142, bias2: 0.5042391419410706, variance: 0.525903046131134\n",
      "Train size: [400] hidden size: [483] trial: 25, train_loss: 0.656943, test loss: 1.030381, bias2: 0.5025933384895325, variance: 0.5277878642082214\n",
      "Train size: [400] hidden size: [483] trial: 26, train_loss: 0.656863, test loss: 1.028583, bias2: 0.5027744770050049, variance: 0.5258090496063232\n",
      "Train size: [400] hidden size: [483] trial: 27, train_loss: 0.655395, test loss: 1.028874, bias2: 0.5034765601158142, variance: 0.5253971219062805\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [483] trial: 28, train_loss: 0.653225, test loss: 1.029556, bias2: 0.5053702592849731, variance: 0.5241855382919312\n",
      "Train size: [400] hidden size: [483] trial: 29, train_loss: 0.654128, test loss: 1.032633, bias2: 0.5057094097137451, variance: 0.5269232988357544\n",
      "Train size: [400] hidden size: [483] trial: 30, train_loss: 0.653383, test loss: 1.031889, bias2: 0.5034427046775818, variance: 0.5284462571144104\n",
      "Train size: [400] hidden size: [483] trial: 31, train_loss: 0.651122, test loss: 1.031123, bias2: 0.5037863254547119, variance: 0.527336597442627\n",
      "Train size: [400] hidden size: [483] trial: 32, train_loss: 0.649825, test loss: 1.030513, bias2: 0.5034295320510864, variance: 0.5270830392837524\n",
      "Train size: [400] hidden size: [483] trial: 33, train_loss: 0.649570, test loss: 1.031826, bias2: 0.50334632396698, variance: 0.5284796953201294\n",
      "Train size: [400] hidden size: [483] trial: 34, train_loss: 0.654144, test loss: 1.036482, bias2: 0.5054887533187866, variance: 0.5309929847717285\n",
      "Train size: [400] hidden size: [483] trial: 35, train_loss: 0.653909, test loss: 1.035361, bias2: 0.5037314891815186, variance: 0.5316290855407715\n",
      "Train size: [400] hidden size: [483] trial: 36, train_loss: 0.653176, test loss: 1.033273, bias2: 0.5019187331199646, variance: 0.531353771686554\n",
      "Train size: [400] hidden size: [483] trial: 37, train_loss: 0.650451, test loss: 1.032892, bias2: 0.5025010704994202, variance: 0.5303911566734314\n",
      "Train size: [400] hidden size: [483] trial: 38, train_loss: 0.652821, test loss: 1.032460, bias2: 0.5025566220283508, variance: 0.5299031138420105\n",
      "Train size: [400] hidden size: [483] trial: 39, train_loss: 0.653516, test loss: 1.030454, bias2: 0.5004214644432068, variance: 0.5300325751304626\n",
      "Train size: [400] hidden size: [483] trial: 40, train_loss: 0.652596, test loss: 1.029170, bias2: 0.5000349879264832, variance: 0.5291352868080139\n",
      "Train size: [400] hidden size: [483] trial: 41, train_loss: 0.653363, test loss: 1.028411, bias2: 0.49972623586654663, variance: 0.5286845564842224\n",
      "Train size: [400] hidden size: [483] trial: 42, train_loss: 0.653832, test loss: 1.027508, bias2: 0.49947822093963623, variance: 0.5280299186706543\n",
      "Train size: [400] hidden size: [483] trial: 43, train_loss: 0.653822, test loss: 1.027521, bias2: 0.5000393390655518, variance: 0.5274820327758789\n",
      "Train size: [400] hidden size: [483] trial: 44, train_loss: 0.652499, test loss: 1.028114, bias2: 0.5011547803878784, variance: 0.5269590616226196\n",
      "Train size: [400] hidden size: [483] trial: 45, train_loss: 0.651691, test loss: 1.026570, bias2: 0.5006085634231567, variance: 0.5259616374969482\n",
      "Train size: [400] hidden size: [483] trial: 46, train_loss: 0.652814, test loss: 1.027858, bias2: 0.5018327236175537, variance: 0.5260257720947266\n",
      "Train size: [400] hidden size: [483] trial: 47, train_loss: 0.652717, test loss: 1.030708, bias2: 0.504301130771637, variance: 0.5264068245887756\n",
      "Train size: [400] hidden size: [483] trial: 48, train_loss: 0.653123, test loss: 1.030543, bias2: 0.5026260614395142, variance: 0.5279167890548706\n",
      "Train size: [400] hidden size: [483] trial: 49, train_loss: 0.653624, test loss: 1.030429, bias2: 0.5028344988822937, variance: 0.527594268321991\n",
      "##################################################\n",
      "Train size: [400] hidden size: [556] trial: 0, train_loss: 0.591709, test loss: 0.996164, bias2: 0.9961641430854797, variance: 1.1677644407015464e-09\n",
      "Train size: [400] hidden size: [556] trial: 1, train_loss: 0.613474, test loss: 1.002001, bias2: 0.7489286661148071, variance: 0.253072053194046\n",
      "Train size: [400] hidden size: [556] trial: 2, train_loss: 0.610078, test loss: 1.001028, bias2: 0.6630529165267944, variance: 0.3379746973514557\n",
      "Train size: [400] hidden size: [556] trial: 3, train_loss: 0.599728, test loss: 0.985951, bias2: 0.6150423884391785, variance: 0.3709084987640381\n",
      "Train size: [400] hidden size: [556] trial: 4, train_loss: 0.605467, test loss: 0.972131, bias2: 0.5806002020835876, variance: 0.3915303945541382\n",
      "Train size: [400] hidden size: [556] trial: 5, train_loss: 0.588574, test loss: 0.984581, bias2: 0.5721279382705688, variance: 0.4124528467655182\n",
      "Train size: [400] hidden size: [556] trial: 6, train_loss: 0.593173, test loss: 0.978753, bias2: 0.5531418919563293, variance: 0.4256107807159424\n",
      "Train size: [400] hidden size: [556] trial: 7, train_loss: 0.592706, test loss: 0.989392, bias2: 0.5506616830825806, variance: 0.4387301802635193\n",
      "Train size: [400] hidden size: [556] trial: 8, train_loss: 0.593368, test loss: 0.990415, bias2: 0.5391758680343628, variance: 0.4512389600276947\n",
      "Train size: [400] hidden size: [556] trial: 9, train_loss: 0.591768, test loss: 0.985953, bias2: 0.524171769618988, variance: 0.4617815613746643\n",
      "Train size: [400] hidden size: [556] trial: 10, train_loss: 0.593231, test loss: 0.992899, bias2: 0.5224610567092896, variance: 0.4704377353191376\n",
      "Train size: [400] hidden size: [556] trial: 11, train_loss: 0.595772, test loss: 0.998283, bias2: 0.5143735408782959, variance: 0.4839094281196594\n",
      "Train size: [400] hidden size: [556] trial: 12, train_loss: 0.591477, test loss: 0.992509, bias2: 0.5030684471130371, variance: 0.48944008350372314\n",
      "Train size: [400] hidden size: [556] trial: 13, train_loss: 0.592780, test loss: 0.988473, bias2: 0.4952586889266968, variance: 0.49321383237838745\n",
      "Train size: [400] hidden size: [556] trial: 14, train_loss: 0.592968, test loss: 0.986936, bias2: 0.48782917857170105, variance: 0.4991070330142975\n",
      "Train size: [400] hidden size: [556] trial: 15, train_loss: 0.594355, test loss: 0.982391, bias2: 0.48338985443115234, variance: 0.4990013837814331\n",
      "Train size: [400] hidden size: [556] trial: 16, train_loss: 0.592436, test loss: 0.981402, bias2: 0.48324334621429443, variance: 0.49815815687179565\n",
      "Train size: [400] hidden size: [556] trial: 17, train_loss: 0.591369, test loss: 0.980771, bias2: 0.47982895374298096, variance: 0.5009419322013855\n",
      "Train size: [400] hidden size: [556] trial: 18, train_loss: 0.588344, test loss: 0.978730, bias2: 0.47805696725845337, variance: 0.5006729960441589\n",
      "Train size: [400] hidden size: [556] trial: 19, train_loss: 0.587836, test loss: 0.977479, bias2: 0.4749777317047119, variance: 0.5025016069412231\n",
      "Train size: [400] hidden size: [556] trial: 20, train_loss: 0.588131, test loss: 0.979732, bias2: 0.4764891266822815, variance: 0.5032429695129395\n",
      "Train size: [400] hidden size: [556] trial: 21, train_loss: 0.590797, test loss: 0.978727, bias2: 0.47377657890319824, variance: 0.5049508810043335\n",
      "Train size: [400] hidden size: [556] trial: 22, train_loss: 0.591821, test loss: 0.983239, bias2: 0.47227609157562256, variance: 0.5109633803367615\n",
      "Train size: [400] hidden size: [556] trial: 23, train_loss: 0.592457, test loss: 0.983385, bias2: 0.4715203642845154, variance: 0.5118641257286072\n",
      "Train size: [400] hidden size: [556] trial: 24, train_loss: 0.592511, test loss: 0.984646, bias2: 0.47167038917541504, variance: 0.5129759907722473\n",
      "Train size: [400] hidden size: [556] trial: 25, train_loss: 0.590299, test loss: 0.983323, bias2: 0.4706695079803467, variance: 0.512653112411499\n",
      "Train size: [400] hidden size: [556] trial: 26, train_loss: 0.587853, test loss: 0.979689, bias2: 0.46862661838531494, variance: 0.5110625624656677\n",
      "Train size: [400] hidden size: [556] trial: 27, train_loss: 0.586021, test loss: 0.980618, bias2: 0.4692126512527466, variance: 0.5114058256149292\n",
      "Train size: [400] hidden size: [556] trial: 28, train_loss: 0.582859, test loss: 0.980141, bias2: 0.4707285761833191, variance: 0.5094122886657715\n",
      "Train size: [400] hidden size: [556] trial: 29, train_loss: 0.581104, test loss: 0.977512, bias2: 0.468140184879303, variance: 0.5093716979026794\n",
      "Train size: [400] hidden size: [556] trial: 30, train_loss: 0.580961, test loss: 0.977512, bias2: 0.4679678678512573, variance: 0.5095446109771729\n",
      "Train size: [400] hidden size: [556] trial: 31, train_loss: 0.579061, test loss: 0.980780, bias2: 0.47165173292160034, variance: 0.509128749370575\n",
      "Train size: [400] hidden size: [556] trial: 32, train_loss: 0.578675, test loss: 0.984160, bias2: 0.47518759965896606, variance: 0.5089722275733948\n",
      "Train size: [400] hidden size: [556] trial: 33, train_loss: 0.580363, test loss: 0.984435, bias2: 0.4732794165611267, variance: 0.5111551880836487\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [556] trial: 34, train_loss: 0.579821, test loss: 0.983064, bias2: 0.4713483452796936, variance: 0.5117156505584717\n",
      "Train size: [400] hidden size: [556] trial: 35, train_loss: 0.580631, test loss: 0.985644, bias2: 0.47370070219039917, variance: 0.5119435787200928\n",
      "Train size: [400] hidden size: [556] trial: 36, train_loss: 0.581461, test loss: 0.986386, bias2: 0.47419387102127075, variance: 0.5121921896934509\n",
      "Train size: [400] hidden size: [556] trial: 37, train_loss: 0.580997, test loss: 0.987188, bias2: 0.4742256999015808, variance: 0.512962281703949\n",
      "Train size: [400] hidden size: [556] trial: 38, train_loss: 0.582513, test loss: 0.990748, bias2: 0.4767889976501465, variance: 0.5139586329460144\n",
      "Train size: [400] hidden size: [556] trial: 39, train_loss: 0.580050, test loss: 0.990680, bias2: 0.4777872562408447, variance: 0.5128923654556274\n",
      "Train size: [400] hidden size: [556] trial: 40, train_loss: 0.578961, test loss: 0.993385, bias2: 0.4813741445541382, variance: 0.5120110511779785\n",
      "Train size: [400] hidden size: [556] trial: 41, train_loss: 0.577003, test loss: 0.993121, bias2: 0.4825971722602844, variance: 0.510524332523346\n",
      "Train size: [400] hidden size: [556] trial: 42, train_loss: 0.577866, test loss: 0.993389, bias2: 0.4837460517883301, variance: 0.5096425414085388\n",
      "Train size: [400] hidden size: [556] trial: 43, train_loss: 0.577387, test loss: 0.993542, bias2: 0.48379814624786377, variance: 0.5097435712814331\n",
      "Train size: [400] hidden size: [556] trial: 44, train_loss: 0.577261, test loss: 0.994286, bias2: 0.48432713747024536, variance: 0.5099587440490723\n",
      "Train size: [400] hidden size: [556] trial: 45, train_loss: 0.578779, test loss: 0.995861, bias2: 0.4848617911338806, variance: 0.5109995603561401\n",
      "Train size: [400] hidden size: [556] trial: 46, train_loss: 0.578328, test loss: 0.997402, bias2: 0.48514264822006226, variance: 0.5122592449188232\n",
      "Train size: [400] hidden size: [556] trial: 47, train_loss: 0.578712, test loss: 0.997375, bias2: 0.4855823516845703, variance: 0.5117926597595215\n",
      "Train size: [400] hidden size: [556] trial: 48, train_loss: 0.578801, test loss: 0.998324, bias2: 0.4861981272697449, variance: 0.5121263265609741\n",
      "Train size: [400] hidden size: [556] trial: 49, train_loss: 0.579098, test loss: 0.999874, bias2: 0.4862448573112488, variance: 0.5136287212371826\n",
      "##################################################\n",
      "Train size: [400] hidden size: [640] trial: 0, train_loss: 0.650782, test loss: 0.931963, bias2: 0.9319625496864319, variance: -1.1677644407015464e-09\n",
      "Train size: [400] hidden size: [640] trial: 1, train_loss: 0.590152, test loss: 0.932045, bias2: 0.6665186285972595, variance: 0.2655261158943176\n",
      "Train size: [400] hidden size: [640] trial: 2, train_loss: 0.578949, test loss: 0.984269, bias2: 0.6073852777481079, variance: 0.3768833577632904\n",
      "Train size: [400] hidden size: [640] trial: 3, train_loss: 0.573892, test loss: 0.991773, bias2: 0.5608110427856445, variance: 0.4309619963169098\n",
      "Train size: [400] hidden size: [640] trial: 4, train_loss: 0.568472, test loss: 0.985384, bias2: 0.5353567600250244, variance: 0.45002686977386475\n",
      "Train size: [400] hidden size: [640] trial: 5, train_loss: 0.554573, test loss: 0.997643, bias2: 0.5203791260719299, variance: 0.47726404666900635\n",
      "Train size: [400] hidden size: [640] trial: 6, train_loss: 0.545409, test loss: 1.000924, bias2: 0.517499566078186, variance: 0.4834239184856415\n",
      "Train size: [400] hidden size: [640] trial: 7, train_loss: 0.543376, test loss: 0.993602, bias2: 0.5082958936691284, variance: 0.48530635237693787\n",
      "Train size: [400] hidden size: [640] trial: 8, train_loss: 0.535696, test loss: 0.990325, bias2: 0.49914073944091797, variance: 0.49118441343307495\n",
      "Train size: [400] hidden size: [640] trial: 9, train_loss: 0.537435, test loss: 0.988733, bias2: 0.4901382327079773, variance: 0.49859482049942017\n",
      "Train size: [400] hidden size: [640] trial: 10, train_loss: 0.537301, test loss: 0.991317, bias2: 0.49089759588241577, variance: 0.500419557094574\n",
      "Train size: [400] hidden size: [640] trial: 11, train_loss: 0.533990, test loss: 0.996572, bias2: 0.48950910568237305, variance: 0.5070624351501465\n",
      "Train size: [400] hidden size: [640] trial: 12, train_loss: 0.534091, test loss: 0.997570, bias2: 0.4898719787597656, variance: 0.5076977610588074\n",
      "Train size: [400] hidden size: [640] trial: 13, train_loss: 0.531533, test loss: 0.994284, bias2: 0.4805825352668762, variance: 0.5137014985084534\n",
      "Train size: [400] hidden size: [640] trial: 14, train_loss: 0.529819, test loss: 0.987413, bias2: 0.47313791513442993, variance: 0.5142754316329956\n",
      "Train size: [400] hidden size: [640] trial: 15, train_loss: 0.528244, test loss: 0.985419, bias2: 0.4683701992034912, variance: 0.5170487761497498\n",
      "Train size: [400] hidden size: [640] trial: 16, train_loss: 0.523931, test loss: 0.990460, bias2: 0.4719724655151367, variance: 0.518487274646759\n",
      "Train size: [400] hidden size: [640] trial: 17, train_loss: 0.521639, test loss: 0.990023, bias2: 0.46866899728775024, variance: 0.5213541388511658\n",
      "Train size: [400] hidden size: [640] trial: 18, train_loss: 0.518439, test loss: 0.987474, bias2: 0.46618932485580444, variance: 0.5212851762771606\n",
      "Train size: [400] hidden size: [640] trial: 19, train_loss: 0.517351, test loss: 0.992360, bias2: 0.4695521593093872, variance: 0.5228075385093689\n",
      "Train size: [400] hidden size: [640] trial: 20, train_loss: 0.520674, test loss: 0.992470, bias2: 0.46604543924331665, variance: 0.5264241099357605\n",
      "Train size: [400] hidden size: [640] trial: 21, train_loss: 0.518199, test loss: 0.993600, bias2: 0.4656018614768982, variance: 0.5279982089996338\n",
      "Train size: [400] hidden size: [640] trial: 22, train_loss: 0.516123, test loss: 0.995975, bias2: 0.4661637544631958, variance: 0.5298109650611877\n",
      "Train size: [400] hidden size: [640] trial: 23, train_loss: 0.519865, test loss: 0.998654, bias2: 0.4671761393547058, variance: 0.5314778685569763\n",
      "Train size: [400] hidden size: [640] trial: 24, train_loss: 0.517042, test loss: 0.996964, bias2: 0.46607714891433716, variance: 0.5308865904808044\n",
      "Train size: [400] hidden size: [640] trial: 25, train_loss: 0.516119, test loss: 0.994622, bias2: 0.46602505445480347, variance: 0.528597354888916\n",
      "Train size: [400] hidden size: [640] trial: 26, train_loss: 0.515384, test loss: 0.991148, bias2: 0.46242934465408325, variance: 0.5287189483642578\n",
      "Train size: [400] hidden size: [640] trial: 27, train_loss: 0.517131, test loss: 0.992843, bias2: 0.46440595388412476, variance: 0.5284374952316284\n",
      "Train size: [400] hidden size: [640] trial: 28, train_loss: 0.518082, test loss: 0.995287, bias2: 0.46552908420562744, variance: 0.5297577977180481\n",
      "Train size: [400] hidden size: [640] trial: 29, train_loss: 0.516595, test loss: 0.993889, bias2: 0.46335846185684204, variance: 0.5305305123329163\n",
      "Train size: [400] hidden size: [640] trial: 30, train_loss: 0.516417, test loss: 0.995182, bias2: 0.46390730142593384, variance: 0.5312743186950684\n",
      "Train size: [400] hidden size: [640] trial: 31, train_loss: 0.518519, test loss: 0.994868, bias2: 0.4633450508117676, variance: 0.5315231084823608\n",
      "Train size: [400] hidden size: [640] trial: 32, train_loss: 0.515806, test loss: 0.993209, bias2: 0.461834192276001, variance: 0.531374454498291\n",
      "Train size: [400] hidden size: [640] trial: 33, train_loss: 0.515864, test loss: 0.991659, bias2: 0.46202683448791504, variance: 0.5296318531036377\n",
      "Train size: [400] hidden size: [640] trial: 34, train_loss: 0.517494, test loss: 0.991149, bias2: 0.4600088596343994, variance: 0.5311405658721924\n",
      "Train size: [400] hidden size: [640] trial: 35, train_loss: 0.516543, test loss: 0.992212, bias2: 0.4614967107772827, variance: 0.5307155251502991\n",
      "Train size: [400] hidden size: [640] trial: 36, train_loss: 0.515055, test loss: 0.991448, bias2: 0.46057581901550293, variance: 0.530872642993927\n",
      "Train size: [400] hidden size: [640] trial: 37, train_loss: 0.516192, test loss: 0.992850, bias2: 0.46122848987579346, variance: 0.5316210985183716\n",
      "Train size: [400] hidden size: [640] trial: 38, train_loss: 0.516084, test loss: 0.993703, bias2: 0.45925986766815186, variance: 0.534442663192749\n",
      "Train size: [400] hidden size: [640] trial: 39, train_loss: 0.515385, test loss: 0.995428, bias2: 0.4603998064994812, variance: 0.5350279211997986\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [640] trial: 40, train_loss: 0.512892, test loss: 0.995655, bias2: 0.46001410484313965, variance: 0.5356405973434448\n",
      "Train size: [400] hidden size: [640] trial: 41, train_loss: 0.511788, test loss: 0.997827, bias2: 0.46224910020828247, variance: 0.5355774760246277\n",
      "Train size: [400] hidden size: [640] trial: 42, train_loss: 0.510903, test loss: 0.998645, bias2: 0.46307748556137085, variance: 0.5355677008628845\n",
      "Train size: [400] hidden size: [640] trial: 43, train_loss: 0.511474, test loss: 0.998733, bias2: 0.46318602561950684, variance: 0.5355470776557922\n",
      "Train size: [400] hidden size: [640] trial: 44, train_loss: 0.514123, test loss: 0.999606, bias2: 0.4639260768890381, variance: 0.5356801152229309\n",
      "Train size: [400] hidden size: [640] trial: 45, train_loss: 0.512131, test loss: 0.998622, bias2: 0.4634593725204468, variance: 0.5351629853248596\n",
      "Train size: [400] hidden size: [640] trial: 46, train_loss: 0.512050, test loss: 0.997043, bias2: 0.46358007192611694, variance: 0.5334631204605103\n",
      "Train size: [400] hidden size: [640] trial: 47, train_loss: 0.511426, test loss: 0.996326, bias2: 0.4644433856010437, variance: 0.5318825244903564\n",
      "Train size: [400] hidden size: [640] trial: 48, train_loss: 0.510076, test loss: 0.997444, bias2: 0.4647957682609558, variance: 0.5326485633850098\n",
      "Train size: [400] hidden size: [640] trial: 49, train_loss: 0.509169, test loss: 0.997668, bias2: 0.46514254808425903, variance: 0.5325254797935486\n",
      "##################################################\n",
      "Train size: [400] hidden size: [737] trial: 0, train_loss: 0.381514, test loss: 0.951185, bias2: 0.9511846899986267, variance: -3.1140383605077204e-09\n",
      "Train size: [400] hidden size: [737] trial: 1, train_loss: 0.405994, test loss: 0.979753, bias2: 0.7222123146057129, variance: 0.2575405538082123\n",
      "Train size: [400] hidden size: [737] trial: 2, train_loss: 0.435345, test loss: 0.985938, bias2: 0.629780113697052, variance: 0.3561580777168274\n",
      "Train size: [400] hidden size: [737] trial: 3, train_loss: 0.440827, test loss: 0.981909, bias2: 0.5808825492858887, variance: 0.40102633833885193\n",
      "Train size: [400] hidden size: [737] trial: 4, train_loss: 0.431692, test loss: 0.972537, bias2: 0.5501115918159485, variance: 0.42242497205734253\n",
      "Train size: [400] hidden size: [737] trial: 5, train_loss: 0.421126, test loss: 0.963509, bias2: 0.5283672213554382, variance: 0.4351416826248169\n",
      "Train size: [400] hidden size: [737] trial: 6, train_loss: 0.424832, test loss: 0.959800, bias2: 0.5149561166763306, variance: 0.44484347105026245\n",
      "Train size: [400] hidden size: [737] trial: 7, train_loss: 0.436062, test loss: 0.961625, bias2: 0.5059055089950562, variance: 0.45571964979171753\n",
      "Train size: [400] hidden size: [737] trial: 8, train_loss: 0.433930, test loss: 0.968970, bias2: 0.49867498874664307, variance: 0.4702945947647095\n",
      "Train size: [400] hidden size: [737] trial: 9, train_loss: 0.433333, test loss: 0.965414, bias2: 0.48689231276512146, variance: 0.4785216152667999\n",
      "Train size: [400] hidden size: [737] trial: 10, train_loss: 0.435665, test loss: 0.968369, bias2: 0.48663514852523804, variance: 0.4817342162132263\n",
      "Train size: [400] hidden size: [737] trial: 11, train_loss: 0.435733, test loss: 0.971937, bias2: 0.48462551832199097, variance: 0.48731154203414917\n",
      "Train size: [400] hidden size: [737] trial: 12, train_loss: 0.436220, test loss: 0.968450, bias2: 0.4782860279083252, variance: 0.49016356468200684\n",
      "Train size: [400] hidden size: [737] trial: 13, train_loss: 0.437740, test loss: 0.970654, bias2: 0.47603440284729004, variance: 0.49461913108825684\n",
      "Train size: [400] hidden size: [737] trial: 14, train_loss: 0.433953, test loss: 0.969085, bias2: 0.47380587458610535, variance: 0.4952790439128876\n",
      "Train size: [400] hidden size: [737] trial: 15, train_loss: 0.434539, test loss: 0.968382, bias2: 0.47279250621795654, variance: 0.4955897331237793\n",
      "Train size: [400] hidden size: [737] trial: 16, train_loss: 0.439216, test loss: 0.970666, bias2: 0.47024005651474, variance: 0.5004263520240784\n",
      "Train size: [400] hidden size: [737] trial: 17, train_loss: 0.435949, test loss: 0.969365, bias2: 0.4667183756828308, variance: 0.5026463270187378\n",
      "Train size: [400] hidden size: [737] trial: 18, train_loss: 0.434532, test loss: 0.966055, bias2: 0.46452921628952026, variance: 0.5015254616737366\n",
      "Train size: [400] hidden size: [737] trial: 19, train_loss: 0.431080, test loss: 0.964038, bias2: 0.4613979458808899, variance: 0.5026405453681946\n",
      "Train size: [400] hidden size: [737] trial: 20, train_loss: 0.434755, test loss: 0.961021, bias2: 0.4552973508834839, variance: 0.5057238936424255\n",
      "Train size: [400] hidden size: [737] trial: 21, train_loss: 0.435277, test loss: 0.963207, bias2: 0.45630818605422974, variance: 0.5068985819816589\n",
      "Train size: [400] hidden size: [737] trial: 22, train_loss: 0.433919, test loss: 0.965073, bias2: 0.4586808681488037, variance: 0.5063923597335815\n",
      "Train size: [400] hidden size: [737] trial: 23, train_loss: 0.433166, test loss: 0.965111, bias2: 0.45894312858581543, variance: 0.5061682462692261\n",
      "Train size: [400] hidden size: [737] trial: 24, train_loss: 0.433486, test loss: 0.965186, bias2: 0.45723432302474976, variance: 0.5079518556594849\n",
      "Train size: [400] hidden size: [737] trial: 25, train_loss: 0.434953, test loss: 0.964444, bias2: 0.45779645442962646, variance: 0.5066478848457336\n",
      "Train size: [400] hidden size: [737] trial: 26, train_loss: 0.436012, test loss: 0.961799, bias2: 0.453660786151886, variance: 0.5081383585929871\n",
      "Train size: [400] hidden size: [737] trial: 27, train_loss: 0.436668, test loss: 0.961213, bias2: 0.4501032829284668, variance: 0.5111096501350403\n",
      "Train size: [400] hidden size: [737] trial: 28, train_loss: 0.435434, test loss: 0.962179, bias2: 0.4500386714935303, variance: 0.5121402740478516\n",
      "Train size: [400] hidden size: [737] trial: 29, train_loss: 0.435906, test loss: 0.959428, bias2: 0.4480867385864258, variance: 0.5113417506217957\n",
      "Train size: [400] hidden size: [737] trial: 30, train_loss: 0.436539, test loss: 0.964126, bias2: 0.4501606225967407, variance: 0.5139656662940979\n",
      "Train size: [400] hidden size: [737] trial: 31, train_loss: 0.437758, test loss: 0.963530, bias2: 0.44987380504608154, variance: 0.5136559009552002\n",
      "Train size: [400] hidden size: [737] trial: 32, train_loss: 0.438465, test loss: 0.964279, bias2: 0.44913387298583984, variance: 0.5151453018188477\n",
      "Train size: [400] hidden size: [737] trial: 33, train_loss: 0.437410, test loss: 0.964737, bias2: 0.44878989458084106, variance: 0.5159468650817871\n",
      "Train size: [400] hidden size: [737] trial: 34, train_loss: 0.436198, test loss: 0.965663, bias2: 0.44886863231658936, variance: 0.5167939066886902\n",
      "Train size: [400] hidden size: [737] trial: 35, train_loss: 0.435036, test loss: 0.963213, bias2: 0.4479435682296753, variance: 0.5152696967124939\n",
      "Train size: [400] hidden size: [737] trial: 36, train_loss: 0.433738, test loss: 0.965048, bias2: 0.45034289360046387, variance: 0.51470547914505\n",
      "Train size: [400] hidden size: [737] trial: 37, train_loss: 0.434300, test loss: 0.963044, bias2: 0.44776850938796997, variance: 0.5152750611305237\n",
      "Train size: [400] hidden size: [737] trial: 38, train_loss: 0.432491, test loss: 0.962899, bias2: 0.44748353958129883, variance: 0.5154159069061279\n",
      "Train size: [400] hidden size: [737] trial: 39, train_loss: 0.431880, test loss: 0.960375, bias2: 0.4460204243659973, variance: 0.5143541693687439\n",
      "Train size: [400] hidden size: [737] trial: 40, train_loss: 0.431196, test loss: 0.960146, bias2: 0.44625622034072876, variance: 0.5138895511627197\n",
      "Train size: [400] hidden size: [737] trial: 41, train_loss: 0.433475, test loss: 0.961336, bias2: 0.44638311862945557, variance: 0.5149533152580261\n",
      "Train size: [400] hidden size: [737] trial: 42, train_loss: 0.433080, test loss: 0.957880, bias2: 0.4445958137512207, variance: 0.5132843852043152\n",
      "Train size: [400] hidden size: [737] trial: 43, train_loss: 0.434371, test loss: 0.956405, bias2: 0.442766010761261, variance: 0.5136390328407288\n",
      "Train size: [400] hidden size: [737] trial: 44, train_loss: 0.434536, test loss: 0.956979, bias2: 0.4424743056297302, variance: 0.5145043730735779\n",
      "Train size: [400] hidden size: [737] trial: 45, train_loss: 0.435593, test loss: 0.956266, bias2: 0.4417407512664795, variance: 0.5145256519317627\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [737] trial: 46, train_loss: 0.436134, test loss: 0.954026, bias2: 0.43993353843688965, variance: 0.5140923261642456\n",
      "Train size: [400] hidden size: [737] trial: 47, train_loss: 0.436546, test loss: 0.953603, bias2: 0.4391065835952759, variance: 0.5144962668418884\n",
      "Train size: [400] hidden size: [737] trial: 48, train_loss: 0.436273, test loss: 0.951757, bias2: 0.4368754029273987, variance: 0.5148810744285583\n",
      "Train size: [400] hidden size: [737] trial: 49, train_loss: 0.435744, test loss: 0.951028, bias2: 0.4369019865989685, variance: 0.5141255259513855\n",
      "##################################################\n",
      "Train size: [400] hidden size: [848] trial: 0, train_loss: 0.397518, test loss: 0.964947, bias2: 0.9649474620819092, variance: -1.1677644407015464e-09\n",
      "Train size: [400] hidden size: [848] trial: 1, train_loss: 0.410435, test loss: 0.949519, bias2: 0.7021035552024841, variance: 0.2474154829978943\n",
      "Train size: [400] hidden size: [848] trial: 2, train_loss: 0.386698, test loss: 0.963670, bias2: 0.6211546659469604, variance: 0.3425157368183136\n",
      "Train size: [400] hidden size: [848] trial: 3, train_loss: 0.388220, test loss: 0.969563, bias2: 0.5816981792449951, variance: 0.38786521553993225\n",
      "Train size: [400] hidden size: [848] trial: 4, train_loss: 0.369601, test loss: 0.959497, bias2: 0.554279088973999, variance: 0.40521785616874695\n",
      "Train size: [400] hidden size: [848] trial: 5, train_loss: 0.368541, test loss: 0.943072, bias2: 0.5235816240310669, variance: 0.419490247964859\n",
      "Train size: [400] hidden size: [848] trial: 6, train_loss: 0.373283, test loss: 0.942683, bias2: 0.5122740864753723, variance: 0.43040889501571655\n",
      "Train size: [400] hidden size: [848] trial: 7, train_loss: 0.376321, test loss: 0.946050, bias2: 0.5033705234527588, variance: 0.44267934560775757\n",
      "Train size: [400] hidden size: [848] trial: 8, train_loss: 0.375024, test loss: 0.943005, bias2: 0.4844018220901489, variance: 0.45860356092453003\n",
      "Train size: [400] hidden size: [848] trial: 9, train_loss: 0.377696, test loss: 0.948487, bias2: 0.4821060597896576, variance: 0.46638068556785583\n",
      "Train size: [400] hidden size: [848] trial: 10, train_loss: 0.386830, test loss: 0.950138, bias2: 0.47950541973114014, variance: 0.4706326127052307\n",
      "Train size: [400] hidden size: [848] trial: 11, train_loss: 0.383277, test loss: 0.949636, bias2: 0.4727751910686493, variance: 0.4768610894680023\n",
      "Train size: [400] hidden size: [848] trial: 12, train_loss: 0.389930, test loss: 0.951378, bias2: 0.47308114171028137, variance: 0.4782966673374176\n",
      "Train size: [400] hidden size: [848] trial: 13, train_loss: 0.391834, test loss: 0.948818, bias2: 0.46441254019737244, variance: 0.48440513014793396\n",
      "Train size: [400] hidden size: [848] trial: 14, train_loss: 0.392444, test loss: 0.951490, bias2: 0.46297261118888855, variance: 0.4885174334049225\n",
      "Train size: [400] hidden size: [848] trial: 15, train_loss: 0.393387, test loss: 0.952954, bias2: 0.4623226523399353, variance: 0.490631103515625\n",
      "Train size: [400] hidden size: [848] trial: 16, train_loss: 0.391121, test loss: 0.950790, bias2: 0.4586692154407501, variance: 0.4921204745769501\n",
      "Train size: [400] hidden size: [848] trial: 17, train_loss: 0.391657, test loss: 0.950677, bias2: 0.45827341079711914, variance: 0.49240386486053467\n",
      "Train size: [400] hidden size: [848] trial: 18, train_loss: 0.389473, test loss: 0.946690, bias2: 0.4521513283252716, variance: 0.494538813829422\n",
      "Train size: [400] hidden size: [848] trial: 19, train_loss: 0.389176, test loss: 0.954360, bias2: 0.454303503036499, variance: 0.5000566840171814\n",
      "Train size: [400] hidden size: [848] trial: 20, train_loss: 0.388130, test loss: 0.952538, bias2: 0.4518699645996094, variance: 0.5006684064865112\n",
      "Train size: [400] hidden size: [848] trial: 21, train_loss: 0.387781, test loss: 0.952441, bias2: 0.4476381540298462, variance: 0.5048026442527771\n",
      "Train size: [400] hidden size: [848] trial: 22, train_loss: 0.386865, test loss: 0.951711, bias2: 0.446607768535614, variance: 0.5051034688949585\n",
      "Train size: [400] hidden size: [848] trial: 23, train_loss: 0.384352, test loss: 0.954906, bias2: 0.4482383131980896, variance: 0.5066681504249573\n",
      "Train size: [400] hidden size: [848] trial: 24, train_loss: 0.384800, test loss: 0.955014, bias2: 0.4493919014930725, variance: 0.5056223273277283\n",
      "Train size: [400] hidden size: [848] trial: 25, train_loss: 0.384864, test loss: 0.951666, bias2: 0.4464079737663269, variance: 0.5052579641342163\n",
      "Train size: [400] hidden size: [848] trial: 26, train_loss: 0.386856, test loss: 0.951663, bias2: 0.44671809673309326, variance: 0.5049450397491455\n",
      "Train size: [400] hidden size: [848] trial: 27, train_loss: 0.385425, test loss: 0.952305, bias2: 0.4475300908088684, variance: 0.5047746896743774\n",
      "Train size: [400] hidden size: [848] trial: 28, train_loss: 0.387962, test loss: 0.951292, bias2: 0.4468752145767212, variance: 0.5044165849685669\n",
      "Train size: [400] hidden size: [848] trial: 29, train_loss: 0.388555, test loss: 0.950591, bias2: 0.44574952125549316, variance: 0.5048419237136841\n",
      "Train size: [400] hidden size: [848] trial: 30, train_loss: 0.387483, test loss: 0.951906, bias2: 0.4449314475059509, variance: 0.5069747567176819\n",
      "Train size: [400] hidden size: [848] trial: 31, train_loss: 0.387481, test loss: 0.953566, bias2: 0.4450603723526001, variance: 0.5085057616233826\n",
      "Train size: [400] hidden size: [848] trial: 32, train_loss: 0.388171, test loss: 0.954793, bias2: 0.44511985778808594, variance: 0.5096726417541504\n",
      "Train size: [400] hidden size: [848] trial: 33, train_loss: 0.389328, test loss: 0.956322, bias2: 0.44436073303222656, variance: 0.5119608044624329\n",
      "Train size: [400] hidden size: [848] trial: 34, train_loss: 0.390994, test loss: 0.957397, bias2: 0.4449789524078369, variance: 0.5124176144599915\n",
      "Train size: [400] hidden size: [848] trial: 35, train_loss: 0.390172, test loss: 0.957706, bias2: 0.4457130432128906, variance: 0.5119926333427429\n",
      "Train size: [400] hidden size: [848] trial: 36, train_loss: 0.389245, test loss: 0.958348, bias2: 0.44617146253585815, variance: 0.5121763348579407\n",
      "Train size: [400] hidden size: [848] trial: 37, train_loss: 0.387391, test loss: 0.959481, bias2: 0.4479629397392273, variance: 0.5115182399749756\n",
      "Train size: [400] hidden size: [848] trial: 38, train_loss: 0.388019, test loss: 0.960125, bias2: 0.4464513063430786, variance: 0.5136739611625671\n",
      "Train size: [400] hidden size: [848] trial: 39, train_loss: 0.387299, test loss: 0.960508, bias2: 0.4461376667022705, variance: 0.5143701434135437\n",
      "Train size: [400] hidden size: [848] trial: 40, train_loss: 0.386925, test loss: 0.960157, bias2: 0.447046160697937, variance: 0.5131108164787292\n",
      "Train size: [400] hidden size: [848] trial: 41, train_loss: 0.387554, test loss: 0.960402, bias2: 0.44722485542297363, variance: 0.5131773352622986\n",
      "Train size: [400] hidden size: [848] trial: 42, train_loss: 0.388095, test loss: 0.961728, bias2: 0.44744056463241577, variance: 0.5142871141433716\n",
      "Train size: [400] hidden size: [848] trial: 43, train_loss: 0.390109, test loss: 0.962372, bias2: 0.44675928354263306, variance: 0.5156129598617554\n",
      "Train size: [400] hidden size: [848] trial: 44, train_loss: 0.389443, test loss: 0.960015, bias2: 0.44529300928115845, variance: 0.5147218108177185\n",
      "Train size: [400] hidden size: [848] trial: 45, train_loss: 0.389285, test loss: 0.958889, bias2: 0.44450563192367554, variance: 0.5143836140632629\n",
      "Train size: [400] hidden size: [848] trial: 46, train_loss: 0.389330, test loss: 0.957264, bias2: 0.4432891607284546, variance: 0.5139745473861694\n",
      "Train size: [400] hidden size: [848] trial: 47, train_loss: 0.389520, test loss: 0.954893, bias2: 0.4414975047111511, variance: 0.5133953094482422\n",
      "Train size: [400] hidden size: [848] trial: 48, train_loss: 0.388587, test loss: 0.953134, bias2: 0.4403420090675354, variance: 0.51279217004776\n",
      "Train size: [400] hidden size: [848] trial: 49, train_loss: 0.388505, test loss: 0.952700, bias2: 0.43995386362075806, variance: 0.5127463936805725\n",
      "##################################################\n",
      "Train size: [400] hidden size: [977] trial: 0, train_loss: 0.381814, test loss: 0.903353, bias2: 0.9033526182174683, variance: 3.5032932110823367e-09\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [977] trial: 1, train_loss: 0.369968, test loss: 0.917230, bias2: 0.6564136743545532, variance: 0.2608166038990021\n",
      "Train size: [400] hidden size: [977] trial: 2, train_loss: 0.347840, test loss: 0.909076, bias2: 0.5621342062950134, variance: 0.34694182872772217\n",
      "Train size: [400] hidden size: [977] trial: 3, train_loss: 0.341026, test loss: 0.890544, bias2: 0.5070899724960327, variance: 0.38345369696617126\n",
      "Train size: [400] hidden size: [977] trial: 4, train_loss: 0.354605, test loss: 0.898599, bias2: 0.4863715171813965, variance: 0.4122275710105896\n",
      "Train size: [400] hidden size: [977] trial: 5, train_loss: 0.352716, test loss: 0.897182, bias2: 0.4680178165435791, variance: 0.4291646480560303\n",
      "Train size: [400] hidden size: [977] trial: 6, train_loss: 0.353115, test loss: 0.914270, bias2: 0.47112753987312317, variance: 0.4431420862674713\n",
      "Train size: [400] hidden size: [977] trial: 7, train_loss: 0.354395, test loss: 0.916614, bias2: 0.4652214050292969, variance: 0.4513930678367615\n",
      "Train size: [400] hidden size: [977] trial: 8, train_loss: 0.353125, test loss: 0.917829, bias2: 0.46529513597488403, variance: 0.4525333642959595\n",
      "Train size: [400] hidden size: [977] trial: 9, train_loss: 0.352292, test loss: 0.915156, bias2: 0.46141529083251953, variance: 0.4537409543991089\n",
      "Train size: [400] hidden size: [977] trial: 10, train_loss: 0.350278, test loss: 0.911513, bias2: 0.45596662163734436, variance: 0.45554664731025696\n",
      "Train size: [400] hidden size: [977] trial: 11, train_loss: 0.350382, test loss: 0.910127, bias2: 0.44680702686309814, variance: 0.46332043409347534\n",
      "Train size: [400] hidden size: [977] trial: 12, train_loss: 0.351385, test loss: 0.909800, bias2: 0.44785159826278687, variance: 0.4619484543800354\n",
      "Train size: [400] hidden size: [977] trial: 13, train_loss: 0.351020, test loss: 0.913453, bias2: 0.4496210813522339, variance: 0.4638316035270691\n",
      "Train size: [400] hidden size: [977] trial: 14, train_loss: 0.347730, test loss: 0.914492, bias2: 0.4496024250984192, variance: 0.4648895859718323\n",
      "Train size: [400] hidden size: [977] trial: 15, train_loss: 0.347627, test loss: 0.914686, bias2: 0.4511902332305908, variance: 0.463495671749115\n",
      "Train size: [400] hidden size: [977] trial: 16, train_loss: 0.347072, test loss: 0.912286, bias2: 0.4475584030151367, variance: 0.464727520942688\n",
      "Train size: [400] hidden size: [977] trial: 17, train_loss: 0.346398, test loss: 0.911186, bias2: 0.4439389407634735, variance: 0.4672469198703766\n",
      "Train size: [400] hidden size: [977] trial: 18, train_loss: 0.349520, test loss: 0.907560, bias2: 0.439227819442749, variance: 0.46833258867263794\n",
      "Train size: [400] hidden size: [977] trial: 19, train_loss: 0.348206, test loss: 0.911075, bias2: 0.4396953284740448, variance: 0.4713801443576813\n",
      "Train size: [400] hidden size: [977] trial: 20, train_loss: 0.350208, test loss: 0.914493, bias2: 0.4405219852924347, variance: 0.47397080063819885\n",
      "Train size: [400] hidden size: [977] trial: 21, train_loss: 0.348428, test loss: 0.911206, bias2: 0.4368305504322052, variance: 0.4743753969669342\n",
      "Train size: [400] hidden size: [977] trial: 22, train_loss: 0.347385, test loss: 0.910627, bias2: 0.4351300895214081, variance: 0.47549644112586975\n",
      "Train size: [400] hidden size: [977] trial: 23, train_loss: 0.348935, test loss: 0.910391, bias2: 0.4308667480945587, variance: 0.4795243442058563\n",
      "Train size: [400] hidden size: [977] trial: 24, train_loss: 0.347810, test loss: 0.910709, bias2: 0.4281949996948242, variance: 0.4825136661529541\n",
      "Train size: [400] hidden size: [977] trial: 25, train_loss: 0.346785, test loss: 0.910544, bias2: 0.4276118278503418, variance: 0.4829319715499878\n",
      "Train size: [400] hidden size: [977] trial: 26, train_loss: 0.347510, test loss: 0.913230, bias2: 0.4285549819469452, variance: 0.4846750795841217\n",
      "Train size: [400] hidden size: [977] trial: 27, train_loss: 0.349342, test loss: 0.914976, bias2: 0.42794090509414673, variance: 0.48703473806381226\n",
      "Train size: [400] hidden size: [977] trial: 28, train_loss: 0.350361, test loss: 0.917500, bias2: 0.4275355339050293, variance: 0.48996496200561523\n",
      "Train size: [400] hidden size: [977] trial: 29, train_loss: 0.349419, test loss: 0.910386, bias2: 0.4222051501274109, variance: 0.48818057775497437\n",
      "Train size: [400] hidden size: [977] trial: 30, train_loss: 0.351435, test loss: 0.909007, bias2: 0.4205189645290375, variance: 0.48848840594291687\n",
      "Train size: [400] hidden size: [977] trial: 31, train_loss: 0.351105, test loss: 0.909564, bias2: 0.4204190969467163, variance: 0.489144504070282\n",
      "Train size: [400] hidden size: [977] trial: 32, train_loss: 0.350322, test loss: 0.908618, bias2: 0.41644468903541565, variance: 0.4921731650829315\n",
      "Train size: [400] hidden size: [977] trial: 33, train_loss: 0.349214, test loss: 0.908347, bias2: 0.41545671224594116, variance: 0.4928898215293884\n",
      "Train size: [400] hidden size: [977] trial: 34, train_loss: 0.348600, test loss: 0.906669, bias2: 0.4126634895801544, variance: 0.49400559067726135\n",
      "Train size: [400] hidden size: [977] trial: 35, train_loss: 0.348797, test loss: 0.908737, bias2: 0.41380101442337036, variance: 0.49493616819381714\n",
      "Train size: [400] hidden size: [977] trial: 36, train_loss: 0.347886, test loss: 0.908609, bias2: 0.4117983281612396, variance: 0.4968101680278778\n",
      "Train size: [400] hidden size: [977] trial: 37, train_loss: 0.347103, test loss: 0.909589, bias2: 0.4122634530067444, variance: 0.4973260164260864\n",
      "Train size: [400] hidden size: [977] trial: 38, train_loss: 0.347973, test loss: 0.910164, bias2: 0.411312460899353, variance: 0.4988519549369812\n",
      "Train size: [400] hidden size: [977] trial: 39, train_loss: 0.346842, test loss: 0.910795, bias2: 0.4116600751876831, variance: 0.4991353750228882\n",
      "Train size: [400] hidden size: [977] trial: 40, train_loss: 0.346657, test loss: 0.914167, bias2: 0.41415172815322876, variance: 0.5000147819519043\n",
      "Train size: [400] hidden size: [977] trial: 41, train_loss: 0.347500, test loss: 0.913542, bias2: 0.4135468304157257, variance: 0.4999949634075165\n",
      "Train size: [400] hidden size: [977] trial: 42, train_loss: 0.347564, test loss: 0.915456, bias2: 0.4154289960861206, variance: 0.500026524066925\n",
      "Train size: [400] hidden size: [977] trial: 43, train_loss: 0.347090, test loss: 0.915526, bias2: 0.4151408076286316, variance: 0.5003851056098938\n",
      "Train size: [400] hidden size: [977] trial: 44, train_loss: 0.347979, test loss: 0.914169, bias2: 0.41217589378356934, variance: 0.5019927024841309\n",
      "Train size: [400] hidden size: [977] trial: 45, train_loss: 0.347907, test loss: 0.912913, bias2: 0.411044716835022, variance: 0.5018687844276428\n",
      "Train size: [400] hidden size: [977] trial: 46, train_loss: 0.347736, test loss: 0.913234, bias2: 0.4115660786628723, variance: 0.5016675591468811\n",
      "Train size: [400] hidden size: [977] trial: 47, train_loss: 0.348887, test loss: 0.913161, bias2: 0.41016680002212524, variance: 0.5029937624931335\n",
      "Train size: [400] hidden size: [977] trial: 48, train_loss: 0.349207, test loss: 0.912286, bias2: 0.408115029335022, variance: 0.5041713714599609\n",
      "Train size: [400] hidden size: [977] trial: 49, train_loss: 0.349425, test loss: 0.912310, bias2: 0.4084773063659668, variance: 0.5038328170776367\n",
      "##################################################\n",
      "Train size: [400] hidden size: [1125] trial: 0, train_loss: 0.272387, test loss: 0.851631, bias2: 0.8516307473182678, variance: 0.0\n",
      "Train size: [400] hidden size: [1125] trial: 1, train_loss: 0.295977, test loss: 0.859932, bias2: 0.6126154661178589, variance: 0.2473161667585373\n",
      "Train size: [400] hidden size: [1125] trial: 2, train_loss: 0.287036, test loss: 0.854227, bias2: 0.5430636405944824, variance: 0.31116369366645813\n",
      "Train size: [400] hidden size: [1125] trial: 3, train_loss: 0.301307, test loss: 0.855735, bias2: 0.48482921719551086, variance: 0.37090596556663513\n",
      "Train size: [400] hidden size: [1125] trial: 4, train_loss: 0.304060, test loss: 0.871761, bias2: 0.4695582091808319, variance: 0.4022023379802704\n",
      "Train size: [400] hidden size: [1125] trial: 5, train_loss: 0.305127, test loss: 0.866448, bias2: 0.44890448451042175, variance: 0.4175432026386261\n",
      "Train size: [400] hidden size: [1125] trial: 6, train_loss: 0.308465, test loss: 0.868643, bias2: 0.4440974295139313, variance: 0.424545556306839\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [1125] trial: 7, train_loss: 0.311954, test loss: 0.878500, bias2: 0.44880935549736023, variance: 0.42969104647636414\n",
      "Train size: [400] hidden size: [1125] trial: 8, train_loss: 0.311203, test loss: 0.876481, bias2: 0.44056272506713867, variance: 0.4359182119369507\n",
      "Train size: [400] hidden size: [1125] trial: 9, train_loss: 0.306864, test loss: 0.874387, bias2: 0.4382789731025696, variance: 0.436107873916626\n",
      "Train size: [400] hidden size: [1125] trial: 10, train_loss: 0.308124, test loss: 0.879383, bias2: 0.4355563223361969, variance: 0.44382670521736145\n",
      "Train size: [400] hidden size: [1125] trial: 11, train_loss: 0.309084, test loss: 0.880316, bias2: 0.4292484223842621, variance: 0.45106759667396545\n",
      "Train size: [400] hidden size: [1125] trial: 12, train_loss: 0.311030, test loss: 0.881556, bias2: 0.4237060844898224, variance: 0.45784977078437805\n",
      "Train size: [400] hidden size: [1125] trial: 13, train_loss: 0.311281, test loss: 0.880264, bias2: 0.4197635352611542, variance: 0.460500031709671\n",
      "Train size: [400] hidden size: [1125] trial: 14, train_loss: 0.312518, test loss: 0.880835, bias2: 0.4185597598552704, variance: 0.4622757136821747\n",
      "Train size: [400] hidden size: [1125] trial: 15, train_loss: 0.314037, test loss: 0.881758, bias2: 0.41357648372650146, variance: 0.4681816101074219\n",
      "Train size: [400] hidden size: [1125] trial: 16, train_loss: 0.311804, test loss: 0.877213, bias2: 0.40928080677986145, variance: 0.4679320752620697\n",
      "Train size: [400] hidden size: [1125] trial: 17, train_loss: 0.311128, test loss: 0.875107, bias2: 0.40568915009498596, variance: 0.46941813826560974\n",
      "Train size: [400] hidden size: [1125] trial: 18, train_loss: 0.311964, test loss: 0.874583, bias2: 0.40644118189811707, variance: 0.46814224123954773\n",
      "Train size: [400] hidden size: [1125] trial: 19, train_loss: 0.310923, test loss: 0.875477, bias2: 0.4079078137874603, variance: 0.46756884455680847\n",
      "Train size: [400] hidden size: [1125] trial: 20, train_loss: 0.311007, test loss: 0.875651, bias2: 0.4095473289489746, variance: 0.4661039113998413\n",
      "Train size: [400] hidden size: [1125] trial: 21, train_loss: 0.315456, test loss: 0.877737, bias2: 0.4106425344944, variance: 0.4670943319797516\n",
      "Train size: [400] hidden size: [1125] trial: 22, train_loss: 0.316939, test loss: 0.876786, bias2: 0.40834325551986694, variance: 0.46844279766082764\n",
      "Train size: [400] hidden size: [1125] trial: 23, train_loss: 0.317567, test loss: 0.877442, bias2: 0.4042525887489319, variance: 0.47318947315216064\n",
      "Train size: [400] hidden size: [1125] trial: 24, train_loss: 0.317105, test loss: 0.879477, bias2: 0.40600043535232544, variance: 0.4734768271446228\n",
      "Train size: [400] hidden size: [1125] trial: 25, train_loss: 0.315668, test loss: 0.876097, bias2: 0.4037775993347168, variance: 0.4723193645477295\n",
      "Train size: [400] hidden size: [1125] trial: 26, train_loss: 0.315666, test loss: 0.874635, bias2: 0.4025845229625702, variance: 0.47205087542533875\n",
      "Train size: [400] hidden size: [1125] trial: 27, train_loss: 0.316079, test loss: 0.873538, bias2: 0.4010481834411621, variance: 0.47248971462249756\n",
      "Train size: [400] hidden size: [1125] trial: 28, train_loss: 0.316009, test loss: 0.875016, bias2: 0.40149539709091187, variance: 0.4735209345817566\n",
      "Train size: [400] hidden size: [1125] trial: 29, train_loss: 0.315678, test loss: 0.871540, bias2: 0.399715393781662, variance: 0.47182443737983704\n",
      "Train size: [400] hidden size: [1125] trial: 30, train_loss: 0.317162, test loss: 0.870633, bias2: 0.3983515501022339, variance: 0.47228139638900757\n",
      "Train size: [400] hidden size: [1125] trial: 31, train_loss: 0.317002, test loss: 0.869935, bias2: 0.39720916748046875, variance: 0.47272568941116333\n",
      "Train size: [400] hidden size: [1125] trial: 32, train_loss: 0.317974, test loss: 0.870620, bias2: 0.3970334529876709, variance: 0.4735862612724304\n",
      "Train size: [400] hidden size: [1125] trial: 33, train_loss: 0.318487, test loss: 0.871177, bias2: 0.3975101709365845, variance: 0.4736669063568115\n",
      "Train size: [400] hidden size: [1125] trial: 34, train_loss: 0.318462, test loss: 0.871078, bias2: 0.3961296081542969, variance: 0.4749481678009033\n",
      "Train size: [400] hidden size: [1125] trial: 35, train_loss: 0.319004, test loss: 0.872089, bias2: 0.3977813124656677, variance: 0.4743078947067261\n",
      "Train size: [400] hidden size: [1125] trial: 36, train_loss: 0.318280, test loss: 0.872969, bias2: 0.3986530900001526, variance: 0.4743156433105469\n",
      "Train size: [400] hidden size: [1125] trial: 37, train_loss: 0.317908, test loss: 0.872157, bias2: 0.39826634526252747, variance: 0.47389063239097595\n",
      "Train size: [400] hidden size: [1125] trial: 38, train_loss: 0.317770, test loss: 0.873395, bias2: 0.3988479673862457, variance: 0.47454723715782166\n",
      "Train size: [400] hidden size: [1125] trial: 39, train_loss: 0.318630, test loss: 0.876665, bias2: 0.4005679488182068, variance: 0.4760974049568176\n",
      "Train size: [400] hidden size: [1125] trial: 40, train_loss: 0.318616, test loss: 0.873413, bias2: 0.39878177642822266, variance: 0.47463077306747437\n",
      "Train size: [400] hidden size: [1125] trial: 41, train_loss: 0.318878, test loss: 0.875153, bias2: 0.3996026813983917, variance: 0.4755503237247467\n",
      "Train size: [400] hidden size: [1125] trial: 42, train_loss: 0.318774, test loss: 0.874111, bias2: 0.3983880579471588, variance: 0.47572287917137146\n",
      "Train size: [400] hidden size: [1125] trial: 43, train_loss: 0.318876, test loss: 0.873080, bias2: 0.39650699496269226, variance: 0.47657325863838196\n",
      "Train size: [400] hidden size: [1125] trial: 44, train_loss: 0.319307, test loss: 0.872642, bias2: 0.39658012986183167, variance: 0.4760614335536957\n",
      "Train size: [400] hidden size: [1125] trial: 45, train_loss: 0.319652, test loss: 0.872996, bias2: 0.3964677155017853, variance: 0.47652873396873474\n",
      "Train size: [400] hidden size: [1125] trial: 46, train_loss: 0.319338, test loss: 0.874501, bias2: 0.39658334851264954, variance: 0.47791799902915955\n",
      "Train size: [400] hidden size: [1125] trial: 47, train_loss: 0.319240, test loss: 0.874458, bias2: 0.39762231707572937, variance: 0.47683581709861755\n",
      "Train size: [400] hidden size: [1125] trial: 48, train_loss: 0.319373, test loss: 0.877176, bias2: 0.3984839916229248, variance: 0.4786922335624695\n",
      "Train size: [400] hidden size: [1125] trial: 49, train_loss: 0.320857, test loss: 0.878207, bias2: 0.39882877469062805, variance: 0.47937801480293274\n",
      "##################################################\n",
      "Train size: [400] hidden size: [1295] trial: 0, train_loss: 0.340793, test loss: 0.836018, bias2: 0.8360180258750916, variance: 3.8925479506346505e-10\n",
      "Train size: [400] hidden size: [1295] trial: 1, train_loss: 0.306912, test loss: 0.825858, bias2: 0.5983694791793823, variance: 0.22748808562755585\n",
      "Train size: [400] hidden size: [1295] trial: 2, train_loss: 0.291687, test loss: 0.863351, bias2: 0.5453646183013916, variance: 0.31798669695854187\n",
      "Train size: [400] hidden size: [1295] trial: 3, train_loss: 0.281595, test loss: 0.856477, bias2: 0.5069512128829956, variance: 0.3495261073112488\n",
      "Train size: [400] hidden size: [1295] trial: 4, train_loss: 0.280878, test loss: 0.861035, bias2: 0.48761042952537537, variance: 0.37342438101768494\n",
      "Train size: [400] hidden size: [1295] trial: 5, train_loss: 0.285021, test loss: 0.859735, bias2: 0.46312734484672546, variance: 0.39660772681236267\n",
      "Train size: [400] hidden size: [1295] trial: 6, train_loss: 0.282669, test loss: 0.856781, bias2: 0.4455138146877289, variance: 0.4112667739391327\n",
      "Train size: [400] hidden size: [1295] trial: 7, train_loss: 0.280629, test loss: 0.851360, bias2: 0.4415977895259857, variance: 0.4097622334957123\n",
      "Train size: [400] hidden size: [1295] trial: 8, train_loss: 0.278812, test loss: 0.848006, bias2: 0.4348408579826355, variance: 0.4131649136543274\n",
      "Train size: [400] hidden size: [1295] trial: 9, train_loss: 0.279607, test loss: 0.845848, bias2: 0.427432656288147, variance: 0.4184156060218811\n",
      "Train size: [400] hidden size: [1295] trial: 10, train_loss: 0.281899, test loss: 0.844433, bias2: 0.4203910529613495, variance: 0.42404189705848694\n",
      "Train size: [400] hidden size: [1295] trial: 11, train_loss: 0.278814, test loss: 0.847410, bias2: 0.4178721308708191, variance: 0.4295382499694824\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [1295] trial: 12, train_loss: 0.277064, test loss: 0.847119, bias2: 0.4182511866092682, variance: 0.42886772751808167\n",
      "Train size: [400] hidden size: [1295] trial: 13, train_loss: 0.277281, test loss: 0.847705, bias2: 0.41342127323150635, variance: 0.4342838525772095\n",
      "Train size: [400] hidden size: [1295] trial: 14, train_loss: 0.277449, test loss: 0.847885, bias2: 0.4095560908317566, variance: 0.4383288025856018\n",
      "Train size: [400] hidden size: [1295] trial: 15, train_loss: 0.278820, test loss: 0.847687, bias2: 0.40691980719566345, variance: 0.44076719880104065\n",
      "Train size: [400] hidden size: [1295] trial: 16, train_loss: 0.279601, test loss: 0.848852, bias2: 0.4075709879398346, variance: 0.4412810504436493\n",
      "Train size: [400] hidden size: [1295] trial: 17, train_loss: 0.279942, test loss: 0.850782, bias2: 0.4094621539115906, variance: 0.4413200616836548\n",
      "Train size: [400] hidden size: [1295] trial: 18, train_loss: 0.281611, test loss: 0.850747, bias2: 0.40566185116767883, variance: 0.4450855553150177\n",
      "Train size: [400] hidden size: [1295] trial: 19, train_loss: 0.284740, test loss: 0.849816, bias2: 0.4010866582393646, variance: 0.44872912764549255\n",
      "Train size: [400] hidden size: [1295] trial: 20, train_loss: 0.284047, test loss: 0.847880, bias2: 0.3998427093029022, variance: 0.44803765416145325\n",
      "Train size: [400] hidden size: [1295] trial: 21, train_loss: 0.282437, test loss: 0.851302, bias2: 0.4050174355506897, variance: 0.44628435373306274\n",
      "Train size: [400] hidden size: [1295] trial: 22, train_loss: 0.284339, test loss: 0.854238, bias2: 0.40512746572494507, variance: 0.4491102695465088\n",
      "Train size: [400] hidden size: [1295] trial: 23, train_loss: 0.285730, test loss: 0.853711, bias2: 0.40514716506004333, variance: 0.4485642611980438\n",
      "Train size: [400] hidden size: [1295] trial: 24, train_loss: 0.285875, test loss: 0.854535, bias2: 0.40580540895462036, variance: 0.44872939586639404\n",
      "Train size: [400] hidden size: [1295] trial: 25, train_loss: 0.285403, test loss: 0.852802, bias2: 0.40218234062194824, variance: 0.4506199359893799\n",
      "Train size: [400] hidden size: [1295] trial: 26, train_loss: 0.284534, test loss: 0.850490, bias2: 0.4001867175102234, variance: 0.4503030776977539\n",
      "Train size: [400] hidden size: [1295] trial: 27, train_loss: 0.283936, test loss: 0.848560, bias2: 0.3991595208644867, variance: 0.449400395154953\n",
      "Train size: [400] hidden size: [1295] trial: 28, train_loss: 0.285268, test loss: 0.848618, bias2: 0.39724859595298767, variance: 0.4513690769672394\n",
      "Train size: [400] hidden size: [1295] trial: 29, train_loss: 0.283825, test loss: 0.845152, bias2: 0.3957837224006653, variance: 0.4493684768676758\n",
      "Train size: [400] hidden size: [1295] trial: 30, train_loss: 0.283650, test loss: 0.843171, bias2: 0.3934941589832306, variance: 0.4496772587299347\n",
      "Train size: [400] hidden size: [1295] trial: 31, train_loss: 0.283691, test loss: 0.844875, bias2: 0.3946768343448639, variance: 0.4501986801624298\n",
      "Train size: [400] hidden size: [1295] trial: 32, train_loss: 0.283788, test loss: 0.844952, bias2: 0.39409318566322327, variance: 0.45085880160331726\n",
      "Train size: [400] hidden size: [1295] trial: 33, train_loss: 0.283288, test loss: 0.843412, bias2: 0.3912539482116699, variance: 0.45215821266174316\n",
      "Train size: [400] hidden size: [1295] trial: 34, train_loss: 0.283704, test loss: 0.842881, bias2: 0.39139971137046814, variance: 0.45148155093193054\n",
      "Train size: [400] hidden size: [1295] trial: 35, train_loss: 0.283742, test loss: 0.841715, bias2: 0.39061009883880615, variance: 0.45110464096069336\n",
      "Train size: [400] hidden size: [1295] trial: 36, train_loss: 0.283392, test loss: 0.842778, bias2: 0.3909784257411957, variance: 0.45179983973503113\n",
      "Train size: [400] hidden size: [1295] trial: 37, train_loss: 0.283029, test loss: 0.841482, bias2: 0.3906444311141968, variance: 0.4508371949195862\n",
      "Train size: [400] hidden size: [1295] trial: 38, train_loss: 0.283844, test loss: 0.843575, bias2: 0.3909928500652313, variance: 0.45258232951164246\n",
      "Train size: [400] hidden size: [1295] trial: 39, train_loss: 0.283941, test loss: 0.844249, bias2: 0.38978928327560425, variance: 0.45445936918258667\n",
      "Train size: [400] hidden size: [1295] trial: 40, train_loss: 0.283625, test loss: 0.844108, bias2: 0.39028069376945496, variance: 0.45382705330848694\n",
      "Train size: [400] hidden size: [1295] trial: 41, train_loss: 0.284937, test loss: 0.842936, bias2: 0.3887903392314911, variance: 0.45414599776268005\n",
      "Train size: [400] hidden size: [1295] trial: 42, train_loss: 0.285320, test loss: 0.844297, bias2: 0.38941264152526855, variance: 0.45488423109054565\n",
      "Train size: [400] hidden size: [1295] trial: 43, train_loss: 0.286044, test loss: 0.845483, bias2: 0.3902947008609772, variance: 0.4551885426044464\n",
      "Train size: [400] hidden size: [1295] trial: 44, train_loss: 0.285348, test loss: 0.845244, bias2: 0.3906400799751282, variance: 0.45460426807403564\n",
      "Train size: [400] hidden size: [1295] trial: 45, train_loss: 0.284743, test loss: 0.845738, bias2: 0.3910122811794281, variance: 0.4547257125377655\n",
      "Train size: [400] hidden size: [1295] trial: 46, train_loss: 0.285296, test loss: 0.845299, bias2: 0.39110398292541504, variance: 0.45419466495513916\n",
      "Train size: [400] hidden size: [1295] trial: 47, train_loss: 0.284729, test loss: 0.843508, bias2: 0.39063239097595215, variance: 0.4528753161430359\n",
      "Train size: [400] hidden size: [1295] trial: 48, train_loss: 0.284094, test loss: 0.845078, bias2: 0.3920718729496002, variance: 0.4530063569545746\n",
      "Train size: [400] hidden size: [1295] trial: 49, train_loss: 0.283453, test loss: 0.844642, bias2: 0.3922737240791321, variance: 0.45236796140670776\n",
      "##################################################\n",
      "Train size: [400] hidden size: [1491] trial: 0, train_loss: 0.300733, test loss: 0.780454, bias2: 0.7804537415504456, variance: -4.281802912231569e-09\n",
      "Train size: [400] hidden size: [1491] trial: 1, train_loss: 0.277786, test loss: 0.797334, bias2: 0.5663978457450867, variance: 0.2309359312057495\n",
      "Train size: [400] hidden size: [1491] trial: 2, train_loss: 0.285351, test loss: 0.803079, bias2: 0.48240718245506287, variance: 0.3206721842288971\n",
      "Train size: [400] hidden size: [1491] trial: 3, train_loss: 0.278151, test loss: 0.797533, bias2: 0.44727781414985657, variance: 0.3502548038959503\n",
      "Train size: [400] hidden size: [1491] trial: 4, train_loss: 0.274051, test loss: 0.808614, bias2: 0.4371342957019806, variance: 0.37147942185401917\n",
      "Train size: [400] hidden size: [1491] trial: 5, train_loss: 0.277616, test loss: 0.809158, bias2: 0.4232647716999054, variance: 0.3858936131000519\n",
      "Train size: [400] hidden size: [1491] trial: 6, train_loss: 0.282547, test loss: 0.814776, bias2: 0.41346612572669983, variance: 0.40131011605262756\n",
      "Train size: [400] hidden size: [1491] trial: 7, train_loss: 0.282889, test loss: 0.812445, bias2: 0.4054643213748932, variance: 0.4069805443286896\n",
      "Train size: [400] hidden size: [1491] trial: 8, train_loss: 0.276550, test loss: 0.811360, bias2: 0.3982071280479431, variance: 0.4131527543067932\n",
      "Train size: [400] hidden size: [1491] trial: 9, train_loss: 0.273445, test loss: 0.814810, bias2: 0.39957353472709656, variance: 0.41523608565330505\n",
      "Train size: [400] hidden size: [1491] trial: 10, train_loss: 0.268573, test loss: 0.816991, bias2: 0.40183767676353455, variance: 0.4151534140110016\n",
      "Train size: [400] hidden size: [1491] trial: 11, train_loss: 0.268447, test loss: 0.814926, bias2: 0.39883601665496826, variance: 0.4160900115966797\n",
      "Train size: [400] hidden size: [1491] trial: 12, train_loss: 0.267335, test loss: 0.814656, bias2: 0.3957960605621338, variance: 0.41885989904403687\n",
      "Train size: [400] hidden size: [1491] trial: 13, train_loss: 0.267332, test loss: 0.818594, bias2: 0.39635196328163147, variance: 0.42224153876304626\n",
      "Train size: [400] hidden size: [1491] trial: 14, train_loss: 0.266276, test loss: 0.818471, bias2: 0.393381267786026, variance: 0.42508968710899353\n",
      "Train size: [400] hidden size: [1491] trial: 15, train_loss: 0.265208, test loss: 0.819354, bias2: 0.3932991921901703, variance: 0.42605456709861755\n",
      "Train size: [400] hidden size: [1491] trial: 16, train_loss: 0.266049, test loss: 0.820976, bias2: 0.392715185880661, variance: 0.42826059460639954\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [1491] trial: 17, train_loss: 0.265905, test loss: 0.821401, bias2: 0.3903369903564453, variance: 0.431064248085022\n",
      "Train size: [400] hidden size: [1491] trial: 18, train_loss: 0.265912, test loss: 0.819479, bias2: 0.38815873861312866, variance: 0.4313204288482666\n",
      "Train size: [400] hidden size: [1491] trial: 19, train_loss: 0.267913, test loss: 0.815898, bias2: 0.3833259642124176, variance: 0.432571679353714\n",
      "Train size: [400] hidden size: [1491] trial: 20, train_loss: 0.266533, test loss: 0.813796, bias2: 0.38153958320617676, variance: 0.43225663900375366\n",
      "Train size: [400] hidden size: [1491] trial: 21, train_loss: 0.265413, test loss: 0.815887, bias2: 0.3830055594444275, variance: 0.432881236076355\n",
      "Train size: [400] hidden size: [1491] trial: 22, train_loss: 0.267030, test loss: 0.814660, bias2: 0.37888243794441223, variance: 0.4357771575450897\n",
      "Train size: [400] hidden size: [1491] trial: 23, train_loss: 0.267155, test loss: 0.815423, bias2: 0.3808553218841553, variance: 0.434567391872406\n",
      "Train size: [400] hidden size: [1491] trial: 24, train_loss: 0.267344, test loss: 0.816767, bias2: 0.3824525475502014, variance: 0.4343148469924927\n",
      "Train size: [400] hidden size: [1491] trial: 25, train_loss: 0.268539, test loss: 0.817014, bias2: 0.3789997100830078, variance: 0.4380147457122803\n",
      "Train size: [400] hidden size: [1491] trial: 26, train_loss: 0.268402, test loss: 0.819592, bias2: 0.38064005970954895, variance: 0.4389517605304718\n",
      "Train size: [400] hidden size: [1491] trial: 27, train_loss: 0.268366, test loss: 0.821314, bias2: 0.3825538754463196, variance: 0.43876057863235474\n",
      "Train size: [400] hidden size: [1491] trial: 28, train_loss: 0.268210, test loss: 0.823955, bias2: 0.384307861328125, variance: 0.43964684009552\n",
      "Train size: [400] hidden size: [1491] trial: 29, train_loss: 0.268016, test loss: 0.822996, bias2: 0.38454678654670715, variance: 0.43844929337501526\n",
      "Train size: [400] hidden size: [1491] trial: 30, train_loss: 0.267248, test loss: 0.821608, bias2: 0.3841035068035126, variance: 0.4375046193599701\n",
      "Train size: [400] hidden size: [1491] trial: 31, train_loss: 0.267517, test loss: 0.823328, bias2: 0.38407838344573975, variance: 0.43924981355667114\n",
      "Train size: [400] hidden size: [1491] trial: 32, train_loss: 0.266218, test loss: 0.825020, bias2: 0.38676804304122925, variance: 0.43825191259384155\n",
      "Train size: [400] hidden size: [1491] trial: 33, train_loss: 0.266008, test loss: 0.825789, bias2: 0.38693273067474365, variance: 0.4388560652732849\n",
      "Train size: [400] hidden size: [1491] trial: 34, train_loss: 0.266521, test loss: 0.825260, bias2: 0.3845651149749756, variance: 0.4406946897506714\n",
      "Train size: [400] hidden size: [1491] trial: 35, train_loss: 0.264733, test loss: 0.825634, bias2: 0.3863082826137543, variance: 0.43932583928108215\n",
      "Train size: [400] hidden size: [1491] trial: 36, train_loss: 0.264706, test loss: 0.823730, bias2: 0.3844558298587799, variance: 0.4392746388912201\n",
      "Train size: [400] hidden size: [1491] trial: 37, train_loss: 0.264802, test loss: 0.822471, bias2: 0.383764386177063, variance: 0.43870657682418823\n",
      "Train size: [400] hidden size: [1491] trial: 38, train_loss: 0.266314, test loss: 0.821424, bias2: 0.3808439373970032, variance: 0.4405803680419922\n",
      "Train size: [400] hidden size: [1491] trial: 39, train_loss: 0.265519, test loss: 0.821696, bias2: 0.3819025158882141, variance: 0.43979305028915405\n",
      "Train size: [400] hidden size: [1491] trial: 40, train_loss: 0.265614, test loss: 0.821714, bias2: 0.3798738718032837, variance: 0.44183963537216187\n",
      "Train size: [400] hidden size: [1491] trial: 41, train_loss: 0.265522, test loss: 0.821481, bias2: 0.3799006938934326, variance: 0.4415803551673889\n",
      "Train size: [400] hidden size: [1491] trial: 42, train_loss: 0.266016, test loss: 0.820552, bias2: 0.378964900970459, variance: 0.4415872097015381\n",
      "Train size: [400] hidden size: [1491] trial: 43, train_loss: 0.266597, test loss: 0.820477, bias2: 0.37817350029945374, variance: 0.442303329706192\n",
      "Train size: [400] hidden size: [1491] trial: 44, train_loss: 0.267227, test loss: 0.820849, bias2: 0.3784825801849365, variance: 0.4423660635948181\n",
      "Train size: [400] hidden size: [1491] trial: 45, train_loss: 0.267290, test loss: 0.821841, bias2: 0.37898463010787964, variance: 0.4428562521934509\n",
      "Train size: [400] hidden size: [1491] trial: 46, train_loss: 0.266925, test loss: 0.819425, bias2: 0.37702512741088867, variance: 0.44239962100982666\n",
      "Train size: [400] hidden size: [1491] trial: 47, train_loss: 0.266567, test loss: 0.819336, bias2: 0.3772754371166229, variance: 0.4420609176158905\n",
      "Train size: [400] hidden size: [1491] trial: 48, train_loss: 0.266467, test loss: 0.820662, bias2: 0.3773064911365509, variance: 0.44335511326789856\n",
      "Train size: [400] hidden size: [1491] trial: 49, train_loss: 0.266323, test loss: 0.821916, bias2: 0.37808912992477417, variance: 0.44382667541503906\n",
      "##################################################\n",
      "Train size: [400] hidden size: [1717] trial: 0, train_loss: 0.234451, test loss: 0.807138, bias2: 0.807137668132782, variance: -2.3355288814030928e-09\n",
      "Train size: [400] hidden size: [1717] trial: 1, train_loss: 0.257214, test loss: 0.787286, bias2: 0.5619274377822876, variance: 0.22535841166973114\n",
      "Train size: [400] hidden size: [1717] trial: 2, train_loss: 0.259581, test loss: 0.765467, bias2: 0.468189001083374, variance: 0.29727816581726074\n",
      "Train size: [400] hidden size: [1717] trial: 3, train_loss: 0.250811, test loss: 0.792050, bias2: 0.45857661962509155, variance: 0.3334731459617615\n",
      "Train size: [400] hidden size: [1717] trial: 4, train_loss: 0.253575, test loss: 0.802845, bias2: 0.44044363498687744, variance: 0.36240124702453613\n",
      "Train size: [400] hidden size: [1717] trial: 5, train_loss: 0.253756, test loss: 0.798754, bias2: 0.4267352521419525, variance: 0.3720192015171051\n",
      "Train size: [400] hidden size: [1717] trial: 6, train_loss: 0.249295, test loss: 0.801542, bias2: 0.42379507422447205, variance: 0.37774714827537537\n",
      "Train size: [400] hidden size: [1717] trial: 7, train_loss: 0.246116, test loss: 0.800634, bias2: 0.4188741147518158, variance: 0.38176003098487854\n",
      "Train size: [400] hidden size: [1717] trial: 8, train_loss: 0.244752, test loss: 0.796162, bias2: 0.4142303466796875, variance: 0.3819320797920227\n",
      "Train size: [400] hidden size: [1717] trial: 9, train_loss: 0.246437, test loss: 0.798995, bias2: 0.4098150432109833, variance: 0.3891797959804535\n",
      "Train size: [400] hidden size: [1717] trial: 10, train_loss: 0.246953, test loss: 0.800902, bias2: 0.40244290232658386, variance: 0.39845892786979675\n",
      "Train size: [400] hidden size: [1717] trial: 11, train_loss: 0.247861, test loss: 0.799064, bias2: 0.3988398313522339, variance: 0.40022462606430054\n",
      "Train size: [400] hidden size: [1717] trial: 12, train_loss: 0.247732, test loss: 0.791812, bias2: 0.38617539405822754, variance: 0.4056370258331299\n",
      "Train size: [400] hidden size: [1717] trial: 13, train_loss: 0.251063, test loss: 0.796978, bias2: 0.38751596212387085, variance: 0.409462034702301\n",
      "Train size: [400] hidden size: [1717] trial: 14, train_loss: 0.253060, test loss: 0.796142, bias2: 0.3853070139884949, variance: 0.4108351469039917\n",
      "Train size: [400] hidden size: [1717] trial: 15, train_loss: 0.253154, test loss: 0.798842, bias2: 0.38538292050361633, variance: 0.41345903277397156\n",
      "Train size: [400] hidden size: [1717] trial: 16, train_loss: 0.250474, test loss: 0.798767, bias2: 0.3862604796886444, variance: 0.4125063717365265\n",
      "Train size: [400] hidden size: [1717] trial: 17, train_loss: 0.250558, test loss: 0.798444, bias2: 0.38525763154029846, variance: 0.413186639547348\n",
      "Train size: [400] hidden size: [1717] trial: 18, train_loss: 0.249528, test loss: 0.798774, bias2: 0.3839443624019623, variance: 0.41482964158058167\n",
      "Train size: [400] hidden size: [1717] trial: 19, train_loss: 0.251173, test loss: 0.798328, bias2: 0.3818023204803467, variance: 0.4165254235267639\n",
      "Train size: [400] hidden size: [1717] trial: 20, train_loss: 0.251860, test loss: 0.796750, bias2: 0.3812154531478882, variance: 0.41553449630737305\n",
      "Train size: [400] hidden size: [1717] trial: 21, train_loss: 0.250737, test loss: 0.795800, bias2: 0.3784174621105194, variance: 0.4173826277256012\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [1717] trial: 22, train_loss: 0.250883, test loss: 0.791710, bias2: 0.37610703706741333, variance: 0.41560304164886475\n",
      "Train size: [400] hidden size: [1717] trial: 23, train_loss: 0.250547, test loss: 0.793080, bias2: 0.3741644620895386, variance: 0.4189158082008362\n",
      "Train size: [400] hidden size: [1717] trial: 24, train_loss: 0.249579, test loss: 0.792033, bias2: 0.37306201457977295, variance: 0.41897112131118774\n",
      "Train size: [400] hidden size: [1717] trial: 25, train_loss: 0.249168, test loss: 0.790897, bias2: 0.37267589569091797, variance: 0.41822075843811035\n",
      "Train size: [400] hidden size: [1717] trial: 26, train_loss: 0.250255, test loss: 0.793097, bias2: 0.37362390756607056, variance: 0.4194726347923279\n",
      "Train size: [400] hidden size: [1717] trial: 27, train_loss: 0.249385, test loss: 0.797088, bias2: 0.37781479954719543, variance: 0.4192735254764557\n",
      "Train size: [400] hidden size: [1717] trial: 28, train_loss: 0.249882, test loss: 0.796652, bias2: 0.3766948878765106, variance: 0.4199574887752533\n",
      "Train size: [400] hidden size: [1717] trial: 29, train_loss: 0.248919, test loss: 0.797973, bias2: 0.37778013944625854, variance: 0.4201925992965698\n",
      "Train size: [400] hidden size: [1717] trial: 30, train_loss: 0.248756, test loss: 0.798509, bias2: 0.37843194603919983, variance: 0.4200766384601593\n",
      "Train size: [400] hidden size: [1717] trial: 31, train_loss: 0.248739, test loss: 0.800044, bias2: 0.3778073787689209, variance: 0.4222365617752075\n",
      "Train size: [400] hidden size: [1717] trial: 32, train_loss: 0.249003, test loss: 0.797655, bias2: 0.37598419189453125, variance: 0.42167043685913086\n",
      "Train size: [400] hidden size: [1717] trial: 33, train_loss: 0.249078, test loss: 0.796685, bias2: 0.37469300627708435, variance: 0.4219925105571747\n",
      "Train size: [400] hidden size: [1717] trial: 34, train_loss: 0.249327, test loss: 0.794404, bias2: 0.3730887472629547, variance: 0.42131564021110535\n",
      "Train size: [400] hidden size: [1717] trial: 35, train_loss: 0.250077, test loss: 0.795074, bias2: 0.3733290433883667, variance: 0.4217451214790344\n",
      "Train size: [400] hidden size: [1717] trial: 36, train_loss: 0.250428, test loss: 0.795180, bias2: 0.3732798099517822, variance: 0.4219006299972534\n",
      "Train size: [400] hidden size: [1717] trial: 37, train_loss: 0.249400, test loss: 0.793894, bias2: 0.37276455760002136, variance: 0.4211297333240509\n",
      "Train size: [400] hidden size: [1717] trial: 38, train_loss: 0.250145, test loss: 0.796095, bias2: 0.3727428913116455, variance: 0.42335259914398193\n",
      "Train size: [400] hidden size: [1717] trial: 39, train_loss: 0.249563, test loss: 0.794961, bias2: 0.37186577916145325, variance: 0.4230951964855194\n",
      "Train size: [400] hidden size: [1717] trial: 40, train_loss: 0.249627, test loss: 0.793968, bias2: 0.3707141876220703, variance: 0.4232534170150757\n",
      "Train size: [400] hidden size: [1717] trial: 41, train_loss: 0.249287, test loss: 0.794227, bias2: 0.3704591989517212, variance: 0.4237680435180664\n",
      "Train size: [400] hidden size: [1717] trial: 42, train_loss: 0.248984, test loss: 0.792617, bias2: 0.3687281608581543, variance: 0.42388880252838135\n",
      "Train size: [400] hidden size: [1717] trial: 43, train_loss: 0.248027, test loss: 0.793984, bias2: 0.3700474500656128, variance: 0.42393678426742554\n",
      "Train size: [400] hidden size: [1717] trial: 44, train_loss: 0.247126, test loss: 0.794299, bias2: 0.3708439767360687, variance: 0.4234550893306732\n",
      "Train size: [400] hidden size: [1717] trial: 45, train_loss: 0.246691, test loss: 0.795989, bias2: 0.3718937933444977, variance: 0.4240953028202057\n",
      "Train size: [400] hidden size: [1717] trial: 46, train_loss: 0.246577, test loss: 0.793883, bias2: 0.3701406419277191, variance: 0.4237422049045563\n",
      "Train size: [400] hidden size: [1717] trial: 47, train_loss: 0.246750, test loss: 0.793686, bias2: 0.36957186460494995, variance: 0.4241138696670532\n",
      "Train size: [400] hidden size: [1717] trial: 48, train_loss: 0.246611, test loss: 0.794222, bias2: 0.36910802125930786, variance: 0.42511433362960815\n",
      "Train size: [400] hidden size: [1717] trial: 49, train_loss: 0.246910, test loss: 0.794026, bias2: 0.36803165078163147, variance: 0.42599400877952576\n",
      "##################################################\n",
      "Train size: [400] hidden size: [1977] trial: 0, train_loss: 0.246621, test loss: 0.912076, bias2: 0.9120757579803467, variance: 4.6710577628061856e-09\n",
      "Train size: [400] hidden size: [1977] trial: 1, train_loss: 0.233296, test loss: 0.849697, bias2: 0.6293652057647705, variance: 0.22033177316188812\n",
      "Train size: [400] hidden size: [1977] trial: 2, train_loss: 0.229451, test loss: 0.824427, bias2: 0.5459834337234497, variance: 0.27844369411468506\n",
      "Train size: [400] hidden size: [1977] trial: 3, train_loss: 0.229713, test loss: 0.812606, bias2: 0.49597856402397156, variance: 0.3166278898715973\n",
      "Train size: [400] hidden size: [1977] trial: 4, train_loss: 0.224333, test loss: 0.799079, bias2: 0.4678935110569, variance: 0.3311857283115387\n",
      "Train size: [400] hidden size: [1977] trial: 5, train_loss: 0.228065, test loss: 0.796455, bias2: 0.4550021290779114, variance: 0.34145259857177734\n",
      "Train size: [400] hidden size: [1977] trial: 6, train_loss: 0.231096, test loss: 0.786268, bias2: 0.43390336632728577, variance: 0.352365106344223\n",
      "Train size: [400] hidden size: [1977] trial: 7, train_loss: 0.230422, test loss: 0.779955, bias2: 0.41976383328437805, variance: 0.3601911962032318\n",
      "Train size: [400] hidden size: [1977] trial: 8, train_loss: 0.231678, test loss: 0.781130, bias2: 0.419379860162735, variance: 0.3617500960826874\n",
      "Train size: [400] hidden size: [1977] trial: 9, train_loss: 0.230103, test loss: 0.771598, bias2: 0.40996259450912476, variance: 0.3616354465484619\n",
      "Train size: [400] hidden size: [1977] trial: 10, train_loss: 0.228261, test loss: 0.771960, bias2: 0.4073008894920349, variance: 0.36465948820114136\n",
      "Train size: [400] hidden size: [1977] trial: 11, train_loss: 0.225970, test loss: 0.777584, bias2: 0.4083611071109772, variance: 0.369223028421402\n",
      "Train size: [400] hidden size: [1977] trial: 12, train_loss: 0.224894, test loss: 0.777734, bias2: 0.4074464738368988, variance: 0.3702875077724457\n",
      "Train size: [400] hidden size: [1977] trial: 13, train_loss: 0.224807, test loss: 0.773809, bias2: 0.3998381197452545, variance: 0.37397047877311707\n",
      "Train size: [400] hidden size: [1977] trial: 14, train_loss: 0.225749, test loss: 0.771491, bias2: 0.3956504166126251, variance: 0.37584105134010315\n",
      "Train size: [400] hidden size: [1977] trial: 15, train_loss: 0.225875, test loss: 0.772590, bias2: 0.3969119191169739, variance: 0.3756778836250305\n",
      "Train size: [400] hidden size: [1977] trial: 16, train_loss: 0.227227, test loss: 0.770490, bias2: 0.39234980940818787, variance: 0.3781401216983795\n",
      "Train size: [400] hidden size: [1977] trial: 17, train_loss: 0.227565, test loss: 0.771768, bias2: 0.38885796070098877, variance: 0.3829103112220764\n",
      "Train size: [400] hidden size: [1977] trial: 18, train_loss: 0.227539, test loss: 0.770347, bias2: 0.3848152160644531, variance: 0.3855316638946533\n",
      "Train size: [400] hidden size: [1977] trial: 19, train_loss: 0.227743, test loss: 0.768829, bias2: 0.3816995322704315, variance: 0.38712945580482483\n",
      "Train size: [400] hidden size: [1977] trial: 20, train_loss: 0.228974, test loss: 0.767137, bias2: 0.3782564103603363, variance: 0.38888105750083923\n",
      "Train size: [400] hidden size: [1977] trial: 21, train_loss: 0.230144, test loss: 0.767984, bias2: 0.3779847025871277, variance: 0.3899994492530823\n",
      "Train size: [400] hidden size: [1977] trial: 22, train_loss: 0.230757, test loss: 0.771195, bias2: 0.379352331161499, variance: 0.39184266328811646\n",
      "Train size: [400] hidden size: [1977] trial: 23, train_loss: 0.230347, test loss: 0.769850, bias2: 0.37587490677833557, variance: 0.3939753472805023\n",
      "Train size: [400] hidden size: [1977] trial: 24, train_loss: 0.229909, test loss: 0.771307, bias2: 0.3767256736755371, variance: 0.39458167552948\n",
      "Train size: [400] hidden size: [1977] trial: 25, train_loss: 0.229362, test loss: 0.771653, bias2: 0.3768519163131714, variance: 0.39480096101760864\n",
      "Train size: [400] hidden size: [1977] trial: 26, train_loss: 0.229511, test loss: 0.772897, bias2: 0.3785742223262787, variance: 0.3943232595920563\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [1977] trial: 27, train_loss: 0.228874, test loss: 0.773057, bias2: 0.3778328001499176, variance: 0.3952242434024811\n",
      "Train size: [400] hidden size: [1977] trial: 28, train_loss: 0.228200, test loss: 0.775803, bias2: 0.37984806299209595, variance: 0.3959553837776184\n",
      "Train size: [400] hidden size: [1977] trial: 29, train_loss: 0.228454, test loss: 0.776583, bias2: 0.37983351945877075, variance: 0.39674943685531616\n",
      "Train size: [400] hidden size: [1977] trial: 30, train_loss: 0.228497, test loss: 0.774704, bias2: 0.3771570920944214, variance: 0.39754682779312134\n",
      "Train size: [400] hidden size: [1977] trial: 31, train_loss: 0.228268, test loss: 0.774861, bias2: 0.37670034170150757, variance: 0.39816033840179443\n",
      "Train size: [400] hidden size: [1977] trial: 32, train_loss: 0.227526, test loss: 0.775790, bias2: 0.3769770562648773, variance: 0.39881274104118347\n",
      "Train size: [400] hidden size: [1977] trial: 33, train_loss: 0.227849, test loss: 0.774529, bias2: 0.37489619851112366, variance: 0.3996332585811615\n",
      "Train size: [400] hidden size: [1977] trial: 34, train_loss: 0.228497, test loss: 0.776270, bias2: 0.376286119222641, variance: 0.39998385310173035\n",
      "Train size: [400] hidden size: [1977] trial: 35, train_loss: 0.228586, test loss: 0.776553, bias2: 0.3754141628742218, variance: 0.40113887190818787\n",
      "Train size: [400] hidden size: [1977] trial: 36, train_loss: 0.228045, test loss: 0.776280, bias2: 0.37483012676239014, variance: 0.40145009756088257\n",
      "Train size: [400] hidden size: [1977] trial: 37, train_loss: 0.227428, test loss: 0.777652, bias2: 0.3760148584842682, variance: 0.40163764357566833\n",
      "Train size: [400] hidden size: [1977] trial: 38, train_loss: 0.227141, test loss: 0.779792, bias2: 0.3779238164424896, variance: 0.4018685519695282\n",
      "Train size: [400] hidden size: [1977] trial: 39, train_loss: 0.226982, test loss: 0.780831, bias2: 0.37867534160614014, variance: 0.4021560549736023\n",
      "Train size: [400] hidden size: [1977] trial: 40, train_loss: 0.227514, test loss: 0.779001, bias2: 0.3761720359325409, variance: 0.40282902121543884\n",
      "Train size: [400] hidden size: [1977] trial: 41, train_loss: 0.227501, test loss: 0.779157, bias2: 0.37564778327941895, variance: 0.40350890159606934\n",
      "Train size: [400] hidden size: [1977] trial: 42, train_loss: 0.227260, test loss: 0.780020, bias2: 0.37595897912979126, variance: 0.40406060218811035\n",
      "Train size: [400] hidden size: [1977] trial: 43, train_loss: 0.227150, test loss: 0.779332, bias2: 0.3748196065425873, variance: 0.4045127332210541\n",
      "Train size: [400] hidden size: [1977] trial: 44, train_loss: 0.227391, test loss: 0.779863, bias2: 0.3756248950958252, variance: 0.40423840284347534\n",
      "Train size: [400] hidden size: [1977] trial: 45, train_loss: 0.226853, test loss: 0.779381, bias2: 0.3753308057785034, variance: 0.4040501117706299\n",
      "Train size: [400] hidden size: [1977] trial: 46, train_loss: 0.226831, test loss: 0.777868, bias2: 0.37439215183258057, variance: 0.4034753441810608\n",
      "Train size: [400] hidden size: [1977] trial: 47, train_loss: 0.227075, test loss: 0.777203, bias2: 0.3733980357646942, variance: 0.40380534529685974\n",
      "Train size: [400] hidden size: [1977] trial: 48, train_loss: 0.227054, test loss: 0.778507, bias2: 0.3747090995311737, variance: 0.4037981927394867\n",
      "Train size: [400] hidden size: [1977] trial: 49, train_loss: 0.227118, test loss: 0.779487, bias2: 0.37519848346710205, variance: 0.40428900718688965\n",
      "##################################################\n",
      "Train size: [400] hidden size: [2276] trial: 0, train_loss: 0.224631, test loss: 0.747852, bias2: 0.7478522062301636, variance: 5.449567463955418e-09\n",
      "Train size: [400] hidden size: [2276] trial: 1, train_loss: 0.215217, test loss: 0.753799, bias2: 0.5508680939674377, variance: 0.20293103158473969\n",
      "Train size: [400] hidden size: [2276] trial: 2, train_loss: 0.222208, test loss: 0.750091, bias2: 0.45891597867012024, variance: 0.29117539525032043\n",
      "Train size: [400] hidden size: [2276] trial: 3, train_loss: 0.220216, test loss: 0.760130, bias2: 0.44573646783828735, variance: 0.3143931031227112\n",
      "Train size: [400] hidden size: [2276] trial: 4, train_loss: 0.216260, test loss: 0.757820, bias2: 0.43053096532821655, variance: 0.3272888660430908\n",
      "Train size: [400] hidden size: [2276] trial: 5, train_loss: 0.211690, test loss: 0.742285, bias2: 0.4073712229728699, variance: 0.3349132537841797\n",
      "Train size: [400] hidden size: [2276] trial: 6, train_loss: 0.210234, test loss: 0.737081, bias2: 0.39497771859169006, variance: 0.34210333228111267\n",
      "Train size: [400] hidden size: [2276] trial: 7, train_loss: 0.208416, test loss: 0.744982, bias2: 0.3988792300224304, variance: 0.34610307216644287\n",
      "Train size: [400] hidden size: [2276] trial: 8, train_loss: 0.208961, test loss: 0.741143, bias2: 0.39365237951278687, variance: 0.3474908471107483\n",
      "Train size: [400] hidden size: [2276] trial: 9, train_loss: 0.207356, test loss: 0.747108, bias2: 0.39476123452186584, variance: 0.35234716534614563\n",
      "Train size: [400] hidden size: [2276] trial: 10, train_loss: 0.209936, test loss: 0.749351, bias2: 0.39190393686294556, variance: 0.35744673013687134\n",
      "Train size: [400] hidden size: [2276] trial: 11, train_loss: 0.210165, test loss: 0.753782, bias2: 0.39256155490875244, variance: 0.36122018098831177\n",
      "Train size: [400] hidden size: [2276] trial: 12, train_loss: 0.211630, test loss: 0.754315, bias2: 0.38729652762413025, variance: 0.3670184314250946\n",
      "Train size: [400] hidden size: [2276] trial: 13, train_loss: 0.212454, test loss: 0.753677, bias2: 0.3845503032207489, variance: 0.3691271245479584\n",
      "Train size: [400] hidden size: [2276] trial: 14, train_loss: 0.215309, test loss: 0.758000, bias2: 0.3828903138637543, variance: 0.3751101791858673\n",
      "Train size: [400] hidden size: [2276] trial: 15, train_loss: 0.216843, test loss: 0.755441, bias2: 0.3791000545024872, variance: 0.3763406574726105\n",
      "Train size: [400] hidden size: [2276] trial: 16, train_loss: 0.216477, test loss: 0.757341, bias2: 0.37840282917022705, variance: 0.3789384365081787\n",
      "Train size: [400] hidden size: [2276] trial: 17, train_loss: 0.214990, test loss: 0.757336, bias2: 0.3775099515914917, variance: 0.3798263669013977\n",
      "Train size: [400] hidden size: [2276] trial: 18, train_loss: 0.214231, test loss: 0.757714, bias2: 0.3774855136871338, variance: 0.3802288770675659\n",
      "Train size: [400] hidden size: [2276] trial: 19, train_loss: 0.214251, test loss: 0.755882, bias2: 0.3746338188648224, variance: 0.38124802708625793\n",
      "Train size: [400] hidden size: [2276] trial: 20, train_loss: 0.215819, test loss: 0.757598, bias2: 0.37516602873802185, variance: 0.38243159651756287\n",
      "Train size: [400] hidden size: [2276] trial: 21, train_loss: 0.216151, test loss: 0.757893, bias2: 0.3749340772628784, variance: 0.382959246635437\n",
      "Train size: [400] hidden size: [2276] trial: 22, train_loss: 0.216401, test loss: 0.759947, bias2: 0.37403762340545654, variance: 0.3859092593193054\n",
      "Train size: [400] hidden size: [2276] trial: 23, train_loss: 0.216760, test loss: 0.759786, bias2: 0.37313976883888245, variance: 0.3866458237171173\n",
      "Train size: [400] hidden size: [2276] trial: 24, train_loss: 0.218478, test loss: 0.760640, bias2: 0.37100961804389954, variance: 0.3896302878856659\n",
      "Train size: [400] hidden size: [2276] trial: 25, train_loss: 0.217419, test loss: 0.758755, bias2: 0.3701043128967285, variance: 0.3886508345603943\n",
      "Train size: [400] hidden size: [2276] trial: 26, train_loss: 0.217336, test loss: 0.759098, bias2: 0.3698527216911316, variance: 0.38924533128738403\n",
      "Train size: [400] hidden size: [2276] trial: 27, train_loss: 0.219308, test loss: 0.759812, bias2: 0.36983874440193176, variance: 0.38997307419776917\n",
      "Train size: [400] hidden size: [2276] trial: 28, train_loss: 0.218438, test loss: 0.760523, bias2: 0.37053632736206055, variance: 0.38998711109161377\n",
      "Train size: [400] hidden size: [2276] trial: 29, train_loss: 0.217666, test loss: 0.760972, bias2: 0.37100949883461, variance: 0.38996216654777527\n",
      "Train size: [400] hidden size: [2276] trial: 30, train_loss: 0.217526, test loss: 0.764428, bias2: 0.3732491433620453, variance: 0.39117875695228577\n",
      "Train size: [400] hidden size: [2276] trial: 31, train_loss: 0.217650, test loss: 0.763167, bias2: 0.3720754086971283, variance: 0.3910917341709137\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [2276] trial: 32, train_loss: 0.216224, test loss: 0.763640, bias2: 0.3725545108318329, variance: 0.3910849988460541\n",
      "Train size: [400] hidden size: [2276] trial: 33, train_loss: 0.215211, test loss: 0.763349, bias2: 0.3714842200279236, variance: 0.3918642997741699\n",
      "Train size: [400] hidden size: [2276] trial: 34, train_loss: 0.215148, test loss: 0.761414, bias2: 0.3695369362831116, variance: 0.39187687635421753\n",
      "Train size: [400] hidden size: [2276] trial: 35, train_loss: 0.215751, test loss: 0.762007, bias2: 0.3681149184703827, variance: 0.3938925564289093\n",
      "Train size: [400] hidden size: [2276] trial: 36, train_loss: 0.215439, test loss: 0.763674, bias2: 0.36886951327323914, variance: 0.3948046863079071\n",
      "Train size: [400] hidden size: [2276] trial: 37, train_loss: 0.215997, test loss: 0.763657, bias2: 0.3671415150165558, variance: 0.39651569724082947\n",
      "Train size: [400] hidden size: [2276] trial: 38, train_loss: 0.215186, test loss: 0.763113, bias2: 0.3666068911552429, variance: 0.39650654792785645\n",
      "Train size: [400] hidden size: [2276] trial: 39, train_loss: 0.215660, test loss: 0.764112, bias2: 0.36734461784362793, variance: 0.396767795085907\n",
      "Train size: [400] hidden size: [2276] trial: 40, train_loss: 0.215712, test loss: 0.762133, bias2: 0.3660302758216858, variance: 0.3961032032966614\n",
      "Train size: [400] hidden size: [2276] trial: 41, train_loss: 0.215498, test loss: 0.761467, bias2: 0.36515793204307556, variance: 0.3963092267513275\n",
      "Train size: [400] hidden size: [2276] trial: 42, train_loss: 0.215284, test loss: 0.762515, bias2: 0.36623120307922363, variance: 0.39628344774246216\n",
      "Train size: [400] hidden size: [2276] trial: 43, train_loss: 0.215802, test loss: 0.763231, bias2: 0.36609068512916565, variance: 0.39714065194129944\n",
      "Train size: [400] hidden size: [2276] trial: 44, train_loss: 0.215604, test loss: 0.763541, bias2: 0.3665943443775177, variance: 0.39694663882255554\n",
      "Train size: [400] hidden size: [2276] trial: 45, train_loss: 0.215662, test loss: 0.764236, bias2: 0.3660604953765869, variance: 0.3981751799583435\n",
      "Train size: [400] hidden size: [2276] trial: 46, train_loss: 0.215752, test loss: 0.763576, bias2: 0.3654380440711975, variance: 0.3981374502182007\n",
      "Train size: [400] hidden size: [2276] trial: 47, train_loss: 0.215408, test loss: 0.763206, bias2: 0.3656967580318451, variance: 0.3975089490413666\n",
      "Train size: [400] hidden size: [2276] trial: 48, train_loss: 0.215574, test loss: 0.763363, bias2: 0.36625587940216064, variance: 0.39710718393325806\n",
      "Train size: [400] hidden size: [2276] trial: 49, train_loss: 0.215307, test loss: 0.763808, bias2: 0.3670911192893982, variance: 0.39671725034713745\n",
      "##################################################\n",
      "Train size: [400] hidden size: [2621] trial: 0, train_loss: 0.212603, test loss: 0.799566, bias2: 0.7995664477348328, variance: 1.1677644407015464e-09\n",
      "Train size: [400] hidden size: [2621] trial: 1, train_loss: 0.212953, test loss: 0.765325, bias2: 0.572767972946167, variance: 0.1925572007894516\n",
      "Train size: [400] hidden size: [2621] trial: 2, train_loss: 0.218065, test loss: 0.772582, bias2: 0.514845609664917, variance: 0.2577362656593323\n",
      "Train size: [400] hidden size: [2621] trial: 3, train_loss: 0.222347, test loss: 0.762386, bias2: 0.4710697829723358, variance: 0.2913157045841217\n",
      "Train size: [400] hidden size: [2621] trial: 4, train_loss: 0.220155, test loss: 0.758438, bias2: 0.4536961317062378, variance: 0.3047419786453247\n",
      "Train size: [400] hidden size: [2621] trial: 5, train_loss: 0.215957, test loss: 0.755926, bias2: 0.43983861804008484, variance: 0.3160874545574188\n",
      "Train size: [400] hidden size: [2621] trial: 6, train_loss: 0.211791, test loss: 0.755175, bias2: 0.4239959716796875, variance: 0.33117932081222534\n",
      "Train size: [400] hidden size: [2621] trial: 7, train_loss: 0.209122, test loss: 0.746732, bias2: 0.414061963558197, variance: 0.3326701521873474\n",
      "Train size: [400] hidden size: [2621] trial: 8, train_loss: 0.209871, test loss: 0.748981, bias2: 0.4079986810684204, variance: 0.3409825563430786\n",
      "Train size: [400] hidden size: [2621] trial: 9, train_loss: 0.206998, test loss: 0.749822, bias2: 0.40139999985694885, variance: 0.3484216034412384\n",
      "Train size: [400] hidden size: [2621] trial: 10, train_loss: 0.207498, test loss: 0.746875, bias2: 0.3908940553665161, variance: 0.3559809923171997\n",
      "Train size: [400] hidden size: [2621] trial: 11, train_loss: 0.205648, test loss: 0.746237, bias2: 0.3873630166053772, variance: 0.35887348651885986\n",
      "Train size: [400] hidden size: [2621] trial: 12, train_loss: 0.204793, test loss: 0.748982, bias2: 0.38696151971817017, variance: 0.3620208501815796\n",
      "Train size: [400] hidden size: [2621] trial: 13, train_loss: 0.204293, test loss: 0.749185, bias2: 0.385731041431427, variance: 0.3634541630744934\n",
      "Train size: [400] hidden size: [2621] trial: 14, train_loss: 0.205168, test loss: 0.749479, bias2: 0.38188254833221436, variance: 0.3675963282585144\n",
      "Train size: [400] hidden size: [2621] trial: 15, train_loss: 0.205219, test loss: 0.746915, bias2: 0.3780120313167572, variance: 0.36890336871147156\n",
      "Train size: [400] hidden size: [2621] trial: 16, train_loss: 0.205206, test loss: 0.747422, bias2: 0.377025306224823, variance: 0.37039655447006226\n",
      "Train size: [400] hidden size: [2621] trial: 17, train_loss: 0.206497, test loss: 0.750332, bias2: 0.37697625160217285, variance: 0.373355507850647\n",
      "Train size: [400] hidden size: [2621] trial: 18, train_loss: 0.207275, test loss: 0.753864, bias2: 0.378052294254303, variance: 0.37581151723861694\n",
      "Train size: [400] hidden size: [2621] trial: 19, train_loss: 0.208036, test loss: 0.751767, bias2: 0.37424707412719727, variance: 0.37751972675323486\n",
      "Train size: [400] hidden size: [2621] trial: 20, train_loss: 0.207264, test loss: 0.747934, bias2: 0.37219756841659546, variance: 0.37573617696762085\n",
      "Train size: [400] hidden size: [2621] trial: 21, train_loss: 0.208308, test loss: 0.744787, bias2: 0.36786019802093506, variance: 0.37692707777023315\n",
      "Train size: [400] hidden size: [2621] trial: 22, train_loss: 0.207843, test loss: 0.745340, bias2: 0.36747246980667114, variance: 0.37786781787872314\n",
      "Train size: [400] hidden size: [2621] trial: 23, train_loss: 0.207417, test loss: 0.741477, bias2: 0.36464187502861023, variance: 0.37683549523353577\n",
      "Train size: [400] hidden size: [2621] trial: 24, train_loss: 0.205967, test loss: 0.742614, bias2: 0.3646484613418579, variance: 0.3779653310775757\n",
      "Train size: [400] hidden size: [2621] trial: 25, train_loss: 0.205706, test loss: 0.742413, bias2: 0.3637675940990448, variance: 0.3786458671092987\n",
      "Train size: [400] hidden size: [2621] trial: 26, train_loss: 0.205309, test loss: 0.743051, bias2: 0.3634379804134369, variance: 0.3796127736568451\n",
      "Train size: [400] hidden size: [2621] trial: 27, train_loss: 0.204538, test loss: 0.742631, bias2: 0.3629351258277893, variance: 0.3796960115432739\n",
      "Train size: [400] hidden size: [2621] trial: 28, train_loss: 0.204410, test loss: 0.741238, bias2: 0.3627832233905792, variance: 0.37845489382743835\n",
      "Train size: [400] hidden size: [2621] trial: 29, train_loss: 0.204619, test loss: 0.738404, bias2: 0.36019861698150635, variance: 0.37820500135421753\n",
      "Train size: [400] hidden size: [2621] trial: 30, train_loss: 0.204432, test loss: 0.737503, bias2: 0.3598850667476654, variance: 0.3776175081729889\n",
      "Train size: [400] hidden size: [2621] trial: 31, train_loss: 0.204019, test loss: 0.739072, bias2: 0.36135849356651306, variance: 0.3777138292789459\n",
      "Train size: [400] hidden size: [2621] trial: 32, train_loss: 0.203351, test loss: 0.739624, bias2: 0.3617023527622223, variance: 0.37792208790779114\n",
      "Train size: [400] hidden size: [2621] trial: 33, train_loss: 0.203743, test loss: 0.740586, bias2: 0.3626929819583893, variance: 0.3778931200504303\n",
      "Train size: [400] hidden size: [2621] trial: 34, train_loss: 0.203977, test loss: 0.739445, bias2: 0.36068230867385864, variance: 0.37876296043395996\n",
      "Train size: [400] hidden size: [2621] trial: 35, train_loss: 0.204186, test loss: 0.738070, bias2: 0.3603564500808716, variance: 0.3777132034301758\n",
      "Train size: [400] hidden size: [2621] trial: 36, train_loss: 0.204762, test loss: 0.736364, bias2: 0.3592648208141327, variance: 0.37709882855415344\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [2621] trial: 37, train_loss: 0.204709, test loss: 0.737271, bias2: 0.3587976396083832, variance: 0.37847378849983215\n",
      "Train size: [400] hidden size: [2621] trial: 38, train_loss: 0.204404, test loss: 0.736547, bias2: 0.3591158986091614, variance: 0.3774312734603882\n",
      "Train size: [400] hidden size: [2621] trial: 39, train_loss: 0.204617, test loss: 0.736381, bias2: 0.35821568965911865, variance: 0.3781653046607971\n",
      "Train size: [400] hidden size: [2621] trial: 40, train_loss: 0.204471, test loss: 0.737964, bias2: 0.3586551249027252, variance: 0.3793084919452667\n",
      "Train size: [400] hidden size: [2621] trial: 41, train_loss: 0.204417, test loss: 0.737371, bias2: 0.35854676365852356, variance: 0.37882426381111145\n",
      "Train size: [400] hidden size: [2621] trial: 42, train_loss: 0.204000, test loss: 0.738551, bias2: 0.35992348194122314, variance: 0.37862730026245117\n",
      "Train size: [400] hidden size: [2621] trial: 43, train_loss: 0.203900, test loss: 0.737504, bias2: 0.3584114909172058, variance: 0.3790924549102783\n",
      "Train size: [400] hidden size: [2621] trial: 44, train_loss: 0.203083, test loss: 0.737216, bias2: 0.35900428891181946, variance: 0.37821200489997864\n",
      "Train size: [400] hidden size: [2621] trial: 45, train_loss: 0.202888, test loss: 0.735898, bias2: 0.35774141550064087, variance: 0.3781569004058838\n",
      "Train size: [400] hidden size: [2621] trial: 46, train_loss: 0.202728, test loss: 0.737004, bias2: 0.3579414486885071, variance: 0.3790621757507324\n",
      "Train size: [400] hidden size: [2621] trial: 47, train_loss: 0.203492, test loss: 0.737767, bias2: 0.356831431388855, variance: 0.3809359669685364\n",
      "Train size: [400] hidden size: [2621] trial: 48, train_loss: 0.203677, test loss: 0.736479, bias2: 0.3557110130786896, variance: 0.3807678520679474\n",
      "Train size: [400] hidden size: [2621] trial: 49, train_loss: 0.203477, test loss: 0.734654, bias2: 0.3543738126754761, variance: 0.380280077457428\n",
      "##################################################\n",
      "Train size: [400] hidden size: [3017] trial: 0, train_loss: 0.169280, test loss: 0.713180, bias2: 0.7131798267364502, variance: 3.8925479506346505e-10\n",
      "Train size: [400] hidden size: [3017] trial: 1, train_loss: 0.201979, test loss: 0.744840, bias2: 0.5706508159637451, variance: 0.17418964207172394\n",
      "Train size: [400] hidden size: [3017] trial: 2, train_loss: 0.204963, test loss: 0.733748, bias2: 0.4816788136959076, variance: 0.2520689070224762\n",
      "Train size: [400] hidden size: [3017] trial: 3, train_loss: 0.196286, test loss: 0.725917, bias2: 0.45162445306777954, variance: 0.2742924690246582\n",
      "Train size: [400] hidden size: [3017] trial: 4, train_loss: 0.191004, test loss: 0.713186, bias2: 0.4236097037792206, variance: 0.2895762622356415\n",
      "Train size: [400] hidden size: [3017] trial: 5, train_loss: 0.193526, test loss: 0.713004, bias2: 0.4006440341472626, variance: 0.3123597204685211\n",
      "Train size: [400] hidden size: [3017] trial: 6, train_loss: 0.190812, test loss: 0.719361, bias2: 0.39341822266578674, variance: 0.32594242691993713\n",
      "Train size: [400] hidden size: [3017] trial: 7, train_loss: 0.191609, test loss: 0.724724, bias2: 0.3872958719730377, variance: 0.3374278247356415\n",
      "Train size: [400] hidden size: [3017] trial: 8, train_loss: 0.192500, test loss: 0.726640, bias2: 0.37888041138648987, variance: 0.347759872674942\n",
      "Train size: [400] hidden size: [3017] trial: 9, train_loss: 0.192884, test loss: 0.719430, bias2: 0.36852583289146423, variance: 0.3509044945240021\n",
      "Train size: [400] hidden size: [3017] trial: 10, train_loss: 0.192121, test loss: 0.715075, bias2: 0.3644495904445648, variance: 0.35062524676322937\n",
      "Train size: [400] hidden size: [3017] trial: 11, train_loss: 0.192363, test loss: 0.720093, bias2: 0.3649732768535614, variance: 0.3551194369792938\n",
      "Train size: [400] hidden size: [3017] trial: 12, train_loss: 0.192004, test loss: 0.722980, bias2: 0.36699214577674866, variance: 0.35598835349082947\n",
      "Train size: [400] hidden size: [3017] trial: 13, train_loss: 0.192287, test loss: 0.723589, bias2: 0.3658018708229065, variance: 0.35778695344924927\n",
      "Train size: [400] hidden size: [3017] trial: 14, train_loss: 0.192930, test loss: 0.725667, bias2: 0.36711224913597107, variance: 0.3585543930530548\n",
      "Train size: [400] hidden size: [3017] trial: 15, train_loss: 0.192010, test loss: 0.721804, bias2: 0.36371496319770813, variance: 0.35808905959129333\n",
      "Train size: [400] hidden size: [3017] trial: 16, train_loss: 0.190749, test loss: 0.723656, bias2: 0.36373835802078247, variance: 0.35991811752319336\n",
      "Train size: [400] hidden size: [3017] trial: 17, train_loss: 0.190493, test loss: 0.721492, bias2: 0.36279094219207764, variance: 0.35870105028152466\n",
      "Train size: [400] hidden size: [3017] trial: 18, train_loss: 0.191049, test loss: 0.724886, bias2: 0.36459651589393616, variance: 0.3602893054485321\n",
      "Train size: [400] hidden size: [3017] trial: 19, train_loss: 0.191628, test loss: 0.725874, bias2: 0.3625253140926361, variance: 0.36334851384162903\n",
      "Train size: [400] hidden size: [3017] trial: 20, train_loss: 0.189634, test loss: 0.726377, bias2: 0.36388328671455383, variance: 0.36249396204948425\n",
      "Train size: [400] hidden size: [3017] trial: 21, train_loss: 0.191140, test loss: 0.723438, bias2: 0.3615846633911133, variance: 0.3618529438972473\n",
      "Train size: [400] hidden size: [3017] trial: 22, train_loss: 0.190918, test loss: 0.723965, bias2: 0.35970473289489746, variance: 0.36426055431365967\n",
      "Train size: [400] hidden size: [3017] trial: 23, train_loss: 0.190587, test loss: 0.723551, bias2: 0.3595062792301178, variance: 0.3640446364879608\n",
      "Train size: [400] hidden size: [3017] trial: 24, train_loss: 0.190609, test loss: 0.719975, bias2: 0.3571471869945526, variance: 0.36282822489738464\n",
      "Train size: [400] hidden size: [3017] trial: 25, train_loss: 0.190544, test loss: 0.719032, bias2: 0.3563275635242462, variance: 0.36270472407341003\n",
      "Train size: [400] hidden size: [3017] trial: 26, train_loss: 0.191075, test loss: 0.720326, bias2: 0.35504767298698425, variance: 0.3652787506580353\n",
      "Train size: [400] hidden size: [3017] trial: 27, train_loss: 0.190502, test loss: 0.724437, bias2: 0.3576299846172333, variance: 0.36680731177330017\n",
      "Train size: [400] hidden size: [3017] trial: 28, train_loss: 0.190194, test loss: 0.725162, bias2: 0.3568391799926758, variance: 0.3683229088783264\n",
      "Train size: [400] hidden size: [3017] trial: 29, train_loss: 0.190803, test loss: 0.723784, bias2: 0.35500368475914, variance: 0.3687799274921417\n",
      "Train size: [400] hidden size: [3017] trial: 30, train_loss: 0.191370, test loss: 0.727331, bias2: 0.35720834136009216, variance: 0.37012234330177307\n",
      "Train size: [400] hidden size: [3017] trial: 31, train_loss: 0.190729, test loss: 0.728283, bias2: 0.3577118515968323, variance: 0.3705707788467407\n",
      "Train size: [400] hidden size: [3017] trial: 32, train_loss: 0.191315, test loss: 0.725745, bias2: 0.35554465651512146, variance: 0.37020036578178406\n",
      "Train size: [400] hidden size: [3017] trial: 33, train_loss: 0.190990, test loss: 0.725446, bias2: 0.3552256226539612, variance: 0.3702201843261719\n",
      "Train size: [400] hidden size: [3017] trial: 34, train_loss: 0.190928, test loss: 0.724454, bias2: 0.3549336791038513, variance: 0.3695199489593506\n",
      "Train size: [400] hidden size: [3017] trial: 35, train_loss: 0.191486, test loss: 0.724567, bias2: 0.3544416129589081, variance: 0.3701254427433014\n",
      "Train size: [400] hidden size: [3017] trial: 36, train_loss: 0.191193, test loss: 0.722212, bias2: 0.35399046540260315, variance: 0.36822107434272766\n",
      "Train size: [400] hidden size: [3017] trial: 37, train_loss: 0.191177, test loss: 0.722696, bias2: 0.35399192571640015, variance: 0.36870449781417847\n",
      "Train size: [400] hidden size: [3017] trial: 38, train_loss: 0.190752, test loss: 0.722489, bias2: 0.35321828722953796, variance: 0.36927083134651184\n",
      "Train size: [400] hidden size: [3017] trial: 39, train_loss: 0.190688, test loss: 0.722710, bias2: 0.35403260588645935, variance: 0.3686775267124176\n",
      "Train size: [400] hidden size: [3017] trial: 40, train_loss: 0.190632, test loss: 0.722730, bias2: 0.3547303378582001, variance: 0.36799952387809753\n",
      "Train size: [400] hidden size: [3017] trial: 41, train_loss: 0.191103, test loss: 0.723829, bias2: 0.3557761609554291, variance: 0.3680526912212372\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [3017] trial: 42, train_loss: 0.190819, test loss: 0.722971, bias2: 0.3562313914299011, variance: 0.36673951148986816\n",
      "Train size: [400] hidden size: [3017] trial: 43, train_loss: 0.190561, test loss: 0.724002, bias2: 0.35661858320236206, variance: 0.36738306283950806\n",
      "Train size: [400] hidden size: [3017] trial: 44, train_loss: 0.190559, test loss: 0.724197, bias2: 0.3563983738422394, variance: 0.3677981197834015\n",
      "Train size: [400] hidden size: [3017] trial: 45, train_loss: 0.190377, test loss: 0.724579, bias2: 0.35695165395736694, variance: 0.3676273226737976\n",
      "Train size: [400] hidden size: [3017] trial: 46, train_loss: 0.190375, test loss: 0.725198, bias2: 0.3570237457752228, variance: 0.3681739866733551\n",
      "Train size: [400] hidden size: [3017] trial: 47, train_loss: 0.190607, test loss: 0.724506, bias2: 0.35574525594711304, variance: 0.36876070499420166\n",
      "Train size: [400] hidden size: [3017] trial: 48, train_loss: 0.190924, test loss: 0.723666, bias2: 0.3549477756023407, variance: 0.3687179386615753\n",
      "Train size: [400] hidden size: [3017] trial: 49, train_loss: 0.190729, test loss: 0.724646, bias2: 0.35566872358322144, variance: 0.36897772550582886\n",
      "##################################################\n",
      "Train size: [400] hidden size: [3474] trial: 0, train_loss: 0.165519, test loss: 0.704626, bias2: 0.7046257853507996, variance: -1.7516466055411684e-09\n",
      "Train size: [400] hidden size: [3474] trial: 1, train_loss: 0.179845, test loss: 0.700128, bias2: 0.5397814512252808, variance: 0.16034692525863647\n",
      "Train size: [400] hidden size: [3474] trial: 2, train_loss: 0.178567, test loss: 0.703681, bias2: 0.48885178565979004, variance: 0.2148291915655136\n",
      "Train size: [400] hidden size: [3474] trial: 3, train_loss: 0.180011, test loss: 0.707047, bias2: 0.4577489495277405, variance: 0.2492978572845459\n",
      "Train size: [400] hidden size: [3474] trial: 4, train_loss: 0.184760, test loss: 0.703838, bias2: 0.42891237139701843, variance: 0.274926096200943\n",
      "Train size: [400] hidden size: [3474] trial: 5, train_loss: 0.184895, test loss: 0.700745, bias2: 0.4045720398426056, variance: 0.29617252945899963\n",
      "Train size: [400] hidden size: [3474] trial: 6, train_loss: 0.186627, test loss: 0.698307, bias2: 0.39479386806488037, variance: 0.30351322889328003\n",
      "Train size: [400] hidden size: [3474] trial: 7, train_loss: 0.188969, test loss: 0.696348, bias2: 0.38328373432159424, variance: 0.31306391954421997\n",
      "Train size: [400] hidden size: [3474] trial: 8, train_loss: 0.189396, test loss: 0.695706, bias2: 0.3739561438560486, variance: 0.32174962759017944\n",
      "Train size: [400] hidden size: [3474] trial: 9, train_loss: 0.191578, test loss: 0.699818, bias2: 0.37429067492485046, variance: 0.3255276381969452\n",
      "Train size: [400] hidden size: [3474] trial: 10, train_loss: 0.190315, test loss: 0.709959, bias2: 0.37610533833503723, variance: 0.33385351300239563\n",
      "Train size: [400] hidden size: [3474] trial: 11, train_loss: 0.192641, test loss: 0.712562, bias2: 0.37618306279182434, variance: 0.3363786041736603\n",
      "Train size: [400] hidden size: [3474] trial: 12, train_loss: 0.193219, test loss: 0.711887, bias2: 0.3711799681186676, variance: 0.34070727229118347\n",
      "Train size: [400] hidden size: [3474] trial: 13, train_loss: 0.193079, test loss: 0.714341, bias2: 0.368949294090271, variance: 0.34539222717285156\n",
      "Train size: [400] hidden size: [3474] trial: 14, train_loss: 0.190634, test loss: 0.717052, bias2: 0.37080681324005127, variance: 0.34624558687210083\n",
      "Train size: [400] hidden size: [3474] trial: 15, train_loss: 0.189649, test loss: 0.714249, bias2: 0.3668600022792816, variance: 0.34738871455192566\n",
      "Train size: [400] hidden size: [3474] trial: 16, train_loss: 0.189148, test loss: 0.711644, bias2: 0.3650626838207245, variance: 0.34658095240592957\n",
      "Train size: [400] hidden size: [3474] trial: 17, train_loss: 0.189264, test loss: 0.708762, bias2: 0.36316075921058655, variance: 0.3456009328365326\n",
      "Train size: [400] hidden size: [3474] trial: 18, train_loss: 0.190964, test loss: 0.704849, bias2: 0.357275128364563, variance: 0.347573459148407\n",
      "Train size: [400] hidden size: [3474] trial: 19, train_loss: 0.191825, test loss: 0.702753, bias2: 0.3551998734474182, variance: 0.3475533127784729\n",
      "Train size: [400] hidden size: [3474] trial: 20, train_loss: 0.192444, test loss: 0.703719, bias2: 0.3544108271598816, variance: 0.3493083715438843\n",
      "Train size: [400] hidden size: [3474] trial: 21, train_loss: 0.191867, test loss: 0.704749, bias2: 0.35409441590309143, variance: 0.35065439343452454\n",
      "Train size: [400] hidden size: [3474] trial: 22, train_loss: 0.191664, test loss: 0.705971, bias2: 0.35616055130958557, variance: 0.34981009364128113\n",
      "Train size: [400] hidden size: [3474] trial: 23, train_loss: 0.190149, test loss: 0.706908, bias2: 0.35620760917663574, variance: 0.35070037841796875\n",
      "Train size: [400] hidden size: [3474] trial: 24, train_loss: 0.191106, test loss: 0.708871, bias2: 0.3568888008594513, variance: 0.35198214650154114\n",
      "Train size: [400] hidden size: [3474] trial: 25, train_loss: 0.190782, test loss: 0.708033, bias2: 0.3548165559768677, variance: 0.35321658849716187\n",
      "Train size: [400] hidden size: [3474] trial: 26, train_loss: 0.190597, test loss: 0.706624, bias2: 0.35428881645202637, variance: 0.3523353934288025\n",
      "Train size: [400] hidden size: [3474] trial: 27, train_loss: 0.190067, test loss: 0.706600, bias2: 0.3548005223274231, variance: 0.3517991304397583\n",
      "Train size: [400] hidden size: [3474] trial: 28, train_loss: 0.190294, test loss: 0.705750, bias2: 0.3541801869869232, variance: 0.35156992077827454\n",
      "Train size: [400] hidden size: [3474] trial: 29, train_loss: 0.190052, test loss: 0.708423, bias2: 0.3545522689819336, variance: 0.3538709282875061\n",
      "Train size: [400] hidden size: [3474] trial: 30, train_loss: 0.189676, test loss: 0.707689, bias2: 0.3549049496650696, variance: 0.35278403759002686\n",
      "Train size: [400] hidden size: [3474] trial: 31, train_loss: 0.189848, test loss: 0.707007, bias2: 0.3542591631412506, variance: 0.3527476489543915\n",
      "Train size: [400] hidden size: [3474] trial: 32, train_loss: 0.189421, test loss: 0.707164, bias2: 0.35474148392677307, variance: 0.3524229824542999\n",
      "Train size: [400] hidden size: [3474] trial: 33, train_loss: 0.189871, test loss: 0.707514, bias2: 0.3551565706729889, variance: 0.35235777497291565\n",
      "Train size: [400] hidden size: [3474] trial: 34, train_loss: 0.189769, test loss: 0.708513, bias2: 0.35624638199806213, variance: 0.3522661626338959\n",
      "Train size: [400] hidden size: [3474] trial: 35, train_loss: 0.189853, test loss: 0.707951, bias2: 0.35537993907928467, variance: 0.3525707721710205\n",
      "Train size: [400] hidden size: [3474] trial: 36, train_loss: 0.189981, test loss: 0.707143, bias2: 0.35387203097343445, variance: 0.3532712757587433\n",
      "Train size: [400] hidden size: [3474] trial: 37, train_loss: 0.190065, test loss: 0.705169, bias2: 0.3513339161872864, variance: 0.3538350462913513\n",
      "Train size: [400] hidden size: [3474] trial: 38, train_loss: 0.190347, test loss: 0.705177, bias2: 0.350240021944046, variance: 0.35493704676628113\n",
      "Train size: [400] hidden size: [3474] trial: 39, train_loss: 0.189674, test loss: 0.704626, bias2: 0.3496970534324646, variance: 0.3549293875694275\n",
      "Train size: [400] hidden size: [3474] trial: 40, train_loss: 0.189745, test loss: 0.705886, bias2: 0.3501410186290741, variance: 0.3557448089122772\n",
      "Train size: [400] hidden size: [3474] trial: 41, train_loss: 0.189615, test loss: 0.704984, bias2: 0.3486955165863037, variance: 0.35628896951675415\n",
      "Train size: [400] hidden size: [3474] trial: 42, train_loss: 0.189571, test loss: 0.706744, bias2: 0.349310040473938, variance: 0.35743415355682373\n",
      "Train size: [400] hidden size: [3474] trial: 43, train_loss: 0.190398, test loss: 0.707606, bias2: 0.34962528944015503, variance: 0.35798102617263794\n",
      "Train size: [400] hidden size: [3474] trial: 44, train_loss: 0.190562, test loss: 0.708100, bias2: 0.3498273193836212, variance: 0.3582729399204254\n",
      "Train size: [400] hidden size: [3474] trial: 45, train_loss: 0.190568, test loss: 0.707301, bias2: 0.3489028513431549, variance: 0.35839781165122986\n",
      "Train size: [400] hidden size: [3474] trial: 46, train_loss: 0.191029, test loss: 0.706393, bias2: 0.3475291430950165, variance: 0.35886338353157043\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [3474] trial: 47, train_loss: 0.191038, test loss: 0.707953, bias2: 0.3489408791065216, variance: 0.35901185870170593\n",
      "Train size: [400] hidden size: [3474] trial: 48, train_loss: 0.191070, test loss: 0.707529, bias2: 0.3482643663883209, variance: 0.3592648208141327\n",
      "Train size: [400] hidden size: [3474] trial: 49, train_loss: 0.190699, test loss: 0.706772, bias2: 0.34776127338409424, variance: 0.3590104579925537\n",
      "##################################################\n",
      "Train size: [400] hidden size: [4000] trial: 0, train_loss: 0.196249, test loss: 0.662564, bias2: 0.662563681602478, variance: -1.5570191802538602e-09\n",
      "Train size: [400] hidden size: [4000] trial: 1, train_loss: 0.184437, test loss: 0.694877, bias2: 0.5287377834320068, variance: 0.16613896191120148\n",
      "Train size: [400] hidden size: [4000] trial: 2, train_loss: 0.176556, test loss: 0.710292, bias2: 0.48354876041412354, variance: 0.22674338519573212\n",
      "Train size: [400] hidden size: [4000] trial: 3, train_loss: 0.173568, test loss: 0.724148, bias2: 0.4662395119667053, variance: 0.2579081058502197\n",
      "Train size: [400] hidden size: [4000] trial: 4, train_loss: 0.177743, test loss: 0.705683, bias2: 0.43119552731513977, variance: 0.2744879424571991\n",
      "Train size: [400] hidden size: [4000] trial: 5, train_loss: 0.180344, test loss: 0.686133, bias2: 0.40378740429878235, variance: 0.28234604001045227\n",
      "Train size: [400] hidden size: [4000] trial: 6, train_loss: 0.178584, test loss: 0.692144, bias2: 0.39831629395484924, variance: 0.2938275635242462\n",
      "Train size: [400] hidden size: [4000] trial: 7, train_loss: 0.175594, test loss: 0.690969, bias2: 0.3887680470943451, variance: 0.30220094323158264\n",
      "Train size: [400] hidden size: [4000] trial: 8, train_loss: 0.175873, test loss: 0.686219, bias2: 0.38081541657447815, variance: 0.3054034411907196\n",
      "Train size: [400] hidden size: [4000] trial: 9, train_loss: 0.177916, test loss: 0.690992, bias2: 0.37742069363594055, variance: 0.31357088685035706\n",
      "Train size: [400] hidden size: [4000] trial: 10, train_loss: 0.176156, test loss: 0.689956, bias2: 0.3763469457626343, variance: 0.3136094808578491\n",
      "Train size: [400] hidden size: [4000] trial: 11, train_loss: 0.176352, test loss: 0.688821, bias2: 0.37411829829216003, variance: 0.31470224261283875\n",
      "Train size: [400] hidden size: [4000] trial: 12, train_loss: 0.177615, test loss: 0.692686, bias2: 0.37323418259620667, variance: 0.31945136189460754\n",
      "Train size: [400] hidden size: [4000] trial: 13, train_loss: 0.178571, test loss: 0.695459, bias2: 0.3740006685256958, variance: 0.32145822048187256\n",
      "Train size: [400] hidden size: [4000] trial: 14, train_loss: 0.177350, test loss: 0.697414, bias2: 0.37525132298469543, variance: 0.3221624791622162\n",
      "Train size: [400] hidden size: [4000] trial: 15, train_loss: 0.177420, test loss: 0.699609, bias2: 0.3753361999988556, variance: 0.3242723047733307\n",
      "Train size: [400] hidden size: [4000] trial: 16, train_loss: 0.177284, test loss: 0.700473, bias2: 0.37399962544441223, variance: 0.326473206281662\n",
      "Train size: [400] hidden size: [4000] trial: 17, train_loss: 0.177446, test loss: 0.702730, bias2: 0.37216073274612427, variance: 0.3305695056915283\n",
      "Train size: [400] hidden size: [4000] trial: 18, train_loss: 0.176742, test loss: 0.704648, bias2: 0.37194234132766724, variance: 0.33270519971847534\n",
      "Train size: [400] hidden size: [4000] trial: 19, train_loss: 0.176587, test loss: 0.700191, bias2: 0.36857885122299194, variance: 0.33161187171936035\n",
      "Train size: [400] hidden size: [4000] trial: 20, train_loss: 0.176863, test loss: 0.696912, bias2: 0.3647911846637726, variance: 0.3321206271648407\n",
      "Train size: [400] hidden size: [4000] trial: 21, train_loss: 0.176965, test loss: 0.699886, bias2: 0.36639752984046936, variance: 0.33348819613456726\n",
      "Train size: [400] hidden size: [4000] trial: 22, train_loss: 0.177961, test loss: 0.697678, bias2: 0.36265477538108826, variance: 0.3350233733654022\n",
      "Train size: [400] hidden size: [4000] trial: 23, train_loss: 0.177712, test loss: 0.696135, bias2: 0.36043474078178406, variance: 0.335700660943985\n",
      "Train size: [400] hidden size: [4000] trial: 24, train_loss: 0.177886, test loss: 0.695575, bias2: 0.35940104722976685, variance: 0.33617353439331055\n",
      "Train size: [400] hidden size: [4000] trial: 25, train_loss: 0.178691, test loss: 0.697180, bias2: 0.3600199520587921, variance: 0.33715978264808655\n",
      "Train size: [400] hidden size: [4000] trial: 26, train_loss: 0.178463, test loss: 0.697317, bias2: 0.35914698243141174, variance: 0.3381703794002533\n",
      "Train size: [400] hidden size: [4000] trial: 27, train_loss: 0.180078, test loss: 0.698840, bias2: 0.35749658942222595, variance: 0.3413437306880951\n",
      "Train size: [400] hidden size: [4000] trial: 28, train_loss: 0.180858, test loss: 0.699701, bias2: 0.3569621443748474, variance: 0.3427387475967407\n",
      "Train size: [400] hidden size: [4000] trial: 29, train_loss: 0.180568, test loss: 0.703004, bias2: 0.3582814633846283, variance: 0.34472253918647766\n",
      "Train size: [400] hidden size: [4000] trial: 30, train_loss: 0.180333, test loss: 0.701974, bias2: 0.3555090129375458, variance: 0.3464645445346832\n",
      "Train size: [400] hidden size: [4000] trial: 31, train_loss: 0.180881, test loss: 0.699799, bias2: 0.35268673300743103, variance: 0.34711208939552307\n",
      "Train size: [400] hidden size: [4000] trial: 32, train_loss: 0.180982, test loss: 0.699918, bias2: 0.3526245653629303, variance: 0.3472937047481537\n",
      "Train size: [400] hidden size: [4000] trial: 33, train_loss: 0.181623, test loss: 0.700363, bias2: 0.352142333984375, variance: 0.3482203483581543\n",
      "Train size: [400] hidden size: [4000] trial: 34, train_loss: 0.181384, test loss: 0.700860, bias2: 0.35252365469932556, variance: 0.34833601117134094\n",
      "Train size: [400] hidden size: [4000] trial: 35, train_loss: 0.182170, test loss: 0.702133, bias2: 0.3518233597278595, variance: 0.35030993819236755\n",
      "Train size: [400] hidden size: [4000] trial: 36, train_loss: 0.182316, test loss: 0.704247, bias2: 0.35264164209365845, variance: 0.35160571336746216\n",
      "Train size: [400] hidden size: [4000] trial: 37, train_loss: 0.181707, test loss: 0.702441, bias2: 0.35177019238471985, variance: 0.35067078471183777\n",
      "Train size: [400] hidden size: [4000] trial: 38, train_loss: 0.182306, test loss: 0.701862, bias2: 0.3491421639919281, variance: 0.35271987318992615\n",
      "Train size: [400] hidden size: [4000] trial: 39, train_loss: 0.182019, test loss: 0.701828, bias2: 0.34868940711021423, variance: 0.35313865542411804\n",
      "Train size: [400] hidden size: [4000] trial: 40, train_loss: 0.181687, test loss: 0.699906, bias2: 0.3471226990222931, variance: 0.3527829349040985\n",
      "Train size: [400] hidden size: [4000] trial: 41, train_loss: 0.181599, test loss: 0.700065, bias2: 0.3467531204223633, variance: 0.35331207513809204\n",
      "Train size: [400] hidden size: [4000] trial: 42, train_loss: 0.181621, test loss: 0.699974, bias2: 0.3464518189430237, variance: 0.35352253913879395\n",
      "Train size: [400] hidden size: [4000] trial: 43, train_loss: 0.181313, test loss: 0.699247, bias2: 0.345694899559021, variance: 0.35355186462402344\n",
      "Train size: [400] hidden size: [4000] trial: 44, train_loss: 0.181028, test loss: 0.698168, bias2: 0.3446240723133087, variance: 0.3535436689853668\n",
      "Train size: [400] hidden size: [4000] trial: 45, train_loss: 0.181095, test loss: 0.698797, bias2: 0.34359851479530334, variance: 0.355198472738266\n",
      "Train size: [400] hidden size: [4000] trial: 46, train_loss: 0.181044, test loss: 0.698865, bias2: 0.34364354610443115, variance: 0.35522180795669556\n",
      "Train size: [400] hidden size: [4000] trial: 47, train_loss: 0.180955, test loss: 0.698976, bias2: 0.3437930643558502, variance: 0.35518333315849304\n",
      "Train size: [400] hidden size: [4000] trial: 48, train_loss: 0.180972, test loss: 0.697839, bias2: 0.3432411551475525, variance: 0.35459792613983154\n",
      "Train size: [400] hidden size: [4000] trial: 49, train_loss: 0.180911, test loss: 0.697733, bias2: 0.34267711639404297, variance: 0.35505592823028564\n",
      "##################################################\n"
     ]
    }
   ],
   "source": [
    "run_exps_ridge(train_sizes, N_Ds, P_Ns, beta, test_size, feature_dim, num_classes, num_trials, coef,\n",
    "             outdir, 'ensembleNNK=2_output.csv', SNR= SNR, K = 2, F_norm = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "K2_df = pd.read_csv(os.path.join(outdir, 'ensembleNNK=2_output.csv'))\n",
    "K1_df = pd.read_csv(os.path.join(outdir, 'singleNN_output.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "font = {\n",
    "        'size'   : 18}\n",
    "matplotlib.rc('font', **font)\n",
    "figsize = (16, 5)\n",
    "import seaborn as sns\n",
    "sns.set_style('darkgrid')\n",
    "\n",
    "def plot_bias_var(df, N_D, ymin=0, ymax=1.0):\n",
    "    fig1, axes1 = plt.subplots(1, 3, figsize=figsize)\n",
    "    axes1[0].set_xscale('log')\n",
    "    axes1[1].set_xscale('log')\n",
    "    axes1[2].set_xscale('log')\n",
    "    cur_df = df[df['train_size']/feature_dim==N_D]\n",
    "    test_loss = cur_df['test_loss']\n",
    "    bias2 = cur_df['bias2']\n",
    "    var = cur_df['variance']\n",
    "    P_N = cur_df['hidden_size']/cur_df['train_size']\n",
    "    axes1[0].plot(P_N, test_loss)\n",
    "    axes1[0].set_xlabel(\"P/N\")\n",
    "    axes1[0].set_ylabel(\"Test Loss\")\n",
    "    axes1[0].set_ylim(ymin, ymax)\n",
    "    axes1[1].plot(P_N, bias2)\n",
    "    axes1[1].set_xlabel(\"P/N\")\n",
    "    axes1[1].set_ylabel(\"Bias Square\")\n",
    "    axes1[1].set_ylim(ymin, ymax)\n",
    "    axes1[2].plot(P_N, var)\n",
    "    axes1[2].set_xlabel(\"P/N\")\n",
    "    axes1[2].set_ylabel(\"Variance\")\n",
    "    axes1[2].set_ylim(ymin, ymax)\n",
    "    fig1.suptitle(\"Bias-Variance Decomposition (N/D={:.2f})\".format(N_D))\n",
    "    plt.show()\n",
    "def plot_single_vs_ensemble(dfs_list, Ks_list, N_D, feature_dim, ymin=0, ymax=1.0):\n",
    "    assert len(dfs_list) == len(Ks_list)\n",
    "    fig1, axes1 = plt.subplots(1, 3, figsize=figsize)\n",
    "    for i in range(3):\n",
    "        axes1[i].set_xscale('log')\n",
    "    dfs_list = [df[df['train_size']/feature_dim==N_D] for df in dfs_list]\n",
    "    for cur_df, K in zip(dfs_list, Ks_list):\n",
    "        test_loss = cur_df['test_loss']\n",
    "        bias2 = cur_df['bias2']\n",
    "        var = cur_df['variance']\n",
    "        P_N = cur_df['hidden_size']/cur_df['train_size']\n",
    "        axes1[0].plot(P_N, test_loss, label='K={}'.format(K))\n",
    "        axes1[1].plot(P_N, bias2, label='K={}'.format(K))\n",
    "        axes1[2].plot(P_N, var, label='K={}'.format(K))\n",
    "    \n",
    "    axes1[0].set_xlabel(\"P/N\")\n",
    "    axes1[0].set_ylabel(\"Test Loss\")\n",
    "    axes1[0].set_ylim(ymin, ymax)\n",
    "    \n",
    "    axes1[1].set_xlabel(\"P/N\")\n",
    "    axes1[1].set_ylabel(\"Bias Square\")\n",
    "    axes1[1].set_ylim(ymin, ymax)\n",
    "    \n",
    "    axes1[2].set_xlabel(\"P/N\")\n",
    "    axes1[2].set_ylabel(\"Variance\")\n",
    "    axes1[2].set_ylim(ymin, ymax)\n",
    "    fig1.suptitle(\"Bias-Variance Decomposition (N/D={:.2f})\".format(N_D))\n",
    "    plt.legend()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA8gAAAFzCAYAAADiwCCdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzs3Xd8zef7x/HXOdkSiRB7x4iaiRpVu6XUCmq1tSk6jKJFW1ptzbZoUerb0pq1FaWUUiuIrVbtlcZMSCIyz+8Pj3N+IkPGiUPyfj4e/sj5rOt8zskt1+e+7+s2mEwmEyIiIiIiIiLZnNHWAYiIiIiIiIg8DZQgi4iIiIiIiKAEWURERERERARQgiwiIiIiIiICKEEWERERERERAZQgi4iIiIiIiABKkEXESl566SV8fHwS/CtXrhzVq1fnjTfeYPHixcTHxyc6bs+ePfj4+NClSxcbRJ20999/Hx8fH8aOHZuq/f39/fHx8WHRokWZGldUVBQ+Pj5UqlQpU6/ztDN/Pg//8/Pzo27dunTp0oUJEyZw7NgxW4cpj3H27Fl8fHxo2rRpmo81fwd+//33TIjMeq5fv46fnx/9+/dP8Lr5vfv4+FCrVi0iIiKSPH7btm34+Pjw+uuvp3idFi1a8PzzzxMdHQ1Ahw4dErXFVatWpUGDBvTs2ZNvv/2W8+fPW+dNPsbmzZuZPHkyvXr1ombNmvj4+FCvXr0MnzcgIIBevXpRo0YNfH198ff355dffiEuLi7ZY6Kjo5k1axYtWrSgcuXK1KxZk379+nHgwIEk9587dy4+Pj5s27Ytw/GKyLPD3tYBiEjWUqdOHfLmzQtATEwMV69e5cCBA+zfv5+tW7fy/fffYzAYbBxlytq0acO6detYu3YtH374Ifb2yTeVJ0+e5OTJkzg5OdG8efMnGKVUqFCBsmXLAg/+8A0JCeH48ePs3buX2bNnU69ePcaMGUO+fPlsHKmkxdmzZ2nWrBklS5bkjz/+sHU4GTJ58mTu37/PwIEDk93n9u3b/Pzzz7z77rvpusbFixc5ffo0zZs3x9HRMcG26tWrU6RIEQAiIyO5ffs2hw4dYufOnXz//ff4+/szcuRIcubMma5rp8agQYMsibu1LFy4kM8//xyj0UjNmjXJmTMnu3fvZuzYsezevZtp06ZhZ2eX4Jjo6Gh69uxJYGAguXPnpkGDBoSEhLB161a2bdvG119/TbNmzRIc06lTJ3766ScmTJhA7dq1E51TRLImJcgiYlV9+vShZs2aCV47fPgwXbp04a+//mLz5s00atTIsq1y5cqsW7cOFxeXJx1qsmrXrk2+fPm4fv0627Zt46WXXkp235UrVwLw8ssv4+7unqlxOTo6sm7dOoxGDf4BaNq0KX369EnwmslkYtu2bYwdO5Zt27bRpUsXFi9eTK5cuWwUpSSnaNGirFu3LlFSlxrDhw/nvffeI3/+/JkQmXWcPn2aVatW8corr1C6dOkk93F0dCQ2NpY5c+bw5ptvput7+ueffwIkaFfNXn/99UQP7mJjY9mwYQPjxo3jt99+49KlS8ydOzddn0NqvPrqq5QtW5aKFSvi4uJChw4dMnS+8+fPM2bMGOzt7ZkzZw7Vq1cHHjxo6Nq1K3/99RcLFiyga9euCY6bMWMGgYGBVK5cmTlz5uDm5gbA33//Tb9+/fjoo4+oXr265QEvPPh8evfuzZdffsmKFSto3759hmIXkWeD/soSkUxXpUoVmjRpAjwYUv0wFxcXSpUqRaFChWwRWpLs7Oxo3bo1AKtWrUp2v9jYWNasWQM86HXObAaDgVKlSlGyZMlMv9azymAwUL9+fZYuXUrx4sW5cOECEydOtHVYkgRHR0dKlSpF0aJF03xs/vz5KVWqlCXJeRotWLCA+Ph4XnvttWT38fT0pFmzZoSFhfG///0vXdfZtGkTDg4OqR62bG9vT/PmzS0Pjg4ePJjua6fGxIkT6d27Ny+88IJVPq85c+YQGxvL66+/bkmOAXLnzs3IkSMB+OmnnzCZTJZt0dHRzJ07F4DPP/88QRz169fH39+fyMhI5s+fn+h6LVq0wMHBgXnz5mU4dhF5NihBFpEnwsvLCyDR/LDk5iDHxMSwatUqBg0aRJMmTfDz88PPz49WrVoxbdo07t27l+R1Ll68yKhRo2jSpAm+vr5UrVqVRo0aMWjQIAICAlIdrznh/euvvwgNDU1yn+3bt3Pr1i3y5ctH7dq1La9HR0ezYsUKBgwYwCuvvIKvry9+fn60bt2aGTNmcP/+/UTnenh+cXx8PPPmzaN169b4+flZzp3SHORt27YxatQoWrZsSfXq1alUqRKNGzfms88+Izg4OMn4zfMUDx06xL59++jRowfPP/88vr6+dO7cmb179yZ7f8LCwvj+++9p27YtVatWpUqVKrzyyisMHz6cw4cPJ9o/PDycadOm4e/vj5+fH76+vrRp04aff/6ZmJiYZK+TXu7u7gwbNgyA1atXc/v27UT73Lx5kwkTJvDqq69SpUoVqlatSqdOnVixYkWy542Li2PlypV069aNmjVrUrFiRRo0aEDfvn1Zt25dov3DwsKYMmUKzZs3t1yjQ4cOLFiwgNjY2ET7f/311/j4+DBr1iwuX77M4MGDqVWrFr6+vnTq1Indu3db9t2wYQOdOnXCz8+PGjVqMHToUG7evJnonIsWLcLHx4dRo0Zx48YNPvroI+rUqUOlSpV49dVX+fHHH5OMBR5853766Sfatm1r+dz8/f2ZOXMmkZGRSR6zYcMGunXrRt26dalYsSK1atWiTZs2TJgwIcHvUlJzkB8e5nr+/PkE82gf3i+lOchpjfnh+xMaGsro0aOpV68eFStW5JVXXmHGjBlJ1k9ISUREBKtXr8bLyytB25CUgQMHYm9vz4IFC7hx40aarnPz5k0OHz5MrVq10px8Fi5c2DKse+7cuWl+j7by119/AQ8S10fVrFkTLy8vgoOD+eeffyyv7927l/DwcLy9vXnuuecSHWf+zm3evDnRNk9PT+rXr8+pU6eSnassIlmLEmQReSKOHj0KQKlSpVK1/61btxg2bBgBAQGW+WJ+fn4EBQUxdepUOnfunCjRPHnyJK1bt2bx4sXY29tTr149ateuTa5cudi0aRPr169Pdbze3t74+voSExOTbCEg8/Bqf3//BHPT/vvvP0aMGMGePXvw8vKiYcOG+Pr6cunSJaZMmUL37t1TnJP38ccfM2HCBDw8PGjYsCHe3t6PjfeTTz7ht99+w9HRkVq1alG7dm2io6NZtGgRbdq04fLly8ke++eff9K1a1fCw8OpV68ehQsXJjAwkJ49e3Lo0KFE+58/fx5/f3++/fZbrly5Qo0aNWjYsCEeHh6sXbuW5cuXJ9j/8uXLtGnThqlTp3L79m1q1KhB9erVCQoKYty4cfTr1y/ZBC0jGjZsiKurKzExMezbty/BtqNHj9KyZUtmz55NdHQ0derUoXLlypw6dYoRI0YwYsSIROeLjIykd+/eDB8+nP379+Pj40OTJk0oUqQI+/fv57vvvkuw//Xr12nXrh0zZswgJCSE+vXrU6NGDU6fPs3nn39O3759k304cOHCBV577TWOHz/OCy+8gLe3NwcPHqR3796WHr/Bgwfj5OREnTp1cHBwYM2aNfTs2TPZc4aEhNCuXTu2bNlC1apVefHFFwkKCuKrr75iwIABCXrc4EGS17VrVyZOnMjFixepVasWdevW5b///mPy5Mm88cYb3L17N8ExEydOZMCAAezfvx9vb2+aNGlC+fLlCQsLY/bs2fz3338pfmYVKlSwDBV2c3OjTZs2ln+NGzdO8dj0xmwWGhpKhw4d+PPPP/Hz86NatWoEBQUxZcqUVBfsM9uzZw8RERFUr179sfNWixUrxmuvvUZkZCTff/99mq6zefNm4uPjkxxenRrmJDM0NJQTJ06k6xxP0s2bN7lx4wZGozHJRBcefIeABO/n+PHjCbY9qmLFigCcO3eOqKioRNvN04bMybmIZG2agywimSYmJoagoCDmzZtHYGAgBQsWxN/fP1XHurm5MXPmTOrWrZugSFZYWBhDhgzh77//Zu7cuQnmoP7yyy/cu3ePIUOGJJqbGhoaytWrV9MUf5s2bTh06BCrVq3izTffTLDtzp07bNmyxbLfw3LlysWsWbOoU6dOgj+O79y5w6BBg9i1axcLFy6ke/fuia4ZHR3Nli1bWL58OT4+PqmOdeTIkYl6kWJjY/n222+ZNWsW48aNS/aP79mzZ/Pdd99ZEhCTycSoUaNYsmQJ06dPTzD8MjY2lnfffZerV6/Spk0bRo0aRY4cOSzbb926xcWLFy0/x8fH079/fy5dukS/fv149913LXMdQ0NDGThwIDt27ODHH3+kX79+qX6/qWE0GilXrhz79+/nzJkzvPLKK8CD3ux3332XkJAQRo0axeuvv26Z1x0UFETfvn1ZsWIFL774Ii1btrScb8yYMezatYsKFSowbdq0BNMC7t+/n6jHfeTIkVy4cIGGDRsyadIky30KDg6mW7du7NixgxkzZjBgwIBEsS9fvpx+/foxaNAgS1G78ePHM2fOHEaMGMHt27f59ddfLaMJQkJC6NChA6dOneLPP/9MVGwIYOPGjbz44otMmzYNV1dX4MHDiy5durB582aWLFlCx44dLft/8803HDp0iIoVK/K///2P3LlzA3D37l369u3LgQMHGDNmDBMmTAAeJKdz587F3d2dlStXWopDmR07dowCBQqk+JmZ56tu2rSJvHnzMn78+BT3f1RaY37Yhg0baNasGRMmTLB8RwMDA+nSpQsLFy6kT58+qS74Zv4u+Pr6pmr/d999l1WrVrF06VJ69eqV6N4lZ9OmTRiNxhTrJKQkd+7cFChQgODgYM6cOWNJIKOioqhcuXKaz5dU22tNQUFBAOTJkyfZOdPm79jD7b35uIIFCyZ5TO7cuXF0dCQ6Oprg4GCKFy+eYLv5c0xpVI2IZB3qQRYRq+ratatlSKR5iOK8efNo2bIlixcvTvUwQDc3Nxo2bJiognTOnDn56KOPgAd/0D7s1q1bANStWzfR+XLlypVs70FymjdvjrOzM0eOHOHs2bMJtv3+++9ER0dTpUqVRL3iHh4e1K9fP1HPkYeHB8OHDwceJCvJ6devX5qSY4DGjRsnurf29vYMHjwYT09Ptm3blmTPCDzoAX+4d85gMFiGXgYGBiYYevnHH39w9uxZypYty5gxYxIkx/DgD9eqVataft60aRMnTpygTp06vP/++wn+qM2VKxfjx4/HaDSyYMGCNL3f1PL09ARIMLR36dKlXLt2jQ4dOvDmm28mKHpWqFAhRo8eDZAgpv/++48VK1bg6OjI9OnTE82Zd3Z2TjAH9Pz582zduhVHR0dGjx6d4D4VKFCAjz/+GIB58+Yl2eNbokQJBgwYkKDie+/evS3n7t69e4Kh9p6enpYCQo/O8zczGo18+umnluQYHhTKMldYNs/RhAcPEZYtWwbA6NGjLYkmPBi+/sUXX2A0GlmzZo1lWPDdu3eJiYmhZMmSSSZ4FSpUsHwemSE9MT/M3d2dzz77LMF3tHr16rzwwgvExcUlGoWQEnPvZWpGf8CDOdVvvvkmMTExTJ06NVXHhIeHs3v3bqpUqZKgsFRaJfU7YjQaE/Tep/afuap8ZjEvh5VSUUfz79rDS2eZp+Sk9Tgz8+f4LPSyi0jGqQdZRKzq4WWeTCYTN27c4OjRo6xbtw4nJyc+/fTTNFVLPXLkCHv27CEoKIj79+9jMpksQ0EvXLiQYN+KFSvy999/M3r0aAYOHMjzzz+focqsOXPmpFGjRqxdu5ZVq1YxZMgQyzZz8a6UinMdOnSIvXv38t9//1liNw8lfjT2h6V3uOTly5f5+++/uXDhAhEREZb7ZDKZiImJ4cqVK0kOcU+quE+BAgXIkSMH9+7dIywsDA8PD+DBvGt48L5Ts+SJef3Q5Na6LViwIEWKFOHSpUsEBQVZvVibObl/ONF8XExVqlTBwcGBf/75h7i4OOzs7Ni1axdxcXHUq1cv2V6oh5mTqRdffDHJSsv16tUjb9683Lhxg1OnTlmGeJrVqlUr0f318vKyfCZ16tRJdM5ixYoBD4Z2J6Vy5cqUKFEi0evNmzfno48+4syZM9y+fZvcuXNz5MgRoqKiKFOmTKLYAEqXLk2VKlU4ePAgBw4coEmTJhQoUIC8efNy+PBhJk+eTNu2bRP1xGWm9MT8sCpVqli+5w8rWbIkAQEByd7XpJjnvKelKnWfPn1YvHgxq1ev5q233kq28rXZtm3biI6OTnd7YZbU74iDg0Oae++zMjc3NxwcHIiOjiY8PPypLg4nIhmnBFlErCqpZZ7Cw8MZOHAgy5Ytw2g08sUXXzz2PBEREQwePJitW7cmu094eHiCn3v37s2RI0fYvn073bt3x9HRkQoVKvDCCy/QunXrBMnBrFmzOHfuXKJzPvpHYZs2bVi7di2rV6/m/fffx2g0cu7cOQ4fPpzs2sdhYWEMHDiQnTt3pjp2M6PR+NhhqI8ymUx89dVXzJkzJ8VCO8ldM7nrmZOxh+dLm4cqpraStnnu8yeffMInn3yS4r63b9+2eoIcEhICkCDxMcfUo0ePxx5/9+5dPD09LXNnU/u+r127BpDiUNmiRYty48YNrl27liihe9xnklTSbe4BS25+e+HChZN83dHRkXz58hEcHMz169fJnTt3quIvUqQIBw8etOxrMBj46quvGDp0KDNnzmTmzJnkzZsXPz8/GjZsSPPmzXFyckr2fBmVnpgfltyDD3OPe1rW8jXPc364t/5xPD096dGjB9OmTWPKlClMmzYtxf03bdoEpP+BmllSvyNPK/P9TK5AHPx/b/HD9978u5HW4x69dmhoKHfv3lWCLJLFKUEWkUzn5ubGsGHD2LFjB8uXL+eDDz547JrB33zzDVu3bqVMmTIMHTqUihUr4uHhYXmKn1Ql5xw5cvDjjz9y9OhR/v77b/bu3cvhw4c5ePAgs2bN4rPPPrOswbl9+/Yk55M9miC/+OKLljl6AQEB1K5d29J7nNzax+PHj2fnzp0899xzDB48mAoVKuDu7o6DgwPh4eE8//zziQoimdnb2ycaVv44q1ev5qeffsLDwyPBWp7m3vM2bdpw/PjxZK+ZlnWVH+5lSg1zwm5eWzol1l5HOi4ujlOnTgEkGPppjimpYemPSutnYS2P+0ye1rWwa9WqxcaNG9m+fTs7d+5k//79bNy4kY0bNzJ9+nQWLlz41K5dnNbvdkrc3d0JDg5OcrhuSnr06MH8+fP5888/LYUNkxITE8O2bdsoXbp0kqMCUuvWrVuWnvGHf0diYmIsSyalRdOmTWnQoEG643kc8wO0W7duER0dneQIIXPV/ocfCJmPS65I3O3bt4mOjsbOzi7Zh1PmzzKz17sXEdtTgiwiT4R5rdO4uDguXryYZIL7MPP84kmTJiWa13bp0qUUj61UqZLl/FFRUSxevJixY8fy5Zdf8uqrr5IzZ85Ur2lpNBpp3bo1M2fOZOXKldSqVYvffvsNSH54tTn2b7/9NtEQ04cLWFmL+XoffPCBZf3mhz3ufqWF+Q/NlIaIP8z8x2br1q1p1aqV1eJIjS1btnDv3j0cHByoVq1agpiuXr1qWdYqNczv+/z586na35wEplQ93LztSSWM5t7/R0VHR1uSJPNDjNTEf+XKlQT7mrm6utK0aVPLEPbLly8zcuRIAgICmDJlCuPGjcvYG0lGRmK2tjx58gAku0Rcctzc3OjTpw8TJ05k8uTJSRbyA9i9ezdhYWGJigem1dq1a4EHRaoernsQHx9vqdKfFt7e3pmaIHt5eVmmJpw4cYIqVaok2ufYsWMAlCtXzvJa+fLlE2x7lHlJqJIlSyY5yiE8PJyYmBicnJzUeyySDTydj6BFJMt5OEl7tLBTUu7cuQMkPezR/Eddajg5OdG1a1eKFy9OVFRUqhOch5kT4U2bNrFp0yaCg4MTrX1sFhcXR1hYGAaDIcmeiLTEnlrme5XU9bZu3Zrs0Or0ML/nlStXJlrTOinmgmmPFlTLbGFhYUycOBGAtm3bJpgLmp6YzHOCd+7cmey60g8zJ+QBAQFJDufdvn07N27cwN3dPc0F2dLryJEjST4sWbduHfHx8ZQqVcpS2Kpy5co4OTlx5syZBOvJmp09e5bDhw9jZ2eXoChbUooWLUrfvn0BLD36KTH3Cqbm+/Uwa8acUeYliB4t7pcanTt3Jl++fOzcuZPAwMAk9zEPr3755ZfTHWNQUJClsn337t0TjEpwcnLi1KlTaf6XmRWszcwVu5NqS/fs2cPNmzfJnz9/goewNWrUwM3NjXPnziVZaMu8hnlyw9XNn2NyS0uJSNaiBFlEMl14eLglWSlevHiqKrua53ouXLgwweu7du1izpw5SR6zYMGCJHs2T506xdWrV9M1vxceVBT28/MjMjKSUaNGAYnXPjazs7OjRIkSmEwmFi1alGDb33//zfz589N8/ccx388lS5YkWE/44sWLfP7551a9VtOmTfH29ubUqVOMHDky0Zy+W7ducfDgQcvPzZo1o0yZMmzatImvvvoqySGnly9fZs2aNVaJz2QysW3bNtq3b8/FixcpWbJkguJqAG+88QZeXl7Mnz/fsg7yo06dOmVJQuDBg5o2bdoQHR3Nu+++myhJjoqKshQwgwff3/r16xMdHc2nn36a4D5du3bNsq5uly5dcHBwsMp7f5y4uDhGjx5tmWsJD3pUzes3d+7c2fK6m5sbr732GgCfffaZZZ4qPHj4MGrUKOLj42nZsqWlKN+lS5dYuXJlkp+xuZZAagqceXl5YTQaCQ4OTtPDnfTEnFlq1KgBkOQ64o/j5OTEO++8A5DkSBeTycRff/1FgQIFHjsSJymxsbGsW7eODh06EBoayvPPP5+q+fhP0r59+2jatGmSo0569OiBvb09ixYtSlBZPCQkhC+//BJ4UI/i4SHzjo6OdO3aFYBPP/00wffq77//5rfffsPFxSXZHnnz52j+XEUka9MQaxGxqlmzZlmG5plMJm7evMnRo0e5c+cOrq6ujB8/PlVz/d5++23ef/99Jk2axB9//IG3tzdXr17l4MGD9OnTh1mzZiU6ZsmSJXz++ecUL16cMmXK4OzszPXr1zlw4ACxsbH06tUr1euYPqpt27YcPHjQ8kd3StWr3377bYYNG8a4ceNYs2YNJUqU4PLlyxw+fDjZ2DOie/furF27lo0bN9KkSRMqVapEWFgYe/bsoXr16nh6eibZo5YeDg4OTJs2jV69erF8+XI2b96Mn58fzs7OXL16lRMnTtC2bVv8/PyAB3N4Z8yYQe/evfnxxx9ZunQpPj4+5MuXj4iICM6ePculS5eoUaNGgjWHU+OPP/6wFFqLjo4mNDSU48ePWz6jBg0a8OWXXyYqPuTh4cHMmTN5++23mTBhAj/99BNly5YlT5483L17l1OnThEcHEybNm0S9Ch9/PHHXLp0ib1799K4cWOqVq2Kl5cX169f58SJE3h5efHHH39Y9v/iiy/o2rUrW7ZsoVGjRlSrVo2oqCj27NljqURt7bWfU/LKK69w5MgRGjVqRPXq1YmKimL37t1ERkbSsGFDOnXqlGD/oUOHcuzYMQ4fPkzjxo154YUXMBqN7Nmzh9DQUMqXL29ZrgoezOMcPnw4n376KeXLl6dQoULExsZy8uRJLl68iJubG++9995j43RxcaFOnTps27YNf39//Pz8cHJyIm/evAwaNCjFY9Mac2apUaMGrq6uBAYGWiqhp0W7du2YPXt2kj3+hw8f5vr167z55puPbUsXLVpkeXATFRXFrVu3OHbsGOHh4RgMBtq2bcvHH3+coWr/jzNlyhR27dpliQEefFfM9SDgwUOrh6eH3Lt3j/PnzycZV8mSJfnoo4/4/PPP6dq1Ky+88AJubm7s3r2bO3fu0LBhwyQT3bfffpvAwEACAwNp3LgxNWrU4Pbt2wQGBmIwGBgzZkyy/z/s3r0bgIYNG6b/RojIM0MJsohY1Y4dOxL87OLiQuHChfH396dnz56p6kGCBz2Pnp6eTJs2jX///ZcLFy5QpkwZJkyYQOvWrZNMMgcNGsSWLVs4fPgw+/bt4969e+TNm5e6devy+uuvU79+/XS/r2bNmjFmzBju37+f5NrHD2vdujW5c+dmxowZnD59mvPnz1O2bFm++eYbGjdubPUEuVSpUixfvpxJkyZx6NAh/vrrL4oUKcI777xD7969E/QMWut6q1at4pdffmHTpk0EBARgNBrJly8frVq1ol27dgn2L1q0KCtXrmTx4sVs2LCBEydOcPDgQXLnzk2hQoVo1apVsksupeTYsWOWOYUuLi7kzJmTMmXKUKlSJVq2bJnicMhKlSqxZs0a5s+fb/nOxMTE4OXlRbFixejcuXOimHLkyMGcOXNYsWIFq1at4tixY0RFReHl5UW1atUSzf/Onz8/y5Yt46effmLjxo1s2bIFOzs7SpUqRZs2bejYseMTLQLm6enJkiVLmDx5Mtu3b+fOnTsUKVKEtm3b0qNHj0SFv1xdXZk3bx7z5s1j7dq17NixA5PJRLFixejevTvdu3dPsK6st7c3w4YNY+/evZw+fZqTJ09ib29PwYIF6dmzJ127dk317//48eP5+uuv2bFjB+vXryc2NpaSJUs+NkFOa8yZxdXVlVatWrFo0SJ27NiR5rbHwcGB/v3788EHHyTalpbq1eaE0GAw4OLigru7O1WqVKFKlSr4+/tnqMBXal28eJHDhw8neC0mJibBa2mtxP3mm29SsmRJS1HG6OhoihcvzjvvvEOXLl2SfCDh6OjI7NmzmTNnDqtXr2bLli04OztTv359+vbtm+yw+5CQELZv346Pj0+mD80XkaeDwZRcWVMRERF55i1atIjPPvuMjh07Wn3IvSTv9OnTtGrVisaNG1uGsVtD06ZNuXXrFgEBATarsp6dzJ07lzFjxvDll1/Svn17W4cjIk+AWlYRERERKytTpgytW7dm1apVnD59mjJlymT4nJGRkTRv3pxixYopOX4CoqOj+emnnyjOpapbAAAgAElEQVRdunSK02pEJGtRkS4RERGRTPD+++/j7OxstR5kFxcX+vfvj7+/v1XOJyn79ddfCQ4OZtiwYXogIZKN6LddREREJBPky5cvQVV3ebZ07drVUv1aRLIPzUEWERERERERQUOsRURERERERAAlyCIiIiIiIiKAEmQRERERERERQAmyiIiIiIiICKAEWURERERERARQgiwiIiIiIiICKEEWERERERERAZQgi4iIiIiIiABKkEVEREREREQAsLflxc+fP8/q1avZuXMnly5dIioqimLFitG0aVO6detGjhw5UnWev//+mxkzZnDy5EkcHR154YUX+OCDDyhatGgmvwMRkcdTWyci2YHaOhHJCgwmk8lkq4t//fXXLFiwgJdeeglfX1/s7e3Zs2cP69evx8fHhyVLluDs7JziOTZu3MiAAQMoV64c7du3Jzw8nF9++QWj0cjy5cvJnz//E3o3IiJJU1snItmB2joRyQpsmiAfPXqUEiVKkDNnzgSvT548mZkzZzJy5Eg6d+6c7PExMTG89NJL2Nvbs3btWlxdXQE4ceIEbdu2pV27dnzxxReZ+h5ERB5HbZ2IZAdq60QkK7DpHORKlSolakQBmjVrBsC///6b4vGBgYFcv36ddu3aWRpRgOeee44aNWqwbt06YmJirBu0iEgaqa0TkexAbZ2IZAVPZZGu4OBgALy8vFLc7+jRowD4+fkl2ubr60t4eDgXLlywenwiItagtk5EsgO1dSLyLHnqEuS4uDhmzJiBvb09LVq0SHHf69evAyQ5HyVfvnwAXLt2zfpBiohkkNo6EckO1NaJyLPGplWskzJ27FgOHjzI4MGD8fb2TnHfyMhIABwdHRNtc3JyAuD+/fuPvabJZCItM7ENBtK0v/w/3buM0f1Lv7TeO6PRkHnBoLYuq9O9yxjdv4x5mto7tXVZn+5f+uneZUxmtXVPVYI8ZcoU5s+fT8eOHenbt+9j93dxcQEgOjo60baoqCiAx1ZLBIiNjSc09F6q48yVK0ea9pf/p3uXMbp/6ZfWe5c3b+J5dNaiti7r073LGN2/jHla2ju1ddmD7l/66d5lTGa1dU/NEOupU6cyY8YM2rZty+jRo1N1TErDbVIapiMiYitq60QkO1BbJyLPqqciQZ46dSrTpk2jTZs2jBkzBoMhdd3flSpVAuDgwYOJth06dAg3NzdKlChhzVBFRNJNbZ2IZAdq60TkWWbzBHnatGlMmzYNf39/xo4di9GYdEjXr1/n7NmzlvkpANWrVydv3rwsW7aMiIgIy+snT55k7969NG3aFAcHh0x/DyIij6O2TkSyA7V1IvKss+kc5AULFjB16lQKFSrEiy++yJo1axJs9/Lyonbt2gBMmjSJlStXMnfuXGrWrAmAg4MDH3/8Me+//z5vvvkm7du3JyIigp9//pncuXMzYMCAJ/6eREQepbZORLIDtXUikhXYNEE2r3cXFBTEsGHDEm2vUaOGpSFNzquvvoqzszMzZsxg4sSJODo6UqtWLYYOHap5KiLyVFBbJyLZgdo6EckKDCaTiovHxMSp2uETonuXMbp/6fe0VHW1JbV1T47uXcbo/mVMdm/v1NY9Wbp/6ad7lzFZvoq1iIiIiIiIiC09Vesgi4iIiIiIPK0iIyMID79DXFxMhs917ZoBDeZNv5s37XFwcMbV1R17e+sV8FOCLCIiIiIi8hgxMdGEhYWQK5cXDg5OqV7CLDl2dkbi4uKtFF328uDBQjwREeHcvn2N3LnzWy1J1hBrERERERGRxwgLC8XNzQNHR+cMJ8eSMQaDAXt7B9zcPMiRIycREXetdm4lyCIiIiIiIo8RGxuNk5OLrcOQRzg7uxIVFfn4HVNJCbKIiIiIiMhjxMfHYTTa2ToMeYSdnR3x8XFWO58SZBERERERkVTQ0Oqnj7U/EyXIIiIiIiIiIihBFhEREREREQGUIIuIiIiIiMhDDhzYR5061Vi4cF6ibQcP7qdJk/r4+zfhzJnTGbrOzZs3+eGH6Qwe3J8WLRpRp041xoz5LEPnzCglyCIiIiIiIvJYO3duZ8iQAbi7e/D99z9RunSZDJ3v0qULzJs3hwsXzlGuXHkrRZkx9rYOQERERERERJ5uGzf+wZgxn1KsWHEmT56Ol1feDJ+zXLnnWLPmTzw9PQkNDaVFi0ZWiDRjlCCLiIiIiIhIslauXMakSRMoV64833zzHe7uHlY5b44cruTI4WqVc1mLEmQRERERERFJ0rx5c/jhh+k8/3x1xo37hhw5ciTYHh0dzb1791J1LqPRiLu7e2aEaTVKkEVERERERCSRVauWERR0lbp1GzB69FgcHR0T7bNp0wbGjh2dqvMVKFCQZcvWWDtMq1KCLCIiIiIikk6/H7vG6n+C03ycwQAmUyYEBLSqWIDmFfJn+Dy3bt0EoHDhIkkmxwA1atRi8uTpqTqfk5NThmPKbEqQRUREREREJJHOnbtz6NABfv11PiaTif7930+0j5eXF15eXjaILnMoQRYREREREUmn5hXyp6u31s7OSFxcfCZEZD1OTs5MnDiZDz8czOLFCzCZ4hkwYEiCfaKi7hMeHp6q8xmNdnh6emZGqFajBFlERERERESS9CBJnsSwYYNZsmQRJhMMHPj/SfLmzX9qDrKIiIiIiIhkD05OzkyYMInhw4ewdOkiTCYTgwYNBTQHWURERERERLIZJydnxo+fxIgRQ1i27FdMpnjef//DDM9B/vnnHwGIiooC4OzZ05bXfH2r4utbNePBp4ESZBEREREREXksJycnxo37hhEjhrJ8+RLi400MHvwhBoMh3ef88ceZCX7+999T/PvvKQB69HhLCbKIiIiIiIjYTtWq1dixY1+S25ycnJg0aarVrpXcdWzFaOsARERERERERJ4GSpBFREREREREUIIsIiIiIiIiAihBFhEREREREQGUIIuIiIiIiIgASpBFREREREREACXIIiIiIiIiIoASZBERERERERFACbKIiIiIiIgIoARZREREREREBFCCLCIiIiIiIgIoQRYREREREREBlCCLiIiIiIiIAEqQRURERERE5CEHDuyjTp1qLFw4L9G2gwf306RJffz9m3DmzOkMXefgwf18880EunbtyCuv1KdFi0a8/XZP/vzzD0wmU4bOnV72NrmqiIiIiIiIPFN27tzOyJHDyZMnD1OmfE/hwkUydL4ZM6Zy48Z16tVrgLd3ae7fj2Tz5j8ZPfoTDhzYx7Bhn1gp8tRTgiwiIiIiIiIp2rjxD8aM+ZRixYozefJ0vLzyZvicb7/dn8qVfbGzs7O81r796wwY0I81a1bRvn0nvL1LZ/g6aaEh1iIiIiIiIpKslSuX8cUXIylbthzTp//PKskxgJ/f8wmSYwCj0UiDBi8BcO7cWatcJy3UgywiIiIiIiJJmjdvDj/8MJ3nn6/OuHHfkCNHjgTbo6OjuXfvXqrOZTQacXd3f+x+169fByB37jxpDziDlCCLiIiIiIhIIqtWLSMo6Cp16zZg9OixODo6Jtpn06YNjB07OlXnK1CgIMuWrUlxn5s3b7B69UoKFSpM5cq+6Yo7I5Qgi4iIiIiIpJPTyWU4n/g1zccZDIZMq9R8/7lORJVrl+Hz3Lp1E4DChYskmRwD1KhRi8mTp6fqfE5OTiluv3//PiNGDCUy8h4TJkzC3v7Jp6tKkEVERERERCSRzp27c+jQAX79dT4mk4n+/d9PtI+XlxdeXl4ZvlZUVBQjRgzh1KkTfPzxZ1Sp4pfhc6aHEmQREREREZF0iirXLl29tXZ2RuLi4jMhIutxcnJm4sTJfPjhYBYvXoDJFM+AAUMS7BMVdZ/w8PBUnc9otMPT0zPR6w+S46Hs27eX4cNH0qRJM6vEnx5KkEVERERERCRJD5LkSQwbNpglSxZhMsHAgf+fJG/e/GeG5iCbk+PAwN18+OHHNG/eyqrxp5USZBEREREREUmWk5MzEyZMYvjwISxdugiTycSgQUOBjM1Bjo6O5qOPPiAwcDdDh46gZcvWVo89rZQgi4iIiIiISIqcnJwZP34SI0YMYdmyXzGZ4nn//Q8zNAf5888/Yc+eXVSrVgNnZ2c2bFiXYHupUmUoXbqMNcJPNSXIIiIiIiIi8lhOTk6MG/cNI0YMZfnyJcTHmxg8+EMMBkO6znfy5AkA9u3by759exNt79HjLSXIIiIiIiIiYjtVq1Zjx459SW5zcnJi0qSpVrnO49ZEtgWjrQMQEREREREReRooQRYRERERERFBCbKIiIiIiIgIoARZREREREREBLBxka4ffviBY8eOcezYMa5cuULhwoX566+/0nSOl156iatXrya5LSAggNy5c1sjVBGRdFNbJyLZgdo6EckKbJogT5o0iVy5clG+fHnCwsLSfR5vb2/69euX6HU3N7eMhCciYhVq60QkO1BbJyJZgU0T5E2bNlG0aFEAWrRowb1799J1Hi8vL/z9/a0ZmoiI1aitE5HsQG2diGQFNp2DbG5ErSE2Npbw8HCrnU9ExFrU1olIdqC2TrIDk8lk6xDkEdb+TGzag2wthw8fxtfXl5iYGHLmzMnLL7/M4MGDyZ8/v61DExGxGrV1IpIdqK2Tp5WdnT0xMdE4OjrZOhR5SExMFPb2DlY73zOfIJcuXZp27dpRqlQpYmNj2bNnD8uWLSMgIIClS5eqMRWRLEFtnYhkB2rr5Gnm5paL0NAb5MqVFwcHRwwGg61DyrZMJhNxcbFEREQQEXGHnDk9rXZug+kpGSdgnquS1mqHSVmzZg1Dhw6lffv2fPnll4/dPz4+nri41N8GOzsjcXHxGQkx29K9yxjdv/RL671zcLDLlDjU1mUPuncZo/uXMU9De6e2LvvIbvfv7t273Lx5g9jY2AwP7TUYDBqynU4GgwF7e3scHZ3ImzcvTk6P79VPbVv3zPcgJ6Vly5ZMnjyZrVu3pmr/uDgToaGpLySRK1eONO0v/0/3LmN0/9Ivrfcub96cmRiNdaite3rp3mWM7l/GZLX2Tm3d0y373T97cucuaJUzZb97Z13m+xcZGUdk5OPvY2rbOpsW6cpMhQsXJjQ01NZhiIhkKrV1IpIdqK0TkSclyybIly5dIk+ePLYOQ0QkU6mtE5HsQG2diDwpz0yCHBQUxNmzZ4mJibG8ltyTxAULFhAcHEzDhg2fVHgiIlahtk5EsgO1dSLytLLpHORVq1YRFBQEwO3bt4mJieH7778HoFChQrRu3dqy77Bhw9i7dy+bN2+mSJEiluOXL19OnTp1KFKkCLGxsezdu5dNmzZRrFgxBgwY8OTflIjII9TWiUh2oLZORLICmybIy5cvZ+/evQle+/bbbwGoUaNGgoY0KZUqVWL37t2sX7+e27dvYzKZKFKkCG+99RZ9+vTB3d0902IXEUkttXUikh2orRORrOCpWebJlmJi4lTt8AnJ6vdu5/nb7L4QgpujHe4uDrg72ePubI9PPjfy5cz4ovJZ/f5lpqxW1TU91NY9Obp3GaP7lzHZvb1TW/dk6f6ln+5dxmRWW5cll3kSedKiY+OZuv08vx64ipO9kajYhOsBujraMatjFcrmc7NRhCIiIiIi8jhKkEUy6HJIJB+tPcHJ6+F0qlqY/nVLYmc0EB4Vy937sdyMiOaT30/Qf/lRfnrdlyK5XGwdsoiIiIiIJOGZqWIt8jTaePI6XeYfIOjufb72L8+QhqVwtDdiZzTg4eJAUU8X/Ip4MK1dZeLiTfRffpRbEdG2DltERERERJKgHmSRVDgWHMayQ0HciogmNDKG0MgYQu7FcD82nsqF3BnTvBwF3J2TPb5knhxMblORd5YeYeCKf5jZoTJuTvr1ExERERF5mugvdJEURMXGM2vXRebvu4ybkz2FPZzJ5eJAyTw5yOXiQHFPF1pVLIC93eMHY1Qq5M74VuUZsuoYH/x2jCltK+Fkr0EcIiIiIiJPCyXIIsk4GnSXzzec4sLtSPwrFWBQfe8M9/rWLpmbT5uWZdS6U4xcd5KxLZ7D3miwUsQiIiIiIpIRSpBFHnE/Jo4fdl1k4f4r5HVzYuprFXmhRG6rnf/V5/ITGhnLpC1nGbPxX0Y2KYvRoCRZRERERMTWlCCLPOTglTt8ufFfLoVE0qZyAQbUy3ivcVJer1qY8PuxzAq4iJuTPYMbeGNQkiwiIiIiYlNKkEWAiOhYpm+/wNJDQRTycOb79pWoXswzU6/Zu1YxwqJiWXTgKu5O9rz1YvFMvZ6kzZUrVwgICODmzZu0bNmSIkWKEB0dzc2bN/Hy8sLR0dHWIYqIiIiIlSlBlmxvz4UQxvz5L8F3o+hUtTDv1CmBi4Ndpl/XYDAwqIE34VEPepJdnex44/kimX5debzvv/+OJUsWEhcXh8FgwNfX15IgN2/enIEDB9K9e3dbhykiIiIiVqYSupKtrT4aTP/lR3G0M/K/TlUY0rDUE0mOzYwGAx+9UpaXyngxees5Vv8T/MSuLUlbtWo5ixbN44033mD27NmYTCbLNjc3N1566SW2bNliwwhFREREJLOoB1myrRWHgxi36QwvFPfkK//yOD/BxPhh9kYDXzQrx71Vxxiz8V/cHO14qWxem8QisHLlMurVa8DHH39MSEhIou0+Pj4EBgbaIDIRERERyWzqQZZsacnBq4zbdIY63rn5unUFmyXHZo72Rib6l6dCAXc+WXeSPRcSJ2byZFy+fInq1Wsmu93T0zPJxFlEREREnn1KkCXbWbj/Cl/9dZb6pfIwoWV5nOyfjl8DFwc7prStQIncORj62zGOBN21dUjZkqOjI5GR95PdHhQUhLu7+xOMSERERESelKcjMxB5Qubuvczkred4uawX41s+h+NTkhybuTs78N1rlcjr5sigFf9w+ka4rUPKdsqXr8C2bUnPMY6KiuK3336jatWqTzgqEREREXkSnq7sQCQTBV4KYer28zT2ycuXzZ/D3u7p/Pp7uToyrV1lXByMvLfsKEF3ku/NFOt7/fUuHDt2lA8++IBTp04BcPPmTbZv306XLl24du0aPXv2tHGUIiIiIpIZns4MQcTKomPjGb/pDIU9nBnVpCz2RoOtQ0pRIQ9nprWrTER0HD/vvWTrcLKV6tVrMmTIcDZs2ECPHj0A+PDDD+nTpw8nT57kiy++wM/Pz8ZRioiIiEhmUBVryRbmBl7mUkgk37ataPOCXKlVMk8OmpbLx/rj13mvbkncnR1sHVK24e/fFn//Zvzxxx+cO3cOk8lEiRIlePXVV8mfP7+twxMRERGRTKIEWbK8yyGRzNlziUZl8/Jiydy2DidN2vsV4rd/glnzzzXerFbE1uFkedHR0Rw//g958nhRtWoFunTpYuuQREREROQJyvAQ68jISK5fv26NWESszmQyMXHzGRzsjAxu6G3rcNLMJ58bvoXdWXooiLh4k63DyfKMRiMDB77N7t27bB2KiIiIiNhAqhPkdevW8eWXXyZ47fvvv6datWrUr1+fnj17EhkZafUARTJi07832X0xhH61S5DXzcnW4aRLB7/CXL1zn13nb9s6lCzP3t6ePHm8MJn0MEJEREQkO0p1grxgwQLu3v3/dVlPnDjB1KlTKV++PC1atCAgIIBffvklU4IUSY/wqFgmbTlLuXxutPMtZOtw0q1h6TzkdXNkyaEgW4eSLTRs+DJbtvxJfHy8rUMRERERkScs1XOQL1y4QKNGjSw/r1+/Hjc3N+bNm4ezszOOjo78/vvv9OvXL1MCFUkLk8nEt3+f41ZENF+3rvDUV61Oib2dkbaVC/LDroucuxFObgcVn89MLVq05sCBffTo0YNu3bpRvHhxXFxcEu1XqNCz+9BFRERERJKW6gT57t27eHh4WH4OCAigVq1aODs7A+Dr68v69eutH6FIOszadZFVR4PpUq0IFQrktHU4GdamckFm77nEgr2X6V+7uK3DydK6du2IwWDgzBkTe/fuTXa/EydOPMGoREQyz4EDB9i5cyc3b96kW7dueHt7ExERwalTpyhTpgw5cz77/4+KiKRWqhNkLy8vLl16sB5raGgox48fp2XLlpbtkZGRGAzPbi+dZB0/77nEj7sv0apift6rV9LW4VhFHldHGpXNy/KDV+hZvTCujipAn1m6d++NwWDA1fXZnLMuIpJa8fHxfPHFKDZv3ojJZMJgMNC0aVO8vb2xt7enb9++vPXWW/Tp08fWoYqIPDGp/iu7WrVqLFq0iPz58xMQEIDJZKJBgwaW7RcuXCBfvnyZEaNIqi3cf4XpOy7QpFxePmpcFmMWemjTwa8Q609c5/dj1+ngp+G9maVXr74A5M2rHhMRydoWLJjL5s0bGTp0KPXq1UvQ8eHk5ESjRo3YunWrEmQRyVZSPZlxwIABuLq6Mnr0aDZu3EjXrl0pVqwYAHFxcWzcuJHq1atnWqAij7P8cBCTt57jpTJefPZqOeye4XnHSalY0J3KhT1YeuiqqiyLiEiGrV+/hiZNmtGrVy+8vLwSbS9VqpRl9KCISHaR6h7kokWLsn79eo4fP07OnDkpXbq0Zdu9e/f48MMPqVy5cqYEKZKS+zFxLD0UxHfbzlPHOzdfNi/3TBflSknnmsX4cMVRtp65RcMyif+YEeuJi4vj3Llz3LlzJ8kHEnogKCLPuuDg/+jUqXOy2z08PLhz584TjEhExPbSNJHRyckJPz+/RK/nzJmTVq1aWS0okdQ4dyuCFYf/4/fj1wiPiuPFkp6Mb1keB7usW+W5ReWC/LDtLN9sOUvN4p7kcLSzdUhZ0vz5P7Nw4VzCw8OT3UdFukTkWefi4kJY2N1kt1+8eBFPT88nGJGIiO2lOpMICgpi3759CV47efIkgwcPplevXqxZs8bqwYkkZc+FEPouPkzHn/ez/PB/1C6Zm1kdqzClTUWc7LNucgzgYGdkRKMyXAuLYtaui7YOJ0tau3YVP/wwnXLlyjFo0CBMJhPdunWjV69eeHh4ULFiRcaOHWvrMEVEMqxSpSps3PhHktvu3r3LihUrqFmz5hOOSkTEtlLdgzxhwgRu3LjBwoULAbhz5w49evQgJCQEBwcHdu3ahbu7O/Xr18+0YCV7C7kXzeSt51h/4joF3Z14r25JWlbMT+4cjrYO7YmqUtiD1pUK8OuBKzQrn4+y+dxsHVKWsnLlcipUqMS8efMICQlh8uTJ1K9fn1q1atG1a1dat25NXFycrcMUEcmwrl178u67b9G9e3fatm0LwOnTp7ly5QqzZs0iIiJCBbpEJNtJdXfb0aNHqV27tuXn33//ndDQUJYuXcrevXt57rnn+PnnnzMjRsnmTCYTa48F037OPv48dYPeLxRjaY/qdKtRNNslx2bv1S2Ju7MD4zadJi5eBbus6eLF8zRs+DKAZem6+Ph4APLly0eHDh2YO3euzeITEbGW8uUr8sUX4zl16hTDhg0DYNy4cYwcOZKwsDC+++47ypQpY+MoRUSerFT3IN++fZv8+fNbft62bRu+vr5UqlQJgFatWvHjjz9aP0LJ1oLu3GfMxn/ZeymUyoXc+ahxGUp5udo6LJvzcHFgUANvPl1/ipVH/qOdr5Z9shaj0Q5nZxcAcuTIATxY+92scOHCXLyo4e0ikjXUqVOfV19txI4dOzh79iwmk4nixYtTv359SxsoIpKdpDpBdnJyIiIiAnjQm7J//35ef/11y3ZXV1fu3k2+0INIWh2+eoehvx0nJi6eYS+Xpm2VgllqXeOMevW5fKw9do3pO87ToIwXXq7Zszfd2vLnz89//wUB4OjoSMGCBdm3bx/NmzcHHoym8fDwsGWIIiJW5ezsTKNGjWjUqJGtQxERsblUD7H29vbm999/JzIyktWrVxMeHk6tWrUs24OCglTpUKxm/YlrvL30CO7O9sztXJV2voWUHD/CYDAw7OXSRMXGM3nLWVuHk2VUqVKVgIAdlp+bNm3K4sWLGTFiBMOHD2fZsmWqtSAiWcLp0/+yatXyZLf/+uuvnDx58glGJCJie6nuQe7RowcDBw6kWrVqxMfHU7p06QSVDQMCAnjuuecyJUjJPkwmE7N2XeTH3ZeoWsSDia3K4+HiYOuwnlrFc+egR41izAq4SNsqBXm+aC5bh/TM69ChE6VLl+H+/fs4OzvTv39/zp8/z6pVqwCoXbs2Q4YMsXGUIiIZN3v2LKKionjrre5Jbv/rr7/YtWsX33333ZMNTETEhlKdIL/yyivMnDmTzZs34+bmRo8ePTAaH3RAh4SEkCNHDq2FLBlyJTSSadvPs/nfm7SokJ+PGpfJ0msaW0uX6kVYefQ/pm8/z0+v+1oKS0n6FCtWgmLFSuDs7Aw8mIc8c+ZMwsLCMBqNuLpqDryIZA0nThzjtdc6Jru9evXqzJs37wlGJCJie6lOkAHq16+f5NBCT09PZs+ebbWgJHs5cS2MeYFX2PzvDYwGA+/WKUG3GkWV6KWSs4Mdb9Uqztg/T7Pt7C3ql/aydUhZUs6cOW0dgoiIVd25E5piTQUPDw9CQkKeYEQiIraXpgTZ7Pz581y+fBmAokWLUrJkSasGJVmfyWRi78VQfgm8TOClUFwd7ehcrQidqhYmr5uTrcN75rSsWID5+64wfccF6njnwc6ohwvpFRwcDEBMTFiK+xUqpMrhIvJs8/TMzYUL55LdfubMGRUlFJFsJ00JcmBgIKNHj+bs2YQFgUqXLs2nn35KtWrVrBqcZE37LoUyY+cFjgTdxcvVkQH1StKmckHcnNL1vEYAe6OBd+qUYPiaE6w7fo2WFQvYOqRnVvv2LVM1euHEiRNPIBoRkcxTtWo11qz5je7du1CqVKkE286ePcvSpUt5+eWXbRSdiIhtpDojOXLkCD179sTOzo527dpRunRp4MHTxbVr19KzZ08WLFhgWRdZ5FGHr97hp5X/EHDuNvncHBn2cmlaVSyAo73mGVvDS2W8eC6/G7N2XRvRSPwAACAASURBVOSVcvlw0n1Nl+7de2MwGHB1/f+RDLGxsVy+fJnNmzdTtmxZ6tWrZ8MIRUSso3v33mzbtpXXXnuN9u3bW4qtnjhxgmXLlmEwGHjnnXdsHKWIyJOV6gR52rRpeHh48Ouvv1KkSJEE2/r160fHjh2ZNm0aP/zwg9WDlGfb6RvhTN9+gZ3nb5PH1ZHBDUvRtnJBJXBWZjAYeK9uSd5ddpTlh4N44/kijz9IEunVqy8AefMmnnN8+fJlOnbsSMWKFZ90WCIiVlekSFEmT57OhAmfM2/ePAwGAyaTCXiwvOe4cePw9va2cZQiIk9WqhPkgwcP0q1bt0TJMUDhwoXp1KkTv/zyi1WDk2fb9bAofth1gTX/XMPNyZ736pbkrQaliL4XbevQsqwaxT2pUSwXc/ZcplXFAhq2bmVFixalY8eOfPfddzRo0MDW4YiIZFiFChVZt24d//zzDxcvXgSgRIkSVKhQQcUyRSRbSvVfz9HR0Y+tdBgdrcRHICI6lnmBV5i/7wrxJhOvP1+YnjWL4eHiQA5HeyXImezduiXptuAgC/ZdoW/tErYOJ8vJnz9/ojoMIiLPMoPBQKVKlTRNTkSENCTIJUqUYMOGDbz55puW9Y/N4uPj2bBhAyVKlLB2fPIMiYs3sfZYMN/vuMDtezE09snLO3VKUCSXi61Dy1bKF8hJo7JeLNh/Bf9KBSjg7mzrkLKUTZs24e7ubuswRESsKjo6mtDQUMsQ64flz5/fBhGJiNhGqhPkDh068MUXX9CnTx/69OljKdJ1+vRp/ve//7F//34++eSTTAtUnm77L4cyactZ/r0RQaWC7nztX4FKhZRE2Mp79Uqy49xtJmw+w6TWGiaXFnPm/A+AHDkcE7x+584ddu/ezenTp+ndu7ctQhMRsar4+Hj+j737Do+qWB84/j1bs7spm95DEhISIr1DEOkl9CqCiChYrtjAqz+716uoVxRFRQQRBRRQkSJNmoAgHQwdQkkogZDek23n90cwgrTEbLIp83mePMmeczLzZlhmd3bmvLNo0bcsW/ZD6RZ3NyOy9guCUJeUeYA8evRoTp06xcKFC9m+fft152RZZtSoUYwePdruAQrVR1peMWfSCzBZbZisMiaLDZPFxrazGfyakIafi5a3+0bTI8pbDMgcLNBNx2OxoXy05QzrT6TSM9rH0SHVGF99NeuW57y8vHjmmWeYMGFCFUYkCIJQOWbNmsG3335DeHg49957L0aj0dEhCYIgOFy5Mvi8/vrrDB8+nA0bNnDhwgWgJGlN9+7dS7cGEGqXnCIzm06m8cuJVPady+LGhVegUyt4PDaUUS0DcVIrqzxG4eZGtghk3YlUpm46TZt67hh1akeHVCP88MMKADw8DKXHJEnCzc0Ng8Fwq18TBEGocdauXUXr1u2YN2+u+GBbEAThqnKnuI2JiSEmJuaG45mZmaSnp5cuvRZqBqtNZt2JKyz54xImqw2VQkKlVKBWSFhlmfiLOVhsMsFGJx5uF0KrECNOKgUalQKNUoFWpcBNp0YnBsbVjlIh8XKPSB749gAfbTnDG72jHB1SjeDn5w/cfJsnQRCE2iQnJ4dOnTqLwbEgCMI17LYHzKJFi5g+fbq4T6WGsNpk1p9I5csdSSRlFhLmoSfQ6ITZasNslSk027DKMiOaB9Ar2oeGvs7iBbQGauDjzAOtg5i76zx9on1oG+ru6JAEQRCEaiIsLJz09DRHhyEIglCtiE1S6xirTWbDiVS+3JlEYkYh9b30vNu/IV0ivVCIAbBDSaY8ZEkJavtm/X64XT02nkxjyvqTLHqwlZjtv4OnnnoMAHU52kmSJLEPvCAINc64ceN5//0pjBs3RmSqFgRBuEoMkGspWZZJyzdxNr2AC1mFnM8q4kJWISev5JGcU0y4p553+jWkawMxMK5yliIUeZdQZSagSjuCKvUwqrSjKHPPAyArtdh0HticPJB1nli8G2MKbI/Zvw2gL3d1WpWCl3tG8ujig8zcnsiznevb+Q+qXZKTL1JcXExWViZA6ZZOOTk5AHh4eODkJLbOEgSh5jtz5jS+vv706dOHXr16ERQUhFJ5/YeDkiTx6KOPOihCQRCEqicGyDWYLMsUmK3kFlnIKbJwNr2Ak6l5nLySz8nUPDIKzKXXapQSgUYdEd7OTOwUTjcxMK4SirxktAkrUF/ehyIvGWVuMorC1NLzMhJWYzhm3+YUxYxCVihQFGagKMpEKspAkX8F3R9foN//GbJChRzQAr1fe4piRmFzCSxzHC2CjAxt6s/CfRfpVN+TlsEiU+mtfPzx5zz11GM88MADTJgwAW9vbwBSU1OZNWsWGzdu5JtvviE4ONjBkQqCIFTM7Nmfl/68dOnSm14jBsiCINQ1YoBcA8iyTEpuMafTCjidls/p9HxOpxWQmFFAscV23bUqhUR9LwOxYR5E+TgT7qUn2KjDx0UrBsRVRCrORnt6FdqTS1Ff3ImEjMUYjs01mGKvu7C5BGJ1DsDqFobFsyFo7pAZ2ZSP+vJeNBd/xyllF/p9n6LfP4Oi6OEUtJyIzTWkTHE91Smc3UmZvL7mBAsfaImLk/jvfzOffPIhjRo14aWXXrruuLe3Ny+//DJpaWm88847zJgxw0ERCoIg2MeiRSWD4muz9guCINR1Dn2H/MUXX3DkyBGOHDnChQsXCAwMZNOmTeUuZ9myZXz99decOXMGZ2dnunTpwuTJk/Hw8KiEqCtGlmWyiyyk5BRzObeIK3km0vP/+sooMGO2/jXolYHk7CLyTdbSYz7OGsI9DbRs6o+XQYOLVoWLk4pgo44wTz1qpcIBf1kdIstI5nykoiwUhakosxNLvrLOosxORJV6GMlmwmIMp6DNJIoiB2Ezhv3z+jQGzCH3YA65B7VRT875BPT7Z+B0dCFOxxZTHDWUgpYTsRrDb1uMXqPkzbhoxi/8g/c2JvBWX7E1280cOLCPxx9/8pbn27RpwwcffFDucutifycIQvUWGBgE2Ddrv+jrBEGo6W47QB45cmSZC0pJSSl35R9++CFGo5GYmBhyc3PL/fsAX3/9Ne+88w5t2rTh5Zdf5vLly3z99df88ccf/PDDD+j15b9n83ZS84q5kG/GZrLgrFVi0KjQKKXrMjzbrs74nssoJCmzgHOZhSRlFnI5p4jLOcUU/W3WVwLc9Wo8DRo89Ro0qusHuM0C3ajvpae+p4FwLz2uTmI/2zKRr+7afKuZc5sVRe4FlNlnS+71NUbckCBLKspCfWEbmqRfUafsR1GUgVScjWSzXF8VEjbnAKxuoRQ2GUdx5AAs3k1uXXcF2FwCybvnbQpaPYnuwEx0h+ejPbGEvE5vU9To/tv+biN/V8a3r8cXvycRG+5Bn4YiKcvfSZJEYmLiLc+fOnXqH5VbE/s7QRCE8hJ9nSAINd1tB8hnz54t19Y+bm5u5ap8w4YNpffx9evXj4KCgnL9fkZGBh999BGNGzfm66+/Lk0s0bhxYx5//HHmzZvHY489Vq4y72TConguZhddd0ylkDBolBi0KtQKicu5xdctfdarlQS76wj3NNAhzANfFy1+rk74uWjxcdZg1GtQKerY8mdZRirKRHYyglSOGW+bFWX6cZT5l7BpXJGdjMhaN2xaNxQFqaiuxKO+Eo/qykFUqYeQrMXYDL7YDH5YDX7Y9N4oCq6gykxAmXUWyVr8V0hI2FxDsHhEYXUNRp16ENXlfUiyDZvWDbN/W8wBbZG1RmxOxpLvOg+sbqFYXUNAVbWJm2wGP/I7vkFBiydw2TQZly3/hzL7LPntXwLFrTMwP9g2hB2Jmby34RTNAt3wdxUJp67VunU7li37kdatmzNw4MDSPlCWZZYtW8bixYvp1q1bucutif2dIAi1n9VqZcOGDcTHx5OdnY3854fLV0mSxJtvvlnm8kRfJwhCTXfbAfKuXbsqtfKKJrnZuHEjhYWF3H///ddlXezatSvBwcGsWLHC7p3o54Prk5GVRlp2IQVmGwUmKwUmG/lmGwVmEyaLjHewlkB3HUFuTgS5OeGuVyNJErJCDUo1slIDCvVfA0ObBclUCJYiJHMBisJ0FAWpJV+FqSDLyCotKLXISqe/flY5YXUJKllae6fBmc0K1uKSAaHVjCRbS47J1qs/W5BMeUjmPCRTLpIpD4UpF6ymktnSq99lSYGscS75UhuQ1Vd/1rgga5yxXf1eUqcNSbaAbEMyF6BKP4Yi5yiu5/ahvnIQRWEqNo0LFt/mmH2bY/FtgdmvBbLaUBKnpSReZe4F1Mm7UV/aheryvpK4bkNWqLF4xVDcYBCy2oAi/3JJ1ujUgygKUrHpvbG6R2AKvgerewRWYxhSQRqqjJMoM06iyjiB5txmLF4NKWj5JKaQLlh8m4Giet6zK+u9yYn7Cudtb6D/4wuU2Ynk9PgE1Df/hF2lkHgzLorR8/bz+urjfD6iKcq69gHNbTz55LMcP36UF198kalTpxIaGgpAYmIi6enp+Pv78+KLL5a73JrY3wmCULvl5OTwzDOPc+pUArIsl7xXuTpA/vPn8g6QRV8nCEJNVz3f8ZfRoUOHAGjevPkN55o2bcqqVavIz8/HYLBf8omYX4ahykywS1myQg3INyzXLXc5kuKvGUyrCclqvjqgNV19XFzhOkriVZUMdmXbnS++TaxK90hM9Tpj8YhCmZ2E+vI+9Ps+uWO5FvdIiiMGYA5og9UtDMmUi6I4G6k4G0VRFjYnNyw+TbF4RoNSW+7YTNcFKlfK8uhKo1CR1+ktLMZwnLe9gXHpMHL6foXN4HfTywPddPy7awRvrD3B/D3nebBt2RJ91QU+Pr7MnfsdS5cuZOPGjRw8eBAoedM3ZMgQxo8fX7r1U1Wq8v7OlA9XElFm55d80GWzlPQjf37JNmQnd2wGH2w6b1CKWz8Eoab58svPOXPmNP/5z39o06YNvXv3ZtasWfj7+zNjxgwuXLjArFmzqjQmR7y3EwRBuFaNHiBfuXIF4Kab2/v6+iLLMleuXCEsrAIJkv4mt+tUXIrPUZhfTEkKLfmve12RSw7dlFzyBtNqApsZyWoq+RmQ1bqSmWG1DlmlQ3bywKb3LvnSeZUsl7UWI1n+nAG++rOlAGV2EsqMEygzTyPZzMhK7TWz1BpkpQZZ5XR19lkLSg2yUg2SEiRlyaBXUoBChaw2lM4A/zkjLCu1JbPdClXJgFGWwVJYMsNsziuZdTblliStujrzLP05w6tQXa1DCQoNFo8GOEe0IqvgJkuqTfmor/yB6kp8yUy1Uls6U27TeWL2a4Wsq8LEHDVpcHyNoiYPYXOth8u6f+Gx4G5seh9sWldkjSuy1gVzQDsKm44HIC7Gh9/OpDN7RxLdo7wJMuruUHrd4ezszKRJk5g0aZKjQylV1f2d88oHUV/aQVn/19mcPEoGy3rfkr7jzxUzpStnnK72Ky7YtG7IGpcbVmXIah02rRHZyYhN617yoV8N/b8oCDXB779vo3fvvowYMYLMzJK939VqNZGRkUybNo3Ro0czffp0Xn/99SqLyRHv7QRBEK5VowfIhYWFAGg0mhvOabUlM4hFRUU3nPs7pVLCaCxjwgfj3SiUCpys/3wW9Z9xvsXx9lUaRQkD4PWPflOpVGDU3Kzt9ODTA+hRkcBqPaVScefnarP+WAPqozjwDVJRFsqibCjKRso8ifbMWpzc3JGbjQHgjYGN6PXxb3y2PYnPR7eogr/AccrUdtWYPfq78vR1k80PYTG1xooSlVqDs84JZ70TLjonXA163HQqnCxZaAvTcCpOQ2dKxWBKw5B2BSf5HBrJggYLKqwoZQuSteQWkvKQlVrQeYDOiOwZgRzYGjmwFbJf0xsS6lU3Nf355mii/SqmrO2Xnp5Gy5YlM7UqVclbQpPpr/VUPXr04KuvvqrSAXJV93Ul14vnW0WI9vvnRNtVTGW1X40eIOt0JW+QTCYTTk7X34NbXFySfOnvx2/GapXJyir7GzejUV+u64W/iLarmDK3nyYU2v7tDY3NitvKMajXPk+WIQqLdyOcgIfbhvDJb2dZdeACsWG1d/uM27VdTk42ly5dol690NI+w9vbBVmWmT17NkuWLCElJYWIiAgmTZpEhw4dqjJ0wD79XXn6unG9OnMioy3nUvNIzzeRlm/ieJ6J1DQT6Ummq4kIdYA/EqBRKVArJVQKBXnFFiy2G5fTaCQLrhTgKhXhKhXg66wkzNNAqIeOMHc9IS4yelsuiqIspOKsv74XZqBKjkd5/Geg5HYPi2fDklsqfJph9m1Wkovh7wn/JEX5kgDakejrKka0X8WUtf1cXFzJyMgGwGAwoFKpuHz5cul5tVpNdnZ2pcV5M1Xd14F4vlWUaL9/TrRdxZS3/cq6pV2NHiD7+PgAJVtM1atX77pzKSkpSJJUeo0g1HkKJTk9PsH9+964rn2UzBGrkbVu3NcykOWHL/PBplO0Htvqhm3G6oIFC75hxYqfWLZs7XXHP/jgA+bMmQOAq6srhw8f5tFHH+WHH34gOjq6SmOs6v4uyKijUajnTV94ZFmmwGxFKUmolIobsvDbZJmMAjNXcotJufqVXWjGdvV3ZRmsNplzmYX8lJLLlTMm/rw/xdvZk1CPYEI99IR66AkL0hHqocfLoEFRkIo6ZT/qlD9QXfkDbcIKdEcW3PbvkJFKlnIrlMhSyXebwQ+raz2sble/XOthM/gi6zywOXmA8saZK0GojYKDQ0q3tVMoFERHR7Ns2TKGDBmCzWZjxYoVBAUFVWlM4r2dIAiOVqMHyI0bN2bx4sUcOHDghk40Pj6esLAwkcRBEK4h6zzJ6TUT49KhuGx4lpy4L1ErFfy7a32eXHKYb/ddYFwdTNh16NAftG3b/rpZiZycHObNm4eHhwcLFiwgLCyMvXv3MmHCBObOnct7771XpTFWp/5OkiQMmlu/fCgkCS+DBi+Dhhi/O39am5ZXzLGUPE6n5ZOYUUBiRiGrj6aQb7KWXhPmqWdQYz/iGnbDGN675KBsQ5l1FtWVAyhzL95YsGy7mlzMCrIFbFYkqwlF/mWU2YloLmxFsty4VNOmccHqGoKpXjdMod1Lstg7aCZaECpT69ZtWbz4O0wmExqNhnHjxjF58mTatGmDQqGgoKCAN954o0pjqk59nSAIdVOZB8hHjhwhODj4ltlbc3NzOXfuHHfddZfdgrtWcnIyhYWFhISEoFaXZEvt1q0bb731Ft9++y39+/cv3Q5g06ZNnD9/nqeffrpSYhGEmszi15L8Dq/ivO11dAc+p7DFE7QL9aBLpBdf7TxHn4Y++NWxvZGTk5Np1y72umM7duzAZDIxduzY0mQwrVq1on///mzfvr3S46lL/Z2Xs5a7nbXcXd+z9Jgsy6TlmzibXsCptHzWn0hl2uYzfLL1LMFGHXqNEoNGWfJd2xgvQ0sa+bnQKMAVL0MZZ4BlGUXBFRTZSSgKU1EUZqAoTEcqykCVdhT9/s8w7JuOTedNcWg3TCGdsbmFYnUJRNYaRQIxocYbM2Yc9947urSf6du3L5IksWLFCpRKJb169WLAgAGVVn9d6+sEQagZyjxAHjZsGP/73//o37//Tc//9ttvTJ48mWPHjpW58mXLlpGcnAyUbAxvNpuZMWMGAAEBAQwaNKj02hdeeIHdu3ezcePG0uU+Hh4ePP3007z33ns8+OCD9OvXj5SUFObOnUt4eDhjx44tcyyCUJcUNnkI1eW9GHa+V7qf9Vv+WXyXeJKzy1cR1Hs0Fu9Gjg6zyuTm5uDl5X3dsYMHDyJJErGx1w+c/1yCWF6ivysfSZLwdtbi7aylTT13RrUM4lRaPquPpJCcU0R+sZV8k5W0fBMFV7//ed+zv6uWRv6u1PfSE2zUEeyuI9iow1mr+nsl2Ay+2Aw3ZssFkIoy0ST9iiZxA9rTq9AdW1R6TlbpsboEYvZrgSm8D6agWFBV78RhgvB3SqUSnU6HdM2HPXFxccTFxf3jMkVfJwhCTVfmAbIs33L/IgCsVut1HWxZLFmyhN27d1937OOPPwagTZs213Wit/LQQw9hNBr5+uuveeutt3B2dqZ3794899xzYgmOINyKJJHX5X1U6cdx2foKAK7Av5VADph/Wkru0J+wesU4NMyqYjS6k5GRcd2x+Ph4NBoNUVFR1x3XaDSl2V7LQ/R3FRfhZeCpe8Jveq7YYuPElTwOX8rhUHIuhy/lsP5E6nXXGHVqQtx19I3xYWBjf5SK279myU7uFEcNoThqCFhNqNKPoci9iDIvueR7zjm0p1ejO7YYWaXHVK8zxaE9sTn7I+U4oyqwlGyhp1BjdY8Ue0ULdYLo6wRBqOkk+U4j36uio6OZOnUq/fr1u+n5d999l+XLl7Njxw67BlgVzGaryHZYRUTbVYzd289SiDLr7NVZZAPFko6nv93Cp0X/h4tWSeG9PyO7Vm2Clspyu7Z79tknyMrK5Msv56NUKklLS2PEiAG0aNGCb7755rprp02bxpo1a1i3bl1VhG1Xda2vKzJbuZBdxPnMQi5kFXIus5BjKXmcuJJHpLeBSZ3r0yrEWLFKrCbUF39He+YXNGfXoSxIuellFmN98mNfxVSvm1iaXQY1/bnnaLdqv3XrShIR9uzZ+7rHrne4reZWqwerq7rW1zmaaL9/TrRdxVRWFuvbDpC/++47Fi5cCEBCQgL+/v44O9+4H292djapqakMGDCgyhPX2IPoSKuOaLuKqYr2yygwMWv5Wl5Pf458jReWkT/j5Op551+s5m7Xdtu2beXFFycTE9OIpk2b8fvv2zh3Lon33nvvhvvv7r33Xnx8fPjkk0+qImy7En1dyWqojSfTmL71DJdyiukc4cnT94QTZNRhk2VyiyxkFJjRa5T4umjLWbgNZdoxFKYcnPVK8nLykWQrUmEG+v2foco6jSkwlrzY17B6V06+jtqiNj73qtKt2u/uu1sjSRIbN25HrVaXPr7dXIkkSeW6fa46EH1d1aqL7VdktuKkVla4nLrYdvbkkG2eVCpV6UbtkiShVCpv2LhdkiRCQ0MZNGgQjzzySJkDFAShevLQa/j3vf1ZscHG8JPPcPLbkRQMXkS4X80fJN9Kx46duO++MSxe/C1Hjx4G4P77779hcHz8+HHi4+N5/fXXb1aMUANIkkT3KG86hnuwcP9F5u46x4iv9+LmpCaz0Iz16n3MSgmGNw/k0Q71brx3+ZaFK7B634UVkI16zNe8aBc3GIzTkQUY9nyI+/e9KYoeQUGbydhcAirhrxSEm5s27TOA0oRYfz42GvUOi0kQahJZlpm2+Qzf/5HMkCb+PNQupOyJIYUao8xLrNu1a8ebb75Jz549KzumKic+aaw6ou0qpqrb7/yOhTTb/zwbbK1JvPtjBjUNKneugeqiLG2XmZlJcvJFAgICadDgxu2u0tLSuHz5MuHh4ej1Ne8NpejrbpSaV8z8PRcoMFlx16vxMGjw0KnZfyGbpQcv4a5X81SncOJifMr13L9V20nF2ej3Tkd38CuQbRTXj6Ow6Xgsvi3E0utr1IXnXmWqrFmVmkL0dVWrLrXf3F3nmLEtkcb+rhxNyUWtkBjVKogxrYLK/mHqNepS21UGhyyxritER1p1RNtVjCPaz7p7Jn573uIHSyd+8P83L/aMJshY87L11vU3jCD6uvI6lpLL/zae4vClXJoGuPLvrhFE+d54m9HN3KntFDkX0B2ai9PRhShMOZh9mlIUPRxZ4woKNbJSDQo1Vmf/OpMs71p1/blXUWVpv4KCAh5++H4GDx7OE0/UrhWAoq+rWnWl/ZYfusRb6xLo3dCH//SJ4mJWEZ9vT2T9iVTcnFQMbRZAA28D9dz1BLvr0KoUdyyzrrRdZXHIEutr5eXlkZubi7+/f+mxlJQUFixYQHZ2Nv3796d169ZlDlAQhJpB2eYx8ihg+J4Pcb5i5oFvnmDC3ZGMaBZwxyzAglCTNfR1Yc59zVh5OIVPfjvL/Qv20yzQlf53+dEtyguDpuQlVJZlzmcVceBCFsdS8hjRPIAWd1iyanMNIj/2VfJbT8LpxI/oDs4pzSj/d0X1+5Ef+5pYji3YlV6vJzMzA52u5n3gKQhVbcupdKasT6BdqDuv9WqAQpIIdtcxpV9DHmgdxGfbEvlq57nS6yVKthzsEe3D47Gh4v1SDVPmGeQXXniBkydPsnTpUgCKioqIi4sr3etOpVIxf/58mjdvXnnRVhLxSWPVEW1XMY5sP92BmTj//hb7tW25L/txogK8eKdfQ3zKm8jIQcQMsujrKiKnyMzSg5f5+fBlkjIL0akVdIn0wmyVOXAhm7R8U+m1oR46lj8Ri6nAdJsS/0a2ochNRrKZwGoGmwXJZkJzbjP6fZ+CpKCg5VMUNH8ElDXj/1xFiOdexZS1/Z599gkCA4N4770pVRBV1RF9XdWq7e0XfzGbJ348RH0vA58Pb4Jec/PkXAUmK+czC0nKLCApo5BjKbn8diaDjuEevNU3uvRD1WvV9rarbJX13u7Oc/9XHThwgM6dO5c+XrNmDcnJyXz00Uf88ssvBAUFMXv27DIHKAhCzVLY/DFy73mH5sW72ez3Gcmp6by08hgWW52/S0OoA1yd1IxtE8wP41ox575m9Ir2YcupdOIvZtMy2I0Xe0Tyw4Ot+GxYY5IyCpmy5nj5KpAU2FyDsBrDsXpGYfW+C4tvcwpaP0vGqM2YQjpj2PUe7gu7oUncCOLuKMEOHnvsSTZuXM+yZcscHYogVEtJGQVMWnYEXxctHw2+65aDYwC9RkmUrzM9o32Y0KEeHw5uxP91j2DH2QwmLIonJbe4CiMXKqLMS6xTU1MJCPhredeWLVuIiYmhd++SvfSGDh3K/Pnz7R+hIAjVRlGjMchqHX4bJ7HG/QO6JT/J7B1GHo8NdXRoglAlJEmiSYArTQJcealHZOmxP4V66nmgTTDf7D5Pc38XX6GW6AAAIABJREFUujXwrnCdNtdgcvrMRn1uC86/vYbbqrGYQu4hr8NrWD2jKly+UHfNnPkJbm5uvPjii0ydOpXg4OAbllxLksScOXMcFKEgONa0zWeQZfhkaGPc9eXPVj20aQABbk68+PMxxn13gA8H3UW0b+1boVbblHkGWalUYjL9tVxsz549tGnTpvSxu7s7mZmZ9o1OEIRqpzhqGDm9ZuKVd4zVru/y885D7Dkn/u8LdY8kSTfNbP1Yh3o0CXTj7XUJXM4pslt95pB7yBy5nryOb6BK+QP3xT1x3vIyUmGG3eoQ6pbExLOYTCZ8fHxQKpUkJydz+vTpG74EoS7aey6L7WczGNc2mAA3p39cTvtQD74c2QylJDFhUTw7E0WfXd2VeYAcEhLCpk2bAPjtt9/IyMigXbt2pecvX76Mm5ub/SMUBKHaMdWPI7vvXAKsF1mi+y+frdpGZnnutxSEWkylVPDhiKZYbTKvrTlRureyXSg1FDYdT8bo3yhqdD9ORxbgsaAjuj9mgVUs3xPKZ+nS1fz00yq2bNlyy6/Nmzc7OkxBqHI2WWb61jP4uWgZ0TywwuVFeBuYO7o5gUYnXl9zguxCsx2iFCpLmQfII0eOZPv27XTs2JEnnngCf39/OnToUHr+wIEDREREVEqQgiBUP+aQzmQP+I4AZQ6zra8wc+VGbLXgvsijRw+zYsXS645t2LCB/v37c/fdd/Phhx86KDKhJqnnoeeF7hEcuJDN3F3n7vwL5STrPMjr9DaZ967D4tcc5+1v4vHtPWhP/Ag2q93rEwRBqEs2nEjlWEoej8WGlmm7prLwMmj4T59osgvNTN96xi5lCpWjzP/iI0aM4LXXXiMqKoouXbrwxRdfoNGUrMXPzMzk4sWL9OjRo9ICFQSh+rEEtCF3yI8Y1TZevDKZDVt/dXRIFTZ37my2bdta+jg5OZnJkyeTmpqKi4sLs2fPZsmSJQ6MUKgp4mJ86d3Qhy93JDHr90T2nsuiwGTfwavVM4rs/t+SNeA7bE7uuG54Bvfve6NO+lUk8hIEQfgHTBYbn21LJNLbQO+GPnYtO8rHmdGtglhxOIW957LsWrZgP2VO0gUwatQoRo0adcNxd3d31q5da7egBEGoOSzejbANX4ri++H0P/QYv+Y9T5NuY3F2Ujs6tH/k1KkEhg4dUfp41apVyLLM8uXL8fX1Zfz48Xz//fcMHTrUgVEKNcUL3SK4nFPE7B3ngHMoJYj0dqZJgCtDmvpT38tgl3rMwZ3ICuqI9tTPGHb+D+PKMRSH9iS3y/+Q9V52qUOonZKTLzJr1hIOHjxIdnY2N9v985dffnFAZILgGEsOXiI5u4jpQxtVyv7FE9rXY1NCGlPWn6RjQ1+7ly9U3D9aM5Camsrx48cpKBD7dgmCADaPCPKGLSVNE8TAxDe4MGcIy37bTaG55i31zM7OxsPDs/Txtm3baN26Nb6+JS9iXbt2JTEx0UHRCTWNs1bF7JHN2PCv9nw0pBFj24bg4qTi5yOXmbAonqOXc+1XmaSgOHIgGaN+Ja/DK2jOb8FjUXc0Z9fbrw6hVjlz5jQPPTSahQsXkpeXR2JiIkqlkpycHJKSkrBarXh6et65IEGoJfKKLczZkUSbECPt6rlXSh1OaiUvdo/kfFYRn20WSfCqo3INkHfs2EH//v3p1KkTgwcPJj4+HoD09HQGDhzIxo0bKyVIQRCqP71XKC7j15PQ5EVaS8cYHX8fP8x+jUX7kmrUXskuLs5kZKQDYDKZiI+Pp1WrVqXnJUmiuFgkQxLKx02nJjbMg8djQ5kxvAmLH2yFi5OKJ348yOFLOfatTKmhsPljZA5fhU3vg9vqcTj/+jyY8u1bj1DjzZkzE6VSybJly0q36nz11VfZsWMHr732Gvn5+fz3v/91cJSCUHW+2X2e7CILT3YKu+kuBfbSpp47/e7y5cttZ0lIzau0eoR/pswD5P379zNhwgRkWeahhx66bgmOp6cnbm5urFy5slKCFAShhlAoMd79BPn3b6bAry2T5W/o9PsYXp6/itNpNePNeUREFCtXLufw4cN89tlnFBcX07Fjx9LzFy5cEDMqQoX5uzrxxYgmGHVqJv54iIPJdh4kA1bPaDKH/0xBi3/hdHQhHot7orq01+71CDVXfPwfDBgwhIiIiBsGA6NGjSI2NpapU6c6KDpBqFq7kjJZuP8ivaK9q2Sv4qfvCcdVp+atdQn23e1AqLAyD5A//fRTwsLCWLp0KQ8//PAN51u1asXhw4ftGpwgCDWTzTUIeei35PScQbQmjY/zJjH321l8s/t8tZ9NfvDBh0lPT2P48OF88cUXdOjQgcaNG5ee37x5M02bNnVghEJt4efqxMwRTfE0aHjyx0PsSMzgfGYhp9LyOXI5lwMXsjmfWVixSpRa8tu/RPbgH0G2YVw6BMOOKWJLKAGAgoJ8AgODAFCr1VeP/XX7XMuWLdm/f79DYhOEqpKeb+KVVceY+OMhfJw1TLw7rErqNerUvBIXzdHLuczfc75K6hTKpsxJuuLj45k4cSJqtfqmSw78/f1JTU21a3CCINRgkkRx5ADMvs0xrJ7AF+kf8OmOUzxychyv9okhzFPv6AhvqnHjpsyZs4CjRw/g4uJCXFxc6bnMzExiY2NFxn7BbnxdtMwc0YTHvj/IU0tu/JBZKcGHgxvRIcyjQvWYA9qSOXI9hu1vot8/A03iRnK7f4zFu1GFyhVqNnd3DzIzMwBwdnZGp9ORlJRUej43NxeLxeKo8AShUtlkmaUHL/Hpb2cpttgY3y6EB9uG2G1bp7Lo19if1fGX+Hx7Ig19XWgbWjn3PQvlU+YBssViwcnJ6Zbns7KyUCqVdglKEITaw+YaTO6wZchbX2XisYW0zD7Dk/MnMrhdIx5oHYxaWXUvRGUVElKPli1vHDi4u7vz0ksvOSAioTbzdtYyZ2Qztp5JR6WQ0KoUaJQKNCoF07ec4aWVx5g9simR3s4VqkfWOJPX5X+Ywnrh/OvzGH/sR0GrZyho8QQoa2bWeaFiIiIiOX78aOnjVq1aMX/+fJo1a4bNZuO7774jKirKgREKQuXILjTz7NIjHLqUQ6tgN17oHkmoR9V/cC9JEq/2asDZjHxeXnWMb+5vTqCbrsrjEK5X5nemYWFhHDhw4Jbnt27dSoMGDewSlCAItYzKibyu75PbZSptFSdYr30B/a73efabX4i/mO3o6ATB4Yx6NQMa+REX40u3Bt7cXd+TtvXcmTa4EQaNkmd+Okxqnn2WRZtCu5F53waK6/fFsHsqrmvGg6XILmULNUu3br3IyEinqKjk3//pp58mKyuL0aNHM2bMGLKysnj22WcdHKUg2JdNlnlj7QmOpeTyRu8oZgxv4pDB8Z/0GiXvD7gLmwzPLz9KUQ3cAaS2KfMM8qBBg5g6dSqdO3emffv2QMmnHhaLhenTp7N3716R6VAQhNsqihmJ2bsxhl3/48mk5TxRuIJflzRlWfBwuvW6Fxe91tEhAnDx4gU+//wH4uPjycnJwWazXXdekiQ2bNjgoOiEusTHRcuHgxsxYdEfTFp6hFkjm6JTV3y1luzkTm7PzzAHtMN5y0u4rRxLdtxXoLHPvsxC9WUymdBoNAD07Nmbnj17l64QbNSoEStXrmTdunUoFAo6d+5MvXr1HBmuINjdt3svsO1MBs91qU/fu6rHPsTB7jr+GxfNs0sP8/b6BN7sE1WpWbSF21O+8cYbb5TlwiZNmnD06FFmzpzJ8uXLKSwsZPfu3UyfPp1du3bRp08fJk2aVMnhVg6bTaaoyFzm652c1OW6XviLaLuKqQ3tJxt8KG4wmKLoEZiVTgSl/0aH7JUU/rGQwmITWr9oUN36do5/qqxtd/r0KR55ZCyHDh3C1dWVs2fP4ufnR15eHikpKbi7u+Pn58eQIUPsHmNlE31d1bFn23kZNER6G1i4/yKn0gro3sAbhZ3eOFl8mmJ1q4fu4JdoLu6guH4cqBz/QZV47lXM7dqvX78epKRcxsPDEy8vbwAMhr/+zV1dXWnevDnNmjXDaDRWSbz2Jvq6qlWT2i/+YjavrT5Ol0gvnr4n3OGD0GvbLsRdh1IhsWj/RVyc1DT2d3VobDVBeZ971/Z1t1PmAbIkSfTt25egoCDS09Mxm83IskxUVBQTJ07kmWeeKXNw1Y3oSKuOaLuKqU3tJ2tdsQV3xNp8PGeVYWRdPE5MyjI08XNRFVzB6haK7GS/ZBVlbbv3359CWloqP/74IyNHjmTOnDl88MEHvP766/j4+LB582amT5+Oh0fFkiY5gujrqo692y7EXY+bk5qF+y+SUWCmfZiH3QbJVq8YLB4N0B2ci+bcZorD40Dt2HvgxHOvYm7XfsuXL2Hv3t2sXLmMLVt+xWIxExlZ/7Z5Zmoa0ddVrZrSflmFZp744SBuOjUfD2mEVuX43El/b7umga6cSs3n+wMXaR1ixM+19vy/rAyVNUCW5Gs3NP6b5ORkPDw8alWneTNms5WsrII7X3iV0agv1/XCX0TbVUxtbr/UvGJmLFlB5+ylDFLtQClbKI4aSu4979jlzXpZ265fv+707z+YV175PzIzM2nfvj1z584tvbXk+eefJycnh5kzZ1Y4pqom+rqqU1lt98nWs8zbc57mQW5M6RuNl7P9Zns1iRtxXfsIVrdQsvvNx+YSYLeyy0s89yrmTu23b98eVq9ewZYtv1JcXIxGo6Fbt24MHTr0un3fayrR11WtmtB+Nllm0tIj7D6XyVf3NauSfY7L4mZtl1dsYdS8feg1Shbc3wJVNUxmWl2U97nn7V22f/fbtni3bt1Yv359mSsVBEH4p7ydtbwwaghrw16lfeHHrDfei/bEEow/DUaRe7HK4igoKLjtvqAtWrQQ+4IKDvNkpzD+0yeKY5dzGT1/P/vOZ9mtbFNoN7L7zUORexH3H/qiurzPbmUL1UvLlq159dX/smLFLzz33Is0bNiQNWvWMGHCBLp06cL06dO5cOGCo8MUBLtZsOcC289m8Gzn+tVmcHwrzloVkzrX53RaAd//kezocOqk2w6QbzO5LAiCYHdOaiVv94tmYLsmPHJ5AC85vYycmYjx+zjUyTurJAZ3dw8yMtKBv/YFTUxMLD2fk5OD1SoyTAqOExfjy9ejm+OiVfGvHw7y9a5z2Oz0em0OiiVr2ApktR7jshFoT/xol3KF6kmvNzBw4BAWL17M6tWrGTduHGazmRkzZtCzZ0/Gjh3Lzz//7OgwBaFCUnKLmfl7Il0jvRjW1N/R4ZTJPRGetA91Z9bvSaTZaQcDoezEnL0gCNWKQpJ4NDaU9wfEsEPRkt4Fb3CxWIvrsntRH/ym0uuPjGzA8ePHSh+3adOGefPmsWfPHnbt2sWCBQuIjo6u9DgE4Xbqexn45v7mdG/gzWfbEnnx52NYrLY7/2IZWD0akDl8JWa/lrhueAbDjilgEx8K1Xbh4eE8//zzbN26lZkzZxIbG8uuXbt44YUXHB2aIFTIvN3nsclUi6RcZSVJEs91jcBktTF961lHh1PniAGyIAjVUudILxaNbcUj/brxjPNUNlsaY/ztZYq+6Ytp+0co045CJaxy6dGjN9nZWdftC5qbm8sDDzzAgw8+SG5urtgXVKgWDBoVb/WN5qlOYWxKSOPt9Ql2W/klO7mT3f9bChs9gH7/DFzXPIxkyrVL2UL1dvDgQTZt2sSBAweAv241EYSa6EpuMUsPXaLfXb4EuNWsnEoh7jrGtA5mzbEr7L9gv9tphDu74z7Ie/fuLddywkGDBlUoIEEQhD8pFRLdGnjTNdKL38825Jst02mds4mYP6bCH1PJU3thDu4ETe/HEtDGLnV269aTbt16liYnjImJYdWqVaxfvx6lUkmnTp0IDg62S12CUFGSJDGmdTBFZhuzdiThoVfzZKdw+xSuVJN3zxQsHlE4//Yaxh/7kxP3FVajncoXqo20tDSWLVvGTz/9xNmzZ5FlmYYNGzJs2DD69+/v6PAE4R+bt6dk9nhc25r5uj2uTTBrjqbwv42nRMKuKnTbLNbR0dFlXoogyzKSJHHs2LE7X1zNiGyHVUe0XcWI9oNLOUXsOHSUvBMbiczbTSfFQYxSPikebVB1/De24PY3/b3KynRYk4i+rupUddvJssz/Np7ix/hLPHNPOKNbBdm1fPXF33Fd+xjYLOT2/BRTva52Lf/vxHOvYsrSfhaLhe3bt7Jq1c/s2bMTi8WCq6sr/fr1Y9iwYcTExFRRtPYn+rqqVV3bLzWvmEFf7qZPQ19e6dXA0eHcVFnabnNCGv9ecZRnO4czqqV9+/aarrLe291xBnnEiBE0a9aszBULgiBUJn9XJ4bEtoDYFpzPLGT20XOoDi7g/vSf8FwxnLPOLZA7PIdLxN1QQ+41EoSK+vN+tcxCMx9tOYO7Xk1cjK/dyjcHdiBz+Cpc14zHdeVY8tu9QGGLJ8T/sRro1KkEVq9ewbp1a8nJyQagbdu2DBs2jJ49e6LRaBwcoSDYx7w9F7DaZB6sobPHf7onwpMOYSUJu7pEeuEv9kaudHccILdq1UosrxEEoVoKdtfxYGwU1vZvsv3Uo+Tumkuv7MX4rBtFxgYPMr1a49agM4p6seB2103LmDLlP0iSxPPPv4xSqWTKlP8AJZvP34okSUyZMqVS/iZB+KeUCok3+0STXXSYN385idlqo38jPxR2GsTaXIPJGrIMl02Tcd75Luor8eTFvorNNcQu5QtVY9y4UQD4+PgyduzDxMX1p0mTKAdHJQj2lZZXzNKDl4iL8SXIqHN0OBUiSRL/7hrBmAX7mfjjIWaPbIqHXnyQVZnuOEAWBEGo7pQKidgGQdDgVZLTJ7Jz27c4JW+nWcouvK78Atsg3zkU6d6fkZ3cr/vdNWtWlsy+PfciSqWSNWtW3rE+MUAWqiuNSsH7A2KYtPQwb61LYEn8JSZ3qU/TQDf7VKDWkdvzMyzed2HY/SEeiespir6XglZPYXMJtE8dQqXq3Lkb/foNpE2bdjUmo68glNe8PRewWG081K52fIAXZNQxbVAjJi45xNNLDvP5iCY4a8UwrrKIlhUEoVYJ8HQnYOBEZPkJDifnsO/gPkxnf8M9K4WuJhWef1uZ9Ntve276uDbegyzUDc5aFTPvbcraY1f47LezjF8UT88obyZ2CrPP0jxJorDFExQ3GIJ+/6c4HVmI0/HvKYq5j4KWE7E5B1S8DqHS/Pe/7zo6BEGoVGn5Jn46eIk+tWD2+FrNgtx4r38Mk5cf4bnlR/h4SGO0KpG0qzKIAbIgCLWSJEk0DnSjcWBXLLYumJVKdLJ99okVhOpOIUnExfjSJdKLebvPM3/vBbacTuelHpF2uzfZ5uxPXqe3KWj+L/T7PsHp6EK0CcvJGvazyHQtCILDzN9zvmT2uG3tmD2+Vmy4B2/0juK11cd5aeUx3hsQg0ohVoLY220/djh+/Li4/1gQhBpPpZDwr2H7HwqCPejUSh6NDeXHca2I8XPh7XUnSUjNs2sdNpdA8jq/S+bIDSApcF09Hslk3zoEQRDK4lRaPt8fSCYuxpdg99oze3yt3g19eK5rBFtPp/PWupPcZkMi4R8S8/KCIAhASsplvv9+IUuX/khmZgYAly5dYvLkycTGxtKsWTPuv/9+9u7d6+BIBaH8/FydeLd/Q1yd1Ly08hiFZqvd67C61yen5+cos07hsmkSiDdtgiBUIatN5u11J3HWqnjKXvvBV1MjmgfwSPt6rDqSwrf7Ljo6nFpHDJAFQajzkpISGTt2JJ9+Oo0PP3yPsWPv4+zZs4wZM4ZVq1ZhMpmQJIm9e/cybtw4Dh8+7OiQBaHcPPQa3oyLIimjkPc3nqqUOszBHclv/zLa06vR7f+sUuoQBEG4mcUHLnL4Ui6Tu9THqL/1ThS1xfj2IXSO8OTTrWeIv5jt6HBqFTFAFgShzvv2228wm8089dQk3nzzHZydnXnqqacoKiri+++/Z8+ePRw4cIA5c+agUqmYNWuWo0MWhH+kdYg749qF8PORFNYcS6mUOgqbPUJR5EAMO99DnfRrpdQhCIJwrYvZhXy+LZHYMA96RXs7OpwqIUkSr/eOwt/NiZdWHiOjwOTokGoNMUAWBKHO++OP/fTvP5hhw0bSpUt3nnxyEgkJCYwbN44mTZqUXhcbG8uIESPYt2+fA6MVhIqZ0L4ezQNdeXf9Kc5lFtq/Akkit8v7WD2jcV0/EUV2ov3rEARBuEqWZd5Zn4BCkvi/7hF1avsyZ62Kd/vHkFVo5tVVx7HaxK0t9iAGyIIg1HlpaWlERESUPq5fv+Tna4/9KTIykqysrCqLTRDsTaWQeDMuGrVS4qWVxzBZKiG7u1pPdp8vATCuGIUq5YD96xAEQQBWHU1hV1IWEzuF4WePrexqmCgfZ/7dNYLd57KYszPJ0eHUCmKALAhCnWc2m9Bo/npR1Wq1AGg0mhuu1Wg02GxiuyihZvNzdeLVXlGcuJLHxB8Pcr4SZpJtbvXI7jcfbFaMPw1Gt+9TsNk/OZggCHVXer6JaZvP0CzQlaFN/R0djsMMbOxH3xgfvtxxjp2JGY4Op8YTA2RBEARBqIPuifDkP32iSEjL5755+1i0/yI2O2eetvi1IHPkOorD++C8813cVoxEkZds1zoEQai7pm0+TaHZyss9GqCoQ0ur/06SJF7oHkmYp55XV58gNa/Y0SHVaCpHByAIglAd7Ny5nYyMNACKioqQJIm1a9dy/Pjx664TGayF2iQuxpdWwUamrE/gg19Ps+lkKq/2irLr/qGy1o3cnjMwhXTBZesruC/qQU6vzzEHd7JbHYIg1D1pecWsP5HK6JZBhHrqHR2Ow+nUSt7rH8OYBft5bc0JPh3aGKWi7n5oUBFigCwIggCsX7+W9evXXnds8eLFN722LiUAEWo/Hxct0wbfxaqjKXzw62num7eP0S0DGdM6GGetnd4mSBLFDUdg8W+F65oJuK55hKzhq7C617dP+YIg1Dlrj6dik2FAYz9Hh1JthHrqea5rfd5al8D8Ped5sG2Io0OqkcQAWRCEOm/69Jk3HDMaxafRQt0hSRL97vKjTYg7H285w1e7zrMk/hIPtQthWNMANCr73JFlNYaT3W8e7t/3wXXNBLKGrUDWONulbEEQ6pbVR1No5O9CqId4vb7WgEZ+7EzMYub2RFoGG2kc4OrokGocMUAWBKHOa9685Q3HvL1dHBCJIDiWj4uWt/s1ZEzrID797SzTNp9h4b6LPN4xlD4NfeyyesLmEkhOr89xW3EfLpsmk9NrJohVGYIglMPJK3kkpObzfLcbd5uo6yRJ4qUekRy5nMMrq47x7QMt7bcaqI4QSboEQRAEQbhOtK8Lnw5rwqfDGuOuV/P6mhPM3XXebuWbg2LJb/8S2tOr0B24cQWHIAjC7aw6moJKIdEjytvRoVRLLk4q/hsXTUpuMVPWJyDbOQFjbScGyIIgCIIg3FTbeu58Pbo5cTE+fL49kZ8OXrJb2YXNHqWofj8MO99BfX6b3coVBKF2s9hk1h67QsdwD4w6taPDqbaaBrrxSIdQ1p9IZcXhy44Op0YRA2RBEARBEG5JIUm82rMBsWEevLchgU0JafYpWJLI7foBVmMEruv+hTLrjH3KFQShVtuVlElGgZm+Mb6ODqXaG9smmFbBbryzPkEMkstBDJAFQRAEQbgtlVLBu/0bcpefK6+sOsbec1n2KVhjICfuS5CtuC/qgeH3t5GKs+1TtiAItdLqIym4OamIDfdwdCjVnlIh8f7Au2gVYuS/v5xk9o4ksdy6DMQAWRAEQRCEO3JSK5k2+C6CjDqeW36EEyl5dinXagwn8971FEcOQHdgJh4LOqLY8wVYTXYpXxCE2iOv2MKW0+n0jPZBrRTDmLJw1qqYNrgRfWN8mPV7ElPWJ2CxiUHy7YhnliAIgiAIZeKmU/PJ0Ma4aFU89dMhkrOL7FKuzSWA3G7TyBqxBotnDMp1L+K+sCvK9ON2KV8QhNph48lUii02+sb4ODqUGkWtVPB67yjGtQ1m2aHL/Hv5EQrNVkeHVW2JAbIgCIIgCGXm66Llk6GNMVtlnl16mLxii93Ktng3InvgIiz3LkYyF+C6ZrxYci0IQqlVR68Q6qEjxk9sxVhekiTxr45h/F/3CH4/m8GoeftYdSRFzCbfhEM3xbLZbMybN49FixZx8eJFPDw86NOnD0899RR6/Z03/Y6Kirrpcb1ez4EDB+wdriAIwj8m+juhNgn11PPegIY8ueQwL/58jGlDGqFS2GkvY0lCjuhBbu8vMC4bjsvGSeT0mQ2S+Ey/JhB9nVBZLmYXcuBCNv/qGGqXPdlrOkXeJVRX4jGF3AMqXZl/b2jTAIKMOj7ecoY31p7gq13neLhdCD2jfezXj9dwDh0gT5kyhfnz59OjRw8eeughTp8+zfz58zl69Chff/01CsWdXwxbtWrFiBEjrjumVouU74IgVC+ivxNqm9Yh7rzYPYK31iUwddMpXugWYdc3rRb/1uR3eAXnbW+g2z+DwpYT7Va2UHlEXydUlhWHU5CAPg1r9/JqRXYShj3TsLhHUBw9HJvh+mzdUlEm+n2fojv0NZK1GKvBl4KWT1IUcx8otWWqo209dxaMacGWU+nM3pHE62tOMGfnOf7dtT7tQkXyM4cNkBMSEliwYAE9e/bkk08+KT0eFBTEW2+9xapVq+jfv/8dywkODmbgwIGVGaogCEKFiP5OqK0GNvbnXGYR8/acJ8Rdx6iWQXYtv7DJw6gu78ew639YfJphDu5o1/IF+xJ9nVBZ0vJNLNx3gc6RXvi5Ojk6nEqjPrcZ13VPIFmKcLIWY9j1PqbQ7hTF3IfZvw26Q3PRHZiJZMqjOGoIxeG90f3xJS5bX0G//3MKWj1FUfQIUN75AyWFJNEl0ot7IjzZciqdz7cl8sxPh3mpZwNZ1zYIAAAgAElEQVQGNPKrgr+2+nLYeqWVK1ciyzJjx4697viIESPQ6XSsWLGizGWZTCby8/PtHaIgCIJdiP5OqM2euDuUrpFefLT5DFtO2WmP5D9JErld3i/dK1mRm2zf8gW7En2dUFlm/Z6IySoz8e4wR4dSOWQZ3b5Pcft5DDZnfzLu20jG6K0UNnsE9eX9uK16EM85jTDseh9zYAcyR64nt/vHmML7kD34R7IGfIfN4IPL5hfw/KoJHvPa4f5dF4zfx+H201Bc1j2B0+F5KDMS4G/bPP05UJ47ulnpdlBzd52r09tBOWwG+fDhwygUCpo0aXLdca1WS3R0NIcOHSpTOb/88gsrVqzAarXi4eFBXFwczzzzDC4u4uZ9QRCqB9HfCbWZQpL4T58oLucW88KKowxpGsAj7eth1NtpSazGQE6fWRh/6IvrL4+S3W8+spPRPmULdiX6OqEynE7LZ/mhywxvFkCIe9nvta0xTPm4bpqE9vQqiiIHktvlfVCX3K+f3+Fl8ts+jyZpI+qLv1McORCLX8vrf1+SMAd3IivobjRJG9EkbUIyFyBZCsFSiGQuQJ28E6eE5QDYdF6YAtpRHDUUU1iP0mIMmpLtoP6z9gQztiWSlmdiUpf6KOvgfckOGyBfuXIFd3d3NBrNDed8fX05cOAAJpPppuf/1KRJE3r37k29evXIy8tjy5YtLFiwgN27d7No0SIMBkNl/gmCIAhlIvo7obZzUiuZPqQRM7cn8lN8MmuOpfBwu3qMaBaARlXxxWpW9whyu32I69rH8JjXlqKY0RQ2G4/NOcAO0Qv2Ivo6oTJ8svUseo2S8e3rOToU+5FtqK4cRBG/GY+DP6DIPU9eh1cpbPYI/D2Xg1KNKbw3pvDety9TkjCFdscU2v0m9ckoshPRJO9AfXEn6ou/43R6JUUNBpN3939LP3RUKxW8GReNl0HLt/sukF5g4tVeDTBoHJq2qso57K8tLCy8ZQep1ZbcYF5UVHTbTvSHH3647vGgQYOIiopi2rRpzJs3j8cff7xMsSiVEkbjnTMr/nW9olzXC38RbVcxov3+OUe2XXXp70RfV3XqYtsZjfDOsKY81Kk+7/1ygo+3nOGng5d4tW9DukSVL6nOTduv5XAsQQ1R7piO7uAcdIe+Qm40HGu7J8E72o5/Sc3nqOef6Ovqpspsv+2n09h+NoMXekUR6u9WKXVUJenCLhTxC5FOrUPKu4wsKZCD2mDt9xHasHsoW4qtf8j9Lgi9CxiPzWqG36eh3TYVbfJOrP0+Rq7/18D6jUGN+P/27jw+qvre//jrzJaZ7AlZCPsaMIRNBQRRC4KsCnJ7tbZ63aq1rZfqrfd2ufbqrdZfF7tqe7V6ew2gVdRqcamKqKCICIqshiWsCZCQfZvMen5/oLGpBENmMkvm/Xw88kg4c87kOx/PvM1nzjnfMzA3hZ++spt1ZTVMG9aHmaPzmDk6L6auAe+pfc8wo3SC+aWXXkpNTQ3vvvvu5x77zne+wyuvvML27dtPG6Kn4vP5mDhxIsXFxTz55JNd3CZAfX1rl39HZmbyGa0vn1HtQqP6dd+Z1i43N3yn8sVK3inrIke1g/cO1vLrt/ZzoKaVO2aO4IqJXT/a+0X1szQewfXRH3F9/Gfwe2gruoqW876P6dLsqxC9vFPWJaaeql8gaHLNig9p8fhZef0kksJwNko02Ss2kLHqKkyrE++gL+EdOgvX2AXUe6N32ritahtpa27HVrsbd9HXaDn/R5iO1PbHdxxrZPXuE6wrq6G8vg2As/JT+fYFQ5kyOCtaw27XU1kXtT0tLy+Puro6vF7v5x6rrKzs9BSdL2K329ufW0QkFijvJBGdNySbkq9NZPqwbH7xxj4eXn8wbJO+BNMH0nLhPdT8y/u4x38d58dPkf34BTi3/R8E/WH5HXLmlHUSTi/vqmTviRa+fcHQuG+OLfUHSP/bTQQyhlB77Uaa5j6EZ9SXIblPVMflzxtH3T+/ROvEW3DueoLMp+djrd7V/nhxQTq3f2k4f7lhEk9ddw7fnj6EFm+AW5/Zzq/fKsPjD0Zx9D0nantbcXExwWCQbdu2dVju8XgoLS2luLi4W8/r8XiorKykT5/o7nAiIp9S3kmictqt/HzRGBaOyefR9w7zszX7CATDd+Ka6cqmZfpd1H1lNf7csaS9/SOyVs7DfnRj2H6HdJ2yTsKlzRfgf9YfZEzfNGaPyo32cEJieBrIePl6MAwaFjyGmRRjp4rbnLRMu5OGxSsxvC1kPXMpzl1PdJjt2jAMhvVJ4bopg3j8mrO5YkI/nviggmsf/5A9Vc1RHHzPiFqDPH/+fAzDoKSkpMPylStX4na7O9wn7/Dhw5SVlXVYr7NPEX/zm9/g9/uZMWNG+ActItINyjtJZDaLwX/NKeRfJg3g2a3H+M+XPsYb5qMOgexCGi77Mw1zHsLwNJLx3JdJ3vQbMHvn0Y1YpayTcFm+qZwTzV5uu2gYxj9OWhVPgn7SX/0m1oZDNM57hGDGkGiPqFO+/lOpu/JVfAWTSXvzP0hbcxv4Pn/6stNu5d8vHsFvlhRT7/Zz3RNbWLG5vFfdFipqk3SNGjWKr33ta6xYsYJbb72Viy66iLKyMpYvX87kyZM7hOh1111HRUUFu3fvbl/2P//zP2zdupUpU6ZQUFBAa2sra9euZePGjYwfP55rrrkmGi9LRORzlHeS6AzD4F8vHEZWsoPfrt3Pewc3cFZ+KmMK0inum0ZxQRo5qSFOT2MYeEcspHbwTNLe+j4p79+PrWorTbN+E3tHbHopZZ2Ew8GaVv7v/cPMHpXLhAHx/d5NffsuHEfW0TTjfnz9zov2cL6QmZxDw6UrSP7gdyS//ytsVdtoPefb+AqmEEwb0GGG7fOHZvPkv5zDT1bv4bdr93OwtpUfzBrZK24LFdU5u3/4wx/Sv39/nnrqKd566y2ysrK4+uqrWbp0KRbL6Q9uT548mbKyMp577jnq6+uxWq0MHjyY22+/neuvv759tkQRkVigvBOBq88dwIicZNbuq2Hn8SZWbC5vP+V6QVEe3581EqfdGtovsSfTNOu3+PInkrr+v8l8egGN8x4l0EczXUeCsk5CETRN7lu9B6fNyndnDI/2cELi2voorh0ltE74Bm1FX4n2cLrOYqV10u0njyS//h3SX78NgEBqAb6Cyfj6nYdn5GWYSRlkJtv5+WVFPPTuIf703mHafAHunjsKmzW+rxmP2izWsUSzHUaOahca1a/7ojmLdaxQ1kWOatc1bb4Au6uaWbuvhhWbyxmRm8LPLyuieEifsNTPdvR90l+9BYu3idbxX8cIeLG4q7G4qzFaa/AXnEvz+f8F1jOfOCqWJXreKesiK5z1+8u2Y/y/1Xu585KRLBpbEJbnjDjTJPmDB0nZ+DM8Q+fQOPePYDn1B38xv++ZQaw1pdiPvY/96EbsR9/H2lpJ0JGOe9wNuMd/vf0eyiXvH+HBtw9w0fA+3LfwLBwRmFitp7LOevfdd9/dzTH1GsGgSVubr8vrO532M1pfPqPahUb1674zrV1KSu87UqGsixzVrmtsVgt9051MGZJFUUEaL+6s5PntxxndN42+KaE3rcG0/ngKF2M7thnXnr9gO7EDS1sdGBZMRxrOfS9gP7YZ79A5YOs97/lEzztlXWSFq37VzR7u+OtOxvZL57szhsfntcdmkJS37yLlwwdpK7ycptm/A6u909Vjft8zDMzkXPz5E/COWIh7ws14h16CtfkYrp0rcO5cjuF3488pYvzgfDJddp74sIJdx5uYOTKnx48k91TWRfUUaxERERE4eT1bydcm8h+rdnHTig+4aepgrp8yCFuI17MFU/JpuPwZ8LvB5upwDV1S6TOkvXkHmX+5nIaFywmmdf1ezSISXve/WYbXH+SHswvjszkOeEh7/Xac+1bROv4mWs7/ERjxfarx5xgG/tyxNM57BGv1LlI2/5aUzb/FtfV/aZ38b1wx7npcdgv3vraHbz+znbvnjmJgVvTu89xdvey/moiIiMSrAZku/nTVBC4b148/vnuI+Q+9xy/W7GPb0cbQZkg1DLAnd2iOATyjv0zDwhVYmo+S+eylWE/sDPEViEh3rN1Xw5o91Xx96mAGxWFDZXibyXjxOpz7VtE89Ye0nP9fva85/geBnCIa5z5M7VdW4+s3mdT1PyZr5VyWZB/iJwvOYt+JFq4s2cwD6w7Q4o2v+9PrFGt0Kk4kqXahUf26L9FPOQRlXSSpdt1ns1q4dGJ/hmQ4afb6ea20iue2HeelXVXUtXoJBiHDaScpTNe3BTMG4R1yMc69z+PasQysTsykDExn1uca6niR6HmnrIusUOvX1Obn9ud2UJDu5O65o7DE2yzIZpD0v30dR/k7NM38JW3jrutydvSGfc9MzsUzcjH+nDEkHXiN5G2PMtJew9xZC6j22nhm6zFe3FlJdrKd4TkpYT07oKeyTpN0ockcIkm1C43q132JPmkNKOsiSbULzd/Xr9nj58291bxaWsWmw/V8Muk1g7NcjClIY3z/DOaMziXFEdpVY5bmY6S/cjP2yi0ABFL74R1wAb6BF+DrezbBtIFx0zAnet4p6yKru/UzTZPVu0/wm7X7qW3x8uhVEyguSO+BEfYs10d/JHX9j2m68F7axl53Rtv2un3P10rK5t/h+uhhMCz488ZxLLmIJ47l8VJdP1Jzh3H1pIFhuz65p7JODTIK0khS7UKj+nVfov/BCMq6SFLtQtNZ/Zra/OyqbGLnsSZ2Hm9ix7FGalt9pDttfGVif66Y2I8MV+cT4nSFpeEgjiPv4Chfh718PRZPAwBBRxqBPmfhzzkLf84YPENmYybnhvS7ekqi552yLrK6U78DNa38/I19bD5cz6i8VL538QjG9ou/5thWtY3MZxfhHTyTxnmPnvGHaL1137PWleHcuRx75UfYTmzHCHgAOE4Oj/jmsMY5l4Vnj2Dx2L4hZbYa5B6kII0c1S40ql/3JfofjKCsiyTVLjRdrZ9pmuw83sRjG4+wtqwGl93CknH9uGJiP/qmJ2EJ9YhvMICtege2E9uxVX+MrWYX1uqPsfiaMS02vEMvwV30VXwDL4yp6w0TPe+UdZF1JvXz+oM8/O5BHv+ggmS7lW9NH8Ll4wqwxttp1Zy87jhz5VyMgIe6K187eVnGGUqIfS/gw1a7G1vlFpL2/hXH0fdoMVJY5pvJ48xn9LARFOalMCInhRG5KfRNS+ryadg9lXWaxVpERETikmEYFBekc//iMeyrbqHk/SP8+cNyHv+gHJvFIDfVQV5qErmpSQzt42L6sD6Mzk/teuNsseLPG48/b/xny8wg1to9OEufxlm6kqSylwmkDaTtrCvxDJtDIHt050eRTBPMYKf3RBXp7R597xDLNpVzWXE+t14wlKzk+L0HeeraH2JtPEzD4qe71RwnDKsdf24x/txi2oqvwVb5Ea4tD3HL/pe4iVdYc+Q8/rLvHP4vOA43TlIcVsYWpDN9WDbTh2fTPyPyk7bpCDL6pDGSVLvQqH7dl+hHVEBZF0mqXWhCqV95vZv1+2upavZQ1ezlRLOHE81eyuvdBE3ITXVw4fA+XDC8D3mpDo42tFHR0Nb+3WW3MiTbxeCsZAZnuxiUlUyyo5OGNuAhaf+rOHc+jqNi/clFKfl4B34J36Av4c8dg7V2z8kj0FXbsJ/YjuFpxJ83Dl/fcz75OhczJa+7pTqlRM87ZV1kdbV+VU0elvxpE18a0Yd7F5wVgZH1nKTSZ0hfcxstk/6N1sn/1u3nSeR9z9JwkOStj5C0569YPPUELEkczpzCRsdUHq8vYnv9yVOvh/ZJZvrQbM4bksW4fuk47Z/lsU6x7kEK0shR7UKj+nVfov/BCMq6SFLtQtMT9atv9bH+QC3rymrYcLAWty/Y4fEUh5WCdCetvgDHGtr4+z+Ozhucxb9MHsC5AzM7PfXP0nwM+5F1OA6/hePIuvZrlwFMw0ogeyT+3HEEkzKxV23BVrWt/bo8f9ZIPCMX0Va4mGDGkJBfa6LnnbIusrpav3tf3cPLH1fy9PXnRuWoYLhYa/eQ9fRCfHljaVi0MqQzQrTvAUE/9qMbcex/haQDr2JtPoqJQWt2MTtd5/BCSxFPVxXQFrTisBqM7ZfOuQMzmTQokwuL+tLQ4O7yr1KDfAYUpJGj2oVG9eu+RP+DEZR1kaTahaan6+fxB/mwvJ5mT4B+GU76ZzjJcNram1+PP8iRejeHalvZU9XM89uPU9vqo6hvGtdOGsBFI3JOf81k0I+taiu22t34s0fh71OE3+pka0UDRxvamNA/gwFpBvbqndiPbcZxcDWOo+8B4MufSFvh5fhzijECbRj+Ngy/G/wegmn98eeNx3Sknvb1JXreKesiqyv1K6tu4avLPuArZ/fn9i8Nj9DIws9esYH0v30dLHbqrniZYGq/kJ5P+94/ME1sJ7bhOPQmjiNrsR3/EMMMELSnUZcynIpgFnvb0tnVksYRM5crvnoT4/O7PrmbGuQzoCCNHNUuNKpf9yX6H4ygrIsk1S40sVY/jz/ISzuPs3xzOeX1bQzKcjFtaDZn5adS1DeNQVmuU17X7PUH2XSknjf3VLO2rIZ692f368xLdTBpUCbnDsqkMDeVDF8VuUdeIuvAKhy1H3c6FtOwEMguxJd/Dr6+ZxPILiSQMRTTmdm+TqLnnbIusrpSv9uf28FHFQ08d+NkMkOcaT5aknY/S9obdxDIGEzDwmUE0weF/Jza907P8DRgL1+P48g6rPUHsDQfxdpyDMPfBkDr4mW09J/Z5efTJF0iIiIiYZBks7BkfD8WjS3gzb3VPLP1KM9vO8aT/pOnaacmWRmRk4IBeAImHn8Arz9ITYuPVl+AFIeV6cOymTEyh8HZyXxU3sAHR+pZf6COl3ZV/d1vGg+MZ4RRzkhnI9kZ6eRkpJOflUn/7HQGGsfJrd9G0oktJO17Adeux9u3DCZlEsgYgr/PaJj3EyApkiUS6dQHR+p5Z38tt14wND6bY9MkedOvSdn0K7z9p9E4948dPpCSnmMmZeAdPh/v8Pl/t9DE8NRjtNWTPrgIzuAU665SgywiIiLSBVaLwaxRucwalYs/aHKwppVdx5vYVdnE/uoWrBaDTIcVh9VBks1CutPOtKFZTB6UhcP22W2gRuSk8OUJ/QiaJmXVLRypc+P2BXH7Arh9Adp8g6ls8rCtppX9B1po2R0A6gEnFmMyOSnT6ZtqZ1yfExTaKhloHqNv4Bh9vBWkHN8ObQ1ghHfiL5HuME2TB9YdIC/VwZUTQzsdOSoCXtLe/A+cu5+hbfQ/0/Sln4E1fmfe7hUMA9OZdXLm8FBv5dcJNcgiIiIiZ8hmMRiRe/K+nZeN7dut57AYBiNzUxmZ2/k1xaZpcqLZy4GaVo42tlHZ5Gn/Wlffh+da0mjxDu2wzfPuLPond2tIImG1Zk81O4838aM5hR1mH44LPjcZr9yE4/BbtEy+g9Zzv9NjDZnEFjXIIiIiIjHKMAzy0pLIS+v8lOk2X4CaVi81LT68/iCj+6bT1Bj+0w5Fuso0TV4rPcHP1uxjeE4yC4ryoz2kM2J4m0h/6TrsR9+nacbPaSv6arSHJBGkBllEREQkjjntVvpnuNpvnXPaGbZFeli928fPXt/H63tOMLYgnR/PHxVX+6TRVkfGC1djO7GDptkP4ClcHO0hSYSpQRYRERERkZC9s7+Ge1/bS4Pbx7enD+GaSQPjqzluPUHmqquw1u2ncd4jeIdeEu0hSRSoQRYRERERkZD8+q0ynvigghE5KfxuSTGFeae/X3essTSWk/HCV7E2H6NhYQm+gRdEe0gSJWqQRURERESk2z4qb+CJDypYPLYv/z5zRIdZ2+OBtXoXGS9eg+FzU3/ZE/gLJkV7SBJF8bX3ioiIiIhIzDBNk9+/c4CcFAffnTE87ppje8W7ZD73T4BB/ZJn1RyLGmQREREREemedXur+aiikRvPGxR3t3JK2vsCGauuJphSQP0/rSLQ56xoD0ligBpkERERERE5Y0HT5Jer99A/w8mibt4PPFpcW/+XtNe+hT9/AvVLniWY1i/aQ5IYoQZZRERERETO2Jo91Xx8vImbpw3Gbo2ftiLp46dIfecuvMPmUH/Z45jOrGgPSWKIJukSEREREZEz4g+aPLT+IIV5qcwZnRft4XSZ7fgHpL31A7wDLqBxzkNgUTskHcXPRz0iIiIiIhITXtxxnMN1bm6fNTJu7nVsaakk/W83E0wtoHHOH9QcyympQRYRERERkS7z+IM8suEQYwvSuDhejh4HPKT/7SYs3iYa5j+q06qlU2qQRURERESky57depSqZi/fmj4Uw4iDo8emSera/8Re+SGNs36t2arltHRegYiIiIiInFZdq5e399eybl8NGw7WMnlQJucOyoz2sL6YaeLa+iiuj5+k5ZyleIcviPaIJMapQRYRERERkVN6eVclz287xtajjQRNyE9LYvHYAq6dPDDaQzs908Re/g4p79+P/fgHeIbMpnXKHdEelcQBNcgiIiIiItKBaZo8suEQj2w4zNA+ydwwZRAXjejDqLzUmD+t2n50I8kbf4Hj6HsEUgtouuintJ11BRi6ulS+mBpkERERERFpZ5omv1m7nyc+qGDhmHz+85JCbHEwU7XhbSZtzW0k7X+FQHIeTRf8mLair4LNGe2hSRxRgywiIiIiIgAEgiY/fX0vz28/zhUT+vHdmcOxxPgRYwBLUwUZL12LtXYvzed9H/e4G8HuivawJA6pQRYREREREXyBIP/9ym5eLT3BdZMH8q3pQ2L+dGoAW9VW0l+6HsPvpmHhMnyDLor2kCSOqUEWEREREUlwH5U3cN/qvRyobeVb04dw/ZRB0R5Slzj2/4301f9K0JVD/WV/JtBnVLSHJHFODbKIiIiISIJqbPPxwLoDPL/9OH3TkvjV4jFcMLxPtIf1hYy2elxbHyF58+/w50+gYf6fMJNzoz0s6QXUIIuIiIiIJBjTNHmt9AS/equMBrePq88dwM3TBuOyW6M9tNOy1u3Dte1POEufxvC7aRu5iKaZ94NN1xtLeKhBFhERERFJAMcb29h0uJ5Nh+t5/3A9NS1eivqm8bt/GsuovNRoD++0bFVbSdn4cxyH12JaHHgKF9M67kYCuWOiPTTpZdQgi4iIiIj0YhsP1vH7dw7wcWUzAFkuO5MGZXL+sGzmjM7DGsu3cDJNnDuXk/r2XZhJmbRMvgP3mKsxk3OiPTLppdQgi4iIiIj0QntPNPO7dQd472Ad/dKT+M5Fw5gyOJPhOSlxcesmfG7S1n4f5+5n8Q76Eo2zH8B0ZkV7VNLLqUEWEREREelFqpo8PLT+IC/urCTNaeO2i4bxzxP64bBZoj20LrPW7yf9lZux1uymZfJ3aT33O2DEz/glfqlBFhERERHpBQJBk6c/Osof3jmAP2jy1XMGcMN5A0l32qM9tK4LBkja/Qyp79wNhvXkfY0Hz4j2qCSBqEEWEREREYlzZdUt/OS1PWw/1sTUIVl8b9YI+mfE0czOpolj/99I2fgLbHV78fU9h8bZvyeYPiDaI5MEowZZRERERCRO+QJBHtt4hD9tPEyKw8p/zxvFvLPyMOLhGmMA08Re/g4p7/0Ue9VW/FkjaJj7MN5h8yFeXoP0KmqQRURERETijGmafFjewM/X7GN/TStzRufy3RnDyUp2RHtoX8jSWI6j/B3sFeuxl7+LtbWSQGp/Gmf+Es+ofwKLWhSJHu19IiIiIiJx4lBtK698XMUrpVWU17eRn5bEry8fw/RhfaI9tNMyPA04dyzHtevPWBsPARB05eAdcD4tAy/EU7gYrElRHqWIGmQRERERkZjV5guw83gTH5Y3sH5/LTuPN2EAkwZlcsOUQVxcmEuywxrtYXbK0nIc10eP4Nz5OBZfM97+5+Medz3eAdMJZI/SadQSc9Qgi4iIiIjECNM02VrRyDsHatlS3sCu4034gyYGMCovle9cNIxLRuWSlxbDR1sDPhzlb5O053mS9r0Iph/PiEtxT/wm/tziaI9O5LTUIIuIiIiIRJk/aPLGnhOs2FzOx5XNWC0GRflpfPWc/kwckMH4fhmkOWP4T/dgAPvR90ja+1eSyl7G4qkn6EinregqWifcRDBjSLRHKNIlMfwuExERERHpvQJBk48qGnh99wne3FdDTYuXQVkufjBrBPOK8nHZY/fUacPTiK1yC5bt28k4+N7Jnz0NmLZkPEMvwTNyEd5BF+q6Yok7apBFRERERCLEHzT58Eg9b+yt5s291dS2+kiyWZg+LJv5RflMH5aNJRavyzVNrLV7SCp7iaT9r2Ct+RgDExMDM7sQz/AFeAdeiHfwxWCPo/svi/wDNcgiIiIiIj3E7Quwp6qZXZXN7DrexHsH66h3+3DZLUwf1oeLC3OYNjQ7do4WBwMY3iYMbyMWTyNGWx32ig0klb2Erb4MEwN/wSRaJ38XX99zSCmcSr1bLYX0HtqbRURERERC0OL1s/NYE3tOtHCi2UN1s5cTLV6qmz1UNLQRNE+ul5fqYMrgTC4uzGXqkCycMdAUG95mbMc24Ti6AXvFBmxV2zDMQId1TMOCr99UmsbfiGfoXMyUvM8eTEoGd2uERy3Sc9Qgi4iIiIh0UZsvwPFGD7urmtl2tJGtRxvZe6K5vQlOslnIS3WQk5rE6Pw0LhmdR1HfNM7KTyU3NUrX4/rbsNXuwdJ0BEtLJdaWypPf6/ZhO7EdwwxgWuz48yfinvgNgsl5BB3pmEnpmI40/H1GY7pi+z7LIuES9QY5GAyybNkynnzySSoqKsjOzmbevHksXbqU5OTkHt9eRCQSlHUikgjiLev8QZOj9W4qa1px+wK4fQHafEHcvgCtvgBub4CqZg/HGj0ca2zjaEMbta2+9u1ddgtjCtK5fsogxvVLp+iffS0AAA8HSURBVKhvGhlOG0ZPXkMcDEDAgxHwYPjbPvnZixHwwCffDX8b1vr92E7swFa9A2vdPoygv/0pTIudYHIegbQBtJ79bXz9p+Lre66uHRYhBhrk++67j+XLlzN79mxuuOEGysrKWL58Obt27eKxxx7DYrH06PYiIpGgrBORRBBvWffT1Xv5647jp13HZjEoSE+iIN3JBcP7tP88tE8yI3NTsVl6rhm2NB/DfmwT9mMbsR/dhLVuL0bQ98UbfiKQnIc/ZwyeIbPx54whkDmMYEo+pjMLDP1/Q+RUotog7927lxUrVnDJJZfwwAMPtC8fMGAA9957Ly+99BKXXnppj20vIhIJyjoRSQTxmHVXTxrAlBE5mD4/TrsVl92Cy25t/znZbiXDZQ9tVmnTxPC1YGmtwtJ6AsPTiOF3g9+N4Xdj+D757ndj+FoxvI0Y3iZsNbuxNh05+RS2ZHx9z8E76CJMezKmNQmsSZjWJEybE6wOTKvjk+UnvwfTBxJMyQ9TpUQSR1Qb5BdffBHTNLn22ms7LL/iiiv45S9/yapVq04bhKFuLyISCco6EUkE8Zh1Q7JcTBjah/oG9+lX9LmxtFZiaT2BpeXkd8P/6TafNM+GgRHwYbRWYW2tOtkQt5z8/tm6nTOtSZj2FExHGqY9BX9uMe7xN+IrmIw/pwgsUT/xUyQhRPWdtmPHDiwWC+PGjeuwPCkpidGjR7N9+/Ye3V5EJBKUdSKSCOIx61LeuQv7tj+RY1jBYsO02E82ohY7ptUGhg2jrQ6Lr7nLzxl0pBNMySOYnIcvfyLBlHyCrhyCKbkEk/MwkzIwbcmYNhem3YVpc4HNqVOeRWJEVBvkqqoqsrKycDgcn3ssPz+fLVu24PV6T/l4OLYXEYkEZZ2IJIJ4zDpP4eUkZeTQ1uo+eW1v0H/ye8B/8mfTTzAp4+Sszsl5BJNzTza8ybmY9lTgk6mrzU++W6wnm10RiVtRbZDdbnenIZeUdHIa/La2tk7XCXX7T9ntVnJz07o6bIAzXl8+o9qFRvXrvmjVTlmXmFS70Kh+oYlG/eIy63IvhOILSena2tIJvV+7T7ULTU/UL6rncrhcLrxe7ykf83g8ADidnX8KF+r2IiKRoKwTkUSgrBOR3iCqDXJeXh51dXWnDMPKyspOT7MJ1/YiIpGgrBORRKCsE5HeIKoNcnFxMcFgkG3btnVY7vF4KC0tpbi4uEe3FxGJBGWdiCQCZZ2I9AZRbZDnz5+PYRiUlJR0WL5y5UrcbneHqfwPHz5MWVlZt7cXEYkWZZ2IJAJlnYj0BoZpfjrtXnTcc889rFixgtmzZ3PRRRdRVlbG8uXLOfvssykpKcFiOdnDz5w5k4qKCnbv3t2t7UVEoklZJyKJQFknIvEu6g1yIBCgpKSEp556ioqKCrKyspg/fz5Lly4lJeWzOQU7C9Kubh9tXq+XH//4x2zYsIHa2lry8vK4+uqrueaaa6I9tLjw8ssvs3z5ckpLS8nKyuKNN96I9pBilt/v56c//SmrVq0iGAxyySWXcNddd7XPACqn11P7mrJOWdcVyrquU9aFRlkXGmVdaJR1XaesC0139rWoN8iJorW1lT/+8Y9cfvnlDBw4kN27d3PjjTdy5513Mn/+/GgPL+atX7+e+vp6qqurKSkpUZCexoMPPsirr77Ko48+it1u55vf/CZjx47lzjvvjPbQ4oL2tdAo60Kj/a/rlHWh0b4WGmVdaLT/dZ2yLjTd2dd0nkqEJCcnc9tttzF48GAsFgtnnXUWM2fO5MMPP4z20OLC+eefz4IFC+jfv3+0hxLznnnmGW655Rby8/PJzs7m1ltv5S9/+QuBQCDaQ4sL2tdCo6wLjfa/rlPWhUb7WmiUdaHR/td1yrrQdGdfs/XgeGLOww8/zM6dO9m5cyfl5eX079+/008RgsEgy5Yt48knn6SiooLs7GzmzZvH0qVLSU5ODnksPp+PzZs3c+ONN4b8XJEQS7XrLXqipo2NjRw7dozRo0e3LxszZgwtLS1UVFQwaNCgHn9dkaJ9snOxVBtlnSjrQqN9snOxVBtlnSjrQhNL+2RCNci/+tWvyMzMpKioiKamptOue99997F8+XJmz57NDTfc0D5JxK5du3jsscc6TBJx++238/LLL3f6XMuWLWPKlCkdlt1zzz2kpKSwaNGi0F5UhMRS7XqLnqhpS0sLAOnp6e3bpqWldXist+ipfbI3iKX3q7LuJGWdsq67lHWdi6X3q7LuJGWdsq67YirrzARy+PDh9p8XLFhgzpgx45Tr7dmzxxw1apR56623dli+bNkys7Cw0Fy1alWH5U1NTWZNTU2nX16vt8P69913n7lw4UKzpqYmTK+s58VK7VavXt3p7443PVHThoYGs7Cw0CwrK2tfVlNTYxYWFpqHDh0K8yuIrp7aJz8Vz/tarLxflXWfUdadpKw7c8q6zsXK+1VZ9xll3UnKujMXS1nXuz5K/AIDBw7s0novvvgipmly7bXXdlh+xRVX4HK5WLVqVYflqampZGdnd/plt9vb1/3JT37Cu+++S0lJCdnZ2aG/qAiJhdr1Nj1R0/T0dAoKCigtLW1ftmvXLlJSUnrddT49tU/2BrHwflXWKes+pawLjbKuc7HwflXWKes+pawLTSxlXUI1yF21Y8cOLBYL48aN67A8KSmJ0aNHs3379m4977333suGDRviLkTPRE/VLhAI4PF48Pl8mKaJx+PB6/WGY8gx70xr+uUvf5mHH36YyspKamtrefDBB1myZAlWqzWSw44ZZ1q/RNrXlHXdp6wLP2VdaJR1nVPWdZ+yLvyUdaGJRNYl1DXIXVVVVUVWVhYOh+Nzj+Xn57Nlyxa8Xu8pH+9MRUUFy5cvx+FwcPHFF7cvP+ecc3j00UfDMu5Y0BO1A/jrX//KD37wg/Z/jxs37rQX7/cmZ1rTW265hfr6ehYuXEgwGGTOnDnccccdkR52zDjT+iXSvqas6z5lXfgp60KjrOucsq77lHXhp6wLTSSyTg3yKbjd7k7f6J/elLutre2MwqB///7s3r07LOOLZT1RO4AlS5awZMmSkMcXj860pjabjTvvvFP3x/vEmdYvkfY1ZV33KevCT1kXGmVd55R13aesCz9lXWgikXU6xfoUXC5Xp4fePR4PAE6nM5JDihuqXfippqFR/Tqn2nSfahd+qmloVL/OqTbdp9qFn2oamkjUTw3yKeTl5VFXV3fK4ldWVnZ6WF9Uu56gmoZG9eucatN9ql34qaahUf06p9p0n2oXfqppaCJRPzXIp1BcXEwwGGTbtm0dlns8HkpLSykuLo7SyGKfahd+qmloVL/OqTbdp9qFn2oaGtWvc6pN96l24aeahiYS9VODfArz58/HMAxKSko6LF+5ciVut5tLL700SiOLfapd+KmmoVH9OqfadJ9qF36qaWhUv86pNt2n2oWfahqaSNTPevfdd98d8rPEieeff5433niDTZs2sXHjRtxuN36/n02bNlFRUcHo0aMByMnJoa6ujueee47du3fT0tLCCy+8wB/+8AfOPfdcvve972EYRpRfTWSpduGnmoZG9eucatN9ql34qaahUf06p9p0n2oXfqppaGKpfoZpmmY4XlQ8uOaaa3j//fdP+djkyZNZvnx5+78DgQAlJSU89dRTVFRUkJWVxfz581m6dCkpKSmRGnLMUO3CTzUNjerXOdWm+1S78FNNQ6P6dU616T7VLvxU09DEUv0SqkEWERERERER6YyuQRYRERERERFBDbKIiIiIiIgIoAZZREREREREBFCDLCIiIiIiIgKoQRYREREREREB1CCLiIiIiIiIAGqQRURERERERAA1yCIiIiIiIiKAGmQRERERERERQA2yiIiIiIiICKAGWXqxjRs3MmrUqA5fEydOZMmSJZSUlBAIBD63zTe+8Q2uvPLKz22/cuXKU/6OUaNG8Y1vfKNHX4eIyOko60QkESjrJFJs0R6ASE9buHAhF154IaZpUlVVxXPPPcd9993Hvn37uOeee9rXa25u5t1332Xp0qWfe44HHniAyy67DKfTGcmhi4h0mbJORBKBsk56mo4gS69XVFTEokWLWLx4MTfffDNPP/00eXl5PP3001RXV7evt27dOrxeL7NmzeqwfXFxMVVVVZSUlER66CIiXaasE5FEoKyTnqYGWRJOamoqEydOxDRNjhw50r789ddfZ8SIEQwdOrTD+vPmzWPMmDE88sgj1NXVRXq4IiLdoqwTkUSgrJNwU4MsCcc0TQ4dOgRAVlYWAF6vl7Vr137uU0YAwzC44447aGpq4qGHHoroWEVEuktZJyKJQFkn4aYGWXo9t9tNbW0ttbW1lJaW8qMf/YjS0lImTJjAkCFDANiwYQPNzc2nDFKAadOmcf755/PEE09QUVERwdGLiHSNsk5EEoGyTnqaGmTp9R544AGmTp3K1KlTWbRoEc8++ywzZ87k97//ffs6a9asoW/fvowdO7bT57njjjvw+Xz89re/jcSwRUTOiLJORBKBsk56mmaxll7vyiuvZO7cuRiGgcvlYsiQIWRmZrY/HgwGWbNmDXPnzj3t8xQVFbFgwQJeeOEFbrjhBkaPHt3TQxcR6TJlnYgkAmWd9DQdQZZeb/DgwUybNo2pU6cyYcKEDiEKsGXLFqqrqzs9Defv3XbbbVitVu6///6eGq6ISLco60QkESjrpKepQZaE9/rrr5ORkcGkSZO+cN2BAwdy1VVX8fbbb7Nx48YIjE5EJDyUdSKSCJR1Eio1yJLwVq9ezYwZM7DZunbFwTe/+U1SU1P5xS9+0cMjExEJH2WdiCQCZZ2ESg2yJLTS0lKOHDnSpdNwPpWdnc2NN97I9u3be3BkIiLho6wTkUSgrJNwUIMsCe3111/H6XQyffr0M9ru+uuvJzc3t4dGJSISXso6EUkEyjoJB8M0TTPagxCJlsWLF9OvXz/+8Ic/RHsoIiI9RlknIolAWSfhoNs8ScLyer3MmjWLadOmRXsoIiI9RlknIolAWSfhoiPIIiIiIiIiIugaZBERERERERFADbKIiIiIiIgIoAZZREREREREBFCDLCIiIiIiIgKoQRYREREREREB1CCLiIiIiIiIAGqQRURERERERAD4/x6flFkBg5EjAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 1152x360 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_single_vs_ensemble([K1_df, K2_df], [1, 2], N_Ds[0], feature_dim, ymax=2.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change the coef to 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [4] trial: 0, train_loss: 2.037904, test loss: 1.022333, bias2: 1.0223325490951538, variance: 2.1895582569264604e-10\n",
      "Train size: [400] hidden size: [4] trial: 1, train_loss: 1.939638, test loss: 1.022546, bias2: 1.0103169679641724, variance: 0.012228565290570259\n",
      "Train size: [400] hidden size: [4] trial: 2, train_loss: 1.908710, test loss: 1.019008, bias2: 1.0052242279052734, variance: 0.013784150592982769\n",
      "Train size: [400] hidden size: [4] trial: 3, train_loss: 1.915815, test loss: 1.011454, bias2: 0.9934030771255493, variance: 0.01805102452635765\n",
      "Train size: [400] hidden size: [4] trial: 4, train_loss: 1.903022, test loss: 1.011127, bias2: 0.9859099388122559, variance: 0.025216590613126755\n",
      "Train size: [400] hidden size: [4] trial: 5, train_loss: 1.922316, test loss: 1.009327, bias2: 0.9871187210083008, variance: 0.022208215668797493\n",
      "Train size: [400] hidden size: [4] trial: 6, train_loss: 1.933179, test loss: 1.008635, bias2: 0.9886596202850342, variance: 0.019975291565060616\n",
      "Train size: [400] hidden size: [4] trial: 7, train_loss: 1.971255, test loss: 1.007431, bias2: 0.9891195297241211, variance: 0.018311498686671257\n",
      "Train size: [400] hidden size: [4] trial: 8, train_loss: 1.949992, test loss: 1.006629, bias2: 0.9894014000892639, variance: 0.01722794771194458\n",
      "Train size: [400] hidden size: [4] trial: 9, train_loss: 1.942298, test loss: 1.009011, bias2: 0.9888314008712769, variance: 0.02017938531935215\n",
      "Train size: [400] hidden size: [4] trial: 10, train_loss: 1.951202, test loss: 1.008705, bias2: 0.9891061782836914, variance: 0.019598722457885742\n",
      "Train size: [400] hidden size: [4] trial: 11, train_loss: 1.967884, test loss: 1.008454, bias2: 0.9893826246261597, variance: 0.019070973619818687\n",
      "Train size: [400] hidden size: [4] trial: 12, train_loss: 1.943831, test loss: 1.008968, bias2: 0.9903193712234497, variance: 0.018648624420166016\n",
      "Train size: [400] hidden size: [4] trial: 13, train_loss: 1.950301, test loss: 1.009526, bias2: 0.9911375641822815, variance: 0.018388472497463226\n",
      "Train size: [400] hidden size: [4] trial: 14, train_loss: 1.953848, test loss: 1.009816, bias2: 0.9914684295654297, variance: 0.018348079174757004\n",
      "Train size: [400] hidden size: [4] trial: 15, train_loss: 1.950542, test loss: 1.009402, bias2: 0.9917792081832886, variance: 0.017623038962483406\n",
      "Train size: [400] hidden size: [4] trial: 16, train_loss: 1.949250, test loss: 1.010776, bias2: 0.9888501167297363, variance: 0.021925540640950203\n",
      "Train size: [400] hidden size: [4] trial: 17, train_loss: 1.956517, test loss: 1.011513, bias2: 0.9889957308769226, variance: 0.022517608478665352\n",
      "Train size: [400] hidden size: [4] trial: 18, train_loss: 1.966560, test loss: 1.012166, bias2: 0.989628255367279, variance: 0.022537915036082268\n",
      "Train size: [400] hidden size: [4] trial: 19, train_loss: 1.962438, test loss: 1.011805, bias2: 0.9896204471588135, variance: 0.022184129804372787\n",
      "Train size: [400] hidden size: [4] trial: 20, train_loss: 1.969103, test loss: 1.011546, bias2: 0.9897499084472656, variance: 0.02179657109081745\n",
      "Train size: [400] hidden size: [4] trial: 21, train_loss: 1.970405, test loss: 1.011765, bias2: 0.9896618127822876, variance: 0.022102802991867065\n",
      "Train size: [400] hidden size: [4] trial: 22, train_loss: 1.970559, test loss: 1.012494, bias2: 0.9887692332267761, variance: 0.02372436597943306\n",
      "Train size: [400] hidden size: [4] trial: 23, train_loss: 1.978744, test loss: 1.011654, bias2: 0.9871222376823425, variance: 0.024531397968530655\n",
      "Train size: [400] hidden size: [4] trial: 24, train_loss: 1.980358, test loss: 1.010786, bias2: 0.9865692853927612, variance: 0.02421702817082405\n",
      "Train size: [400] hidden size: [4] trial: 25, train_loss: 1.971774, test loss: 1.010670, bias2: 0.9866886138916016, variance: 0.023981234058737755\n",
      "Train size: [400] hidden size: [4] trial: 26, train_loss: 1.972065, test loss: 1.010220, bias2: 0.9868208765983582, variance: 0.023399392142891884\n",
      "Train size: [400] hidden size: [4] trial: 27, train_loss: 1.967676, test loss: 1.010765, bias2: 0.9865333437919617, variance: 0.024231482297182083\n",
      "Train size: [400] hidden size: [4] trial: 28, train_loss: 1.967513, test loss: 1.010021, bias2: 0.9860668182373047, variance: 0.02395426668226719\n",
      "Train size: [400] hidden size: [4] trial: 29, train_loss: 1.968338, test loss: 1.010100, bias2: 0.9866676926612854, variance: 0.023432297632098198\n",
      "Train size: [400] hidden size: [4] trial: 30, train_loss: 1.962740, test loss: 1.010725, bias2: 0.9864327907562256, variance: 0.024291738867759705\n",
      "Train size: [400] hidden size: [4] trial: 31, train_loss: 1.968456, test loss: 1.012078, bias2: 0.9870762228965759, variance: 0.02500220388174057\n",
      "Train size: [400] hidden size: [4] trial: 32, train_loss: 1.963391, test loss: 1.012184, bias2: 0.9867866635322571, variance: 0.02539699152112007\n",
      "Train size: [400] hidden size: [4] trial: 33, train_loss: 1.959651, test loss: 1.011936, bias2: 0.9865458607673645, variance: 0.02539009600877762\n",
      "Train size: [400] hidden size: [4] trial: 34, train_loss: 1.952611, test loss: 1.012181, bias2: 0.9868221282958984, variance: 0.025359293445944786\n",
      "Train size: [400] hidden size: [4] trial: 35, train_loss: 1.962549, test loss: 1.012140, bias2: 0.986707329750061, variance: 0.025432705879211426\n",
      "Train size: [400] hidden size: [4] trial: 36, train_loss: 1.961815, test loss: 1.012351, bias2: 0.9866382479667664, variance: 0.025713128969073296\n",
      "Train size: [400] hidden size: [4] trial: 37, train_loss: 1.966484, test loss: 1.012077, bias2: 0.9868764281272888, variance: 0.025200439617037773\n",
      "Train size: [400] hidden size: [4] trial: 38, train_loss: 1.964371, test loss: 1.011733, bias2: 0.9867974519729614, variance: 0.024935102090239525\n",
      "Train size: [400] hidden size: [4] trial: 39, train_loss: 1.968877, test loss: 1.011386, bias2: 0.9867235422134399, variance: 0.02466275356709957\n",
      "Train size: [400] hidden size: [4] trial: 40, train_loss: 1.968239, test loss: 1.010780, bias2: 0.9863322973251343, variance: 0.02444734051823616\n",
      "Train size: [400] hidden size: [4] trial: 41, train_loss: 1.967679, test loss: 1.010807, bias2: 0.9866392016410828, variance: 0.024167824536561966\n",
      "Train size: [400] hidden size: [4] trial: 42, train_loss: 1.966275, test loss: 1.010935, bias2: 0.9868197441101074, variance: 0.024115556851029396\n",
      "Train size: [400] hidden size: [4] trial: 43, train_loss: 1.969818, test loss: 1.011355, bias2: 0.9871727824211121, variance: 0.02418202906847\n",
      "Train size: [400] hidden size: [4] trial: 44, train_loss: 1.974689, test loss: 1.011127, bias2: 0.9865154027938843, variance: 0.024611609056591988\n",
      "Train size: [400] hidden size: [4] trial: 45, train_loss: 1.970920, test loss: 1.011943, bias2: 0.9865823984146118, variance: 0.02536080591380596\n",
      "Train size: [400] hidden size: [4] trial: 46, train_loss: 1.972066, test loss: 1.012134, bias2: 0.9864952564239502, variance: 0.025638679042458534\n",
      "Train size: [400] hidden size: [4] trial: 47, train_loss: 1.966801, test loss: 1.011647, bias2: 0.9860935807228088, variance: 0.02555364929139614\n",
      "Train size: [400] hidden size: [4] trial: 48, train_loss: 1.964549, test loss: 1.011393, bias2: 0.9861633777618408, variance: 0.02522956021130085\n",
      "Train size: [400] hidden size: [4] trial: 49, train_loss: 1.968424, test loss: 1.011515, bias2: 0.9862039089202881, variance: 0.025311442092061043\n",
      "##################################################\n",
      "Train size: [400] hidden size: [5] trial: 0, train_loss: 2.012788, test loss: 1.001648, bias2: 1.0016484260559082, variance: 2.311200397731028e-10\n",
      "Train size: [400] hidden size: [5] trial: 1, train_loss: 1.997547, test loss: 1.015562, bias2: 1.0000308752059937, variance: 0.015531251206994057\n",
      "Train size: [400] hidden size: [5] trial: 2, train_loss: 2.039362, test loss: 1.022432, bias2: 0.9923911690711975, variance: 0.03004046529531479\n",
      "Train size: [400] hidden size: [5] trial: 3, train_loss: 2.029943, test loss: 1.022467, bias2: 0.9861440658569336, variance: 0.036323074251413345\n",
      "Train size: [400] hidden size: [5] trial: 4, train_loss: 2.015299, test loss: 1.020100, bias2: 0.9846327900886536, variance: 0.03546731173992157\n",
      "Train size: [400] hidden size: [5] trial: 5, train_loss: 1.977967, test loss: 1.019645, bias2: 0.9821038246154785, variance: 0.03754091262817383\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [5] trial: 6, train_loss: 1.991885, test loss: 1.019310, bias2: 0.9811966419219971, variance: 0.03811332955956459\n",
      "Train size: [400] hidden size: [5] trial: 7, train_loss: 1.980800, test loss: 1.019005, bias2: 0.9805086851119995, variance: 0.03849615901708603\n",
      "Train size: [400] hidden size: [5] trial: 8, train_loss: 1.974581, test loss: 1.019765, bias2: 0.9805285334587097, variance: 0.03923683613538742\n",
      "Train size: [400] hidden size: [5] trial: 9, train_loss: 1.998992, test loss: 1.021528, bias2: 0.9830766320228577, variance: 0.03845136612653732\n",
      "Train size: [400] hidden size: [5] trial: 10, train_loss: 2.002708, test loss: 1.021449, bias2: 0.9834628105163574, variance: 0.037986014038324356\n",
      "Train size: [400] hidden size: [5] trial: 11, train_loss: 1.992410, test loss: 1.019681, bias2: 0.9839743375778198, variance: 0.035706549882888794\n",
      "Train size: [400] hidden size: [5] trial: 12, train_loss: 1.983169, test loss: 1.020043, bias2: 0.9837977290153503, variance: 0.03624481335282326\n",
      "Train size: [400] hidden size: [5] trial: 13, train_loss: 1.983309, test loss: 1.022925, bias2: 0.9826729893684387, variance: 0.040251556783914566\n",
      "Train size: [400] hidden size: [5] trial: 14, train_loss: 1.994027, test loss: 1.024277, bias2: 0.9831165671348572, variance: 0.04116014391183853\n",
      "Train size: [400] hidden size: [5] trial: 15, train_loss: 1.992307, test loss: 1.023137, bias2: 0.9839366674423218, variance: 0.039200786501169205\n",
      "Train size: [400] hidden size: [5] trial: 16, train_loss: 1.992336, test loss: 1.024571, bias2: 0.9850443601608276, variance: 0.03952692076563835\n",
      "Train size: [400] hidden size: [5] trial: 17, train_loss: 2.005361, test loss: 1.026125, bias2: 0.9867362380027771, variance: 0.03938845917582512\n",
      "Train size: [400] hidden size: [5] trial: 18, train_loss: 2.009412, test loss: 1.027123, bias2: 0.9867929220199585, variance: 0.04032981023192406\n",
      "Train size: [400] hidden size: [5] trial: 19, train_loss: 2.010113, test loss: 1.026831, bias2: 0.9862783551216125, variance: 0.040553018450737\n",
      "Train size: [400] hidden size: [5] trial: 20, train_loss: 2.005047, test loss: 1.026033, bias2: 0.9866116642951965, variance: 0.03942123427987099\n",
      "Train size: [400] hidden size: [5] trial: 21, train_loss: 2.006572, test loss: 1.024713, bias2: 0.9843449592590332, variance: 0.0403682142496109\n",
      "Train size: [400] hidden size: [5] trial: 22, train_loss: 2.004664, test loss: 1.025098, bias2: 0.9841276407241821, variance: 0.04097022861242294\n",
      "Train size: [400] hidden size: [5] trial: 23, train_loss: 1.995093, test loss: 1.025715, bias2: 0.9840193390846252, variance: 0.041696012020111084\n",
      "Train size: [400] hidden size: [5] trial: 24, train_loss: 1.992845, test loss: 1.026167, bias2: 0.984535813331604, variance: 0.041631001979112625\n",
      "Train size: [400] hidden size: [5] trial: 25, train_loss: 1.991967, test loss: 1.026674, bias2: 0.9850136041641235, variance: 0.041660163551568985\n",
      "Train size: [400] hidden size: [5] trial: 26, train_loss: 1.984613, test loss: 1.029189, bias2: 0.9863070845603943, variance: 0.042881764471530914\n",
      "Train size: [400] hidden size: [5] trial: 27, train_loss: 1.979276, test loss: 1.028679, bias2: 0.9868058562278748, variance: 0.041873376816511154\n",
      "Train size: [400] hidden size: [5] trial: 28, train_loss: 1.981345, test loss: 1.028422, bias2: 0.986949622631073, variance: 0.04147200286388397\n",
      "Train size: [400] hidden size: [5] trial: 29, train_loss: 1.981625, test loss: 1.027550, bias2: 0.9864152073860168, variance: 0.041134513914585114\n",
      "Train size: [400] hidden size: [5] trial: 30, train_loss: 1.976796, test loss: 1.026953, bias2: 0.9861302971839905, variance: 0.040823034942150116\n",
      "Train size: [400] hidden size: [5] trial: 31, train_loss: 1.973904, test loss: 1.026464, bias2: 0.9863500595092773, variance: 0.04011392593383789\n",
      "Train size: [400] hidden size: [5] trial: 32, train_loss: 1.969454, test loss: 1.025840, bias2: 0.9860736727714539, variance: 0.03976662456989288\n",
      "Train size: [400] hidden size: [5] trial: 33, train_loss: 1.968609, test loss: 1.025126, bias2: 0.9863072037696838, variance: 0.03881855681538582\n",
      "Train size: [400] hidden size: [5] trial: 34, train_loss: 1.966212, test loss: 1.024417, bias2: 0.9851095080375671, variance: 0.039307285100221634\n",
      "Train size: [400] hidden size: [5] trial: 35, train_loss: 1.968618, test loss: 1.023981, bias2: 0.9848536252975464, variance: 0.03912780061364174\n",
      "Train size: [400] hidden size: [5] trial: 36, train_loss: 1.968984, test loss: 1.023522, bias2: 0.984978973865509, variance: 0.03854280710220337\n",
      "Train size: [400] hidden size: [5] trial: 37, train_loss: 1.971901, test loss: 1.024829, bias2: 0.9850989580154419, variance: 0.03972984105348587\n",
      "Train size: [400] hidden size: [5] trial: 38, train_loss: 1.966267, test loss: 1.024272, bias2: 0.9848669171333313, variance: 0.039404548704624176\n",
      "Train size: [400] hidden size: [5] trial: 39, train_loss: 1.964501, test loss: 1.023479, bias2: 0.9849101901054382, variance: 0.03856879100203514\n",
      "Train size: [400] hidden size: [5] trial: 40, train_loss: 1.964298, test loss: 1.023237, bias2: 0.9827724099159241, variance: 0.040464796125888824\n",
      "Train size: [400] hidden size: [5] trial: 41, train_loss: 1.962608, test loss: 1.022835, bias2: 0.9829398393630981, variance: 0.03989490866661072\n",
      "Train size: [400] hidden size: [5] trial: 42, train_loss: 1.962443, test loss: 1.022403, bias2: 0.9828623533248901, variance: 0.03954027220606804\n",
      "Train size: [400] hidden size: [5] trial: 43, train_loss: 1.970203, test loss: 1.022002, bias2: 0.9830211997032166, variance: 0.038981132209300995\n",
      "Train size: [400] hidden size: [5] trial: 44, train_loss: 1.966159, test loss: 1.021565, bias2: 0.9831713438034058, variance: 0.038393281400203705\n",
      "Train size: [400] hidden size: [5] trial: 45, train_loss: 1.966731, test loss: 1.021125, bias2: 0.983223021030426, variance: 0.03790219500660896\n",
      "Train size: [400] hidden size: [5] trial: 46, train_loss: 1.962973, test loss: 1.020913, bias2: 0.9836077094078064, variance: 0.03730527311563492\n",
      "Train size: [400] hidden size: [5] trial: 47, train_loss: 1.966660, test loss: 1.022018, bias2: 0.9836548566818237, variance: 0.03836359083652496\n",
      "Train size: [400] hidden size: [5] trial: 48, train_loss: 1.964229, test loss: 1.021708, bias2: 0.9836611151695251, variance: 0.03804675489664078\n",
      "Train size: [400] hidden size: [5] trial: 49, train_loss: 1.962639, test loss: 1.021143, bias2: 0.9835081696510315, variance: 0.03763504698872566\n",
      "##################################################\n",
      "Train size: [400] hidden size: [6] trial: 0, train_loss: 1.709943, test loss: 0.994075, bias2: 0.9940746426582336, variance: -1.2164212345733283e-11\n",
      "Train size: [400] hidden size: [6] trial: 1, train_loss: 1.826165, test loss: 1.008703, bias2: 0.9933673739433289, variance: 0.015335740521550179\n",
      "Train size: [400] hidden size: [6] trial: 2, train_loss: 1.820004, test loss: 1.010934, bias2: 0.981574535369873, variance: 0.02935960330069065\n",
      "Train size: [400] hidden size: [6] trial: 3, train_loss: 1.866274, test loss: 1.011766, bias2: 0.9777548909187317, variance: 0.03401152417063713\n",
      "Train size: [400] hidden size: [6] trial: 4, train_loss: 1.907741, test loss: 1.016081, bias2: 0.9807032346725464, variance: 0.03537747636437416\n",
      "Train size: [400] hidden size: [6] trial: 5, train_loss: 1.889808, test loss: 1.014109, bias2: 0.9763838648796082, variance: 0.03772563114762306\n",
      "Train size: [400] hidden size: [6] trial: 6, train_loss: 1.901934, test loss: 1.012314, bias2: 0.9775705337524414, variance: 0.03474317863583565\n",
      "Train size: [400] hidden size: [6] trial: 7, train_loss: 1.926767, test loss: 1.016486, bias2: 0.9749563932418823, variance: 0.04152988642454147\n",
      "Train size: [400] hidden size: [6] trial: 8, train_loss: 1.915216, test loss: 1.013985, bias2: 0.9747358560562134, variance: 0.03924965113401413\n",
      "Train size: [400] hidden size: [6] trial: 9, train_loss: 1.928513, test loss: 1.012554, bias2: 0.9758785367012024, variance: 0.03667527809739113\n",
      "Train size: [400] hidden size: [6] trial: 10, train_loss: 1.945299, test loss: 1.013670, bias2: 0.977577269077301, variance: 0.036093179136514664\n",
      "Train size: [400] hidden size: [6] trial: 11, train_loss: 1.972566, test loss: 1.012414, bias2: 0.9736536145210266, variance: 0.038759998977184296\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [6] trial: 12, train_loss: 1.982949, test loss: 1.012955, bias2: 0.9746814966201782, variance: 0.038273341953754425\n",
      "Train size: [400] hidden size: [6] trial: 13, train_loss: 1.992585, test loss: 1.012135, bias2: 0.9745544195175171, variance: 0.037580106407403946\n",
      "Train size: [400] hidden size: [6] trial: 14, train_loss: 1.992940, test loss: 1.011626, bias2: 0.9747411012649536, variance: 0.03688513860106468\n",
      "Train size: [400] hidden size: [6] trial: 15, train_loss: 2.001168, test loss: 1.011129, bias2: 0.9744427800178528, variance: 0.03668611869215965\n",
      "Train size: [400] hidden size: [6] trial: 16, train_loss: 2.011819, test loss: 1.014284, bias2: 0.9729765057563782, variance: 0.04130752012133598\n",
      "Train size: [400] hidden size: [6] trial: 17, train_loss: 2.021090, test loss: 1.015132, bias2: 0.9733685851097107, variance: 0.04176301881670952\n",
      "Train size: [400] hidden size: [6] trial: 18, train_loss: 2.007452, test loss: 1.014856, bias2: 0.9726118445396423, variance: 0.04224412143230438\n",
      "Train size: [400] hidden size: [6] trial: 19, train_loss: 1.995104, test loss: 1.014435, bias2: 0.973449170589447, variance: 0.040985651314258575\n",
      "Train size: [400] hidden size: [6] trial: 20, train_loss: 1.992846, test loss: 1.014110, bias2: 0.9738593697547913, variance: 0.04025037959218025\n",
      "Train size: [400] hidden size: [6] trial: 21, train_loss: 1.992500, test loss: 1.013105, bias2: 0.9738804697990417, variance: 0.03922446444630623\n",
      "Train size: [400] hidden size: [6] trial: 22, train_loss: 1.988509, test loss: 1.012917, bias2: 0.9734709858894348, variance: 0.03944652900099754\n",
      "Train size: [400] hidden size: [6] trial: 23, train_loss: 1.987317, test loss: 1.013353, bias2: 0.9734013676643372, variance: 0.03995150327682495\n",
      "Train size: [400] hidden size: [6] trial: 24, train_loss: 1.988591, test loss: 1.014301, bias2: 0.9740279912948608, variance: 0.04027259349822998\n",
      "Train size: [400] hidden size: [6] trial: 25, train_loss: 1.983889, test loss: 1.014483, bias2: 0.9743914604187012, variance: 0.04009196162223816\n",
      "Train size: [400] hidden size: [6] trial: 26, train_loss: 1.972418, test loss: 1.014826, bias2: 0.9743326306343079, variance: 0.04049331322312355\n",
      "Train size: [400] hidden size: [6] trial: 27, train_loss: 1.974922, test loss: 1.015424, bias2: 0.9743304252624512, variance: 0.04109404981136322\n",
      "Train size: [400] hidden size: [6] trial: 28, train_loss: 1.970249, test loss: 1.015011, bias2: 0.9738892316818237, variance: 0.041121579706668854\n",
      "Train size: [400] hidden size: [6] trial: 29, train_loss: 1.971563, test loss: 1.014525, bias2: 0.9735245108604431, variance: 0.04100029543042183\n",
      "Train size: [400] hidden size: [6] trial: 30, train_loss: 1.969383, test loss: 1.013913, bias2: 0.9736593961715698, variance: 0.04025328904390335\n",
      "Train size: [400] hidden size: [6] trial: 31, train_loss: 1.967773, test loss: 1.014125, bias2: 0.9745503067970276, variance: 0.03957432508468628\n",
      "Train size: [400] hidden size: [6] trial: 32, train_loss: 1.972284, test loss: 1.014145, bias2: 0.974577009677887, variance: 0.039567913860082626\n",
      "Train size: [400] hidden size: [6] trial: 33, train_loss: 1.971508, test loss: 1.013798, bias2: 0.9749668836593628, variance: 0.038830652832984924\n",
      "Train size: [400] hidden size: [6] trial: 34, train_loss: 1.974630, test loss: 1.014537, bias2: 0.9749262928962708, variance: 0.03961057588458061\n",
      "Train size: [400] hidden size: [6] trial: 35, train_loss: 1.971653, test loss: 1.015323, bias2: 0.9747490882873535, variance: 0.04057357832789421\n",
      "Train size: [400] hidden size: [6] trial: 36, train_loss: 1.971722, test loss: 1.016574, bias2: 0.9742328524589539, variance: 0.04234163463115692\n",
      "Train size: [400] hidden size: [6] trial: 37, train_loss: 1.970958, test loss: 1.016140, bias2: 0.974057674407959, variance: 0.042081862688064575\n",
      "Train size: [400] hidden size: [6] trial: 38, train_loss: 1.969503, test loss: 1.016353, bias2: 0.974097728729248, variance: 0.04225538671016693\n",
      "Train size: [400] hidden size: [6] trial: 39, train_loss: 1.968514, test loss: 1.016915, bias2: 0.9747948050498962, variance: 0.04212063178420067\n",
      "Train size: [400] hidden size: [6] trial: 40, train_loss: 1.970991, test loss: 1.017215, bias2: 0.9748520255088806, variance: 0.04236310347914696\n",
      "Train size: [400] hidden size: [6] trial: 41, train_loss: 1.969398, test loss: 1.017892, bias2: 0.974976658821106, variance: 0.04291525110602379\n",
      "Train size: [400] hidden size: [6] trial: 42, train_loss: 1.968476, test loss: 1.017725, bias2: 0.9751877784729004, variance: 0.04253683611750603\n",
      "Train size: [400] hidden size: [6] trial: 43, train_loss: 1.965041, test loss: 1.018477, bias2: 0.9755972027778625, variance: 0.04287966340780258\n",
      "Train size: [400] hidden size: [6] trial: 44, train_loss: 1.961492, test loss: 1.017761, bias2: 0.9746911525726318, variance: 0.043069496750831604\n",
      "Train size: [400] hidden size: [6] trial: 45, train_loss: 1.964595, test loss: 1.017660, bias2: 0.9751909375190735, variance: 0.04246931150555611\n",
      "Train size: [400] hidden size: [6] trial: 46, train_loss: 1.965386, test loss: 1.016801, bias2: 0.9744907021522522, variance: 0.042310286313295364\n",
      "Train size: [400] hidden size: [6] trial: 47, train_loss: 1.965898, test loss: 1.016867, bias2: 0.9743455052375793, variance: 0.04252142086625099\n",
      "Train size: [400] hidden size: [6] trial: 48, train_loss: 1.962186, test loss: 1.017033, bias2: 0.9746071696281433, variance: 0.042425792664289474\n",
      "Train size: [400] hidden size: [6] trial: 49, train_loss: 1.958608, test loss: 1.017985, bias2: 0.9750967025756836, variance: 0.042888786643743515\n",
      "##################################################\n",
      "Train size: [400] hidden size: [7] trial: 0, train_loss: 2.107406, test loss: 1.025117, bias2: 1.0251171588897705, variance: -2.4328424691466566e-11\n",
      "Train size: [400] hidden size: [7] trial: 1, train_loss: 1.971665, test loss: 1.027359, bias2: 0.9997757077217102, variance: 0.02758353017270565\n",
      "Train size: [400] hidden size: [7] trial: 2, train_loss: 1.921079, test loss: 1.027121, bias2: 0.9873685240745544, variance: 0.039752207696437836\n",
      "Train size: [400] hidden size: [7] trial: 3, train_loss: 1.901155, test loss: 1.031537, bias2: 0.9815983176231384, variance: 0.049939073622226715\n",
      "Train size: [400] hidden size: [7] trial: 4, train_loss: 1.908605, test loss: 1.034770, bias2: 0.9828235507011414, variance: 0.051946356892585754\n",
      "Train size: [400] hidden size: [7] trial: 5, train_loss: 1.900624, test loss: 1.029484, bias2: 0.9778522253036499, variance: 0.05163183808326721\n",
      "Train size: [400] hidden size: [7] trial: 6, train_loss: 1.909146, test loss: 1.025017, bias2: 0.9768116474151611, variance: 0.04820558428764343\n",
      "Train size: [400] hidden size: [7] trial: 7, train_loss: 1.900600, test loss: 1.023921, bias2: 0.9777526259422302, variance: 0.046168018132448196\n",
      "Train size: [400] hidden size: [7] trial: 8, train_loss: 1.934650, test loss: 1.021311, bias2: 0.9729622006416321, variance: 0.04834846034646034\n",
      "Train size: [400] hidden size: [7] trial: 9, train_loss: 1.941315, test loss: 1.026158, bias2: 0.9751726984977722, variance: 0.05098506435751915\n",
      "Train size: [400] hidden size: [7] trial: 10, train_loss: 1.941506, test loss: 1.028360, bias2: 0.974118709564209, variance: 0.05424153804779053\n",
      "Train size: [400] hidden size: [7] trial: 11, train_loss: 1.940531, test loss: 1.026203, bias2: 0.9735763072967529, variance: 0.0526268407702446\n",
      "Train size: [400] hidden size: [7] trial: 12, train_loss: 1.959739, test loss: 1.025124, bias2: 0.9735054969787598, variance: 0.05161797255277634\n",
      "Train size: [400] hidden size: [7] trial: 13, train_loss: 1.963702, test loss: 1.024141, bias2: 0.9745631814002991, variance: 0.04957776144146919\n",
      "Train size: [400] hidden size: [7] trial: 14, train_loss: 1.962656, test loss: 1.023447, bias2: 0.9750521779060364, variance: 0.048395074903964996\n",
      "Train size: [400] hidden size: [7] trial: 15, train_loss: 1.963139, test loss: 1.023252, bias2: 0.9745751023292542, variance: 0.04867655783891678\n",
      "Train size: [400] hidden size: [7] trial: 16, train_loss: 1.964586, test loss: 1.022713, bias2: 0.9759869575500488, variance: 0.04672613739967346\n",
      "Train size: [400] hidden size: [7] trial: 17, train_loss: 1.960569, test loss: 1.025449, bias2: 0.9771609306335449, variance: 0.0482882522046566\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [7] trial: 18, train_loss: 1.963552, test loss: 1.026907, bias2: 0.9781752824783325, variance: 0.04873180761933327\n",
      "Train size: [400] hidden size: [7] trial: 19, train_loss: 1.969985, test loss: 1.027566, bias2: 0.9785109162330627, variance: 0.049054812639951706\n",
      "Train size: [400] hidden size: [7] trial: 20, train_loss: 1.969672, test loss: 1.026429, bias2: 0.9786763787269592, variance: 0.04775279760360718\n",
      "Train size: [400] hidden size: [7] trial: 21, train_loss: 1.956940, test loss: 1.026986, bias2: 0.9782276153564453, variance: 0.048757895827293396\n",
      "Train size: [400] hidden size: [7] trial: 22, train_loss: 1.959740, test loss: 1.027790, bias2: 0.9775260090827942, variance: 0.050263579934835434\n",
      "Train size: [400] hidden size: [7] trial: 23, train_loss: 1.958842, test loss: 1.027538, bias2: 0.9767797589302063, variance: 0.050758302211761475\n",
      "Train size: [400] hidden size: [7] trial: 24, train_loss: 1.957812, test loss: 1.026566, bias2: 0.9760184288024902, variance: 0.05054748058319092\n",
      "Train size: [400] hidden size: [7] trial: 25, train_loss: 1.962256, test loss: 1.027025, bias2: 0.9755169153213501, variance: 0.051508430391550064\n",
      "Train size: [400] hidden size: [7] trial: 26, train_loss: 1.957815, test loss: 1.026806, bias2: 0.9761106967926025, variance: 0.05069480463862419\n",
      "Train size: [400] hidden size: [7] trial: 27, train_loss: 1.958397, test loss: 1.025916, bias2: 0.9760705232620239, variance: 0.04984571784734726\n",
      "Train size: [400] hidden size: [7] trial: 28, train_loss: 1.959615, test loss: 1.026624, bias2: 0.9756041765213013, variance: 0.05102017521858215\n",
      "Train size: [400] hidden size: [7] trial: 29, train_loss: 1.957654, test loss: 1.026082, bias2: 0.9758789539337158, variance: 0.05020342022180557\n",
      "Train size: [400] hidden size: [7] trial: 30, train_loss: 1.957668, test loss: 1.024755, bias2: 0.975573718547821, variance: 0.04918128624558449\n",
      "Train size: [400] hidden size: [7] trial: 31, train_loss: 1.958663, test loss: 1.025162, bias2: 0.9750868678092957, variance: 0.050075214356184006\n",
      "Train size: [400] hidden size: [7] trial: 32, train_loss: 1.966793, test loss: 1.024448, bias2: 0.9747592210769653, variance: 0.04968918487429619\n",
      "Train size: [400] hidden size: [7] trial: 33, train_loss: 1.964410, test loss: 1.024782, bias2: 0.9755630493164062, variance: 0.0492190346121788\n",
      "Train size: [400] hidden size: [7] trial: 34, train_loss: 1.962243, test loss: 1.023235, bias2: 0.9743428826332092, variance: 0.0488920621573925\n",
      "Train size: [400] hidden size: [7] trial: 35, train_loss: 1.965397, test loss: 1.023767, bias2: 0.9735155701637268, variance: 0.05025143921375275\n",
      "Train size: [400] hidden size: [7] trial: 36, train_loss: 1.963926, test loss: 1.023952, bias2: 0.9743696451187134, variance: 0.04958197474479675\n",
      "Train size: [400] hidden size: [7] trial: 37, train_loss: 1.969629, test loss: 1.023256, bias2: 0.9745891690254211, variance: 0.048666540533304214\n",
      "Train size: [400] hidden size: [7] trial: 38, train_loss: 1.972871, test loss: 1.023780, bias2: 0.9739816188812256, variance: 0.04979885369539261\n",
      "Train size: [400] hidden size: [7] trial: 39, train_loss: 1.977038, test loss: 1.024103, bias2: 0.9745151996612549, variance: 0.04958793893456459\n",
      "Train size: [400] hidden size: [7] trial: 40, train_loss: 1.975521, test loss: 1.024113, bias2: 0.9742384552955627, variance: 0.049874741584062576\n",
      "Train size: [400] hidden size: [7] trial: 41, train_loss: 1.975600, test loss: 1.023820, bias2: 0.9735612869262695, variance: 0.05025865137577057\n",
      "Train size: [400] hidden size: [7] trial: 42, train_loss: 1.975487, test loss: 1.023909, bias2: 0.9744628071784973, variance: 0.04944569244980812\n",
      "Train size: [400] hidden size: [7] trial: 43, train_loss: 1.977975, test loss: 1.023441, bias2: 0.9741423726081848, variance: 0.049298714846372604\n",
      "Train size: [400] hidden size: [7] trial: 44, train_loss: 1.976657, test loss: 1.022919, bias2: 0.9741953611373901, variance: 0.04872383922338486\n",
      "Train size: [400] hidden size: [7] trial: 45, train_loss: 1.977388, test loss: 1.022514, bias2: 0.9745352268218994, variance: 0.04797913879156113\n",
      "Train size: [400] hidden size: [7] trial: 46, train_loss: 1.974918, test loss: 1.022120, bias2: 0.974252462387085, variance: 0.04786776378750801\n",
      "Train size: [400] hidden size: [7] trial: 47, train_loss: 1.978163, test loss: 1.022638, bias2: 0.9739281535148621, variance: 0.048709556460380554\n",
      "Train size: [400] hidden size: [7] trial: 48, train_loss: 1.973951, test loss: 1.022435, bias2: 0.9741929173469543, variance: 0.04824217036366463\n",
      "Train size: [400] hidden size: [7] trial: 49, train_loss: 1.968132, test loss: 1.021789, bias2: 0.9737966060638428, variance: 0.04799282178282738\n",
      "##################################################\n",
      "Train size: [400] hidden size: [8] trial: 0, train_loss: 2.016152, test loss: 1.013998, bias2: 1.0139977931976318, variance: 0.0\n",
      "Train size: [400] hidden size: [8] trial: 1, train_loss: 2.009251, test loss: 1.037992, bias2: 1.018934965133667, variance: 0.019057177007198334\n",
      "Train size: [400] hidden size: [8] trial: 2, train_loss: 2.047441, test loss: 1.029445, bias2: 0.9998342990875244, variance: 0.02961074188351631\n",
      "Train size: [400] hidden size: [8] trial: 3, train_loss: 2.038067, test loss: 1.020941, bias2: 0.9891732335090637, variance: 0.03176780045032501\n",
      "Train size: [400] hidden size: [8] trial: 4, train_loss: 2.011002, test loss: 1.019820, bias2: 0.9869135618209839, variance: 0.032906413078308105\n",
      "Train size: [400] hidden size: [8] trial: 5, train_loss: 2.004207, test loss: 1.017890, bias2: 0.9847627282142639, variance: 0.03312724083662033\n",
      "Train size: [400] hidden size: [8] trial: 6, train_loss: 1.997838, test loss: 1.017119, bias2: 0.983529269695282, variance: 0.033589426428079605\n",
      "Train size: [400] hidden size: [8] trial: 7, train_loss: 1.971163, test loss: 1.024378, bias2: 0.9805805683135986, variance: 0.043796904385089874\n",
      "Train size: [400] hidden size: [8] trial: 8, train_loss: 1.989076, test loss: 1.024312, bias2: 0.9797053337097168, variance: 0.044607020914554596\n",
      "Train size: [400] hidden size: [8] trial: 9, train_loss: 1.985055, test loss: 1.025664, bias2: 0.9789988398551941, variance: 0.0466655008494854\n",
      "Train size: [400] hidden size: [8] trial: 10, train_loss: 1.988689, test loss: 1.022708, bias2: 0.9782044887542725, variance: 0.04450380802154541\n",
      "Train size: [400] hidden size: [8] trial: 11, train_loss: 1.998740, test loss: 1.025975, bias2: 0.9785564541816711, variance: 0.04741887003183365\n",
      "Train size: [400] hidden size: [8] trial: 12, train_loss: 1.996541, test loss: 1.026623, bias2: 0.9792993664741516, variance: 0.047323741018772125\n",
      "Train size: [400] hidden size: [8] trial: 13, train_loss: 1.997749, test loss: 1.025602, bias2: 0.9764798283576965, variance: 0.0491224005818367\n",
      "Train size: [400] hidden size: [8] trial: 14, train_loss: 1.992704, test loss: 1.024569, bias2: 0.9767123460769653, variance: 0.04785618931055069\n",
      "Train size: [400] hidden size: [8] trial: 15, train_loss: 1.992683, test loss: 1.026260, bias2: 0.9745563268661499, variance: 0.051703840494155884\n",
      "Train size: [400] hidden size: [8] trial: 16, train_loss: 1.985014, test loss: 1.027247, bias2: 0.9692378640174866, variance: 0.05800873786211014\n",
      "Train size: [400] hidden size: [8] trial: 17, train_loss: 1.972954, test loss: 1.026437, bias2: 0.9668545722961426, variance: 0.059582144021987915\n",
      "Train size: [400] hidden size: [8] trial: 18, train_loss: 1.973624, test loss: 1.026310, bias2: 0.9679953455924988, variance: 0.05831485241651535\n",
      "Train size: [400] hidden size: [8] trial: 19, train_loss: 1.979438, test loss: 1.026249, bias2: 0.9693683385848999, variance: 0.05688033998012543\n",
      "Train size: [400] hidden size: [8] trial: 20, train_loss: 1.966874, test loss: 1.026203, bias2: 0.9669092297554016, variance: 0.05929359421133995\n",
      "Train size: [400] hidden size: [8] trial: 21, train_loss: 1.955354, test loss: 1.027687, bias2: 0.967572808265686, variance: 0.06011389568448067\n",
      "Train size: [400] hidden size: [8] trial: 22, train_loss: 1.941693, test loss: 1.027121, bias2: 0.9674538969993591, variance: 0.0596667043864727\n",
      "Train size: [400] hidden size: [8] trial: 23, train_loss: 1.944196, test loss: 1.025994, bias2: 0.9662752747535706, variance: 0.059718646109104156\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [8] trial: 24, train_loss: 1.960436, test loss: 1.025832, bias2: 0.9674155712127686, variance: 0.0584164559841156\n",
      "Train size: [400] hidden size: [8] trial: 25, train_loss: 1.965795, test loss: 1.024879, bias2: 0.9674020409584045, variance: 0.05747705325484276\n",
      "Train size: [400] hidden size: [8] trial: 26, train_loss: 1.973667, test loss: 1.024259, bias2: 0.967472493648529, variance: 0.056786101311445236\n",
      "Train size: [400] hidden size: [8] trial: 27, train_loss: 1.958095, test loss: 1.025316, bias2: 0.9679341912269592, variance: 0.05738144740462303\n",
      "Train size: [400] hidden size: [8] trial: 28, train_loss: 1.956709, test loss: 1.025144, bias2: 0.9684325456619263, variance: 0.056711189448833466\n",
      "Train size: [400] hidden size: [8] trial: 29, train_loss: 1.949293, test loss: 1.024389, bias2: 0.9690024852752686, variance: 0.055386800318956375\n",
      "Train size: [400] hidden size: [8] trial: 30, train_loss: 1.954194, test loss: 1.024314, bias2: 0.9692021012306213, variance: 0.05511244013905525\n",
      "Train size: [400] hidden size: [8] trial: 31, train_loss: 1.953233, test loss: 1.024754, bias2: 0.9698578119277954, variance: 0.05489661544561386\n",
      "Train size: [400] hidden size: [8] trial: 32, train_loss: 1.952148, test loss: 1.024839, bias2: 0.9692160487174988, variance: 0.05562286823987961\n",
      "Train size: [400] hidden size: [8] trial: 33, train_loss: 1.949836, test loss: 1.023981, bias2: 0.9689478874206543, variance: 0.055032987147569656\n",
      "Train size: [400] hidden size: [8] trial: 34, train_loss: 1.947102, test loss: 1.024277, bias2: 0.9686338305473328, variance: 0.05564325675368309\n",
      "Train size: [400] hidden size: [8] trial: 35, train_loss: 1.942675, test loss: 1.024785, bias2: 0.968648374080658, variance: 0.05613628402352333\n",
      "Train size: [400] hidden size: [8] trial: 36, train_loss: 1.941087, test loss: 1.024124, bias2: 0.9685460329055786, variance: 0.05557850003242493\n",
      "Train size: [400] hidden size: [8] trial: 37, train_loss: 1.943417, test loss: 1.024042, bias2: 0.9691014885902405, variance: 0.05494039133191109\n",
      "Train size: [400] hidden size: [8] trial: 38, train_loss: 1.946872, test loss: 1.024979, bias2: 0.9686182737350464, variance: 0.0563603900372982\n",
      "Train size: [400] hidden size: [8] trial: 39, train_loss: 1.946176, test loss: 1.025269, bias2: 0.9688515067100525, variance: 0.05641717091202736\n",
      "Train size: [400] hidden size: [8] trial: 40, train_loss: 1.948569, test loss: 1.024646, bias2: 0.9692304134368896, variance: 0.05541573092341423\n",
      "Train size: [400] hidden size: [8] trial: 41, train_loss: 1.943906, test loss: 1.024718, bias2: 0.9687386751174927, variance: 0.055979251861572266\n",
      "Train size: [400] hidden size: [8] trial: 42, train_loss: 1.948830, test loss: 1.024529, bias2: 0.9684616327285767, variance: 0.05606689304113388\n",
      "Train size: [400] hidden size: [8] trial: 43, train_loss: 1.948630, test loss: 1.024806, bias2: 0.9686143398284912, variance: 0.05619201809167862\n",
      "Train size: [400] hidden size: [8] trial: 44, train_loss: 1.949207, test loss: 1.024416, bias2: 0.9686616659164429, variance: 0.05575445294380188\n",
      "Train size: [400] hidden size: [8] trial: 45, train_loss: 1.945125, test loss: 1.024073, bias2: 0.9681984782218933, variance: 0.05587451159954071\n",
      "Train size: [400] hidden size: [8] trial: 46, train_loss: 1.939126, test loss: 1.023802, bias2: 0.9688470959663391, variance: 0.05495532229542732\n",
      "Train size: [400] hidden size: [8] trial: 47, train_loss: 1.940598, test loss: 1.023156, bias2: 0.9679518938064575, variance: 0.05520414188504219\n",
      "Train size: [400] hidden size: [8] trial: 48, train_loss: 1.936638, test loss: 1.023029, bias2: 0.9683941602706909, variance: 0.05463495850563049\n",
      "Train size: [400] hidden size: [8] trial: 49, train_loss: 1.931452, test loss: 1.023054, bias2: 0.9679546356201172, variance: 0.055099159479141235\n",
      "##################################################\n",
      "Train size: [400] hidden size: [9] trial: 0, train_loss: 1.952868, test loss: 1.036457, bias2: 1.0364573001861572, variance: -1.9462739753173253e-10\n",
      "Train size: [400] hidden size: [9] trial: 1, train_loss: 1.955365, test loss: 1.022356, bias2: 0.9853466749191284, variance: 0.037009481340646744\n",
      "Train size: [400] hidden size: [9] trial: 2, train_loss: 1.981472, test loss: 1.013457, bias2: 0.9788954854011536, variance: 0.034561123698949814\n",
      "Train size: [400] hidden size: [9] trial: 3, train_loss: 1.955247, test loss: 1.016700, bias2: 0.9706452488899231, variance: 0.0460551455616951\n",
      "Train size: [400] hidden size: [9] trial: 4, train_loss: 1.930105, test loss: 1.022310, bias2: 0.9649508595466614, variance: 0.05735870823264122\n",
      "Train size: [400] hidden size: [9] trial: 5, train_loss: 1.924066, test loss: 1.023173, bias2: 0.9615164399147034, variance: 0.06165606155991554\n",
      "Train size: [400] hidden size: [9] trial: 6, train_loss: 1.935362, test loss: 1.025171, bias2: 0.9613868594169617, variance: 0.06378408521413803\n",
      "Train size: [400] hidden size: [9] trial: 7, train_loss: 1.930950, test loss: 1.027483, bias2: 0.9585055112838745, variance: 0.06897714734077454\n",
      "Train size: [400] hidden size: [9] trial: 8, train_loss: 1.946442, test loss: 1.031310, bias2: 0.9590138792991638, variance: 0.07229655236005783\n",
      "Train size: [400] hidden size: [9] trial: 9, train_loss: 1.966123, test loss: 1.030349, bias2: 0.9627549648284912, variance: 0.06759441643953323\n",
      "Train size: [400] hidden size: [9] trial: 10, train_loss: 1.964339, test loss: 1.028987, bias2: 0.9623256325721741, variance: 0.0666608214378357\n",
      "Train size: [400] hidden size: [9] trial: 11, train_loss: 1.961430, test loss: 1.030570, bias2: 0.9643840789794922, variance: 0.06618546694517136\n",
      "Train size: [400] hidden size: [9] trial: 12, train_loss: 1.962209, test loss: 1.030779, bias2: 0.9660695791244507, variance: 0.06470932811498642\n",
      "Train size: [400] hidden size: [9] trial: 13, train_loss: 1.957243, test loss: 1.029281, bias2: 0.9662516117095947, variance: 0.06302891671657562\n",
      "Train size: [400] hidden size: [9] trial: 14, train_loss: 1.941810, test loss: 1.027292, bias2: 0.9624879956245422, variance: 0.06480427831411362\n",
      "Train size: [400] hidden size: [9] trial: 15, train_loss: 1.949923, test loss: 1.028876, bias2: 0.9632886052131653, variance: 0.06558696180582047\n",
      "Train size: [400] hidden size: [9] trial: 16, train_loss: 1.950486, test loss: 1.029241, bias2: 0.9649852514266968, variance: 0.0642554983496666\n",
      "Train size: [400] hidden size: [9] trial: 17, train_loss: 1.952266, test loss: 1.027996, bias2: 0.9648410677909851, variance: 0.06315451115369797\n",
      "Train size: [400] hidden size: [9] trial: 18, train_loss: 1.943875, test loss: 1.025681, bias2: 0.9636242389678955, variance: 0.062056880444288254\n",
      "Train size: [400] hidden size: [9] trial: 19, train_loss: 1.951770, test loss: 1.028414, bias2: 0.9653566479682922, variance: 0.06305690109729767\n",
      "Train size: [400] hidden size: [9] trial: 20, train_loss: 1.942425, test loss: 1.028367, bias2: 0.9660753011703491, variance: 0.06229196488857269\n",
      "Train size: [400] hidden size: [9] trial: 21, train_loss: 1.938345, test loss: 1.027685, bias2: 0.9658621549606323, variance: 0.06182243302464485\n",
      "Train size: [400] hidden size: [9] trial: 22, train_loss: 1.933152, test loss: 1.026846, bias2: 0.9648686051368713, variance: 0.06197695806622505\n",
      "Train size: [400] hidden size: [9] trial: 23, train_loss: 1.930456, test loss: 1.026604, bias2: 0.9659555554389954, variance: 0.060647886246442795\n",
      "Train size: [400] hidden size: [9] trial: 24, train_loss: 1.928856, test loss: 1.025539, bias2: 0.9659496545791626, variance: 0.05958971381187439\n",
      "Train size: [400] hidden size: [9] trial: 25, train_loss: 1.930929, test loss: 1.025333, bias2: 0.9668201208114624, variance: 0.058512426912784576\n",
      "Train size: [400] hidden size: [9] trial: 26, train_loss: 1.932101, test loss: 1.026361, bias2: 0.9673998355865479, variance: 0.058961011469364166\n",
      "Train size: [400] hidden size: [9] trial: 27, train_loss: 1.935410, test loss: 1.026146, bias2: 0.9672737121582031, variance: 0.05887267366051674\n",
      "Train size: [400] hidden size: [9] trial: 28, train_loss: 1.941347, test loss: 1.025825, bias2: 0.9671012163162231, variance: 0.05872347950935364\n",
      "Train size: [400] hidden size: [9] trial: 29, train_loss: 1.939684, test loss: 1.026043, bias2: 0.9671384692192078, variance: 0.058904919773340225\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [9] trial: 30, train_loss: 1.943077, test loss: 1.025748, bias2: 0.9676995873451233, variance: 0.05804841220378876\n",
      "Train size: [400] hidden size: [9] trial: 31, train_loss: 1.948236, test loss: 1.025948, bias2: 0.9682247638702393, variance: 0.057722922414541245\n",
      "Train size: [400] hidden size: [9] trial: 32, train_loss: 1.940449, test loss: 1.026868, bias2: 0.9685680270195007, variance: 0.058300409466028214\n",
      "Train size: [400] hidden size: [9] trial: 33, train_loss: 1.944074, test loss: 1.029120, bias2: 0.9694427847862244, variance: 0.05967717245221138\n",
      "Train size: [400] hidden size: [9] trial: 34, train_loss: 1.941109, test loss: 1.029190, bias2: 0.9699624180793762, variance: 0.05922798067331314\n",
      "Train size: [400] hidden size: [9] trial: 35, train_loss: 1.939544, test loss: 1.028146, bias2: 0.9687647819519043, variance: 0.05938135087490082\n",
      "Train size: [400] hidden size: [9] trial: 36, train_loss: 1.938793, test loss: 1.029078, bias2: 0.9681007862091064, variance: 0.06097748875617981\n",
      "Train size: [400] hidden size: [9] trial: 37, train_loss: 1.937828, test loss: 1.030158, bias2: 0.9676938652992249, variance: 0.06246379762887955\n",
      "Train size: [400] hidden size: [9] trial: 38, train_loss: 1.935248, test loss: 1.029918, bias2: 0.967077374458313, variance: 0.06284080445766449\n",
      "Train size: [400] hidden size: [9] trial: 39, train_loss: 1.931793, test loss: 1.029877, bias2: 0.9667340517044067, variance: 0.06314292550086975\n",
      "Train size: [400] hidden size: [9] trial: 40, train_loss: 1.941457, test loss: 1.031121, bias2: 0.9668988585472107, variance: 0.0642218217253685\n",
      "Train size: [400] hidden size: [9] trial: 41, train_loss: 1.937638, test loss: 1.032610, bias2: 0.9672342538833618, variance: 0.0653756707906723\n",
      "Train size: [400] hidden size: [9] trial: 42, train_loss: 1.935608, test loss: 1.032944, bias2: 0.9673815965652466, variance: 0.06556235253810883\n",
      "Train size: [400] hidden size: [9] trial: 43, train_loss: 1.935943, test loss: 1.033551, bias2: 0.9671933650970459, variance: 0.06635785102844238\n",
      "Train size: [400] hidden size: [9] trial: 44, train_loss: 1.934696, test loss: 1.033586, bias2: 0.9673827886581421, variance: 0.06620322912931442\n",
      "Train size: [400] hidden size: [9] trial: 45, train_loss: 1.927743, test loss: 1.033079, bias2: 0.9675469994544983, variance: 0.06553155928850174\n",
      "Train size: [400] hidden size: [9] trial: 46, train_loss: 1.928529, test loss: 1.033316, bias2: 0.9676254391670227, variance: 0.06569106131792068\n",
      "Train size: [400] hidden size: [9] trial: 47, train_loss: 1.926677, test loss: 1.033660, bias2: 0.9684502482414246, variance: 0.06520957499742508\n",
      "Train size: [400] hidden size: [9] trial: 48, train_loss: 1.928247, test loss: 1.033516, bias2: 0.9689700603485107, variance: 0.06454622000455856\n",
      "Train size: [400] hidden size: [9] trial: 49, train_loss: 1.929560, test loss: 1.033829, bias2: 0.9694034457206726, variance: 0.0644257515668869\n",
      "##################################################\n",
      "Train size: [400] hidden size: [11] trial: 0, train_loss: 1.861329, test loss: 1.037144, bias2: 1.0371438264846802, variance: 9.731369876586626e-11\n",
      "Train size: [400] hidden size: [11] trial: 1, train_loss: 1.815233, test loss: 1.017120, bias2: 0.9810243844985962, variance: 0.03609538823366165\n",
      "Train size: [400] hidden size: [11] trial: 2, train_loss: 1.820666, test loss: 1.029495, bias2: 0.9563025236129761, variance: 0.07319244742393494\n",
      "Train size: [400] hidden size: [11] trial: 3, train_loss: 1.887008, test loss: 1.025655, bias2: 0.9522083401679993, variance: 0.0734463483095169\n",
      "Train size: [400] hidden size: [11] trial: 4, train_loss: 1.858340, test loss: 1.015565, bias2: 0.9441196322441101, variance: 0.07144515961408615\n",
      "Train size: [400] hidden size: [11] trial: 5, train_loss: 1.848062, test loss: 1.021561, bias2: 0.9468233585357666, variance: 0.07473769783973694\n",
      "Train size: [400] hidden size: [11] trial: 6, train_loss: 1.884900, test loss: 1.023301, bias2: 0.9496363997459412, variance: 0.0736645832657814\n",
      "Train size: [400] hidden size: [11] trial: 7, train_loss: 1.889272, test loss: 1.029082, bias2: 0.953671932220459, variance: 0.07541021704673767\n",
      "Train size: [400] hidden size: [11] trial: 8, train_loss: 1.877852, test loss: 1.031230, bias2: 0.9566024541854858, variance: 0.07462762296199799\n",
      "Train size: [400] hidden size: [11] trial: 9, train_loss: 1.876838, test loss: 1.028835, bias2: 0.9558283090591431, variance: 0.0730065107345581\n",
      "Train size: [400] hidden size: [11] trial: 10, train_loss: 1.877197, test loss: 1.029752, bias2: 0.9552657604217529, variance: 0.07448650896549225\n",
      "Train size: [400] hidden size: [11] trial: 11, train_loss: 1.864322, test loss: 1.029606, bias2: 0.9575165510177612, variance: 0.07208944857120514\n",
      "Train size: [400] hidden size: [11] trial: 12, train_loss: 1.854487, test loss: 1.030040, bias2: 0.9583721160888672, variance: 0.07166755944490433\n",
      "Train size: [400] hidden size: [11] trial: 13, train_loss: 1.863023, test loss: 1.031154, bias2: 0.9582990407943726, variance: 0.07285473495721817\n",
      "Train size: [400] hidden size: [11] trial: 14, train_loss: 1.862893, test loss: 1.032578, bias2: 0.9597451090812683, variance: 0.0728328675031662\n",
      "Train size: [400] hidden size: [11] trial: 15, train_loss: 1.858254, test loss: 1.031321, bias2: 0.9602662920951843, variance: 0.07105440646409988\n",
      "Train size: [400] hidden size: [11] trial: 16, train_loss: 1.857870, test loss: 1.031075, bias2: 0.9604474306106567, variance: 0.07062732428312302\n",
      "Train size: [400] hidden size: [11] trial: 17, train_loss: 1.850370, test loss: 1.033579, bias2: 0.961794376373291, variance: 0.07178458571434021\n",
      "Train size: [400] hidden size: [11] trial: 18, train_loss: 1.863401, test loss: 1.032362, bias2: 0.9611886739730835, variance: 0.07117322087287903\n",
      "Train size: [400] hidden size: [11] trial: 19, train_loss: 1.855229, test loss: 1.033924, bias2: 0.9610933065414429, variance: 0.07283081859350204\n",
      "Train size: [400] hidden size: [11] trial: 20, train_loss: 1.847671, test loss: 1.033819, bias2: 0.9611435532569885, variance: 0.07267563790082932\n",
      "Train size: [400] hidden size: [11] trial: 21, train_loss: 1.851446, test loss: 1.033919, bias2: 0.9622473120689392, variance: 0.07167140394449234\n",
      "Train size: [400] hidden size: [11] trial: 22, train_loss: 1.859714, test loss: 1.032022, bias2: 0.9594088792800903, variance: 0.07261335104703903\n",
      "Train size: [400] hidden size: [11] trial: 23, train_loss: 1.855478, test loss: 1.032562, bias2: 0.9583932757377625, variance: 0.07416875660419464\n",
      "Train size: [400] hidden size: [11] trial: 24, train_loss: 1.852604, test loss: 1.031580, bias2: 0.9581462144851685, variance: 0.07343410700559616\n",
      "Train size: [400] hidden size: [11] trial: 25, train_loss: 1.854415, test loss: 1.031442, bias2: 0.9590507745742798, variance: 0.07239114493131638\n",
      "Train size: [400] hidden size: [11] trial: 26, train_loss: 1.861916, test loss: 1.032183, bias2: 0.9596683979034424, variance: 0.07251467555761337\n",
      "Train size: [400] hidden size: [11] trial: 27, train_loss: 1.864007, test loss: 1.034878, bias2: 0.9613845348358154, variance: 0.07349386066198349\n",
      "Train size: [400] hidden size: [11] trial: 28, train_loss: 1.861348, test loss: 1.033615, bias2: 0.9605588912963867, variance: 0.07305563986301422\n",
      "Train size: [400] hidden size: [11] trial: 29, train_loss: 1.861640, test loss: 1.033104, bias2: 0.9606598615646362, variance: 0.07244396209716797\n",
      "Train size: [400] hidden size: [11] trial: 30, train_loss: 1.865869, test loss: 1.033143, bias2: 0.9604212045669556, variance: 0.07272134721279144\n",
      "Train size: [400] hidden size: [11] trial: 31, train_loss: 1.865278, test loss: 1.033079, bias2: 0.9602856636047363, variance: 0.07279311120510101\n",
      "Train size: [400] hidden size: [11] trial: 32, train_loss: 1.857415, test loss: 1.035452, bias2: 0.9605414867401123, variance: 0.07491030544042587\n",
      "Train size: [400] hidden size: [11] trial: 33, train_loss: 1.861579, test loss: 1.035771, bias2: 0.960416853427887, variance: 0.07535380125045776\n",
      "Train size: [400] hidden size: [11] trial: 34, train_loss: 1.863747, test loss: 1.035704, bias2: 0.9610382318496704, variance: 0.07466556131839752\n",
      "Train size: [400] hidden size: [11] trial: 35, train_loss: 1.865653, test loss: 1.034548, bias2: 0.9607383012771606, variance: 0.07380995154380798\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [11] trial: 36, train_loss: 1.866746, test loss: 1.034591, bias2: 0.9614431858062744, variance: 0.07314810156822205\n",
      "Train size: [400] hidden size: [11] trial: 37, train_loss: 1.868482, test loss: 1.034760, bias2: 0.960634708404541, variance: 0.0741247907280922\n",
      "Train size: [400] hidden size: [11] trial: 38, train_loss: 1.871600, test loss: 1.034332, bias2: 0.960480272769928, variance: 0.07385165244340897\n",
      "Train size: [400] hidden size: [11] trial: 39, train_loss: 1.876595, test loss: 1.034409, bias2: 0.9603061079978943, variance: 0.07410281896591187\n",
      "Train size: [400] hidden size: [11] trial: 40, train_loss: 1.875379, test loss: 1.034230, bias2: 0.9596248865127563, variance: 0.07460487633943558\n",
      "Train size: [400] hidden size: [11] trial: 41, train_loss: 1.878869, test loss: 1.034329, bias2: 0.9601169228553772, variance: 0.07421189546585083\n",
      "Train size: [400] hidden size: [11] trial: 42, train_loss: 1.880647, test loss: 1.035022, bias2: 0.9602761268615723, variance: 0.07474622875452042\n",
      "Train size: [400] hidden size: [11] trial: 43, train_loss: 1.881120, test loss: 1.035315, bias2: 0.9600117206573486, variance: 0.07530341297388077\n",
      "Train size: [400] hidden size: [11] trial: 44, train_loss: 1.879588, test loss: 1.034924, bias2: 0.9602746367454529, variance: 0.0746493935585022\n",
      "Train size: [400] hidden size: [11] trial: 45, train_loss: 1.879144, test loss: 1.036605, bias2: 0.9597790837287903, variance: 0.07682640850543976\n",
      "Train size: [400] hidden size: [11] trial: 46, train_loss: 1.879565, test loss: 1.036939, bias2: 0.9595955610275269, variance: 0.07734384387731552\n",
      "Train size: [400] hidden size: [11] trial: 47, train_loss: 1.881871, test loss: 1.036463, bias2: 0.9603724479675293, variance: 0.07609093934297562\n",
      "Train size: [400] hidden size: [11] trial: 48, train_loss: 1.877811, test loss: 1.036954, bias2: 0.9602788090705872, variance: 0.07667502015829086\n",
      "Train size: [400] hidden size: [11] trial: 49, train_loss: 1.884446, test loss: 1.037809, bias2: 0.9601174592971802, variance: 0.07769178599119186\n",
      "##################################################\n",
      "Train size: [400] hidden size: [12] trial: 0, train_loss: 1.837943, test loss: 1.080015, bias2: 1.0800144672393799, variance: -4.379116513852921e-10\n",
      "Train size: [400] hidden size: [12] trial: 1, train_loss: 1.903631, test loss: 1.041388, bias2: 1.0065115690231323, variance: 0.03487686812877655\n",
      "Train size: [400] hidden size: [12] trial: 2, train_loss: 1.897394, test loss: 1.031394, bias2: 0.9737792015075684, variance: 0.057615187019109726\n",
      "Train size: [400] hidden size: [12] trial: 3, train_loss: 1.923846, test loss: 1.042327, bias2: 0.9716677069664001, variance: 0.0706588476896286\n",
      "Train size: [400] hidden size: [12] trial: 4, train_loss: 1.936688, test loss: 1.046370, bias2: 0.9697648882865906, variance: 0.0766051635146141\n",
      "Train size: [400] hidden size: [12] trial: 5, train_loss: 1.972912, test loss: 1.047045, bias2: 0.9640693664550781, variance: 0.0829758420586586\n",
      "Train size: [400] hidden size: [12] trial: 6, train_loss: 1.967341, test loss: 1.043081, bias2: 0.9624623656272888, variance: 0.08061821758747101\n",
      "Train size: [400] hidden size: [12] trial: 7, train_loss: 1.974181, test loss: 1.041067, bias2: 0.9586263298988342, variance: 0.0824403166770935\n",
      "Train size: [400] hidden size: [12] trial: 8, train_loss: 1.968974, test loss: 1.039379, bias2: 0.9597164988517761, variance: 0.0796627625823021\n",
      "Train size: [400] hidden size: [12] trial: 9, train_loss: 1.970888, test loss: 1.035796, bias2: 0.958433985710144, variance: 0.07736220210790634\n",
      "Train size: [400] hidden size: [12] trial: 10, train_loss: 1.976610, test loss: 1.033955, bias2: 0.9574953317642212, variance: 0.07645974308252335\n",
      "Train size: [400] hidden size: [12] trial: 11, train_loss: 1.968562, test loss: 1.035285, bias2: 0.9541452527046204, variance: 0.08113963901996613\n",
      "Train size: [400] hidden size: [12] trial: 12, train_loss: 1.964741, test loss: 1.036049, bias2: 0.954716682434082, variance: 0.08133198320865631\n",
      "Train size: [400] hidden size: [12] trial: 13, train_loss: 1.970336, test loss: 1.036094, bias2: 0.9573919177055359, variance: 0.07870212942361832\n",
      "Train size: [400] hidden size: [12] trial: 14, train_loss: 1.952896, test loss: 1.035216, bias2: 0.956281840801239, variance: 0.07893446832895279\n",
      "Train size: [400] hidden size: [12] trial: 15, train_loss: 1.946786, test loss: 1.034767, bias2: 0.9583736658096313, variance: 0.07639360427856445\n",
      "Train size: [400] hidden size: [12] trial: 16, train_loss: 1.946073, test loss: 1.033821, bias2: 0.9577581286430359, variance: 0.07606296986341476\n",
      "Train size: [400] hidden size: [12] trial: 17, train_loss: 1.958831, test loss: 1.035846, bias2: 0.9584170579910278, variance: 0.0774284303188324\n",
      "Train size: [400] hidden size: [12] trial: 18, train_loss: 1.957697, test loss: 1.034951, bias2: 0.9601806402206421, variance: 0.074769988656044\n",
      "Train size: [400] hidden size: [12] trial: 19, train_loss: 1.948429, test loss: 1.033255, bias2: 0.9584990739822388, variance: 0.07475623488426208\n",
      "Train size: [400] hidden size: [12] trial: 20, train_loss: 1.945750, test loss: 1.036207, bias2: 0.9600961804389954, variance: 0.07611066848039627\n",
      "Train size: [400] hidden size: [12] trial: 21, train_loss: 1.946426, test loss: 1.035168, bias2: 0.9564088582992554, variance: 0.07875942438840866\n",
      "Train size: [400] hidden size: [12] trial: 22, train_loss: 1.941016, test loss: 1.034474, bias2: 0.9572864174842834, variance: 0.07718795537948608\n",
      "Train size: [400] hidden size: [12] trial: 23, train_loss: 1.943720, test loss: 1.033327, bias2: 0.9578761458396912, variance: 0.0754513368010521\n",
      "Train size: [400] hidden size: [12] trial: 24, train_loss: 1.947992, test loss: 1.034201, bias2: 0.9587433338165283, variance: 0.07545746117830276\n",
      "Train size: [400] hidden size: [12] trial: 25, train_loss: 1.940221, test loss: 1.033527, bias2: 0.9582644104957581, variance: 0.07526274025440216\n",
      "Train size: [400] hidden size: [12] trial: 26, train_loss: 1.941499, test loss: 1.033347, bias2: 0.9573559761047363, variance: 0.0759907066822052\n",
      "Train size: [400] hidden size: [12] trial: 27, train_loss: 1.941799, test loss: 1.033261, bias2: 0.9581918120384216, variance: 0.075068898499012\n",
      "Train size: [400] hidden size: [12] trial: 28, train_loss: 1.940778, test loss: 1.033192, bias2: 0.9579335451126099, variance: 0.07525837421417236\n",
      "Train size: [400] hidden size: [12] trial: 29, train_loss: 1.943491, test loss: 1.032696, bias2: 0.9580821394920349, variance: 0.07461433112621307\n",
      "Train size: [400] hidden size: [12] trial: 30, train_loss: 1.938533, test loss: 1.030915, bias2: 0.9560245871543884, variance: 0.07489042729139328\n",
      "Train size: [400] hidden size: [12] trial: 31, train_loss: 1.946105, test loss: 1.030139, bias2: 0.9564085602760315, variance: 0.07373031228780746\n",
      "Train size: [400] hidden size: [12] trial: 32, train_loss: 1.944701, test loss: 1.029973, bias2: 0.9566632509231567, variance: 0.07330979406833649\n",
      "Train size: [400] hidden size: [12] trial: 33, train_loss: 1.935457, test loss: 1.030154, bias2: 0.9578444957733154, variance: 0.0723097175359726\n",
      "Train size: [400] hidden size: [12] trial: 34, train_loss: 1.934373, test loss: 1.029213, bias2: 0.957726240158081, variance: 0.0714869573712349\n",
      "Train size: [400] hidden size: [12] trial: 35, train_loss: 1.936529, test loss: 1.030501, bias2: 0.9583065509796143, variance: 0.07219447195529938\n",
      "Train size: [400] hidden size: [12] trial: 36, train_loss: 1.939164, test loss: 1.030693, bias2: 0.9591829180717468, variance: 0.07150989025831223\n",
      "Train size: [400] hidden size: [12] trial: 37, train_loss: 1.944592, test loss: 1.031921, bias2: 0.958291232585907, variance: 0.07362955063581467\n",
      "Train size: [400] hidden size: [12] trial: 38, train_loss: 1.940398, test loss: 1.031275, bias2: 0.9584805369377136, variance: 0.07279413938522339\n",
      "Train size: [400] hidden size: [12] trial: 39, train_loss: 1.943756, test loss: 1.030711, bias2: 0.9585115909576416, variance: 0.07219955325126648\n",
      "Train size: [400] hidden size: [12] trial: 40, train_loss: 1.942148, test loss: 1.030873, bias2: 0.9577471017837524, variance: 0.07312604784965515\n",
      "Train size: [400] hidden size: [12] trial: 41, train_loss: 1.943216, test loss: 1.033496, bias2: 0.9580244421958923, variance: 0.07547136396169662\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [12] trial: 42, train_loss: 1.937888, test loss: 1.033495, bias2: 0.9581077098846436, variance: 0.07538769394159317\n",
      "Train size: [400] hidden size: [12] trial: 43, train_loss: 1.936326, test loss: 1.033362, bias2: 0.9579426050186157, variance: 0.07541953772306442\n",
      "Train size: [400] hidden size: [12] trial: 44, train_loss: 1.935703, test loss: 1.033581, bias2: 0.9585607051849365, variance: 0.07502005249261856\n",
      "Train size: [400] hidden size: [12] trial: 45, train_loss: 1.938645, test loss: 1.033129, bias2: 0.9586409330368042, variance: 0.07448838651180267\n",
      "Train size: [400] hidden size: [12] trial: 46, train_loss: 1.936081, test loss: 1.033304, bias2: 0.957749605178833, variance: 0.07555415481328964\n",
      "Train size: [400] hidden size: [12] trial: 47, train_loss: 1.938685, test loss: 1.034657, bias2: 0.9570760130882263, variance: 0.077581487596035\n",
      "Train size: [400] hidden size: [12] trial: 48, train_loss: 1.939740, test loss: 1.033901, bias2: 0.9567736387252808, variance: 0.07712733745574951\n",
      "Train size: [400] hidden size: [12] trial: 49, train_loss: 1.935479, test loss: 1.033678, bias2: 0.9572054743766785, variance: 0.0764724388718605\n",
      "##################################################\n",
      "Train size: [400] hidden size: [14] trial: 0, train_loss: 1.879223, test loss: 1.045800, bias2: 1.045799970626831, variance: -3.8925479506346505e-10\n",
      "Train size: [400] hidden size: [14] trial: 1, train_loss: 1.940028, test loss: 1.035712, bias2: 0.9795082211494446, variance: 0.05620390549302101\n",
      "Train size: [400] hidden size: [14] trial: 2, train_loss: 1.982048, test loss: 1.029258, bias2: 0.9726009964942932, variance: 0.05665702000260353\n",
      "Train size: [400] hidden size: [14] trial: 3, train_loss: 2.002453, test loss: 1.032760, bias2: 0.9711315035820007, variance: 0.061628855764865875\n",
      "Train size: [400] hidden size: [14] trial: 4, train_loss: 2.002207, test loss: 1.036028, bias2: 0.976374626159668, variance: 0.059653542935848236\n",
      "Train size: [400] hidden size: [14] trial: 5, train_loss: 1.997037, test loss: 1.045650, bias2: 0.9810394644737244, variance: 0.06461051851511002\n",
      "Train size: [400] hidden size: [14] trial: 6, train_loss: 2.034788, test loss: 1.043650, bias2: 0.9733937978744507, variance: 0.07025669515132904\n",
      "Train size: [400] hidden size: [14] trial: 7, train_loss: 2.025069, test loss: 1.041918, bias2: 0.9709970355033875, variance: 0.07092086225748062\n",
      "Train size: [400] hidden size: [14] trial: 8, train_loss: 2.007746, test loss: 1.040064, bias2: 0.9700692892074585, variance: 0.06999453902244568\n",
      "Train size: [400] hidden size: [14] trial: 9, train_loss: 2.013091, test loss: 1.041988, bias2: 0.9695798754692078, variance: 0.07240811735391617\n",
      "Train size: [400] hidden size: [14] trial: 10, train_loss: 1.999397, test loss: 1.040743, bias2: 0.9708507657051086, variance: 0.06989245116710663\n",
      "Train size: [400] hidden size: [14] trial: 11, train_loss: 1.995734, test loss: 1.037846, bias2: 0.9675411581993103, variance: 0.07030469179153442\n",
      "Train size: [400] hidden size: [14] trial: 12, train_loss: 1.996589, test loss: 1.038948, bias2: 0.9631590247154236, variance: 0.07578880339860916\n",
      "Train size: [400] hidden size: [14] trial: 13, train_loss: 1.977292, test loss: 1.039216, bias2: 0.9617984294891357, variance: 0.07741771638393402\n",
      "Train size: [400] hidden size: [14] trial: 14, train_loss: 1.974662, test loss: 1.037463, bias2: 0.9594625234603882, variance: 0.07800076901912689\n",
      "Train size: [400] hidden size: [14] trial: 15, train_loss: 1.967790, test loss: 1.036479, bias2: 0.9549573659896851, variance: 0.08152136951684952\n",
      "Train size: [400] hidden size: [14] trial: 16, train_loss: 1.961740, test loss: 1.037240, bias2: 0.9534627199172974, variance: 0.08377744257450104\n",
      "Train size: [400] hidden size: [14] trial: 17, train_loss: 1.968676, test loss: 1.037326, bias2: 0.9535467028617859, variance: 0.08377952128648758\n",
      "Train size: [400] hidden size: [14] trial: 18, train_loss: 1.973650, test loss: 1.036965, bias2: 0.9525154232978821, variance: 0.08444970101118088\n",
      "Train size: [400] hidden size: [14] trial: 19, train_loss: 1.971714, test loss: 1.043672, bias2: 0.9549148082733154, variance: 0.08875761926174164\n",
      "Train size: [400] hidden size: [14] trial: 20, train_loss: 1.968690, test loss: 1.042288, bias2: 0.9546197056770325, variance: 0.08766835182905197\n",
      "Train size: [400] hidden size: [14] trial: 21, train_loss: 1.951545, test loss: 1.041533, bias2: 0.9523537158966064, variance: 0.0891796201467514\n",
      "Train size: [400] hidden size: [14] trial: 22, train_loss: 1.941774, test loss: 1.042086, bias2: 0.953193187713623, variance: 0.08889282494783401\n",
      "Train size: [400] hidden size: [14] trial: 23, train_loss: 1.946537, test loss: 1.041383, bias2: 0.9544956684112549, variance: 0.08688738942146301\n",
      "Train size: [400] hidden size: [14] trial: 24, train_loss: 1.943891, test loss: 1.040682, bias2: 0.9550988674163818, variance: 0.08558334410190582\n",
      "Train size: [400] hidden size: [14] trial: 25, train_loss: 1.947496, test loss: 1.040248, bias2: 0.9561735391616821, variance: 0.08407462388277054\n",
      "Train size: [400] hidden size: [14] trial: 26, train_loss: 1.941385, test loss: 1.038813, bias2: 0.9564796686172485, variance: 0.08233332633972168\n",
      "Train size: [400] hidden size: [14] trial: 27, train_loss: 1.935713, test loss: 1.038004, bias2: 0.9550029635429382, variance: 0.08300072699785233\n",
      "Train size: [400] hidden size: [14] trial: 28, train_loss: 1.937028, test loss: 1.037198, bias2: 0.9529460668563843, variance: 0.08425237238407135\n",
      "Train size: [400] hidden size: [14] trial: 29, train_loss: 1.932331, test loss: 1.038004, bias2: 0.9523591995239258, variance: 0.08564484864473343\n",
      "Train size: [400] hidden size: [14] trial: 30, train_loss: 1.932568, test loss: 1.039658, bias2: 0.9508243203163147, variance: 0.08883349597454071\n",
      "Train size: [400] hidden size: [14] trial: 31, train_loss: 1.930691, test loss: 1.038899, bias2: 0.9511862397193909, variance: 0.08771306276321411\n",
      "Train size: [400] hidden size: [14] trial: 32, train_loss: 1.934726, test loss: 1.040736, bias2: 0.9513352513313293, variance: 0.08940119296312332\n",
      "Train size: [400] hidden size: [14] trial: 33, train_loss: 1.932752, test loss: 1.040548, bias2: 0.9509623050689697, variance: 0.08958589285612106\n",
      "Train size: [400] hidden size: [14] trial: 34, train_loss: 1.930678, test loss: 1.040797, bias2: 0.9508815407752991, variance: 0.0899152159690857\n",
      "Train size: [400] hidden size: [14] trial: 35, train_loss: 1.929106, test loss: 1.042504, bias2: 0.9521905183792114, variance: 0.09031376987695694\n",
      "Train size: [400] hidden size: [14] trial: 36, train_loss: 1.923145, test loss: 1.043286, bias2: 0.9531673192977905, variance: 0.09011861681938171\n",
      "Train size: [400] hidden size: [14] trial: 37, train_loss: 1.920844, test loss: 1.042676, bias2: 0.9524420499801636, variance: 0.0902344137430191\n",
      "Train size: [400] hidden size: [14] trial: 38, train_loss: 1.919336, test loss: 1.043835, bias2: 0.9537163376808167, variance: 0.09011882543563843\n",
      "Train size: [400] hidden size: [14] trial: 39, train_loss: 1.921492, test loss: 1.043781, bias2: 0.9540202021598816, variance: 0.08976107090711594\n",
      "Train size: [400] hidden size: [14] trial: 40, train_loss: 1.924083, test loss: 1.043099, bias2: 0.9544531106948853, variance: 0.08864548802375793\n",
      "Train size: [400] hidden size: [14] trial: 41, train_loss: 1.925519, test loss: 1.043844, bias2: 0.9538189768791199, variance: 0.09002454578876495\n",
      "Train size: [400] hidden size: [14] trial: 42, train_loss: 1.920506, test loss: 1.042323, bias2: 0.9530906677246094, variance: 0.08923245966434479\n",
      "Train size: [400] hidden size: [14] trial: 43, train_loss: 1.917703, test loss: 1.042026, bias2: 0.9521223902702332, variance: 0.08990355581045151\n",
      "Train size: [400] hidden size: [14] trial: 44, train_loss: 1.920671, test loss: 1.041108, bias2: 0.9516980648040771, variance: 0.08941039443016052\n",
      "Train size: [400] hidden size: [14] trial: 45, train_loss: 1.919052, test loss: 1.041487, bias2: 0.9524180889129639, variance: 0.08906841278076172\n",
      "Train size: [400] hidden size: [14] trial: 46, train_loss: 1.918050, test loss: 1.041649, bias2: 0.953234851360321, variance: 0.08841388672590256\n",
      "Train size: [400] hidden size: [14] trial: 47, train_loss: 1.919870, test loss: 1.041749, bias2: 0.9534844160079956, variance: 0.08826425671577454\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [14] trial: 48, train_loss: 1.918895, test loss: 1.041708, bias2: 0.9529889225959778, variance: 0.0887192115187645\n",
      "Train size: [400] hidden size: [14] trial: 49, train_loss: 1.918682, test loss: 1.040974, bias2: 0.9513013958930969, variance: 0.08967237174510956\n",
      "##################################################\n",
      "Train size: [400] hidden size: [16] trial: 0, train_loss: 2.034949, test loss: 1.030106, bias2: 1.0301059484481812, variance: 1.9462739753173253e-10\n",
      "Train size: [400] hidden size: [16] trial: 1, train_loss: 1.940738, test loss: 1.052762, bias2: 0.9866436719894409, variance: 0.06611838191747665\n",
      "Train size: [400] hidden size: [16] trial: 2, train_loss: 1.923180, test loss: 1.054273, bias2: 0.9540396332740784, variance: 0.10023301839828491\n",
      "Train size: [400] hidden size: [16] trial: 3, train_loss: 1.963465, test loss: 1.056143, bias2: 0.9498424530029297, variance: 0.10630038380622864\n",
      "Train size: [400] hidden size: [16] trial: 4, train_loss: 1.938267, test loss: 1.050179, bias2: 0.9405637979507446, variance: 0.10961545258760452\n",
      "Train size: [400] hidden size: [16] trial: 5, train_loss: 1.946941, test loss: 1.055294, bias2: 0.9375250935554504, variance: 0.11776943504810333\n",
      "Train size: [400] hidden size: [16] trial: 6, train_loss: 1.920137, test loss: 1.054969, bias2: 0.9361574053764343, variance: 0.11881178617477417\n",
      "Train size: [400] hidden size: [16] trial: 7, train_loss: 1.908828, test loss: 1.053381, bias2: 0.9353160262107849, variance: 0.11806482076644897\n",
      "Train size: [400] hidden size: [16] trial: 8, train_loss: 1.903606, test loss: 1.049292, bias2: 0.937593400478363, variance: 0.11169834434986115\n",
      "Train size: [400] hidden size: [16] trial: 9, train_loss: 1.902138, test loss: 1.056286, bias2: 0.9397075772285461, variance: 0.1165786162018776\n",
      "Train size: [400] hidden size: [16] trial: 10, train_loss: 1.917877, test loss: 1.053556, bias2: 0.9409060478210449, variance: 0.11264955252408981\n",
      "Train size: [400] hidden size: [16] trial: 11, train_loss: 1.910771, test loss: 1.050757, bias2: 0.9404324293136597, variance: 0.11032477021217346\n",
      "Train size: [400] hidden size: [16] trial: 12, train_loss: 1.929381, test loss: 1.050212, bias2: 0.9436553716659546, variance: 0.10655689984560013\n",
      "Train size: [400] hidden size: [16] trial: 13, train_loss: 1.921640, test loss: 1.046860, bias2: 0.9386788606643677, variance: 0.10818148404359818\n",
      "Train size: [400] hidden size: [16] trial: 14, train_loss: 1.932294, test loss: 1.046077, bias2: 0.9387049078941345, variance: 0.1073722243309021\n",
      "Train size: [400] hidden size: [16] trial: 15, train_loss: 1.933379, test loss: 1.048352, bias2: 0.9373683333396912, variance: 0.11098355799913406\n",
      "Train size: [400] hidden size: [16] trial: 16, train_loss: 1.913766, test loss: 1.049256, bias2: 0.9354453682899475, variance: 0.1138104796409607\n",
      "Train size: [400] hidden size: [16] trial: 17, train_loss: 1.921533, test loss: 1.047993, bias2: 0.9352787733078003, variance: 0.11271403729915619\n",
      "Train size: [400] hidden size: [16] trial: 18, train_loss: 1.914050, test loss: 1.049987, bias2: 0.9358299374580383, variance: 0.11415687948465347\n",
      "Train size: [400] hidden size: [16] trial: 19, train_loss: 1.914607, test loss: 1.049998, bias2: 0.9366803169250488, variance: 0.11331772059202194\n",
      "Train size: [400] hidden size: [16] trial: 20, train_loss: 1.910002, test loss: 1.050297, bias2: 0.9363803267478943, variance: 0.11391644179821014\n",
      "Train size: [400] hidden size: [16] trial: 21, train_loss: 1.907534, test loss: 1.050119, bias2: 0.9353610873222351, variance: 0.11475831270217896\n",
      "Train size: [400] hidden size: [16] trial: 22, train_loss: 1.919915, test loss: 1.047962, bias2: 0.9349276423454285, variance: 0.11303479969501495\n",
      "Train size: [400] hidden size: [16] trial: 23, train_loss: 1.914018, test loss: 1.049469, bias2: 0.9353803992271423, variance: 0.11408821493387222\n",
      "Train size: [400] hidden size: [16] trial: 24, train_loss: 1.918464, test loss: 1.048269, bias2: 0.9368230700492859, variance: 0.1114455834031105\n",
      "Train size: [400] hidden size: [16] trial: 25, train_loss: 1.911309, test loss: 1.050215, bias2: 0.9358614683151245, variance: 0.11435308307409286\n",
      "Train size: [400] hidden size: [16] trial: 26, train_loss: 1.908059, test loss: 1.050576, bias2: 0.9377540349960327, variance: 0.11282157897949219\n",
      "Train size: [400] hidden size: [16] trial: 27, train_loss: 1.907936, test loss: 1.052094, bias2: 0.9389115571975708, variance: 0.11318252235651016\n",
      "Train size: [400] hidden size: [16] trial: 28, train_loss: 1.910594, test loss: 1.052111, bias2: 0.9394721984863281, variance: 0.11263833194971085\n",
      "Train size: [400] hidden size: [16] trial: 29, train_loss: 1.905418, test loss: 1.051276, bias2: 0.9388448596000671, variance: 0.1124308779835701\n",
      "Train size: [400] hidden size: [16] trial: 30, train_loss: 1.906075, test loss: 1.050075, bias2: 0.9387701153755188, variance: 0.11130448430776596\n",
      "Train size: [400] hidden size: [16] trial: 31, train_loss: 1.902592, test loss: 1.050593, bias2: 0.9387449026107788, variance: 0.11184832453727722\n",
      "Train size: [400] hidden size: [16] trial: 32, train_loss: 1.899057, test loss: 1.049700, bias2: 0.9381763935089111, variance: 0.11152376979589462\n",
      "Train size: [400] hidden size: [16] trial: 33, train_loss: 1.897928, test loss: 1.051322, bias2: 0.9379751682281494, variance: 0.11334683746099472\n",
      "Train size: [400] hidden size: [16] trial: 34, train_loss: 1.889572, test loss: 1.052642, bias2: 0.9380860328674316, variance: 0.11455558985471725\n",
      "Train size: [400] hidden size: [16] trial: 35, train_loss: 1.891456, test loss: 1.053555, bias2: 0.9380691051483154, variance: 0.1154862493276596\n",
      "Train size: [400] hidden size: [16] trial: 36, train_loss: 1.889276, test loss: 1.053619, bias2: 0.9374526143074036, variance: 0.11616654694080353\n",
      "Train size: [400] hidden size: [16] trial: 37, train_loss: 1.888116, test loss: 1.054598, bias2: 0.9374855756759644, variance: 0.11711263656616211\n",
      "Train size: [400] hidden size: [16] trial: 38, train_loss: 1.894855, test loss: 1.054800, bias2: 0.9381700158119202, variance: 0.11663015186786652\n",
      "Train size: [400] hidden size: [16] trial: 39, train_loss: 1.897921, test loss: 1.054762, bias2: 0.9366848468780518, variance: 0.11807738244533539\n",
      "Train size: [400] hidden size: [16] trial: 40, train_loss: 1.897506, test loss: 1.054843, bias2: 0.9371490478515625, variance: 0.11769368499517441\n",
      "Train size: [400] hidden size: [16] trial: 41, train_loss: 1.902558, test loss: 1.055392, bias2: 0.9379277229309082, variance: 0.11746393889188766\n",
      "Train size: [400] hidden size: [16] trial: 42, train_loss: 1.899337, test loss: 1.054157, bias2: 0.9380251169204712, variance: 0.11613200604915619\n",
      "Train size: [400] hidden size: [16] trial: 43, train_loss: 1.897274, test loss: 1.053356, bias2: 0.9374480247497559, variance: 0.11590754240751266\n",
      "Train size: [400] hidden size: [16] trial: 44, train_loss: 1.896197, test loss: 1.052334, bias2: 0.9374925494194031, variance: 0.1148417517542839\n",
      "Train size: [400] hidden size: [16] trial: 45, train_loss: 1.896686, test loss: 1.051527, bias2: 0.9378863573074341, variance: 0.1136406660079956\n",
      "Train size: [400] hidden size: [16] trial: 46, train_loss: 1.894988, test loss: 1.052035, bias2: 0.9378114342689514, variance: 0.11422307044267654\n",
      "Train size: [400] hidden size: [16] trial: 47, train_loss: 1.893152, test loss: 1.052202, bias2: 0.9386438727378845, variance: 0.11355773359537125\n",
      "Train size: [400] hidden size: [16] trial: 48, train_loss: 1.898136, test loss: 1.052641, bias2: 0.9390243887901306, variance: 0.11361652612686157\n",
      "Train size: [400] hidden size: [16] trial: 49, train_loss: 1.896004, test loss: 1.053710, bias2: 0.9393903613090515, variance: 0.11431988328695297\n",
      "##################################################\n",
      "Train size: [400] hidden size: [19] trial: 0, train_loss: 2.159072, test loss: 1.075465, bias2: 1.0754646062850952, variance: -8.758233027705842e-10\n",
      "Train size: [400] hidden size: [19] trial: 1, train_loss: 2.044032, test loss: 1.077110, bias2: 0.9990731477737427, variance: 0.07803729176521301\n",
      "Train size: [400] hidden size: [19] trial: 2, train_loss: 2.009836, test loss: 1.077344, bias2: 0.9771429300308228, variance: 0.10020110011100769\n",
      "Train size: [400] hidden size: [19] trial: 3, train_loss: 1.950809, test loss: 1.077758, bias2: 0.9669399261474609, variance: 0.11081825941801071\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [19] trial: 4, train_loss: 1.932670, test loss: 1.082758, bias2: 0.9595791697502136, variance: 0.12317924946546555\n",
      "Train size: [400] hidden size: [19] trial: 5, train_loss: 1.957637, test loss: 1.076809, bias2: 0.9568336009979248, variance: 0.11997582018375397\n",
      "Train size: [400] hidden size: [19] trial: 6, train_loss: 1.945558, test loss: 1.072054, bias2: 0.952189564704895, variance: 0.11986467242240906\n",
      "Train size: [400] hidden size: [19] trial: 7, train_loss: 1.939981, test loss: 1.067962, bias2: 0.9461508989334106, variance: 0.1218113973736763\n",
      "Train size: [400] hidden size: [19] trial: 8, train_loss: 1.920076, test loss: 1.070828, bias2: 0.944240927696228, variance: 0.12658679485321045\n",
      "Train size: [400] hidden size: [19] trial: 9, train_loss: 1.920877, test loss: 1.067551, bias2: 0.944179117679596, variance: 0.1233721598982811\n",
      "Train size: [400] hidden size: [19] trial: 10, train_loss: 1.921888, test loss: 1.066343, bias2: 0.9419024586677551, variance: 0.12444086372852325\n",
      "Train size: [400] hidden size: [19] trial: 11, train_loss: 1.920323, test loss: 1.063129, bias2: 0.9438095092773438, variance: 0.11931929737329483\n",
      "Train size: [400] hidden size: [19] trial: 12, train_loss: 1.932277, test loss: 1.061859, bias2: 0.9403319358825684, variance: 0.12152710556983948\n",
      "Train size: [400] hidden size: [19] trial: 13, train_loss: 1.921540, test loss: 1.060615, bias2: 0.939775288105011, variance: 0.12083979696035385\n",
      "Train size: [400] hidden size: [19] trial: 14, train_loss: 1.925019, test loss: 1.057860, bias2: 0.938226580619812, variance: 0.11963357776403427\n",
      "Train size: [400] hidden size: [19] trial: 15, train_loss: 1.901335, test loss: 1.056305, bias2: 0.9364683032035828, variance: 0.11983661353588104\n",
      "Train size: [400] hidden size: [19] trial: 16, train_loss: 1.895442, test loss: 1.054196, bias2: 0.9328131079673767, variance: 0.12138278782367706\n",
      "Train size: [400] hidden size: [19] trial: 17, train_loss: 1.911796, test loss: 1.055650, bias2: 0.9333372116088867, variance: 0.12231255322694778\n",
      "Train size: [400] hidden size: [19] trial: 18, train_loss: 1.895044, test loss: 1.055925, bias2: 0.9346060156822205, variance: 0.1213192492723465\n",
      "Train size: [400] hidden size: [19] trial: 19, train_loss: 1.889973, test loss: 1.055666, bias2: 0.9349412322044373, variance: 0.1207251027226448\n",
      "Train size: [400] hidden size: [19] trial: 20, train_loss: 1.889179, test loss: 1.056508, bias2: 0.9365150928497314, variance: 0.11999309808015823\n",
      "Train size: [400] hidden size: [19] trial: 21, train_loss: 1.887739, test loss: 1.058918, bias2: 0.9363308548927307, variance: 0.12258680909872055\n",
      "Train size: [400] hidden size: [19] trial: 22, train_loss: 1.888181, test loss: 1.059116, bias2: 0.9382674694061279, variance: 0.1208481639623642\n",
      "Train size: [400] hidden size: [19] trial: 23, train_loss: 1.879522, test loss: 1.057630, bias2: 0.938108503818512, variance: 0.11952109634876251\n",
      "Train size: [400] hidden size: [19] trial: 24, train_loss: 1.881683, test loss: 1.056623, bias2: 0.9380276799201965, variance: 0.11859507858753204\n",
      "Train size: [400] hidden size: [19] trial: 25, train_loss: 1.878110, test loss: 1.057944, bias2: 0.9378617405891418, variance: 0.12008220702409744\n",
      "Train size: [400] hidden size: [19] trial: 26, train_loss: 1.878450, test loss: 1.056540, bias2: 0.9391271471977234, variance: 0.11741262674331665\n",
      "Train size: [400] hidden size: [19] trial: 27, train_loss: 1.882885, test loss: 1.057021, bias2: 0.9412737488746643, variance: 0.11574764549732208\n",
      "Train size: [400] hidden size: [19] trial: 28, train_loss: 1.881058, test loss: 1.057532, bias2: 0.9412102103233337, variance: 0.11632140725851059\n",
      "Train size: [400] hidden size: [19] trial: 29, train_loss: 1.875493, test loss: 1.058733, bias2: 0.9417508840560913, variance: 0.1169823482632637\n",
      "Train size: [400] hidden size: [19] trial: 30, train_loss: 1.877036, test loss: 1.057570, bias2: 0.9406993985176086, variance: 0.1168702095746994\n",
      "Train size: [400] hidden size: [19] trial: 31, train_loss: 1.873864, test loss: 1.057348, bias2: 0.939276933670044, variance: 0.11807084083557129\n",
      "Train size: [400] hidden size: [19] trial: 32, train_loss: 1.871935, test loss: 1.057950, bias2: 0.9382665753364563, variance: 0.11968322098255157\n",
      "Train size: [400] hidden size: [19] trial: 33, train_loss: 1.872168, test loss: 1.057522, bias2: 0.9385576248168945, variance: 0.1189645528793335\n",
      "Train size: [400] hidden size: [19] trial: 34, train_loss: 1.871620, test loss: 1.058139, bias2: 0.9389747381210327, variance: 0.1191643700003624\n",
      "Train size: [400] hidden size: [19] trial: 35, train_loss: 1.868833, test loss: 1.057794, bias2: 0.9389669895172119, variance: 0.1188267171382904\n",
      "Train size: [400] hidden size: [19] trial: 36, train_loss: 1.873831, test loss: 1.057436, bias2: 0.9396529793739319, variance: 0.11778279393911362\n",
      "Train size: [400] hidden size: [19] trial: 37, train_loss: 1.873895, test loss: 1.056795, bias2: 0.9404036998748779, variance: 0.11639165878295898\n",
      "Train size: [400] hidden size: [19] trial: 38, train_loss: 1.874667, test loss: 1.055696, bias2: 0.9408164024353027, variance: 0.11487939953804016\n",
      "Train size: [400] hidden size: [19] trial: 39, train_loss: 1.869539, test loss: 1.056465, bias2: 0.9408053159713745, variance: 0.11565925180912018\n",
      "Train size: [400] hidden size: [19] trial: 40, train_loss: 1.873585, test loss: 1.056973, bias2: 0.9406653046607971, variance: 0.11630717664957047\n",
      "Train size: [400] hidden size: [19] trial: 41, train_loss: 1.872236, test loss: 1.056754, bias2: 0.9403235912322998, variance: 0.11643003672361374\n",
      "Train size: [400] hidden size: [19] trial: 42, train_loss: 1.876218, test loss: 1.055884, bias2: 0.9396754503250122, variance: 0.11620818078517914\n",
      "Train size: [400] hidden size: [19] trial: 43, train_loss: 1.878337, test loss: 1.055736, bias2: 0.940192461013794, variance: 0.11554339528083801\n",
      "Train size: [400] hidden size: [19] trial: 44, train_loss: 1.878653, test loss: 1.056810, bias2: 0.9397761821746826, variance: 0.11703358590602875\n",
      "Train size: [400] hidden size: [19] trial: 45, train_loss: 1.880104, test loss: 1.056963, bias2: 0.938664972782135, variance: 0.11829765141010284\n",
      "Train size: [400] hidden size: [19] trial: 46, train_loss: 1.878653, test loss: 1.056110, bias2: 0.9390208721160889, variance: 0.11708950251340866\n",
      "Train size: [400] hidden size: [19] trial: 47, train_loss: 1.875939, test loss: 1.055957, bias2: 0.9390770196914673, variance: 0.11688029021024704\n",
      "Train size: [400] hidden size: [19] trial: 48, train_loss: 1.873328, test loss: 1.055824, bias2: 0.9389172792434692, variance: 0.11690665036439896\n",
      "Train size: [400] hidden size: [19] trial: 49, train_loss: 1.875160, test loss: 1.055770, bias2: 0.9393283128738403, variance: 0.11644160747528076\n",
      "##################################################\n",
      "Train size: [400] hidden size: [22] trial: 0, train_loss: 1.809207, test loss: 1.046950, bias2: 1.046950101852417, variance: 3.4059796649721363e-10\n",
      "Train size: [400] hidden size: [22] trial: 1, train_loss: 1.866053, test loss: 1.053557, bias2: 0.9861587285995483, variance: 0.06739844381809235\n",
      "Train size: [400] hidden size: [22] trial: 2, train_loss: 1.908741, test loss: 1.047786, bias2: 0.9472318291664124, variance: 0.10055381059646606\n",
      "Train size: [400] hidden size: [22] trial: 3, train_loss: 1.937760, test loss: 1.059327, bias2: 0.9554383754730225, variance: 0.10388896614313126\n",
      "Train size: [400] hidden size: [22] trial: 4, train_loss: 1.944935, test loss: 1.063960, bias2: 0.9526325464248657, variance: 0.11132708191871643\n",
      "Train size: [400] hidden size: [22] trial: 5, train_loss: 1.908046, test loss: 1.061775, bias2: 0.9498336911201477, variance: 0.11194102466106415\n",
      "Train size: [400] hidden size: [22] trial: 6, train_loss: 1.890783, test loss: 1.064591, bias2: 0.9520078897476196, variance: 0.11258316785097122\n",
      "Train size: [400] hidden size: [22] trial: 7, train_loss: 1.886227, test loss: 1.066529, bias2: 0.9516890048980713, variance: 0.11483953148126602\n",
      "Train size: [400] hidden size: [22] trial: 8, train_loss: 1.894322, test loss: 1.069894, bias2: 0.951669454574585, variance: 0.11822453141212463\n",
      "Train size: [400] hidden size: [22] trial: 9, train_loss: 1.895210, test loss: 1.076614, bias2: 0.9526584148406982, variance: 0.1239553913474083\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [22] trial: 10, train_loss: 1.896693, test loss: 1.077871, bias2: 0.9508729577064514, variance: 0.12699787318706512\n",
      "Train size: [400] hidden size: [22] trial: 11, train_loss: 1.891512, test loss: 1.070263, bias2: 0.9452633857727051, variance: 0.12499915063381195\n",
      "Train size: [400] hidden size: [22] trial: 12, train_loss: 1.898489, test loss: 1.068191, bias2: 0.9455211758613586, variance: 0.12266963720321655\n",
      "Train size: [400] hidden size: [22] trial: 13, train_loss: 1.884461, test loss: 1.070286, bias2: 0.9468115568161011, variance: 0.12347424775362015\n",
      "Train size: [400] hidden size: [22] trial: 14, train_loss: 1.878179, test loss: 1.071509, bias2: 0.9472038149833679, variance: 0.12430555373430252\n",
      "Train size: [400] hidden size: [22] trial: 15, train_loss: 1.871652, test loss: 1.075024, bias2: 0.9426983594894409, variance: 0.13232599198818207\n",
      "Train size: [400] hidden size: [22] trial: 16, train_loss: 1.871734, test loss: 1.072604, bias2: 0.941687822341919, variance: 0.13091573119163513\n",
      "Train size: [400] hidden size: [22] trial: 17, train_loss: 1.873118, test loss: 1.076583, bias2: 0.9373013377189636, variance: 0.13928191363811493\n",
      "Train size: [400] hidden size: [22] trial: 18, train_loss: 1.867190, test loss: 1.074846, bias2: 0.9380574226379395, variance: 0.1367889791727066\n",
      "Train size: [400] hidden size: [22] trial: 19, train_loss: 1.868586, test loss: 1.076326, bias2: 0.9381429553031921, variance: 0.13818351924419403\n",
      "Train size: [400] hidden size: [22] trial: 20, train_loss: 1.868819, test loss: 1.077012, bias2: 0.938356876373291, variance: 0.13865554332733154\n",
      "Train size: [400] hidden size: [22] trial: 21, train_loss: 1.871226, test loss: 1.075551, bias2: 0.9386908411979675, variance: 0.13686007261276245\n",
      "Train size: [400] hidden size: [22] trial: 22, train_loss: 1.872139, test loss: 1.075681, bias2: 0.9376271367073059, variance: 0.13805371522903442\n",
      "Train size: [400] hidden size: [22] trial: 23, train_loss: 1.876366, test loss: 1.076598, bias2: 0.9378010034561157, variance: 0.13879719376564026\n",
      "Train size: [400] hidden size: [22] trial: 24, train_loss: 1.874345, test loss: 1.078427, bias2: 0.9353682994842529, variance: 0.1430583894252777\n",
      "Train size: [400] hidden size: [22] trial: 25, train_loss: 1.865641, test loss: 1.077801, bias2: 0.9344908595085144, variance: 0.14331059157848358\n",
      "Train size: [400] hidden size: [22] trial: 26, train_loss: 1.860605, test loss: 1.077069, bias2: 0.9344860911369324, variance: 0.1425824761390686\n",
      "Train size: [400] hidden size: [22] trial: 27, train_loss: 1.855136, test loss: 1.077217, bias2: 0.9352052211761475, variance: 0.14201223850250244\n",
      "Train size: [400] hidden size: [22] trial: 28, train_loss: 1.859571, test loss: 1.076461, bias2: 0.9326269626617432, variance: 0.14383414387702942\n",
      "Train size: [400] hidden size: [22] trial: 29, train_loss: 1.851191, test loss: 1.075770, bias2: 0.9336546659469604, variance: 0.14211584627628326\n",
      "Train size: [400] hidden size: [22] trial: 30, train_loss: 1.843787, test loss: 1.075477, bias2: 0.9320194721221924, variance: 0.14345763623714447\n",
      "Train size: [400] hidden size: [22] trial: 31, train_loss: 1.841260, test loss: 1.075777, bias2: 0.932319164276123, variance: 0.14345799386501312\n",
      "Train size: [400] hidden size: [22] trial: 32, train_loss: 1.845544, test loss: 1.075016, bias2: 0.9335408210754395, variance: 0.14147484302520752\n",
      "Train size: [400] hidden size: [22] trial: 33, train_loss: 1.838544, test loss: 1.075812, bias2: 0.9334663152694702, variance: 0.14234554767608643\n",
      "Train size: [400] hidden size: [22] trial: 34, train_loss: 1.835347, test loss: 1.075307, bias2: 0.9320383071899414, variance: 0.14326858520507812\n",
      "Train size: [400] hidden size: [22] trial: 35, train_loss: 1.831513, test loss: 1.078423, bias2: 0.9317442774772644, variance: 0.14667896926403046\n",
      "Train size: [400] hidden size: [22] trial: 36, train_loss: 1.830479, test loss: 1.078843, bias2: 0.9302918910980225, variance: 0.14855121076107025\n",
      "Train size: [400] hidden size: [22] trial: 37, train_loss: 1.827774, test loss: 1.078572, bias2: 0.9300762414932251, variance: 0.14849552512168884\n",
      "Train size: [400] hidden size: [22] trial: 38, train_loss: 1.824040, test loss: 1.078068, bias2: 0.9293797612190247, variance: 0.1486881524324417\n",
      "Train size: [400] hidden size: [22] trial: 39, train_loss: 1.826899, test loss: 1.077436, bias2: 0.9301496148109436, variance: 0.14728660881519318\n",
      "Train size: [400] hidden size: [22] trial: 40, train_loss: 1.827568, test loss: 1.077519, bias2: 0.9301774501800537, variance: 0.14734187722206116\n",
      "Train size: [400] hidden size: [22] trial: 41, train_loss: 1.824635, test loss: 1.077041, bias2: 0.9291322231292725, variance: 0.1479083001613617\n",
      "Train size: [400] hidden size: [22] trial: 42, train_loss: 1.825797, test loss: 1.076154, bias2: 0.928835391998291, variance: 0.14731839299201965\n",
      "Train size: [400] hidden size: [22] trial: 43, train_loss: 1.829452, test loss: 1.076158, bias2: 0.9289361238479614, variance: 0.14722204208374023\n",
      "Train size: [400] hidden size: [22] trial: 44, train_loss: 1.835827, test loss: 1.076808, bias2: 0.928642988204956, variance: 0.14816537499427795\n",
      "Train size: [400] hidden size: [22] trial: 45, train_loss: 1.839171, test loss: 1.076099, bias2: 0.9297271370887756, variance: 0.14637213945388794\n",
      "Train size: [400] hidden size: [22] trial: 46, train_loss: 1.841769, test loss: 1.075339, bias2: 0.929775595664978, variance: 0.14556387066841125\n",
      "Train size: [400] hidden size: [22] trial: 47, train_loss: 1.842199, test loss: 1.075058, bias2: 0.9272974729537964, variance: 0.147760272026062\n",
      "Train size: [400] hidden size: [22] trial: 48, train_loss: 1.838256, test loss: 1.074912, bias2: 0.9256080389022827, variance: 0.14930376410484314\n",
      "Train size: [400] hidden size: [22] trial: 49, train_loss: 1.841016, test loss: 1.075403, bias2: 0.9250142574310303, variance: 0.1503891944885254\n",
      "##################################################\n",
      "Train size: [400] hidden size: [25] trial: 0, train_loss: 1.772196, test loss: 1.000319, bias2: 1.0003185272216797, variance: 0.0\n",
      "Train size: [400] hidden size: [25] trial: 1, train_loss: 1.840135, test loss: 1.064579, bias2: 0.9782770276069641, variance: 0.08630246669054031\n",
      "Train size: [400] hidden size: [25] trial: 2, train_loss: 1.966087, test loss: 1.080158, bias2: 0.9612239003181458, variance: 0.11893363296985626\n",
      "Train size: [400] hidden size: [25] trial: 3, train_loss: 1.920040, test loss: 1.089970, bias2: 0.9586165547370911, variance: 0.13135306537151337\n",
      "Train size: [400] hidden size: [25] trial: 4, train_loss: 1.920898, test loss: 1.098744, bias2: 0.9483761787414551, variance: 0.15036776661872864\n",
      "Train size: [400] hidden size: [25] trial: 5, train_loss: 1.909909, test loss: 1.097207, bias2: 0.9391644597053528, variance: 0.15804235637187958\n",
      "Train size: [400] hidden size: [25] trial: 6, train_loss: 1.927004, test loss: 1.095870, bias2: 0.9350255727767944, variance: 0.1608441025018692\n",
      "Train size: [400] hidden size: [25] trial: 7, train_loss: 1.929480, test loss: 1.093704, bias2: 0.9279291033744812, variance: 0.1657753735780716\n",
      "Train size: [400] hidden size: [25] trial: 8, train_loss: 1.907136, test loss: 1.095229, bias2: 0.925325870513916, variance: 0.16990293562412262\n",
      "Train size: [400] hidden size: [25] trial: 9, train_loss: 1.901520, test loss: 1.092412, bias2: 0.9214886426925659, variance: 0.17092345654964447\n",
      "Train size: [400] hidden size: [25] trial: 10, train_loss: 1.929515, test loss: 1.089774, bias2: 0.9207003116607666, variance: 0.16907323896884918\n",
      "Train size: [400] hidden size: [25] trial: 11, train_loss: 1.923425, test loss: 1.095009, bias2: 0.9232177734375, variance: 0.17179130017757416\n",
      "Train size: [400] hidden size: [25] trial: 12, train_loss: 1.904165, test loss: 1.096626, bias2: 0.9215725064277649, variance: 0.17505353689193726\n",
      "Train size: [400] hidden size: [25] trial: 13, train_loss: 1.896558, test loss: 1.096772, bias2: 0.921146035194397, variance: 0.17562638223171234\n",
      "Train size: [400] hidden size: [25] trial: 14, train_loss: 1.893306, test loss: 1.096568, bias2: 0.919890284538269, variance: 0.1766776740550995\n",
      "Train size: [400] hidden size: [25] trial: 15, train_loss: 1.904564, test loss: 1.092756, bias2: 0.9219018220901489, variance: 0.17085400223731995\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [25] trial: 16, train_loss: 1.911323, test loss: 1.091878, bias2: 0.9247862100601196, variance: 0.16709232330322266\n",
      "Train size: [400] hidden size: [25] trial: 17, train_loss: 1.913432, test loss: 1.091901, bias2: 0.9246951341629028, variance: 0.16720589995384216\n",
      "Train size: [400] hidden size: [25] trial: 18, train_loss: 1.896204, test loss: 1.090698, bias2: 0.9245274662971497, variance: 0.1661704033613205\n",
      "Train size: [400] hidden size: [25] trial: 19, train_loss: 1.896324, test loss: 1.089330, bias2: 0.924774706363678, variance: 0.1645553559064865\n",
      "Train size: [400] hidden size: [25] trial: 20, train_loss: 1.893530, test loss: 1.091323, bias2: 0.9254447221755981, variance: 0.1658782660961151\n",
      "Train size: [400] hidden size: [25] trial: 21, train_loss: 1.892900, test loss: 1.090193, bias2: 0.9237769842147827, variance: 0.16641603410243988\n",
      "Train size: [400] hidden size: [25] trial: 22, train_loss: 1.890962, test loss: 1.090205, bias2: 0.9231457710266113, variance: 0.16705940663814545\n",
      "Train size: [400] hidden size: [25] trial: 23, train_loss: 1.877174, test loss: 1.088352, bias2: 0.9217469096183777, variance: 0.16660469770431519\n",
      "Train size: [400] hidden size: [25] trial: 24, train_loss: 1.885697, test loss: 1.088976, bias2: 0.9212620854377747, variance: 0.16771359741687775\n",
      "Train size: [400] hidden size: [25] trial: 25, train_loss: 1.885801, test loss: 1.086760, bias2: 0.9177693128585815, variance: 0.16899064183235168\n",
      "Train size: [400] hidden size: [25] trial: 26, train_loss: 1.883744, test loss: 1.086924, bias2: 0.9181928634643555, variance: 0.16873086988925934\n",
      "Train size: [400] hidden size: [25] trial: 27, train_loss: 1.885635, test loss: 1.086917, bias2: 0.9176385998725891, variance: 0.1692783236503601\n",
      "Train size: [400] hidden size: [25] trial: 28, train_loss: 1.880205, test loss: 1.086295, bias2: 0.9178494215011597, variance: 0.16844555735588074\n",
      "Train size: [400] hidden size: [25] trial: 29, train_loss: 1.872359, test loss: 1.086863, bias2: 0.9178197383880615, variance: 0.16904321312904358\n",
      "Train size: [400] hidden size: [25] trial: 30, train_loss: 1.865141, test loss: 1.084620, bias2: 0.9155863523483276, variance: 0.16903403401374817\n",
      "Train size: [400] hidden size: [25] trial: 31, train_loss: 1.868374, test loss: 1.086100, bias2: 0.9168747663497925, variance: 0.16922524571418762\n",
      "Train size: [400] hidden size: [25] trial: 32, train_loss: 1.863924, test loss: 1.087693, bias2: 0.9167361855506897, variance: 0.17095713317394257\n",
      "Train size: [400] hidden size: [25] trial: 33, train_loss: 1.865898, test loss: 1.087171, bias2: 0.917168378829956, variance: 0.17000268399715424\n",
      "Train size: [400] hidden size: [25] trial: 34, train_loss: 1.861577, test loss: 1.087342, bias2: 0.9170295596122742, variance: 0.17031295597553253\n",
      "Train size: [400] hidden size: [25] trial: 35, train_loss: 1.856047, test loss: 1.088837, bias2: 0.9141137599945068, variance: 0.1747230440378189\n",
      "Train size: [400] hidden size: [25] trial: 36, train_loss: 1.852042, test loss: 1.088420, bias2: 0.9125038385391235, variance: 0.1759166717529297\n",
      "Train size: [400] hidden size: [25] trial: 37, train_loss: 1.854531, test loss: 1.088602, bias2: 0.912775456905365, variance: 0.17582672834396362\n",
      "Train size: [400] hidden size: [25] trial: 38, train_loss: 1.852214, test loss: 1.088801, bias2: 0.91270911693573, variance: 0.17609164118766785\n",
      "Train size: [400] hidden size: [25] trial: 39, train_loss: 1.847588, test loss: 1.090081, bias2: 0.9125974178314209, variance: 0.1774837076663971\n",
      "Train size: [400] hidden size: [25] trial: 40, train_loss: 1.848133, test loss: 1.089632, bias2: 0.9119163155555725, variance: 0.1777152270078659\n",
      "Train size: [400] hidden size: [25] trial: 41, train_loss: 1.846222, test loss: 1.088642, bias2: 0.91084885597229, variance: 0.17779287695884705\n",
      "Train size: [400] hidden size: [25] trial: 42, train_loss: 1.845681, test loss: 1.088033, bias2: 0.9112898707389832, variance: 0.17674343287944794\n",
      "Train size: [400] hidden size: [25] trial: 43, train_loss: 1.845758, test loss: 1.088185, bias2: 0.9111112952232361, variance: 0.177073672413826\n",
      "Train size: [400] hidden size: [25] trial: 44, train_loss: 1.850121, test loss: 1.090116, bias2: 0.9109228849411011, variance: 0.17919349670410156\n",
      "Train size: [400] hidden size: [25] trial: 45, train_loss: 1.851634, test loss: 1.090849, bias2: 0.9109633564949036, variance: 0.17988519370555878\n",
      "Train size: [400] hidden size: [25] trial: 46, train_loss: 1.859020, test loss: 1.090557, bias2: 0.9114165306091309, variance: 0.179140105843544\n",
      "Train size: [400] hidden size: [25] trial: 47, train_loss: 1.856395, test loss: 1.091711, bias2: 0.9117666482925415, variance: 0.17994438111782074\n",
      "Train size: [400] hidden size: [25] trial: 48, train_loss: 1.860320, test loss: 1.092936, bias2: 0.9112256765365601, variance: 0.18171046674251556\n",
      "Train size: [400] hidden size: [25] trial: 49, train_loss: 1.860548, test loss: 1.092511, bias2: 0.9121975898742676, variance: 0.1803135722875595\n",
      "##################################################\n",
      "Train size: [400] hidden size: [29] trial: 0, train_loss: 1.856369, test loss: 1.111572, bias2: 1.1115721464157104, variance: -1.0704507280578923e-09\n",
      "Train size: [400] hidden size: [29] trial: 1, train_loss: 1.765588, test loss: 1.087527, bias2: 0.9891210794448853, variance: 0.09840606898069382\n",
      "Train size: [400] hidden size: [29] trial: 2, train_loss: 1.793046, test loss: 1.075615, bias2: 0.9443271160125732, variance: 0.13128778338432312\n",
      "Train size: [400] hidden size: [29] trial: 3, train_loss: 1.837133, test loss: 1.077784, bias2: 0.9299816489219666, variance: 0.14780193567276\n",
      "Train size: [400] hidden size: [29] trial: 4, train_loss: 1.829556, test loss: 1.077712, bias2: 0.9309813976287842, variance: 0.14673055708408356\n",
      "Train size: [400] hidden size: [29] trial: 5, train_loss: 1.814335, test loss: 1.076822, bias2: 0.9259042739868164, variance: 0.15091803669929504\n",
      "Train size: [400] hidden size: [29] trial: 6, train_loss: 1.803137, test loss: 1.078010, bias2: 0.913846492767334, variance: 0.16416345536708832\n",
      "Train size: [400] hidden size: [29] trial: 7, train_loss: 1.814116, test loss: 1.084416, bias2: 0.9133999347686768, variance: 0.17101573944091797\n",
      "Train size: [400] hidden size: [29] trial: 8, train_loss: 1.804157, test loss: 1.077360, bias2: 0.9088306427001953, variance: 0.16852964460849762\n",
      "Train size: [400] hidden size: [29] trial: 9, train_loss: 1.826013, test loss: 1.075634, bias2: 0.9050518870353699, variance: 0.1705823540687561\n",
      "Train size: [400] hidden size: [29] trial: 10, train_loss: 1.823713, test loss: 1.075029, bias2: 0.9051879048347473, variance: 0.169841468334198\n",
      "Train size: [400] hidden size: [29] trial: 11, train_loss: 1.840736, test loss: 1.074791, bias2: 0.9033937454223633, variance: 0.17139768600463867\n",
      "Train size: [400] hidden size: [29] trial: 12, train_loss: 1.855411, test loss: 1.076352, bias2: 0.9006808400154114, variance: 0.17567114531993866\n",
      "Train size: [400] hidden size: [29] trial: 13, train_loss: 1.859614, test loss: 1.073190, bias2: 0.9018990993499756, variance: 0.17129111289978027\n",
      "Train size: [400] hidden size: [29] trial: 14, train_loss: 1.853254, test loss: 1.072891, bias2: 0.8957241177558899, variance: 0.17716725170612335\n",
      "Train size: [400] hidden size: [29] trial: 15, train_loss: 1.848013, test loss: 1.078243, bias2: 0.9009894132614136, variance: 0.17725369334220886\n",
      "Train size: [400] hidden size: [29] trial: 16, train_loss: 1.824751, test loss: 1.080455, bias2: 0.8996466398239136, variance: 0.1808086484670639\n",
      "Train size: [400] hidden size: [29] trial: 17, train_loss: 1.829188, test loss: 1.079678, bias2: 0.8947764039039612, variance: 0.184901162981987\n",
      "Train size: [400] hidden size: [29] trial: 18, train_loss: 1.823237, test loss: 1.082828, bias2: 0.8946897387504578, variance: 0.18813808262348175\n",
      "Train size: [400] hidden size: [29] trial: 19, train_loss: 1.810869, test loss: 1.087825, bias2: 0.8968421816825867, variance: 0.19098322093486786\n",
      "Train size: [400] hidden size: [29] trial: 20, train_loss: 1.805489, test loss: 1.089125, bias2: 0.8968446254730225, variance: 0.19228044152259827\n",
      "Train size: [400] hidden size: [29] trial: 21, train_loss: 1.810860, test loss: 1.090550, bias2: 0.8940662145614624, variance: 0.19648364186286926\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [29] trial: 22, train_loss: 1.805862, test loss: 1.087591, bias2: 0.890516459941864, variance: 0.19707472622394562\n",
      "Train size: [400] hidden size: [29] trial: 23, train_loss: 1.808683, test loss: 1.086060, bias2: 0.8913939595222473, variance: 0.19466586410999298\n",
      "Train size: [400] hidden size: [29] trial: 24, train_loss: 1.808459, test loss: 1.084422, bias2: 0.8908202052116394, variance: 0.19360201060771942\n",
      "Train size: [400] hidden size: [29] trial: 25, train_loss: 1.809486, test loss: 1.088202, bias2: 0.8901873826980591, variance: 0.19801458716392517\n",
      "Train size: [400] hidden size: [29] trial: 26, train_loss: 1.809922, test loss: 1.093636, bias2: 0.8920230269432068, variance: 0.20161350071430206\n",
      "Train size: [400] hidden size: [29] trial: 27, train_loss: 1.815591, test loss: 1.093170, bias2: 0.8927009105682373, variance: 0.2004694789648056\n",
      "Train size: [400] hidden size: [29] trial: 28, train_loss: 1.813873, test loss: 1.090635, bias2: 0.8897970914840698, variance: 0.20083805918693542\n",
      "Train size: [400] hidden size: [29] trial: 29, train_loss: 1.819691, test loss: 1.088765, bias2: 0.8884080648422241, variance: 0.2003573179244995\n",
      "Train size: [400] hidden size: [29] trial: 30, train_loss: 1.819157, test loss: 1.089303, bias2: 0.8902854919433594, variance: 0.19901761412620544\n",
      "Train size: [400] hidden size: [29] trial: 31, train_loss: 1.818587, test loss: 1.088900, bias2: 0.8902384042739868, variance: 0.19866123795509338\n",
      "Train size: [400] hidden size: [29] trial: 32, train_loss: 1.822940, test loss: 1.088722, bias2: 0.8881914019584656, variance: 0.20053046941757202\n",
      "Train size: [400] hidden size: [29] trial: 33, train_loss: 1.823889, test loss: 1.089923, bias2: 0.8897395133972168, variance: 0.20018362998962402\n",
      "Train size: [400] hidden size: [29] trial: 34, train_loss: 1.820435, test loss: 1.088725, bias2: 0.8891813158988953, variance: 0.1995440125465393\n",
      "Train size: [400] hidden size: [29] trial: 35, train_loss: 1.830780, test loss: 1.090341, bias2: 0.8907399773597717, variance: 0.19960133731365204\n",
      "Train size: [400] hidden size: [29] trial: 36, train_loss: 1.832417, test loss: 1.091463, bias2: 0.8920563459396362, variance: 0.19940707087516785\n",
      "Train size: [400] hidden size: [29] trial: 37, train_loss: 1.831572, test loss: 1.091571, bias2: 0.892807126045227, variance: 0.19876398146152496\n",
      "Train size: [400] hidden size: [29] trial: 38, train_loss: 1.832776, test loss: 1.093239, bias2: 0.8942593336105347, variance: 0.19897983968257904\n",
      "Train size: [400] hidden size: [29] trial: 39, train_loss: 1.827958, test loss: 1.094173, bias2: 0.8943650126457214, variance: 0.1998080462217331\n",
      "Train size: [400] hidden size: [29] trial: 40, train_loss: 1.827943, test loss: 1.094556, bias2: 0.8937379121780396, variance: 0.20081833004951477\n",
      "Train size: [400] hidden size: [29] trial: 41, train_loss: 1.820533, test loss: 1.096842, bias2: 0.8949056267738342, variance: 0.20193617045879364\n",
      "Train size: [400] hidden size: [29] trial: 42, train_loss: 1.818004, test loss: 1.095846, bias2: 0.8960921764373779, variance: 0.1997535228729248\n",
      "Train size: [400] hidden size: [29] trial: 43, train_loss: 1.818292, test loss: 1.096365, bias2: 0.8961666822433472, variance: 0.20019817352294922\n",
      "Train size: [400] hidden size: [29] trial: 44, train_loss: 1.813933, test loss: 1.097385, bias2: 0.8965492248535156, variance: 0.20083573460578918\n",
      "Train size: [400] hidden size: [29] trial: 45, train_loss: 1.812580, test loss: 1.097363, bias2: 0.8965954184532166, variance: 0.20076791942119598\n",
      "Train size: [400] hidden size: [29] trial: 46, train_loss: 1.813559, test loss: 1.096868, bias2: 0.8968811631202698, variance: 0.19998697936534882\n",
      "Train size: [400] hidden size: [29] trial: 47, train_loss: 1.811092, test loss: 1.096820, bias2: 0.8960329294204712, variance: 0.20078745484352112\n",
      "Train size: [400] hidden size: [29] trial: 48, train_loss: 1.813780, test loss: 1.097518, bias2: 0.895754337310791, variance: 0.20176337659358978\n",
      "Train size: [400] hidden size: [29] trial: 49, train_loss: 1.812552, test loss: 1.097762, bias2: 0.89524245262146, variance: 0.2025197595357895\n",
      "##################################################\n",
      "Train size: [400] hidden size: [33] trial: 0, train_loss: 1.832823, test loss: 1.127447, bias2: 1.1274473667144775, variance: 4.6710577628061856e-09\n",
      "Train size: [400] hidden size: [33] trial: 1, train_loss: 1.991820, test loss: 1.138454, bias2: 1.0196378231048584, variance: 0.11881629377603531\n",
      "Train size: [400] hidden size: [33] trial: 2, train_loss: 1.976308, test loss: 1.121873, bias2: 0.9629039764404297, variance: 0.15896880626678467\n",
      "Train size: [400] hidden size: [33] trial: 3, train_loss: 1.930558, test loss: 1.118778, bias2: 0.9412297010421753, variance: 0.17754875123500824\n",
      "Train size: [400] hidden size: [33] trial: 4, train_loss: 1.890167, test loss: 1.111185, bias2: 0.9187504053115845, variance: 0.19243445992469788\n",
      "Train size: [400] hidden size: [33] trial: 5, train_loss: 1.816063, test loss: 1.103893, bias2: 0.914480447769165, variance: 0.18941257894039154\n",
      "Train size: [400] hidden size: [33] trial: 6, train_loss: 1.821474, test loss: 1.117120, bias2: 0.9111137986183167, variance: 0.2060062438249588\n",
      "Train size: [400] hidden size: [33] trial: 7, train_loss: 1.834470, test loss: 1.119080, bias2: 0.9124782681465149, variance: 0.20660190284252167\n",
      "Train size: [400] hidden size: [33] trial: 8, train_loss: 1.808034, test loss: 1.127666, bias2: 0.9098446369171143, variance: 0.21782159805297852\n",
      "Train size: [400] hidden size: [33] trial: 9, train_loss: 1.793363, test loss: 1.128587, bias2: 0.9033136963844299, variance: 0.22527353465557098\n",
      "Train size: [400] hidden size: [33] trial: 10, train_loss: 1.792998, test loss: 1.124884, bias2: 0.8970984220504761, variance: 0.22778545320034027\n",
      "Train size: [400] hidden size: [33] trial: 11, train_loss: 1.799238, test loss: 1.125768, bias2: 0.8945125937461853, variance: 0.23125547170639038\n",
      "Train size: [400] hidden size: [33] trial: 12, train_loss: 1.797701, test loss: 1.122132, bias2: 0.8908785581588745, variance: 0.23125359416007996\n",
      "Train size: [400] hidden size: [33] trial: 13, train_loss: 1.810929, test loss: 1.120517, bias2: 0.8915579319000244, variance: 0.2289585918188095\n",
      "Train size: [400] hidden size: [33] trial: 14, train_loss: 1.810042, test loss: 1.117472, bias2: 0.8887022137641907, variance: 0.22876949608325958\n",
      "Train size: [400] hidden size: [33] trial: 15, train_loss: 1.819764, test loss: 1.118398, bias2: 0.8891685009002686, variance: 0.22922906279563904\n",
      "Train size: [400] hidden size: [33] trial: 16, train_loss: 1.816500, test loss: 1.116566, bias2: 0.8902914524078369, variance: 0.2262742668390274\n",
      "Train size: [400] hidden size: [33] trial: 17, train_loss: 1.806149, test loss: 1.115285, bias2: 0.8905994892120361, variance: 0.22468605637550354\n",
      "Train size: [400] hidden size: [33] trial: 18, train_loss: 1.807604, test loss: 1.114497, bias2: 0.8879663944244385, variance: 0.22653020918369293\n",
      "Train size: [400] hidden size: [33] trial: 19, train_loss: 1.827510, test loss: 1.113720, bias2: 0.8840922713279724, variance: 0.22962777316570282\n",
      "Train size: [400] hidden size: [33] trial: 20, train_loss: 1.821616, test loss: 1.114712, bias2: 0.8857698440551758, variance: 0.2289423644542694\n",
      "Train size: [400] hidden size: [33] trial: 21, train_loss: 1.821941, test loss: 1.119510, bias2: 0.8836848139762878, variance: 0.23582512140274048\n",
      "Train size: [400] hidden size: [33] trial: 22, train_loss: 1.813263, test loss: 1.122184, bias2: 0.8847050666809082, variance: 0.2374788522720337\n",
      "Train size: [400] hidden size: [33] trial: 23, train_loss: 1.814567, test loss: 1.121704, bias2: 0.8842324018478394, variance: 0.23747161030769348\n",
      "Train size: [400] hidden size: [33] trial: 24, train_loss: 1.816320, test loss: 1.120031, bias2: 0.8833460211753845, variance: 0.2366848587989807\n",
      "Train size: [400] hidden size: [33] trial: 25, train_loss: 1.813333, test loss: 1.122413, bias2: 0.8849355578422546, variance: 0.23747782409191132\n",
      "Train size: [400] hidden size: [33] trial: 26, train_loss: 1.818007, test loss: 1.122537, bias2: 0.8878207802772522, variance: 0.23471660912036896\n",
      "Train size: [400] hidden size: [33] trial: 27, train_loss: 1.819848, test loss: 1.120820, bias2: 0.8850491642951965, variance: 0.23577076196670532\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [33] trial: 28, train_loss: 1.822567, test loss: 1.126196, bias2: 0.8886629343032837, variance: 0.23753294348716736\n",
      "Train size: [400] hidden size: [33] trial: 29, train_loss: 1.823008, test loss: 1.127073, bias2: 0.8859987258911133, variance: 0.2410743087530136\n",
      "Train size: [400] hidden size: [33] trial: 30, train_loss: 1.818578, test loss: 1.125689, bias2: 0.885918915271759, variance: 0.23977035284042358\n",
      "Train size: [400] hidden size: [33] trial: 31, train_loss: 1.815885, test loss: 1.124488, bias2: 0.8856124877929688, variance: 0.2388756424188614\n",
      "Train size: [400] hidden size: [33] trial: 32, train_loss: 1.810448, test loss: 1.124306, bias2: 0.8843561410903931, variance: 0.23994968831539154\n",
      "Train size: [400] hidden size: [33] trial: 33, train_loss: 1.812605, test loss: 1.123245, bias2: 0.8831860423088074, variance: 0.24005873501300812\n",
      "Train size: [400] hidden size: [33] trial: 34, train_loss: 1.812387, test loss: 1.125856, bias2: 0.8842693567276001, variance: 0.2415863424539566\n",
      "Train size: [400] hidden size: [33] trial: 35, train_loss: 1.813372, test loss: 1.125870, bias2: 0.8850015997886658, variance: 0.24086840450763702\n",
      "Train size: [400] hidden size: [33] trial: 36, train_loss: 1.813801, test loss: 1.124086, bias2: 0.8843605518341064, variance: 0.23972555994987488\n",
      "Train size: [400] hidden size: [33] trial: 37, train_loss: 1.810711, test loss: 1.125121, bias2: 0.8851135969161987, variance: 0.24000728130340576\n",
      "Train size: [400] hidden size: [33] trial: 38, train_loss: 1.814346, test loss: 1.124769, bias2: 0.8852666020393372, variance: 0.23950262367725372\n",
      "Train size: [400] hidden size: [33] trial: 39, train_loss: 1.813409, test loss: 1.124864, bias2: 0.887529730796814, variance: 0.23733390867710114\n",
      "Train size: [400] hidden size: [33] trial: 40, train_loss: 1.816876, test loss: 1.123039, bias2: 0.887393593788147, variance: 0.23564563691616058\n",
      "Train size: [400] hidden size: [33] trial: 41, train_loss: 1.812111, test loss: 1.122981, bias2: 0.8881435394287109, variance: 0.23483693599700928\n",
      "Train size: [400] hidden size: [33] trial: 42, train_loss: 1.807491, test loss: 1.122578, bias2: 0.887340247631073, variance: 0.23523813486099243\n",
      "Train size: [400] hidden size: [33] trial: 43, train_loss: 1.808176, test loss: 1.120668, bias2: 0.8872016668319702, variance: 0.23346629738807678\n",
      "Train size: [400] hidden size: [33] trial: 44, train_loss: 1.805788, test loss: 1.122629, bias2: 0.8869261741638184, variance: 0.2357032299041748\n",
      "Train size: [400] hidden size: [33] trial: 45, train_loss: 1.804124, test loss: 1.121447, bias2: 0.8869690299034119, variance: 0.23447827994823456\n",
      "Train size: [400] hidden size: [33] trial: 46, train_loss: 1.802822, test loss: 1.122171, bias2: 0.8855095505714417, variance: 0.2366611212491989\n",
      "Train size: [400] hidden size: [33] trial: 47, train_loss: 1.803297, test loss: 1.121232, bias2: 0.8830865621566772, variance: 0.23814496397972107\n",
      "Train size: [400] hidden size: [33] trial: 48, train_loss: 1.799996, test loss: 1.120890, bias2: 0.8841173648834229, variance: 0.23677241802215576\n",
      "Train size: [400] hidden size: [33] trial: 49, train_loss: 1.799428, test loss: 1.121397, bias2: 0.8849930167198181, variance: 0.23640435934066772\n",
      "##################################################\n",
      "Train size: [400] hidden size: [38] trial: 0, train_loss: 1.648798, test loss: 1.165040, bias2: 1.1650397777557373, variance: -1.9462739753173253e-10\n",
      "Train size: [400] hidden size: [38] trial: 1, train_loss: 1.655108, test loss: 1.120977, bias2: 0.9901967644691467, variance: 0.1307803988456726\n",
      "Train size: [400] hidden size: [38] trial: 2, train_loss: 1.648684, test loss: 1.112462, bias2: 0.9475491046905518, variance: 0.16491247713565826\n",
      "Train size: [400] hidden size: [38] trial: 3, train_loss: 1.675736, test loss: 1.115704, bias2: 0.9312348961830139, variance: 0.1844688057899475\n",
      "Train size: [400] hidden size: [38] trial: 4, train_loss: 1.678506, test loss: 1.097840, bias2: 0.9053725004196167, variance: 0.1924678385257721\n",
      "Train size: [400] hidden size: [38] trial: 5, train_loss: 1.698300, test loss: 1.118193, bias2: 0.9145895838737488, variance: 0.20360298454761505\n",
      "Train size: [400] hidden size: [38] trial: 6, train_loss: 1.726421, test loss: 1.106602, bias2: 0.8978686332702637, variance: 0.20873381197452545\n",
      "Train size: [400] hidden size: [38] trial: 7, train_loss: 1.717828, test loss: 1.109472, bias2: 0.8967714309692383, variance: 0.21270081400871277\n",
      "Train size: [400] hidden size: [38] trial: 8, train_loss: 1.723578, test loss: 1.119222, bias2: 0.8979522585868835, variance: 0.2212696671485901\n",
      "Train size: [400] hidden size: [38] trial: 9, train_loss: 1.728586, test loss: 1.121354, bias2: 0.8920607566833496, variance: 0.2292935997247696\n",
      "Train size: [400] hidden size: [38] trial: 10, train_loss: 1.725575, test loss: 1.127476, bias2: 0.8917162418365479, variance: 0.23575976490974426\n",
      "Train size: [400] hidden size: [38] trial: 11, train_loss: 1.725977, test loss: 1.124227, bias2: 0.8788390755653381, variance: 0.2453874796628952\n",
      "Train size: [400] hidden size: [38] trial: 12, train_loss: 1.711004, test loss: 1.127276, bias2: 0.8833094835281372, variance: 0.24396666884422302\n",
      "Train size: [400] hidden size: [38] trial: 13, train_loss: 1.712805, test loss: 1.125709, bias2: 0.8774033188819885, variance: 0.24830526113510132\n",
      "Train size: [400] hidden size: [38] trial: 14, train_loss: 1.709231, test loss: 1.130183, bias2: 0.879993200302124, variance: 0.2501901388168335\n",
      "Train size: [400] hidden size: [38] trial: 15, train_loss: 1.708685, test loss: 1.141395, bias2: 0.8796205520629883, variance: 0.2617741823196411\n",
      "Train size: [400] hidden size: [38] trial: 16, train_loss: 1.722408, test loss: 1.140963, bias2: 0.8787602186203003, variance: 0.2622027099132538\n",
      "Train size: [400] hidden size: [38] trial: 17, train_loss: 1.731851, test loss: 1.137934, bias2: 0.8785727024078369, variance: 0.2593611180782318\n",
      "Train size: [400] hidden size: [38] trial: 18, train_loss: 1.720092, test loss: 1.140195, bias2: 0.8810134530067444, variance: 0.25918132066726685\n",
      "Train size: [400] hidden size: [38] trial: 19, train_loss: 1.719361, test loss: 1.139115, bias2: 0.8821607232093811, variance: 0.25695449113845825\n",
      "Train size: [400] hidden size: [38] trial: 20, train_loss: 1.715599, test loss: 1.140894, bias2: 0.8811385035514832, variance: 0.25975579023361206\n",
      "Train size: [400] hidden size: [38] trial: 21, train_loss: 1.707056, test loss: 1.138946, bias2: 0.8815490007400513, variance: 0.25739702582359314\n",
      "Train size: [400] hidden size: [38] trial: 22, train_loss: 1.707352, test loss: 1.141091, bias2: 0.8817279934883118, variance: 0.2593626379966736\n",
      "Train size: [400] hidden size: [38] trial: 23, train_loss: 1.709373, test loss: 1.141257, bias2: 0.8824587464332581, variance: 0.2587980628013611\n",
      "Train size: [400] hidden size: [38] trial: 24, train_loss: 1.707908, test loss: 1.142030, bias2: 0.8820689916610718, variance: 0.25996121764183044\n",
      "Train size: [400] hidden size: [38] trial: 25, train_loss: 1.713326, test loss: 1.144127, bias2: 0.8821840882301331, variance: 0.26194339990615845\n",
      "Train size: [400] hidden size: [38] trial: 26, train_loss: 1.712656, test loss: 1.143653, bias2: 0.8840630054473877, variance: 0.2595895528793335\n",
      "Train size: [400] hidden size: [38] trial: 27, train_loss: 1.708835, test loss: 1.147119, bias2: 0.8850457072257996, variance: 0.26207298040390015\n",
      "Train size: [400] hidden size: [38] trial: 28, train_loss: 1.713276, test loss: 1.145048, bias2: 0.8854339122772217, variance: 0.2596140205860138\n",
      "Train size: [400] hidden size: [38] trial: 29, train_loss: 1.722742, test loss: 1.147681, bias2: 0.8832166194915771, variance: 0.26446422934532166\n",
      "Train size: [400] hidden size: [38] trial: 30, train_loss: 1.723436, test loss: 1.146251, bias2: 0.8817254304885864, variance: 0.2645252048969269\n",
      "Train size: [400] hidden size: [38] trial: 31, train_loss: 1.735167, test loss: 1.146646, bias2: 0.8811646699905396, variance: 0.2654811441898346\n",
      "Train size: [400] hidden size: [38] trial: 32, train_loss: 1.738698, test loss: 1.145281, bias2: 0.8804574012756348, variance: 0.2648235559463501\n",
      "Train size: [400] hidden size: [38] trial: 33, train_loss: 1.737602, test loss: 1.145003, bias2: 0.8807723522186279, variance: 0.264230877161026\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [38] trial: 34, train_loss: 1.742480, test loss: 1.146483, bias2: 0.8814936876296997, variance: 0.2649894058704376\n",
      "Train size: [400] hidden size: [38] trial: 35, train_loss: 1.744034, test loss: 1.147877, bias2: 0.881135880947113, variance: 0.26674097776412964\n",
      "Train size: [400] hidden size: [38] trial: 36, train_loss: 1.744740, test loss: 1.149039, bias2: 0.8805026412010193, variance: 0.2685360312461853\n",
      "Train size: [400] hidden size: [38] trial: 37, train_loss: 1.747211, test loss: 1.149417, bias2: 0.878868579864502, variance: 0.2705487012863159\n",
      "Train size: [400] hidden size: [38] trial: 38, train_loss: 1.747452, test loss: 1.149326, bias2: 0.87633216381073, variance: 0.2729935348033905\n",
      "Train size: [400] hidden size: [38] trial: 39, train_loss: 1.744131, test loss: 1.148195, bias2: 0.8761123418807983, variance: 0.2720830738544464\n",
      "Train size: [400] hidden size: [38] trial: 40, train_loss: 1.742684, test loss: 1.150659, bias2: 0.8751457929611206, variance: 0.27551332116127014\n",
      "Train size: [400] hidden size: [38] trial: 41, train_loss: 1.745838, test loss: 1.150136, bias2: 0.8747284412384033, variance: 0.2754077911376953\n",
      "Train size: [400] hidden size: [38] trial: 42, train_loss: 1.746761, test loss: 1.150241, bias2: 0.8746297359466553, variance: 0.27561137080192566\n",
      "Train size: [400] hidden size: [38] trial: 43, train_loss: 1.745907, test loss: 1.147830, bias2: 0.8732385635375977, variance: 0.2745915949344635\n",
      "Train size: [400] hidden size: [38] trial: 44, train_loss: 1.745717, test loss: 1.147157, bias2: 0.8740336298942566, variance: 0.2731238007545471\n",
      "Train size: [400] hidden size: [38] trial: 45, train_loss: 1.741941, test loss: 1.148965, bias2: 0.8724206686019897, variance: 0.27654436230659485\n",
      "Train size: [400] hidden size: [38] trial: 46, train_loss: 1.739487, test loss: 1.148270, bias2: 0.873570442199707, variance: 0.2746991813182831\n",
      "Train size: [400] hidden size: [38] trial: 47, train_loss: 1.738965, test loss: 1.147266, bias2: 0.8737841844558716, variance: 0.27348223328590393\n",
      "Train size: [400] hidden size: [38] trial: 48, train_loss: 1.738038, test loss: 1.146747, bias2: 0.8731505870819092, variance: 0.27359673380851746\n",
      "Train size: [400] hidden size: [38] trial: 49, train_loss: 1.745538, test loss: 1.145918, bias2: 0.8740329742431641, variance: 0.2718847990036011\n",
      "##################################################\n",
      "Train size: [400] hidden size: [44] trial: 0, train_loss: 1.768206, test loss: 1.094848, bias2: 1.0948477983474731, variance: 4.6710577628061856e-09\n",
      "Train size: [400] hidden size: [44] trial: 1, train_loss: 1.759567, test loss: 1.096222, bias2: 0.9482696056365967, variance: 0.14795280992984772\n",
      "Train size: [400] hidden size: [44] trial: 2, train_loss: 1.705601, test loss: 1.111479, bias2: 0.914069652557373, variance: 0.19740985333919525\n",
      "Train size: [400] hidden size: [44] trial: 3, train_loss: 1.647918, test loss: 1.104687, bias2: 0.8979283571243286, variance: 0.2067587673664093\n",
      "Train size: [400] hidden size: [44] trial: 4, train_loss: 1.666635, test loss: 1.115156, bias2: 0.8767682909965515, variance: 0.23838751018047333\n",
      "Train size: [400] hidden size: [44] trial: 5, train_loss: 1.657444, test loss: 1.125024, bias2: 0.8696866035461426, variance: 0.2553368806838989\n",
      "Train size: [400] hidden size: [44] trial: 6, train_loss: 1.660966, test loss: 1.143000, bias2: 0.8678789138793945, variance: 0.2751213014125824\n",
      "Train size: [400] hidden size: [44] trial: 7, train_loss: 1.668792, test loss: 1.137546, bias2: 0.8653640747070312, variance: 0.2721816301345825\n",
      "Train size: [400] hidden size: [44] trial: 8, train_loss: 1.647810, test loss: 1.151964, bias2: 0.8608185648918152, variance: 0.2911457419395447\n",
      "Train size: [400] hidden size: [44] trial: 9, train_loss: 1.674162, test loss: 1.154209, bias2: 0.8626118898391724, variance: 0.29159727692604065\n",
      "Train size: [400] hidden size: [44] trial: 10, train_loss: 1.687956, test loss: 1.151673, bias2: 0.8597934246063232, variance: 0.2918795645236969\n",
      "Train size: [400] hidden size: [44] trial: 11, train_loss: 1.678084, test loss: 1.142521, bias2: 0.8533117175102234, variance: 0.2892088294029236\n",
      "Train size: [400] hidden size: [44] trial: 12, train_loss: 1.682639, test loss: 1.143724, bias2: 0.8575851917266846, variance: 0.2861388921737671\n",
      "Train size: [400] hidden size: [44] trial: 13, train_loss: 1.690107, test loss: 1.140435, bias2: 0.8530601263046265, variance: 0.2873746156692505\n",
      "Train size: [400] hidden size: [44] trial: 14, train_loss: 1.684604, test loss: 1.140313, bias2: 0.8540684580802917, variance: 0.28624409437179565\n",
      "Train size: [400] hidden size: [44] trial: 15, train_loss: 1.695278, test loss: 1.139380, bias2: 0.85530686378479, variance: 0.28407347202301025\n",
      "Train size: [400] hidden size: [44] trial: 16, train_loss: 1.709023, test loss: 1.147826, bias2: 0.8639392852783203, variance: 0.2838863432407379\n",
      "Train size: [400] hidden size: [44] trial: 17, train_loss: 1.710880, test loss: 1.153580, bias2: 0.8616491556167603, variance: 0.29193127155303955\n",
      "Train size: [400] hidden size: [44] trial: 18, train_loss: 1.710159, test loss: 1.159168, bias2: 0.8595095872879028, variance: 0.2996583878993988\n",
      "Train size: [400] hidden size: [44] trial: 19, train_loss: 1.719104, test loss: 1.160555, bias2: 0.8564508557319641, variance: 0.30410391092300415\n",
      "Train size: [400] hidden size: [44] trial: 20, train_loss: 1.725036, test loss: 1.164229, bias2: 0.855471134185791, variance: 0.30875828862190247\n",
      "Train size: [400] hidden size: [44] trial: 21, train_loss: 1.717314, test loss: 1.166262, bias2: 0.8559877276420593, variance: 0.31027477979660034\n",
      "Train size: [400] hidden size: [44] trial: 22, train_loss: 1.715293, test loss: 1.170069, bias2: 0.8585017919540405, variance: 0.311567097902298\n",
      "Train size: [400] hidden size: [44] trial: 23, train_loss: 1.714247, test loss: 1.166358, bias2: 0.8573545217514038, variance: 0.3090038299560547\n",
      "Train size: [400] hidden size: [44] trial: 24, train_loss: 1.717048, test loss: 1.163810, bias2: 0.8570750951766968, variance: 0.3067344129085541\n",
      "Train size: [400] hidden size: [44] trial: 25, train_loss: 1.709954, test loss: 1.161018, bias2: 0.8558066487312317, variance: 0.3052113652229309\n",
      "Train size: [400] hidden size: [44] trial: 26, train_loss: 1.715889, test loss: 1.168933, bias2: 0.8556784391403198, variance: 0.31325414776802063\n",
      "Train size: [400] hidden size: [44] trial: 27, train_loss: 1.716825, test loss: 1.169995, bias2: 0.8564822673797607, variance: 0.3135124742984772\n",
      "Train size: [400] hidden size: [44] trial: 28, train_loss: 1.714087, test loss: 1.169082, bias2: 0.8543169498443604, variance: 0.3147651255130768\n",
      "Train size: [400] hidden size: [44] trial: 29, train_loss: 1.715216, test loss: 1.167475, bias2: 0.8529007434844971, variance: 0.3145744502544403\n",
      "Train size: [400] hidden size: [44] trial: 30, train_loss: 1.718711, test loss: 1.168690, bias2: 0.8512461185455322, variance: 0.31744375824928284\n",
      "Train size: [400] hidden size: [44] trial: 31, train_loss: 1.715067, test loss: 1.168390, bias2: 0.8496493697166443, variance: 0.3187404274940491\n",
      "Train size: [400] hidden size: [44] trial: 32, train_loss: 1.714569, test loss: 1.168652, bias2: 0.8516268730163574, variance: 0.31702545285224915\n",
      "Train size: [400] hidden size: [44] trial: 33, train_loss: 1.719055, test loss: 1.168471, bias2: 0.8529554605484009, variance: 0.31551530957221985\n",
      "Train size: [400] hidden size: [44] trial: 34, train_loss: 1.719885, test loss: 1.167669, bias2: 0.8513500690460205, variance: 0.31631895899772644\n",
      "Train size: [400] hidden size: [44] trial: 35, train_loss: 1.722616, test loss: 1.166406, bias2: 0.8522142171859741, variance: 0.3141913414001465\n",
      "Train size: [400] hidden size: [44] trial: 36, train_loss: 1.719905, test loss: 1.163702, bias2: 0.8503596782684326, variance: 0.3133418560028076\n",
      "Train size: [400] hidden size: [44] trial: 37, train_loss: 1.719850, test loss: 1.160572, bias2: 0.8475338220596313, variance: 0.31303855776786804\n",
      "Train size: [400] hidden size: [44] trial: 38, train_loss: 1.713299, test loss: 1.159347, bias2: 0.8461052179336548, variance: 0.3132418394088745\n",
      "Train size: [400] hidden size: [44] trial: 39, train_loss: 1.711798, test loss: 1.159335, bias2: 0.8477548360824585, variance: 0.3115801513195038\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [44] trial: 40, train_loss: 1.706496, test loss: 1.159050, bias2: 0.8481349945068359, variance: 0.3109147250652313\n",
      "Train size: [400] hidden size: [44] trial: 41, train_loss: 1.708327, test loss: 1.157534, bias2: 0.8492727875709534, variance: 0.30826109647750854\n",
      "Train size: [400] hidden size: [44] trial: 42, train_loss: 1.713833, test loss: 1.159457, bias2: 0.8467864990234375, variance: 0.3126702308654785\n",
      "Train size: [400] hidden size: [44] trial: 43, train_loss: 1.714917, test loss: 1.158375, bias2: 0.8469401597976685, variance: 0.31143447756767273\n",
      "Train size: [400] hidden size: [44] trial: 44, train_loss: 1.709685, test loss: 1.156482, bias2: 0.8479481935501099, variance: 0.30853402614593506\n",
      "Train size: [400] hidden size: [44] trial: 45, train_loss: 1.713610, test loss: 1.157959, bias2: 0.8493142127990723, variance: 0.308644562959671\n",
      "Train size: [400] hidden size: [44] trial: 46, train_loss: 1.711993, test loss: 1.157003, bias2: 0.8504049777984619, variance: 0.30659759044647217\n",
      "Train size: [400] hidden size: [44] trial: 47, train_loss: 1.710190, test loss: 1.157506, bias2: 0.8518882989883423, variance: 0.3056180775165558\n",
      "Train size: [400] hidden size: [44] trial: 48, train_loss: 1.707416, test loss: 1.159254, bias2: 0.8498141765594482, variance: 0.30943942070007324\n",
      "Train size: [400] hidden size: [44] trial: 49, train_loss: 1.709632, test loss: 1.161684, bias2: 0.8490083813667297, variance: 0.312675416469574\n",
      "##################################################\n",
      "Train size: [400] hidden size: [51] trial: 0, train_loss: 1.755734, test loss: 1.174540, bias2: 1.1745401620864868, variance: 3.8925479506346505e-10\n",
      "Train size: [400] hidden size: [51] trial: 1, train_loss: 1.733448, test loss: 1.168745, bias2: 0.9685696363449097, variance: 0.20017516613006592\n",
      "Train size: [400] hidden size: [51] trial: 2, train_loss: 1.706252, test loss: 1.194831, bias2: 0.922942578792572, variance: 0.2718885540962219\n",
      "Train size: [400] hidden size: [51] trial: 3, train_loss: 1.697272, test loss: 1.181428, bias2: 0.8823271989822388, variance: 0.2991003692150116\n",
      "Train size: [400] hidden size: [51] trial: 4, train_loss: 1.655302, test loss: 1.188608, bias2: 0.8651913404464722, variance: 0.32341668009757996\n",
      "Train size: [400] hidden size: [51] trial: 5, train_loss: 1.650475, test loss: 1.175313, bias2: 0.8501598834991455, variance: 0.32515278458595276\n",
      "Train size: [400] hidden size: [51] trial: 6, train_loss: 1.662087, test loss: 1.171775, bias2: 0.8518407344818115, variance: 0.3199346363544464\n",
      "Train size: [400] hidden size: [51] trial: 7, train_loss: 1.653000, test loss: 1.170544, bias2: 0.8292670845985413, variance: 0.3412770628929138\n",
      "Train size: [400] hidden size: [51] trial: 8, train_loss: 1.652459, test loss: 1.186213, bias2: 0.8371573090553284, variance: 0.34905534982681274\n",
      "Train size: [400] hidden size: [51] trial: 9, train_loss: 1.647910, test loss: 1.185963, bias2: 0.8377148509025574, variance: 0.34824830293655396\n",
      "Train size: [400] hidden size: [51] trial: 10, train_loss: 1.636273, test loss: 1.184517, bias2: 0.8421038389205933, variance: 0.34241268038749695\n",
      "Train size: [400] hidden size: [51] trial: 11, train_loss: 1.657529, test loss: 1.184224, bias2: 0.8418871164321899, variance: 0.34233665466308594\n",
      "Train size: [400] hidden size: [51] trial: 12, train_loss: 1.653530, test loss: 1.176459, bias2: 0.8379381895065308, variance: 0.3385208547115326\n",
      "Train size: [400] hidden size: [51] trial: 13, train_loss: 1.642988, test loss: 1.182339, bias2: 0.8365697264671326, variance: 0.3457692265510559\n",
      "Train size: [400] hidden size: [51] trial: 14, train_loss: 1.631240, test loss: 1.185418, bias2: 0.8408464193344116, variance: 0.3445718288421631\n",
      "Train size: [400] hidden size: [51] trial: 15, train_loss: 1.627781, test loss: 1.180756, bias2: 0.8401684761047363, variance: 0.3405876159667969\n",
      "Train size: [400] hidden size: [51] trial: 16, train_loss: 1.625765, test loss: 1.175128, bias2: 0.8364108800888062, variance: 0.33871713280677795\n",
      "Train size: [400] hidden size: [51] trial: 17, train_loss: 1.626905, test loss: 1.170181, bias2: 0.8328260779380798, variance: 0.337354838848114\n",
      "Train size: [400] hidden size: [51] trial: 18, train_loss: 1.632346, test loss: 1.169106, bias2: 0.831076979637146, variance: 0.3380293548107147\n",
      "Train size: [400] hidden size: [51] trial: 19, train_loss: 1.645200, test loss: 1.168717, bias2: 0.8325943946838379, variance: 0.3361227512359619\n",
      "Train size: [400] hidden size: [51] trial: 20, train_loss: 1.645710, test loss: 1.164558, bias2: 0.827974796295166, variance: 0.33658361434936523\n",
      "Train size: [400] hidden size: [51] trial: 21, train_loss: 1.642029, test loss: 1.165163, bias2: 0.8279377222061157, variance: 0.3372255861759186\n",
      "Train size: [400] hidden size: [51] trial: 22, train_loss: 1.639288, test loss: 1.162840, bias2: 0.8266332745552063, variance: 0.33620697259902954\n",
      "Train size: [400] hidden size: [51] trial: 23, train_loss: 1.633421, test loss: 1.166331, bias2: 0.8256229162216187, variance: 0.340708464384079\n",
      "Train size: [400] hidden size: [51] trial: 24, train_loss: 1.637514, test loss: 1.166531, bias2: 0.8238375782966614, variance: 0.3426937460899353\n",
      "Train size: [400] hidden size: [51] trial: 25, train_loss: 1.641291, test loss: 1.168447, bias2: 0.82215815782547, variance: 0.3462892174720764\n",
      "Train size: [400] hidden size: [51] trial: 26, train_loss: 1.634739, test loss: 1.168800, bias2: 0.8200064301490784, variance: 0.34879380464553833\n",
      "Train size: [400] hidden size: [51] trial: 27, train_loss: 1.641267, test loss: 1.171191, bias2: 0.8224029541015625, variance: 0.34878766536712646\n",
      "Train size: [400] hidden size: [51] trial: 28, train_loss: 1.641811, test loss: 1.176708, bias2: 0.8249896764755249, variance: 0.3517184257507324\n",
      "Train size: [400] hidden size: [51] trial: 29, train_loss: 1.642882, test loss: 1.177853, bias2: 0.823031485080719, variance: 0.3548211455345154\n",
      "Train size: [400] hidden size: [51] trial: 30, train_loss: 1.643462, test loss: 1.181885, bias2: 0.8248289823532104, variance: 0.35705602169036865\n",
      "Train size: [400] hidden size: [51] trial: 31, train_loss: 1.645928, test loss: 1.181775, bias2: 0.8245387077331543, variance: 0.35723647475242615\n",
      "Train size: [400] hidden size: [51] trial: 32, train_loss: 1.643309, test loss: 1.181602, bias2: 0.8257169723510742, variance: 0.3558849096298218\n",
      "Train size: [400] hidden size: [51] trial: 33, train_loss: 1.646117, test loss: 1.182566, bias2: 0.8254163265228271, variance: 0.3571496903896332\n",
      "Train size: [400] hidden size: [51] trial: 34, train_loss: 1.649969, test loss: 1.184049, bias2: 0.8257440328598022, variance: 0.358304888010025\n",
      "Train size: [400] hidden size: [51] trial: 35, train_loss: 1.652466, test loss: 1.184348, bias2: 0.8249307870864868, variance: 0.3594176471233368\n",
      "Train size: [400] hidden size: [51] trial: 36, train_loss: 1.653846, test loss: 1.182623, bias2: 0.8253211379051208, variance: 0.35730165243148804\n",
      "Train size: [400] hidden size: [51] trial: 37, train_loss: 1.649856, test loss: 1.185493, bias2: 0.8276251554489136, variance: 0.35786759853363037\n",
      "Train size: [400] hidden size: [51] trial: 38, train_loss: 1.650034, test loss: 1.185858, bias2: 0.828542172908783, variance: 0.35731571912765503\n",
      "Train size: [400] hidden size: [51] trial: 39, train_loss: 1.653863, test loss: 1.191435, bias2: 0.8286155462265015, variance: 0.3628196716308594\n",
      "Train size: [400] hidden size: [51] trial: 40, train_loss: 1.652308, test loss: 1.190008, bias2: 0.8290392160415649, variance: 0.360968679189682\n",
      "Train size: [400] hidden size: [51] trial: 41, train_loss: 1.652254, test loss: 1.187483, bias2: 0.8277758359909058, variance: 0.3597071170806885\n",
      "Train size: [400] hidden size: [51] trial: 42, train_loss: 1.651720, test loss: 1.186299, bias2: 0.8265699148178101, variance: 0.35972920060157776\n",
      "Train size: [400] hidden size: [51] trial: 43, train_loss: 1.655326, test loss: 1.185328, bias2: 0.8262416124343872, variance: 0.3590860366821289\n",
      "Train size: [400] hidden size: [51] trial: 44, train_loss: 1.651561, test loss: 1.186354, bias2: 0.8260765075683594, variance: 0.36027753353118896\n",
      "Train size: [400] hidden size: [51] trial: 45, train_loss: 1.654627, test loss: 1.186505, bias2: 0.825656533241272, variance: 0.3608480393886566\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [51] trial: 46, train_loss: 1.656658, test loss: 1.186260, bias2: 0.8260701298713684, variance: 0.36018961668014526\n",
      "Train size: [400] hidden size: [51] trial: 47, train_loss: 1.658303, test loss: 1.187086, bias2: 0.8262500762939453, variance: 0.36083558201789856\n",
      "Train size: [400] hidden size: [51] trial: 48, train_loss: 1.660618, test loss: 1.188391, bias2: 0.82692551612854, variance: 0.36146512627601624\n",
      "Train size: [400] hidden size: [51] trial: 49, train_loss: 1.660198, test loss: 1.190495, bias2: 0.8271514177322388, variance: 0.3633434474468231\n",
      "##################################################\n",
      "Train size: [400] hidden size: [58] trial: 0, train_loss: 1.735980, test loss: 1.383228, bias2: 1.3832284212112427, variance: -1.5570191802538602e-09\n",
      "Train size: [400] hidden size: [58] trial: 1, train_loss: 1.726423, test loss: 1.286333, bias2: 1.0639842748641968, variance: 0.22234858572483063\n",
      "Train size: [400] hidden size: [58] trial: 2, train_loss: 1.726485, test loss: 1.237348, bias2: 0.9777332544326782, variance: 0.25961431860923767\n",
      "Train size: [400] hidden size: [58] trial: 3, train_loss: 1.693901, test loss: 1.237179, bias2: 0.9155981540679932, variance: 0.321581095457077\n",
      "Train size: [400] hidden size: [58] trial: 4, train_loss: 1.642354, test loss: 1.213009, bias2: 0.8726388216018677, variance: 0.34036991000175476\n",
      "Train size: [400] hidden size: [58] trial: 5, train_loss: 1.671387, test loss: 1.220866, bias2: 0.8592599630355835, variance: 0.361606240272522\n",
      "Train size: [400] hidden size: [58] trial: 6, train_loss: 1.644105, test loss: 1.235198, bias2: 0.8416838049888611, variance: 0.3935137391090393\n",
      "Train size: [400] hidden size: [58] trial: 7, train_loss: 1.640327, test loss: 1.235024, bias2: 0.8269551992416382, variance: 0.40806862711906433\n",
      "Train size: [400] hidden size: [58] trial: 8, train_loss: 1.636562, test loss: 1.238079, bias2: 0.8304792642593384, variance: 0.40759968757629395\n",
      "Train size: [400] hidden size: [58] trial: 9, train_loss: 1.644337, test loss: 1.236947, bias2: 0.8122826814651489, variance: 0.4246647357940674\n",
      "Train size: [400] hidden size: [58] trial: 10, train_loss: 1.654281, test loss: 1.241511, bias2: 0.807767391204834, variance: 0.43374335765838623\n",
      "Train size: [400] hidden size: [58] trial: 11, train_loss: 1.664067, test loss: 1.237507, bias2: 0.8059914112091064, variance: 0.43151554465293884\n",
      "Train size: [400] hidden size: [58] trial: 12, train_loss: 1.670198, test loss: 1.229269, bias2: 0.8062732219696045, variance: 0.42299607396125793\n",
      "Train size: [400] hidden size: [58] trial: 13, train_loss: 1.683894, test loss: 1.224982, bias2: 0.8082313537597656, variance: 0.41675078868865967\n",
      "Train size: [400] hidden size: [58] trial: 14, train_loss: 1.671408, test loss: 1.220584, bias2: 0.7987822890281677, variance: 0.4218018651008606\n",
      "Train size: [400] hidden size: [58] trial: 15, train_loss: 1.675055, test loss: 1.225544, bias2: 0.7983627319335938, variance: 0.4271810054779053\n",
      "Train size: [400] hidden size: [58] trial: 16, train_loss: 1.673344, test loss: 1.231420, bias2: 0.8031436204910278, variance: 0.4282759428024292\n",
      "Train size: [400] hidden size: [58] trial: 17, train_loss: 1.673644, test loss: 1.237084, bias2: 0.8065454363822937, variance: 0.43053895235061646\n",
      "Train size: [400] hidden size: [58] trial: 18, train_loss: 1.682215, test loss: 1.242655, bias2: 0.8055419325828552, variance: 0.4371127486228943\n",
      "Train size: [400] hidden size: [58] trial: 19, train_loss: 1.685012, test loss: 1.244705, bias2: 0.8057401180267334, variance: 0.43896496295928955\n",
      "Train size: [400] hidden size: [58] trial: 20, train_loss: 1.681605, test loss: 1.246720, bias2: 0.8082545399665833, variance: 0.43846529722213745\n",
      "Train size: [400] hidden size: [58] trial: 21, train_loss: 1.676620, test loss: 1.243851, bias2: 0.8070958852767944, variance: 0.4367554485797882\n",
      "Train size: [400] hidden size: [58] trial: 22, train_loss: 1.675472, test loss: 1.242080, bias2: 0.8076841831207275, variance: 0.4343959093093872\n",
      "Train size: [400] hidden size: [58] trial: 23, train_loss: 1.667554, test loss: 1.235317, bias2: 0.8082617521286011, variance: 0.42705488204956055\n",
      "Train size: [400] hidden size: [58] trial: 24, train_loss: 1.663006, test loss: 1.233102, bias2: 0.8055760860443115, variance: 0.4275260269641876\n",
      "Train size: [400] hidden size: [58] trial: 25, train_loss: 1.652614, test loss: 1.230666, bias2: 0.8029932975769043, variance: 0.42767226696014404\n",
      "Train size: [400] hidden size: [58] trial: 26, train_loss: 1.638424, test loss: 1.231865, bias2: 0.8044528961181641, variance: 0.4274117052555084\n",
      "Train size: [400] hidden size: [58] trial: 27, train_loss: 1.634488, test loss: 1.231829, bias2: 0.8042161464691162, variance: 0.427613228559494\n",
      "Train size: [400] hidden size: [58] trial: 28, train_loss: 1.631339, test loss: 1.230420, bias2: 0.8049989938735962, variance: 0.42542099952697754\n",
      "Train size: [400] hidden size: [58] trial: 29, train_loss: 1.632476, test loss: 1.234327, bias2: 0.8032809495925903, variance: 0.43104636669158936\n",
      "Train size: [400] hidden size: [58] trial: 30, train_loss: 1.633061, test loss: 1.232748, bias2: 0.8035697340965271, variance: 0.4291786551475525\n",
      "Train size: [400] hidden size: [58] trial: 31, train_loss: 1.627825, test loss: 1.229219, bias2: 0.803866982460022, variance: 0.42535242438316345\n",
      "Train size: [400] hidden size: [58] trial: 32, train_loss: 1.625773, test loss: 1.230694, bias2: 0.8054272532463074, variance: 0.42526644468307495\n",
      "Train size: [400] hidden size: [58] trial: 33, train_loss: 1.629852, test loss: 1.229376, bias2: 0.8057570457458496, variance: 0.4236186444759369\n",
      "Train size: [400] hidden size: [58] trial: 34, train_loss: 1.629863, test loss: 1.228332, bias2: 0.8040777444839478, variance: 0.42425426840782166\n",
      "Train size: [400] hidden size: [58] trial: 35, train_loss: 1.628588, test loss: 1.227190, bias2: 0.8037874698638916, variance: 0.42340290546417236\n",
      "Train size: [400] hidden size: [58] trial: 36, train_loss: 1.625004, test loss: 1.228885, bias2: 0.8029971122741699, variance: 0.42588767409324646\n",
      "Train size: [400] hidden size: [58] trial: 37, train_loss: 1.620652, test loss: 1.227762, bias2: 0.8047682642936707, variance: 0.42299360036849976\n",
      "Train size: [400] hidden size: [58] trial: 38, train_loss: 1.619306, test loss: 1.225043, bias2: 0.804541826248169, variance: 0.42050108313560486\n",
      "Train size: [400] hidden size: [58] trial: 39, train_loss: 1.620238, test loss: 1.223950, bias2: 0.8051592111587524, variance: 0.41879069805145264\n",
      "Train size: [400] hidden size: [58] trial: 40, train_loss: 1.613651, test loss: 1.225654, bias2: 0.8040502071380615, variance: 0.421604186296463\n",
      "Train size: [400] hidden size: [58] trial: 41, train_loss: 1.613123, test loss: 1.225399, bias2: 0.8025579452514648, variance: 0.4228408634662628\n",
      "Train size: [400] hidden size: [58] trial: 42, train_loss: 1.611974, test loss: 1.224018, bias2: 0.8011595010757446, variance: 0.4228585660457611\n",
      "Train size: [400] hidden size: [58] trial: 43, train_loss: 1.616697, test loss: 1.224538, bias2: 0.8001024723052979, variance: 0.4244360029697418\n",
      "Train size: [400] hidden size: [58] trial: 44, train_loss: 1.618589, test loss: 1.224049, bias2: 0.8005897998809814, variance: 0.42345914244651794\n",
      "Train size: [400] hidden size: [58] trial: 45, train_loss: 1.618947, test loss: 1.222814, bias2: 0.7987679839134216, variance: 0.42404621839523315\n",
      "Train size: [400] hidden size: [58] trial: 46, train_loss: 1.618813, test loss: 1.222674, bias2: 0.8006139993667603, variance: 0.42205992341041565\n",
      "Train size: [400] hidden size: [58] trial: 47, train_loss: 1.620891, test loss: 1.223667, bias2: 0.8004305958747864, variance: 0.4232361912727356\n",
      "Train size: [400] hidden size: [58] trial: 48, train_loss: 1.622852, test loss: 1.222630, bias2: 0.8005893230438232, variance: 0.4220409691333771\n",
      "Train size: [400] hidden size: [58] trial: 49, train_loss: 1.620572, test loss: 1.220300, bias2: 0.7994911074638367, variance: 0.42080897092819214\n",
      "##################################################\n",
      "Train size: [400] hidden size: [67] trial: 0, train_loss: 1.638753, test loss: 1.261289, bias2: 1.2612890005111694, variance: -7.785095901269301e-10\n",
      "Train size: [400] hidden size: [67] trial: 1, train_loss: 1.672786, test loss: 1.271038, bias2: 1.0565301179885864, variance: 0.2145073115825653\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [67] trial: 2, train_loss: 1.564741, test loss: 1.233588, bias2: 0.9270646572113037, variance: 0.30652377009391785\n",
      "Train size: [400] hidden size: [67] trial: 3, train_loss: 1.520173, test loss: 1.252244, bias2: 0.9096011519432068, variance: 0.34264272451400757\n",
      "Train size: [400] hidden size: [67] trial: 4, train_loss: 1.541476, test loss: 1.232551, bias2: 0.8829876184463501, variance: 0.349563866853714\n",
      "Train size: [400] hidden size: [67] trial: 5, train_loss: 1.594915, test loss: 1.228024, bias2: 0.8530858755111694, variance: 0.3749382495880127\n",
      "Train size: [400] hidden size: [67] trial: 6, train_loss: 1.565300, test loss: 1.225492, bias2: 0.8272513151168823, variance: 0.39824047684669495\n",
      "Train size: [400] hidden size: [67] trial: 7, train_loss: 1.572175, test loss: 1.224870, bias2: 0.8210944533348083, variance: 0.40377551317214966\n",
      "Train size: [400] hidden size: [67] trial: 8, train_loss: 1.585340, test loss: 1.230787, bias2: 0.8127326369285583, variance: 0.41805392503738403\n",
      "Train size: [400] hidden size: [67] trial: 9, train_loss: 1.588822, test loss: 1.229713, bias2: 0.8056899905204773, variance: 0.4240233302116394\n",
      "Train size: [400] hidden size: [67] trial: 10, train_loss: 1.562244, test loss: 1.226242, bias2: 0.7957116365432739, variance: 0.43053027987480164\n",
      "Train size: [400] hidden size: [67] trial: 11, train_loss: 1.578857, test loss: 1.222119, bias2: 0.7896333336830139, variance: 0.4324856400489807\n",
      "Train size: [400] hidden size: [67] trial: 12, train_loss: 1.578548, test loss: 1.219712, bias2: 0.7897372245788574, variance: 0.4299749433994293\n",
      "Train size: [400] hidden size: [67] trial: 13, train_loss: 1.574686, test loss: 1.222800, bias2: 0.7911715507507324, variance: 0.4316282272338867\n",
      "Train size: [400] hidden size: [67] trial: 14, train_loss: 1.577197, test loss: 1.219077, bias2: 0.7868674993515015, variance: 0.4322092831134796\n",
      "Train size: [400] hidden size: [67] trial: 15, train_loss: 1.559379, test loss: 1.214965, bias2: 0.7879936695098877, variance: 0.4269712269306183\n",
      "Train size: [400] hidden size: [67] trial: 16, train_loss: 1.553139, test loss: 1.223623, bias2: 0.7914455533027649, variance: 0.43217748403549194\n",
      "Train size: [400] hidden size: [67] trial: 17, train_loss: 1.550154, test loss: 1.227111, bias2: 0.7909364104270935, variance: 0.43617480993270874\n",
      "Train size: [400] hidden size: [67] trial: 18, train_loss: 1.553253, test loss: 1.228136, bias2: 0.7924057245254517, variance: 0.4357306659221649\n",
      "Train size: [400] hidden size: [67] trial: 19, train_loss: 1.550557, test loss: 1.235976, bias2: 0.7922186851501465, variance: 0.44375744462013245\n",
      "Train size: [400] hidden size: [67] trial: 20, train_loss: 1.545718, test loss: 1.237299, bias2: 0.7923452854156494, variance: 0.44495344161987305\n",
      "Train size: [400] hidden size: [67] trial: 21, train_loss: 1.550314, test loss: 1.234043, bias2: 0.7895305156707764, variance: 0.4445122480392456\n",
      "Train size: [400] hidden size: [67] trial: 22, train_loss: 1.559469, test loss: 1.237040, bias2: 0.7884138822555542, variance: 0.44862571358680725\n",
      "Train size: [400] hidden size: [67] trial: 23, train_loss: 1.561745, test loss: 1.239771, bias2: 0.7882493734359741, variance: 0.45152154564857483\n",
      "Train size: [400] hidden size: [67] trial: 24, train_loss: 1.556084, test loss: 1.241756, bias2: 0.7887089252471924, variance: 0.4530470669269562\n",
      "Train size: [400] hidden size: [67] trial: 25, train_loss: 1.560644, test loss: 1.239795, bias2: 0.7894539833068848, variance: 0.45034071803092957\n",
      "Train size: [400] hidden size: [67] trial: 26, train_loss: 1.572396, test loss: 1.238973, bias2: 0.7902976274490356, variance: 0.4486753046512604\n",
      "Train size: [400] hidden size: [67] trial: 27, train_loss: 1.575738, test loss: 1.237447, bias2: 0.7887864708900452, variance: 0.4486609101295471\n",
      "Train size: [400] hidden size: [67] trial: 28, train_loss: 1.579953, test loss: 1.238064, bias2: 0.7918733358383179, variance: 0.4461905062198639\n",
      "Train size: [400] hidden size: [67] trial: 29, train_loss: 1.581613, test loss: 1.236991, bias2: 0.7925460338592529, variance: 0.44444540143013\n",
      "Train size: [400] hidden size: [67] trial: 30, train_loss: 1.583995, test loss: 1.239066, bias2: 0.7936655282974243, variance: 0.44540098309516907\n",
      "Train size: [400] hidden size: [67] trial: 31, train_loss: 1.581773, test loss: 1.236858, bias2: 0.7943048477172852, variance: 0.44255319237709045\n",
      "Train size: [400] hidden size: [67] trial: 32, train_loss: 1.578624, test loss: 1.239652, bias2: 0.7936134338378906, variance: 0.44603869318962097\n",
      "Train size: [400] hidden size: [67] trial: 33, train_loss: 1.580619, test loss: 1.236919, bias2: 0.7930240631103516, variance: 0.4438945949077606\n",
      "Train size: [400] hidden size: [67] trial: 34, train_loss: 1.584066, test loss: 1.237028, bias2: 0.7917616367340088, variance: 0.44526585936546326\n",
      "Train size: [400] hidden size: [67] trial: 35, train_loss: 1.586275, test loss: 1.237792, bias2: 0.7924954891204834, variance: 0.44529637694358826\n",
      "Train size: [400] hidden size: [67] trial: 36, train_loss: 1.591425, test loss: 1.238192, bias2: 0.7925270795822144, variance: 0.445664644241333\n",
      "Train size: [400] hidden size: [67] trial: 37, train_loss: 1.588554, test loss: 1.239218, bias2: 0.7936822175979614, variance: 0.4455359876155853\n",
      "Train size: [400] hidden size: [67] trial: 38, train_loss: 1.583667, test loss: 1.233914, bias2: 0.7916554808616638, variance: 0.4422590136528015\n",
      "Train size: [400] hidden size: [67] trial: 39, train_loss: 1.586789, test loss: 1.235733, bias2: 0.7888326644897461, variance: 0.44690003991127014\n",
      "Train size: [400] hidden size: [67] trial: 40, train_loss: 1.591061, test loss: 1.233377, bias2: 0.7901535034179688, variance: 0.4432229697704315\n",
      "Train size: [400] hidden size: [67] trial: 41, train_loss: 1.587119, test loss: 1.238103, bias2: 0.7911011576652527, variance: 0.44700151681900024\n",
      "Train size: [400] hidden size: [67] trial: 42, train_loss: 1.588635, test loss: 1.239683, bias2: 0.7882208824157715, variance: 0.4514618217945099\n",
      "Train size: [400] hidden size: [67] trial: 43, train_loss: 1.589542, test loss: 1.239719, bias2: 0.7876226902008057, variance: 0.4520961046218872\n",
      "Train size: [400] hidden size: [67] trial: 44, train_loss: 1.589926, test loss: 1.242872, bias2: 0.788461446762085, variance: 0.4544106721878052\n",
      "Train size: [400] hidden size: [67] trial: 45, train_loss: 1.582482, test loss: 1.241072, bias2: 0.7887582778930664, variance: 0.452313631772995\n",
      "Train size: [400] hidden size: [67] trial: 46, train_loss: 1.584571, test loss: 1.242349, bias2: 0.7880250215530396, variance: 0.45432424545288086\n",
      "Train size: [400] hidden size: [67] trial: 47, train_loss: 1.587907, test loss: 1.242421, bias2: 0.7869198322296143, variance: 0.4555010497570038\n",
      "Train size: [400] hidden size: [67] trial: 48, train_loss: 1.590989, test loss: 1.242351, bias2: 0.7881114482879639, variance: 0.4542395770549774\n",
      "Train size: [400] hidden size: [67] trial: 49, train_loss: 1.588926, test loss: 1.242261, bias2: 0.7867913246154785, variance: 0.4554695785045624\n",
      "##################################################\n",
      "Train size: [400] hidden size: [77] trial: 0, train_loss: 1.535489, test loss: 1.304276, bias2: 1.3042761087417603, variance: 0.0\n",
      "Train size: [400] hidden size: [77] trial: 1, train_loss: 1.528338, test loss: 1.307844, bias2: 1.0071699619293213, variance: 0.30067381262779236\n",
      "Train size: [400] hidden size: [77] trial: 2, train_loss: 1.508080, test loss: 1.326507, bias2: 0.9249357581138611, variance: 0.40157169103622437\n",
      "Train size: [400] hidden size: [77] trial: 3, train_loss: 1.519567, test loss: 1.326603, bias2: 0.8904610872268677, variance: 0.4361422061920166\n",
      "Train size: [400] hidden size: [77] trial: 4, train_loss: 1.484128, test loss: 1.314905, bias2: 0.8608365058898926, variance: 0.45406875014305115\n",
      "Train size: [400] hidden size: [77] trial: 5, train_loss: 1.508768, test loss: 1.280827, bias2: 0.8428435325622559, variance: 0.43798306584358215\n",
      "Train size: [400] hidden size: [77] trial: 6, train_loss: 1.527353, test loss: 1.277856, bias2: 0.8174605369567871, variance: 0.46039533615112305\n",
      "Train size: [400] hidden size: [77] trial: 7, train_loss: 1.518356, test loss: 1.265156, bias2: 0.7937641143798828, variance: 0.47139212489128113\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [77] trial: 8, train_loss: 1.513746, test loss: 1.266669, bias2: 0.7890939712524414, variance: 0.477575421333313\n",
      "Train size: [400] hidden size: [77] trial: 9, train_loss: 1.512387, test loss: 1.276129, bias2: 0.7864640951156616, variance: 0.48966529965400696\n",
      "Train size: [400] hidden size: [77] trial: 10, train_loss: 1.503444, test loss: 1.279067, bias2: 0.7826886177062988, variance: 0.49637797474861145\n",
      "Train size: [400] hidden size: [77] trial: 11, train_loss: 1.492040, test loss: 1.279101, bias2: 0.7748783230781555, variance: 0.5042223334312439\n",
      "Train size: [400] hidden size: [77] trial: 12, train_loss: 1.497747, test loss: 1.283816, bias2: 0.7722399234771729, variance: 0.5115765333175659\n",
      "Train size: [400] hidden size: [77] trial: 13, train_loss: 1.497869, test loss: 1.286560, bias2: 0.7723167538642883, variance: 0.5142437815666199\n",
      "Train size: [400] hidden size: [77] trial: 14, train_loss: 1.489644, test loss: 1.279765, bias2: 0.764369785785675, variance: 0.5153951048851013\n",
      "Train size: [400] hidden size: [77] trial: 15, train_loss: 1.493939, test loss: 1.282682, bias2: 0.7623093128204346, variance: 0.5203731060028076\n",
      "Train size: [400] hidden size: [77] trial: 16, train_loss: 1.502746, test loss: 1.281381, bias2: 0.7564812302589417, variance: 0.5249002575874329\n",
      "Train size: [400] hidden size: [77] trial: 17, train_loss: 1.506244, test loss: 1.280271, bias2: 0.7544752955436707, variance: 0.5257957577705383\n",
      "Train size: [400] hidden size: [77] trial: 18, train_loss: 1.506549, test loss: 1.284167, bias2: 0.7551053166389465, variance: 0.5290619730949402\n",
      "Train size: [400] hidden size: [77] trial: 19, train_loss: 1.514130, test loss: 1.294152, bias2: 0.7575199007987976, variance: 0.5366316437721252\n",
      "Train size: [400] hidden size: [77] trial: 20, train_loss: 1.512814, test loss: 1.299809, bias2: 0.757372260093689, variance: 0.5424371957778931\n",
      "Train size: [400] hidden size: [77] trial: 21, train_loss: 1.509443, test loss: 1.298691, bias2: 0.7554782032966614, variance: 0.5432129502296448\n",
      "Train size: [400] hidden size: [77] trial: 22, train_loss: 1.510591, test loss: 1.304480, bias2: 0.7565604448318481, variance: 0.547919750213623\n",
      "Train size: [400] hidden size: [77] trial: 23, train_loss: 1.508609, test loss: 1.304059, bias2: 0.7534179091453552, variance: 0.5506406426429749\n",
      "Train size: [400] hidden size: [77] trial: 24, train_loss: 1.509700, test loss: 1.300890, bias2: 0.7521708607673645, variance: 0.5487189888954163\n",
      "Train size: [400] hidden size: [77] trial: 25, train_loss: 1.500814, test loss: 1.305956, bias2: 0.7549313306808472, variance: 0.5510241985321045\n",
      "Train size: [400] hidden size: [77] trial: 26, train_loss: 1.500408, test loss: 1.304504, bias2: 0.7515672445297241, variance: 0.5529365539550781\n",
      "Train size: [400] hidden size: [77] trial: 27, train_loss: 1.497856, test loss: 1.305046, bias2: 0.7496325373649597, variance: 0.5554133057594299\n",
      "Train size: [400] hidden size: [77] trial: 28, train_loss: 1.502572, test loss: 1.306692, bias2: 0.7509790658950806, variance: 0.5557130575180054\n",
      "Train size: [400] hidden size: [77] trial: 29, train_loss: 1.503245, test loss: 1.306301, bias2: 0.7512909173965454, variance: 0.5550097227096558\n",
      "Train size: [400] hidden size: [77] trial: 30, train_loss: 1.503445, test loss: 1.304716, bias2: 0.7489972114562988, variance: 0.5557183027267456\n",
      "Train size: [400] hidden size: [77] trial: 31, train_loss: 1.495871, test loss: 1.306168, bias2: 0.7483378052711487, variance: 0.5578301548957825\n",
      "Train size: [400] hidden size: [77] trial: 32, train_loss: 1.498756, test loss: 1.303361, bias2: 0.7491393685340881, variance: 0.5542210936546326\n",
      "Train size: [400] hidden size: [77] trial: 33, train_loss: 1.496383, test loss: 1.304535, bias2: 0.7479515075683594, variance: 0.556583046913147\n",
      "Train size: [400] hidden size: [77] trial: 34, train_loss: 1.495480, test loss: 1.303628, bias2: 0.7478454113006592, variance: 0.5557827949523926\n",
      "Train size: [400] hidden size: [77] trial: 35, train_loss: 1.495397, test loss: 1.302022, bias2: 0.7494512796401978, variance: 0.5525710582733154\n",
      "Train size: [400] hidden size: [77] trial: 36, train_loss: 1.500451, test loss: 1.301619, bias2: 0.7516780495643616, variance: 0.54994136095047\n",
      "Train size: [400] hidden size: [77] trial: 37, train_loss: 1.502696, test loss: 1.301674, bias2: 0.750359833240509, variance: 0.5513145327568054\n",
      "Train size: [400] hidden size: [77] trial: 38, train_loss: 1.509962, test loss: 1.300208, bias2: 0.7506229877471924, variance: 0.5495851039886475\n",
      "Train size: [400] hidden size: [77] trial: 39, train_loss: 1.511582, test loss: 1.300708, bias2: 0.7497521638870239, variance: 0.5509554147720337\n",
      "Train size: [400] hidden size: [77] trial: 40, train_loss: 1.514927, test loss: 1.301551, bias2: 0.7480433583259583, variance: 0.5535081028938293\n",
      "Train size: [400] hidden size: [77] trial: 41, train_loss: 1.516700, test loss: 1.301825, bias2: 0.7474387288093567, variance: 0.5543860793113708\n",
      "Train size: [400] hidden size: [77] trial: 42, train_loss: 1.520124, test loss: 1.306514, bias2: 0.7469879984855652, variance: 0.5595257878303528\n",
      "Train size: [400] hidden size: [77] trial: 43, train_loss: 1.518684, test loss: 1.308555, bias2: 0.7479235529899597, variance: 0.5606319308280945\n",
      "Train size: [400] hidden size: [77] trial: 44, train_loss: 1.517108, test loss: 1.309102, bias2: 0.7472371459007263, variance: 0.5618649125099182\n",
      "Train size: [400] hidden size: [77] trial: 45, train_loss: 1.514221, test loss: 1.307200, bias2: 0.7461194396018982, variance: 0.5610808730125427\n",
      "Train size: [400] hidden size: [77] trial: 46, train_loss: 1.519523, test loss: 1.307860, bias2: 0.7477197647094727, variance: 0.5601407289505005\n",
      "Train size: [400] hidden size: [77] trial: 47, train_loss: 1.518182, test loss: 1.304214, bias2: 0.7449703812599182, variance: 0.5592438578605652\n",
      "Train size: [400] hidden size: [77] trial: 48, train_loss: 1.513676, test loss: 1.305056, bias2: 0.7452911734580994, variance: 0.5597650408744812\n",
      "Train size: [400] hidden size: [77] trial: 49, train_loss: 1.513684, test loss: 1.305100, bias2: 0.7482426762580872, variance: 0.5568577647209167\n",
      "##################################################\n",
      "Train size: [400] hidden size: [89] trial: 0, train_loss: 1.502055, test loss: 1.353405, bias2: 1.3534049987792969, variance: -2.724783731977709e-09\n",
      "Train size: [400] hidden size: [89] trial: 1, train_loss: 1.488049, test loss: 1.476015, bias2: 1.0734182596206665, variance: 0.4025968313217163\n",
      "Train size: [400] hidden size: [89] trial: 2, train_loss: 1.454659, test loss: 1.409115, bias2: 0.9173414707183838, variance: 0.4917730987071991\n",
      "Train size: [400] hidden size: [89] trial: 3, train_loss: 1.419403, test loss: 1.364104, bias2: 0.8634323477745056, variance: 0.5006715655326843\n",
      "Train size: [400] hidden size: [89] trial: 4, train_loss: 1.398860, test loss: 1.357926, bias2: 0.8347799777984619, variance: 0.5231461524963379\n",
      "Train size: [400] hidden size: [89] trial: 5, train_loss: 1.407951, test loss: 1.376178, bias2: 0.8091161847114563, variance: 0.5670616030693054\n",
      "Train size: [400] hidden size: [89] trial: 6, train_loss: 1.430857, test loss: 1.350321, bias2: 0.7885022759437561, variance: 0.5618191361427307\n",
      "Train size: [400] hidden size: [89] trial: 7, train_loss: 1.429410, test loss: 1.361094, bias2: 0.7710898518562317, variance: 0.5900036692619324\n",
      "Train size: [400] hidden size: [89] trial: 8, train_loss: 1.429482, test loss: 1.376423, bias2: 0.7665835022926331, variance: 0.6098393797874451\n",
      "Train size: [400] hidden size: [89] trial: 9, train_loss: 1.442420, test loss: 1.376041, bias2: 0.7605879902839661, variance: 0.6154528260231018\n",
      "Train size: [400] hidden size: [89] trial: 10, train_loss: 1.437641, test loss: 1.372412, bias2: 0.7604405879974365, variance: 0.6119714975357056\n",
      "Train size: [400] hidden size: [89] trial: 11, train_loss: 1.433600, test loss: 1.364212, bias2: 0.7500911355018616, variance: 0.6141210198402405\n",
      "Train size: [400] hidden size: [89] trial: 12, train_loss: 1.433994, test loss: 1.353676, bias2: 0.7466586828231812, variance: 0.6070173978805542\n",
      "Train size: [400] hidden size: [89] trial: 13, train_loss: 1.425002, test loss: 1.348537, bias2: 0.7356334924697876, variance: 0.6129037141799927\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [89] trial: 14, train_loss: 1.411447, test loss: 1.339982, bias2: 0.7241771817207336, variance: 0.6158044934272766\n",
      "Train size: [400] hidden size: [89] trial: 15, train_loss: 1.410894, test loss: 1.340770, bias2: 0.7207666635513306, variance: 0.6200029850006104\n",
      "Train size: [400] hidden size: [89] trial: 16, train_loss: 1.407283, test loss: 1.340776, bias2: 0.7182862162590027, variance: 0.6224893927574158\n",
      "Train size: [400] hidden size: [89] trial: 17, train_loss: 1.410721, test loss: 1.331474, bias2: 0.717006266117096, variance: 0.6144679188728333\n",
      "Train size: [400] hidden size: [89] trial: 18, train_loss: 1.403971, test loss: 1.331967, bias2: 0.7173740267753601, variance: 0.6145930886268616\n",
      "Train size: [400] hidden size: [89] trial: 19, train_loss: 1.404310, test loss: 1.328301, bias2: 0.7172237038612366, variance: 0.6110777258872986\n",
      "Train size: [400] hidden size: [89] trial: 20, train_loss: 1.406653, test loss: 1.330934, bias2: 0.7160000205039978, variance: 0.6149339079856873\n",
      "Train size: [400] hidden size: [89] trial: 21, train_loss: 1.406089, test loss: 1.327667, bias2: 0.7174369096755981, variance: 0.6102298498153687\n",
      "Train size: [400] hidden size: [89] trial: 22, train_loss: 1.409988, test loss: 1.324843, bias2: 0.7163332104682922, variance: 0.6085098385810852\n",
      "Train size: [400] hidden size: [89] trial: 23, train_loss: 1.409539, test loss: 1.333831, bias2: 0.717059850692749, variance: 0.6167714595794678\n",
      "Train size: [400] hidden size: [89] trial: 24, train_loss: 1.417438, test loss: 1.333675, bias2: 0.7170425653457642, variance: 0.6166324615478516\n",
      "Train size: [400] hidden size: [89] trial: 25, train_loss: 1.418119, test loss: 1.332797, bias2: 0.7173727750778198, variance: 0.615424633026123\n",
      "Train size: [400] hidden size: [89] trial: 26, train_loss: 1.418161, test loss: 1.333972, bias2: 0.7152930498123169, variance: 0.6186792850494385\n",
      "Train size: [400] hidden size: [89] trial: 27, train_loss: 1.416401, test loss: 1.342854, bias2: 0.7162423133850098, variance: 0.6266118288040161\n",
      "Train size: [400] hidden size: [89] trial: 28, train_loss: 1.417726, test loss: 1.342636, bias2: 0.7163059115409851, variance: 0.6263297200202942\n",
      "Train size: [400] hidden size: [89] trial: 29, train_loss: 1.422651, test loss: 1.340513, bias2: 0.712260365486145, variance: 0.628252387046814\n",
      "Train size: [400] hidden size: [89] trial: 30, train_loss: 1.421948, test loss: 1.344136, bias2: 0.7072598934173584, variance: 0.6368758678436279\n",
      "Train size: [400] hidden size: [89] trial: 31, train_loss: 1.420400, test loss: 1.345503, bias2: 0.7058334350585938, variance: 0.6396697759628296\n",
      "Train size: [400] hidden size: [89] trial: 32, train_loss: 1.420313, test loss: 1.346227, bias2: 0.7115878462791443, variance: 0.6346392035484314\n",
      "Train size: [400] hidden size: [89] trial: 33, train_loss: 1.414550, test loss: 1.349500, bias2: 0.7126539945602417, variance: 0.6368457078933716\n",
      "Train size: [400] hidden size: [89] trial: 34, train_loss: 1.423901, test loss: 1.353744, bias2: 0.7125813961029053, variance: 0.6411629915237427\n",
      "Train size: [400] hidden size: [89] trial: 35, train_loss: 1.424142, test loss: 1.352814, bias2: 0.7090314626693726, variance: 0.6437820196151733\n",
      "Train size: [400] hidden size: [89] trial: 36, train_loss: 1.422135, test loss: 1.357811, bias2: 0.7099800705909729, variance: 0.6478306651115417\n",
      "Train size: [400] hidden size: [89] trial: 37, train_loss: 1.423951, test loss: 1.353978, bias2: 0.7093070149421692, variance: 0.6446713805198669\n",
      "Train size: [400] hidden size: [89] trial: 38, train_loss: 1.425219, test loss: 1.350891, bias2: 0.7060365676879883, variance: 0.6448546648025513\n",
      "Train size: [400] hidden size: [89] trial: 39, train_loss: 1.425518, test loss: 1.348145, bias2: 0.7059632539749146, variance: 0.6421819925308228\n",
      "Train size: [400] hidden size: [89] trial: 40, train_loss: 1.436094, test loss: 1.347360, bias2: 0.7067508101463318, variance: 0.6406089663505554\n",
      "Train size: [400] hidden size: [89] trial: 41, train_loss: 1.435319, test loss: 1.348090, bias2: 0.7057245373725891, variance: 0.6423658728599548\n",
      "Train size: [400] hidden size: [89] trial: 42, train_loss: 1.435436, test loss: 1.348219, bias2: 0.7065389752388, variance: 0.6416798233985901\n",
      "Train size: [400] hidden size: [89] trial: 43, train_loss: 1.437612, test loss: 1.348091, bias2: 0.7065433859825134, variance: 0.6415477395057678\n",
      "Train size: [400] hidden size: [89] trial: 44, train_loss: 1.436901, test loss: 1.344471, bias2: 0.7067983150482178, variance: 0.6376723051071167\n",
      "Train size: [400] hidden size: [89] trial: 45, train_loss: 1.437405, test loss: 1.344742, bias2: 0.7063287496566772, variance: 0.638413667678833\n",
      "Train size: [400] hidden size: [89] trial: 46, train_loss: 1.429781, test loss: 1.344502, bias2: 0.7076147794723511, variance: 0.6368870735168457\n",
      "Train size: [400] hidden size: [89] trial: 47, train_loss: 1.429554, test loss: 1.345333, bias2: 0.7090432643890381, variance: 0.6362901926040649\n",
      "Train size: [400] hidden size: [89] trial: 48, train_loss: 1.428451, test loss: 1.342667, bias2: 0.7070081233978271, variance: 0.635658860206604\n",
      "Train size: [400] hidden size: [89] trial: 49, train_loss: 1.425857, test loss: 1.343353, bias2: 0.7087186574935913, variance: 0.6346344947814941\n",
      "##################################################\n",
      "Train size: [400] hidden size: [102] trial: 0, train_loss: 1.368428, test loss: 1.628837, bias2: 1.6288368701934814, variance: -2.724783731977709e-09\n",
      "Train size: [400] hidden size: [102] trial: 1, train_loss: 1.508026, test loss: 1.540739, bias2: 1.1596533060073853, variance: 0.38108527660369873\n",
      "Train size: [400] hidden size: [102] trial: 2, train_loss: 1.408159, test loss: 1.517488, bias2: 1.0035794973373413, variance: 0.5139086246490479\n",
      "Train size: [400] hidden size: [102] trial: 3, train_loss: 1.424679, test loss: 1.479865, bias2: 0.9212800860404968, variance: 0.558584988117218\n",
      "Train size: [400] hidden size: [102] trial: 4, train_loss: 1.371545, test loss: 1.471529, bias2: 0.873249888420105, variance: 0.5982786417007446\n",
      "Train size: [400] hidden size: [102] trial: 5, train_loss: 1.353140, test loss: 1.437540, bias2: 0.8200885057449341, variance: 0.6174517869949341\n",
      "Train size: [400] hidden size: [102] trial: 6, train_loss: 1.333204, test loss: 1.452809, bias2: 0.8090350031852722, variance: 0.6437738537788391\n",
      "Train size: [400] hidden size: [102] trial: 7, train_loss: 1.336398, test loss: 1.430602, bias2: 0.7895373702049255, variance: 0.6410647034645081\n",
      "Train size: [400] hidden size: [102] trial: 8, train_loss: 1.330974, test loss: 1.435159, bias2: 0.7873774766921997, variance: 0.6477819681167603\n",
      "Train size: [400] hidden size: [102] trial: 9, train_loss: 1.345723, test loss: 1.429611, bias2: 0.7719169855117798, variance: 0.6576939821243286\n",
      "Train size: [400] hidden size: [102] trial: 10, train_loss: 1.360719, test loss: 1.425724, bias2: 0.7670933604240417, variance: 0.6586304306983948\n",
      "Train size: [400] hidden size: [102] trial: 11, train_loss: 1.349085, test loss: 1.431397, bias2: 0.7522990107536316, variance: 0.679097592830658\n",
      "Train size: [400] hidden size: [102] trial: 12, train_loss: 1.346621, test loss: 1.421372, bias2: 0.7402418851852417, variance: 0.6811302900314331\n",
      "Train size: [400] hidden size: [102] trial: 13, train_loss: 1.352200, test loss: 1.415769, bias2: 0.7358391880989075, variance: 0.6799299120903015\n",
      "Train size: [400] hidden size: [102] trial: 14, train_loss: 1.342997, test loss: 1.437963, bias2: 0.7283452749252319, variance: 0.7096177339553833\n",
      "Train size: [400] hidden size: [102] trial: 15, train_loss: 1.345437, test loss: 1.442422, bias2: 0.7242619395256042, variance: 0.7181598544120789\n",
      "Train size: [400] hidden size: [102] trial: 16, train_loss: 1.350096, test loss: 1.445602, bias2: 0.717786967754364, variance: 0.7278146147727966\n",
      "Train size: [400] hidden size: [102] trial: 17, train_loss: 1.350639, test loss: 1.436594, bias2: 0.7126436233520508, variance: 0.7239505052566528\n",
      "Train size: [400] hidden size: [102] trial: 18, train_loss: 1.343330, test loss: 1.436304, bias2: 0.7128868699073792, variance: 0.7234174609184265\n",
      "Train size: [400] hidden size: [102] trial: 19, train_loss: 1.350497, test loss: 1.444001, bias2: 0.716536819934845, variance: 0.7274640202522278\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [102] trial: 20, train_loss: 1.359117, test loss: 1.454031, bias2: 0.7197794318199158, variance: 0.7342519164085388\n",
      "Train size: [400] hidden size: [102] trial: 21, train_loss: 1.369713, test loss: 1.444288, bias2: 0.7169488668441772, variance: 0.7273386716842651\n",
      "Train size: [400] hidden size: [102] trial: 22, train_loss: 1.372573, test loss: 1.437894, bias2: 0.7128729224205017, variance: 0.7250205874443054\n",
      "Train size: [400] hidden size: [102] trial: 23, train_loss: 1.372170, test loss: 1.439056, bias2: 0.7109087109565735, variance: 0.7281474471092224\n",
      "Train size: [400] hidden size: [102] trial: 24, train_loss: 1.364915, test loss: 1.442900, bias2: 0.7047296762466431, variance: 0.7381699085235596\n",
      "Train size: [400] hidden size: [102] trial: 25, train_loss: 1.369962, test loss: 1.442529, bias2: 0.708044707775116, variance: 0.7344847321510315\n",
      "Train size: [400] hidden size: [102] trial: 26, train_loss: 1.371444, test loss: 1.439081, bias2: 0.708143413066864, variance: 0.7309373021125793\n",
      "Train size: [400] hidden size: [102] trial: 27, train_loss: 1.374236, test loss: 1.444182, bias2: 0.7090620398521423, variance: 0.7351203560829163\n",
      "Train size: [400] hidden size: [102] trial: 28, train_loss: 1.374150, test loss: 1.448835, bias2: 0.7084642052650452, variance: 0.74037104845047\n",
      "Train size: [400] hidden size: [102] trial: 29, train_loss: 1.370738, test loss: 1.450719, bias2: 0.7090038657188416, variance: 0.7417156100273132\n",
      "Train size: [400] hidden size: [102] trial: 30, train_loss: 1.369837, test loss: 1.451505, bias2: 0.7072545886039734, variance: 0.7442501187324524\n",
      "Train size: [400] hidden size: [102] trial: 31, train_loss: 1.372900, test loss: 1.453255, bias2: 0.7063437104225159, variance: 0.7469108700752258\n",
      "Train size: [400] hidden size: [102] trial: 32, train_loss: 1.373116, test loss: 1.451928, bias2: 0.7062938809394836, variance: 0.7456342577934265\n",
      "Train size: [400] hidden size: [102] trial: 33, train_loss: 1.376290, test loss: 1.447711, bias2: 0.7054049968719482, variance: 0.7423062324523926\n",
      "Train size: [400] hidden size: [102] trial: 34, train_loss: 1.375876, test loss: 1.450869, bias2: 0.7010765671730042, variance: 0.7497922778129578\n",
      "Train size: [400] hidden size: [102] trial: 35, train_loss: 1.371607, test loss: 1.450932, bias2: 0.6987393498420715, variance: 0.752193033695221\n",
      "Train size: [400] hidden size: [102] trial: 36, train_loss: 1.367040, test loss: 1.446308, bias2: 0.6980295181274414, variance: 0.7482783794403076\n",
      "Train size: [400] hidden size: [102] trial: 37, train_loss: 1.366417, test loss: 1.447073, bias2: 0.6962429881095886, variance: 0.7508298754692078\n",
      "Train size: [400] hidden size: [102] trial: 38, train_loss: 1.364543, test loss: 1.447227, bias2: 0.6951327919960022, variance: 0.7520938515663147\n",
      "Train size: [400] hidden size: [102] trial: 39, train_loss: 1.363897, test loss: 1.449342, bias2: 0.6951811909675598, variance: 0.7541608214378357\n",
      "Train size: [400] hidden size: [102] trial: 40, train_loss: 1.365388, test loss: 1.444906, bias2: 0.6940565705299377, variance: 0.7508495450019836\n",
      "Train size: [400] hidden size: [102] trial: 41, train_loss: 1.362204, test loss: 1.442235, bias2: 0.6950392723083496, variance: 0.7471957206726074\n",
      "Train size: [400] hidden size: [102] trial: 42, train_loss: 1.368385, test loss: 1.445518, bias2: 0.6922218799591064, variance: 0.7532964944839478\n",
      "Train size: [400] hidden size: [102] trial: 43, train_loss: 1.367278, test loss: 1.444249, bias2: 0.6926134824752808, variance: 0.7516357898712158\n",
      "Train size: [400] hidden size: [102] trial: 44, train_loss: 1.365704, test loss: 1.441842, bias2: 0.6906787753105164, variance: 0.7511635422706604\n",
      "Train size: [400] hidden size: [102] trial: 45, train_loss: 1.367516, test loss: 1.443041, bias2: 0.6891520023345947, variance: 0.753888726234436\n",
      "Train size: [400] hidden size: [102] trial: 46, train_loss: 1.365931, test loss: 1.445999, bias2: 0.6896637082099915, variance: 0.7563356757164001\n",
      "Train size: [400] hidden size: [102] trial: 47, train_loss: 1.367996, test loss: 1.448968, bias2: 0.6901583075523376, variance: 0.7588096261024475\n",
      "Train size: [400] hidden size: [102] trial: 48, train_loss: 1.366550, test loss: 1.447726, bias2: 0.6866719722747803, variance: 0.7610540390014648\n",
      "Train size: [400] hidden size: [102] trial: 49, train_loss: 1.367884, test loss: 1.444617, bias2: 0.6881347298622131, variance: 0.7564825415611267\n",
      "##################################################\n",
      "Train size: [400] hidden size: [118] trial: 0, train_loss: 1.328024, test loss: 1.510550, bias2: 1.5105504989624023, variance: -7.785095901269301e-10\n",
      "Train size: [400] hidden size: [118] trial: 1, train_loss: 1.327302, test loss: 1.488425, bias2: 1.0579631328582764, variance: 0.43046194314956665\n",
      "Train size: [400] hidden size: [118] trial: 2, train_loss: 1.326676, test loss: 1.419577, bias2: 0.893603503704071, variance: 0.5259732604026794\n",
      "Train size: [400] hidden size: [118] trial: 3, train_loss: 1.319237, test loss: 1.447984, bias2: 0.8604456782341003, variance: 0.5875386595726013\n",
      "Train size: [400] hidden size: [118] trial: 4, train_loss: 1.341476, test loss: 1.488485, bias2: 0.8081519603729248, variance: 0.6803330183029175\n",
      "Train size: [400] hidden size: [118] trial: 5, train_loss: 1.310540, test loss: 1.536675, bias2: 0.7731463313102722, variance: 0.7635287642478943\n",
      "Train size: [400] hidden size: [118] trial: 6, train_loss: 1.275464, test loss: 1.541071, bias2: 0.755039632320404, variance: 0.786031186580658\n",
      "Train size: [400] hidden size: [118] trial: 7, train_loss: 1.274699, test loss: 1.528685, bias2: 0.741215705871582, variance: 0.7874690294265747\n",
      "Train size: [400] hidden size: [118] trial: 8, train_loss: 1.260887, test loss: 1.536837, bias2: 0.7400969862937927, variance: 0.7967395186424255\n",
      "Train size: [400] hidden size: [118] trial: 9, train_loss: 1.244722, test loss: 1.526459, bias2: 0.7250009775161743, variance: 0.801458477973938\n",
      "Train size: [400] hidden size: [118] trial: 10, train_loss: 1.242046, test loss: 1.524685, bias2: 0.7183453440666199, variance: 0.8063398003578186\n",
      "Train size: [400] hidden size: [118] trial: 11, train_loss: 1.244386, test loss: 1.529416, bias2: 0.7134753465652466, variance: 0.8159410953521729\n",
      "Train size: [400] hidden size: [118] trial: 12, train_loss: 1.261000, test loss: 1.519988, bias2: 0.7044317722320557, variance: 0.8155558109283447\n",
      "Train size: [400] hidden size: [118] trial: 13, train_loss: 1.259262, test loss: 1.522145, bias2: 0.6973467469215393, variance: 0.8247984051704407\n",
      "Train size: [400] hidden size: [118] trial: 14, train_loss: 1.250471, test loss: 1.521235, bias2: 0.6878786683082581, variance: 0.8333563208580017\n",
      "Train size: [400] hidden size: [118] trial: 15, train_loss: 1.251196, test loss: 1.523529, bias2: 0.6869076490402222, variance: 0.8366211652755737\n",
      "Train size: [400] hidden size: [118] trial: 16, train_loss: 1.250991, test loss: 1.531424, bias2: 0.6864641904830933, variance: 0.8449593782424927\n",
      "Train size: [400] hidden size: [118] trial: 17, train_loss: 1.259330, test loss: 1.535218, bias2: 0.687761664390564, variance: 0.8474562168121338\n",
      "Train size: [400] hidden size: [118] trial: 18, train_loss: 1.255619, test loss: 1.524934, bias2: 0.6798573732376099, variance: 0.8450770378112793\n",
      "Train size: [400] hidden size: [118] trial: 19, train_loss: 1.256593, test loss: 1.533934, bias2: 0.6795209050178528, variance: 0.8544132113456726\n",
      "Train size: [400] hidden size: [118] trial: 20, train_loss: 1.255133, test loss: 1.545980, bias2: 0.6741780042648315, variance: 0.8718023300170898\n",
      "Train size: [400] hidden size: [118] trial: 21, train_loss: 1.257127, test loss: 1.550759, bias2: 0.6687631011009216, variance: 0.8819957375526428\n",
      "Train size: [400] hidden size: [118] trial: 22, train_loss: 1.256635, test loss: 1.546455, bias2: 0.6643218398094177, variance: 0.8821328282356262\n",
      "Train size: [400] hidden size: [118] trial: 23, train_loss: 1.263049, test loss: 1.545090, bias2: 0.6684330105781555, variance: 0.8766569495201111\n",
      "Train size: [400] hidden size: [118] trial: 24, train_loss: 1.266449, test loss: 1.545396, bias2: 0.6693887114524841, variance: 0.8760071396827698\n",
      "Train size: [400] hidden size: [118] trial: 25, train_loss: 1.269073, test loss: 1.547450, bias2: 0.6695405840873718, variance: 0.8779096007347107\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [118] trial: 26, train_loss: 1.268998, test loss: 1.541495, bias2: 0.6672990918159485, variance: 0.8741959929466248\n",
      "Train size: [400] hidden size: [118] trial: 27, train_loss: 1.270083, test loss: 1.541145, bias2: 0.6636412739753723, variance: 0.8775036931037903\n",
      "Train size: [400] hidden size: [118] trial: 28, train_loss: 1.272535, test loss: 1.541592, bias2: 0.6628594994544983, variance: 0.8787326216697693\n",
      "Train size: [400] hidden size: [118] trial: 29, train_loss: 1.266250, test loss: 1.540423, bias2: 0.6607255339622498, variance: 0.8796979784965515\n",
      "Train size: [400] hidden size: [118] trial: 30, train_loss: 1.271462, test loss: 1.536225, bias2: 0.6590401530265808, variance: 0.877185046672821\n",
      "Train size: [400] hidden size: [118] trial: 31, train_loss: 1.272658, test loss: 1.535138, bias2: 0.6587551832199097, variance: 0.8763831853866577\n",
      "Train size: [400] hidden size: [118] trial: 32, train_loss: 1.272422, test loss: 1.536284, bias2: 0.6568262577056885, variance: 0.879457950592041\n",
      "Train size: [400] hidden size: [118] trial: 33, train_loss: 1.269582, test loss: 1.541571, bias2: 0.6543064713478088, variance: 0.8872645497322083\n",
      "Train size: [400] hidden size: [118] trial: 34, train_loss: 1.274713, test loss: 1.542891, bias2: 0.6529309749603271, variance: 0.8899598121643066\n",
      "Train size: [400] hidden size: [118] trial: 35, train_loss: 1.272296, test loss: 1.544500, bias2: 0.6512748599052429, variance: 0.8932248950004578\n",
      "Train size: [400] hidden size: [118] trial: 36, train_loss: 1.275184, test loss: 1.542689, bias2: 0.6497870087623596, variance: 0.8929017186164856\n",
      "Train size: [400] hidden size: [118] trial: 37, train_loss: 1.278165, test loss: 1.539883, bias2: 0.6482077240943909, variance: 0.8916749358177185\n",
      "Train size: [400] hidden size: [118] trial: 38, train_loss: 1.278343, test loss: 1.541927, bias2: 0.6505582928657532, variance: 0.8913691639900208\n",
      "Train size: [400] hidden size: [118] trial: 39, train_loss: 1.277009, test loss: 1.545361, bias2: 0.6478745937347412, variance: 0.8974862098693848\n",
      "Train size: [400] hidden size: [118] trial: 40, train_loss: 1.276941, test loss: 1.543703, bias2: 0.6478198170661926, variance: 0.8958835005760193\n",
      "Train size: [400] hidden size: [118] trial: 41, train_loss: 1.276871, test loss: 1.545594, bias2: 0.6474189162254333, variance: 0.8981749415397644\n",
      "Train size: [400] hidden size: [118] trial: 42, train_loss: 1.278578, test loss: 1.545756, bias2: 0.6472819447517395, variance: 0.8984745144844055\n",
      "Train size: [400] hidden size: [118] trial: 43, train_loss: 1.276428, test loss: 1.545347, bias2: 0.6455851793289185, variance: 0.8997617959976196\n",
      "Train size: [400] hidden size: [118] trial: 44, train_loss: 1.276428, test loss: 1.543657, bias2: 0.6415184736251831, variance: 0.9021382331848145\n",
      "Train size: [400] hidden size: [118] trial: 45, train_loss: 1.276317, test loss: 1.539970, bias2: 0.6388559341430664, variance: 0.9011136293411255\n",
      "Train size: [400] hidden size: [118] trial: 46, train_loss: 1.279964, test loss: 1.539627, bias2: 0.6391343474388123, variance: 0.9004924893379211\n",
      "Train size: [400] hidden size: [118] trial: 47, train_loss: 1.281423, test loss: 1.541589, bias2: 0.6404082179069519, variance: 0.9011803269386292\n",
      "Train size: [400] hidden size: [118] trial: 48, train_loss: 1.281402, test loss: 1.541964, bias2: 0.6394334435462952, variance: 0.9025309681892395\n",
      "Train size: [400] hidden size: [118] trial: 49, train_loss: 1.283880, test loss: 1.546305, bias2: 0.6395455598831177, variance: 0.9067593812942505\n",
      "##################################################\n",
      "Train size: [400] hidden size: [136] trial: 0, train_loss: 1.022150, test loss: 1.465172, bias2: 1.4651716947555542, variance: 4.6710577628061856e-09\n",
      "Train size: [400] hidden size: [136] trial: 1, train_loss: 1.184180, test loss: 1.485933, bias2: 1.0164215564727783, variance: 0.46951109170913696\n",
      "Train size: [400] hidden size: [136] trial: 2, train_loss: 1.151113, test loss: 1.546878, bias2: 0.8675256371498108, variance: 0.6793521046638489\n",
      "Train size: [400] hidden size: [136] trial: 3, train_loss: 1.164981, test loss: 1.585473, bias2: 0.8262340426445007, variance: 0.7592385411262512\n",
      "Train size: [400] hidden size: [136] trial: 4, train_loss: 1.182269, test loss: 1.579673, bias2: 0.7691419720649719, variance: 0.810530960559845\n",
      "Train size: [400] hidden size: [136] trial: 5, train_loss: 1.157736, test loss: 1.588953, bias2: 0.7382795214653015, variance: 0.8506737351417542\n",
      "Train size: [400] hidden size: [136] trial: 6, train_loss: 1.164507, test loss: 1.615521, bias2: 0.7224777340888977, variance: 0.893043577671051\n",
      "Train size: [400] hidden size: [136] trial: 7, train_loss: 1.173525, test loss: 1.651432, bias2: 0.7132850289344788, variance: 0.9381467700004578\n",
      "Train size: [400] hidden size: [136] trial: 8, train_loss: 1.172113, test loss: 1.638734, bias2: 0.6959498524665833, variance: 0.9427838921546936\n",
      "Train size: [400] hidden size: [136] trial: 9, train_loss: 1.189040, test loss: 1.646216, bias2: 0.6770262718200684, variance: 0.9691900014877319\n",
      "Train size: [400] hidden size: [136] trial: 10, train_loss: 1.191172, test loss: 1.650387, bias2: 0.6618564128875732, variance: 0.9885302782058716\n",
      "Train size: [400] hidden size: [136] trial: 11, train_loss: 1.184891, test loss: 1.629482, bias2: 0.649745523929596, variance: 0.979736864566803\n",
      "Train size: [400] hidden size: [136] trial: 12, train_loss: 1.184237, test loss: 1.614481, bias2: 0.6355196833610535, variance: 0.978961169719696\n",
      "Train size: [400] hidden size: [136] trial: 13, train_loss: 1.192613, test loss: 1.643379, bias2: 0.6339606046676636, variance: 1.0094188451766968\n",
      "Train size: [400] hidden size: [136] trial: 14, train_loss: 1.190880, test loss: 1.633368, bias2: 0.6258020401000977, variance: 1.0075657367706299\n",
      "Train size: [400] hidden size: [136] trial: 15, train_loss: 1.182614, test loss: 1.639185, bias2: 0.634986162185669, variance: 1.004198670387268\n",
      "Train size: [400] hidden size: [136] trial: 16, train_loss: 1.187978, test loss: 1.645420, bias2: 0.6328634023666382, variance: 1.012557029724121\n",
      "Train size: [400] hidden size: [136] trial: 17, train_loss: 1.184113, test loss: 1.638820, bias2: 0.6267883777618408, variance: 1.0120311975479126\n",
      "Train size: [400] hidden size: [136] trial: 18, train_loss: 1.182179, test loss: 1.629840, bias2: 0.6258018016815186, variance: 1.0040379762649536\n",
      "Train size: [400] hidden size: [136] trial: 19, train_loss: 1.174236, test loss: 1.624508, bias2: 0.6217077970504761, variance: 1.0028002262115479\n",
      "Train size: [400] hidden size: [136] trial: 20, train_loss: 1.183405, test loss: 1.627823, bias2: 0.6221212148666382, variance: 1.0057013034820557\n",
      "Train size: [400] hidden size: [136] trial: 21, train_loss: 1.183766, test loss: 1.627740, bias2: 0.6150789260864258, variance: 1.0126614570617676\n",
      "Train size: [400] hidden size: [136] trial: 22, train_loss: 1.174664, test loss: 1.616076, bias2: 0.6083558797836304, variance: 1.0077205896377563\n",
      "Train size: [400] hidden size: [136] trial: 23, train_loss: 1.170402, test loss: 1.615311, bias2: 0.603662371635437, variance: 1.0116491317749023\n",
      "Train size: [400] hidden size: [136] trial: 24, train_loss: 1.176745, test loss: 1.610830, bias2: 0.6026023626327515, variance: 1.0082277059555054\n",
      "Train size: [400] hidden size: [136] trial: 25, train_loss: 1.174146, test loss: 1.611275, bias2: 0.6041407585144043, variance: 1.0071340799331665\n",
      "Train size: [400] hidden size: [136] trial: 26, train_loss: 1.167892, test loss: 1.611607, bias2: 0.6051187515258789, variance: 1.0064882040023804\n",
      "Train size: [400] hidden size: [136] trial: 27, train_loss: 1.167236, test loss: 1.613486, bias2: 0.6043124198913574, variance: 1.0091735124588013\n",
      "Train size: [400] hidden size: [136] trial: 28, train_loss: 1.170262, test loss: 1.629377, bias2: 0.6042745113372803, variance: 1.0251024961471558\n",
      "Train size: [400] hidden size: [136] trial: 29, train_loss: 1.171192, test loss: 1.633873, bias2: 0.6062664985656738, variance: 1.0276061296463013\n",
      "Train size: [400] hidden size: [136] trial: 30, train_loss: 1.172518, test loss: 1.634202, bias2: 0.6030311584472656, variance: 1.0311708450317383\n",
      "Train size: [400] hidden size: [136] trial: 31, train_loss: 1.172725, test loss: 1.628500, bias2: 0.599066972732544, variance: 1.029433012008667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [136] trial: 32, train_loss: 1.170387, test loss: 1.625939, bias2: 0.5977550745010376, variance: 1.028184175491333\n",
      "Train size: [400] hidden size: [136] trial: 33, train_loss: 1.168249, test loss: 1.617719, bias2: 0.5986038446426392, variance: 1.019115686416626\n",
      "Train size: [400] hidden size: [136] trial: 34, train_loss: 1.166168, test loss: 1.618498, bias2: 0.5978991985321045, variance: 1.0205984115600586\n",
      "Train size: [400] hidden size: [136] trial: 35, train_loss: 1.167000, test loss: 1.620504, bias2: 0.599579930305481, variance: 1.0209245681762695\n",
      "Train size: [400] hidden size: [136] trial: 36, train_loss: 1.165593, test loss: 1.614906, bias2: 0.6002780199050903, variance: 1.0146278142929077\n",
      "Train size: [400] hidden size: [136] trial: 37, train_loss: 1.164405, test loss: 1.616679, bias2: 0.6003810167312622, variance: 1.016297698020935\n",
      "Train size: [400] hidden size: [136] trial: 38, train_loss: 1.165332, test loss: 1.615441, bias2: 0.5990400314331055, variance: 1.0164011716842651\n",
      "Train size: [400] hidden size: [136] trial: 39, train_loss: 1.165040, test loss: 1.613602, bias2: 0.5978115797042847, variance: 1.0157908201217651\n",
      "Train size: [400] hidden size: [136] trial: 40, train_loss: 1.167895, test loss: 1.610826, bias2: 0.5972959995269775, variance: 1.013529658317566\n",
      "Train size: [400] hidden size: [136] trial: 41, train_loss: 1.166601, test loss: 1.612625, bias2: 0.5981961488723755, variance: 1.0144288539886475\n",
      "Train size: [400] hidden size: [136] trial: 42, train_loss: 1.165398, test loss: 1.610352, bias2: 0.5981855392456055, variance: 1.0121667385101318\n",
      "Train size: [400] hidden size: [136] trial: 43, train_loss: 1.166327, test loss: 1.609628, bias2: 0.597395658493042, variance: 1.0122321844100952\n",
      "Train size: [400] hidden size: [136] trial: 44, train_loss: 1.168517, test loss: 1.609740, bias2: 0.5964757204055786, variance: 1.0132644176483154\n",
      "Train size: [400] hidden size: [136] trial: 45, train_loss: 1.170175, test loss: 1.613386, bias2: 0.5961848497390747, variance: 1.0172009468078613\n",
      "Train size: [400] hidden size: [136] trial: 46, train_loss: 1.173756, test loss: 1.611782, bias2: 0.5979244709014893, variance: 1.013857364654541\n",
      "Train size: [400] hidden size: [136] trial: 47, train_loss: 1.171375, test loss: 1.608454, bias2: 0.5984580516815186, variance: 1.0099962949752808\n",
      "Train size: [400] hidden size: [136] trial: 48, train_loss: 1.168920, test loss: 1.610437, bias2: 0.5989373922348022, variance: 1.0114991664886475\n",
      "Train size: [400] hidden size: [136] trial: 49, train_loss: 1.168671, test loss: 1.612115, bias2: 0.5976386070251465, variance: 1.0144766569137573\n",
      "##################################################\n",
      "Train size: [400] hidden size: [156] trial: 0, train_loss: 0.945038, test loss: 2.066281, bias2: 2.0662808418273926, variance: -7.785095901269301e-10\n",
      "Train size: [400] hidden size: [156] trial: 1, train_loss: 1.030413, test loss: 1.902891, bias2: 1.2820703983306885, variance: 0.6208208799362183\n",
      "Train size: [400] hidden size: [156] trial: 2, train_loss: 0.988594, test loss: 1.861424, bias2: 1.0222198963165283, variance: 0.8392036557197571\n",
      "Train size: [400] hidden size: [156] trial: 3, train_loss: 0.990000, test loss: 1.942986, bias2: 0.9054124355316162, variance: 1.0375734567642212\n",
      "Train size: [400] hidden size: [156] trial: 4, train_loss: 0.971398, test loss: 1.909024, bias2: 0.8419284820556641, variance: 1.0670956373214722\n",
      "Train size: [400] hidden size: [156] trial: 5, train_loss: 0.966809, test loss: 1.905747, bias2: 0.774739146232605, variance: 1.1310080289840698\n",
      "Train size: [400] hidden size: [156] trial: 6, train_loss: 0.970989, test loss: 1.873607, bias2: 0.7376636266708374, variance: 1.135943055152893\n",
      "Train size: [400] hidden size: [156] trial: 7, train_loss: 0.971779, test loss: 1.860355, bias2: 0.7085278034210205, variance: 1.151827096939087\n",
      "Train size: [400] hidden size: [156] trial: 8, train_loss: 0.987625, test loss: 1.875293, bias2: 0.7039052248001099, variance: 1.1713882684707642\n",
      "Train size: [400] hidden size: [156] trial: 9, train_loss: 0.986399, test loss: 1.860964, bias2: 0.6706209182739258, variance: 1.1903433799743652\n",
      "Train size: [400] hidden size: [156] trial: 10, train_loss: 1.012488, test loss: 1.847137, bias2: 0.6548889875411987, variance: 1.1922475099563599\n",
      "Train size: [400] hidden size: [156] trial: 11, train_loss: 1.025259, test loss: 1.835311, bias2: 0.6386923789978027, variance: 1.1966185569763184\n",
      "Train size: [400] hidden size: [156] trial: 12, train_loss: 1.029834, test loss: 1.846120, bias2: 0.642982006072998, variance: 1.2031375169754028\n",
      "Train size: [400] hidden size: [156] trial: 13, train_loss: 1.035690, test loss: 1.844355, bias2: 0.6445266008377075, variance: 1.199828863143921\n",
      "Train size: [400] hidden size: [156] trial: 14, train_loss: 1.029698, test loss: 1.837825, bias2: 0.6365088224411011, variance: 1.2013161182403564\n",
      "Train size: [400] hidden size: [156] trial: 15, train_loss: 1.039709, test loss: 1.839049, bias2: 0.632414698600769, variance: 1.206634283065796\n",
      "Train size: [400] hidden size: [156] trial: 16, train_loss: 1.048577, test loss: 1.843341, bias2: 0.6256222724914551, variance: 1.2177183628082275\n",
      "Train size: [400] hidden size: [156] trial: 17, train_loss: 1.052154, test loss: 1.833388, bias2: 0.617707371711731, variance: 1.2156809568405151\n",
      "Train size: [400] hidden size: [156] trial: 18, train_loss: 1.055794, test loss: 1.836543, bias2: 0.6062318086624146, variance: 1.230311393737793\n",
      "Train size: [400] hidden size: [156] trial: 19, train_loss: 1.051642, test loss: 1.844321, bias2: 0.6084154844284058, variance: 1.2359050512313843\n",
      "Train size: [400] hidden size: [156] trial: 20, train_loss: 1.045025, test loss: 1.838350, bias2: 0.6067359447479248, variance: 1.231614112854004\n",
      "Train size: [400] hidden size: [156] trial: 21, train_loss: 1.042478, test loss: 1.839164, bias2: 0.6032724380493164, variance: 1.2358919382095337\n",
      "Train size: [400] hidden size: [156] trial: 22, train_loss: 1.037952, test loss: 1.834375, bias2: 0.6000524759292603, variance: 1.2343230247497559\n",
      "Train size: [400] hidden size: [156] trial: 23, train_loss: 1.032867, test loss: 1.824177, bias2: 0.5967180728912354, variance: 1.2274590730667114\n",
      "Train size: [400] hidden size: [156] trial: 24, train_loss: 1.034184, test loss: 1.817882, bias2: 0.5933446884155273, variance: 1.2245376110076904\n",
      "Train size: [400] hidden size: [156] trial: 25, train_loss: 1.033067, test loss: 1.823995, bias2: 0.5930237770080566, variance: 1.2309707403182983\n",
      "Train size: [400] hidden size: [156] trial: 26, train_loss: 1.033535, test loss: 1.821877, bias2: 0.5939105749130249, variance: 1.22796630859375\n",
      "Train size: [400] hidden size: [156] trial: 27, train_loss: 1.034381, test loss: 1.814157, bias2: 0.5907934904098511, variance: 1.2233631610870361\n",
      "Train size: [400] hidden size: [156] trial: 28, train_loss: 1.045333, test loss: 1.813931, bias2: 0.5886551141738892, variance: 1.2252758741378784\n",
      "Train size: [400] hidden size: [156] trial: 29, train_loss: 1.046848, test loss: 1.806044, bias2: 0.5833712816238403, variance: 1.222672462463379\n",
      "Train size: [400] hidden size: [156] trial: 30, train_loss: 1.051703, test loss: 1.807066, bias2: 0.5759339332580566, variance: 1.23113214969635\n",
      "Train size: [400] hidden size: [156] trial: 31, train_loss: 1.056170, test loss: 1.797600, bias2: 0.5748988389968872, variance: 1.222700834274292\n",
      "Train size: [400] hidden size: [156] trial: 32, train_loss: 1.055223, test loss: 1.795540, bias2: 0.5746179819107056, variance: 1.2209222316741943\n",
      "Train size: [400] hidden size: [156] trial: 33, train_loss: 1.055746, test loss: 1.792350, bias2: 0.5669810771942139, variance: 1.2253689765930176\n",
      "Train size: [400] hidden size: [156] trial: 34, train_loss: 1.057730, test loss: 1.790478, bias2: 0.5674090385437012, variance: 1.2230688333511353\n",
      "Train size: [400] hidden size: [156] trial: 35, train_loss: 1.054736, test loss: 1.793067, bias2: 0.5662938356399536, variance: 1.2267732620239258\n",
      "Train size: [400] hidden size: [156] trial: 36, train_loss: 1.054932, test loss: 1.787324, bias2: 0.5619615316390991, variance: 1.2253620624542236\n",
      "Train size: [400] hidden size: [156] trial: 37, train_loss: 1.054584, test loss: 1.787731, bias2: 0.5618559122085571, variance: 1.2258756160736084\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [156] trial: 38, train_loss: 1.054566, test loss: 1.787215, bias2: 0.5589473247528076, variance: 1.2282676696777344\n",
      "Train size: [400] hidden size: [156] trial: 39, train_loss: 1.055335, test loss: 1.784271, bias2: 0.5602517127990723, variance: 1.2240194082260132\n",
      "Train size: [400] hidden size: [156] trial: 40, train_loss: 1.055183, test loss: 1.793215, bias2: 0.5610160827636719, variance: 1.2321993112564087\n",
      "Train size: [400] hidden size: [156] trial: 41, train_loss: 1.058193, test loss: 1.789993, bias2: 0.5606848001480103, variance: 1.229308009147644\n",
      "Train size: [400] hidden size: [156] trial: 42, train_loss: 1.059431, test loss: 1.782445, bias2: 0.5598829984664917, variance: 1.2225615978240967\n",
      "Train size: [400] hidden size: [156] trial: 43, train_loss: 1.059446, test loss: 1.784632, bias2: 0.5609058141708374, variance: 1.2237266302108765\n",
      "Train size: [400] hidden size: [156] trial: 44, train_loss: 1.058719, test loss: 1.784147, bias2: 0.5603227615356445, variance: 1.2238242626190186\n",
      "Train size: [400] hidden size: [156] trial: 45, train_loss: 1.055706, test loss: 1.782666, bias2: 0.5592437982559204, variance: 1.2234219312667847\n",
      "Train size: [400] hidden size: [156] trial: 46, train_loss: 1.052925, test loss: 1.781113, bias2: 0.5581146478652954, variance: 1.2229987382888794\n",
      "Train size: [400] hidden size: [156] trial: 47, train_loss: 1.052715, test loss: 1.780557, bias2: 0.5584020614624023, variance: 1.2221546173095703\n",
      "Train size: [400] hidden size: [156] trial: 48, train_loss: 1.055434, test loss: 1.782121, bias2: 0.5596777200698853, variance: 1.222442865371704\n",
      "Train size: [400] hidden size: [156] trial: 49, train_loss: 1.053121, test loss: 1.786507, bias2: 0.5600234270095825, variance: 1.2264835834503174\n",
      "##################################################\n",
      "Train size: [400] hidden size: [180] trial: 0, train_loss: 0.914077, test loss: 1.915555, bias2: 1.9155547618865967, variance: -7.785095901269301e-10\n",
      "Train size: [400] hidden size: [180] trial: 1, train_loss: 0.897991, test loss: 1.856946, bias2: 1.1271237134933472, variance: 0.7298221588134766\n",
      "Train size: [400] hidden size: [180] trial: 2, train_loss: 0.917295, test loss: 1.903255, bias2: 0.9099633693695068, variance: 0.9932914972305298\n",
      "Train size: [400] hidden size: [180] trial: 3, train_loss: 0.901487, test loss: 1.989248, bias2: 0.8063926696777344, variance: 1.1828551292419434\n",
      "Train size: [400] hidden size: [180] trial: 4, train_loss: 0.919606, test loss: 2.048842, bias2: 0.7398933172225952, variance: 1.3089488744735718\n",
      "Train size: [400] hidden size: [180] trial: 5, train_loss: 0.931880, test loss: 2.011881, bias2: 0.679410457611084, variance: 1.332470178604126\n",
      "Train size: [400] hidden size: [180] trial: 6, train_loss: 0.938536, test loss: 2.027168, bias2: 0.6637729406356812, variance: 1.363394856452942\n",
      "Train size: [400] hidden size: [180] trial: 7, train_loss: 0.916025, test loss: 2.020025, bias2: 0.6402419805526733, variance: 1.379783272743225\n",
      "Train size: [400] hidden size: [180] trial: 8, train_loss: 0.924556, test loss: 2.020621, bias2: 0.617955207824707, variance: 1.402665615081787\n",
      "Train size: [400] hidden size: [180] trial: 9, train_loss: 0.925492, test loss: 2.020951, bias2: 0.6099777221679688, variance: 1.410973310470581\n",
      "Train size: [400] hidden size: [180] trial: 10, train_loss: 0.933204, test loss: 2.022533, bias2: 0.614425778388977, variance: 1.4081071615219116\n",
      "Train size: [400] hidden size: [180] trial: 11, train_loss: 0.940021, test loss: 2.020748, bias2: 0.6081832647323608, variance: 1.4125646352767944\n",
      "Train size: [400] hidden size: [180] trial: 12, train_loss: 0.937589, test loss: 2.046406, bias2: 0.58769690990448, variance: 1.458708643913269\n",
      "Train size: [400] hidden size: [180] trial: 13, train_loss: 0.941644, test loss: 2.083874, bias2: 0.5829876661300659, variance: 1.5008867979049683\n",
      "Train size: [400] hidden size: [180] trial: 14, train_loss: 0.938606, test loss: 2.087383, bias2: 0.5723291635513306, variance: 1.5150541067123413\n",
      "Train size: [400] hidden size: [180] trial: 15, train_loss: 0.935785, test loss: 2.087008, bias2: 0.5632764101028442, variance: 1.52373206615448\n",
      "Train size: [400] hidden size: [180] trial: 16, train_loss: 0.935843, test loss: 2.071530, bias2: 0.5557385683059692, variance: 1.5157917737960815\n",
      "Train size: [400] hidden size: [180] trial: 17, train_loss: 0.945805, test loss: 2.074026, bias2: 0.5481507778167725, variance: 1.5258755683898926\n",
      "Train size: [400] hidden size: [180] trial: 18, train_loss: 0.946771, test loss: 2.061991, bias2: 0.544845700263977, variance: 1.517145037651062\n",
      "Train size: [400] hidden size: [180] trial: 19, train_loss: 0.953527, test loss: 2.050252, bias2: 0.5433710813522339, variance: 1.5068813562393188\n",
      "Train size: [400] hidden size: [180] trial: 20, train_loss: 0.950324, test loss: 2.043656, bias2: 0.5356712341308594, variance: 1.5079846382141113\n",
      "Train size: [400] hidden size: [180] trial: 21, train_loss: 0.949884, test loss: 2.056586, bias2: 0.5321216583251953, variance: 1.5244638919830322\n",
      "Train size: [400] hidden size: [180] trial: 22, train_loss: 0.949147, test loss: 2.054851, bias2: 0.5324873924255371, variance: 1.5223634243011475\n",
      "Train size: [400] hidden size: [180] trial: 23, train_loss: 0.947141, test loss: 2.041886, bias2: 0.528622031211853, variance: 1.513264536857605\n",
      "Train size: [400] hidden size: [180] trial: 24, train_loss: 0.941007, test loss: 2.044303, bias2: 0.5254770517349243, variance: 1.518825888633728\n",
      "Train size: [400] hidden size: [180] trial: 25, train_loss: 0.938571, test loss: 2.045380, bias2: 0.5271397829055786, variance: 1.5182398557662964\n",
      "Train size: [400] hidden size: [180] trial: 26, train_loss: 0.938538, test loss: 2.050240, bias2: 0.5245577096939087, variance: 1.5256825685501099\n",
      "Train size: [400] hidden size: [180] trial: 27, train_loss: 0.933765, test loss: 2.040200, bias2: 0.5242972373962402, variance: 1.5159029960632324\n",
      "Train size: [400] hidden size: [180] trial: 28, train_loss: 0.933193, test loss: 2.032596, bias2: 0.5208280086517334, variance: 1.511768102645874\n",
      "Train size: [400] hidden size: [180] trial: 29, train_loss: 0.935105, test loss: 2.033802, bias2: 0.5186417102813721, variance: 1.515160083770752\n",
      "Train size: [400] hidden size: [180] trial: 30, train_loss: 0.937782, test loss: 2.041508, bias2: 0.5213687419891357, variance: 1.5201389789581299\n",
      "Train size: [400] hidden size: [180] trial: 31, train_loss: 0.935067, test loss: 2.037467, bias2: 0.5202158689498901, variance: 1.5172516107559204\n",
      "Train size: [400] hidden size: [180] trial: 32, train_loss: 0.938966, test loss: 2.039024, bias2: 0.5182461738586426, variance: 1.5207781791687012\n",
      "Train size: [400] hidden size: [180] trial: 33, train_loss: 0.940376, test loss: 2.037364, bias2: 0.5156298875808716, variance: 1.5217336416244507\n",
      "Train size: [400] hidden size: [180] trial: 34, train_loss: 0.938637, test loss: 2.034989, bias2: 0.5170303583145142, variance: 1.5179587602615356\n",
      "Train size: [400] hidden size: [180] trial: 35, train_loss: 0.942472, test loss: 2.033542, bias2: 0.5148766040802002, variance: 1.5186653137207031\n",
      "Train size: [400] hidden size: [180] trial: 36, train_loss: 0.941265, test loss: 2.022500, bias2: 0.5138469934463501, variance: 1.5086532831192017\n",
      "Train size: [400] hidden size: [180] trial: 37, train_loss: 0.936255, test loss: 2.022613, bias2: 0.5122417211532593, variance: 1.5103708505630493\n",
      "Train size: [400] hidden size: [180] trial: 38, train_loss: 0.933216, test loss: 2.021265, bias2: 0.50834059715271, variance: 1.5129244327545166\n",
      "Train size: [400] hidden size: [180] trial: 39, train_loss: 0.932251, test loss: 2.014111, bias2: 0.5066814422607422, variance: 1.507429599761963\n",
      "Train size: [400] hidden size: [180] trial: 40, train_loss: 0.936593, test loss: 2.010419, bias2: 0.5072853565216064, variance: 1.5031332969665527\n",
      "Train size: [400] hidden size: [180] trial: 41, train_loss: 0.933102, test loss: 2.010751, bias2: 0.5052347183227539, variance: 1.5055158138275146\n",
      "Train size: [400] hidden size: [180] trial: 42, train_loss: 0.935238, test loss: 2.010432, bias2: 0.5052754878997803, variance: 1.5051569938659668\n",
      "Train size: [400] hidden size: [180] trial: 43, train_loss: 0.939557, test loss: 2.007884, bias2: 0.5027898550033569, variance: 1.5050944089889526\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [180] trial: 44, train_loss: 0.942655, test loss: 2.016066, bias2: 0.5058801174163818, variance: 1.5101861953735352\n",
      "Train size: [400] hidden size: [180] trial: 45, train_loss: 0.940018, test loss: 2.019557, bias2: 0.5017095804214478, variance: 1.5178474187850952\n",
      "Train size: [400] hidden size: [180] trial: 46, train_loss: 0.939807, test loss: 2.018515, bias2: 0.5022553205490112, variance: 1.516259789466858\n",
      "Train size: [400] hidden size: [180] trial: 47, train_loss: 0.939217, test loss: 2.014102, bias2: 0.5029356479644775, variance: 1.5111668109893799\n",
      "Train size: [400] hidden size: [180] trial: 48, train_loss: 0.939141, test loss: 2.008930, bias2: 0.5009255409240723, variance: 1.5080044269561768\n",
      "Train size: [400] hidden size: [180] trial: 49, train_loss: 0.938900, test loss: 2.008972, bias2: 0.4992814064025879, variance: 1.509690523147583\n",
      "##################################################\n",
      "Train size: [400] hidden size: [207] trial: 0, train_loss: 0.834436, test loss: 2.037116, bias2: 2.0371158123016357, variance: 1.8684231051224742e-08\n",
      "Train size: [400] hidden size: [207] trial: 1, train_loss: 0.794567, test loss: 2.171681, bias2: 1.2985892295837402, variance: 0.873091995716095\n",
      "Train size: [400] hidden size: [207] trial: 2, train_loss: 0.776821, test loss: 2.264709, bias2: 1.0089138746261597, variance: 1.2557953596115112\n",
      "Train size: [400] hidden size: [207] trial: 3, train_loss: 0.784013, test loss: 2.322447, bias2: 0.9095351696014404, variance: 1.4129118919372559\n",
      "Train size: [400] hidden size: [207] trial: 4, train_loss: 0.771783, test loss: 2.295830, bias2: 0.7894730567932129, variance: 1.5063574314117432\n",
      "Train size: [400] hidden size: [207] trial: 5, train_loss: 0.753359, test loss: 2.235885, bias2: 0.735142707824707, variance: 1.5007421970367432\n",
      "Train size: [400] hidden size: [207] trial: 6, train_loss: 0.765559, test loss: 2.245127, bias2: 0.6858950853347778, variance: 1.5592321157455444\n",
      "Train size: [400] hidden size: [207] trial: 7, train_loss: 0.764896, test loss: 2.233570, bias2: 0.6503787040710449, variance: 1.5831913948059082\n",
      "Train size: [400] hidden size: [207] trial: 8, train_loss: 0.762365, test loss: 2.241095, bias2: 0.6222714185714722, variance: 1.6188234090805054\n",
      "Train size: [400] hidden size: [207] trial: 9, train_loss: 0.760671, test loss: 2.249354, bias2: 0.5938899517059326, variance: 1.655463695526123\n",
      "Train size: [400] hidden size: [207] trial: 10, train_loss: 0.761248, test loss: 2.262580, bias2: 0.592528223991394, variance: 1.6700516939163208\n",
      "Train size: [400] hidden size: [207] trial: 11, train_loss: 0.764376, test loss: 2.250965, bias2: 0.5642516613006592, variance: 1.686713695526123\n",
      "Train size: [400] hidden size: [207] trial: 12, train_loss: 0.763988, test loss: 2.268103, bias2: 0.5584026575088501, variance: 1.7097002267837524\n",
      "Train size: [400] hidden size: [207] trial: 13, train_loss: 0.766209, test loss: 2.265769, bias2: 0.5505906343460083, variance: 1.7151778936386108\n",
      "Train size: [400] hidden size: [207] trial: 14, train_loss: 0.770392, test loss: 2.258055, bias2: 0.5428622961044312, variance: 1.7151926755905151\n",
      "Train size: [400] hidden size: [207] trial: 15, train_loss: 0.765997, test loss: 2.258798, bias2: 0.5281277894973755, variance: 1.7306700944900513\n",
      "Train size: [400] hidden size: [207] trial: 16, train_loss: 0.768395, test loss: 2.238697, bias2: 0.5200505256652832, variance: 1.718646764755249\n",
      "Train size: [400] hidden size: [207] trial: 17, train_loss: 0.769233, test loss: 2.242222, bias2: 0.5135141611099243, variance: 1.7287079095840454\n",
      "Train size: [400] hidden size: [207] trial: 18, train_loss: 0.769912, test loss: 2.243081, bias2: 0.5092374086380005, variance: 1.733843207359314\n",
      "Train size: [400] hidden size: [207] trial: 19, train_loss: 0.771902, test loss: 2.231002, bias2: 0.5023903846740723, variance: 1.728611707687378\n",
      "Train size: [400] hidden size: [207] trial: 20, train_loss: 0.777229, test loss: 2.237073, bias2: 0.49596571922302246, variance: 1.7411072254180908\n",
      "Train size: [400] hidden size: [207] trial: 21, train_loss: 0.776437, test loss: 2.226049, bias2: 0.48803985118865967, variance: 1.7380090951919556\n",
      "Train size: [400] hidden size: [207] trial: 22, train_loss: 0.771401, test loss: 2.231405, bias2: 0.49031782150268555, variance: 1.7410869598388672\n",
      "Train size: [400] hidden size: [207] trial: 23, train_loss: 0.771310, test loss: 2.227654, bias2: 0.4861646890640259, variance: 1.7414888143539429\n",
      "Train size: [400] hidden size: [207] trial: 24, train_loss: 0.772784, test loss: 2.217620, bias2: 0.48637139797210693, variance: 1.7312482595443726\n",
      "Train size: [400] hidden size: [207] trial: 25, train_loss: 0.780305, test loss: 2.210517, bias2: 0.4822371006011963, variance: 1.7282793521881104\n",
      "Train size: [400] hidden size: [207] trial: 26, train_loss: 0.784478, test loss: 2.209952, bias2: 0.48086512088775635, variance: 1.7290865182876587\n",
      "Train size: [400] hidden size: [207] trial: 27, train_loss: 0.784966, test loss: 2.208339, bias2: 0.4747816324234009, variance: 1.733557105064392\n",
      "Train size: [400] hidden size: [207] trial: 28, train_loss: 0.786527, test loss: 2.209204, bias2: 0.4738200902938843, variance: 1.7353838682174683\n",
      "Train size: [400] hidden size: [207] trial: 29, train_loss: 0.784362, test loss: 2.205868, bias2: 0.4676394462585449, variance: 1.7382287979125977\n",
      "Train size: [400] hidden size: [207] trial: 30, train_loss: 0.785362, test loss: 2.204138, bias2: 0.470150351524353, variance: 1.7339879274368286\n",
      "Train size: [400] hidden size: [207] trial: 31, train_loss: 0.792106, test loss: 2.208462, bias2: 0.4703434705734253, variance: 1.738118052482605\n",
      "Train size: [400] hidden size: [207] trial: 32, train_loss: 0.796952, test loss: 2.206273, bias2: 0.4703540802001953, variance: 1.7359187602996826\n",
      "Train size: [400] hidden size: [207] trial: 33, train_loss: 0.790618, test loss: 2.194894, bias2: 0.4685680866241455, variance: 1.7263259887695312\n",
      "Train size: [400] hidden size: [207] trial: 34, train_loss: 0.791799, test loss: 2.199196, bias2: 0.46529293060302734, variance: 1.7339026927947998\n",
      "Train size: [400] hidden size: [207] trial: 35, train_loss: 0.790741, test loss: 2.205798, bias2: 0.46674561500549316, variance: 1.7390520572662354\n",
      "Train size: [400] hidden size: [207] trial: 36, train_loss: 0.789261, test loss: 2.208555, bias2: 0.4689347743988037, variance: 1.7396202087402344\n",
      "Train size: [400] hidden size: [207] trial: 37, train_loss: 0.788467, test loss: 2.200529, bias2: 0.46659326553344727, variance: 1.733936071395874\n",
      "Train size: [400] hidden size: [207] trial: 38, train_loss: 0.788785, test loss: 2.207839, bias2: 0.462890625, variance: 1.744947910308838\n",
      "Train size: [400] hidden size: [207] trial: 39, train_loss: 0.788126, test loss: 2.217483, bias2: 0.46280860900878906, variance: 1.7546744346618652\n",
      "Train size: [400] hidden size: [207] trial: 40, train_loss: 0.789456, test loss: 2.215819, bias2: 0.4641052484512329, variance: 1.7517138719558716\n",
      "Train size: [400] hidden size: [207] trial: 41, train_loss: 0.786758, test loss: 2.216686, bias2: 0.46213996410369873, variance: 1.75454580783844\n",
      "Train size: [400] hidden size: [207] trial: 42, train_loss: 0.786843, test loss: 2.210242, bias2: 0.45846498012542725, variance: 1.7517765760421753\n",
      "Train size: [400] hidden size: [207] trial: 43, train_loss: 0.788361, test loss: 2.201814, bias2: 0.4553847312927246, variance: 1.7464289665222168\n",
      "Train size: [400] hidden size: [207] trial: 44, train_loss: 0.789553, test loss: 2.195788, bias2: 0.4558664560317993, variance: 1.73992121219635\n",
      "Train size: [400] hidden size: [207] trial: 45, train_loss: 0.790511, test loss: 2.196523, bias2: 0.45828795433044434, variance: 1.7382347583770752\n",
      "Train size: [400] hidden size: [207] trial: 46, train_loss: 0.792888, test loss: 2.196612, bias2: 0.4560030698776245, variance: 1.740608811378479\n",
      "Train size: [400] hidden size: [207] trial: 47, train_loss: 0.792619, test loss: 2.192899, bias2: 0.45442259311676025, variance: 1.7384761571884155\n",
      "Train size: [400] hidden size: [207] trial: 48, train_loss: 0.789890, test loss: 2.194879, bias2: 0.45451295375823975, variance: 1.7403661012649536\n",
      "Train size: [400] hidden size: [207] trial: 49, train_loss: 0.790221, test loss: 2.200579, bias2: 0.45556938648223877, variance: 1.7450093030929565\n",
      "##################################################\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [239] trial: 0, train_loss: 0.644813, test loss: 2.578860, bias2: 2.578859567642212, variance: -2.1798269855821673e-08\n",
      "Train size: [400] hidden size: [239] trial: 1, train_loss: 0.686437, test loss: 2.348988, bias2: 1.2891640663146973, variance: 1.059823751449585\n",
      "Train size: [400] hidden size: [239] trial: 2, train_loss: 0.691564, test loss: 2.313786, bias2: 0.9843131303787231, variance: 1.3294724225997925\n",
      "Train size: [400] hidden size: [239] trial: 3, train_loss: 0.665838, test loss: 2.331445, bias2: 0.8477137088775635, variance: 1.4837312698364258\n",
      "Train size: [400] hidden size: [239] trial: 4, train_loss: 0.678318, test loss: 2.348965, bias2: 0.7188879251480103, variance: 1.6300767660140991\n",
      "Train size: [400] hidden size: [239] trial: 5, train_loss: 0.671644, test loss: 2.326221, bias2: 0.6566205024719238, variance: 1.6696009635925293\n",
      "Train size: [400] hidden size: [239] trial: 6, train_loss: 0.683412, test loss: 2.417115, bias2: 0.6284512281417847, variance: 1.7886635065078735\n",
      "Train size: [400] hidden size: [239] trial: 7, train_loss: 0.674052, test loss: 2.425004, bias2: 0.5986500978469849, variance: 1.8263541460037231\n",
      "Train size: [400] hidden size: [239] trial: 8, train_loss: 0.659577, test loss: 2.464289, bias2: 0.5899389982223511, variance: 1.8743501901626587\n",
      "Train size: [400] hidden size: [239] trial: 9, train_loss: 0.665593, test loss: 2.445086, bias2: 0.5654990673065186, variance: 1.8795874118804932\n",
      "Train size: [400] hidden size: [239] trial: 10, train_loss: 0.666219, test loss: 2.450706, bias2: 0.5402114391326904, variance: 1.910494089126587\n",
      "Train size: [400] hidden size: [239] trial: 11, train_loss: 0.663258, test loss: 2.462661, bias2: 0.5145294666290283, variance: 1.9481313228607178\n",
      "Train size: [400] hidden size: [239] trial: 12, train_loss: 0.664613, test loss: 2.481381, bias2: 0.5086995363235474, variance: 1.9726814031600952\n",
      "Train size: [400] hidden size: [239] trial: 13, train_loss: 0.662371, test loss: 2.454054, bias2: 0.4981273412704468, variance: 1.955926537513733\n",
      "Train size: [400] hidden size: [239] trial: 14, train_loss: 0.664788, test loss: 2.462051, bias2: 0.49365127086639404, variance: 1.9683996438980103\n",
      "Train size: [400] hidden size: [239] trial: 15, train_loss: 0.665929, test loss: 2.475918, bias2: 0.48612916469573975, variance: 1.9897888898849487\n",
      "Train size: [400] hidden size: [239] trial: 16, train_loss: 0.667605, test loss: 2.483556, bias2: 0.47617149353027344, variance: 2.0073843002319336\n",
      "Train size: [400] hidden size: [239] trial: 17, train_loss: 0.667587, test loss: 2.468427, bias2: 0.4700946807861328, variance: 1.9983325004577637\n",
      "Train size: [400] hidden size: [239] trial: 18, train_loss: 0.665014, test loss: 2.484486, bias2: 0.471360445022583, variance: 2.0131256580352783\n",
      "Train size: [400] hidden size: [239] trial: 19, train_loss: 0.660136, test loss: 2.478564, bias2: 0.4622042179107666, variance: 2.016360282897949\n",
      "Train size: [400] hidden size: [239] trial: 20, train_loss: 0.659304, test loss: 2.463367, bias2: 0.4590950012207031, variance: 2.004272222518921\n",
      "Train size: [400] hidden size: [239] trial: 21, train_loss: 0.658820, test loss: 2.458054, bias2: 0.4578371047973633, variance: 2.000216484069824\n",
      "Train size: [400] hidden size: [239] trial: 22, train_loss: 0.655632, test loss: 2.466273, bias2: 0.4532437324523926, variance: 2.0130293369293213\n",
      "Train size: [400] hidden size: [239] trial: 23, train_loss: 0.657600, test loss: 2.478330, bias2: 0.4465181827545166, variance: 2.0318119525909424\n",
      "Train size: [400] hidden size: [239] trial: 24, train_loss: 0.660019, test loss: 2.466827, bias2: 0.44543886184692383, variance: 2.0213875770568848\n",
      "Train size: [400] hidden size: [239] trial: 25, train_loss: 0.662907, test loss: 2.466371, bias2: 0.44246602058410645, variance: 2.0239052772521973\n",
      "Train size: [400] hidden size: [239] trial: 26, train_loss: 0.663378, test loss: 2.471777, bias2: 0.4413635730743408, variance: 2.0304136276245117\n",
      "Train size: [400] hidden size: [239] trial: 27, train_loss: 0.666147, test loss: 2.495867, bias2: 0.4380183219909668, variance: 2.0578484535217285\n",
      "Train size: [400] hidden size: [239] trial: 28, train_loss: 0.663213, test loss: 2.507474, bias2: 0.4361412525177002, variance: 2.0713329315185547\n",
      "Train size: [400] hidden size: [239] trial: 29, train_loss: 0.664717, test loss: 2.493836, bias2: 0.43171119689941406, variance: 2.062124490737915\n",
      "Train size: [400] hidden size: [239] trial: 30, train_loss: 0.665643, test loss: 2.494764, bias2: 0.42862796783447266, variance: 2.0661356449127197\n",
      "Train size: [400] hidden size: [239] trial: 31, train_loss: 0.663367, test loss: 2.503203, bias2: 0.4288187026977539, variance: 2.0743844509124756\n",
      "Train size: [400] hidden size: [239] trial: 32, train_loss: 0.662904, test loss: 2.495846, bias2: 0.4284689426422119, variance: 2.0673768520355225\n",
      "Train size: [400] hidden size: [239] trial: 33, train_loss: 0.662611, test loss: 2.483546, bias2: 0.422649621963501, variance: 2.0608959197998047\n",
      "Train size: [400] hidden size: [239] trial: 34, train_loss: 0.660693, test loss: 2.490908, bias2: 0.4247729778289795, variance: 2.0661351680755615\n",
      "Train size: [400] hidden size: [239] trial: 35, train_loss: 0.658323, test loss: 2.498075, bias2: 0.422715425491333, variance: 2.075359582901001\n",
      "Train size: [400] hidden size: [239] trial: 36, train_loss: 0.657829, test loss: 2.495946, bias2: 0.41841983795166016, variance: 2.0775258541107178\n",
      "Train size: [400] hidden size: [239] trial: 37, train_loss: 0.659229, test loss: 2.492272, bias2: 0.41754841804504395, variance: 2.074723482131958\n",
      "Train size: [400] hidden size: [239] trial: 38, train_loss: 0.661820, test loss: 2.484441, bias2: 0.4190213680267334, variance: 2.065420150756836\n",
      "Train size: [400] hidden size: [239] trial: 39, train_loss: 0.667121, test loss: 2.494695, bias2: 0.42073726654052734, variance: 2.0739574432373047\n",
      "Train size: [400] hidden size: [239] trial: 40, train_loss: 0.666748, test loss: 2.494018, bias2: 0.41760730743408203, variance: 2.0764102935791016\n",
      "Train size: [400] hidden size: [239] trial: 41, train_loss: 0.666343, test loss: 2.483073, bias2: 0.4148428440093994, variance: 2.068230152130127\n",
      "Train size: [400] hidden size: [239] trial: 42, train_loss: 0.665996, test loss: 2.479127, bias2: 0.4160735607147217, variance: 2.0630533695220947\n",
      "Train size: [400] hidden size: [239] trial: 43, train_loss: 0.665159, test loss: 2.484155, bias2: 0.416201114654541, variance: 2.06795334815979\n",
      "Train size: [400] hidden size: [239] trial: 44, train_loss: 0.664496, test loss: 2.495617, bias2: 0.4173433780670166, variance: 2.0782735347747803\n",
      "Train size: [400] hidden size: [239] trial: 45, train_loss: 0.664837, test loss: 2.497084, bias2: 0.41442370414733887, variance: 2.082660675048828\n",
      "Train size: [400] hidden size: [239] trial: 46, train_loss: 0.663632, test loss: 2.505010, bias2: 0.4156167507171631, variance: 2.089393377304077\n",
      "Train size: [400] hidden size: [239] trial: 47, train_loss: 0.664937, test loss: 2.498184, bias2: 0.4142274856567383, variance: 2.083956718444824\n",
      "Train size: [400] hidden size: [239] trial: 48, train_loss: 0.665248, test loss: 2.498581, bias2: 0.41220760345458984, variance: 2.0863728523254395\n",
      "Train size: [400] hidden size: [239] trial: 49, train_loss: 0.668582, test loss: 2.496977, bias2: 0.41000866889953613, variance: 2.086968183517456\n",
      "##################################################\n",
      "Train size: [400] hidden size: [275] trial: 0, train_loss: 0.522674, test loss: 2.861109, bias2: 2.8611090183258057, variance: -6.228076721015441e-09\n",
      "Train size: [400] hidden size: [275] trial: 1, train_loss: 0.528171, test loss: 2.709576, bias2: 1.4721342325210571, variance: 1.237442135810852\n",
      "Train size: [400] hidden size: [275] trial: 2, train_loss: 0.516274, test loss: 2.746843, bias2: 1.083681583404541, variance: 1.6631615161895752\n",
      "Train size: [400] hidden size: [275] trial: 3, train_loss: 0.540653, test loss: 2.734677, bias2: 0.8994148969650269, variance: 1.8352621793746948\n",
      "Train size: [400] hidden size: [275] trial: 4, train_loss: 0.545123, test loss: 2.688905, bias2: 0.7874363660812378, variance: 1.9014688730239868\n",
      "Train size: [400] hidden size: [275] trial: 5, train_loss: 0.549217, test loss: 2.681304, bias2: 0.6982020139694214, variance: 1.983101725578308\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [275] trial: 6, train_loss: 0.547720, test loss: 2.642369, bias2: 0.6362442970275879, variance: 2.006124496459961\n",
      "Train size: [400] hidden size: [275] trial: 7, train_loss: 0.543221, test loss: 2.636876, bias2: 0.5819449424743652, variance: 2.054931402206421\n",
      "Train size: [400] hidden size: [275] trial: 8, train_loss: 0.546494, test loss: 2.608608, bias2: 0.5435795783996582, variance: 2.065028667449951\n",
      "Train size: [400] hidden size: [275] trial: 9, train_loss: 0.537347, test loss: 2.601686, bias2: 0.525712251663208, variance: 2.075974225997925\n",
      "Train size: [400] hidden size: [275] trial: 10, train_loss: 0.535603, test loss: 2.603525, bias2: 0.5075032711029053, variance: 2.0960211753845215\n",
      "Train size: [400] hidden size: [275] trial: 11, train_loss: 0.519795, test loss: 2.592255, bias2: 0.5036866664886475, variance: 2.0885682106018066\n",
      "Train size: [400] hidden size: [275] trial: 12, train_loss: 0.521131, test loss: 2.594664, bias2: 0.4856104850769043, variance: 2.109053373336792\n",
      "Train size: [400] hidden size: [275] trial: 13, train_loss: 0.521850, test loss: 2.650271, bias2: 0.49065208435058594, variance: 2.159619092941284\n",
      "Train size: [400] hidden size: [275] trial: 14, train_loss: 0.522360, test loss: 2.701591, bias2: 0.4779653549194336, variance: 2.2236251831054688\n",
      "Train size: [400] hidden size: [275] trial: 15, train_loss: 0.524994, test loss: 2.683664, bias2: 0.4629654884338379, variance: 2.220698833465576\n",
      "Train size: [400] hidden size: [275] trial: 16, train_loss: 0.521928, test loss: 2.679502, bias2: 0.44727110862731934, variance: 2.2322306632995605\n",
      "Train size: [400] hidden size: [275] trial: 17, train_loss: 0.515625, test loss: 2.683472, bias2: 0.44136762619018555, variance: 2.2421038150787354\n",
      "Train size: [400] hidden size: [275] trial: 18, train_loss: 0.517130, test loss: 2.717146, bias2: 0.4394805431365967, variance: 2.277665376663208\n",
      "Train size: [400] hidden size: [275] trial: 19, train_loss: 0.514753, test loss: 2.716562, bias2: 0.4364662170410156, variance: 2.280095338821411\n",
      "Train size: [400] hidden size: [275] trial: 20, train_loss: 0.509897, test loss: 2.720970, bias2: 0.4347505569458008, variance: 2.286219358444214\n",
      "Train size: [400] hidden size: [275] trial: 21, train_loss: 0.512577, test loss: 2.739239, bias2: 0.4284348487854004, variance: 2.3108041286468506\n",
      "Train size: [400] hidden size: [275] trial: 22, train_loss: 0.513852, test loss: 2.746803, bias2: 0.4213902950286865, variance: 2.3254129886627197\n",
      "Train size: [400] hidden size: [275] trial: 23, train_loss: 0.511886, test loss: 2.777129, bias2: 0.42371511459350586, variance: 2.353414297103882\n",
      "Train size: [400] hidden size: [275] trial: 24, train_loss: 0.512343, test loss: 2.773569, bias2: 0.42047929763793945, variance: 2.3530898094177246\n",
      "Train size: [400] hidden size: [275] trial: 25, train_loss: 0.513725, test loss: 2.769117, bias2: 0.42021703720092773, variance: 2.348900556564331\n",
      "Train size: [400] hidden size: [275] trial: 26, train_loss: 0.509063, test loss: 2.798835, bias2: 0.4105691909790039, variance: 2.388266086578369\n",
      "Train size: [400] hidden size: [275] trial: 27, train_loss: 0.507703, test loss: 2.802065, bias2: 0.40731382369995117, variance: 2.3947508335113525\n",
      "Train size: [400] hidden size: [275] trial: 28, train_loss: 0.509469, test loss: 2.800167, bias2: 0.40411877632141113, variance: 2.3960483074188232\n",
      "Train size: [400] hidden size: [275] trial: 29, train_loss: 0.508917, test loss: 2.791628, bias2: 0.39972758293151855, variance: 2.391900062561035\n",
      "Train size: [400] hidden size: [275] trial: 30, train_loss: 0.507452, test loss: 2.792214, bias2: 0.39471960067749023, variance: 2.3974947929382324\n",
      "Train size: [400] hidden size: [275] trial: 31, train_loss: 0.507259, test loss: 2.801394, bias2: 0.39397668838500977, variance: 2.4074177742004395\n",
      "Train size: [400] hidden size: [275] trial: 32, train_loss: 0.509812, test loss: 2.806209, bias2: 0.38982439041137695, variance: 2.416384220123291\n",
      "Train size: [400] hidden size: [275] trial: 33, train_loss: 0.508726, test loss: 2.797545, bias2: 0.388455867767334, variance: 2.4090888500213623\n",
      "Train size: [400] hidden size: [275] trial: 34, train_loss: 0.508131, test loss: 2.802753, bias2: 0.385636568069458, variance: 2.417116165161133\n",
      "Train size: [400] hidden size: [275] trial: 35, train_loss: 0.510555, test loss: 2.818268, bias2: 0.3877999782562256, variance: 2.4304678440093994\n",
      "Train size: [400] hidden size: [275] trial: 36, train_loss: 0.510580, test loss: 2.813739, bias2: 0.386976957321167, variance: 2.4267616271972656\n",
      "Train size: [400] hidden size: [275] trial: 37, train_loss: 0.510612, test loss: 2.818325, bias2: 0.3886716365814209, variance: 2.4296531677246094\n",
      "Train size: [400] hidden size: [275] trial: 38, train_loss: 0.510739, test loss: 2.830114, bias2: 0.38491296768188477, variance: 2.4452006816864014\n",
      "Train size: [400] hidden size: [275] trial: 39, train_loss: 0.509173, test loss: 2.844338, bias2: 0.382007360458374, variance: 2.4623303413391113\n",
      "Train size: [400] hidden size: [275] trial: 40, train_loss: 0.508162, test loss: 2.847658, bias2: 0.3835451602935791, variance: 2.4641127586364746\n",
      "Train size: [400] hidden size: [275] trial: 41, train_loss: 0.507489, test loss: 2.843943, bias2: 0.379913330078125, variance: 2.464029312133789\n",
      "Train size: [400] hidden size: [275] trial: 42, train_loss: 0.506374, test loss: 2.844416, bias2: 0.3774585723876953, variance: 2.4669575691223145\n",
      "Train size: [400] hidden size: [275] trial: 43, train_loss: 0.507848, test loss: 2.840613, bias2: 0.3762357234954834, variance: 2.464376926422119\n",
      "Train size: [400] hidden size: [275] trial: 44, train_loss: 0.508775, test loss: 2.833369, bias2: 0.37450313568115234, variance: 2.4588658809661865\n",
      "Train size: [400] hidden size: [275] trial: 45, train_loss: 0.509286, test loss: 2.826676, bias2: 0.3736531734466553, variance: 2.4530224800109863\n",
      "Train size: [400] hidden size: [275] trial: 46, train_loss: 0.510340, test loss: 2.820264, bias2: 0.37412118911743164, variance: 2.4461424350738525\n",
      "Train size: [400] hidden size: [275] trial: 47, train_loss: 0.511208, test loss: 2.817727, bias2: 0.3712000846862793, variance: 2.446526527404785\n",
      "Train size: [400] hidden size: [275] trial: 48, train_loss: 0.511002, test loss: 2.816419, bias2: 0.36981797218322754, variance: 2.446601390838623\n",
      "Train size: [400] hidden size: [275] trial: 49, train_loss: 0.511656, test loss: 2.819692, bias2: 0.37272119522094727, variance: 2.4469707012176514\n",
      "##################################################\n",
      "Train size: [400] hidden size: [316] trial: 0, train_loss: 0.335535, test loss: 3.478350, bias2: 3.4783496856689453, variance: 5.760971433232953e-08\n",
      "Train size: [400] hidden size: [316] trial: 1, train_loss: 0.332017, test loss: 3.416535, bias2: 1.9328910112380981, variance: 1.483643651008606\n",
      "Train size: [400] hidden size: [316] trial: 2, train_loss: 0.333727, test loss: 3.184407, bias2: 1.2923414707183838, variance: 1.8920650482177734\n",
      "Train size: [400] hidden size: [316] trial: 3, train_loss: 0.340424, test loss: 3.220316, bias2: 1.1033995151519775, variance: 2.1169168949127197\n",
      "Train size: [400] hidden size: [316] trial: 4, train_loss: 0.333882, test loss: 3.184125, bias2: 0.9184904098510742, variance: 2.2656350135803223\n",
      "Train size: [400] hidden size: [316] trial: 5, train_loss: 0.331494, test loss: 3.172851, bias2: 0.7960391044616699, variance: 2.376812219619751\n",
      "Train size: [400] hidden size: [316] trial: 6, train_loss: 0.331724, test loss: 3.211651, bias2: 0.7039370536804199, variance: 2.50771427154541\n",
      "Train size: [400] hidden size: [316] trial: 7, train_loss: 0.334053, test loss: 3.203739, bias2: 0.6315634250640869, variance: 2.572175979614258\n",
      "Train size: [400] hidden size: [316] trial: 8, train_loss: 0.340657, test loss: 3.122691, bias2: 0.5849332809448242, variance: 2.537757396697998\n",
      "Train size: [400] hidden size: [316] trial: 9, train_loss: 0.339393, test loss: 3.144183, bias2: 0.560387372970581, variance: 2.5837950706481934\n",
      "Train size: [400] hidden size: [316] trial: 10, train_loss: 0.345060, test loss: 3.153831, bias2: 0.5348196029663086, variance: 2.619011402130127\n",
      "Train size: [400] hidden size: [316] trial: 11, train_loss: 0.346374, test loss: 3.192473, bias2: 0.5067522525787354, variance: 2.685720920562744\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [316] trial: 12, train_loss: 0.350569, test loss: 3.170927, bias2: 0.4803121089935303, variance: 2.690614938735962\n",
      "Train size: [400] hidden size: [316] trial: 13, train_loss: 0.354128, test loss: 3.205389, bias2: 0.47238588333129883, variance: 2.7330026626586914\n",
      "Train size: [400] hidden size: [316] trial: 14, train_loss: 0.351188, test loss: 3.230373, bias2: 0.46466898918151855, variance: 2.7657036781311035\n",
      "Train size: [400] hidden size: [316] trial: 15, train_loss: 0.349323, test loss: 3.240797, bias2: 0.46201443672180176, variance: 2.778782606124878\n",
      "Train size: [400] hidden size: [316] trial: 16, train_loss: 0.350555, test loss: 3.253821, bias2: 0.4565126895904541, variance: 2.7973084449768066\n",
      "Train size: [400] hidden size: [316] trial: 17, train_loss: 0.357489, test loss: 3.254327, bias2: 0.44942712783813477, variance: 2.8049001693725586\n",
      "Train size: [400] hidden size: [316] trial: 18, train_loss: 0.355497, test loss: 3.259178, bias2: 0.4310262203216553, variance: 2.8281514644622803\n",
      "Train size: [400] hidden size: [316] trial: 19, train_loss: 0.360392, test loss: 3.245589, bias2: 0.42321300506591797, variance: 2.822376012802124\n",
      "Train size: [400] hidden size: [316] trial: 20, train_loss: 0.360283, test loss: 3.264241, bias2: 0.4148881435394287, variance: 2.849353075027466\n",
      "Train size: [400] hidden size: [316] trial: 21, train_loss: 0.359938, test loss: 3.271878, bias2: 0.4109628200531006, variance: 2.860915422439575\n",
      "Train size: [400] hidden size: [316] trial: 22, train_loss: 0.359569, test loss: 3.262784, bias2: 0.40192151069641113, variance: 2.8608622550964355\n",
      "Train size: [400] hidden size: [316] trial: 23, train_loss: 0.356990, test loss: 3.244283, bias2: 0.3927955627441406, variance: 2.851487159729004\n",
      "Train size: [400] hidden size: [316] trial: 24, train_loss: 0.355801, test loss: 3.257312, bias2: 0.39238953590393066, variance: 2.864922523498535\n",
      "Train size: [400] hidden size: [316] trial: 25, train_loss: 0.355080, test loss: 3.237241, bias2: 0.3886451721191406, variance: 2.8485960960388184\n",
      "Train size: [400] hidden size: [316] trial: 26, train_loss: 0.354484, test loss: 3.241835, bias2: 0.3826920986175537, variance: 2.8591432571411133\n",
      "Train size: [400] hidden size: [316] trial: 27, train_loss: 0.353451, test loss: 3.249318, bias2: 0.37993526458740234, variance: 2.869382619857788\n",
      "Train size: [400] hidden size: [316] trial: 28, train_loss: 0.352187, test loss: 3.251187, bias2: 0.3759126663208008, variance: 2.8752739429473877\n",
      "Train size: [400] hidden size: [316] trial: 29, train_loss: 0.349585, test loss: 3.249386, bias2: 0.3702268600463867, variance: 2.879159450531006\n",
      "Train size: [400] hidden size: [316] trial: 30, train_loss: 0.347442, test loss: 3.241632, bias2: 0.3631322383880615, variance: 2.8784995079040527\n",
      "Train size: [400] hidden size: [316] trial: 31, train_loss: 0.347113, test loss: 3.227930, bias2: 0.36031675338745117, variance: 2.8676130771636963\n",
      "Train size: [400] hidden size: [316] trial: 32, train_loss: 0.347863, test loss: 3.217921, bias2: 0.35424232482910156, variance: 2.863678216934204\n",
      "Train size: [400] hidden size: [316] trial: 33, train_loss: 0.349347, test loss: 3.228758, bias2: 0.3500509262084961, variance: 2.87870717048645\n",
      "Train size: [400] hidden size: [316] trial: 34, train_loss: 0.348891, test loss: 3.213614, bias2: 0.346271276473999, variance: 2.867342948913574\n",
      "Train size: [400] hidden size: [316] trial: 35, train_loss: 0.348920, test loss: 3.216520, bias2: 0.3460524082183838, variance: 2.8704676628112793\n",
      "Train size: [400] hidden size: [316] trial: 36, train_loss: 0.350460, test loss: 3.228620, bias2: 0.34526515007019043, variance: 2.883354902267456\n",
      "Train size: [400] hidden size: [316] trial: 37, train_loss: 0.349732, test loss: 3.232374, bias2: 0.34584641456604004, variance: 2.8865275382995605\n",
      "Train size: [400] hidden size: [316] trial: 38, train_loss: 0.349540, test loss: 3.233537, bias2: 0.34263110160827637, variance: 2.8909058570861816\n",
      "Train size: [400] hidden size: [316] trial: 39, train_loss: 0.350321, test loss: 3.218531, bias2: 0.33958864212036133, variance: 2.8789427280426025\n",
      "Train size: [400] hidden size: [316] trial: 40, train_loss: 0.349643, test loss: 3.211363, bias2: 0.33782339096069336, variance: 2.873539447784424\n",
      "Train size: [400] hidden size: [316] trial: 41, train_loss: 0.348015, test loss: 3.206737, bias2: 0.3381998538970947, variance: 2.868537664413452\n",
      "Train size: [400] hidden size: [316] trial: 42, train_loss: 0.348539, test loss: 3.199290, bias2: 0.33847975730895996, variance: 2.8608102798461914\n",
      "Train size: [400] hidden size: [316] trial: 43, train_loss: 0.349154, test loss: 3.206204, bias2: 0.3388078212738037, variance: 2.8673958778381348\n",
      "Train size: [400] hidden size: [316] trial: 44, train_loss: 0.350257, test loss: 3.215015, bias2: 0.33660435676574707, variance: 2.878410816192627\n",
      "Train size: [400] hidden size: [316] trial: 45, train_loss: 0.351113, test loss: 3.228185, bias2: 0.33394742012023926, variance: 2.894237756729126\n",
      "Train size: [400] hidden size: [316] trial: 46, train_loss: 0.350881, test loss: 3.226408, bias2: 0.33272218704223633, variance: 2.893685817718506\n",
      "Train size: [400] hidden size: [316] trial: 47, train_loss: 0.350121, test loss: 3.224091, bias2: 0.3341665267944336, variance: 2.8899240493774414\n",
      "Train size: [400] hidden size: [316] trial: 48, train_loss: 0.348528, test loss: 3.219810, bias2: 0.3310050964355469, variance: 2.8888051509857178\n",
      "Train size: [400] hidden size: [316] trial: 49, train_loss: 0.349546, test loss: 3.216380, bias2: 0.32827210426330566, variance: 2.888108253479004\n",
      "##################################################\n",
      "Train size: [400] hidden size: [364] trial: 0, train_loss: 0.226986, test loss: 3.084348, bias2: 3.084348440170288, variance: 1.5570192246627812e-08\n",
      "Train size: [400] hidden size: [364] trial: 1, train_loss: 0.258086, test loss: 3.241930, bias2: 1.7037947177886963, variance: 1.5381348133087158\n",
      "Train size: [400] hidden size: [364] trial: 2, train_loss: 0.237176, test loss: 3.173176, bias2: 1.1698331832885742, variance: 2.003343105316162\n",
      "Train size: [400] hidden size: [364] trial: 3, train_loss: 0.235289, test loss: 3.159409, bias2: 0.929459810256958, variance: 2.2299487590789795\n",
      "Train size: [400] hidden size: [364] trial: 4, train_loss: 0.239416, test loss: 3.154863, bias2: 0.8045647144317627, variance: 2.3502981662750244\n",
      "Train size: [400] hidden size: [364] trial: 5, train_loss: 0.238224, test loss: 3.135318, bias2: 0.7254860401153564, variance: 2.4098315238952637\n",
      "Train size: [400] hidden size: [364] trial: 6, train_loss: 0.239477, test loss: 3.148795, bias2: 0.6514091491699219, variance: 2.4973862171173096\n",
      "Train size: [400] hidden size: [364] trial: 7, train_loss: 0.235869, test loss: 3.164867, bias2: 0.6194643974304199, variance: 2.545403003692627\n",
      "Train size: [400] hidden size: [364] trial: 8, train_loss: 0.237710, test loss: 3.205885, bias2: 0.5701198577880859, variance: 2.6357645988464355\n",
      "Train size: [400] hidden size: [364] trial: 9, train_loss: 0.236211, test loss: 3.255531, bias2: 0.5483503341674805, variance: 2.707180976867676\n",
      "Train size: [400] hidden size: [364] trial: 10, train_loss: 0.238755, test loss: 3.229162, bias2: 0.510535478591919, variance: 2.7186262607574463\n",
      "Train size: [400] hidden size: [364] trial: 11, train_loss: 0.237095, test loss: 3.271271, bias2: 0.4891855716705322, variance: 2.782085418701172\n",
      "Train size: [400] hidden size: [364] trial: 12, train_loss: 0.235621, test loss: 3.293895, bias2: 0.46477818489074707, variance: 2.8291168212890625\n",
      "Train size: [400] hidden size: [364] trial: 13, train_loss: 0.236802, test loss: 3.305068, bias2: 0.4426095485687256, variance: 2.8624587059020996\n",
      "Train size: [400] hidden size: [364] trial: 14, train_loss: 0.237605, test loss: 3.319718, bias2: 0.42932605743408203, variance: 2.890392541885376\n",
      "Train size: [400] hidden size: [364] trial: 15, train_loss: 0.237070, test loss: 3.322574, bias2: 0.421245813369751, variance: 2.9013280868530273\n",
      "Train size: [400] hidden size: [364] trial: 16, train_loss: 0.234341, test loss: 3.317663, bias2: 0.40155768394470215, variance: 2.916105270385742\n",
      "Train size: [400] hidden size: [364] trial: 17, train_loss: 0.236403, test loss: 3.304245, bias2: 0.38851308822631836, variance: 2.91573166847229\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [364] trial: 18, train_loss: 0.235602, test loss: 3.299381, bias2: 0.37369799613952637, variance: 2.925682783126831\n",
      "Train size: [400] hidden size: [364] trial: 19, train_loss: 0.233680, test loss: 3.293704, bias2: 0.36652445793151855, variance: 2.9271790981292725\n",
      "Train size: [400] hidden size: [364] trial: 20, train_loss: 0.233470, test loss: 3.290503, bias2: 0.36112546920776367, variance: 2.929377555847168\n",
      "Train size: [400] hidden size: [364] trial: 21, train_loss: 0.234317, test loss: 3.288945, bias2: 0.3616209030151367, variance: 2.9273242950439453\n",
      "Train size: [400] hidden size: [364] trial: 22, train_loss: 0.234695, test loss: 3.288376, bias2: 0.35398340225219727, variance: 2.9343926906585693\n",
      "Train size: [400] hidden size: [364] trial: 23, train_loss: 0.236221, test loss: 3.333316, bias2: 0.34440159797668457, variance: 2.9889140129089355\n",
      "Train size: [400] hidden size: [364] trial: 24, train_loss: 0.237287, test loss: 3.337188, bias2: 0.3344910144805908, variance: 3.002696990966797\n",
      "Train size: [400] hidden size: [364] trial: 25, train_loss: 0.234927, test loss: 3.321453, bias2: 0.3289790153503418, variance: 2.9924745559692383\n",
      "Train size: [400] hidden size: [364] trial: 26, train_loss: 0.233448, test loss: 3.325147, bias2: 0.3248927593231201, variance: 3.0002543926239014\n",
      "Train size: [400] hidden size: [364] trial: 27, train_loss: 0.232727, test loss: 3.352252, bias2: 0.3224148750305176, variance: 3.029836893081665\n",
      "Train size: [400] hidden size: [364] trial: 28, train_loss: 0.230938, test loss: 3.353801, bias2: 0.31934309005737305, variance: 3.0344576835632324\n",
      "Train size: [400] hidden size: [364] trial: 29, train_loss: 0.233504, test loss: 3.374430, bias2: 0.3149423599243164, variance: 3.0594873428344727\n",
      "Train size: [400] hidden size: [364] trial: 30, train_loss: 0.234655, test loss: 3.378125, bias2: 0.315432071685791, variance: 3.0626931190490723\n",
      "Train size: [400] hidden size: [364] trial: 31, train_loss: 0.234278, test loss: 3.385848, bias2: 0.31230664253234863, variance: 3.0735411643981934\n",
      "Train size: [400] hidden size: [364] trial: 32, train_loss: 0.233215, test loss: 3.366146, bias2: 0.3064122200012207, variance: 3.0597336292266846\n",
      "Train size: [400] hidden size: [364] trial: 33, train_loss: 0.231396, test loss: 3.373835, bias2: 0.3048267364501953, variance: 3.0690088272094727\n",
      "Train size: [400] hidden size: [364] trial: 34, train_loss: 0.230525, test loss: 3.375077, bias2: 0.3008701801300049, variance: 3.074207067489624\n",
      "Train size: [400] hidden size: [364] trial: 35, train_loss: 0.231069, test loss: 3.379559, bias2: 0.29738831520080566, variance: 3.0821709632873535\n",
      "Train size: [400] hidden size: [364] trial: 36, train_loss: 0.230822, test loss: 3.380822, bias2: 0.29776525497436523, variance: 3.083057165145874\n",
      "Train size: [400] hidden size: [364] trial: 37, train_loss: 0.231196, test loss: 3.383595, bias2: 0.29871058464050293, variance: 3.0848841667175293\n",
      "Train size: [400] hidden size: [364] trial: 38, train_loss: 0.231847, test loss: 3.381900, bias2: 0.2950856685638428, variance: 3.0868146419525146\n",
      "Train size: [400] hidden size: [364] trial: 39, train_loss: 0.232170, test loss: 3.382487, bias2: 0.29542016983032227, variance: 3.087066888809204\n",
      "Train size: [400] hidden size: [364] trial: 40, train_loss: 0.231904, test loss: 3.383405, bias2: 0.295764684677124, variance: 3.087639808654785\n",
      "Train size: [400] hidden size: [364] trial: 41, train_loss: 0.232847, test loss: 3.382632, bias2: 0.29525256156921387, variance: 3.087378978729248\n",
      "Train size: [400] hidden size: [364] trial: 42, train_loss: 0.232208, test loss: 3.388168, bias2: 0.29731225967407227, variance: 3.0908560752868652\n",
      "Train size: [400] hidden size: [364] trial: 43, train_loss: 0.232285, test loss: 3.396982, bias2: 0.3003973960876465, variance: 3.0965840816497803\n",
      "Train size: [400] hidden size: [364] trial: 44, train_loss: 0.230127, test loss: 3.388228, bias2: 0.2981090545654297, variance: 3.090118885040283\n",
      "Train size: [400] hidden size: [364] trial: 45, train_loss: 0.229194, test loss: 3.396540, bias2: 0.2985248565673828, variance: 3.098015308380127\n",
      "Train size: [400] hidden size: [364] trial: 46, train_loss: 0.230173, test loss: 3.395600, bias2: 0.2995178699493408, variance: 3.0960824489593506\n",
      "Train size: [400] hidden size: [364] trial: 47, train_loss: 0.229390, test loss: 3.403149, bias2: 0.2994546890258789, variance: 3.1036946773529053\n",
      "Train size: [400] hidden size: [364] trial: 48, train_loss: 0.229133, test loss: 3.402523, bias2: 0.29500269889831543, variance: 3.1075198650360107\n",
      "Train size: [400] hidden size: [364] trial: 49, train_loss: 0.228943, test loss: 3.400948, bias2: 0.2948899269104004, variance: 3.1060585975646973\n",
      "##################################################\n",
      "Train size: [400] hidden size: [419] trial: 0, train_loss: 0.098684, test loss: 3.222995, bias2: 3.2229952812194824, variance: 1.8684231051224742e-08\n",
      "Train size: [400] hidden size: [419] trial: 1, train_loss: 0.103903, test loss: 3.196381, bias2: 1.653694748878479, variance: 1.542686104774475\n",
      "Train size: [400] hidden size: [419] trial: 2, train_loss: 0.118195, test loss: 3.257081, bias2: 1.2299506664276123, variance: 2.027130603790283\n",
      "Train size: [400] hidden size: [419] trial: 3, train_loss: 0.115261, test loss: 3.108424, bias2: 0.9539530277252197, variance: 2.154470682144165\n",
      "Train size: [400] hidden size: [419] trial: 4, train_loss: 0.117453, test loss: 3.125094, bias2: 0.7843666076660156, variance: 2.3407275676727295\n",
      "Train size: [400] hidden size: [419] trial: 5, train_loss: 0.119715, test loss: 3.105777, bias2: 0.6809022426605225, variance: 2.424875020980835\n",
      "Train size: [400] hidden size: [419] trial: 6, train_loss: 0.119163, test loss: 3.135267, bias2: 0.6055829524993896, variance: 2.5296835899353027\n",
      "Train size: [400] hidden size: [419] trial: 7, train_loss: 0.123108, test loss: 3.161558, bias2: 0.5438637733459473, variance: 2.617694139480591\n",
      "Train size: [400] hidden size: [419] trial: 8, train_loss: 0.124068, test loss: 3.139128, bias2: 0.5034966468811035, variance: 2.6356313228607178\n",
      "Train size: [400] hidden size: [419] trial: 9, train_loss: 0.123686, test loss: 3.110854, bias2: 0.4700353145599365, variance: 2.6408183574676514\n",
      "Train size: [400] hidden size: [419] trial: 10, train_loss: 0.122474, test loss: 3.090507, bias2: 0.4565744400024414, variance: 2.633932590484619\n",
      "Train size: [400] hidden size: [419] trial: 11, train_loss: 0.123513, test loss: 3.064428, bias2: 0.4336555004119873, variance: 2.630772829055786\n",
      "Train size: [400] hidden size: [419] trial: 12, train_loss: 0.125240, test loss: 3.078025, bias2: 0.40779709815979004, variance: 2.6702280044555664\n",
      "Train size: [400] hidden size: [419] trial: 13, train_loss: 0.125407, test loss: 3.107894, bias2: 0.40062642097473145, variance: 2.7072675228118896\n",
      "Train size: [400] hidden size: [419] trial: 14, train_loss: 0.127580, test loss: 3.110457, bias2: 0.3889005184173584, variance: 2.7215569019317627\n",
      "Train size: [400] hidden size: [419] trial: 15, train_loss: 0.127243, test loss: 3.140985, bias2: 0.3782341480255127, variance: 2.7627506256103516\n",
      "Train size: [400] hidden size: [419] trial: 16, train_loss: 0.126289, test loss: 3.141225, bias2: 0.3743929862976074, variance: 2.766831636428833\n",
      "Train size: [400] hidden size: [419] trial: 17, train_loss: 0.126813, test loss: 3.141269, bias2: 0.3699653148651123, variance: 2.771304130554199\n",
      "Train size: [400] hidden size: [419] trial: 18, train_loss: 0.129300, test loss: 3.133955, bias2: 0.3603217601776123, variance: 2.7736337184906006\n",
      "Train size: [400] hidden size: [419] trial: 19, train_loss: 0.128944, test loss: 3.134722, bias2: 0.34877467155456543, variance: 2.78594708442688\n",
      "Train size: [400] hidden size: [419] trial: 20, train_loss: 0.130944, test loss: 3.150072, bias2: 0.34598398208618164, variance: 2.8040883541107178\n",
      "Train size: [400] hidden size: [419] trial: 21, train_loss: 0.130935, test loss: 3.156289, bias2: 0.338787317276001, variance: 2.8175013065338135\n",
      "Train size: [400] hidden size: [419] trial: 22, train_loss: 0.129885, test loss: 3.144659, bias2: 0.33498525619506836, variance: 2.809673309326172\n",
      "Train size: [400] hidden size: [419] trial: 23, train_loss: 0.128715, test loss: 3.127912, bias2: 0.32835984230041504, variance: 2.7995524406433105\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [419] trial: 24, train_loss: 0.128044, test loss: 3.140845, bias2: 0.3249819278717041, variance: 2.8158631324768066\n",
      "Train size: [400] hidden size: [419] trial: 25, train_loss: 0.128919, test loss: 3.154793, bias2: 0.3219594955444336, variance: 2.832833766937256\n",
      "Train size: [400] hidden size: [419] trial: 26, train_loss: 0.129917, test loss: 3.168876, bias2: 0.32267260551452637, variance: 2.8462038040161133\n",
      "Train size: [400] hidden size: [419] trial: 27, train_loss: 0.129949, test loss: 3.165575, bias2: 0.3200366497039795, variance: 2.84553861618042\n",
      "Train size: [400] hidden size: [419] trial: 28, train_loss: 0.129015, test loss: 3.175555, bias2: 0.3162837028503418, variance: 2.859271287918091\n",
      "Train size: [400] hidden size: [419] trial: 29, train_loss: 0.128833, test loss: 3.174189, bias2: 0.31581950187683105, variance: 2.8583693504333496\n",
      "Train size: [400] hidden size: [419] trial: 30, train_loss: 0.128967, test loss: 3.183822, bias2: 0.31670093536376953, variance: 2.867121458053589\n",
      "Train size: [400] hidden size: [419] trial: 31, train_loss: 0.129793, test loss: 3.189839, bias2: 0.31090426445007324, variance: 2.878934860229492\n",
      "Train size: [400] hidden size: [419] trial: 32, train_loss: 0.129350, test loss: 3.190476, bias2: 0.30991315841674805, variance: 2.8805623054504395\n",
      "Train size: [400] hidden size: [419] trial: 33, train_loss: 0.130351, test loss: 3.214707, bias2: 0.30756044387817383, variance: 2.9071462154388428\n",
      "Train size: [400] hidden size: [419] trial: 34, train_loss: 0.131713, test loss: 3.216512, bias2: 0.30540013313293457, variance: 2.911111354827881\n",
      "Train size: [400] hidden size: [419] trial: 35, train_loss: 0.131443, test loss: 3.209785, bias2: 0.30435729026794434, variance: 2.905427932739258\n",
      "Train size: [400] hidden size: [419] trial: 36, train_loss: 0.132528, test loss: 3.213587, bias2: 0.301959753036499, variance: 2.9116270542144775\n",
      "Train size: [400] hidden size: [419] trial: 37, train_loss: 0.132741, test loss: 3.208021, bias2: 0.29855775833129883, variance: 2.909463405609131\n",
      "Train size: [400] hidden size: [419] trial: 38, train_loss: 0.132391, test loss: 3.199659, bias2: 0.2946658134460449, variance: 2.9049928188323975\n",
      "Train size: [400] hidden size: [419] trial: 39, train_loss: 0.132462, test loss: 3.185529, bias2: 0.2892038822174072, variance: 2.896324872970581\n",
      "Train size: [400] hidden size: [419] trial: 40, train_loss: 0.131413, test loss: 3.182744, bias2: 0.2857975959777832, variance: 2.8969461917877197\n",
      "Train size: [400] hidden size: [419] trial: 41, train_loss: 0.131686, test loss: 3.181301, bias2: 0.28515195846557617, variance: 2.896148681640625\n",
      "Train size: [400] hidden size: [419] trial: 42, train_loss: 0.131624, test loss: 3.180742, bias2: 0.28116917610168457, variance: 2.89957332611084\n",
      "Train size: [400] hidden size: [419] trial: 43, train_loss: 0.132111, test loss: 3.187084, bias2: 0.27863073348999023, variance: 2.9084537029266357\n",
      "Train size: [400] hidden size: [419] trial: 44, train_loss: 0.132520, test loss: 3.204373, bias2: 0.27944397926330566, variance: 2.924929141998291\n",
      "Train size: [400] hidden size: [419] trial: 45, train_loss: 0.133725, test loss: 3.210152, bias2: 0.2757394313812256, variance: 2.934412717819214\n",
      "Train size: [400] hidden size: [419] trial: 46, train_loss: 0.134122, test loss: 3.209205, bias2: 0.2725822925567627, variance: 2.9366226196289062\n",
      "Train size: [400] hidden size: [419] trial: 47, train_loss: 0.133488, test loss: 3.211877, bias2: 0.2761080265045166, variance: 2.9357690811157227\n",
      "Train size: [400] hidden size: [419] trial: 48, train_loss: 0.133342, test loss: 3.212688, bias2: 0.2707686424255371, variance: 2.9419193267822266\n",
      "Train size: [400] hidden size: [419] trial: 49, train_loss: 0.133121, test loss: 3.214790, bias2: 0.27033519744873047, variance: 2.9444544315338135\n",
      "##################################################\n",
      "Train size: [400] hidden size: [483] trial: 0, train_loss: 0.073825, test loss: 2.850807, bias2: 2.850806951522827, variance: 1.5570191802538602e-09\n",
      "Train size: [400] hidden size: [483] trial: 1, train_loss: 0.067166, test loss: 2.695759, bias2: 1.406959056854248, variance: 1.288799524307251\n",
      "Train size: [400] hidden size: [483] trial: 2, train_loss: 0.065080, test loss: 2.846162, bias2: 1.0758637189865112, variance: 1.770297884941101\n",
      "Train size: [400] hidden size: [483] trial: 3, train_loss: 0.071174, test loss: 2.881807, bias2: 0.8974834680557251, variance: 1.9843238592147827\n",
      "Train size: [400] hidden size: [483] trial: 4, train_loss: 0.071478, test loss: 2.934950, bias2: 0.7585291862487793, variance: 2.1764214038848877\n",
      "Train size: [400] hidden size: [483] trial: 5, train_loss: 0.069997, test loss: 2.941403, bias2: 0.6693739891052246, variance: 2.272029399871826\n",
      "Train size: [400] hidden size: [483] trial: 6, train_loss: 0.074703, test loss: 2.971846, bias2: 0.599008321762085, variance: 2.372837543487549\n",
      "Train size: [400] hidden size: [483] trial: 7, train_loss: 0.074969, test loss: 3.005574, bias2: 0.5459134578704834, variance: 2.459660768508911\n",
      "Train size: [400] hidden size: [483] trial: 8, train_loss: 0.075493, test loss: 2.990246, bias2: 0.5003292560577393, variance: 2.4899168014526367\n",
      "Train size: [400] hidden size: [483] trial: 9, train_loss: 0.074142, test loss: 2.972903, bias2: 0.4688735008239746, variance: 2.5040295124053955\n",
      "Train size: [400] hidden size: [483] trial: 10, train_loss: 0.072869, test loss: 2.950884, bias2: 0.4447319507598877, variance: 2.5061519145965576\n",
      "Train size: [400] hidden size: [483] trial: 11, train_loss: 0.072700, test loss: 2.949711, bias2: 0.4260592460632324, variance: 2.523651361465454\n",
      "Train size: [400] hidden size: [483] trial: 12, train_loss: 0.072077, test loss: 2.943128, bias2: 0.39938807487487793, variance: 2.5437402725219727\n",
      "Train size: [400] hidden size: [483] trial: 13, train_loss: 0.074646, test loss: 2.983338, bias2: 0.3915882110595703, variance: 2.591749906539917\n",
      "Train size: [400] hidden size: [483] trial: 14, train_loss: 0.074557, test loss: 2.970148, bias2: 0.38425374031066895, variance: 2.5858945846557617\n",
      "Train size: [400] hidden size: [483] trial: 15, train_loss: 0.075470, test loss: 2.968163, bias2: 0.3647615909576416, variance: 2.6034011840820312\n",
      "Train size: [400] hidden size: [483] trial: 16, train_loss: 0.076787, test loss: 3.004913, bias2: 0.357677698135376, variance: 2.647235155105591\n",
      "Train size: [400] hidden size: [483] trial: 17, train_loss: 0.077687, test loss: 3.022567, bias2: 0.3485543727874756, variance: 2.6740124225616455\n",
      "Train size: [400] hidden size: [483] trial: 18, train_loss: 0.078309, test loss: 3.038128, bias2: 0.3429882526397705, variance: 2.6951396465301514\n",
      "Train size: [400] hidden size: [483] trial: 19, train_loss: 0.079252, test loss: 3.071193, bias2: 0.3392949104309082, variance: 2.731898546218872\n",
      "Train size: [400] hidden size: [483] trial: 20, train_loss: 0.079771, test loss: 3.068383, bias2: 0.33493733406066895, variance: 2.733445405960083\n",
      "Train size: [400] hidden size: [483] trial: 21, train_loss: 0.080114, test loss: 3.046523, bias2: 0.32572484016418457, variance: 2.7207977771759033\n",
      "Train size: [400] hidden size: [483] trial: 22, train_loss: 0.079227, test loss: 3.028089, bias2: 0.3198080062866211, variance: 2.7082808017730713\n",
      "Train size: [400] hidden size: [483] trial: 23, train_loss: 0.077854, test loss: 3.015254, bias2: 0.3198580741882324, variance: 2.6953961849212646\n",
      "Train size: [400] hidden size: [483] trial: 24, train_loss: 0.077567, test loss: 3.000735, bias2: 0.3161923885345459, variance: 2.6845428943634033\n",
      "Train size: [400] hidden size: [483] trial: 25, train_loss: 0.078802, test loss: 3.006770, bias2: 0.3117198944091797, variance: 2.6950502395629883\n",
      "Train size: [400] hidden size: [483] trial: 26, train_loss: 0.080269, test loss: 3.014110, bias2: 0.3097712993621826, variance: 2.704339027404785\n",
      "Train size: [400] hidden size: [483] trial: 27, train_loss: 0.080091, test loss: 3.019706, bias2: 0.3063688278198242, variance: 2.713336706161499\n",
      "Train size: [400] hidden size: [483] trial: 28, train_loss: 0.080579, test loss: 3.021204, bias2: 0.3006167411804199, variance: 2.7205874919891357\n",
      "Train size: [400] hidden size: [483] trial: 29, train_loss: 0.080224, test loss: 3.013987, bias2: 0.2951502799987793, variance: 2.7188363075256348\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [483] trial: 30, train_loss: 0.079675, test loss: 3.007553, bias2: 0.28633880615234375, variance: 2.7212142944335938\n",
      "Train size: [400] hidden size: [483] trial: 31, train_loss: 0.079952, test loss: 3.014601, bias2: 0.2836029529571533, variance: 2.7309980392456055\n",
      "Train size: [400] hidden size: [483] trial: 32, train_loss: 0.079745, test loss: 3.008252, bias2: 0.28418493270874023, variance: 2.724067211151123\n",
      "Train size: [400] hidden size: [483] trial: 33, train_loss: 0.079925, test loss: 3.006961, bias2: 0.28052234649658203, variance: 2.726438522338867\n",
      "Train size: [400] hidden size: [483] trial: 34, train_loss: 0.079558, test loss: 2.999881, bias2: 0.2815394401550293, variance: 2.7183420658111572\n",
      "Train size: [400] hidden size: [483] trial: 35, train_loss: 0.079912, test loss: 2.996904, bias2: 0.276827335357666, variance: 2.720076322555542\n",
      "Train size: [400] hidden size: [483] trial: 36, train_loss: 0.079127, test loss: 2.986217, bias2: 0.27307891845703125, variance: 2.7131378650665283\n",
      "Train size: [400] hidden size: [483] trial: 37, train_loss: 0.079509, test loss: 2.997592, bias2: 0.27068161964416504, variance: 2.726909875869751\n",
      "Train size: [400] hidden size: [483] trial: 38, train_loss: 0.078969, test loss: 2.984557, bias2: 0.2700014114379883, variance: 2.7145557403564453\n",
      "Train size: [400] hidden size: [483] trial: 39, train_loss: 0.078560, test loss: 2.974715, bias2: 0.2682318687438965, variance: 2.7064828872680664\n",
      "Train size: [400] hidden size: [483] trial: 40, train_loss: 0.078146, test loss: 2.964400, bias2: 0.2665832042694092, variance: 2.6978163719177246\n",
      "Train size: [400] hidden size: [483] trial: 41, train_loss: 0.078444, test loss: 2.972985, bias2: 0.26463842391967773, variance: 2.708346366882324\n",
      "Train size: [400] hidden size: [483] trial: 42, train_loss: 0.078478, test loss: 2.975882, bias2: 0.26439571380615234, variance: 2.7114861011505127\n",
      "Train size: [400] hidden size: [483] trial: 43, train_loss: 0.078759, test loss: 2.971802, bias2: 0.2643139362335205, variance: 2.7074878215789795\n",
      "Train size: [400] hidden size: [483] trial: 44, train_loss: 0.078525, test loss: 2.968529, bias2: 0.2631220817565918, variance: 2.705406665802002\n",
      "Train size: [400] hidden size: [483] trial: 45, train_loss: 0.078940, test loss: 2.962732, bias2: 0.2625398635864258, variance: 2.7001917362213135\n",
      "Train size: [400] hidden size: [483] trial: 46, train_loss: 0.078517, test loss: 2.956262, bias2: 0.2599778175354004, variance: 2.696284055709839\n",
      "Train size: [400] hidden size: [483] trial: 47, train_loss: 0.078619, test loss: 2.952864, bias2: 0.256854772567749, variance: 2.696009397506714\n",
      "Train size: [400] hidden size: [483] trial: 48, train_loss: 0.078828, test loss: 2.955747, bias2: 0.2570919990539551, variance: 2.698655366897583\n",
      "Train size: [400] hidden size: [483] trial: 49, train_loss: 0.078495, test loss: 2.949908, bias2: 0.256986141204834, variance: 2.6929221153259277\n",
      "##################################################\n",
      "Train size: [400] hidden size: [556] trial: 0, train_loss: 0.040020, test loss: 2.330081, bias2: 2.330080986022949, variance: 2.1798269855821673e-08\n",
      "Train size: [400] hidden size: [556] trial: 1, train_loss: 0.045513, test loss: 2.496253, bias2: 1.3708746433258057, variance: 1.1253786087036133\n",
      "Train size: [400] hidden size: [556] trial: 2, train_loss: 0.049972, test loss: 2.532248, bias2: 0.9436100721359253, variance: 1.5886377096176147\n",
      "Train size: [400] hidden size: [556] trial: 3, train_loss: 0.048799, test loss: 2.519580, bias2: 0.7206767797470093, variance: 1.7989031076431274\n",
      "Train size: [400] hidden size: [556] trial: 4, train_loss: 0.044867, test loss: 2.438480, bias2: 0.6200863122940063, variance: 1.818393588066101\n",
      "Train size: [400] hidden size: [556] trial: 5, train_loss: 0.043943, test loss: 2.494668, bias2: 0.5803000926971436, variance: 1.91436767578125\n",
      "Train size: [400] hidden size: [556] trial: 6, train_loss: 0.045071, test loss: 2.480096, bias2: 0.5343619585037231, variance: 1.9457343816757202\n",
      "Train size: [400] hidden size: [556] trial: 7, train_loss: 0.045018, test loss: 2.488773, bias2: 0.4993828535079956, variance: 1.9893897771835327\n",
      "Train size: [400] hidden size: [556] trial: 8, train_loss: 0.044961, test loss: 2.511651, bias2: 0.47052669525146484, variance: 2.041124105453491\n",
      "Train size: [400] hidden size: [556] trial: 9, train_loss: 0.046457, test loss: 2.524554, bias2: 0.4357881546020508, variance: 2.088765859603882\n",
      "Train size: [400] hidden size: [556] trial: 10, train_loss: 0.046144, test loss: 2.528666, bias2: 0.4129922389984131, variance: 2.115673780441284\n",
      "Train size: [400] hidden size: [556] trial: 11, train_loss: 0.045034, test loss: 2.513005, bias2: 0.3945949077606201, variance: 2.1184096336364746\n",
      "Train size: [400] hidden size: [556] trial: 12, train_loss: 0.045062, test loss: 2.534115, bias2: 0.38085460662841797, variance: 2.1532607078552246\n",
      "Train size: [400] hidden size: [556] trial: 13, train_loss: 0.044254, test loss: 2.507369, bias2: 0.35358667373657227, variance: 2.153782844543457\n",
      "Train size: [400] hidden size: [556] trial: 14, train_loss: 0.044485, test loss: 2.488783, bias2: 0.3423178195953369, variance: 2.1464648246765137\n",
      "Train size: [400] hidden size: [556] trial: 15, train_loss: 0.045234, test loss: 2.499776, bias2: 0.33243560791015625, variance: 2.1673405170440674\n",
      "Train size: [400] hidden size: [556] trial: 16, train_loss: 0.045570, test loss: 2.517440, bias2: 0.31607508659362793, variance: 2.2013649940490723\n",
      "Train size: [400] hidden size: [556] trial: 17, train_loss: 0.045336, test loss: 2.506892, bias2: 0.31296801567077637, variance: 2.1939244270324707\n",
      "Train size: [400] hidden size: [556] trial: 18, train_loss: 0.045875, test loss: 2.526735, bias2: 0.30391931533813477, variance: 2.222815752029419\n",
      "Train size: [400] hidden size: [556] trial: 19, train_loss: 0.045441, test loss: 2.511296, bias2: 0.29328083992004395, variance: 2.21801495552063\n",
      "Train size: [400] hidden size: [556] trial: 20, train_loss: 0.046273, test loss: 2.535276, bias2: 0.2881951332092285, variance: 2.2470805644989014\n",
      "Train size: [400] hidden size: [556] trial: 21, train_loss: 0.046694, test loss: 2.534289, bias2: 0.2806546688079834, variance: 2.253633975982666\n",
      "Train size: [400] hidden size: [556] trial: 22, train_loss: 0.046482, test loss: 2.512103, bias2: 0.2761368751525879, variance: 2.2359657287597656\n",
      "Train size: [400] hidden size: [556] trial: 23, train_loss: 0.046563, test loss: 2.513192, bias2: 0.2749295234680176, variance: 2.2382619380950928\n",
      "Train size: [400] hidden size: [556] trial: 24, train_loss: 0.046123, test loss: 2.516779, bias2: 0.2727041244506836, variance: 2.2440743446350098\n",
      "Train size: [400] hidden size: [556] trial: 25, train_loss: 0.046284, test loss: 2.515154, bias2: 0.27219343185424805, variance: 2.2429609298706055\n",
      "Train size: [400] hidden size: [556] trial: 26, train_loss: 0.046263, test loss: 2.511930, bias2: 0.26843929290771484, variance: 2.24349045753479\n",
      "Train size: [400] hidden size: [556] trial: 27, train_loss: 0.046400, test loss: 2.518478, bias2: 0.2647109031677246, variance: 2.253767251968384\n",
      "Train size: [400] hidden size: [556] trial: 28, train_loss: 0.046471, test loss: 2.530584, bias2: 0.26796889305114746, variance: 2.2626149654388428\n",
      "Train size: [400] hidden size: [556] trial: 29, train_loss: 0.046473, test loss: 2.528306, bias2: 0.26410818099975586, variance: 2.264197587966919\n",
      "Train size: [400] hidden size: [556] trial: 30, train_loss: 0.046088, test loss: 2.515646, bias2: 0.2639594078063965, variance: 2.2516870498657227\n",
      "Train size: [400] hidden size: [556] trial: 31, train_loss: 0.045910, test loss: 2.507939, bias2: 0.2619783878326416, variance: 2.2459604740142822\n",
      "Train size: [400] hidden size: [556] trial: 32, train_loss: 0.046051, test loss: 2.509817, bias2: 0.2641780376434326, variance: 2.2456393241882324\n",
      "Train size: [400] hidden size: [556] trial: 33, train_loss: 0.046193, test loss: 2.519672, bias2: 0.2628748416900635, variance: 2.2567973136901855\n",
      "Train size: [400] hidden size: [556] trial: 34, train_loss: 0.046226, test loss: 2.508868, bias2: 0.25952959060668945, variance: 2.249338150024414\n",
      "Train size: [400] hidden size: [556] trial: 35, train_loss: 0.046099, test loss: 2.515613, bias2: 0.25955963134765625, variance: 2.2560534477233887\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [556] trial: 36, train_loss: 0.046483, test loss: 2.519688, bias2: 0.2552299499511719, variance: 2.264458179473877\n",
      "Train size: [400] hidden size: [556] trial: 37, train_loss: 0.046347, test loss: 2.518767, bias2: 0.2548027038574219, variance: 2.2639639377593994\n",
      "Train size: [400] hidden size: [556] trial: 38, train_loss: 0.046194, test loss: 2.515650, bias2: 0.25111889839172363, variance: 2.264531373977661\n",
      "Train size: [400] hidden size: [556] trial: 39, train_loss: 0.046092, test loss: 2.509538, bias2: 0.2496497631072998, variance: 2.259887933731079\n",
      "Train size: [400] hidden size: [556] trial: 40, train_loss: 0.045966, test loss: 2.508429, bias2: 0.2495882511138916, variance: 2.258841037750244\n",
      "Train size: [400] hidden size: [556] trial: 41, train_loss: 0.046060, test loss: 2.505338, bias2: 0.25082993507385254, variance: 2.2545080184936523\n",
      "Train size: [400] hidden size: [556] trial: 42, train_loss: 0.045944, test loss: 2.501836, bias2: 0.250014066696167, variance: 2.2518222332000732\n",
      "Train size: [400] hidden size: [556] trial: 43, train_loss: 0.045863, test loss: 2.502321, bias2: 0.2479710578918457, variance: 2.254350185394287\n",
      "Train size: [400] hidden size: [556] trial: 44, train_loss: 0.045761, test loss: 2.501667, bias2: 0.24831366539001465, variance: 2.2533533573150635\n",
      "Train size: [400] hidden size: [556] trial: 45, train_loss: 0.045725, test loss: 2.500302, bias2: 0.247908353805542, variance: 2.252393960952759\n",
      "Train size: [400] hidden size: [556] trial: 46, train_loss: 0.045692, test loss: 2.495514, bias2: 0.24578547477722168, variance: 2.249728202819824\n",
      "Train size: [400] hidden size: [556] trial: 47, train_loss: 0.045556, test loss: 2.492298, bias2: 0.24552154541015625, variance: 2.246776580810547\n",
      "Train size: [400] hidden size: [556] trial: 48, train_loss: 0.045399, test loss: 2.491260, bias2: 0.24196290969848633, variance: 2.2492969036102295\n",
      "Train size: [400] hidden size: [556] trial: 49, train_loss: 0.045395, test loss: 2.484926, bias2: 0.2410905361175537, variance: 2.243835210800171\n",
      "##################################################\n",
      "Train size: [400] hidden size: [640] trial: 0, train_loss: 0.033686, test loss: 2.059915, bias2: 2.05991530418396, variance: -3.1140383605077204e-09\n",
      "Train size: [400] hidden size: [640] trial: 1, train_loss: 0.033785, test loss: 2.132377, bias2: 1.0928314924240112, variance: 1.0395456552505493\n",
      "Train size: [400] hidden size: [640] trial: 2, train_loss: 0.035630, test loss: 2.192701, bias2: 0.8347938060760498, variance: 1.3579068183898926\n",
      "Train size: [400] hidden size: [640] trial: 3, train_loss: 0.037307, test loss: 2.250818, bias2: 0.6935939788818359, variance: 1.5572237968444824\n",
      "Train size: [400] hidden size: [640] trial: 4, train_loss: 0.035906, test loss: 2.232659, bias2: 0.5992379188537598, variance: 1.6334214210510254\n",
      "Train size: [400] hidden size: [640] trial: 5, train_loss: 0.035783, test loss: 2.229255, bias2: 0.5222809314727783, variance: 1.7069737911224365\n",
      "Train size: [400] hidden size: [640] trial: 6, train_loss: 0.035460, test loss: 2.217595, bias2: 0.47258830070495605, variance: 1.7450063228607178\n",
      "Train size: [400] hidden size: [640] trial: 7, train_loss: 0.035997, test loss: 2.236140, bias2: 0.44063639640808105, variance: 1.7955033779144287\n",
      "Train size: [400] hidden size: [640] trial: 8, train_loss: 0.035240, test loss: 2.239982, bias2: 0.4223674535751343, variance: 1.8176146745681763\n",
      "Train size: [400] hidden size: [640] trial: 9, train_loss: 0.034053, test loss: 2.200550, bias2: 0.3926764726638794, variance: 1.8078736066818237\n",
      "Train size: [400] hidden size: [640] trial: 10, train_loss: 0.033713, test loss: 2.204835, bias2: 0.38946521282196045, variance: 1.8153702020645142\n",
      "Train size: [400] hidden size: [640] trial: 11, train_loss: 0.033543, test loss: 2.214127, bias2: 0.3706960678100586, variance: 1.843430519104004\n",
      "Train size: [400] hidden size: [640] trial: 12, train_loss: 0.033607, test loss: 2.199078, bias2: 0.3464968204498291, variance: 1.8525810241699219\n",
      "Train size: [400] hidden size: [640] trial: 13, train_loss: 0.033785, test loss: 2.201615, bias2: 0.33645057678222656, variance: 1.8651647567749023\n",
      "Train size: [400] hidden size: [640] trial: 14, train_loss: 0.033044, test loss: 2.175596, bias2: 0.32865822315216064, variance: 1.8469382524490356\n",
      "Train size: [400] hidden size: [640] trial: 15, train_loss: 0.032850, test loss: 2.169521, bias2: 0.3223838806152344, variance: 1.847137451171875\n",
      "Train size: [400] hidden size: [640] trial: 16, train_loss: 0.032673, test loss: 2.160576, bias2: 0.31053054332733154, variance: 1.8500455617904663\n",
      "Train size: [400] hidden size: [640] trial: 17, train_loss: 0.032953, test loss: 2.169170, bias2: 0.3026573657989502, variance: 1.8665127754211426\n",
      "Train size: [400] hidden size: [640] trial: 18, train_loss: 0.032194, test loss: 2.150488, bias2: 0.2989741563796997, variance: 1.8515139818191528\n",
      "Train size: [400] hidden size: [640] trial: 19, train_loss: 0.032111, test loss: 2.143647, bias2: 0.29447436332702637, variance: 1.8491730690002441\n",
      "Train size: [400] hidden size: [640] trial: 20, train_loss: 0.031979, test loss: 2.140091, bias2: 0.2869042158126831, variance: 1.8531864881515503\n",
      "Train size: [400] hidden size: [640] trial: 21, train_loss: 0.031860, test loss: 2.133230, bias2: 0.28384947776794434, variance: 1.8493800163269043\n",
      "Train size: [400] hidden size: [640] trial: 22, train_loss: 0.031705, test loss: 2.132306, bias2: 0.2762058973312378, variance: 1.8560997247695923\n",
      "Train size: [400] hidden size: [640] trial: 23, train_loss: 0.031969, test loss: 2.131048, bias2: 0.2751122713088989, variance: 1.8559361696243286\n",
      "Train size: [400] hidden size: [640] trial: 24, train_loss: 0.031537, test loss: 2.144819, bias2: 0.2766416072845459, variance: 1.868177890777588\n",
      "Train size: [400] hidden size: [640] trial: 25, train_loss: 0.031246, test loss: 2.130992, bias2: 0.2734382152557373, variance: 1.8575537204742432\n",
      "Train size: [400] hidden size: [640] trial: 26, train_loss: 0.031448, test loss: 2.134443, bias2: 0.2692784070968628, variance: 1.8651641607284546\n",
      "Train size: [400] hidden size: [640] trial: 27, train_loss: 0.031222, test loss: 2.142435, bias2: 0.27073395252227783, variance: 1.8717013597488403\n",
      "Train size: [400] hidden size: [640] trial: 28, train_loss: 0.030995, test loss: 2.138022, bias2: 0.2703744173049927, variance: 1.8676477670669556\n",
      "Train size: [400] hidden size: [640] trial: 29, train_loss: 0.031194, test loss: 2.149077, bias2: 0.27065956592559814, variance: 1.8784171342849731\n",
      "Train size: [400] hidden size: [640] trial: 30, train_loss: 0.031050, test loss: 2.153399, bias2: 0.2707390785217285, variance: 1.8826603889465332\n",
      "Train size: [400] hidden size: [640] trial: 31, train_loss: 0.031037, test loss: 2.149634, bias2: 0.268085241317749, variance: 1.8815486431121826\n",
      "Train size: [400] hidden size: [640] trial: 32, train_loss: 0.030994, test loss: 2.142381, bias2: 0.26459038257598877, variance: 1.8777903318405151\n",
      "Train size: [400] hidden size: [640] trial: 33, train_loss: 0.030990, test loss: 2.146703, bias2: 0.2646913528442383, variance: 1.882011890411377\n",
      "Train size: [400] hidden size: [640] trial: 34, train_loss: 0.030979, test loss: 2.150472, bias2: 0.2614530324935913, variance: 1.8890188932418823\n",
      "Train size: [400] hidden size: [640] trial: 35, train_loss: 0.031310, test loss: 2.157698, bias2: 0.26134729385375977, variance: 1.896350622177124\n",
      "Train size: [400] hidden size: [640] trial: 36, train_loss: 0.031362, test loss: 2.153080, bias2: 0.2598303556442261, variance: 1.8932496309280396\n",
      "Train size: [400] hidden size: [640] trial: 37, train_loss: 0.031405, test loss: 2.155493, bias2: 0.25588393211364746, variance: 1.899608850479126\n",
      "Train size: [400] hidden size: [640] trial: 38, train_loss: 0.031363, test loss: 2.152161, bias2: 0.2529263496398926, variance: 1.8992347717285156\n",
      "Train size: [400] hidden size: [640] trial: 39, train_loss: 0.031231, test loss: 2.155633, bias2: 0.2515186071395874, variance: 1.904114842414856\n",
      "Train size: [400] hidden size: [640] trial: 40, train_loss: 0.031187, test loss: 2.162036, bias2: 0.2505611181259155, variance: 1.9114750623703003\n",
      "Train size: [400] hidden size: [640] trial: 41, train_loss: 0.031337, test loss: 2.164695, bias2: 0.24947941303253174, variance: 1.9152158498764038\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [640] trial: 42, train_loss: 0.031460, test loss: 2.171172, bias2: 0.24832141399383545, variance: 1.922850251197815\n",
      "Train size: [400] hidden size: [640] trial: 43, train_loss: 0.031271, test loss: 2.172535, bias2: 0.24901819229125977, variance: 1.9235165119171143\n",
      "Train size: [400] hidden size: [640] trial: 44, train_loss: 0.031327, test loss: 2.174386, bias2: 0.24774086475372314, variance: 1.9266453981399536\n",
      "Train size: [400] hidden size: [640] trial: 45, train_loss: 0.031262, test loss: 2.173420, bias2: 0.24841046333312988, variance: 1.9250099658966064\n",
      "Train size: [400] hidden size: [640] trial: 46, train_loss: 0.031176, test loss: 2.172337, bias2: 0.24841761589050293, variance: 1.923919677734375\n",
      "Train size: [400] hidden size: [640] trial: 47, train_loss: 0.031100, test loss: 2.172726, bias2: 0.24784183502197266, variance: 1.9248836040496826\n",
      "Train size: [400] hidden size: [640] trial: 48, train_loss: 0.031098, test loss: 2.170637, bias2: 0.24728381633758545, variance: 1.9233530759811401\n",
      "Train size: [400] hidden size: [640] trial: 49, train_loss: 0.030964, test loss: 2.164003, bias2: 0.24585187435150146, variance: 1.9181510210037231\n",
      "##################################################\n",
      "Train size: [400] hidden size: [737] trial: 0, train_loss: 0.018772, test loss: 1.997348, bias2: 1.9973480701446533, variance: -1.5570192246627812e-08\n",
      "Train size: [400] hidden size: [737] trial: 1, train_loss: 0.022103, test loss: 1.971556, bias2: 1.029615879058838, variance: 0.9419398903846741\n",
      "Train size: [400] hidden size: [737] trial: 2, train_loss: 0.021258, test loss: 1.910933, bias2: 0.7274782657623291, variance: 1.1834551095962524\n",
      "Train size: [400] hidden size: [737] trial: 3, train_loss: 0.019928, test loss: 1.879238, bias2: 0.6228111982345581, variance: 1.2564269304275513\n",
      "Train size: [400] hidden size: [737] trial: 4, train_loss: 0.019875, test loss: 1.877455, bias2: 0.52069091796875, variance: 1.3567644357681274\n",
      "Train size: [400] hidden size: [737] trial: 5, train_loss: 0.019733, test loss: 1.838787, bias2: 0.4479401111602783, variance: 1.3908469676971436\n",
      "Train size: [400] hidden size: [737] trial: 6, train_loss: 0.019789, test loss: 1.853721, bias2: 0.41201162338256836, variance: 1.4417091608047485\n",
      "Train size: [400] hidden size: [737] trial: 7, train_loss: 0.019506, test loss: 1.855610, bias2: 0.38913464546203613, variance: 1.4664756059646606\n",
      "Train size: [400] hidden size: [737] trial: 8, train_loss: 0.020170, test loss: 1.882397, bias2: 0.3921157121658325, variance: 1.4902812242507935\n",
      "Train size: [400] hidden size: [737] trial: 9, train_loss: 0.020440, test loss: 1.907275, bias2: 0.3685539960861206, variance: 1.538720726966858\n",
      "Train size: [400] hidden size: [737] trial: 10, train_loss: 0.020779, test loss: 1.925431, bias2: 0.3553262948989868, variance: 1.5701050758361816\n",
      "Train size: [400] hidden size: [737] trial: 11, train_loss: 0.020749, test loss: 1.920829, bias2: 0.34088134765625, variance: 1.5799481868743896\n",
      "Train size: [400] hidden size: [737] trial: 12, train_loss: 0.020652, test loss: 1.898666, bias2: 0.3291938304901123, variance: 1.5694721937179565\n",
      "Train size: [400] hidden size: [737] trial: 13, train_loss: 0.020706, test loss: 1.898822, bias2: 0.3201256990432739, variance: 1.5786958932876587\n",
      "Train size: [400] hidden size: [737] trial: 14, train_loss: 0.020620, test loss: 1.896545, bias2: 0.31132471561431885, variance: 1.5852199792861938\n",
      "Train size: [400] hidden size: [737] trial: 15, train_loss: 0.020704, test loss: 1.889739, bias2: 0.30403101444244385, variance: 1.5857082605361938\n",
      "Train size: [400] hidden size: [737] trial: 16, train_loss: 0.020624, test loss: 1.879908, bias2: 0.30008649826049805, variance: 1.5798217058181763\n",
      "Train size: [400] hidden size: [737] trial: 17, train_loss: 0.020315, test loss: 1.873919, bias2: 0.2965056896209717, variance: 1.5774136781692505\n",
      "Train size: [400] hidden size: [737] trial: 18, train_loss: 0.020131, test loss: 1.872240, bias2: 0.29015445709228516, variance: 1.5820852518081665\n",
      "Train size: [400] hidden size: [737] trial: 19, train_loss: 0.019992, test loss: 1.863106, bias2: 0.2846410274505615, variance: 1.5784653425216675\n",
      "Train size: [400] hidden size: [737] trial: 20, train_loss: 0.020355, test loss: 1.865867, bias2: 0.27394139766693115, variance: 1.5919257402420044\n",
      "Train size: [400] hidden size: [737] trial: 21, train_loss: 0.020541, test loss: 1.874388, bias2: 0.2696528434753418, variance: 1.6047356128692627\n",
      "Train size: [400] hidden size: [737] trial: 22, train_loss: 0.020755, test loss: 1.885961, bias2: 0.2650606632232666, variance: 1.6209003925323486\n",
      "Train size: [400] hidden size: [737] trial: 23, train_loss: 0.020762, test loss: 1.889890, bias2: 0.2607705593109131, variance: 1.629119873046875\n",
      "Train size: [400] hidden size: [737] trial: 24, train_loss: 0.020793, test loss: 1.890093, bias2: 0.2569330930709839, variance: 1.6331593990325928\n",
      "Train size: [400] hidden size: [737] trial: 25, train_loss: 0.020816, test loss: 1.890406, bias2: 0.25683605670928955, variance: 1.633569598197937\n",
      "Train size: [400] hidden size: [737] trial: 26, train_loss: 0.020999, test loss: 1.884448, bias2: 0.2506955862045288, variance: 1.6337522268295288\n",
      "Train size: [400] hidden size: [737] trial: 27, train_loss: 0.020798, test loss: 1.874322, bias2: 0.2443028688430786, variance: 1.6300194263458252\n",
      "Train size: [400] hidden size: [737] trial: 28, train_loss: 0.020785, test loss: 1.870213, bias2: 0.24225378036499023, variance: 1.6279593706130981\n",
      "Train size: [400] hidden size: [737] trial: 29, train_loss: 0.020560, test loss: 1.862030, bias2: 0.24171626567840576, variance: 1.6203137636184692\n",
      "Train size: [400] hidden size: [737] trial: 30, train_loss: 0.020562, test loss: 1.863090, bias2: 0.2374112606048584, variance: 1.625678539276123\n",
      "Train size: [400] hidden size: [737] trial: 31, train_loss: 0.020597, test loss: 1.862951, bias2: 0.23445940017700195, variance: 1.6284911632537842\n",
      "Train size: [400] hidden size: [737] trial: 32, train_loss: 0.020620, test loss: 1.865610, bias2: 0.2353891134262085, variance: 1.630220651626587\n",
      "Train size: [400] hidden size: [737] trial: 33, train_loss: 0.020623, test loss: 1.859740, bias2: 0.2329961061477661, variance: 1.626744031906128\n",
      "Train size: [400] hidden size: [737] trial: 34, train_loss: 0.020666, test loss: 1.868811, bias2: 0.23585259914398193, variance: 1.632957935333252\n",
      "Train size: [400] hidden size: [737] trial: 35, train_loss: 0.020648, test loss: 1.865684, bias2: 0.23490095138549805, variance: 1.6307826042175293\n",
      "Train size: [400] hidden size: [737] trial: 36, train_loss: 0.020675, test loss: 1.863834, bias2: 0.23407447338104248, variance: 1.629759430885315\n",
      "Train size: [400] hidden size: [737] trial: 37, train_loss: 0.020617, test loss: 1.865232, bias2: 0.23521387577056885, variance: 1.630017638206482\n",
      "Train size: [400] hidden size: [737] trial: 38, train_loss: 0.020543, test loss: 1.870194, bias2: 0.23566317558288574, variance: 1.6345312595367432\n",
      "Train size: [400] hidden size: [737] trial: 39, train_loss: 0.020574, test loss: 1.871877, bias2: 0.23342669010162354, variance: 1.6384499073028564\n",
      "Train size: [400] hidden size: [737] trial: 40, train_loss: 0.020536, test loss: 1.871221, bias2: 0.23040950298309326, variance: 1.640811800956726\n",
      "Train size: [400] hidden size: [737] trial: 41, train_loss: 0.020549, test loss: 1.867181, bias2: 0.22817492485046387, variance: 1.6390057802200317\n",
      "Train size: [400] hidden size: [737] trial: 42, train_loss: 0.020512, test loss: 1.868922, bias2: 0.22827208042144775, variance: 1.6406495571136475\n",
      "Train size: [400] hidden size: [737] trial: 43, train_loss: 0.020566, test loss: 1.869477, bias2: 0.22396862506866455, variance: 1.645508885383606\n",
      "Train size: [400] hidden size: [737] trial: 44, train_loss: 0.020398, test loss: 1.862528, bias2: 0.2238020896911621, variance: 1.638725996017456\n",
      "Train size: [400] hidden size: [737] trial: 45, train_loss: 0.020353, test loss: 1.859992, bias2: 0.22292697429656982, variance: 1.637064814567566\n",
      "Train size: [400] hidden size: [737] trial: 46, train_loss: 0.020379, test loss: 1.857749, bias2: 0.2200794219970703, variance: 1.6376694440841675\n",
      "Train size: [400] hidden size: [737] trial: 47, train_loss: 0.020357, test loss: 1.855326, bias2: 0.21847450733184814, variance: 1.6368510723114014\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [737] trial: 48, train_loss: 0.020421, test loss: 1.856228, bias2: 0.21923983097076416, variance: 1.6369885206222534\n",
      "Train size: [400] hidden size: [737] trial: 49, train_loss: 0.020517, test loss: 1.857240, bias2: 0.2170119285583496, variance: 1.6402277946472168\n",
      "##################################################\n",
      "Train size: [400] hidden size: [848] trial: 0, train_loss: 0.017644, test loss: 1.600969, bias2: 1.6009690761566162, variance: -1.0120625226761604e-08\n",
      "Train size: [400] hidden size: [848] trial: 1, train_loss: 0.016704, test loss: 1.600755, bias2: 0.9532716274261475, variance: 0.6474833488464355\n",
      "Train size: [400] hidden size: [848] trial: 2, train_loss: 0.015729, test loss: 1.669205, bias2: 0.6840339303016663, variance: 0.9851714968681335\n",
      "Train size: [400] hidden size: [848] trial: 3, train_loss: 0.015944, test loss: 1.647914, bias2: 0.5576118230819702, variance: 1.0903021097183228\n",
      "Train size: [400] hidden size: [848] trial: 4, train_loss: 0.016913, test loss: 1.691283, bias2: 0.5081651210784912, variance: 1.1831183433532715\n",
      "Train size: [400] hidden size: [848] trial: 5, train_loss: 0.016932, test loss: 1.684896, bias2: 0.4514930248260498, variance: 1.233402967453003\n",
      "Train size: [400] hidden size: [848] trial: 6, train_loss: 0.016374, test loss: 1.662384, bias2: 0.4245542287826538, variance: 1.237829566001892\n",
      "Train size: [400] hidden size: [848] trial: 7, train_loss: 0.016290, test loss: 1.667807, bias2: 0.4012589454650879, variance: 1.2665480375289917\n",
      "Train size: [400] hidden size: [848] trial: 8, train_loss: 0.016184, test loss: 1.680360, bias2: 0.3795815706253052, variance: 1.3007780313491821\n",
      "Train size: [400] hidden size: [848] trial: 9, train_loss: 0.016280, test loss: 1.675933, bias2: 0.3521610498428345, variance: 1.3237723112106323\n",
      "Train size: [400] hidden size: [848] trial: 10, train_loss: 0.016125, test loss: 1.680205, bias2: 0.3352314233779907, variance: 1.3449739217758179\n",
      "Train size: [400] hidden size: [848] trial: 11, train_loss: 0.016075, test loss: 1.673420, bias2: 0.31798863410949707, variance: 1.3554316759109497\n",
      "Train size: [400] hidden size: [848] trial: 12, train_loss: 0.016110, test loss: 1.666235, bias2: 0.3149406909942627, variance: 1.351293921470642\n",
      "Train size: [400] hidden size: [848] trial: 13, train_loss: 0.016091, test loss: 1.662781, bias2: 0.3047327995300293, variance: 1.3580480813980103\n",
      "Train size: [400] hidden size: [848] trial: 14, train_loss: 0.016128, test loss: 1.669668, bias2: 0.30098605155944824, variance: 1.3686819076538086\n",
      "Train size: [400] hidden size: [848] trial: 15, train_loss: 0.016164, test loss: 1.672053, bias2: 0.2930835485458374, variance: 1.3789697885513306\n",
      "Train size: [400] hidden size: [848] trial: 16, train_loss: 0.016049, test loss: 1.669409, bias2: 0.28594887256622314, variance: 1.3834596872329712\n",
      "Train size: [400] hidden size: [848] trial: 17, train_loss: 0.015945, test loss: 1.666640, bias2: 0.28154635429382324, variance: 1.385094165802002\n",
      "Train size: [400] hidden size: [848] trial: 18, train_loss: 0.015738, test loss: 1.652246, bias2: 0.272793173789978, variance: 1.3794524669647217\n",
      "Train size: [400] hidden size: [848] trial: 19, train_loss: 0.016016, test loss: 1.660038, bias2: 0.26837801933288574, variance: 1.3916594982147217\n",
      "Train size: [400] hidden size: [848] trial: 20, train_loss: 0.016168, test loss: 1.659253, bias2: 0.26349329948425293, variance: 1.3957600593566895\n",
      "Train size: [400] hidden size: [848] trial: 21, train_loss: 0.016330, test loss: 1.663566, bias2: 0.25879430770874023, variance: 1.4047714471817017\n",
      "Train size: [400] hidden size: [848] trial: 22, train_loss: 0.016547, test loss: 1.668532, bias2: 0.2560586929321289, variance: 1.4124736785888672\n",
      "Train size: [400] hidden size: [848] trial: 23, train_loss: 0.016412, test loss: 1.661900, bias2: 0.2518500089645386, variance: 1.410050392150879\n",
      "Train size: [400] hidden size: [848] trial: 24, train_loss: 0.016338, test loss: 1.657997, bias2: 0.2490025758743286, variance: 1.4089939594268799\n",
      "Train size: [400] hidden size: [848] trial: 25, train_loss: 0.016308, test loss: 1.656250, bias2: 0.2492823600769043, variance: 1.4069671630859375\n",
      "Train size: [400] hidden size: [848] trial: 26, train_loss: 0.016361, test loss: 1.663147, bias2: 0.24830853939056396, variance: 1.4148386716842651\n",
      "Train size: [400] hidden size: [848] trial: 27, train_loss: 0.016387, test loss: 1.662068, bias2: 0.2452017068862915, variance: 1.4168660640716553\n",
      "Train size: [400] hidden size: [848] trial: 28, train_loss: 0.016376, test loss: 1.659550, bias2: 0.24172353744506836, variance: 1.417826771736145\n",
      "Train size: [400] hidden size: [848] trial: 29, train_loss: 0.016313, test loss: 1.659138, bias2: 0.24045944213867188, variance: 1.4186784029006958\n",
      "Train size: [400] hidden size: [848] trial: 30, train_loss: 0.016290, test loss: 1.656821, bias2: 0.23916935920715332, variance: 1.4176521301269531\n",
      "Train size: [400] hidden size: [848] trial: 31, train_loss: 0.016275, test loss: 1.652113, bias2: 0.2373279333114624, variance: 1.4147847890853882\n",
      "Train size: [400] hidden size: [848] trial: 32, train_loss: 0.016289, test loss: 1.653954, bias2: 0.23608863353729248, variance: 1.4178651571273804\n",
      "Train size: [400] hidden size: [848] trial: 33, train_loss: 0.016272, test loss: 1.650536, bias2: 0.23242366313934326, variance: 1.4181122779846191\n",
      "Train size: [400] hidden size: [848] trial: 34, train_loss: 0.016291, test loss: 1.655243, bias2: 0.23267865180969238, variance: 1.4225647449493408\n",
      "Train size: [400] hidden size: [848] trial: 35, train_loss: 0.016244, test loss: 1.649365, bias2: 0.23068952560424805, variance: 1.4186753034591675\n",
      "Train size: [400] hidden size: [848] trial: 36, train_loss: 0.016198, test loss: 1.652806, bias2: 0.23227190971374512, variance: 1.4205336570739746\n",
      "Train size: [400] hidden size: [848] trial: 37, train_loss: 0.016151, test loss: 1.654840, bias2: 0.23275315761566162, variance: 1.4220871925354004\n",
      "Train size: [400] hidden size: [848] trial: 38, train_loss: 0.016056, test loss: 1.652644, bias2: 0.23235595226287842, variance: 1.420288324356079\n",
      "Train size: [400] hidden size: [848] trial: 39, train_loss: 0.016162, test loss: 1.655010, bias2: 0.23195374011993408, variance: 1.4230560064315796\n",
      "Train size: [400] hidden size: [848] trial: 40, train_loss: 0.016103, test loss: 1.652674, bias2: 0.23258936405181885, variance: 1.4200847148895264\n",
      "Train size: [400] hidden size: [848] trial: 41, train_loss: 0.016115, test loss: 1.654007, bias2: 0.22929167747497559, variance: 1.4247149229049683\n",
      "Train size: [400] hidden size: [848] trial: 42, train_loss: 0.016056, test loss: 1.647201, bias2: 0.22660291194915771, variance: 1.4205985069274902\n",
      "Train size: [400] hidden size: [848] trial: 43, train_loss: 0.016136, test loss: 1.651923, bias2: 0.22553133964538574, variance: 1.4263920783996582\n",
      "Train size: [400] hidden size: [848] trial: 44, train_loss: 0.016238, test loss: 1.654874, bias2: 0.22440433502197266, variance: 1.4304697513580322\n",
      "Train size: [400] hidden size: [848] trial: 45, train_loss: 0.016224, test loss: 1.652632, bias2: 0.22278153896331787, variance: 1.4298503398895264\n",
      "Train size: [400] hidden size: [848] trial: 46, train_loss: 0.016200, test loss: 1.651251, bias2: 0.22114789485931396, variance: 1.4301031827926636\n",
      "Train size: [400] hidden size: [848] trial: 47, train_loss: 0.016118, test loss: 1.649958, bias2: 0.22097790241241455, variance: 1.4289802312850952\n",
      "Train size: [400] hidden size: [848] trial: 48, train_loss: 0.016187, test loss: 1.652512, bias2: 0.21880030632019043, variance: 1.4337117671966553\n",
      "Train size: [400] hidden size: [848] trial: 49, train_loss: 0.016122, test loss: 1.649897, bias2: 0.21760213375091553, variance: 1.4322943687438965\n",
      "##################################################\n",
      "Train size: [400] hidden size: [977] trial: 0, train_loss: 0.014011, test loss: 1.596662, bias2: 1.5966622829437256, variance: -1.0899134927910836e-08\n",
      "Train size: [400] hidden size: [977] trial: 1, train_loss: 0.011903, test loss: 1.523405, bias2: 0.8530575633049011, variance: 0.6703470349311829\n",
      "Train size: [400] hidden size: [977] trial: 2, train_loss: 0.012014, test loss: 1.487960, bias2: 0.5923556685447693, variance: 0.8956043124198914\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [977] trial: 3, train_loss: 0.011759, test loss: 1.470549, bias2: 0.4603170156478882, variance: 1.0102322101593018\n",
      "Train size: [400] hidden size: [977] trial: 4, train_loss: 0.012327, test loss: 1.456300, bias2: 0.38700592517852783, variance: 1.0692938566207886\n",
      "Train size: [400] hidden size: [977] trial: 5, train_loss: 0.012562, test loss: 1.450226, bias2: 0.350766658782959, variance: 1.099458932876587\n",
      "Train size: [400] hidden size: [977] trial: 6, train_loss: 0.012391, test loss: 1.433951, bias2: 0.3206428289413452, variance: 1.1133085489273071\n",
      "Train size: [400] hidden size: [977] trial: 7, train_loss: 0.012324, test loss: 1.447012, bias2: 0.3064413070678711, variance: 1.1405709981918335\n",
      "Train size: [400] hidden size: [977] trial: 8, train_loss: 0.012481, test loss: 1.458770, bias2: 0.3026832342147827, variance: 1.1560872793197632\n",
      "Train size: [400] hidden size: [977] trial: 9, train_loss: 0.012449, test loss: 1.460126, bias2: 0.28727078437805176, variance: 1.172855257987976\n",
      "Train size: [400] hidden size: [977] trial: 10, train_loss: 0.012367, test loss: 1.437225, bias2: 0.2757478952407837, variance: 1.1614773273468018\n",
      "Train size: [400] hidden size: [977] trial: 11, train_loss: 0.012548, test loss: 1.450645, bias2: 0.2668677568435669, variance: 1.1837773323059082\n",
      "Train size: [400] hidden size: [977] trial: 12, train_loss: 0.012398, test loss: 1.445289, bias2: 0.2620507478713989, variance: 1.1832383871078491\n",
      "Train size: [400] hidden size: [977] trial: 13, train_loss: 0.012364, test loss: 1.442861, bias2: 0.2525298595428467, variance: 1.1903307437896729\n",
      "Train size: [400] hidden size: [977] trial: 14, train_loss: 0.012458, test loss: 1.441844, bias2: 0.24893856048583984, variance: 1.1929054260253906\n",
      "Train size: [400] hidden size: [977] trial: 15, train_loss: 0.012500, test loss: 1.450137, bias2: 0.246720552444458, variance: 1.203416347503662\n",
      "Train size: [400] hidden size: [977] trial: 16, train_loss: 0.012487, test loss: 1.456465, bias2: 0.24592125415802002, variance: 1.2105439901351929\n",
      "Train size: [400] hidden size: [977] trial: 17, train_loss: 0.012633, test loss: 1.464701, bias2: 0.24159419536590576, variance: 1.223107099533081\n",
      "Train size: [400] hidden size: [977] trial: 18, train_loss: 0.012785, test loss: 1.467887, bias2: 0.23988187313079834, variance: 1.2280049324035645\n",
      "Train size: [400] hidden size: [977] trial: 19, train_loss: 0.012798, test loss: 1.467476, bias2: 0.23826336860656738, variance: 1.2292126417160034\n",
      "Train size: [400] hidden size: [977] trial: 20, train_loss: 0.012839, test loss: 1.473412, bias2: 0.23786640167236328, variance: 1.2355453968048096\n",
      "Train size: [400] hidden size: [977] trial: 21, train_loss: 0.012741, test loss: 1.469650, bias2: 0.2385958433151245, variance: 1.2310540676116943\n",
      "Train size: [400] hidden size: [977] trial: 22, train_loss: 0.012648, test loss: 1.469466, bias2: 0.24143695831298828, variance: 1.228028655052185\n",
      "Train size: [400] hidden size: [977] trial: 23, train_loss: 0.012664, test loss: 1.468310, bias2: 0.24088072776794434, variance: 1.2274292707443237\n",
      "Train size: [400] hidden size: [977] trial: 24, train_loss: 0.012610, test loss: 1.466914, bias2: 0.23923182487487793, variance: 1.2276822328567505\n",
      "Train size: [400] hidden size: [977] trial: 25, train_loss: 0.012662, test loss: 1.460540, bias2: 0.2358238697052002, variance: 1.2247159481048584\n",
      "Train size: [400] hidden size: [977] trial: 26, train_loss: 0.012616, test loss: 1.460798, bias2: 0.2327861785888672, variance: 1.228011965751648\n",
      "Train size: [400] hidden size: [977] trial: 27, train_loss: 0.012678, test loss: 1.463415, bias2: 0.2316049337387085, variance: 1.2318103313446045\n",
      "Train size: [400] hidden size: [977] trial: 28, train_loss: 0.012728, test loss: 1.465726, bias2: 0.22966265678405762, variance: 1.2360628843307495\n",
      "Train size: [400] hidden size: [977] trial: 29, train_loss: 0.012792, test loss: 1.467182, bias2: 0.22973167896270752, variance: 1.237450122833252\n",
      "Train size: [400] hidden size: [977] trial: 30, train_loss: 0.012757, test loss: 1.460991, bias2: 0.2295081615447998, variance: 1.2314826250076294\n",
      "Train size: [400] hidden size: [977] trial: 31, train_loss: 0.012800, test loss: 1.460736, bias2: 0.2275843620300293, variance: 1.233151912689209\n",
      "Train size: [400] hidden size: [977] trial: 32, train_loss: 0.012826, test loss: 1.461713, bias2: 0.22567439079284668, variance: 1.2360389232635498\n",
      "Train size: [400] hidden size: [977] trial: 33, train_loss: 0.012832, test loss: 1.460785, bias2: 0.2259899377822876, variance: 1.2347948551177979\n",
      "Train size: [400] hidden size: [977] trial: 34, train_loss: 0.012801, test loss: 1.465542, bias2: 0.226057767868042, variance: 1.239484429359436\n",
      "Train size: [400] hidden size: [977] trial: 35, train_loss: 0.012793, test loss: 1.467580, bias2: 0.2254471778869629, variance: 1.2421326637268066\n",
      "Train size: [400] hidden size: [977] trial: 36, train_loss: 0.012710, test loss: 1.463950, bias2: 0.22399473190307617, variance: 1.2399556636810303\n",
      "Train size: [400] hidden size: [977] trial: 37, train_loss: 0.012776, test loss: 1.464119, bias2: 0.22134196758270264, variance: 1.2427774667739868\n",
      "Train size: [400] hidden size: [977] trial: 38, train_loss: 0.012745, test loss: 1.462660, bias2: 0.22162044048309326, variance: 1.2410392761230469\n",
      "Train size: [400] hidden size: [977] trial: 39, train_loss: 0.012847, test loss: 1.466120, bias2: 0.21883070468902588, variance: 1.2472895383834839\n",
      "Train size: [400] hidden size: [977] trial: 40, train_loss: 0.012852, test loss: 1.466823, bias2: 0.2191234827041626, variance: 1.2476993799209595\n",
      "Train size: [400] hidden size: [977] trial: 41, train_loss: 0.012886, test loss: 1.471590, bias2: 0.21986174583435059, variance: 1.2517284154891968\n",
      "Train size: [400] hidden size: [977] trial: 42, train_loss: 0.012849, test loss: 1.473219, bias2: 0.220109224319458, variance: 1.2531094551086426\n",
      "Train size: [400] hidden size: [977] trial: 43, train_loss: 0.012801, test loss: 1.472079, bias2: 0.2194976806640625, variance: 1.252581238746643\n",
      "Train size: [400] hidden size: [977] trial: 44, train_loss: 0.012775, test loss: 1.473436, bias2: 0.21906399726867676, variance: 1.2543723583221436\n",
      "Train size: [400] hidden size: [977] trial: 45, train_loss: 0.012748, test loss: 1.477871, bias2: 0.22068047523498535, variance: 1.257190465927124\n",
      "Train size: [400] hidden size: [977] trial: 46, train_loss: 0.012702, test loss: 1.475530, bias2: 0.220922589302063, variance: 1.2546072006225586\n",
      "Train size: [400] hidden size: [977] trial: 47, train_loss: 0.012637, test loss: 1.472541, bias2: 0.21989738941192627, variance: 1.2526438236236572\n",
      "Train size: [400] hidden size: [977] trial: 48, train_loss: 0.012686, test loss: 1.472827, bias2: 0.2192857265472412, variance: 1.2535409927368164\n",
      "Train size: [400] hidden size: [977] trial: 49, train_loss: 0.012695, test loss: 1.471390, bias2: 0.21879923343658447, variance: 1.2525910139083862\n",
      "##################################################\n",
      "Train size: [400] hidden size: [1125] trial: 0, train_loss: 0.008554, test loss: 1.239713, bias2: 1.239713191986084, variance: 7.785095901269301e-10\n",
      "Train size: [400] hidden size: [1125] trial: 1, train_loss: 0.009546, test loss: 1.295412, bias2: 0.7820607423782349, variance: 0.513351559638977\n",
      "Train size: [400] hidden size: [1125] trial: 2, train_loss: 0.010269, test loss: 1.325520, bias2: 0.6125958561897278, variance: 0.7129243016242981\n",
      "Train size: [400] hidden size: [1125] trial: 3, train_loss: 0.010226, test loss: 1.329649, bias2: 0.5011996030807495, variance: 0.8284492492675781\n",
      "Train size: [400] hidden size: [1125] trial: 4, train_loss: 0.010774, test loss: 1.336358, bias2: 0.43433117866516113, variance: 0.9020271301269531\n",
      "Train size: [400] hidden size: [1125] trial: 5, train_loss: 0.010441, test loss: 1.335127, bias2: 0.395304799079895, variance: 0.9398221969604492\n",
      "Train size: [400] hidden size: [1125] trial: 6, train_loss: 0.010501, test loss: 1.332113, bias2: 0.3600766658782959, variance: 0.9720363616943359\n",
      "Train size: [400] hidden size: [1125] trial: 7, train_loss: 0.010074, test loss: 1.321484, bias2: 0.34249329566955566, variance: 0.978990912437439\n",
      "Train size: [400] hidden size: [1125] trial: 8, train_loss: 0.010021, test loss: 1.314549, bias2: 0.3302774429321289, variance: 0.9842712879180908\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [1125] trial: 9, train_loss: 0.010029, test loss: 1.313785, bias2: 0.31315457820892334, variance: 1.000630497932434\n",
      "Train size: [400] hidden size: [1125] trial: 10, train_loss: 0.010075, test loss: 1.316374, bias2: 0.2959756851196289, variance: 1.0203979015350342\n",
      "Train size: [400] hidden size: [1125] trial: 11, train_loss: 0.010124, test loss: 1.322226, bias2: 0.286726713180542, variance: 1.0354989767074585\n",
      "Train size: [400] hidden size: [1125] trial: 12, train_loss: 0.010193, test loss: 1.330717, bias2: 0.2805955410003662, variance: 1.0501216650009155\n",
      "Train size: [400] hidden size: [1125] trial: 13, train_loss: 0.010167, test loss: 1.328177, bias2: 0.27694642543792725, variance: 1.0512303113937378\n",
      "Train size: [400] hidden size: [1125] trial: 14, train_loss: 0.010181, test loss: 1.327679, bias2: 0.27116477489471436, variance: 1.0565145015716553\n",
      "Train size: [400] hidden size: [1125] trial: 15, train_loss: 0.010197, test loss: 1.338508, bias2: 0.2694438695907593, variance: 1.0690640211105347\n",
      "Train size: [400] hidden size: [1125] trial: 16, train_loss: 0.010362, test loss: 1.340062, bias2: 0.2657451629638672, variance: 1.074316382408142\n",
      "Train size: [400] hidden size: [1125] trial: 17, train_loss: 0.010288, test loss: 1.339215, bias2: 0.26168107986450195, variance: 1.0775341987609863\n",
      "Train size: [400] hidden size: [1125] trial: 18, train_loss: 0.010361, test loss: 1.342994, bias2: 0.2584155797958374, variance: 1.0845786333084106\n",
      "Train size: [400] hidden size: [1125] trial: 19, train_loss: 0.010561, test loss: 1.350781, bias2: 0.2534325122833252, variance: 1.097348690032959\n",
      "Train size: [400] hidden size: [1125] trial: 20, train_loss: 0.010503, test loss: 1.355110, bias2: 0.25115668773651123, variance: 1.1039537191390991\n",
      "Train size: [400] hidden size: [1125] trial: 21, train_loss: 0.010519, test loss: 1.357299, bias2: 0.2504456043243408, variance: 1.1068534851074219\n",
      "Train size: [400] hidden size: [1125] trial: 22, train_loss: 0.010573, test loss: 1.356522, bias2: 0.24718177318572998, variance: 1.1093400716781616\n",
      "Train size: [400] hidden size: [1125] trial: 23, train_loss: 0.010525, test loss: 1.357302, bias2: 0.2448335886001587, variance: 1.1124686002731323\n",
      "Train size: [400] hidden size: [1125] trial: 24, train_loss: 0.010534, test loss: 1.360181, bias2: 0.24116861820220947, variance: 1.119012713432312\n",
      "Train size: [400] hidden size: [1125] trial: 25, train_loss: 0.010602, test loss: 1.366158, bias2: 0.23992526531219482, variance: 1.1262331008911133\n",
      "Train size: [400] hidden size: [1125] trial: 26, train_loss: 0.010627, test loss: 1.367897, bias2: 0.23993301391601562, variance: 1.127963662147522\n",
      "Train size: [400] hidden size: [1125] trial: 27, train_loss: 0.010620, test loss: 1.366517, bias2: 0.23839116096496582, variance: 1.1281254291534424\n",
      "Train size: [400] hidden size: [1125] trial: 28, train_loss: 0.010571, test loss: 1.362750, bias2: 0.23667144775390625, variance: 1.126078724861145\n",
      "Train size: [400] hidden size: [1125] trial: 29, train_loss: 0.010533, test loss: 1.362972, bias2: 0.2361687421798706, variance: 1.1268033981323242\n",
      "Train size: [400] hidden size: [1125] trial: 30, train_loss: 0.010524, test loss: 1.364139, bias2: 0.23395168781280518, variance: 1.1301873922348022\n",
      "Train size: [400] hidden size: [1125] trial: 31, train_loss: 0.010568, test loss: 1.366253, bias2: 0.23494231700897217, variance: 1.1313104629516602\n",
      "Train size: [400] hidden size: [1125] trial: 32, train_loss: 0.010544, test loss: 1.363801, bias2: 0.2341083288192749, variance: 1.129692792892456\n",
      "Train size: [400] hidden size: [1125] trial: 33, train_loss: 0.010552, test loss: 1.361537, bias2: 0.231514573097229, variance: 1.1300228834152222\n",
      "Train size: [400] hidden size: [1125] trial: 34, train_loss: 0.010564, test loss: 1.358294, bias2: 0.22843730449676514, variance: 1.1298567056655884\n",
      "Train size: [400] hidden size: [1125] trial: 35, train_loss: 0.010598, test loss: 1.357441, bias2: 0.22769594192504883, variance: 1.1297452449798584\n",
      "Train size: [400] hidden size: [1125] trial: 36, train_loss: 0.010635, test loss: 1.364685, bias2: 0.2293468713760376, variance: 1.1353381872177124\n",
      "Train size: [400] hidden size: [1125] trial: 37, train_loss: 0.010611, test loss: 1.362305, bias2: 0.2280888557434082, variance: 1.1342157125473022\n",
      "Train size: [400] hidden size: [1125] trial: 38, train_loss: 0.010668, test loss: 1.364059, bias2: 0.2285975217819214, variance: 1.1354619264602661\n",
      "Train size: [400] hidden size: [1125] trial: 39, train_loss: 0.010642, test loss: 1.362146, bias2: 0.22791385650634766, variance: 1.1342320442199707\n",
      "Train size: [400] hidden size: [1125] trial: 40, train_loss: 0.010662, test loss: 1.358129, bias2: 0.22588539123535156, variance: 1.1322436332702637\n",
      "Train size: [400] hidden size: [1125] trial: 41, train_loss: 0.010637, test loss: 1.356640, bias2: 0.22498035430908203, variance: 1.1316592693328857\n",
      "Train size: [400] hidden size: [1125] trial: 42, train_loss: 0.010637, test loss: 1.356186, bias2: 0.22534263134002686, variance: 1.1308436393737793\n",
      "Train size: [400] hidden size: [1125] trial: 43, train_loss: 0.010634, test loss: 1.355719, bias2: 0.22499823570251465, variance: 1.1307203769683838\n",
      "Train size: [400] hidden size: [1125] trial: 44, train_loss: 0.010698, test loss: 1.356234, bias2: 0.2230910062789917, variance: 1.1331428289413452\n",
      "Train size: [400] hidden size: [1125] trial: 45, train_loss: 0.010712, test loss: 1.354848, bias2: 0.22128033638000488, variance: 1.1335675716400146\n",
      "Train size: [400] hidden size: [1125] trial: 46, train_loss: 0.010716, test loss: 1.355265, bias2: 0.22056269645690918, variance: 1.134702205657959\n",
      "Train size: [400] hidden size: [1125] trial: 47, train_loss: 0.010711, test loss: 1.354306, bias2: 0.21983075141906738, variance: 1.134475588798523\n",
      "Train size: [400] hidden size: [1125] trial: 48, train_loss: 0.010669, test loss: 1.353315, bias2: 0.22039175033569336, variance: 1.1329233646392822\n",
      "Train size: [400] hidden size: [1125] trial: 49, train_loss: 0.010638, test loss: 1.352002, bias2: 0.22079288959503174, variance: 1.1312092542648315\n",
      "##################################################\n",
      "Train size: [400] hidden size: [1295] trial: 0, train_loss: 0.010229, test loss: 1.148078, bias2: 1.1480777263641357, variance: -1.0120625226761604e-08\n",
      "Train size: [400] hidden size: [1295] trial: 1, train_loss: 0.008869, test loss: 1.154247, bias2: 0.6713083386421204, variance: 0.48293858766555786\n",
      "Train size: [400] hidden size: [1295] trial: 2, train_loss: 0.008628, test loss: 1.178125, bias2: 0.5274336338043213, variance: 0.6506918668746948\n",
      "Train size: [400] hidden size: [1295] trial: 3, train_loss: 0.008609, test loss: 1.178942, bias2: 0.4624730348587036, variance: 0.7164692878723145\n",
      "Train size: [400] hidden size: [1295] trial: 4, train_loss: 0.008367, test loss: 1.177843, bias2: 0.4172678589820862, variance: 0.7605752348899841\n",
      "Train size: [400] hidden size: [1295] trial: 5, train_loss: 0.008624, test loss: 1.198343, bias2: 0.37906765937805176, variance: 0.81927490234375\n",
      "Train size: [400] hidden size: [1295] trial: 6, train_loss: 0.008662, test loss: 1.197052, bias2: 0.35128629207611084, variance: 0.8457658290863037\n",
      "Train size: [400] hidden size: [1295] trial: 7, train_loss: 0.009049, test loss: 1.212149, bias2: 0.3357428312301636, variance: 0.876406192779541\n",
      "Train size: [400] hidden size: [1295] trial: 8, train_loss: 0.009103, test loss: 1.228890, bias2: 0.31816476583480835, variance: 0.9107252955436707\n",
      "Train size: [400] hidden size: [1295] trial: 9, train_loss: 0.009114, test loss: 1.224407, bias2: 0.30562734603881836, variance: 0.9187793731689453\n",
      "Train size: [400] hidden size: [1295] trial: 10, train_loss: 0.009154, test loss: 1.220104, bias2: 0.293975830078125, variance: 0.9261276721954346\n",
      "Train size: [400] hidden size: [1295] trial: 11, train_loss: 0.009257, test loss: 1.221996, bias2: 0.2850160002708435, variance: 0.9369797110557556\n",
      "Train size: [400] hidden size: [1295] trial: 12, train_loss: 0.009332, test loss: 1.214257, bias2: 0.2707720398902893, variance: 0.9434853196144104\n",
      "Train size: [400] hidden size: [1295] trial: 13, train_loss: 0.009406, test loss: 1.214483, bias2: 0.26426559686660767, variance: 0.9502174258232117\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [1295] trial: 14, train_loss: 0.009377, test loss: 1.217057, bias2: 0.2608887553215027, variance: 0.9561682343482971\n",
      "Train size: [400] hidden size: [1295] trial: 15, train_loss: 0.009363, test loss: 1.219283, bias2: 0.2534409165382385, variance: 0.9658425450325012\n",
      "Train size: [400] hidden size: [1295] trial: 16, train_loss: 0.009318, test loss: 1.220357, bias2: 0.250118613243103, variance: 0.9702383279800415\n",
      "Train size: [400] hidden size: [1295] trial: 17, train_loss: 0.009327, test loss: 1.219192, bias2: 0.24414163827896118, variance: 0.9750506281852722\n",
      "Train size: [400] hidden size: [1295] trial: 18, train_loss: 0.009331, test loss: 1.216557, bias2: 0.24023228883743286, variance: 0.9763244986534119\n",
      "Train size: [400] hidden size: [1295] trial: 19, train_loss: 0.009297, test loss: 1.219488, bias2: 0.23749077320098877, variance: 0.981997013092041\n",
      "Train size: [400] hidden size: [1295] trial: 20, train_loss: 0.009257, test loss: 1.220870, bias2: 0.2322673201560974, variance: 0.9886028170585632\n",
      "Train size: [400] hidden size: [1295] trial: 21, train_loss: 0.009265, test loss: 1.217834, bias2: 0.2275215983390808, variance: 0.9903125166893005\n",
      "Train size: [400] hidden size: [1295] trial: 22, train_loss: 0.009201, test loss: 1.220804, bias2: 0.2265239953994751, variance: 0.9942797422409058\n",
      "Train size: [400] hidden size: [1295] trial: 23, train_loss: 0.009194, test loss: 1.216651, bias2: 0.22378778457641602, variance: 0.9928629398345947\n",
      "Train size: [400] hidden size: [1295] trial: 24, train_loss: 0.009234, test loss: 1.219808, bias2: 0.22236603498458862, variance: 0.9974417090415955\n",
      "Train size: [400] hidden size: [1295] trial: 25, train_loss: 0.009278, test loss: 1.219339, bias2: 0.22038370370864868, variance: 0.9989551901817322\n",
      "Train size: [400] hidden size: [1295] trial: 26, train_loss: 0.009276, test loss: 1.225923, bias2: 0.22159171104431152, variance: 1.0043309926986694\n",
      "Train size: [400] hidden size: [1295] trial: 27, train_loss: 0.009244, test loss: 1.223967, bias2: 0.22072339057922363, variance: 1.0032434463500977\n",
      "Train size: [400] hidden size: [1295] trial: 28, train_loss: 0.009298, test loss: 1.224079, bias2: 0.21811115741729736, variance: 1.0059674978256226\n",
      "Train size: [400] hidden size: [1295] trial: 29, train_loss: 0.009346, test loss: 1.228656, bias2: 0.21748065948486328, variance: 1.0111751556396484\n",
      "Train size: [400] hidden size: [1295] trial: 30, train_loss: 0.009324, test loss: 1.228519, bias2: 0.21456921100616455, variance: 1.013950228691101\n",
      "Train size: [400] hidden size: [1295] trial: 31, train_loss: 0.009346, test loss: 1.231329, bias2: 0.21642303466796875, variance: 1.0149062871932983\n",
      "Train size: [400] hidden size: [1295] trial: 32, train_loss: 0.009322, test loss: 1.229067, bias2: 0.21497273445129395, variance: 1.014094352722168\n",
      "Train size: [400] hidden size: [1295] trial: 33, train_loss: 0.009293, test loss: 1.229299, bias2: 0.21391868591308594, variance: 1.0153805017471313\n",
      "Train size: [400] hidden size: [1295] trial: 34, train_loss: 0.009334, test loss: 1.232244, bias2: 0.21369075775146484, variance: 1.0185534954071045\n",
      "Train size: [400] hidden size: [1295] trial: 35, train_loss: 0.009340, test loss: 1.232386, bias2: 0.21270930767059326, variance: 1.019676923751831\n",
      "Train size: [400] hidden size: [1295] trial: 36, train_loss: 0.009387, test loss: 1.233561, bias2: 0.21286892890930176, variance: 1.0206921100616455\n",
      "Train size: [400] hidden size: [1295] trial: 37, train_loss: 0.009367, test loss: 1.231189, bias2: 0.21252095699310303, variance: 1.0186680555343628\n",
      "Train size: [400] hidden size: [1295] trial: 38, train_loss: 0.009370, test loss: 1.232515, bias2: 0.21074998378753662, variance: 1.021764874458313\n",
      "Train size: [400] hidden size: [1295] trial: 39, train_loss: 0.009357, test loss: 1.232363, bias2: 0.21040654182434082, variance: 1.0219569206237793\n",
      "Train size: [400] hidden size: [1295] trial: 40, train_loss: 0.009429, test loss: 1.232782, bias2: 0.20906245708465576, variance: 1.0237194299697876\n",
      "Train size: [400] hidden size: [1295] trial: 41, train_loss: 0.009404, test loss: 1.232552, bias2: 0.20791161060333252, variance: 1.0246402025222778\n",
      "Train size: [400] hidden size: [1295] trial: 42, train_loss: 0.009405, test loss: 1.231748, bias2: 0.20838046073913574, variance: 1.023368000984192\n",
      "Train size: [400] hidden size: [1295] trial: 43, train_loss: 0.009392, test loss: 1.230615, bias2: 0.20798420906066895, variance: 1.0226308107376099\n",
      "Train size: [400] hidden size: [1295] trial: 44, train_loss: 0.009428, test loss: 1.233202, bias2: 0.2077387571334839, variance: 1.0254628658294678\n",
      "Train size: [400] hidden size: [1295] trial: 45, train_loss: 0.009400, test loss: 1.230863, bias2: 0.20718204975128174, variance: 1.0236811637878418\n",
      "Train size: [400] hidden size: [1295] trial: 46, train_loss: 0.009367, test loss: 1.232158, bias2: 0.20756328105926514, variance: 1.0245944261550903\n",
      "Train size: [400] hidden size: [1295] trial: 47, train_loss: 0.009390, test loss: 1.233864, bias2: 0.20806944370269775, variance: 1.0257947444915771\n",
      "Train size: [400] hidden size: [1295] trial: 48, train_loss: 0.009357, test loss: 1.233404, bias2: 0.2086108922958374, variance: 1.0247931480407715\n",
      "Train size: [400] hidden size: [1295] trial: 49, train_loss: 0.009400, test loss: 1.235615, bias2: 0.2081003189086914, variance: 1.0275150537490845\n",
      "##################################################\n",
      "Train size: [400] hidden size: [1491] trial: 0, train_loss: 0.006855, test loss: 1.215796, bias2: 1.2157961130142212, variance: -1.5570191802538602e-09\n",
      "Train size: [400] hidden size: [1491] trial: 1, train_loss: 0.006619, test loss: 1.147655, bias2: 0.7037444710731506, variance: 0.4439106583595276\n",
      "Train size: [400] hidden size: [1491] trial: 2, train_loss: 0.007136, test loss: 1.134937, bias2: 0.5199543237686157, variance: 0.614983081817627\n",
      "Train size: [400] hidden size: [1491] trial: 3, train_loss: 0.007335, test loss: 1.152136, bias2: 0.46168309450149536, variance: 0.6904526352882385\n",
      "Train size: [400] hidden size: [1491] trial: 4, train_loss: 0.007348, test loss: 1.152645, bias2: 0.4212644100189209, variance: 0.7313803434371948\n",
      "Train size: [400] hidden size: [1491] trial: 5, train_loss: 0.007392, test loss: 1.145028, bias2: 0.3850972056388855, variance: 0.7599303126335144\n",
      "Train size: [400] hidden size: [1491] trial: 6, train_loss: 0.007613, test loss: 1.161262, bias2: 0.3604480028152466, variance: 0.8008143901824951\n",
      "Train size: [400] hidden size: [1491] trial: 7, train_loss: 0.007684, test loss: 1.169772, bias2: 0.345791757106781, variance: 0.8239802718162537\n",
      "Train size: [400] hidden size: [1491] trial: 8, train_loss: 0.007704, test loss: 1.165117, bias2: 0.3269767165184021, variance: 0.8381404280662537\n",
      "Train size: [400] hidden size: [1491] trial: 9, train_loss: 0.007767, test loss: 1.161833, bias2: 0.309650719165802, variance: 0.8521823287010193\n",
      "Train size: [400] hidden size: [1491] trial: 10, train_loss: 0.007755, test loss: 1.161604, bias2: 0.2994426488876343, variance: 0.86216139793396\n",
      "Train size: [400] hidden size: [1491] trial: 11, train_loss: 0.007804, test loss: 1.166243, bias2: 0.2972511053085327, variance: 0.8689922094345093\n",
      "Train size: [400] hidden size: [1491] trial: 12, train_loss: 0.007855, test loss: 1.168912, bias2: 0.28669124841690063, variance: 0.8822205662727356\n",
      "Train size: [400] hidden size: [1491] trial: 13, train_loss: 0.007899, test loss: 1.167444, bias2: 0.2816941738128662, variance: 0.8857496976852417\n",
      "Train size: [400] hidden size: [1491] trial: 14, train_loss: 0.007869, test loss: 1.167682, bias2: 0.27577143907546997, variance: 0.8919106125831604\n",
      "Train size: [400] hidden size: [1491] trial: 15, train_loss: 0.007920, test loss: 1.166591, bias2: 0.27277398109436035, variance: 0.8938174247741699\n",
      "Train size: [400] hidden size: [1491] trial: 16, train_loss: 0.007949, test loss: 1.167707, bias2: 0.2649385929107666, variance: 0.9027684926986694\n",
      "Train size: [400] hidden size: [1491] trial: 17, train_loss: 0.007983, test loss: 1.164756, bias2: 0.2613033056259155, variance: 0.9034528732299805\n",
      "Train size: [400] hidden size: [1491] trial: 18, train_loss: 0.008011, test loss: 1.163269, bias2: 0.255340576171875, variance: 0.907928466796875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [1491] trial: 19, train_loss: 0.007967, test loss: 1.157239, bias2: 0.2526888847351074, variance: 0.9045497179031372\n",
      "Train size: [400] hidden size: [1491] trial: 20, train_loss: 0.007997, test loss: 1.155816, bias2: 0.24958431720733643, variance: 0.9062315225601196\n",
      "Train size: [400] hidden size: [1491] trial: 21, train_loss: 0.007943, test loss: 1.153078, bias2: 0.24662071466445923, variance: 0.9064571261405945\n",
      "Train size: [400] hidden size: [1491] trial: 22, train_loss: 0.007968, test loss: 1.150670, bias2: 0.2441825270652771, variance: 0.9064870476722717\n",
      "Train size: [400] hidden size: [1491] trial: 23, train_loss: 0.007944, test loss: 1.151163, bias2: 0.24519997835159302, variance: 0.905963122844696\n",
      "Train size: [400] hidden size: [1491] trial: 24, train_loss: 0.008011, test loss: 1.150919, bias2: 0.2410721778869629, variance: 0.9098465442657471\n",
      "Train size: [400] hidden size: [1491] trial: 25, train_loss: 0.008044, test loss: 1.145986, bias2: 0.24014747142791748, variance: 0.9058380126953125\n",
      "Train size: [400] hidden size: [1491] trial: 26, train_loss: 0.008041, test loss: 1.147809, bias2: 0.24123454093933105, variance: 0.9065748453140259\n",
      "Train size: [400] hidden size: [1491] trial: 27, train_loss: 0.008055, test loss: 1.147560, bias2: 0.23700761795043945, variance: 0.9105528593063354\n",
      "Train size: [400] hidden size: [1491] trial: 28, train_loss: 0.008062, test loss: 1.151391, bias2: 0.23698925971984863, variance: 0.9144021272659302\n",
      "Train size: [400] hidden size: [1491] trial: 29, train_loss: 0.008033, test loss: 1.153461, bias2: 0.2368837594985962, variance: 0.9165772199630737\n",
      "Train size: [400] hidden size: [1491] trial: 30, train_loss: 0.008034, test loss: 1.156333, bias2: 0.23557084798812866, variance: 0.92076176404953\n",
      "Train size: [400] hidden size: [1491] trial: 31, train_loss: 0.008049, test loss: 1.160274, bias2: 0.23489892482757568, variance: 0.9253751039505005\n",
      "Train size: [400] hidden size: [1491] trial: 32, train_loss: 0.008025, test loss: 1.160003, bias2: 0.23426735401153564, variance: 0.925735354423523\n",
      "Train size: [400] hidden size: [1491] trial: 33, train_loss: 0.007981, test loss: 1.160038, bias2: 0.23198318481445312, variance: 0.9280551671981812\n",
      "Train size: [400] hidden size: [1491] trial: 34, train_loss: 0.008003, test loss: 1.159610, bias2: 0.23148292303085327, variance: 0.928127110004425\n",
      "Train size: [400] hidden size: [1491] trial: 35, train_loss: 0.007962, test loss: 1.158197, bias2: 0.23039847612380981, variance: 0.9277982115745544\n",
      "Train size: [400] hidden size: [1491] trial: 36, train_loss: 0.007957, test loss: 1.159243, bias2: 0.2306051254272461, variance: 0.9286383390426636\n",
      "Train size: [400] hidden size: [1491] trial: 37, train_loss: 0.007926, test loss: 1.158423, bias2: 0.23029661178588867, variance: 0.928126335144043\n",
      "Train size: [400] hidden size: [1491] trial: 38, train_loss: 0.007940, test loss: 1.160269, bias2: 0.2327370047569275, variance: 0.9275322556495667\n",
      "Train size: [400] hidden size: [1491] trial: 39, train_loss: 0.007936, test loss: 1.161971, bias2: 0.23288697004318237, variance: 0.9290841221809387\n",
      "Train size: [400] hidden size: [1491] trial: 40, train_loss: 0.007965, test loss: 1.161021, bias2: 0.23210746049880981, variance: 0.9289138913154602\n",
      "Train size: [400] hidden size: [1491] trial: 41, train_loss: 0.007965, test loss: 1.163148, bias2: 0.2310231328010559, variance: 0.9321251511573792\n",
      "Train size: [400] hidden size: [1491] trial: 42, train_loss: 0.007974, test loss: 1.161237, bias2: 0.23014211654663086, variance: 0.9310951232910156\n",
      "Train size: [400] hidden size: [1491] trial: 43, train_loss: 0.007977, test loss: 1.159062, bias2: 0.2288075089454651, variance: 0.9302543997764587\n",
      "Train size: [400] hidden size: [1491] trial: 44, train_loss: 0.007959, test loss: 1.159368, bias2: 0.22781115770339966, variance: 0.9315572381019592\n",
      "Train size: [400] hidden size: [1491] trial: 45, train_loss: 0.007924, test loss: 1.161763, bias2: 0.2301996350288391, variance: 0.931563675403595\n",
      "Train size: [400] hidden size: [1491] trial: 46, train_loss: 0.007936, test loss: 1.165382, bias2: 0.2313939332962036, variance: 0.933988094329834\n",
      "Train size: [400] hidden size: [1491] trial: 47, train_loss: 0.007927, test loss: 1.163537, bias2: 0.2311028242111206, variance: 0.9324342012405396\n",
      "Train size: [400] hidden size: [1491] trial: 48, train_loss: 0.007923, test loss: 1.164147, bias2: 0.23109173774719238, variance: 0.9330549240112305\n",
      "Train size: [400] hidden size: [1491] trial: 49, train_loss: 0.007899, test loss: 1.162720, bias2: 0.23130059242248535, variance: 0.9314191341400146\n",
      "##################################################\n",
      "Train size: [400] hidden size: [1717] trial: 0, train_loss: 0.007377, test loss: 1.161426, bias2: 1.1614258289337158, variance: 5.449567463955418e-09\n",
      "Train size: [400] hidden size: [1717] trial: 1, train_loss: 0.007433, test loss: 1.142088, bias2: 0.6844525337219238, variance: 0.4576350450515747\n",
      "Train size: [400] hidden size: [1717] trial: 2, train_loss: 0.007408, test loss: 1.101680, bias2: 0.5055685639381409, variance: 0.5961111187934875\n",
      "Train size: [400] hidden size: [1717] trial: 3, train_loss: 0.007280, test loss: 1.087853, bias2: 0.40435880422592163, variance: 0.6834941506385803\n",
      "Train size: [400] hidden size: [1717] trial: 4, train_loss: 0.007315, test loss: 1.107515, bias2: 0.36539167165756226, variance: 0.7421236634254456\n",
      "Train size: [400] hidden size: [1717] trial: 5, train_loss: 0.007057, test loss: 1.097980, bias2: 0.3420060873031616, variance: 0.7559741735458374\n",
      "Train size: [400] hidden size: [1717] trial: 6, train_loss: 0.007107, test loss: 1.083350, bias2: 0.309237539768219, variance: 0.7741124033927917\n",
      "Train size: [400] hidden size: [1717] trial: 7, train_loss: 0.007070, test loss: 1.079426, bias2: 0.2949383854866028, variance: 0.7844874262809753\n",
      "Train size: [400] hidden size: [1717] trial: 8, train_loss: 0.007087, test loss: 1.081359, bias2: 0.28731852769851685, variance: 0.7940402626991272\n",
      "Train size: [400] hidden size: [1717] trial: 9, train_loss: 0.007063, test loss: 1.085934, bias2: 0.28175365924835205, variance: 0.8041806221008301\n",
      "Train size: [400] hidden size: [1717] trial: 10, train_loss: 0.007041, test loss: 1.093516, bias2: 0.2790447473526001, variance: 0.8144707679748535\n",
      "Train size: [400] hidden size: [1717] trial: 11, train_loss: 0.007128, test loss: 1.096264, bias2: 0.27120816707611084, variance: 0.825055718421936\n",
      "Train size: [400] hidden size: [1717] trial: 12, train_loss: 0.007111, test loss: 1.080898, bias2: 0.26149457693099976, variance: 0.8194037079811096\n",
      "Train size: [400] hidden size: [1717] trial: 13, train_loss: 0.007099, test loss: 1.087831, bias2: 0.26305824518203735, variance: 0.8247726559638977\n",
      "Train size: [400] hidden size: [1717] trial: 14, train_loss: 0.007117, test loss: 1.083403, bias2: 0.2557833194732666, variance: 0.8276195526123047\n",
      "Train size: [400] hidden size: [1717] trial: 15, train_loss: 0.007089, test loss: 1.084011, bias2: 0.25284475088119507, variance: 0.8311662077903748\n",
      "Train size: [400] hidden size: [1717] trial: 16, train_loss: 0.007151, test loss: 1.089580, bias2: 0.24625277519226074, variance: 0.8433274030685425\n",
      "Train size: [400] hidden size: [1717] trial: 17, train_loss: 0.007138, test loss: 1.085071, bias2: 0.24468517303466797, variance: 0.8403855562210083\n",
      "Train size: [400] hidden size: [1717] trial: 18, train_loss: 0.007173, test loss: 1.083748, bias2: 0.24054694175720215, variance: 0.8432008028030396\n",
      "Train size: [400] hidden size: [1717] trial: 19, train_loss: 0.007226, test loss: 1.085447, bias2: 0.2396036982536316, variance: 0.8458436131477356\n",
      "Train size: [400] hidden size: [1717] trial: 20, train_loss: 0.007225, test loss: 1.090633, bias2: 0.24047988653182983, variance: 0.8501526713371277\n",
      "Train size: [400] hidden size: [1717] trial: 21, train_loss: 0.007150, test loss: 1.093984, bias2: 0.24427860975265503, variance: 0.8497055172920227\n",
      "Train size: [400] hidden size: [1717] trial: 22, train_loss: 0.007130, test loss: 1.094433, bias2: 0.2436668872833252, variance: 0.8507657051086426\n",
      "Train size: [400] hidden size: [1717] trial: 23, train_loss: 0.007115, test loss: 1.093131, bias2: 0.241671621799469, variance: 0.851459801197052\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [1717] trial: 24, train_loss: 0.007157, test loss: 1.092747, bias2: 0.2405071258544922, variance: 0.8522402048110962\n",
      "Train size: [400] hidden size: [1717] trial: 25, train_loss: 0.007159, test loss: 1.090910, bias2: 0.23503828048706055, variance: 0.8558717966079712\n",
      "Train size: [400] hidden size: [1717] trial: 26, train_loss: 0.007127, test loss: 1.089719, bias2: 0.2337142825126648, variance: 0.8560051321983337\n",
      "Train size: [400] hidden size: [1717] trial: 27, train_loss: 0.007106, test loss: 1.087965, bias2: 0.23504102230072021, variance: 0.8529236316680908\n",
      "Train size: [400] hidden size: [1717] trial: 28, train_loss: 0.007077, test loss: 1.087042, bias2: 0.23561811447143555, variance: 0.8514242172241211\n",
      "Train size: [400] hidden size: [1717] trial: 29, train_loss: 0.007079, test loss: 1.092278, bias2: 0.23710602521896362, variance: 0.8551720976829529\n",
      "Train size: [400] hidden size: [1717] trial: 30, train_loss: 0.007112, test loss: 1.093735, bias2: 0.23650223016738892, variance: 0.857232391834259\n",
      "Train size: [400] hidden size: [1717] trial: 31, train_loss: 0.007115, test loss: 1.094461, bias2: 0.23541975021362305, variance: 0.859041690826416\n",
      "Train size: [400] hidden size: [1717] trial: 32, train_loss: 0.007093, test loss: 1.091401, bias2: 0.23535948991775513, variance: 0.8560412526130676\n",
      "Train size: [400] hidden size: [1717] trial: 33, train_loss: 0.007098, test loss: 1.090488, bias2: 0.23310405015945435, variance: 0.8573842644691467\n",
      "Train size: [400] hidden size: [1717] trial: 34, train_loss: 0.007089, test loss: 1.089927, bias2: 0.23390495777130127, variance: 0.8560218811035156\n",
      "Train size: [400] hidden size: [1717] trial: 35, train_loss: 0.007062, test loss: 1.086876, bias2: 0.23216599225997925, variance: 0.8547102808952332\n",
      "Train size: [400] hidden size: [1717] trial: 36, train_loss: 0.007085, test loss: 1.089618, bias2: 0.23272687196731567, variance: 0.8568912148475647\n",
      "Train size: [400] hidden size: [1717] trial: 37, train_loss: 0.007081, test loss: 1.089218, bias2: 0.2310134768486023, variance: 0.8582047820091248\n",
      "Train size: [400] hidden size: [1717] trial: 38, train_loss: 0.007032, test loss: 1.085108, bias2: 0.23113077878952026, variance: 0.8539767861366272\n",
      "Train size: [400] hidden size: [1717] trial: 39, train_loss: 0.007008, test loss: 1.083579, bias2: 0.23063313961029053, variance: 0.8529462814331055\n",
      "Train size: [400] hidden size: [1717] trial: 40, train_loss: 0.007008, test loss: 1.079673, bias2: 0.22840774059295654, variance: 0.8512650728225708\n",
      "Train size: [400] hidden size: [1717] trial: 41, train_loss: 0.007014, test loss: 1.079763, bias2: 0.22967767715454102, variance: 0.8500852584838867\n",
      "Train size: [400] hidden size: [1717] trial: 42, train_loss: 0.007017, test loss: 1.081795, bias2: 0.2304079532623291, variance: 0.8513869047164917\n",
      "Train size: [400] hidden size: [1717] trial: 43, train_loss: 0.007023, test loss: 1.083148, bias2: 0.22984826564788818, variance: 0.8532994985580444\n",
      "Train size: [400] hidden size: [1717] trial: 44, train_loss: 0.007022, test loss: 1.083547, bias2: 0.23009848594665527, variance: 0.8534480333328247\n",
      "Train size: [400] hidden size: [1717] trial: 45, train_loss: 0.007008, test loss: 1.085507, bias2: 0.23227906227111816, variance: 0.8532277345657349\n",
      "Train size: [400] hidden size: [1717] trial: 46, train_loss: 0.006986, test loss: 1.085197, bias2: 0.2305343747138977, variance: 0.8546623587608337\n",
      "Train size: [400] hidden size: [1717] trial: 47, train_loss: 0.006977, test loss: 1.082892, bias2: 0.23048800230026245, variance: 0.8524035811424255\n",
      "Train size: [400] hidden size: [1717] trial: 48, train_loss: 0.006959, test loss: 1.085707, bias2: 0.23037445545196533, variance: 0.8553327322006226\n",
      "Train size: [400] hidden size: [1717] trial: 49, train_loss: 0.006958, test loss: 1.086477, bias2: 0.22843897342681885, variance: 0.858038067817688\n",
      "##################################################\n",
      "Train size: [400] hidden size: [1977] trial: 0, train_loss: 0.007370, test loss: 1.029919, bias2: 1.0299193859100342, variance: -1.1677644629060069e-08\n",
      "Train size: [400] hidden size: [1977] trial: 1, train_loss: 0.006823, test loss: 0.989095, bias2: 0.6015238761901855, variance: 0.38757118582725525\n",
      "Train size: [400] hidden size: [1977] trial: 2, train_loss: 0.006738, test loss: 0.998069, bias2: 0.4825506806373596, variance: 0.5155186057090759\n",
      "Train size: [400] hidden size: [1977] trial: 3, train_loss: 0.006715, test loss: 0.993589, bias2: 0.41644930839538574, variance: 0.5771392583847046\n",
      "Train size: [400] hidden size: [1977] trial: 4, train_loss: 0.006765, test loss: 0.999847, bias2: 0.37257474660873413, variance: 0.627272367477417\n",
      "Train size: [400] hidden size: [1977] trial: 5, train_loss: 0.006748, test loss: 0.982805, bias2: 0.33589619398117065, variance: 0.6469090580940247\n",
      "Train size: [400] hidden size: [1977] trial: 6, train_loss: 0.006716, test loss: 0.986673, bias2: 0.3163994550704956, variance: 0.6702736020088196\n",
      "Train size: [400] hidden size: [1977] trial: 7, train_loss: 0.006747, test loss: 0.983228, bias2: 0.28957754373550415, variance: 0.6936508417129517\n",
      "Train size: [400] hidden size: [1977] trial: 8, train_loss: 0.006623, test loss: 0.989426, bias2: 0.28342509269714355, variance: 0.706001341342926\n",
      "Train size: [400] hidden size: [1977] trial: 9, train_loss: 0.006634, test loss: 0.989192, bias2: 0.26310479640960693, variance: 0.726087212562561\n",
      "Train size: [400] hidden size: [1977] trial: 10, train_loss: 0.006659, test loss: 0.992071, bias2: 0.25984352827072144, variance: 0.732227623462677\n",
      "Train size: [400] hidden size: [1977] trial: 11, train_loss: 0.006777, test loss: 0.997624, bias2: 0.2557010054588318, variance: 0.7419229745864868\n",
      "Train size: [400] hidden size: [1977] trial: 12, train_loss: 0.006759, test loss: 0.995477, bias2: 0.2499769926071167, variance: 0.7455003261566162\n",
      "Train size: [400] hidden size: [1977] trial: 13, train_loss: 0.006689, test loss: 0.996485, bias2: 0.24691075086593628, variance: 0.7495742440223694\n",
      "Train size: [400] hidden size: [1977] trial: 14, train_loss: 0.006664, test loss: 1.003325, bias2: 0.24943453073501587, variance: 0.7538902163505554\n",
      "Train size: [400] hidden size: [1977] trial: 15, train_loss: 0.006624, test loss: 0.993874, bias2: 0.24129164218902588, variance: 0.7525822520256042\n",
      "Train size: [400] hidden size: [1977] trial: 16, train_loss: 0.006586, test loss: 0.997119, bias2: 0.2403792142868042, variance: 0.756740152835846\n",
      "Train size: [400] hidden size: [1977] trial: 17, train_loss: 0.006567, test loss: 0.996949, bias2: 0.2351236343383789, variance: 0.7618251442909241\n",
      "Train size: [400] hidden size: [1977] trial: 18, train_loss: 0.006548, test loss: 0.996278, bias2: 0.23262625932693481, variance: 0.7636519074440002\n",
      "Train size: [400] hidden size: [1977] trial: 19, train_loss: 0.006514, test loss: 0.996840, bias2: 0.23056894540786743, variance: 0.7662706971168518\n",
      "Train size: [400] hidden size: [1977] trial: 20, train_loss: 0.006531, test loss: 0.994880, bias2: 0.22800570726394653, variance: 0.7668740749359131\n",
      "Train size: [400] hidden size: [1977] trial: 21, train_loss: 0.006497, test loss: 0.998517, bias2: 0.2295045256614685, variance: 0.7690125107765198\n",
      "Train size: [400] hidden size: [1977] trial: 22, train_loss: 0.006545, test loss: 0.997661, bias2: 0.22937935590744019, variance: 0.7682820558547974\n",
      "Train size: [400] hidden size: [1977] trial: 23, train_loss: 0.006525, test loss: 0.998294, bias2: 0.22886598110198975, variance: 0.769428014755249\n",
      "Train size: [400] hidden size: [1977] trial: 24, train_loss: 0.006514, test loss: 1.001142, bias2: 0.23039692640304565, variance: 0.7707452178001404\n",
      "Train size: [400] hidden size: [1977] trial: 25, train_loss: 0.006531, test loss: 0.999986, bias2: 0.2256917953491211, variance: 0.7742946743965149\n",
      "Train size: [400] hidden size: [1977] trial: 26, train_loss: 0.006514, test loss: 0.996834, bias2: 0.22095584869384766, variance: 0.7758778929710388\n",
      "Train size: [400] hidden size: [1977] trial: 27, train_loss: 0.006523, test loss: 1.004489, bias2: 0.22352135181427002, variance: 0.7809678316116333\n",
      "Train size: [400] hidden size: [1977] trial: 28, train_loss: 0.006567, test loss: 1.004102, bias2: 0.22117453813552856, variance: 0.7829269766807556\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [1977] trial: 29, train_loss: 0.006591, test loss: 1.007939, bias2: 0.22013217210769653, variance: 0.7878068089485168\n",
      "Train size: [400] hidden size: [1977] trial: 30, train_loss: 0.006578, test loss: 1.008407, bias2: 0.22174346446990967, variance: 0.7866631746292114\n",
      "Train size: [400] hidden size: [1977] trial: 31, train_loss: 0.006569, test loss: 1.008996, bias2: 0.2224806547164917, variance: 0.7865148782730103\n",
      "Train size: [400] hidden size: [1977] trial: 32, train_loss: 0.006546, test loss: 1.010303, bias2: 0.22245126962661743, variance: 0.7878515124320984\n",
      "Train size: [400] hidden size: [1977] trial: 33, train_loss: 0.006543, test loss: 1.010708, bias2: 0.22029417753219604, variance: 0.7904142737388611\n",
      "Train size: [400] hidden size: [1977] trial: 34, train_loss: 0.006560, test loss: 1.010272, bias2: 0.2193031907081604, variance: 0.7909688353538513\n",
      "Train size: [400] hidden size: [1977] trial: 35, train_loss: 0.006600, test loss: 1.012263, bias2: 0.218488872051239, variance: 0.7937743067741394\n",
      "Train size: [400] hidden size: [1977] trial: 36, train_loss: 0.006616, test loss: 1.014649, bias2: 0.21802979707717896, variance: 0.7966189980506897\n",
      "Train size: [400] hidden size: [1977] trial: 37, train_loss: 0.006594, test loss: 1.012383, bias2: 0.21724987030029297, variance: 0.7951327562332153\n",
      "Train size: [400] hidden size: [1977] trial: 38, train_loss: 0.006615, test loss: 1.014655, bias2: 0.21660631895065308, variance: 0.798048198223114\n",
      "Train size: [400] hidden size: [1977] trial: 39, train_loss: 0.006605, test loss: 1.011688, bias2: 0.2146955132484436, variance: 0.7969922423362732\n",
      "Train size: [400] hidden size: [1977] trial: 40, train_loss: 0.006613, test loss: 1.013709, bias2: 0.21584832668304443, variance: 0.7978605031967163\n",
      "Train size: [400] hidden size: [1977] trial: 41, train_loss: 0.006608, test loss: 1.013500, bias2: 0.21613991260528564, variance: 0.7973597049713135\n",
      "Train size: [400] hidden size: [1977] trial: 42, train_loss: 0.006588, test loss: 1.014203, bias2: 0.216966450214386, variance: 0.7972368597984314\n",
      "Train size: [400] hidden size: [1977] trial: 43, train_loss: 0.006611, test loss: 1.015056, bias2: 0.21668517589569092, variance: 0.7983711957931519\n",
      "Train size: [400] hidden size: [1977] trial: 44, train_loss: 0.006607, test loss: 1.013681, bias2: 0.21653258800506592, variance: 0.7971487045288086\n",
      "Train size: [400] hidden size: [1977] trial: 45, train_loss: 0.006612, test loss: 1.013290, bias2: 0.21395611763000488, variance: 0.7993340492248535\n",
      "Train size: [400] hidden size: [1977] trial: 46, train_loss: 0.006611, test loss: 1.014441, bias2: 0.21444427967071533, variance: 0.7999969720840454\n",
      "Train size: [400] hidden size: [1977] trial: 47, train_loss: 0.006616, test loss: 1.016790, bias2: 0.2137719988822937, variance: 0.8030180335044861\n",
      "Train size: [400] hidden size: [1977] trial: 48, train_loss: 0.006610, test loss: 1.016727, bias2: 0.21395689249038696, variance: 0.8027699589729309\n",
      "Train size: [400] hidden size: [1977] trial: 49, train_loss: 0.006609, test loss: 1.015982, bias2: 0.2135811448097229, variance: 0.802400529384613\n",
      "##################################################\n",
      "Train size: [400] hidden size: [2276] trial: 0, train_loss: 0.005425, test loss: 0.945755, bias2: 0.9457554817199707, variance: 4.6710577628061856e-09\n",
      "Train size: [400] hidden size: [2276] trial: 1, train_loss: 0.005181, test loss: 0.938431, bias2: 0.5584936141967773, variance: 0.3799375593662262\n",
      "Train size: [400] hidden size: [2276] trial: 2, train_loss: 0.005532, test loss: 0.966821, bias2: 0.4562613368034363, variance: 0.5105599164962769\n",
      "Train size: [400] hidden size: [2276] trial: 3, train_loss: 0.005800, test loss: 0.985462, bias2: 0.39800554513931274, variance: 0.587456226348877\n",
      "Train size: [400] hidden size: [2276] trial: 4, train_loss: 0.005696, test loss: 0.977061, bias2: 0.3629552125930786, variance: 0.6141058206558228\n",
      "Train size: [400] hidden size: [2276] trial: 5, train_loss: 0.005986, test loss: 0.965270, bias2: 0.32931673526763916, variance: 0.6359528303146362\n",
      "Train size: [400] hidden size: [2276] trial: 6, train_loss: 0.005879, test loss: 0.953011, bias2: 0.30181610584259033, variance: 0.6511945128440857\n",
      "Train size: [400] hidden size: [2276] trial: 7, train_loss: 0.005917, test loss: 0.949106, bias2: 0.2850322127342224, variance: 0.664073646068573\n",
      "Train size: [400] hidden size: [2276] trial: 8, train_loss: 0.005936, test loss: 0.961500, bias2: 0.2717822194099426, variance: 0.6897173523902893\n",
      "Train size: [400] hidden size: [2276] trial: 9, train_loss: 0.005842, test loss: 0.959766, bias2: 0.2632604241371155, variance: 0.696505606174469\n",
      "Train size: [400] hidden size: [2276] trial: 10, train_loss: 0.005934, test loss: 0.961216, bias2: 0.25467461347579956, variance: 0.7065409421920776\n",
      "Train size: [400] hidden size: [2276] trial: 11, train_loss: 0.005942, test loss: 0.957084, bias2: 0.25112640857696533, variance: 0.7059575319290161\n",
      "Train size: [400] hidden size: [2276] trial: 12, train_loss: 0.005940, test loss: 0.959344, bias2: 0.24527853727340698, variance: 0.714065432548523\n",
      "Train size: [400] hidden size: [2276] trial: 13, train_loss: 0.005976, test loss: 0.961706, bias2: 0.24209225177764893, variance: 0.7196139097213745\n",
      "Train size: [400] hidden size: [2276] trial: 14, train_loss: 0.005996, test loss: 0.955478, bias2: 0.2350347638130188, variance: 0.7204432487487793\n",
      "Train size: [400] hidden size: [2276] trial: 15, train_loss: 0.006045, test loss: 0.962764, bias2: 0.23316097259521484, variance: 0.7296031713485718\n",
      "Train size: [400] hidden size: [2276] trial: 16, train_loss: 0.006094, test loss: 0.970056, bias2: 0.23150509595870972, variance: 0.7385513186454773\n",
      "Train size: [400] hidden size: [2276] trial: 17, train_loss: 0.006076, test loss: 0.968841, bias2: 0.2293667197227478, variance: 0.7394742369651794\n",
      "Train size: [400] hidden size: [2276] trial: 18, train_loss: 0.005992, test loss: 0.963911, bias2: 0.22711801528930664, variance: 0.7367925047874451\n",
      "Train size: [400] hidden size: [2276] trial: 19, train_loss: 0.005984, test loss: 0.963511, bias2: 0.22831839323043823, variance: 0.7351928949356079\n",
      "Train size: [400] hidden size: [2276] trial: 20, train_loss: 0.005988, test loss: 0.964714, bias2: 0.2271159291267395, variance: 0.7375980019569397\n",
      "Train size: [400] hidden size: [2276] trial: 21, train_loss: 0.005967, test loss: 0.968646, bias2: 0.22701603174209595, variance: 0.7416302561759949\n",
      "Train size: [400] hidden size: [2276] trial: 22, train_loss: 0.006009, test loss: 0.970682, bias2: 0.22667145729064941, variance: 0.7440105080604553\n",
      "Train size: [400] hidden size: [2276] trial: 23, train_loss: 0.005988, test loss: 0.965527, bias2: 0.22293007373809814, variance: 0.7425966858863831\n",
      "Train size: [400] hidden size: [2276] trial: 24, train_loss: 0.005988, test loss: 0.964916, bias2: 0.22379964590072632, variance: 0.7411160469055176\n",
      "Train size: [400] hidden size: [2276] trial: 25, train_loss: 0.005975, test loss: 0.968746, bias2: 0.22308385372161865, variance: 0.7456617951393127\n",
      "Train size: [400] hidden size: [2276] trial: 26, train_loss: 0.005995, test loss: 0.968962, bias2: 0.2219673991203308, variance: 0.7469950318336487\n",
      "Train size: [400] hidden size: [2276] trial: 27, train_loss: 0.005962, test loss: 0.969056, bias2: 0.21969622373580933, variance: 0.7493601441383362\n",
      "Train size: [400] hidden size: [2276] trial: 28, train_loss: 0.005955, test loss: 0.972430, bias2: 0.22258704900741577, variance: 0.7498424649238586\n",
      "Train size: [400] hidden size: [2276] trial: 29, train_loss: 0.005984, test loss: 0.971616, bias2: 0.2206817865371704, variance: 0.7509340643882751\n",
      "Train size: [400] hidden size: [2276] trial: 30, train_loss: 0.005995, test loss: 0.970703, bias2: 0.21997332572937012, variance: 0.7507301568984985\n",
      "Train size: [400] hidden size: [2276] trial: 31, train_loss: 0.005984, test loss: 0.968144, bias2: 0.21876907348632812, variance: 0.7493749260902405\n",
      "Train size: [400] hidden size: [2276] trial: 32, train_loss: 0.005977, test loss: 0.970298, bias2: 0.2191256880760193, variance: 0.7511721253395081\n",
      "Train size: [400] hidden size: [2276] trial: 33, train_loss: 0.005991, test loss: 0.969739, bias2: 0.21781659126281738, variance: 0.751922607421875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [2276] trial: 34, train_loss: 0.006035, test loss: 0.969776, bias2: 0.21632933616638184, variance: 0.7534468173980713\n",
      "Train size: [400] hidden size: [2276] trial: 35, train_loss: 0.006030, test loss: 0.969942, bias2: 0.21729153394699097, variance: 0.7526502013206482\n",
      "Train size: [400] hidden size: [2276] trial: 36, train_loss: 0.006039, test loss: 0.968422, bias2: 0.21672594547271729, variance: 0.7516956329345703\n",
      "Train size: [400] hidden size: [2276] trial: 37, train_loss: 0.006067, test loss: 0.968662, bias2: 0.21463966369628906, variance: 0.7540223002433777\n",
      "Train size: [400] hidden size: [2276] trial: 38, train_loss: 0.006078, test loss: 0.967115, bias2: 0.2132863998413086, variance: 0.7538288235664368\n",
      "Train size: [400] hidden size: [2276] trial: 39, train_loss: 0.006097, test loss: 0.968026, bias2: 0.21212905645370483, variance: 0.755896806716919\n",
      "Train size: [400] hidden size: [2276] trial: 40, train_loss: 0.006090, test loss: 0.966629, bias2: 0.21083205938339233, variance: 0.7557965517044067\n",
      "Train size: [400] hidden size: [2276] trial: 41, train_loss: 0.006093, test loss: 0.966124, bias2: 0.2099553942680359, variance: 0.7561684846878052\n",
      "Train size: [400] hidden size: [2276] trial: 42, train_loss: 0.006092, test loss: 0.965661, bias2: 0.21084213256835938, variance: 0.7548192739486694\n",
      "Train size: [400] hidden size: [2276] trial: 43, train_loss: 0.006091, test loss: 0.966697, bias2: 0.2101454734802246, variance: 0.7565516829490662\n",
      "Train size: [400] hidden size: [2276] trial: 44, train_loss: 0.006092, test loss: 0.966705, bias2: 0.20958256721496582, variance: 0.7571228742599487\n",
      "Train size: [400] hidden size: [2276] trial: 45, train_loss: 0.006107, test loss: 0.967679, bias2: 0.21107643842697144, variance: 0.7566025257110596\n",
      "Train size: [400] hidden size: [2276] trial: 46, train_loss: 0.006115, test loss: 0.966757, bias2: 0.21084082126617432, variance: 0.7559163570404053\n",
      "Train size: [400] hidden size: [2276] trial: 47, train_loss: 0.006104, test loss: 0.968253, bias2: 0.2115350365638733, variance: 0.7567175626754761\n",
      "Train size: [400] hidden size: [2276] trial: 48, train_loss: 0.006081, test loss: 0.967721, bias2: 0.21137505769729614, variance: 0.7563462257385254\n",
      "Train size: [400] hidden size: [2276] trial: 49, train_loss: 0.006086, test loss: 0.967596, bias2: 0.21033859252929688, variance: 0.757257878780365\n",
      "##################################################\n",
      "Train size: [400] hidden size: [2621] trial: 0, train_loss: 0.005602, test loss: 0.861896, bias2: 0.8618963360786438, variance: -1.0120625226761604e-08\n",
      "Train size: [400] hidden size: [2621] trial: 1, train_loss: 0.006030, test loss: 0.894666, bias2: 0.5416542887687683, variance: 0.3530113697052002\n",
      "Train size: [400] hidden size: [2621] trial: 2, train_loss: 0.005963, test loss: 0.921271, bias2: 0.4443444013595581, variance: 0.4769270420074463\n",
      "Train size: [400] hidden size: [2621] trial: 3, train_loss: 0.005635, test loss: 0.911419, bias2: 0.37032246589660645, variance: 0.5410968065261841\n",
      "Train size: [400] hidden size: [2621] trial: 4, train_loss: 0.005686, test loss: 0.937008, bias2: 0.34897011518478394, variance: 0.5880374908447266\n",
      "Train size: [400] hidden size: [2621] trial: 5, train_loss: 0.005644, test loss: 0.932145, bias2: 0.31950390338897705, variance: 0.6126406192779541\n",
      "Train size: [400] hidden size: [2621] trial: 6, train_loss: 0.005603, test loss: 0.938842, bias2: 0.30942708253860474, variance: 0.6294150948524475\n",
      "Train size: [400] hidden size: [2621] trial: 7, train_loss: 0.005814, test loss: 0.956730, bias2: 0.298708438873291, variance: 0.6580220460891724\n",
      "Train size: [400] hidden size: [2621] trial: 8, train_loss: 0.005768, test loss: 0.952478, bias2: 0.29026907682418823, variance: 0.662209153175354\n",
      "Train size: [400] hidden size: [2621] trial: 9, train_loss: 0.005641, test loss: 0.953415, bias2: 0.2872857451438904, variance: 0.6661291122436523\n",
      "Train size: [400] hidden size: [2621] trial: 10, train_loss: 0.005631, test loss: 0.944314, bias2: 0.2821924090385437, variance: 0.6621217131614685\n",
      "Train size: [400] hidden size: [2621] trial: 11, train_loss: 0.005623, test loss: 0.950217, bias2: 0.27905476093292236, variance: 0.671162486076355\n",
      "Train size: [400] hidden size: [2621] trial: 12, train_loss: 0.005643, test loss: 0.947616, bias2: 0.2741661071777344, variance: 0.6734498143196106\n",
      "Train size: [400] hidden size: [2621] trial: 13, train_loss: 0.005763, test loss: 0.948257, bias2: 0.271980881690979, variance: 0.676276445388794\n",
      "Train size: [400] hidden size: [2621] trial: 14, train_loss: 0.005828, test loss: 0.951438, bias2: 0.2648929953575134, variance: 0.6865450143814087\n",
      "Train size: [400] hidden size: [2621] trial: 15, train_loss: 0.005744, test loss: 0.944786, bias2: 0.2606942057609558, variance: 0.6840921640396118\n",
      "Train size: [400] hidden size: [2621] trial: 16, train_loss: 0.005749, test loss: 0.948039, bias2: 0.2566620707511902, variance: 0.6913771033287048\n",
      "Train size: [400] hidden size: [2621] trial: 17, train_loss: 0.005767, test loss: 0.950298, bias2: 0.2559172511100769, variance: 0.6943811774253845\n",
      "Train size: [400] hidden size: [2621] trial: 18, train_loss: 0.005726, test loss: 0.946070, bias2: 0.25460582971572876, variance: 0.6914640665054321\n",
      "Train size: [400] hidden size: [2621] trial: 19, train_loss: 0.005762, test loss: 0.944171, bias2: 0.2495686411857605, variance: 0.6946021914482117\n",
      "Train size: [400] hidden size: [2621] trial: 20, train_loss: 0.005732, test loss: 0.952667, bias2: 0.2533583641052246, variance: 0.6993088126182556\n",
      "Train size: [400] hidden size: [2621] trial: 21, train_loss: 0.005716, test loss: 0.950482, bias2: 0.24993515014648438, variance: 0.7005465626716614\n",
      "Train size: [400] hidden size: [2621] trial: 22, train_loss: 0.005708, test loss: 0.949203, bias2: 0.2463148832321167, variance: 0.7028883695602417\n",
      "Train size: [400] hidden size: [2621] trial: 23, train_loss: 0.005694, test loss: 0.946154, bias2: 0.2427881360054016, variance: 0.7033655643463135\n",
      "Train size: [400] hidden size: [2621] trial: 24, train_loss: 0.005688, test loss: 0.952098, bias2: 0.24390971660614014, variance: 0.7081886529922485\n",
      "Train size: [400] hidden size: [2621] trial: 25, train_loss: 0.005696, test loss: 0.951258, bias2: 0.23998159170150757, variance: 0.7112762331962585\n",
      "Train size: [400] hidden size: [2621] trial: 26, train_loss: 0.005705, test loss: 0.953801, bias2: 0.24023360013961792, variance: 0.7135673761367798\n",
      "Train size: [400] hidden size: [2621] trial: 27, train_loss: 0.005688, test loss: 0.953283, bias2: 0.2400924563407898, variance: 0.7131908535957336\n",
      "Train size: [400] hidden size: [2621] trial: 28, train_loss: 0.005647, test loss: 0.950847, bias2: 0.23876231908798218, variance: 0.7120850682258606\n",
      "Train size: [400] hidden size: [2621] trial: 29, train_loss: 0.005655, test loss: 0.950224, bias2: 0.2368677854537964, variance: 0.7133560180664062\n",
      "Train size: [400] hidden size: [2621] trial: 30, train_loss: 0.005682, test loss: 0.952656, bias2: 0.23587274551391602, variance: 0.7167832255363464\n",
      "Train size: [400] hidden size: [2621] trial: 31, train_loss: 0.005657, test loss: 0.951500, bias2: 0.23563998937606812, variance: 0.7158604860305786\n",
      "Train size: [400] hidden size: [2621] trial: 32, train_loss: 0.005662, test loss: 0.949630, bias2: 0.23235869407653809, variance: 0.7172715663909912\n",
      "Train size: [400] hidden size: [2621] trial: 33, train_loss: 0.005690, test loss: 0.950610, bias2: 0.23062676191329956, variance: 0.7199834585189819\n",
      "Train size: [400] hidden size: [2621] trial: 34, train_loss: 0.005670, test loss: 0.948115, bias2: 0.22934484481811523, variance: 0.7187700867652893\n",
      "Train size: [400] hidden size: [2621] trial: 35, train_loss: 0.005679, test loss: 0.946853, bias2: 0.22510290145874023, variance: 0.7217498421669006\n",
      "Train size: [400] hidden size: [2621] trial: 36, train_loss: 0.005668, test loss: 0.946890, bias2: 0.22473937273025513, variance: 0.7221509218215942\n",
      "Train size: [400] hidden size: [2621] trial: 37, train_loss: 0.005679, test loss: 0.944664, bias2: 0.22214490175247192, variance: 0.7225186824798584\n",
      "Train size: [400] hidden size: [2621] trial: 38, train_loss: 0.005679, test loss: 0.944570, bias2: 0.2218453288078308, variance: 0.7227247357368469\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [2621] trial: 39, train_loss: 0.005682, test loss: 0.944868, bias2: 0.22127783298492432, variance: 0.7235899567604065\n",
      "Train size: [400] hidden size: [2621] trial: 40, train_loss: 0.005646, test loss: 0.942781, bias2: 0.22012996673583984, variance: 0.7226512432098389\n",
      "Train size: [400] hidden size: [2621] trial: 41, train_loss: 0.005636, test loss: 0.944167, bias2: 0.22050482034683228, variance: 0.7236618399620056\n",
      "Train size: [400] hidden size: [2621] trial: 42, train_loss: 0.005626, test loss: 0.943179, bias2: 0.21952420473098755, variance: 0.723654568195343\n",
      "Train size: [400] hidden size: [2621] trial: 43, train_loss: 0.005655, test loss: 0.942633, bias2: 0.21880489587783813, variance: 0.7238282561302185\n",
      "Train size: [400] hidden size: [2621] trial: 44, train_loss: 0.005633, test loss: 0.941657, bias2: 0.21935266256332397, variance: 0.7223042845726013\n",
      "Train size: [400] hidden size: [2621] trial: 45, train_loss: 0.005619, test loss: 0.940951, bias2: 0.21927809715270996, variance: 0.721672534942627\n",
      "Train size: [400] hidden size: [2621] trial: 46, train_loss: 0.005594, test loss: 0.938757, bias2: 0.21791088581085205, variance: 0.7208461761474609\n",
      "Train size: [400] hidden size: [2621] trial: 47, train_loss: 0.005595, test loss: 0.938427, bias2: 0.2175866961479187, variance: 0.7208401560783386\n",
      "Train size: [400] hidden size: [2621] trial: 48, train_loss: 0.005580, test loss: 0.936050, bias2: 0.2159954309463501, variance: 0.7200547456741333\n",
      "Train size: [400] hidden size: [2621] trial: 49, train_loss: 0.005583, test loss: 0.933616, bias2: 0.21462053060531616, variance: 0.7189957499504089\n",
      "##################################################\n",
      "Train size: [400] hidden size: [3017] trial: 0, train_loss: 0.005746, test loss: 1.011579, bias2: 1.011578917503357, variance: 1.5570191802538602e-09\n",
      "Train size: [400] hidden size: [3017] trial: 1, train_loss: 0.005441, test loss: 0.970296, bias2: 0.608450710773468, variance: 0.3618450164794922\n",
      "Train size: [400] hidden size: [3017] trial: 2, train_loss: 0.005114, test loss: 0.932770, bias2: 0.4705508053302765, variance: 0.46221962571144104\n",
      "Train size: [400] hidden size: [3017] trial: 3, train_loss: 0.005384, test loss: 0.909800, bias2: 0.38953107595443726, variance: 0.5202690362930298\n",
      "Train size: [400] hidden size: [3017] trial: 4, train_loss: 0.005203, test loss: 0.924072, bias2: 0.3603819012641907, variance: 0.5636898279190063\n",
      "Train size: [400] hidden size: [3017] trial: 5, train_loss: 0.005282, test loss: 0.923995, bias2: 0.3206636309623718, variance: 0.603331446647644\n",
      "Train size: [400] hidden size: [3017] trial: 6, train_loss: 0.005209, test loss: 0.917037, bias2: 0.3075072169303894, variance: 0.6095295548439026\n",
      "Train size: [400] hidden size: [3017] trial: 7, train_loss: 0.005216, test loss: 0.909259, bias2: 0.2927345633506775, variance: 0.6165248155593872\n",
      "Train size: [400] hidden size: [3017] trial: 8, train_loss: 0.005244, test loss: 0.902060, bias2: 0.27082979679107666, variance: 0.6312298774719238\n",
      "Train size: [400] hidden size: [3017] trial: 9, train_loss: 0.005219, test loss: 0.895275, bias2: 0.2590859532356262, variance: 0.6361892819404602\n",
      "Train size: [400] hidden size: [3017] trial: 10, train_loss: 0.005205, test loss: 0.906974, bias2: 0.259410560131073, variance: 0.6475632786750793\n",
      "Train size: [400] hidden size: [3017] trial: 11, train_loss: 0.005291, test loss: 0.917052, bias2: 0.2560740113258362, variance: 0.6609777212142944\n",
      "Train size: [400] hidden size: [3017] trial: 12, train_loss: 0.005247, test loss: 0.915479, bias2: 0.2508593797683716, variance: 0.6646192073822021\n",
      "Train size: [400] hidden size: [3017] trial: 13, train_loss: 0.005240, test loss: 0.914293, bias2: 0.24396741390228271, variance: 0.6703252196311951\n",
      "Train size: [400] hidden size: [3017] trial: 14, train_loss: 0.005254, test loss: 0.916741, bias2: 0.24426120519638062, variance: 0.6724795699119568\n",
      "Train size: [400] hidden size: [3017] trial: 15, train_loss: 0.005262, test loss: 0.910467, bias2: 0.2390691637992859, variance: 0.671397864818573\n",
      "Train size: [400] hidden size: [3017] trial: 16, train_loss: 0.005304, test loss: 0.908110, bias2: 0.23495161533355713, variance: 0.6731586456298828\n",
      "Train size: [400] hidden size: [3017] trial: 17, train_loss: 0.005319, test loss: 0.906822, bias2: 0.23121041059494019, variance: 0.6756113767623901\n",
      "Train size: [400] hidden size: [3017] trial: 18, train_loss: 0.005281, test loss: 0.904671, bias2: 0.23342764377593994, variance: 0.6712433695793152\n",
      "Train size: [400] hidden size: [3017] trial: 19, train_loss: 0.005266, test loss: 0.906167, bias2: 0.2334941029548645, variance: 0.6726734042167664\n",
      "Train size: [400] hidden size: [3017] trial: 20, train_loss: 0.005247, test loss: 0.903606, bias2: 0.23272806406021118, variance: 0.6708776950836182\n",
      "Train size: [400] hidden size: [3017] trial: 21, train_loss: 0.005243, test loss: 0.904544, bias2: 0.23364073038101196, variance: 0.6709030866622925\n",
      "Train size: [400] hidden size: [3017] trial: 22, train_loss: 0.005235, test loss: 0.903219, bias2: 0.23248934745788574, variance: 0.6707295775413513\n",
      "Train size: [400] hidden size: [3017] trial: 23, train_loss: 0.005249, test loss: 0.900479, bias2: 0.23014557361602783, variance: 0.6703334450721741\n",
      "Train size: [400] hidden size: [3017] trial: 24, train_loss: 0.005219, test loss: 0.900216, bias2: 0.23106920719146729, variance: 0.6691467761993408\n",
      "Train size: [400] hidden size: [3017] trial: 25, train_loss: 0.005184, test loss: 0.898341, bias2: 0.23103004693984985, variance: 0.667311429977417\n",
      "Train size: [400] hidden size: [3017] trial: 26, train_loss: 0.005183, test loss: 0.895582, bias2: 0.2275007963180542, variance: 0.668081521987915\n",
      "Train size: [400] hidden size: [3017] trial: 27, train_loss: 0.005156, test loss: 0.893496, bias2: 0.2253705859184265, variance: 0.6681250333786011\n",
      "Train size: [400] hidden size: [3017] trial: 28, train_loss: 0.005158, test loss: 0.893025, bias2: 0.22322142124176025, variance: 0.6698031425476074\n",
      "Train size: [400] hidden size: [3017] trial: 29, train_loss: 0.005144, test loss: 0.892321, bias2: 0.2235945463180542, variance: 0.6687263250350952\n",
      "Train size: [400] hidden size: [3017] trial: 30, train_loss: 0.005152, test loss: 0.892955, bias2: 0.22293472290039062, variance: 0.6700207591056824\n",
      "Train size: [400] hidden size: [3017] trial: 31, train_loss: 0.005146, test loss: 0.892996, bias2: 0.22287380695343018, variance: 0.6701217889785767\n",
      "Train size: [400] hidden size: [3017] trial: 32, train_loss: 0.005141, test loss: 0.891229, bias2: 0.2209123969078064, variance: 0.6703168749809265\n",
      "Train size: [400] hidden size: [3017] trial: 33, train_loss: 0.005154, test loss: 0.889594, bias2: 0.21938657760620117, variance: 0.6702070236206055\n",
      "Train size: [400] hidden size: [3017] trial: 34, train_loss: 0.005159, test loss: 0.889648, bias2: 0.21818405389785767, variance: 0.6714637875556946\n",
      "Train size: [400] hidden size: [3017] trial: 35, train_loss: 0.005168, test loss: 0.891154, bias2: 0.21936845779418945, variance: 0.671785831451416\n",
      "Train size: [400] hidden size: [3017] trial: 36, train_loss: 0.005146, test loss: 0.889075, bias2: 0.21939784288406372, variance: 0.6696776151657104\n",
      "Train size: [400] hidden size: [3017] trial: 37, train_loss: 0.005140, test loss: 0.888719, bias2: 0.2187536358833313, variance: 0.6699649691581726\n",
      "Train size: [400] hidden size: [3017] trial: 38, train_loss: 0.005147, test loss: 0.888155, bias2: 0.2181166410446167, variance: 0.6700388193130493\n",
      "Train size: [400] hidden size: [3017] trial: 39, train_loss: 0.005136, test loss: 0.888113, bias2: 0.21686124801635742, variance: 0.6712512969970703\n",
      "Train size: [400] hidden size: [3017] trial: 40, train_loss: 0.005174, test loss: 0.890375, bias2: 0.21617591381072998, variance: 0.6741986274719238\n",
      "Train size: [400] hidden size: [3017] trial: 41, train_loss: 0.005177, test loss: 0.890431, bias2: 0.21646785736083984, variance: 0.6739628911018372\n",
      "Train size: [400] hidden size: [3017] trial: 42, train_loss: 0.005150, test loss: 0.888315, bias2: 0.2160705327987671, variance: 0.6722448468208313\n",
      "Train size: [400] hidden size: [3017] trial: 43, train_loss: 0.005164, test loss: 0.886487, bias2: 0.21526098251342773, variance: 0.6712255477905273\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [3017] trial: 44, train_loss: 0.005152, test loss: 0.888909, bias2: 0.21618002653121948, variance: 0.6727290749549866\n",
      "Train size: [400] hidden size: [3017] trial: 45, train_loss: 0.005143, test loss: 0.888728, bias2: 0.21596503257751465, variance: 0.6727628707885742\n",
      "Train size: [400] hidden size: [3017] trial: 46, train_loss: 0.005161, test loss: 0.890514, bias2: 0.21591782569885254, variance: 0.6745961308479309\n",
      "Train size: [400] hidden size: [3017] trial: 47, train_loss: 0.005153, test loss: 0.893438, bias2: 0.2161063551902771, variance: 0.6773315668106079\n",
      "Train size: [400] hidden size: [3017] trial: 48, train_loss: 0.005170, test loss: 0.891806, bias2: 0.2140125036239624, variance: 0.6777939200401306\n",
      "Train size: [400] hidden size: [3017] trial: 49, train_loss: 0.005162, test loss: 0.890223, bias2: 0.2133539319038391, variance: 0.67686927318573\n",
      "##################################################\n",
      "Train size: [400] hidden size: [3474] trial: 0, train_loss: 0.005051, test loss: 0.815772, bias2: 0.8157716393470764, variance: 3.8925479506346505e-10\n",
      "Train size: [400] hidden size: [3474] trial: 1, train_loss: 0.004868, test loss: 0.805071, bias2: 0.505354642868042, variance: 0.2997165322303772\n",
      "Train size: [400] hidden size: [3474] trial: 2, train_loss: 0.004929, test loss: 0.854421, bias2: 0.4208250939846039, variance: 0.4335961639881134\n",
      "Train size: [400] hidden size: [3474] trial: 3, train_loss: 0.004890, test loss: 0.865071, bias2: 0.368954062461853, variance: 0.4961167573928833\n",
      "Train size: [400] hidden size: [3474] trial: 4, train_loss: 0.004719, test loss: 0.864083, bias2: 0.3403130769729614, variance: 0.5237697958946228\n",
      "Train size: [400] hidden size: [3474] trial: 5, train_loss: 0.004841, test loss: 0.872093, bias2: 0.3272673487663269, variance: 0.5448256134986877\n",
      "Train size: [400] hidden size: [3474] trial: 6, train_loss: 0.004885, test loss: 0.863860, bias2: 0.2981325387954712, variance: 0.5657278299331665\n",
      "Train size: [400] hidden size: [3474] trial: 7, train_loss: 0.005065, test loss: 0.871978, bias2: 0.29149651527404785, variance: 0.5804811120033264\n",
      "Train size: [400] hidden size: [3474] trial: 8, train_loss: 0.005055, test loss: 0.869144, bias2: 0.2822225093841553, variance: 0.5869213342666626\n",
      "Train size: [400] hidden size: [3474] trial: 9, train_loss: 0.005020, test loss: 0.873533, bias2: 0.2724718451499939, variance: 0.6010615825653076\n",
      "Train size: [400] hidden size: [3474] trial: 10, train_loss: 0.004931, test loss: 0.872884, bias2: 0.26356393098831177, variance: 0.609320342540741\n",
      "Train size: [400] hidden size: [3474] trial: 11, train_loss: 0.004993, test loss: 0.873428, bias2: 0.2598639726638794, variance: 0.6135638952255249\n",
      "Train size: [400] hidden size: [3474] trial: 12, train_loss: 0.005005, test loss: 0.870705, bias2: 0.2560451030731201, variance: 0.614660382270813\n",
      "Train size: [400] hidden size: [3474] trial: 13, train_loss: 0.004996, test loss: 0.874152, bias2: 0.2539152503013611, variance: 0.6202365756034851\n",
      "Train size: [400] hidden size: [3474] trial: 14, train_loss: 0.004993, test loss: 0.882013, bias2: 0.2542828917503357, variance: 0.6277303099632263\n",
      "Train size: [400] hidden size: [3474] trial: 15, train_loss: 0.004993, test loss: 0.883831, bias2: 0.2554987668991089, variance: 0.6283325552940369\n",
      "Train size: [400] hidden size: [3474] trial: 16, train_loss: 0.004985, test loss: 0.875201, bias2: 0.2505379915237427, variance: 0.6246632933616638\n",
      "Train size: [400] hidden size: [3474] trial: 17, train_loss: 0.004954, test loss: 0.878669, bias2: 0.25105637311935425, variance: 0.6276127099990845\n",
      "Train size: [400] hidden size: [3474] trial: 18, train_loss: 0.004973, test loss: 0.882119, bias2: 0.25156116485595703, variance: 0.6305578351020813\n",
      "Train size: [400] hidden size: [3474] trial: 19, train_loss: 0.005016, test loss: 0.880259, bias2: 0.2483026385307312, variance: 0.6319558620452881\n",
      "Train size: [400] hidden size: [3474] trial: 20, train_loss: 0.004995, test loss: 0.873427, bias2: 0.24092894792556763, variance: 0.6324985027313232\n",
      "Train size: [400] hidden size: [3474] trial: 21, train_loss: 0.004961, test loss: 0.876710, bias2: 0.24292290210723877, variance: 0.6337869763374329\n",
      "Train size: [400] hidden size: [3474] trial: 22, train_loss: 0.005004, test loss: 0.877441, bias2: 0.2408856749534607, variance: 0.6365553140640259\n",
      "Train size: [400] hidden size: [3474] trial: 23, train_loss: 0.004974, test loss: 0.876425, bias2: 0.2399258017539978, variance: 0.6364996433258057\n",
      "Train size: [400] hidden size: [3474] trial: 24, train_loss: 0.004970, test loss: 0.880973, bias2: 0.2406705617904663, variance: 0.6403024196624756\n",
      "Train size: [400] hidden size: [3474] trial: 25, train_loss: 0.004987, test loss: 0.883526, bias2: 0.24042505025863647, variance: 0.6431006193161011\n",
      "Train size: [400] hidden size: [3474] trial: 26, train_loss: 0.004975, test loss: 0.883395, bias2: 0.24099314212799072, variance: 0.6424013376235962\n",
      "Train size: [400] hidden size: [3474] trial: 27, train_loss: 0.004985, test loss: 0.880556, bias2: 0.23948466777801514, variance: 0.6410712003707886\n",
      "Train size: [400] hidden size: [3474] trial: 28, train_loss: 0.004969, test loss: 0.878607, bias2: 0.23922812938690186, variance: 0.6393789649009705\n",
      "Train size: [400] hidden size: [3474] trial: 29, train_loss: 0.004963, test loss: 0.876376, bias2: 0.23652803897857666, variance: 0.6398478746414185\n",
      "Train size: [400] hidden size: [3474] trial: 30, train_loss: 0.004958, test loss: 0.875176, bias2: 0.23429721593856812, variance: 0.6408791542053223\n",
      "Train size: [400] hidden size: [3474] trial: 31, train_loss: 0.004933, test loss: 0.874507, bias2: 0.23369932174682617, variance: 0.6408076882362366\n",
      "Train size: [400] hidden size: [3474] trial: 32, train_loss: 0.004949, test loss: 0.877551, bias2: 0.23481738567352295, variance: 0.6427334547042847\n",
      "Train size: [400] hidden size: [3474] trial: 33, train_loss: 0.004918, test loss: 0.876593, bias2: 0.23457318544387817, variance: 0.6420196890830994\n",
      "Train size: [400] hidden size: [3474] trial: 34, train_loss: 0.004897, test loss: 0.876621, bias2: 0.23366832733154297, variance: 0.6429530382156372\n",
      "Train size: [400] hidden size: [3474] trial: 35, train_loss: 0.004911, test loss: 0.875440, bias2: 0.23128271102905273, variance: 0.6441576480865479\n",
      "Train size: [400] hidden size: [3474] trial: 36, train_loss: 0.004931, test loss: 0.876644, bias2: 0.2297900915145874, variance: 0.6468541026115417\n",
      "Train size: [400] hidden size: [3474] trial: 37, train_loss: 0.004937, test loss: 0.878230, bias2: 0.22974109649658203, variance: 0.648489236831665\n",
      "Train size: [400] hidden size: [3474] trial: 38, train_loss: 0.004936, test loss: 0.875839, bias2: 0.22704237699508667, variance: 0.6487964987754822\n",
      "Train size: [400] hidden size: [3474] trial: 39, train_loss: 0.004945, test loss: 0.876107, bias2: 0.22544658184051514, variance: 0.6506607532501221\n",
      "Train size: [400] hidden size: [3474] trial: 40, train_loss: 0.004937, test loss: 0.875325, bias2: 0.22469383478164673, variance: 0.6506315469741821\n",
      "Train size: [400] hidden size: [3474] trial: 41, train_loss: 0.004931, test loss: 0.875938, bias2: 0.2247576117515564, variance: 0.6511802673339844\n",
      "Train size: [400] hidden size: [3474] trial: 42, train_loss: 0.004912, test loss: 0.875058, bias2: 0.2251914143562317, variance: 0.6498661041259766\n",
      "Train size: [400] hidden size: [3474] trial: 43, train_loss: 0.004905, test loss: 0.874849, bias2: 0.22555893659591675, variance: 0.6492897868156433\n",
      "Train size: [400] hidden size: [3474] trial: 44, train_loss: 0.004907, test loss: 0.874083, bias2: 0.22345495223999023, variance: 0.6506279706954956\n",
      "Train size: [400] hidden size: [3474] trial: 45, train_loss: 0.004931, test loss: 0.875567, bias2: 0.2227420210838318, variance: 0.6528246402740479\n",
      "Train size: [400] hidden size: [3474] trial: 46, train_loss: 0.004945, test loss: 0.875359, bias2: 0.22148841619491577, variance: 0.6538704037666321\n",
      "Train size: [400] hidden size: [3474] trial: 47, train_loss: 0.004951, test loss: 0.874954, bias2: 0.22087067365646362, variance: 0.6540830135345459\n",
      "Train size: [400] hidden size: [3474] trial: 48, train_loss: 0.004956, test loss: 0.874622, bias2: 0.219559907913208, variance: 0.6550623178482056\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [3474] trial: 49, train_loss: 0.004986, test loss: 0.874790, bias2: 0.21947991847991943, variance: 0.6553099155426025\n",
      "##################################################\n",
      "Train size: [400] hidden size: [4000] trial: 0, train_loss: 0.005031, test loss: 0.966842, bias2: 0.9668416976928711, variance: -1.5570191802538602e-09\n",
      "Train size: [400] hidden size: [4000] trial: 1, train_loss: 0.005025, test loss: 0.923551, bias2: 0.5831531286239624, variance: 0.3403974175453186\n",
      "Train size: [400] hidden size: [4000] trial: 2, train_loss: 0.005044, test loss: 0.917553, bias2: 0.4775446653366089, variance: 0.44000816345214844\n",
      "Train size: [400] hidden size: [4000] trial: 3, train_loss: 0.005067, test loss: 0.891243, bias2: 0.3936423361301422, variance: 0.49760112166404724\n",
      "Train size: [400] hidden size: [4000] trial: 4, train_loss: 0.005098, test loss: 0.891589, bias2: 0.355252206325531, variance: 0.5363370180130005\n",
      "Train size: [400] hidden size: [4000] trial: 5, train_loss: 0.005027, test loss: 0.888402, bias2: 0.33513832092285156, variance: 0.553263247013092\n",
      "Train size: [400] hidden size: [4000] trial: 6, train_loss: 0.005105, test loss: 0.887792, bias2: 0.31262582540512085, variance: 0.5751664638519287\n",
      "Train size: [400] hidden size: [4000] trial: 7, train_loss: 0.005114, test loss: 0.888981, bias2: 0.2913600206375122, variance: 0.5976210832595825\n",
      "Train size: [400] hidden size: [4000] trial: 8, train_loss: 0.005140, test loss: 0.885747, bias2: 0.27732574939727783, variance: 0.6084209084510803\n",
      "Train size: [400] hidden size: [4000] trial: 9, train_loss: 0.005154, test loss: 0.877134, bias2: 0.2663377523422241, variance: 0.6107959151268005\n",
      "Train size: [400] hidden size: [4000] trial: 10, train_loss: 0.005096, test loss: 0.877623, bias2: 0.2561735510826111, variance: 0.6214497685432434\n",
      "Train size: [400] hidden size: [4000] trial: 11, train_loss: 0.005012, test loss: 0.879106, bias2: 0.24866396188735962, variance: 0.6304419636726379\n",
      "Train size: [400] hidden size: [4000] trial: 12, train_loss: 0.004977, test loss: 0.878505, bias2: 0.24771100282669067, variance: 0.6307944655418396\n",
      "Train size: [400] hidden size: [4000] trial: 13, train_loss: 0.004963, test loss: 0.872878, bias2: 0.24383670091629028, variance: 0.6290409564971924\n",
      "Train size: [400] hidden size: [4000] trial: 14, train_loss: 0.005027, test loss: 0.867576, bias2: 0.2366938591003418, variance: 0.6308820843696594\n",
      "Train size: [400] hidden size: [4000] trial: 15, train_loss: 0.005088, test loss: 0.867418, bias2: 0.2347699999809265, variance: 0.6326480507850647\n",
      "Train size: [400] hidden size: [4000] trial: 16, train_loss: 0.005068, test loss: 0.866771, bias2: 0.23212069272994995, variance: 0.634650707244873\n",
      "Train size: [400] hidden size: [4000] trial: 17, train_loss: 0.005032, test loss: 0.864089, bias2: 0.23102307319641113, variance: 0.6330656409263611\n",
      "Train size: [400] hidden size: [4000] trial: 18, train_loss: 0.005042, test loss: 0.861564, bias2: 0.23006850481033325, variance: 0.6314951181411743\n",
      "Train size: [400] hidden size: [4000] trial: 19, train_loss: 0.005066, test loss: 0.865161, bias2: 0.2320212721824646, variance: 0.6331398487091064\n",
      "Train size: [400] hidden size: [4000] trial: 20, train_loss: 0.005052, test loss: 0.864982, bias2: 0.23056137561798096, variance: 0.6344203352928162\n",
      "Train size: [400] hidden size: [4000] trial: 21, train_loss: 0.005009, test loss: 0.865440, bias2: 0.2302514910697937, variance: 0.6351886987686157\n",
      "Train size: [400] hidden size: [4000] trial: 22, train_loss: 0.005016, test loss: 0.869725, bias2: 0.2323547601699829, variance: 0.6373698711395264\n",
      "Train size: [400] hidden size: [4000] trial: 23, train_loss: 0.005008, test loss: 0.870140, bias2: 0.23350375890731812, variance: 0.6366358995437622\n",
      "Train size: [400] hidden size: [4000] trial: 24, train_loss: 0.004994, test loss: 0.870710, bias2: 0.23338627815246582, variance: 0.6373236775398254\n",
      "Train size: [400] hidden size: [4000] trial: 25, train_loss: 0.004986, test loss: 0.868982, bias2: 0.2326459288597107, variance: 0.6363365054130554\n",
      "Train size: [400] hidden size: [4000] trial: 26, train_loss: 0.004984, test loss: 0.867539, bias2: 0.22965437173843384, variance: 0.6378850340843201\n",
      "Train size: [400] hidden size: [4000] trial: 27, train_loss: 0.004977, test loss: 0.871907, bias2: 0.23037129640579224, variance: 0.6415358185768127\n",
      "Train size: [400] hidden size: [4000] trial: 28, train_loss: 0.004962, test loss: 0.871907, bias2: 0.2287876009941101, variance: 0.6431198120117188\n",
      "Train size: [400] hidden size: [4000] trial: 29, train_loss: 0.004950, test loss: 0.871035, bias2: 0.22796624898910522, variance: 0.6430686712265015\n",
      "Train size: [400] hidden size: [4000] trial: 30, train_loss: 0.004959, test loss: 0.869704, bias2: 0.2269517183303833, variance: 0.6427525877952576\n",
      "Train size: [400] hidden size: [4000] trial: 31, train_loss: 0.004946, test loss: 0.866619, bias2: 0.2238234281539917, variance: 0.6427954435348511\n",
      "Train size: [400] hidden size: [4000] trial: 32, train_loss: 0.004916, test loss: 0.865541, bias2: 0.2237415313720703, variance: 0.6417993307113647\n",
      "Train size: [400] hidden size: [4000] trial: 33, train_loss: 0.004925, test loss: 0.865266, bias2: 0.22286367416381836, variance: 0.642401933670044\n",
      "Train size: [400] hidden size: [4000] trial: 34, train_loss: 0.004935, test loss: 0.862336, bias2: 0.22114109992980957, variance: 0.6411947011947632\n",
      "Train size: [400] hidden size: [4000] trial: 35, train_loss: 0.004943, test loss: 0.862182, bias2: 0.22167277336120605, variance: 0.6405093669891357\n",
      "Train size: [400] hidden size: [4000] trial: 36, train_loss: 0.004940, test loss: 0.861546, bias2: 0.22084707021713257, variance: 0.6406991481781006\n",
      "Train size: [400] hidden size: [4000] trial: 37, train_loss: 0.004957, test loss: 0.860301, bias2: 0.21907228231430054, variance: 0.6412284970283508\n",
      "Train size: [400] hidden size: [4000] trial: 38, train_loss: 0.004962, test loss: 0.858329, bias2: 0.2184075117111206, variance: 0.6399214863777161\n",
      "Train size: [400] hidden size: [4000] trial: 39, train_loss: 0.004965, test loss: 0.861013, bias2: 0.21812671422958374, variance: 0.6428858041763306\n",
      "Train size: [400] hidden size: [4000] trial: 40, train_loss: 0.004957, test loss: 0.858557, bias2: 0.2161722183227539, variance: 0.6423848271369934\n",
      "Train size: [400] hidden size: [4000] trial: 41, train_loss: 0.004956, test loss: 0.858904, bias2: 0.214236319065094, variance: 0.6446674466133118\n",
      "Train size: [400] hidden size: [4000] trial: 42, train_loss: 0.004928, test loss: 0.858840, bias2: 0.2147931456565857, variance: 0.6440469622612\n",
      "Train size: [400] hidden size: [4000] trial: 43, train_loss: 0.004943, test loss: 0.857807, bias2: 0.2135714292526245, variance: 0.6442353129386902\n",
      "Train size: [400] hidden size: [4000] trial: 44, train_loss: 0.004922, test loss: 0.856663, bias2: 0.2138509750366211, variance: 0.6428115367889404\n",
      "Train size: [400] hidden size: [4000] trial: 45, train_loss: 0.004917, test loss: 0.858443, bias2: 0.21472853422164917, variance: 0.6437144875526428\n",
      "Train size: [400] hidden size: [4000] trial: 46, train_loss: 0.004914, test loss: 0.858054, bias2: 0.21397346258163452, variance: 0.6440804600715637\n",
      "Train size: [400] hidden size: [4000] trial: 47, train_loss: 0.004904, test loss: 0.857988, bias2: 0.21440404653549194, variance: 0.6435838937759399\n",
      "Train size: [400] hidden size: [4000] trial: 48, train_loss: 0.004890, test loss: 0.859148, bias2: 0.21483063697814941, variance: 0.6443169713020325\n",
      "Train size: [400] hidden size: [4000] trial: 49, train_loss: 0.004912, test loss: 0.858376, bias2: 0.2129126787185669, variance: 0.6454630494117737\n",
      "##################################################\n",
      "Train size: [400] hidden size: [4] trial: 0, train_loss: 1.799866, test loss: 0.998070, bias2: 0.998070478439331, variance: 2.2807899232452078e-12\n",
      "Train size: [400] hidden size: [4] trial: 1, train_loss: 1.845366, test loss: 0.999769, bias2: 0.9986575841903687, variance: 0.001111476100049913\n",
      "Train size: [400] hidden size: [4] trial: 2, train_loss: 1.910723, test loss: 0.998983, bias2: 0.9964739680290222, variance: 0.00250886264257133\n",
      "Train size: [400] hidden size: [4] trial: 3, train_loss: 1.933730, test loss: 1.001062, bias2: 0.9978761076927185, variance: 0.003185906447470188\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [4] trial: 4, train_loss: 1.965581, test loss: 1.000478, bias2: 0.9974180459976196, variance: 0.0030601928010582924\n",
      "Train size: [400] hidden size: [4] trial: 5, train_loss: 1.959105, test loss: 1.001617, bias2: 0.9976685643196106, variance: 0.003947905730456114\n",
      "Train size: [400] hidden size: [4] trial: 6, train_loss: 1.964111, test loss: 1.000375, bias2: 0.9959831833839417, variance: 0.004391636699438095\n",
      "Train size: [400] hidden size: [4] trial: 7, train_loss: 1.939375, test loss: 0.999976, bias2: 0.9958164095878601, variance: 0.004159722477197647\n",
      "Train size: [400] hidden size: [4] trial: 8, train_loss: 1.938464, test loss: 0.998894, bias2: 0.9947783350944519, variance: 0.004115825518965721\n",
      "Train size: [400] hidden size: [4] trial: 9, train_loss: 1.945351, test loss: 0.999031, bias2: 0.9946784973144531, variance: 0.004352707415819168\n",
      "Train size: [400] hidden size: [4] trial: 10, train_loss: 1.959610, test loss: 0.999134, bias2: 0.9941758513450623, variance: 0.004957970231771469\n",
      "Train size: [400] hidden size: [4] trial: 11, train_loss: 1.963066, test loss: 0.998570, bias2: 0.993256151676178, variance: 0.00531410239636898\n",
      "Train size: [400] hidden size: [4] trial: 12, train_loss: 1.969341, test loss: 0.998561, bias2: 0.9934460520744324, variance: 0.005115428473800421\n",
      "Train size: [400] hidden size: [4] trial: 13, train_loss: 1.964114, test loss: 0.998052, bias2: 0.9930530786514282, variance: 0.00499898474663496\n",
      "Train size: [400] hidden size: [4] trial: 14, train_loss: 1.954747, test loss: 0.998283, bias2: 0.9928274750709534, variance: 0.005455833859741688\n",
      "Train size: [400] hidden size: [4] trial: 15, train_loss: 1.938448, test loss: 0.998484, bias2: 0.9924905896186829, variance: 0.005993170663714409\n",
      "Train size: [400] hidden size: [4] trial: 16, train_loss: 1.934199, test loss: 0.998240, bias2: 0.9924660921096802, variance: 0.005773812532424927\n",
      "Train size: [400] hidden size: [4] trial: 17, train_loss: 1.927102, test loss: 0.998246, bias2: 0.9926300048828125, variance: 0.005616019479930401\n",
      "Train size: [400] hidden size: [4] trial: 18, train_loss: 1.931265, test loss: 0.998144, bias2: 0.9925961494445801, variance: 0.00554786529392004\n",
      "Train size: [400] hidden size: [4] trial: 19, train_loss: 1.938053, test loss: 0.998228, bias2: 0.9925670623779297, variance: 0.005661001894623041\n",
      "Train size: [400] hidden size: [4] trial: 20, train_loss: 1.939418, test loss: 0.998649, bias2: 0.9925655126571655, variance: 0.006083397660404444\n",
      "Train size: [400] hidden size: [4] trial: 21, train_loss: 1.942379, test loss: 0.998797, bias2: 0.9927007555961609, variance: 0.006095801945775747\n",
      "Train size: [400] hidden size: [4] trial: 22, train_loss: 1.953691, test loss: 0.998889, bias2: 0.9929471015930176, variance: 0.0059415847063064575\n",
      "Train size: [400] hidden size: [4] trial: 23, train_loss: 1.948326, test loss: 0.998592, bias2: 0.9926389455795288, variance: 0.005953353364020586\n",
      "Train size: [400] hidden size: [4] trial: 24, train_loss: 1.942390, test loss: 0.998457, bias2: 0.9926230907440186, variance: 0.005834245588630438\n",
      "Train size: [400] hidden size: [4] trial: 25, train_loss: 1.945351, test loss: 0.998649, bias2: 0.9929567575454712, variance: 0.005691851023584604\n",
      "Train size: [400] hidden size: [4] trial: 26, train_loss: 1.942441, test loss: 0.998498, bias2: 0.9929340481758118, variance: 0.00556402001529932\n",
      "Train size: [400] hidden size: [4] trial: 27, train_loss: 1.947280, test loss: 0.998392, bias2: 0.9924676418304443, variance: 0.0059240031987428665\n",
      "Train size: [400] hidden size: [4] trial: 28, train_loss: 1.942395, test loss: 0.998281, bias2: 0.9924609065055847, variance: 0.005819710902869701\n",
      "Train size: [400] hidden size: [4] trial: 29, train_loss: 1.942870, test loss: 0.998472, bias2: 0.9926590919494629, variance: 0.00581326661631465\n",
      "Train size: [400] hidden size: [4] trial: 30, train_loss: 1.942642, test loss: 0.998323, bias2: 0.9926304221153259, variance: 0.005692400969564915\n",
      "Train size: [400] hidden size: [4] trial: 31, train_loss: 1.940272, test loss: 0.997978, bias2: 0.9919095635414124, variance: 0.006068136543035507\n",
      "Train size: [400] hidden size: [4] trial: 32, train_loss: 1.941226, test loss: 0.998067, bias2: 0.9920936822891235, variance: 0.0059735835529863834\n",
      "Train size: [400] hidden size: [4] trial: 33, train_loss: 1.941236, test loss: 0.997952, bias2: 0.9920688271522522, variance: 0.00588335981592536\n",
      "Train size: [400] hidden size: [4] trial: 34, train_loss: 1.944496, test loss: 0.998080, bias2: 0.9920346736907959, variance: 0.006045588292181492\n",
      "Train size: [400] hidden size: [4] trial: 35, train_loss: 1.954211, test loss: 0.998255, bias2: 0.9921425580978394, variance: 0.006112909875810146\n",
      "Train size: [400] hidden size: [4] trial: 36, train_loss: 1.954825, test loss: 0.998308, bias2: 0.9921224117279053, variance: 0.00618522334843874\n",
      "Train size: [400] hidden size: [4] trial: 37, train_loss: 1.955206, test loss: 0.998339, bias2: 0.9921436905860901, variance: 0.006195619236677885\n",
      "Train size: [400] hidden size: [4] trial: 38, train_loss: 1.959901, test loss: 0.998312, bias2: 0.9922428727149963, variance: 0.006069287657737732\n",
      "Train size: [400] hidden size: [4] trial: 39, train_loss: 1.959713, test loss: 0.998529, bias2: 0.9920936822891235, variance: 0.00643481919541955\n",
      "Train size: [400] hidden size: [4] trial: 40, train_loss: 1.961660, test loss: 0.998621, bias2: 0.9922033548355103, variance: 0.006417172960937023\n",
      "Train size: [400] hidden size: [4] trial: 41, train_loss: 1.960166, test loss: 0.998613, bias2: 0.9923252463340759, variance: 0.006287349388003349\n",
      "Train size: [400] hidden size: [4] trial: 42, train_loss: 1.958393, test loss: 0.998557, bias2: 0.9922117590904236, variance: 0.006345745641738176\n",
      "Train size: [400] hidden size: [4] trial: 43, train_loss: 1.954592, test loss: 0.998526, bias2: 0.9922796487808228, variance: 0.0062464517541229725\n",
      "Train size: [400] hidden size: [4] trial: 44, train_loss: 1.952257, test loss: 0.998549, bias2: 0.9923173785209656, variance: 0.006231453735381365\n",
      "Train size: [400] hidden size: [4] trial: 45, train_loss: 1.953473, test loss: 0.998457, bias2: 0.9922326803207397, variance: 0.006224604323506355\n",
      "Train size: [400] hidden size: [4] trial: 46, train_loss: 1.956298, test loss: 0.998550, bias2: 0.9921399354934692, variance: 0.006409639026969671\n",
      "Train size: [400] hidden size: [4] trial: 47, train_loss: 1.956932, test loss: 0.998457, bias2: 0.9921320676803589, variance: 0.006324788089841604\n",
      "Train size: [400] hidden size: [4] trial: 48, train_loss: 1.953004, test loss: 0.998926, bias2: 0.9922945499420166, variance: 0.006631433963775635\n",
      "Train size: [400] hidden size: [4] trial: 49, train_loss: 1.955062, test loss: 0.998712, bias2: 0.9920438528060913, variance: 0.0066677299328148365\n",
      "##################################################\n",
      "Train size: [400] hidden size: [5] trial: 0, train_loss: 1.875656, test loss: 1.002560, bias2: 1.002560019493103, variance: -3.0410531731694945e-11\n",
      "Train size: [400] hidden size: [5] trial: 1, train_loss: 1.982129, test loss: 1.003506, bias2: 0.994987428188324, variance: 0.008518524467945099\n",
      "Train size: [400] hidden size: [5] trial: 2, train_loss: 1.945567, test loss: 1.000390, bias2: 0.9926515817642212, variance: 0.007738858461380005\n",
      "Train size: [400] hidden size: [5] trial: 3, train_loss: 1.961666, test loss: 0.998796, bias2: 0.9916183352470398, variance: 0.007177709136158228\n",
      "Train size: [400] hidden size: [5] trial: 4, train_loss: 1.954433, test loss: 0.998676, bias2: 0.9922209978103638, variance: 0.006455246824771166\n",
      "Train size: [400] hidden size: [5] trial: 5, train_loss: 1.941568, test loss: 0.998366, bias2: 0.99235999584198, variance: 0.006006008479744196\n",
      "Train size: [400] hidden size: [5] trial: 6, train_loss: 1.946427, test loss: 0.998273, bias2: 0.9924013614654541, variance: 0.005871874745935202\n",
      "Train size: [400] hidden size: [5] trial: 7, train_loss: 1.969879, test loss: 0.998531, bias2: 0.9924836754798889, variance: 0.006047319155186415\n",
      "Train size: [400] hidden size: [5] trial: 8, train_loss: 1.941981, test loss: 0.997818, bias2: 0.9919686317443848, variance: 0.005849012173712254\n",
      "Train size: [400] hidden size: [5] trial: 9, train_loss: 1.950402, test loss: 0.997848, bias2: 0.9922505021095276, variance: 0.005597286392003298\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [5] trial: 10, train_loss: 1.951771, test loss: 0.997346, bias2: 0.9912858605384827, variance: 0.006060111336410046\n",
      "Train size: [400] hidden size: [5] trial: 11, train_loss: 1.945246, test loss: 0.997064, bias2: 0.9911664724349976, variance: 0.00589709123596549\n",
      "Train size: [400] hidden size: [5] trial: 12, train_loss: 1.943563, test loss: 0.998154, bias2: 0.991040825843811, variance: 0.0071132308803498745\n",
      "Train size: [400] hidden size: [5] trial: 13, train_loss: 1.951699, test loss: 0.998216, bias2: 0.9909942150115967, variance: 0.007221884094178677\n",
      "Train size: [400] hidden size: [5] trial: 14, train_loss: 1.960487, test loss: 0.998505, bias2: 0.9900653958320618, variance: 0.00843933317810297\n",
      "Train size: [400] hidden size: [5] trial: 15, train_loss: 1.955845, test loss: 0.998905, bias2: 0.9906880259513855, variance: 0.008216677233576775\n",
      "Train size: [400] hidden size: [5] trial: 16, train_loss: 1.955150, test loss: 0.998722, bias2: 0.9908726215362549, variance: 0.007849276065826416\n",
      "Train size: [400] hidden size: [5] trial: 17, train_loss: 1.968312, test loss: 0.998575, bias2: 0.9910946488380432, variance: 0.007480515167117119\n",
      "Train size: [400] hidden size: [5] trial: 18, train_loss: 1.969392, test loss: 0.998430, bias2: 0.9912420511245728, variance: 0.007188391871750355\n",
      "Train size: [400] hidden size: [5] trial: 19, train_loss: 1.962387, test loss: 0.998284, bias2: 0.991348385810852, variance: 0.006935579236596823\n",
      "Train size: [400] hidden size: [5] trial: 20, train_loss: 1.954254, test loss: 0.998323, bias2: 0.9913191795349121, variance: 0.007004143670201302\n",
      "Train size: [400] hidden size: [5] trial: 21, train_loss: 1.968172, test loss: 0.998265, bias2: 0.9912160634994507, variance: 0.007048774044960737\n",
      "Train size: [400] hidden size: [5] trial: 22, train_loss: 1.972372, test loss: 0.998404, bias2: 0.9915391802787781, variance: 0.006864596623927355\n",
      "Train size: [400] hidden size: [5] trial: 23, train_loss: 1.973074, test loss: 0.998463, bias2: 0.9917688369750977, variance: 0.006694642826914787\n",
      "Train size: [400] hidden size: [5] trial: 24, train_loss: 1.968144, test loss: 0.999162, bias2: 0.9922823309898376, variance: 0.006879209075123072\n",
      "Train size: [400] hidden size: [5] trial: 25, train_loss: 1.966624, test loss: 0.999538, bias2: 0.9925830960273743, variance: 0.006955189164727926\n",
      "Train size: [400] hidden size: [5] trial: 26, train_loss: 1.969957, test loss: 0.999238, bias2: 0.9923646450042725, variance: 0.00687298784032464\n",
      "Train size: [400] hidden size: [5] trial: 27, train_loss: 1.975068, test loss: 0.999064, bias2: 0.9921820163726807, variance: 0.006882105953991413\n",
      "Train size: [400] hidden size: [5] trial: 28, train_loss: 1.968349, test loss: 0.999176, bias2: 0.9920509457588196, variance: 0.0071251122280955315\n",
      "Train size: [400] hidden size: [5] trial: 29, train_loss: 1.967870, test loss: 0.999152, bias2: 0.9922396540641785, variance: 0.006912097334861755\n",
      "Train size: [400] hidden size: [5] trial: 30, train_loss: 1.966493, test loss: 0.999363, bias2: 0.9923819303512573, variance: 0.006981158163398504\n",
      "Train size: [400] hidden size: [5] trial: 31, train_loss: 1.978405, test loss: 0.999288, bias2: 0.9924803376197815, variance: 0.006807359866797924\n",
      "Train size: [400] hidden size: [5] trial: 32, train_loss: 1.981709, test loss: 0.999233, bias2: 0.99253249168396, variance: 0.006700987461954355\n",
      "Train size: [400] hidden size: [5] trial: 33, train_loss: 1.978362, test loss: 0.999355, bias2: 0.9927027225494385, variance: 0.006652071140706539\n",
      "Train size: [400] hidden size: [5] trial: 34, train_loss: 1.975422, test loss: 0.999246, bias2: 0.9926447868347168, variance: 0.006601104978471994\n",
      "Train size: [400] hidden size: [5] trial: 35, train_loss: 1.977288, test loss: 0.999180, bias2: 0.9927208423614502, variance: 0.0064592319540679455\n",
      "Train size: [400] hidden size: [5] trial: 36, train_loss: 1.978221, test loss: 0.999172, bias2: 0.9928632378578186, variance: 0.006308617535978556\n",
      "Train size: [400] hidden size: [5] trial: 37, train_loss: 1.979427, test loss: 0.998969, bias2: 0.9927076101303101, variance: 0.006261087488383055\n",
      "Train size: [400] hidden size: [5] trial: 38, train_loss: 1.984502, test loss: 0.998135, bias2: 0.9915537238121033, variance: 0.006581708788871765\n",
      "Train size: [400] hidden size: [5] trial: 39, train_loss: 1.987488, test loss: 0.998183, bias2: 0.9916262626647949, variance: 0.006556341890245676\n",
      "Train size: [400] hidden size: [5] trial: 40, train_loss: 1.988561, test loss: 0.998237, bias2: 0.9914385676383972, variance: 0.006798212416470051\n",
      "Train size: [400] hidden size: [5] trial: 41, train_loss: 1.989036, test loss: 0.998214, bias2: 0.9915407299995422, variance: 0.0066735586151480675\n",
      "Train size: [400] hidden size: [5] trial: 42, train_loss: 1.991939, test loss: 0.998300, bias2: 0.9916259050369263, variance: 0.006673692259937525\n",
      "Train size: [400] hidden size: [5] trial: 43, train_loss: 1.992744, test loss: 0.998269, bias2: 0.9915465116500854, variance: 0.0067222933284938335\n",
      "Train size: [400] hidden size: [5] trial: 44, train_loss: 1.986944, test loss: 0.998334, bias2: 0.9916491508483887, variance: 0.006684537976980209\n",
      "Train size: [400] hidden size: [5] trial: 45, train_loss: 1.986609, test loss: 0.998443, bias2: 0.9917079210281372, variance: 0.006735175848007202\n",
      "Train size: [400] hidden size: [5] trial: 46, train_loss: 1.985602, test loss: 0.998524, bias2: 0.9918016195297241, variance: 0.006722150836139917\n",
      "Train size: [400] hidden size: [5] trial: 47, train_loss: 1.983707, test loss: 0.998423, bias2: 0.9917221069335938, variance: 0.006701103877276182\n",
      "Train size: [400] hidden size: [5] trial: 48, train_loss: 1.984695, test loss: 0.998400, bias2: 0.99177086353302, variance: 0.006628680508583784\n",
      "Train size: [400] hidden size: [5] trial: 49, train_loss: 1.983969, test loss: 0.998437, bias2: 0.9918462038040161, variance: 0.006591280456632376\n",
      "##################################################\n",
      "Train size: [400] hidden size: [6] trial: 0, train_loss: 1.956382, test loss: 0.983763, bias2: 0.9837626218795776, variance: -6.0821061728666415e-12\n",
      "Train size: [400] hidden size: [6] trial: 1, train_loss: 1.929006, test loss: 0.991487, bias2: 0.9878738522529602, variance: 0.0036135446280241013\n",
      "Train size: [400] hidden size: [6] trial: 2, train_loss: 1.910702, test loss: 0.990862, bias2: 0.9842190742492676, variance: 0.006642855238169432\n",
      "Train size: [400] hidden size: [6] trial: 3, train_loss: 1.898035, test loss: 0.991341, bias2: 0.9806562662124634, variance: 0.010684843175113201\n",
      "Train size: [400] hidden size: [6] trial: 4, train_loss: 1.952273, test loss: 0.992265, bias2: 0.9826298356056213, variance: 0.0096348961815238\n",
      "Train size: [400] hidden size: [6] trial: 5, train_loss: 1.974739, test loss: 0.992392, bias2: 0.9828711748123169, variance: 0.009521065279841423\n",
      "Train size: [400] hidden size: [6] trial: 6, train_loss: 1.979210, test loss: 0.995331, bias2: 0.9842474460601807, variance: 0.011083520948886871\n",
      "Train size: [400] hidden size: [6] trial: 7, train_loss: 1.972905, test loss: 0.995561, bias2: 0.984995424747467, variance: 0.010565909557044506\n",
      "Train size: [400] hidden size: [6] trial: 8, train_loss: 1.993847, test loss: 0.995843, bias2: 0.9859424233436584, variance: 0.009900114499032497\n",
      "Train size: [400] hidden size: [6] trial: 9, train_loss: 1.988579, test loss: 0.996015, bias2: 0.9865841865539551, variance: 0.009430376812815666\n",
      "Train size: [400] hidden size: [6] trial: 10, train_loss: 1.996190, test loss: 0.996104, bias2: 0.9872266054153442, variance: 0.00887750182300806\n",
      "Train size: [400] hidden size: [6] trial: 11, train_loss: 2.009669, test loss: 0.996230, bias2: 0.9874976873397827, variance: 0.00873229093849659\n",
      "Train size: [400] hidden size: [6] trial: 12, train_loss: 2.013560, test loss: 0.996233, bias2: 0.9879065155982971, variance: 0.008326112292706966\n",
      "Train size: [400] hidden size: [6] trial: 13, train_loss: 2.003118, test loss: 0.996289, bias2: 0.9880407452583313, variance: 0.00824821274727583\n",
      "Train size: [400] hidden size: [6] trial: 14, train_loss: 2.004378, test loss: 0.996070, bias2: 0.9878028631210327, variance: 0.008267276920378208\n",
      "Train size: [400] hidden size: [6] trial: 15, train_loss: 2.014604, test loss: 0.996603, bias2: 0.9883198738098145, variance: 0.00828354898840189\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [6] trial: 16, train_loss: 2.009930, test loss: 0.996863, bias2: 0.9887171983718872, variance: 0.008145906962454319\n",
      "Train size: [400] hidden size: [6] trial: 17, train_loss: 2.005511, test loss: 0.996612, bias2: 0.9884023666381836, variance: 0.008209716528654099\n",
      "Train size: [400] hidden size: [6] trial: 18, train_loss: 2.005406, test loss: 0.996144, bias2: 0.987831175327301, variance: 0.008312665857374668\n",
      "Train size: [400] hidden size: [6] trial: 19, train_loss: 1.993085, test loss: 0.995903, bias2: 0.9874467253684998, variance: 0.008455855771899223\n",
      "Train size: [400] hidden size: [6] trial: 20, train_loss: 1.992244, test loss: 0.995806, bias2: 0.9874085187911987, variance: 0.008397439494729042\n",
      "Train size: [400] hidden size: [6] trial: 21, train_loss: 1.994410, test loss: 0.995214, bias2: 0.9865323305130005, variance: 0.008681228384375572\n",
      "Train size: [400] hidden size: [6] trial: 22, train_loss: 1.992080, test loss: 0.996424, bias2: 0.9871348738670349, variance: 0.009288829751312733\n",
      "Train size: [400] hidden size: [6] trial: 23, train_loss: 1.982753, test loss: 0.996261, bias2: 0.9868248701095581, variance: 0.009435959160327911\n",
      "Train size: [400] hidden size: [6] trial: 24, train_loss: 1.973331, test loss: 0.995978, bias2: 0.9865093231201172, variance: 0.009469141252338886\n",
      "Train size: [400] hidden size: [6] trial: 25, train_loss: 1.973222, test loss: 0.996289, bias2: 0.9867912530899048, variance: 0.009497576393187046\n",
      "Train size: [400] hidden size: [6] trial: 26, train_loss: 1.969254, test loss: 0.996426, bias2: 0.9868015050888062, variance: 0.009624570608139038\n",
      "Train size: [400] hidden size: [6] trial: 27, train_loss: 1.973054, test loss: 0.996665, bias2: 0.987070620059967, variance: 0.009594087488949299\n",
      "Train size: [400] hidden size: [6] trial: 28, train_loss: 1.966654, test loss: 0.997117, bias2: 0.9875600934028625, variance: 0.009556565433740616\n",
      "Train size: [400] hidden size: [6] trial: 29, train_loss: 1.964325, test loss: 0.997336, bias2: 0.9875276684761047, variance: 0.009808303788304329\n",
      "Train size: [400] hidden size: [6] trial: 30, train_loss: 1.963161, test loss: 0.997697, bias2: 0.9879838228225708, variance: 0.009713363833725452\n",
      "Train size: [400] hidden size: [6] trial: 31, train_loss: 1.960101, test loss: 0.997865, bias2: 0.988000214099884, variance: 0.00986500084400177\n",
      "Train size: [400] hidden size: [6] trial: 32, train_loss: 1.956632, test loss: 0.997792, bias2: 0.9879478812217712, variance: 0.009844533167779446\n",
      "Train size: [400] hidden size: [6] trial: 33, train_loss: 1.955831, test loss: 0.998211, bias2: 0.9882722496986389, variance: 0.009938472881913185\n",
      "Train size: [400] hidden size: [6] trial: 34, train_loss: 1.952723, test loss: 0.998041, bias2: 0.9879129528999329, variance: 0.010128026828169823\n",
      "Train size: [400] hidden size: [6] trial: 35, train_loss: 1.952067, test loss: 0.998087, bias2: 0.9880101680755615, variance: 0.010077291168272495\n",
      "Train size: [400] hidden size: [6] trial: 36, train_loss: 1.955506, test loss: 0.998018, bias2: 0.9878116250038147, variance: 0.010206338949501514\n",
      "Train size: [400] hidden size: [6] trial: 37, train_loss: 1.951310, test loss: 0.998146, bias2: 0.9873352646827698, variance: 0.01081060990691185\n",
      "Train size: [400] hidden size: [6] trial: 38, train_loss: 1.952061, test loss: 0.998204, bias2: 0.9875962138175964, variance: 0.010607683099806309\n",
      "Train size: [400] hidden size: [6] trial: 39, train_loss: 1.957637, test loss: 0.998585, bias2: 0.9874609112739563, variance: 0.011124413460493088\n",
      "Train size: [400] hidden size: [6] trial: 40, train_loss: 1.957265, test loss: 0.998315, bias2: 0.9872653484344482, variance: 0.01104953233152628\n",
      "Train size: [400] hidden size: [6] trial: 41, train_loss: 1.964141, test loss: 0.998500, bias2: 0.9870479702949524, variance: 0.011451789177954197\n",
      "Train size: [400] hidden size: [6] trial: 42, train_loss: 1.963163, test loss: 0.998251, bias2: 0.9868935942649841, variance: 0.01135743223130703\n",
      "Train size: [400] hidden size: [6] trial: 43, train_loss: 1.963154, test loss: 0.997950, bias2: 0.9866200685501099, variance: 0.011329680681228638\n",
      "Train size: [400] hidden size: [6] trial: 44, train_loss: 1.960854, test loss: 0.998184, bias2: 0.9868378043174744, variance: 0.011345824226737022\n",
      "Train size: [400] hidden size: [6] trial: 45, train_loss: 1.959060, test loss: 0.998059, bias2: 0.9867815375328064, variance: 0.01127701997756958\n",
      "Train size: [400] hidden size: [6] trial: 46, train_loss: 1.963071, test loss: 0.998282, bias2: 0.9870630502700806, variance: 0.011218723841011524\n",
      "Train size: [400] hidden size: [6] trial: 47, train_loss: 1.961897, test loss: 0.998261, bias2: 0.9868664145469666, variance: 0.011394611559808254\n",
      "Train size: [400] hidden size: [6] trial: 48, train_loss: 1.958128, test loss: 0.998194, bias2: 0.9868760108947754, variance: 0.011317714117467403\n",
      "Train size: [400] hidden size: [6] trial: 49, train_loss: 1.961424, test loss: 0.998361, bias2: 0.9870297908782959, variance: 0.01133082527667284\n",
      "##################################################\n",
      "Train size: [400] hidden size: [7] trial: 0, train_loss: 1.995713, test loss: 0.998124, bias2: 0.9981235265731812, variance: -2.1287372906075852e-11\n",
      "Train size: [400] hidden size: [7] trial: 1, train_loss: 2.060929, test loss: 1.001174, bias2: 0.9969943165779114, variance: 0.0041799056343734264\n",
      "Train size: [400] hidden size: [7] trial: 2, train_loss: 2.007907, test loss: 1.000992, bias2: 0.9963489174842834, variance: 0.004643523599952459\n",
      "Train size: [400] hidden size: [7] trial: 3, train_loss: 2.003718, test loss: 1.002157, bias2: 0.9967869520187378, variance: 0.0053697689436376095\n",
      "Train size: [400] hidden size: [7] trial: 4, train_loss: 2.018193, test loss: 0.997670, bias2: 0.9872149229049683, variance: 0.010454823262989521\n",
      "Train size: [400] hidden size: [7] trial: 5, train_loss: 2.036793, test loss: 0.999278, bias2: 0.9888471961021423, variance: 0.010431158356368542\n",
      "Train size: [400] hidden size: [7] trial: 6, train_loss: 2.020615, test loss: 1.000183, bias2: 0.9894030094146729, variance: 0.010779731906950474\n",
      "Train size: [400] hidden size: [7] trial: 7, train_loss: 2.005632, test loss: 0.997525, bias2: 0.9847896099090576, variance: 0.012735108844935894\n",
      "Train size: [400] hidden size: [7] trial: 8, train_loss: 1.983797, test loss: 0.997045, bias2: 0.9847546815872192, variance: 0.012290626764297485\n",
      "Train size: [400] hidden size: [7] trial: 9, train_loss: 1.991254, test loss: 0.999199, bias2: 0.985802412033081, variance: 0.01339702308177948\n",
      "Train size: [400] hidden size: [7] trial: 10, train_loss: 1.966294, test loss: 0.998807, bias2: 0.9861977696418762, variance: 0.012609243392944336\n",
      "Train size: [400] hidden size: [7] trial: 11, train_loss: 1.943849, test loss: 0.998611, bias2: 0.9865063428878784, variance: 0.012104202061891556\n",
      "Train size: [400] hidden size: [7] trial: 12, train_loss: 1.944071, test loss: 0.997876, bias2: 0.9852185249328613, variance: 0.012657413259148598\n",
      "Train size: [400] hidden size: [7] trial: 13, train_loss: 1.947176, test loss: 1.000443, bias2: 0.9874855875968933, variance: 0.012957029044628143\n",
      "Train size: [400] hidden size: [7] trial: 14, train_loss: 1.945320, test loss: 1.000271, bias2: 0.9874281883239746, variance: 0.012843221426010132\n",
      "Train size: [400] hidden size: [7] trial: 15, train_loss: 1.944900, test loss: 0.999906, bias2: 0.9873324036598206, variance: 0.012573675252497196\n",
      "Train size: [400] hidden size: [7] trial: 16, train_loss: 1.954581, test loss: 0.999057, bias2: 0.9867703914642334, variance: 0.012286246754229069\n",
      "Train size: [400] hidden size: [7] trial: 17, train_loss: 1.953741, test loss: 0.998757, bias2: 0.9868569374084473, variance: 0.011900289915502071\n",
      "Train size: [400] hidden size: [7] trial: 18, train_loss: 1.960000, test loss: 0.998383, bias2: 0.9866527915000916, variance: 0.01173002365976572\n",
      "Train size: [400] hidden size: [7] trial: 19, train_loss: 1.964076, test loss: 0.998072, bias2: 0.9867728352546692, variance: 0.011298730038106441\n",
      "Train size: [400] hidden size: [7] trial: 20, train_loss: 1.963832, test loss: 0.997632, bias2: 0.9862917065620422, variance: 0.011340245604515076\n",
      "Train size: [400] hidden size: [7] trial: 21, train_loss: 1.968113, test loss: 0.997811, bias2: 0.9867819547653198, variance: 0.011029515415430069\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [7] trial: 22, train_loss: 1.970956, test loss: 0.997769, bias2: 0.9864851832389832, variance: 0.011284095235168934\n",
      "Train size: [400] hidden size: [7] trial: 23, train_loss: 1.971053, test loss: 0.997475, bias2: 0.9860110282897949, variance: 0.011464334093034267\n",
      "Train size: [400] hidden size: [7] trial: 24, train_loss: 1.971449, test loss: 0.998101, bias2: 0.9866054654121399, variance: 0.011495726183056831\n",
      "Train size: [400] hidden size: [7] trial: 25, train_loss: 1.965810, test loss: 0.998326, bias2: 0.9868799448013306, variance: 0.011446249671280384\n",
      "Train size: [400] hidden size: [7] trial: 26, train_loss: 1.964559, test loss: 0.998284, bias2: 0.9870879650115967, variance: 0.011195727623999119\n",
      "Train size: [400] hidden size: [7] trial: 27, train_loss: 1.964496, test loss: 0.998532, bias2: 0.9873669743537903, variance: 0.011165349744260311\n",
      "Train size: [400] hidden size: [7] trial: 28, train_loss: 1.966683, test loss: 0.998258, bias2: 0.9872006177902222, variance: 0.01105731725692749\n",
      "Train size: [400] hidden size: [7] trial: 29, train_loss: 1.970368, test loss: 0.997203, bias2: 0.9854908585548401, variance: 0.01171213760972023\n",
      "Train size: [400] hidden size: [7] trial: 30, train_loss: 1.963073, test loss: 0.997333, bias2: 0.9859536290168762, variance: 0.011379692703485489\n",
      "Train size: [400] hidden size: [7] trial: 31, train_loss: 1.962407, test loss: 0.997521, bias2: 0.9863205552101135, variance: 0.011199951171875\n",
      "Train size: [400] hidden size: [7] trial: 32, train_loss: 1.960447, test loss: 0.997790, bias2: 0.9867647290229797, variance: 0.011025283485651016\n",
      "Train size: [400] hidden size: [7] trial: 33, train_loss: 1.956020, test loss: 0.998451, bias2: 0.9869962930679321, variance: 0.01145473774522543\n",
      "Train size: [400] hidden size: [7] trial: 34, train_loss: 1.955234, test loss: 0.998255, bias2: 0.9870045781135559, variance: 0.011250936426222324\n",
      "Train size: [400] hidden size: [7] trial: 35, train_loss: 1.952492, test loss: 0.998490, bias2: 0.9873679876327515, variance: 0.011121932417154312\n",
      "Train size: [400] hidden size: [7] trial: 36, train_loss: 1.954684, test loss: 0.998378, bias2: 0.9871953725814819, variance: 0.011182256042957306\n",
      "Train size: [400] hidden size: [7] trial: 37, train_loss: 1.947298, test loss: 0.998609, bias2: 0.9872719645500183, variance: 0.01133689470589161\n",
      "Train size: [400] hidden size: [7] trial: 38, train_loss: 1.950259, test loss: 0.998697, bias2: 0.9874495267868042, variance: 0.011247552931308746\n",
      "Train size: [400] hidden size: [7] trial: 39, train_loss: 1.946986, test loss: 0.998958, bias2: 0.9873607754707336, variance: 0.011597562581300735\n",
      "Train size: [400] hidden size: [7] trial: 40, train_loss: 1.944336, test loss: 0.999045, bias2: 0.9875860810279846, variance: 0.011459264904260635\n",
      "Train size: [400] hidden size: [7] trial: 41, train_loss: 1.945532, test loss: 0.999007, bias2: 0.9876481294631958, variance: 0.011358598247170448\n",
      "Train size: [400] hidden size: [7] trial: 42, train_loss: 1.944257, test loss: 0.998820, bias2: 0.9874160289764404, variance: 0.011404450982809067\n",
      "Train size: [400] hidden size: [7] trial: 43, train_loss: 1.944803, test loss: 0.998903, bias2: 0.9875190258026123, variance: 0.01138359121978283\n",
      "Train size: [400] hidden size: [7] trial: 44, train_loss: 1.944761, test loss: 0.998592, bias2: 0.9873427152633667, variance: 0.011249025352299213\n",
      "Train size: [400] hidden size: [7] trial: 45, train_loss: 1.945684, test loss: 0.998688, bias2: 0.9873411059379578, variance: 0.011346576735377312\n",
      "Train size: [400] hidden size: [7] trial: 46, train_loss: 1.938554, test loss: 0.998657, bias2: 0.9872618913650513, variance: 0.011395084671676159\n",
      "Train size: [400] hidden size: [7] trial: 47, train_loss: 1.940655, test loss: 0.998684, bias2: 0.9871755242347717, variance: 0.01150883175432682\n",
      "Train size: [400] hidden size: [7] trial: 48, train_loss: 1.940699, test loss: 0.999115, bias2: 0.9874206781387329, variance: 0.011694789864122868\n",
      "Train size: [400] hidden size: [7] trial: 49, train_loss: 1.940856, test loss: 0.999111, bias2: 0.9875832200050354, variance: 0.011527515947818756\n",
      "##################################################\n",
      "Train size: [400] hidden size: [8] trial: 0, train_loss: 1.990690, test loss: 1.001095, bias2: 1.0010952949523926, variance: -1.0947791284632302e-10\n",
      "Train size: [400] hidden size: [8] trial: 1, train_loss: 1.892991, test loss: 1.000954, bias2: 0.990561306476593, variance: 0.010392967611551285\n",
      "Train size: [400] hidden size: [8] trial: 2, train_loss: 1.983203, test loss: 1.001440, bias2: 0.9905043244361877, variance: 0.010935976170003414\n",
      "Train size: [400] hidden size: [8] trial: 3, train_loss: 1.921303, test loss: 0.995239, bias2: 0.9826076030731201, variance: 0.012631130404770374\n",
      "Train size: [400] hidden size: [8] trial: 4, train_loss: 1.940518, test loss: 0.996357, bias2: 0.9846851825714111, variance: 0.011672113090753555\n",
      "Train size: [400] hidden size: [8] trial: 5, train_loss: 1.937299, test loss: 0.996674, bias2: 0.9858483672142029, variance: 0.010825609788298607\n",
      "Train size: [400] hidden size: [8] trial: 6, train_loss: 1.928541, test loss: 0.998354, bias2: 0.9874523282051086, variance: 0.010901791043579578\n",
      "Train size: [400] hidden size: [8] trial: 7, train_loss: 1.942971, test loss: 0.998494, bias2: 0.9877150058746338, variance: 0.010778669267892838\n",
      "Train size: [400] hidden size: [8] trial: 8, train_loss: 1.954724, test loss: 1.000525, bias2: 0.9885537624359131, variance: 0.011971686035394669\n",
      "Train size: [400] hidden size: [8] trial: 9, train_loss: 1.971848, test loss: 0.999786, bias2: 0.9871206283569336, variance: 0.01266580168157816\n",
      "Train size: [400] hidden size: [8] trial: 10, train_loss: 1.991803, test loss: 1.000750, bias2: 0.9887431859970093, variance: 0.012006664648652077\n",
      "Train size: [400] hidden size: [8] trial: 11, train_loss: 1.983720, test loss: 1.000047, bias2: 0.9881395101547241, variance: 0.011907336302101612\n",
      "Train size: [400] hidden size: [8] trial: 12, train_loss: 1.991411, test loss: 0.999924, bias2: 0.9886977672576904, variance: 0.011226601898670197\n",
      "Train size: [400] hidden size: [8] trial: 13, train_loss: 1.991915, test loss: 1.000684, bias2: 0.9886712431907654, variance: 0.012013128958642483\n",
      "Train size: [400] hidden size: [8] trial: 14, train_loss: 1.983146, test loss: 1.001254, bias2: 0.9869524240493774, variance: 0.01430166233330965\n",
      "Train size: [400] hidden size: [8] trial: 15, train_loss: 1.964567, test loss: 1.000609, bias2: 0.9865460395812988, variance: 0.014063344337046146\n",
      "Train size: [400] hidden size: [8] trial: 16, train_loss: 1.960177, test loss: 1.000757, bias2: 0.9865360856056213, variance: 0.014221252873539925\n",
      "Train size: [400] hidden size: [8] trial: 17, train_loss: 1.950872, test loss: 0.999584, bias2: 0.9857683181762695, variance: 0.013815490528941154\n",
      "Train size: [400] hidden size: [8] trial: 18, train_loss: 1.954325, test loss: 0.998354, bias2: 0.9844983816146851, variance: 0.01385573111474514\n",
      "Train size: [400] hidden size: [8] trial: 19, train_loss: 1.947393, test loss: 0.999720, bias2: 0.9850757122039795, variance: 0.014644289389252663\n",
      "Train size: [400] hidden size: [8] trial: 20, train_loss: 1.948462, test loss: 0.999554, bias2: 0.9840935468673706, variance: 0.01546054519712925\n",
      "Train size: [400] hidden size: [8] trial: 21, train_loss: 1.964743, test loss: 0.999052, bias2: 0.9838689565658569, variance: 0.015182577073574066\n",
      "Train size: [400] hidden size: [8] trial: 22, train_loss: 1.963107, test loss: 0.999628, bias2: 0.9837290048599243, variance: 0.01589941419661045\n",
      "Train size: [400] hidden size: [8] trial: 23, train_loss: 1.963226, test loss: 0.999803, bias2: 0.9840074181556702, variance: 0.01579599641263485\n",
      "Train size: [400] hidden size: [8] trial: 24, train_loss: 1.963367, test loss: 0.999457, bias2: 0.9840033650398254, variance: 0.015453684143722057\n",
      "Train size: [400] hidden size: [8] trial: 25, train_loss: 1.953124, test loss: 0.999293, bias2: 0.9841729402542114, variance: 0.015120508149266243\n",
      "Train size: [400] hidden size: [8] trial: 26, train_loss: 1.953209, test loss: 0.999060, bias2: 0.9837289452552795, variance: 0.01533092837780714\n",
      "Train size: [400] hidden size: [8] trial: 27, train_loss: 1.951999, test loss: 0.999411, bias2: 0.9839233756065369, variance: 0.015487561002373695\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [8] trial: 28, train_loss: 1.962245, test loss: 0.999431, bias2: 0.984157919883728, variance: 0.015273437835276127\n",
      "Train size: [400] hidden size: [8] trial: 29, train_loss: 1.961620, test loss: 0.999176, bias2: 0.9841224551200867, variance: 0.015053864568471909\n",
      "Train size: [400] hidden size: [8] trial: 30, train_loss: 1.957279, test loss: 0.999940, bias2: 0.9842463135719299, variance: 0.015694061294198036\n",
      "Train size: [400] hidden size: [8] trial: 31, train_loss: 1.961740, test loss: 0.999631, bias2: 0.9841222167015076, variance: 0.015508865937590599\n",
      "Train size: [400] hidden size: [8] trial: 32, train_loss: 1.956954, test loss: 0.999513, bias2: 0.984299898147583, variance: 0.015213511884212494\n",
      "Train size: [400] hidden size: [8] trial: 33, train_loss: 1.955460, test loss: 0.999390, bias2: 0.9845046401023865, variance: 0.014885004609823227\n",
      "Train size: [400] hidden size: [8] trial: 34, train_loss: 1.960865, test loss: 0.999525, bias2: 0.9848487377166748, variance: 0.014675813727080822\n",
      "Train size: [400] hidden size: [8] trial: 35, train_loss: 1.960704, test loss: 0.999604, bias2: 0.984822154045105, variance: 0.014781932346522808\n",
      "Train size: [400] hidden size: [8] trial: 36, train_loss: 1.961260, test loss: 0.999758, bias2: 0.9851860404014587, variance: 0.01457227673381567\n",
      "Train size: [400] hidden size: [8] trial: 37, train_loss: 1.956909, test loss: 0.999849, bias2: 0.9853332042694092, variance: 0.014515417627990246\n",
      "Train size: [400] hidden size: [8] trial: 38, train_loss: 1.958078, test loss: 0.999827, bias2: 0.9854233264923096, variance: 0.014403211884200573\n",
      "Train size: [400] hidden size: [8] trial: 39, train_loss: 1.960702, test loss: 1.000188, bias2: 0.9847649931907654, variance: 0.015422877855598927\n",
      "Train size: [400] hidden size: [8] trial: 40, train_loss: 1.957900, test loss: 1.000661, bias2: 0.9853548407554626, variance: 0.015306321904063225\n",
      "Train size: [400] hidden size: [8] trial: 41, train_loss: 1.964750, test loss: 1.000681, bias2: 0.9855426549911499, variance: 0.015138611197471619\n",
      "Train size: [400] hidden size: [8] trial: 42, train_loss: 1.967813, test loss: 1.000681, bias2: 0.985741376876831, variance: 0.014939895831048489\n",
      "Train size: [400] hidden size: [8] trial: 43, train_loss: 1.972178, test loss: 1.000970, bias2: 0.9858721494674683, variance: 0.0150979682803154\n",
      "Train size: [400] hidden size: [8] trial: 44, train_loss: 1.969119, test loss: 1.000955, bias2: 0.9857934713363647, variance: 0.015161661431193352\n",
      "Train size: [400] hidden size: [8] trial: 45, train_loss: 1.968136, test loss: 1.000904, bias2: 0.9856364727020264, variance: 0.015267862007021904\n",
      "Train size: [400] hidden size: [8] trial: 46, train_loss: 1.975261, test loss: 1.001028, bias2: 0.9857200384140015, variance: 0.015307806432247162\n",
      "Train size: [400] hidden size: [8] trial: 47, train_loss: 1.972316, test loss: 1.001202, bias2: 0.9857978224754333, variance: 0.015404661186039448\n",
      "Train size: [400] hidden size: [8] trial: 48, train_loss: 1.969208, test loss: 1.001287, bias2: 0.9860262274742126, variance: 0.015260521322488785\n",
      "Train size: [400] hidden size: [8] trial: 49, train_loss: 1.969751, test loss: 1.001145, bias2: 0.9855456948280334, variance: 0.015599648468196392\n",
      "##################################################\n",
      "Train size: [400] hidden size: [9] trial: 0, train_loss: 1.956208, test loss: 0.993215, bias2: 0.9932154417037964, variance: 6.082106346338989e-11\n",
      "Train size: [400] hidden size: [9] trial: 1, train_loss: 1.997107, test loss: 1.003919, bias2: 0.9947869777679443, variance: 0.009132257662713528\n",
      "Train size: [400] hidden size: [9] trial: 2, train_loss: 1.945365, test loss: 1.002812, bias2: 0.9934301972389221, variance: 0.00938172172755003\n",
      "Train size: [400] hidden size: [9] trial: 3, train_loss: 1.991664, test loss: 0.999281, bias2: 0.987413227558136, variance: 0.011867953464388847\n",
      "Train size: [400] hidden size: [9] trial: 4, train_loss: 1.944278, test loss: 0.999231, bias2: 0.9879432320594788, variance: 0.011288249865174294\n",
      "Train size: [400] hidden size: [9] trial: 5, train_loss: 1.961246, test loss: 0.997324, bias2: 0.9858377575874329, variance: 0.01148599199950695\n",
      "Train size: [400] hidden size: [9] trial: 6, train_loss: 1.940276, test loss: 0.996942, bias2: 0.9831089973449707, variance: 0.01383341383188963\n",
      "Train size: [400] hidden size: [9] trial: 7, train_loss: 1.917238, test loss: 1.000037, bias2: 0.9842497706413269, variance: 0.0157876368612051\n",
      "Train size: [400] hidden size: [9] trial: 8, train_loss: 1.900888, test loss: 1.000591, bias2: 0.9844997525215149, variance: 0.01609102077782154\n",
      "Train size: [400] hidden size: [9] trial: 9, train_loss: 1.903554, test loss: 1.000690, bias2: 0.9846535325050354, variance: 0.016036666929721832\n",
      "Train size: [400] hidden size: [9] trial: 10, train_loss: 1.912122, test loss: 1.000879, bias2: 0.9845705032348633, variance: 0.01630878634750843\n",
      "Train size: [400] hidden size: [9] trial: 11, train_loss: 1.917748, test loss: 1.000865, bias2: 0.9844728112220764, variance: 0.01639190874993801\n",
      "Train size: [400] hidden size: [9] trial: 12, train_loss: 1.921862, test loss: 1.000858, bias2: 0.984907329082489, variance: 0.01595095917582512\n",
      "Train size: [400] hidden size: [9] trial: 13, train_loss: 1.923645, test loss: 1.001092, bias2: 0.9842984080314636, variance: 0.01679377816617489\n",
      "Train size: [400] hidden size: [9] trial: 14, train_loss: 1.938578, test loss: 1.000723, bias2: 0.9838477969169617, variance: 0.016875537112355232\n",
      "Train size: [400] hidden size: [9] trial: 15, train_loss: 1.940781, test loss: 1.000994, bias2: 0.9829815030097961, variance: 0.018012581393122673\n",
      "Train size: [400] hidden size: [9] trial: 16, train_loss: 1.937283, test loss: 1.001131, bias2: 0.9836513996124268, variance: 0.017479537054896355\n",
      "Train size: [400] hidden size: [9] trial: 17, train_loss: 1.942101, test loss: 0.999101, bias2: 0.9807573556900024, variance: 0.018343355506658554\n",
      "Train size: [400] hidden size: [9] trial: 18, train_loss: 1.940944, test loss: 0.998988, bias2: 0.9805736541748047, variance: 0.018414612859487534\n",
      "Train size: [400] hidden size: [9] trial: 19, train_loss: 1.945461, test loss: 0.999368, bias2: 0.9806865453720093, variance: 0.01868152804672718\n",
      "Train size: [400] hidden size: [9] trial: 20, train_loss: 1.946079, test loss: 0.999415, bias2: 0.9806293249130249, variance: 0.018785666674375534\n",
      "Train size: [400] hidden size: [9] trial: 21, train_loss: 1.939417, test loss: 0.999430, bias2: 0.9806285500526428, variance: 0.01880110614001751\n",
      "Train size: [400] hidden size: [9] trial: 22, train_loss: 1.931316, test loss: 0.999459, bias2: 0.9810624718666077, variance: 0.018396686762571335\n",
      "Train size: [400] hidden size: [9] trial: 23, train_loss: 1.922209, test loss: 0.999769, bias2: 0.9818786978721619, variance: 0.017890069633722305\n",
      "Train size: [400] hidden size: [9] trial: 24, train_loss: 1.917444, test loss: 0.999645, bias2: 0.9822252988815308, variance: 0.017419937998056412\n",
      "Train size: [400] hidden size: [9] trial: 25, train_loss: 1.918684, test loss: 0.999543, bias2: 0.9827093482017517, variance: 0.016833344474434853\n",
      "Train size: [400] hidden size: [9] trial: 26, train_loss: 1.928483, test loss: 0.999476, bias2: 0.9829857349395752, variance: 0.016489889472723007\n",
      "Train size: [400] hidden size: [9] trial: 27, train_loss: 1.928747, test loss: 0.998969, bias2: 0.9825595617294312, variance: 0.01640978269279003\n",
      "Train size: [400] hidden size: [9] trial: 28, train_loss: 1.928153, test loss: 0.998988, bias2: 0.9828447699546814, variance: 0.016142915934324265\n",
      "Train size: [400] hidden size: [9] trial: 29, train_loss: 1.921288, test loss: 0.998695, bias2: 0.9827936887741089, variance: 0.015901504084467888\n",
      "Train size: [400] hidden size: [9] trial: 30, train_loss: 1.924179, test loss: 0.998651, bias2: 0.982993483543396, variance: 0.015657881274819374\n",
      "Train size: [400] hidden size: [9] trial: 31, train_loss: 1.921928, test loss: 0.998590, bias2: 0.9832366704940796, variance: 0.015353117138147354\n",
      "Train size: [400] hidden size: [9] trial: 32, train_loss: 1.922761, test loss: 0.998835, bias2: 0.9836557507514954, variance: 0.015179675072431564\n",
      "Train size: [400] hidden size: [9] trial: 33, train_loss: 1.920694, test loss: 0.998892, bias2: 0.9838419556617737, variance: 0.015049988403916359\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [9] trial: 34, train_loss: 1.916122, test loss: 0.999161, bias2: 0.984390377998352, variance: 0.014770123176276684\n",
      "Train size: [400] hidden size: [9] trial: 35, train_loss: 1.917528, test loss: 0.999486, bias2: 0.9847401976585388, variance: 0.014745954424142838\n",
      "Train size: [400] hidden size: [9] trial: 36, train_loss: 1.922930, test loss: 0.999680, bias2: 0.9848192930221558, variance: 0.01486087217926979\n",
      "Train size: [400] hidden size: [9] trial: 37, train_loss: 1.928448, test loss: 0.999613, bias2: 0.9847618937492371, variance: 0.014851530082523823\n",
      "Train size: [400] hidden size: [9] trial: 38, train_loss: 1.934912, test loss: 0.999944, bias2: 0.9849425554275513, variance: 0.015001778490841389\n",
      "Train size: [400] hidden size: [9] trial: 39, train_loss: 1.936264, test loss: 0.999914, bias2: 0.9847453832626343, variance: 0.015168815851211548\n",
      "Train size: [400] hidden size: [9] trial: 40, train_loss: 1.930717, test loss: 0.999911, bias2: 0.985003650188446, variance: 0.014907528646290302\n",
      "Train size: [400] hidden size: [9] trial: 41, train_loss: 1.928160, test loss: 0.999880, bias2: 0.9849919676780701, variance: 0.01488804817199707\n",
      "Train size: [400] hidden size: [9] trial: 42, train_loss: 1.932594, test loss: 1.000285, bias2: 0.9850757122039795, variance: 0.015209289267659187\n",
      "Train size: [400] hidden size: [9] trial: 43, train_loss: 1.930967, test loss: 1.000253, bias2: 0.9851238131523132, variance: 0.015129259787499905\n",
      "Train size: [400] hidden size: [9] trial: 44, train_loss: 1.932551, test loss: 1.000821, bias2: 0.9855450987815857, variance: 0.01527568232268095\n",
      "Train size: [400] hidden size: [9] trial: 45, train_loss: 1.932123, test loss: 1.000625, bias2: 0.9855630397796631, variance: 0.015062321908771992\n",
      "Train size: [400] hidden size: [9] trial: 46, train_loss: 1.931527, test loss: 1.000305, bias2: 0.985183596611023, variance: 0.015121230855584145\n",
      "Train size: [400] hidden size: [9] trial: 47, train_loss: 1.931639, test loss: 1.000546, bias2: 0.985378086566925, variance: 0.015167893841862679\n",
      "Train size: [400] hidden size: [9] trial: 48, train_loss: 1.931039, test loss: 1.000509, bias2: 0.9853189587593079, variance: 0.015189846977591515\n",
      "Train size: [400] hidden size: [9] trial: 49, train_loss: 1.930878, test loss: 1.000482, bias2: 0.9854217767715454, variance: 0.015060205943882465\n",
      "##################################################\n",
      "Train size: [400] hidden size: [11] trial: 0, train_loss: 2.094293, test loss: 0.998560, bias2: 0.9985598921775818, variance: 1.0339579886720074e-10\n",
      "Train size: [400] hidden size: [11] trial: 1, train_loss: 2.059696, test loss: 1.000210, bias2: 0.9864562749862671, variance: 0.013753985986113548\n",
      "Train size: [400] hidden size: [11] trial: 2, train_loss: 1.984971, test loss: 0.997820, bias2: 0.9800482392311096, variance: 0.017771854996681213\n",
      "Train size: [400] hidden size: [11] trial: 3, train_loss: 1.950490, test loss: 0.997875, bias2: 0.9808960556983948, variance: 0.016978831961750984\n",
      "Train size: [400] hidden size: [11] trial: 4, train_loss: 1.928510, test loss: 0.996822, bias2: 0.979336142539978, variance: 0.01748579926788807\n",
      "Train size: [400] hidden size: [11] trial: 5, train_loss: 1.933985, test loss: 0.995362, bias2: 0.9777082204818726, variance: 0.01765388809144497\n",
      "Train size: [400] hidden size: [11] trial: 6, train_loss: 1.876259, test loss: 0.994856, bias2: 0.9778028726577759, variance: 0.017053060233592987\n",
      "Train size: [400] hidden size: [11] trial: 7, train_loss: 1.867852, test loss: 0.996179, bias2: 0.9795058369636536, variance: 0.016672931611537933\n",
      "Train size: [400] hidden size: [11] trial: 8, train_loss: 1.892782, test loss: 0.998215, bias2: 0.9816709160804749, variance: 0.016543777659535408\n",
      "Train size: [400] hidden size: [11] trial: 9, train_loss: 1.904162, test loss: 0.998307, bias2: 0.9823435544967651, variance: 0.015963375568389893\n",
      "Train size: [400] hidden size: [11] trial: 10, train_loss: 1.928682, test loss: 0.998252, bias2: 0.9819809198379517, variance: 0.016271520406007767\n",
      "Train size: [400] hidden size: [11] trial: 11, train_loss: 1.904934, test loss: 0.999250, bias2: 0.9828950762748718, variance: 0.016354534775018692\n",
      "Train size: [400] hidden size: [11] trial: 12, train_loss: 1.906838, test loss: 0.998159, bias2: 0.9816972613334656, variance: 0.016462156549096107\n",
      "Train size: [400] hidden size: [11] trial: 13, train_loss: 1.894869, test loss: 0.997905, bias2: 0.9811595678329468, variance: 0.01674514077603817\n",
      "Train size: [400] hidden size: [11] trial: 14, train_loss: 1.904959, test loss: 0.997349, bias2: 0.97954922914505, variance: 0.01779939979314804\n",
      "Train size: [400] hidden size: [11] trial: 15, train_loss: 1.912889, test loss: 0.997658, bias2: 0.9797554016113281, variance: 0.01790216751396656\n",
      "Train size: [400] hidden size: [11] trial: 16, train_loss: 1.922118, test loss: 0.997052, bias2: 0.9793416857719421, variance: 0.017710402607917786\n",
      "Train size: [400] hidden size: [11] trial: 17, train_loss: 1.909091, test loss: 0.996540, bias2: 0.9795858263969421, variance: 0.01695452630519867\n",
      "Train size: [400] hidden size: [11] trial: 18, train_loss: 1.927712, test loss: 0.997487, bias2: 0.980709969997406, variance: 0.016776643693447113\n",
      "Train size: [400] hidden size: [11] trial: 19, train_loss: 1.930277, test loss: 0.997237, bias2: 0.9800601005554199, variance: 0.017176449298858643\n",
      "Train size: [400] hidden size: [11] trial: 20, train_loss: 1.926734, test loss: 0.997035, bias2: 0.9799066781997681, variance: 0.01712842285633087\n",
      "Train size: [400] hidden size: [11] trial: 21, train_loss: 1.926694, test loss: 0.997079, bias2: 0.979652464389801, variance: 0.01742704212665558\n",
      "Train size: [400] hidden size: [11] trial: 22, train_loss: 1.931235, test loss: 0.997291, bias2: 0.9795700311660767, variance: 0.017721286043524742\n",
      "Train size: [400] hidden size: [11] trial: 23, train_loss: 1.932660, test loss: 0.997529, bias2: 0.9801608920097351, variance: 0.017368026077747345\n",
      "Train size: [400] hidden size: [11] trial: 24, train_loss: 1.931234, test loss: 0.997646, bias2: 0.9805765151977539, variance: 0.017069758847355843\n",
      "Train size: [400] hidden size: [11] trial: 25, train_loss: 1.931862, test loss: 0.997674, bias2: 0.9796683192253113, variance: 0.018005650490522385\n",
      "Train size: [400] hidden size: [11] trial: 26, train_loss: 1.924064, test loss: 0.997764, bias2: 0.9796258211135864, variance: 0.01813814602792263\n",
      "Train size: [400] hidden size: [11] trial: 27, train_loss: 1.922981, test loss: 0.998208, bias2: 0.9801155924797058, variance: 0.01809203065931797\n",
      "Train size: [400] hidden size: [11] trial: 28, train_loss: 1.919347, test loss: 0.998722, bias2: 0.9799138903617859, variance: 0.018807822838425636\n",
      "Train size: [400] hidden size: [11] trial: 29, train_loss: 1.924120, test loss: 0.998793, bias2: 0.9802733063697815, variance: 0.018519356846809387\n",
      "Train size: [400] hidden size: [11] trial: 30, train_loss: 1.922663, test loss: 0.999121, bias2: 0.9806139469146729, variance: 0.01850687339901924\n",
      "Train size: [400] hidden size: [11] trial: 31, train_loss: 1.920506, test loss: 0.998549, bias2: 0.9800916910171509, variance: 0.018457064405083656\n",
      "Train size: [400] hidden size: [11] trial: 32, train_loss: 1.924425, test loss: 0.998806, bias2: 0.9800788164138794, variance: 0.018727058544754982\n",
      "Train size: [400] hidden size: [11] trial: 33, train_loss: 1.919067, test loss: 0.998578, bias2: 0.9798189997673035, variance: 0.018758976832032204\n",
      "Train size: [400] hidden size: [11] trial: 34, train_loss: 1.919705, test loss: 0.998076, bias2: 0.9794052839279175, variance: 0.01867085136473179\n",
      "Train size: [400] hidden size: [11] trial: 35, train_loss: 1.923746, test loss: 0.998083, bias2: 0.9794750213623047, variance: 0.01860758662223816\n",
      "Train size: [400] hidden size: [11] trial: 36, train_loss: 1.930599, test loss: 0.997752, bias2: 0.9790269136428833, variance: 0.018725011497735977\n",
      "Train size: [400] hidden size: [11] trial: 37, train_loss: 1.931049, test loss: 0.997813, bias2: 0.97873455286026, variance: 0.01907840557396412\n",
      "Train size: [400] hidden size: [11] trial: 38, train_loss: 1.925987, test loss: 0.997872, bias2: 0.978866457939148, variance: 0.019006021320819855\n",
      "Train size: [400] hidden size: [11] trial: 39, train_loss: 1.925344, test loss: 0.997384, bias2: 0.9783682823181152, variance: 0.019015613943338394\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [11] trial: 40, train_loss: 1.933549, test loss: 0.997184, bias2: 0.9784274101257324, variance: 0.018756121397018433\n",
      "Train size: [400] hidden size: [11] trial: 41, train_loss: 1.931370, test loss: 0.996993, bias2: 0.9783662557601929, variance: 0.01862690970301628\n",
      "Train size: [400] hidden size: [11] trial: 42, train_loss: 1.931443, test loss: 0.996917, bias2: 0.9782488942146301, variance: 0.018668437376618385\n",
      "Train size: [400] hidden size: [11] trial: 43, train_loss: 1.935078, test loss: 0.996578, bias2: 0.9778769016265869, variance: 0.01870109885931015\n",
      "Train size: [400] hidden size: [11] trial: 44, train_loss: 1.932946, test loss: 0.996651, bias2: 0.9779293537139893, variance: 0.018722012639045715\n",
      "Train size: [400] hidden size: [11] trial: 45, train_loss: 1.933471, test loss: 0.997265, bias2: 0.978337287902832, variance: 0.018927449360489845\n",
      "Train size: [400] hidden size: [11] trial: 46, train_loss: 1.931034, test loss: 0.997161, bias2: 0.9783599972724915, variance: 0.01880074106156826\n",
      "Train size: [400] hidden size: [11] trial: 47, train_loss: 1.928815, test loss: 0.996991, bias2: 0.9783343076705933, variance: 0.018656793981790543\n",
      "Train size: [400] hidden size: [11] trial: 48, train_loss: 1.925060, test loss: 0.996742, bias2: 0.9783028960227966, variance: 0.018439490348100662\n",
      "Train size: [400] hidden size: [11] trial: 49, train_loss: 1.923723, test loss: 0.996600, bias2: 0.9782499670982361, variance: 0.018350103870034218\n",
      "##################################################\n",
      "Train size: [400] hidden size: [12] trial: 0, train_loss: 1.941229, test loss: 0.990126, bias2: 0.9901256561279297, variance: -4.865684938293313e-11\n",
      "Train size: [400] hidden size: [12] trial: 1, train_loss: 1.901702, test loss: 1.002156, bias2: 0.9971030950546265, variance: 0.00505258422344923\n",
      "Train size: [400] hidden size: [12] trial: 2, train_loss: 1.895639, test loss: 1.002973, bias2: 0.9954773187637329, variance: 0.007495902944356203\n",
      "Train size: [400] hidden size: [12] trial: 3, train_loss: 1.881104, test loss: 1.001247, bias2: 0.9870965480804443, variance: 0.01415003091096878\n",
      "Train size: [400] hidden size: [12] trial: 4, train_loss: 1.898237, test loss: 1.002596, bias2: 0.9877967238426208, variance: 0.014799163676798344\n",
      "Train size: [400] hidden size: [12] trial: 5, train_loss: 1.938070, test loss: 1.001753, bias2: 0.9861184358596802, variance: 0.01563500426709652\n",
      "Train size: [400] hidden size: [12] trial: 6, train_loss: 1.936510, test loss: 1.001440, bias2: 0.9852962493896484, variance: 0.016143346205353737\n",
      "Train size: [400] hidden size: [12] trial: 7, train_loss: 1.940958, test loss: 1.001449, bias2: 0.9857633709907532, variance: 0.015685373917222023\n",
      "Train size: [400] hidden size: [12] trial: 8, train_loss: 1.927256, test loss: 1.000169, bias2: 0.9847802519798279, variance: 0.015389039181172848\n",
      "Train size: [400] hidden size: [12] trial: 9, train_loss: 1.921534, test loss: 0.998811, bias2: 0.9822483062744141, variance: 0.016562214121222496\n",
      "Train size: [400] hidden size: [12] trial: 10, train_loss: 1.911309, test loss: 0.997936, bias2: 0.9821032881736755, variance: 0.015832576900720596\n",
      "Train size: [400] hidden size: [12] trial: 11, train_loss: 1.929313, test loss: 0.999811, bias2: 0.9828488826751709, variance: 0.01696205511689186\n",
      "Train size: [400] hidden size: [12] trial: 12, train_loss: 1.922289, test loss: 0.999140, bias2: 0.9827972650527954, variance: 0.016342531889677048\n",
      "Train size: [400] hidden size: [12] trial: 13, train_loss: 1.917453, test loss: 0.998858, bias2: 0.9818879961967468, variance: 0.016970504075288773\n",
      "Train size: [400] hidden size: [12] trial: 14, train_loss: 1.934875, test loss: 1.000918, bias2: 0.9832685589790344, variance: 0.017648989334702492\n",
      "Train size: [400] hidden size: [12] trial: 15, train_loss: 1.947453, test loss: 1.001260, bias2: 0.9842416048049927, variance: 0.017018578946590424\n",
      "Train size: [400] hidden size: [12] trial: 16, train_loss: 1.950796, test loss: 1.001113, bias2: 0.9843728542327881, variance: 0.01674068719148636\n",
      "Train size: [400] hidden size: [12] trial: 17, train_loss: 1.958256, test loss: 1.000969, bias2: 0.9835107922554016, variance: 0.017457902431488037\n",
      "Train size: [400] hidden size: [12] trial: 18, train_loss: 1.964518, test loss: 1.001383, bias2: 0.9835346341133118, variance: 0.017848899587988853\n",
      "Train size: [400] hidden size: [12] trial: 19, train_loss: 1.963338, test loss: 1.001637, bias2: 0.9838083386421204, variance: 0.017828986048698425\n",
      "Train size: [400] hidden size: [12] trial: 20, train_loss: 1.966372, test loss: 1.001661, bias2: 0.9830501079559326, variance: 0.018610816448926926\n",
      "Train size: [400] hidden size: [12] trial: 21, train_loss: 1.960035, test loss: 1.002176, bias2: 0.9827764630317688, variance: 0.019399482756853104\n",
      "Train size: [400] hidden size: [12] trial: 22, train_loss: 1.957892, test loss: 1.001633, bias2: 0.9814070463180542, variance: 0.020225537940859795\n",
      "Train size: [400] hidden size: [12] trial: 23, train_loss: 1.958904, test loss: 1.001859, bias2: 0.9811037182807922, variance: 0.02075548842549324\n",
      "Train size: [400] hidden size: [12] trial: 24, train_loss: 1.949429, test loss: 1.002181, bias2: 0.9815726280212402, variance: 0.02060791850090027\n",
      "Train size: [400] hidden size: [12] trial: 25, train_loss: 1.952622, test loss: 1.002168, bias2: 0.9817959070205688, variance: 0.02037249132990837\n",
      "Train size: [400] hidden size: [12] trial: 26, train_loss: 1.951580, test loss: 1.001024, bias2: 0.9799760580062866, variance: 0.021047823131084442\n",
      "Train size: [400] hidden size: [12] trial: 27, train_loss: 1.954709, test loss: 1.001746, bias2: 0.9806129336357117, variance: 0.02113279141485691\n",
      "Train size: [400] hidden size: [12] trial: 28, train_loss: 1.951047, test loss: 1.001050, bias2: 0.9800577163696289, variance: 0.020992286503314972\n",
      "Train size: [400] hidden size: [12] trial: 29, train_loss: 1.964946, test loss: 1.000905, bias2: 0.9795774817466736, variance: 0.021327773109078407\n",
      "Train size: [400] hidden size: [12] trial: 30, train_loss: 1.957765, test loss: 1.001495, bias2: 0.9794955849647522, variance: 0.021999416872859\n",
      "Train size: [400] hidden size: [12] trial: 31, train_loss: 1.961751, test loss: 1.001668, bias2: 0.9796987175941467, variance: 0.021969132125377655\n",
      "Train size: [400] hidden size: [12] trial: 32, train_loss: 1.959174, test loss: 1.001203, bias2: 0.979461669921875, variance: 0.021740909665822983\n",
      "Train size: [400] hidden size: [12] trial: 33, train_loss: 1.962441, test loss: 1.001313, bias2: 0.9797360301017761, variance: 0.021577199921011925\n",
      "Train size: [400] hidden size: [12] trial: 34, train_loss: 1.963026, test loss: 1.001155, bias2: 0.9797244668006897, variance: 0.021430563181638718\n",
      "Train size: [400] hidden size: [12] trial: 35, train_loss: 1.958065, test loss: 1.001032, bias2: 0.9799572229385376, variance: 0.021074440330266953\n",
      "Train size: [400] hidden size: [12] trial: 36, train_loss: 1.958325, test loss: 1.001072, bias2: 0.9803128242492676, variance: 0.020759329199790955\n",
      "Train size: [400] hidden size: [12] trial: 37, train_loss: 1.958158, test loss: 1.001592, bias2: 0.980911374092102, variance: 0.020680217072367668\n",
      "Train size: [400] hidden size: [12] trial: 38, train_loss: 1.956231, test loss: 1.001845, bias2: 0.9813982248306274, variance: 0.02044687420129776\n",
      "Train size: [400] hidden size: [12] trial: 39, train_loss: 1.954186, test loss: 1.001578, bias2: 0.9813665151596069, variance: 0.02021181955933571\n",
      "Train size: [400] hidden size: [12] trial: 40, train_loss: 1.961140, test loss: 1.001813, bias2: 0.9813087582588196, variance: 0.020504413172602654\n",
      "Train size: [400] hidden size: [12] trial: 41, train_loss: 1.957911, test loss: 1.002305, bias2: 0.9812672138214111, variance: 0.021037600934505463\n",
      "Train size: [400] hidden size: [12] trial: 42, train_loss: 1.959396, test loss: 1.002695, bias2: 0.9817013740539551, variance: 0.020993366837501526\n",
      "Train size: [400] hidden size: [12] trial: 43, train_loss: 1.955665, test loss: 1.002480, bias2: 0.9812654852867126, variance: 0.021214686334133148\n",
      "Train size: [400] hidden size: [12] trial: 44, train_loss: 1.953871, test loss: 1.002278, bias2: 0.981242835521698, variance: 0.021035145968198776\n",
      "Train size: [400] hidden size: [12] trial: 45, train_loss: 1.959256, test loss: 1.002079, bias2: 0.981145977973938, variance: 0.020932884886860847\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [12] trial: 46, train_loss: 1.960779, test loss: 1.002009, bias2: 0.981249213218689, variance: 0.020759351551532745\n",
      "Train size: [400] hidden size: [12] trial: 47, train_loss: 1.963220, test loss: 1.001880, bias2: 0.9809580445289612, variance: 0.020921766757965088\n",
      "Train size: [400] hidden size: [12] trial: 48, train_loss: 1.968010, test loss: 1.001797, bias2: 0.9809262156486511, variance: 0.02087121270596981\n",
      "Train size: [400] hidden size: [12] trial: 49, train_loss: 1.962162, test loss: 1.001804, bias2: 0.9811969995498657, variance: 0.020606501027941704\n",
      "##################################################\n",
      "Train size: [400] hidden size: [14] trial: 0, train_loss: 1.896084, test loss: 0.994394, bias2: 0.994394063949585, variance: 1.9462739753173253e-10\n",
      "Train size: [400] hidden size: [14] trial: 1, train_loss: 1.897959, test loss: 0.992392, bias2: 0.9744247794151306, variance: 0.017967062070965767\n",
      "Train size: [400] hidden size: [14] trial: 2, train_loss: 1.906663, test loss: 0.996522, bias2: 0.9783499836921692, variance: 0.018171723932027817\n",
      "Train size: [400] hidden size: [14] trial: 3, train_loss: 1.883878, test loss: 0.994992, bias2: 0.9728159308433533, variance: 0.022176407277584076\n",
      "Train size: [400] hidden size: [14] trial: 4, train_loss: 1.921656, test loss: 0.996243, bias2: 0.973960280418396, variance: 0.0222831591963768\n",
      "Train size: [400] hidden size: [14] trial: 5, train_loss: 1.919488, test loss: 0.995331, bias2: 0.9739281535148621, variance: 0.021402597427368164\n",
      "Train size: [400] hidden size: [14] trial: 6, train_loss: 1.922213, test loss: 0.991629, bias2: 0.9703344702720642, variance: 0.021294858306646347\n",
      "Train size: [400] hidden size: [14] trial: 7, train_loss: 1.935598, test loss: 0.991998, bias2: 0.9711771011352539, variance: 0.020820602774620056\n",
      "Train size: [400] hidden size: [14] trial: 8, train_loss: 1.933206, test loss: 0.994838, bias2: 0.9743918776512146, variance: 0.02044619619846344\n",
      "Train size: [400] hidden size: [14] trial: 9, train_loss: 1.927576, test loss: 0.996754, bias2: 0.9771033525466919, variance: 0.019650941714644432\n",
      "Train size: [400] hidden size: [14] trial: 10, train_loss: 1.912833, test loss: 0.997354, bias2: 0.9765431880950928, variance: 0.020810993388295174\n",
      "Train size: [400] hidden size: [14] trial: 11, train_loss: 1.938583, test loss: 1.000106, bias2: 0.9762784838676453, variance: 0.023827994242310524\n",
      "Train size: [400] hidden size: [14] trial: 12, train_loss: 1.949744, test loss: 1.000804, bias2: 0.9773418307304382, variance: 0.023461733013391495\n",
      "Train size: [400] hidden size: [14] trial: 13, train_loss: 1.939793, test loss: 1.001895, bias2: 0.978704571723938, variance: 0.023190872743725777\n",
      "Train size: [400] hidden size: [14] trial: 14, train_loss: 1.936560, test loss: 1.002074, bias2: 0.9784523844718933, variance: 0.023621471598744392\n",
      "Train size: [400] hidden size: [14] trial: 15, train_loss: 1.940242, test loss: 1.002181, bias2: 0.9774777293205261, variance: 0.02470322698354721\n",
      "Train size: [400] hidden size: [14] trial: 16, train_loss: 1.939166, test loss: 1.002102, bias2: 0.9773522615432739, variance: 0.02474963106215\n",
      "Train size: [400] hidden size: [14] trial: 17, train_loss: 1.941261, test loss: 1.000942, bias2: 0.9757375717163086, variance: 0.025204913690686226\n",
      "Train size: [400] hidden size: [14] trial: 18, train_loss: 1.950474, test loss: 1.000894, bias2: 0.9750003218650818, variance: 0.025894008576869965\n",
      "Train size: [400] hidden size: [14] trial: 19, train_loss: 1.947518, test loss: 1.001096, bias2: 0.9755702614784241, variance: 0.025525402277708054\n",
      "Train size: [400] hidden size: [14] trial: 20, train_loss: 1.956797, test loss: 1.000813, bias2: 0.9756134152412415, variance: 0.025199683383107185\n",
      "Train size: [400] hidden size: [14] trial: 21, train_loss: 1.973341, test loss: 1.000975, bias2: 0.9756994247436523, variance: 0.025275804102420807\n",
      "Train size: [400] hidden size: [14] trial: 22, train_loss: 1.970721, test loss: 1.000874, bias2: 0.9755046367645264, variance: 0.025369171053171158\n",
      "Train size: [400] hidden size: [14] trial: 23, train_loss: 1.972727, test loss: 1.000635, bias2: 0.9750884771347046, variance: 0.02554619312286377\n",
      "Train size: [400] hidden size: [14] trial: 24, train_loss: 1.964630, test loss: 1.000398, bias2: 0.9743896722793579, variance: 0.02600821852684021\n",
      "Train size: [400] hidden size: [14] trial: 25, train_loss: 1.972335, test loss: 0.999803, bias2: 0.973892092704773, variance: 0.025910936295986176\n",
      "Train size: [400] hidden size: [14] trial: 26, train_loss: 1.965189, test loss: 0.999440, bias2: 0.9740477800369263, variance: 0.0253920815885067\n",
      "Train size: [400] hidden size: [14] trial: 27, train_loss: 1.965198, test loss: 0.998716, bias2: 0.973282516002655, variance: 0.025433916598558426\n",
      "Train size: [400] hidden size: [14] trial: 28, train_loss: 1.963663, test loss: 0.998704, bias2: 0.9727970361709595, variance: 0.025906765833497047\n",
      "Train size: [400] hidden size: [14] trial: 29, train_loss: 1.964597, test loss: 0.998306, bias2: 0.9720550775527954, variance: 0.026250911876559258\n",
      "Train size: [400] hidden size: [14] trial: 30, train_loss: 1.960076, test loss: 0.998494, bias2: 0.9722179174423218, variance: 0.026275955140590668\n",
      "Train size: [400] hidden size: [14] trial: 31, train_loss: 1.966359, test loss: 0.998751, bias2: 0.9726790189743042, variance: 0.0260721854865551\n",
      "Train size: [400] hidden size: [14] trial: 32, train_loss: 1.965890, test loss: 0.998822, bias2: 0.9727495908737183, variance: 0.026072673499584198\n",
      "Train size: [400] hidden size: [14] trial: 33, train_loss: 1.957993, test loss: 0.998696, bias2: 0.9724205732345581, variance: 0.026275373995304108\n",
      "Train size: [400] hidden size: [14] trial: 34, train_loss: 1.957252, test loss: 0.998863, bias2: 0.9725765585899353, variance: 0.026286564767360687\n",
      "Train size: [400] hidden size: [14] trial: 35, train_loss: 1.956547, test loss: 0.998645, bias2: 0.9724305272102356, variance: 0.02621397189795971\n",
      "Train size: [400] hidden size: [14] trial: 36, train_loss: 1.958312, test loss: 0.998253, bias2: 0.9720632433891296, variance: 0.026189561933279037\n",
      "Train size: [400] hidden size: [14] trial: 37, train_loss: 1.954975, test loss: 0.998415, bias2: 0.9722850918769836, variance: 0.026129422709345818\n",
      "Train size: [400] hidden size: [14] trial: 38, train_loss: 1.949843, test loss: 0.998392, bias2: 0.9721071720123291, variance: 0.026284947991371155\n",
      "Train size: [400] hidden size: [14] trial: 39, train_loss: 1.947347, test loss: 0.998781, bias2: 0.9723010659217834, variance: 0.02648029662668705\n",
      "Train size: [400] hidden size: [14] trial: 40, train_loss: 1.943339, test loss: 0.998616, bias2: 0.9722718000411987, variance: 0.026344435289502144\n",
      "Train size: [400] hidden size: [14] trial: 41, train_loss: 1.940942, test loss: 0.998194, bias2: 0.9716700315475464, variance: 0.026524165645241737\n",
      "Train size: [400] hidden size: [14] trial: 42, train_loss: 1.945566, test loss: 0.998136, bias2: 0.9718214869499207, variance: 0.026314066722989082\n",
      "Train size: [400] hidden size: [14] trial: 43, train_loss: 1.944607, test loss: 0.997945, bias2: 0.9715701341629028, variance: 0.026374945417046547\n",
      "Train size: [400] hidden size: [14] trial: 44, train_loss: 1.940972, test loss: 0.997975, bias2: 0.9714418053627014, variance: 0.026533333584666252\n",
      "Train size: [400] hidden size: [14] trial: 45, train_loss: 1.935548, test loss: 0.997969, bias2: 0.971247673034668, variance: 0.026720812544226646\n",
      "Train size: [400] hidden size: [14] trial: 46, train_loss: 1.934314, test loss: 0.997968, bias2: 0.9713911414146423, variance: 0.026577118784189224\n",
      "Train size: [400] hidden size: [14] trial: 47, train_loss: 1.936135, test loss: 0.998166, bias2: 0.971710205078125, variance: 0.02645569108426571\n",
      "Train size: [400] hidden size: [14] trial: 48, train_loss: 1.931883, test loss: 0.998218, bias2: 0.9717122316360474, variance: 0.026506273075938225\n",
      "Train size: [400] hidden size: [14] trial: 49, train_loss: 1.927612, test loss: 0.998178, bias2: 0.9718232154846191, variance: 0.026355238631367683\n",
      "##################################################\n",
      "Train size: [400] hidden size: [16] trial: 0, train_loss: 2.156809, test loss: 1.019124, bias2: 1.019124150276184, variance: -1.2164212692677978e-10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [16] trial: 1, train_loss: 2.019820, test loss: 1.004568, bias2: 0.9868522882461548, variance: 0.01771583966910839\n",
      "Train size: [400] hidden size: [16] trial: 2, train_loss: 1.975337, test loss: 1.002242, bias2: 0.9781880378723145, variance: 0.02405366487801075\n",
      "Train size: [400] hidden size: [16] trial: 3, train_loss: 1.962108, test loss: 0.999858, bias2: 0.9770711064338684, variance: 0.02278720773756504\n",
      "Train size: [400] hidden size: [16] trial: 4, train_loss: 1.959175, test loss: 0.998369, bias2: 0.9735402464866638, variance: 0.024829039350152016\n",
      "Train size: [400] hidden size: [16] trial: 5, train_loss: 1.963505, test loss: 0.994412, bias2: 0.9692659378051758, variance: 0.025146517902612686\n",
      "Train size: [400] hidden size: [16] trial: 6, train_loss: 1.924965, test loss: 0.994180, bias2: 0.9685357809066772, variance: 0.02564440667629242\n",
      "Train size: [400] hidden size: [16] trial: 7, train_loss: 1.956646, test loss: 0.993517, bias2: 0.9688848853111267, variance: 0.024632059037685394\n",
      "Train size: [400] hidden size: [16] trial: 8, train_loss: 1.921033, test loss: 0.995804, bias2: 0.9722772240638733, variance: 0.023527005687355995\n",
      "Train size: [400] hidden size: [16] trial: 9, train_loss: 1.935628, test loss: 0.997900, bias2: 0.9750040769577026, variance: 0.022895459085702896\n",
      "Train size: [400] hidden size: [16] trial: 10, train_loss: 1.960678, test loss: 0.997602, bias2: 0.9728712439537048, variance: 0.024730535224080086\n",
      "Train size: [400] hidden size: [16] trial: 11, train_loss: 1.984023, test loss: 0.998502, bias2: 0.9739741683006287, variance: 0.024527668952941895\n",
      "Train size: [400] hidden size: [16] trial: 12, train_loss: 1.989043, test loss: 0.998299, bias2: 0.9724828004837036, variance: 0.0258158128708601\n",
      "Train size: [400] hidden size: [16] trial: 13, train_loss: 1.986685, test loss: 0.997323, bias2: 0.9725540280342102, variance: 0.024768944829702377\n",
      "Train size: [400] hidden size: [16] trial: 14, train_loss: 1.994632, test loss: 0.996216, bias2: 0.9717557430267334, variance: 0.024460187181830406\n",
      "Train size: [400] hidden size: [16] trial: 15, train_loss: 1.990600, test loss: 0.997281, bias2: 0.9722047448158264, variance: 0.02507670223712921\n",
      "Train size: [400] hidden size: [16] trial: 16, train_loss: 1.982004, test loss: 0.997569, bias2: 0.9711731672286987, variance: 0.02639630064368248\n",
      "Train size: [400] hidden size: [16] trial: 17, train_loss: 1.990544, test loss: 0.996693, bias2: 0.970749020576477, variance: 0.025944074615836143\n",
      "Train size: [400] hidden size: [16] trial: 18, train_loss: 1.994216, test loss: 0.995533, bias2: 0.9694289565086365, variance: 0.02610361948609352\n",
      "Train size: [400] hidden size: [16] trial: 19, train_loss: 1.984631, test loss: 0.995384, bias2: 0.9692633748054504, variance: 0.026121016591787338\n",
      "Train size: [400] hidden size: [16] trial: 20, train_loss: 1.975110, test loss: 0.996218, bias2: 0.9705294966697693, variance: 0.02568846195936203\n",
      "Train size: [400] hidden size: [16] trial: 21, train_loss: 1.973711, test loss: 0.996591, bias2: 0.9702712893486023, variance: 0.026319719851017\n",
      "Train size: [400] hidden size: [16] trial: 22, train_loss: 1.967185, test loss: 0.996173, bias2: 0.969239354133606, variance: 0.02693326584994793\n",
      "Train size: [400] hidden size: [16] trial: 23, train_loss: 1.970362, test loss: 0.996191, bias2: 0.9696344137191772, variance: 0.026556968688964844\n",
      "Train size: [400] hidden size: [16] trial: 24, train_loss: 1.963134, test loss: 0.996188, bias2: 0.9703441262245178, variance: 0.025843430310487747\n",
      "Train size: [400] hidden size: [16] trial: 25, train_loss: 1.966512, test loss: 0.997271, bias2: 0.9709669947624207, variance: 0.026304403319954872\n",
      "Train size: [400] hidden size: [16] trial: 26, train_loss: 1.962834, test loss: 0.996474, bias2: 0.9698390364646912, variance: 0.026635363698005676\n",
      "Train size: [400] hidden size: [16] trial: 27, train_loss: 1.965584, test loss: 0.996678, bias2: 0.9698126912117004, variance: 0.026865584775805473\n",
      "Train size: [400] hidden size: [16] trial: 28, train_loss: 1.958337, test loss: 0.996974, bias2: 0.9700031280517578, variance: 0.02697082795202732\n",
      "Train size: [400] hidden size: [16] trial: 29, train_loss: 1.954394, test loss: 0.997048, bias2: 0.9697959423065186, variance: 0.02725188061594963\n",
      "Train size: [400] hidden size: [16] trial: 30, train_loss: 1.954721, test loss: 0.997316, bias2: 0.9700120687484741, variance: 0.02730373479425907\n",
      "Train size: [400] hidden size: [16] trial: 31, train_loss: 1.956531, test loss: 0.998428, bias2: 0.9702526330947876, variance: 0.028174988925457\n",
      "Train size: [400] hidden size: [16] trial: 32, train_loss: 1.957246, test loss: 0.998696, bias2: 0.9708001613616943, variance: 0.027895871549844742\n",
      "Train size: [400] hidden size: [16] trial: 33, train_loss: 1.957096, test loss: 0.998849, bias2: 0.970564603805542, variance: 0.028284374624490738\n",
      "Train size: [400] hidden size: [16] trial: 34, train_loss: 1.958798, test loss: 0.999208, bias2: 0.9710215926170349, variance: 0.02818654663860798\n",
      "Train size: [400] hidden size: [16] trial: 35, train_loss: 1.960632, test loss: 0.999075, bias2: 0.9712064862251282, variance: 0.02786821685731411\n",
      "Train size: [400] hidden size: [16] trial: 36, train_loss: 1.957741, test loss: 0.998345, bias2: 0.9706892967224121, variance: 0.027656102553009987\n",
      "Train size: [400] hidden size: [16] trial: 37, train_loss: 1.952964, test loss: 0.998772, bias2: 0.9713524580001831, variance: 0.02741941064596176\n",
      "Train size: [400] hidden size: [16] trial: 38, train_loss: 1.950505, test loss: 0.998795, bias2: 0.970996618270874, variance: 0.027798019349575043\n",
      "Train size: [400] hidden size: [16] trial: 39, train_loss: 1.953084, test loss: 0.998650, bias2: 0.9707525372505188, variance: 0.027897322550415993\n",
      "Train size: [400] hidden size: [16] trial: 40, train_loss: 1.952631, test loss: 0.998727, bias2: 0.9703326225280762, variance: 0.028394142165780067\n",
      "Train size: [400] hidden size: [16] trial: 41, train_loss: 1.957727, test loss: 0.998757, bias2: 0.970758855342865, variance: 0.027998248115181923\n",
      "Train size: [400] hidden size: [16] trial: 42, train_loss: 1.953198, test loss: 0.998185, bias2: 0.9699876308441162, variance: 0.02819778583943844\n",
      "Train size: [400] hidden size: [16] trial: 43, train_loss: 1.952866, test loss: 0.997836, bias2: 0.9697668552398682, variance: 0.02806882932782173\n",
      "Train size: [400] hidden size: [16] trial: 44, train_loss: 1.956152, test loss: 0.997990, bias2: 0.9700114727020264, variance: 0.027978170663118362\n",
      "Train size: [400] hidden size: [16] trial: 45, train_loss: 1.958792, test loss: 0.997836, bias2: 0.9699984192848206, variance: 0.02783779986202717\n",
      "Train size: [400] hidden size: [16] trial: 46, train_loss: 1.950344, test loss: 0.998551, bias2: 0.9707784056663513, variance: 0.027772732079029083\n",
      "Train size: [400] hidden size: [16] trial: 47, train_loss: 1.948125, test loss: 0.998873, bias2: 0.971410870552063, variance: 0.027462627738714218\n",
      "Train size: [400] hidden size: [16] trial: 48, train_loss: 1.947742, test loss: 0.999561, bias2: 0.9716373085975647, variance: 0.027923790737986565\n",
      "Train size: [400] hidden size: [16] trial: 49, train_loss: 1.945618, test loss: 0.999565, bias2: 0.9715358018875122, variance: 0.02802884951233864\n",
      "##################################################\n",
      "Train size: [400] hidden size: [19] trial: 0, train_loss: 2.085207, test loss: 0.990504, bias2: 0.9905042052268982, variance: -9.731369876586626e-11\n",
      "Train size: [400] hidden size: [19] trial: 1, train_loss: 2.066750, test loss: 0.993059, bias2: 0.9778199195861816, variance: 0.015238993801176548\n",
      "Train size: [400] hidden size: [19] trial: 2, train_loss: 1.991421, test loss: 0.998032, bias2: 0.9790726900100708, variance: 0.01895977556705475\n",
      "Train size: [400] hidden size: [19] trial: 3, train_loss: 2.014671, test loss: 0.997077, bias2: 0.9786187410354614, variance: 0.0184582881629467\n",
      "Train size: [400] hidden size: [19] trial: 4, train_loss: 1.943737, test loss: 0.997295, bias2: 0.9771486520767212, variance: 0.020145872607827187\n",
      "Train size: [400] hidden size: [19] trial: 5, train_loss: 1.952859, test loss: 0.996861, bias2: 0.9763666987419128, variance: 0.020494241267442703\n",
      "Train size: [400] hidden size: [19] trial: 6, train_loss: 1.916207, test loss: 1.001127, bias2: 0.9786139726638794, variance: 0.022513415664434433\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [19] trial: 7, train_loss: 1.916760, test loss: 1.000841, bias2: 0.9786832928657532, variance: 0.022158106788992882\n",
      "Train size: [400] hidden size: [19] trial: 8, train_loss: 1.924716, test loss: 0.998331, bias2: 0.9749861359596252, variance: 0.023344749584794044\n",
      "Train size: [400] hidden size: [19] trial: 9, train_loss: 1.910737, test loss: 0.998015, bias2: 0.9746201634407043, variance: 0.023394957184791565\n",
      "Train size: [400] hidden size: [19] trial: 10, train_loss: 1.877770, test loss: 1.000481, bias2: 0.972684383392334, variance: 0.027796121314167976\n",
      "Train size: [400] hidden size: [19] trial: 11, train_loss: 1.877877, test loss: 0.997337, bias2: 0.9685904383659363, variance: 0.028746914118528366\n",
      "Train size: [400] hidden size: [19] trial: 12, train_loss: 1.871717, test loss: 0.996970, bias2: 0.968142569065094, variance: 0.02882741577923298\n",
      "Train size: [400] hidden size: [19] trial: 13, train_loss: 1.871435, test loss: 0.996846, bias2: 0.967971682548523, variance: 0.028874240815639496\n",
      "Train size: [400] hidden size: [19] trial: 14, train_loss: 1.874307, test loss: 0.996727, bias2: 0.9678653478622437, variance: 0.028861714527010918\n",
      "Train size: [400] hidden size: [19] trial: 15, train_loss: 1.866633, test loss: 0.996990, bias2: 0.9682475328445435, variance: 0.02874254435300827\n",
      "Train size: [400] hidden size: [19] trial: 16, train_loss: 1.877089, test loss: 0.997202, bias2: 0.9684764742851257, variance: 0.028725523501634598\n",
      "Train size: [400] hidden size: [19] trial: 17, train_loss: 1.872973, test loss: 0.997720, bias2: 0.9697622656822205, variance: 0.02795768715441227\n",
      "Train size: [400] hidden size: [19] trial: 18, train_loss: 1.868135, test loss: 0.997666, bias2: 0.968864381313324, variance: 0.028801238164305687\n",
      "Train size: [400] hidden size: [19] trial: 19, train_loss: 1.858721, test loss: 0.997053, bias2: 0.9690155386924744, variance: 0.028037000447511673\n",
      "Train size: [400] hidden size: [19] trial: 20, train_loss: 1.861151, test loss: 0.997472, bias2: 0.9691131711006165, variance: 0.028359130024909973\n",
      "Train size: [400] hidden size: [19] trial: 21, train_loss: 1.858566, test loss: 0.997515, bias2: 0.9684249758720398, variance: 0.02909042313694954\n",
      "Train size: [400] hidden size: [19] trial: 22, train_loss: 1.851065, test loss: 0.997946, bias2: 0.9683153629302979, variance: 0.029630862176418304\n",
      "Train size: [400] hidden size: [19] trial: 23, train_loss: 1.858470, test loss: 0.998209, bias2: 0.9691046476364136, variance: 0.029104121029376984\n",
      "Train size: [400] hidden size: [19] trial: 24, train_loss: 1.855267, test loss: 0.998577, bias2: 0.9684956073760986, variance: 0.030081313103437424\n",
      "Train size: [400] hidden size: [19] trial: 25, train_loss: 1.854397, test loss: 0.998945, bias2: 0.9688919186592102, variance: 0.030053453519940376\n",
      "Train size: [400] hidden size: [19] trial: 26, train_loss: 1.859235, test loss: 0.997761, bias2: 0.9676657319068909, variance: 0.030094914138317108\n",
      "Train size: [400] hidden size: [19] trial: 27, train_loss: 1.862010, test loss: 0.997565, bias2: 0.9679580926895142, variance: 0.029606893658638\n",
      "Train size: [400] hidden size: [19] trial: 28, train_loss: 1.863209, test loss: 0.997107, bias2: 0.967830240726471, variance: 0.029276570305228233\n",
      "Train size: [400] hidden size: [19] trial: 29, train_loss: 1.867567, test loss: 0.997929, bias2: 0.9679881930351257, variance: 0.029940281063318253\n",
      "Train size: [400] hidden size: [19] trial: 30, train_loss: 1.864215, test loss: 0.997679, bias2: 0.9682808518409729, variance: 0.029398461803793907\n",
      "Train size: [400] hidden size: [19] trial: 31, train_loss: 1.868444, test loss: 0.998143, bias2: 0.9686386585235596, variance: 0.029504796490073204\n",
      "Train size: [400] hidden size: [19] trial: 32, train_loss: 1.872960, test loss: 0.998377, bias2: 0.9685183167457581, variance: 0.029858767986297607\n",
      "Train size: [400] hidden size: [19] trial: 33, train_loss: 1.868260, test loss: 0.998260, bias2: 0.9686346054077148, variance: 0.029625503346323967\n",
      "Train size: [400] hidden size: [19] trial: 34, train_loss: 1.869749, test loss: 0.998235, bias2: 0.9687586426734924, variance: 0.02947656624019146\n",
      "Train size: [400] hidden size: [19] trial: 35, train_loss: 1.879241, test loss: 0.998355, bias2: 0.9682465195655823, variance: 0.030108682811260223\n",
      "Train size: [400] hidden size: [19] trial: 36, train_loss: 1.876984, test loss: 0.998329, bias2: 0.968079149723053, variance: 0.030249767005443573\n",
      "Train size: [400] hidden size: [19] trial: 37, train_loss: 1.876766, test loss: 0.998769, bias2: 0.9687525629997253, variance: 0.03001617267727852\n",
      "Train size: [400] hidden size: [19] trial: 38, train_loss: 1.878432, test loss: 0.998616, bias2: 0.968763530254364, variance: 0.029852109029889107\n",
      "Train size: [400] hidden size: [19] trial: 39, train_loss: 1.882678, test loss: 0.997719, bias2: 0.9678847789764404, variance: 0.029834413900971413\n",
      "Train size: [400] hidden size: [19] trial: 40, train_loss: 1.881096, test loss: 0.997653, bias2: 0.9680985808372498, variance: 0.029554707929491997\n",
      "Train size: [400] hidden size: [19] trial: 41, train_loss: 1.882278, test loss: 0.998676, bias2: 0.9689842462539673, variance: 0.029692037031054497\n",
      "Train size: [400] hidden size: [19] trial: 42, train_loss: 1.885051, test loss: 0.997867, bias2: 0.9681035876274109, variance: 0.02976379543542862\n",
      "Train size: [400] hidden size: [19] trial: 43, train_loss: 1.885175, test loss: 0.998591, bias2: 0.9685406684875488, variance: 0.030049994587898254\n",
      "Train size: [400] hidden size: [19] trial: 44, train_loss: 1.884080, test loss: 0.998646, bias2: 0.9688358306884766, variance: 0.02981029637157917\n",
      "Train size: [400] hidden size: [19] trial: 45, train_loss: 1.884762, test loss: 0.998389, bias2: 0.9684014320373535, variance: 0.029987826943397522\n",
      "Train size: [400] hidden size: [19] trial: 46, train_loss: 1.885483, test loss: 0.998109, bias2: 0.9678626656532288, variance: 0.030246194452047348\n",
      "Train size: [400] hidden size: [19] trial: 47, train_loss: 1.883520, test loss: 0.998207, bias2: 0.9677591919898987, variance: 0.030447931960225105\n",
      "Train size: [400] hidden size: [19] trial: 48, train_loss: 1.887974, test loss: 0.998414, bias2: 0.9672544002532959, variance: 0.03115987218916416\n",
      "Train size: [400] hidden size: [19] trial: 49, train_loss: 1.892521, test loss: 0.998401, bias2: 0.9669414162635803, variance: 0.03145952150225639\n",
      "##################################################\n",
      "Train size: [400] hidden size: [22] trial: 0, train_loss: 2.000282, test loss: 0.988006, bias2: 0.9880062341690063, variance: -2.0679159773440148e-10\n",
      "Train size: [400] hidden size: [22] trial: 1, train_loss: 1.963852, test loss: 0.994106, bias2: 0.9812403917312622, variance: 0.012865990400314331\n",
      "Train size: [400] hidden size: [22] trial: 2, train_loss: 1.920563, test loss: 0.999368, bias2: 0.9819528460502625, variance: 0.01741557940840721\n",
      "Train size: [400] hidden size: [22] trial: 3, train_loss: 1.943011, test loss: 1.002083, bias2: 0.9791622161865234, variance: 0.02292071096599102\n",
      "Train size: [400] hidden size: [22] trial: 4, train_loss: 1.923818, test loss: 1.002754, bias2: 0.9775879383087158, variance: 0.025165678933262825\n",
      "Train size: [400] hidden size: [22] trial: 5, train_loss: 1.911783, test loss: 1.004200, bias2: 0.9755658507347107, variance: 0.028634019196033478\n",
      "Train size: [400] hidden size: [22] trial: 6, train_loss: 1.895102, test loss: 1.002747, bias2: 0.9736689925193787, variance: 0.029077600687742233\n",
      "Train size: [400] hidden size: [22] trial: 7, train_loss: 1.881810, test loss: 1.005060, bias2: 0.9755775332450867, variance: 0.029482528567314148\n",
      "Train size: [400] hidden size: [22] trial: 8, train_loss: 1.875482, test loss: 1.004617, bias2: 0.9732644557952881, variance: 0.03135297819972038\n",
      "Train size: [400] hidden size: [22] trial: 9, train_loss: 1.864063, test loss: 1.004697, bias2: 0.9733046293258667, variance: 0.031392090022563934\n",
      "Train size: [400] hidden size: [22] trial: 10, train_loss: 1.848007, test loss: 1.002872, bias2: 0.9704834818840027, variance: 0.03238828107714653\n",
      "Train size: [400] hidden size: [22] trial: 11, train_loss: 1.842743, test loss: 1.002970, bias2: 0.9712051153182983, variance: 0.03176449239253998\n",
      "Train size: [400] hidden size: [22] trial: 12, train_loss: 1.841485, test loss: 1.000110, bias2: 0.9679763317108154, variance: 0.0321333147585392\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [22] trial: 13, train_loss: 1.831416, test loss: 0.998808, bias2: 0.9663872122764587, variance: 0.03242047503590584\n",
      "Train size: [400] hidden size: [22] trial: 14, train_loss: 1.835993, test loss: 0.998153, bias2: 0.966054379940033, variance: 0.032098814845085144\n",
      "Train size: [400] hidden size: [22] trial: 15, train_loss: 1.843927, test loss: 0.996564, bias2: 0.9650851488113403, variance: 0.031479015946388245\n",
      "Train size: [400] hidden size: [22] trial: 16, train_loss: 1.840328, test loss: 0.997040, bias2: 0.965967059135437, variance: 0.031073102727532387\n",
      "Train size: [400] hidden size: [22] trial: 17, train_loss: 1.846576, test loss: 0.996607, bias2: 0.9649937152862549, variance: 0.031613174825906754\n",
      "Train size: [400] hidden size: [22] trial: 18, train_loss: 1.855762, test loss: 0.996556, bias2: 0.9649472832679749, variance: 0.031608518213033676\n",
      "Train size: [400] hidden size: [22] trial: 19, train_loss: 1.856645, test loss: 0.996430, bias2: 0.9644795060157776, variance: 0.03195072337985039\n",
      "Train size: [400] hidden size: [22] trial: 20, train_loss: 1.862404, test loss: 0.996049, bias2: 0.9636822938919067, variance: 0.032366521656513214\n",
      "Train size: [400] hidden size: [22] trial: 21, train_loss: 1.862283, test loss: 0.995370, bias2: 0.963113009929657, variance: 0.0322565957903862\n",
      "Train size: [400] hidden size: [22] trial: 22, train_loss: 1.856320, test loss: 0.995623, bias2: 0.962841808795929, variance: 0.03278094902634621\n",
      "Train size: [400] hidden size: [22] trial: 23, train_loss: 1.853403, test loss: 0.996084, bias2: 0.9627211689949036, variance: 0.03336260840296745\n",
      "Train size: [400] hidden size: [22] trial: 24, train_loss: 1.851691, test loss: 0.996388, bias2: 0.9619922637939453, variance: 0.034395456314086914\n",
      "Train size: [400] hidden size: [22] trial: 25, train_loss: 1.859978, test loss: 0.996299, bias2: 0.9595409035682678, variance: 0.03675776347517967\n",
      "Train size: [400] hidden size: [22] trial: 26, train_loss: 1.856701, test loss: 0.996427, bias2: 0.9591024518013, variance: 0.037324149161577225\n",
      "Train size: [400] hidden size: [22] trial: 27, train_loss: 1.864730, test loss: 0.996350, bias2: 0.9586007595062256, variance: 0.037749119102954865\n",
      "Train size: [400] hidden size: [22] trial: 28, train_loss: 1.862885, test loss: 0.995671, bias2: 0.9571487903594971, variance: 0.03852269425988197\n",
      "Train size: [400] hidden size: [22] trial: 29, train_loss: 1.859833, test loss: 0.995419, bias2: 0.9571130275726318, variance: 0.03830614686012268\n",
      "Train size: [400] hidden size: [22] trial: 30, train_loss: 1.863650, test loss: 0.996172, bias2: 0.9573284983634949, variance: 0.038843367248773575\n",
      "Train size: [400] hidden size: [22] trial: 31, train_loss: 1.869765, test loss: 0.996382, bias2: 0.957788348197937, variance: 0.038593560457229614\n",
      "Train size: [400] hidden size: [22] trial: 32, train_loss: 1.876227, test loss: 0.996733, bias2: 0.9580530524253845, variance: 0.038679663091897964\n",
      "Train size: [400] hidden size: [22] trial: 33, train_loss: 1.877407, test loss: 0.996696, bias2: 0.958017110824585, variance: 0.038679271936416626\n",
      "Train size: [400] hidden size: [22] trial: 34, train_loss: 1.881195, test loss: 0.997165, bias2: 0.9588270783424377, variance: 0.038338299840688705\n",
      "Train size: [400] hidden size: [22] trial: 35, train_loss: 1.877705, test loss: 0.996812, bias2: 0.9585906863212585, variance: 0.038221172988414764\n",
      "Train size: [400] hidden size: [22] trial: 36, train_loss: 1.884159, test loss: 0.997743, bias2: 0.959498941898346, variance: 0.03824366256594658\n",
      "Train size: [400] hidden size: [22] trial: 37, train_loss: 1.883211, test loss: 0.997553, bias2: 0.9593858122825623, variance: 0.03816690295934677\n",
      "Train size: [400] hidden size: [22] trial: 38, train_loss: 1.884722, test loss: 0.997617, bias2: 0.9593164324760437, variance: 0.038300465792417526\n",
      "Train size: [400] hidden size: [22] trial: 39, train_loss: 1.880868, test loss: 0.998204, bias2: 0.9599899053573608, variance: 0.03821391984820366\n",
      "Train size: [400] hidden size: [22] trial: 40, train_loss: 1.882481, test loss: 0.998015, bias2: 0.9597693085670471, variance: 0.03824590519070625\n",
      "Train size: [400] hidden size: [22] trial: 41, train_loss: 1.885428, test loss: 0.998200, bias2: 0.9602132439613342, variance: 0.03798653930425644\n",
      "Train size: [400] hidden size: [22] trial: 42, train_loss: 1.886512, test loss: 0.997721, bias2: 0.9600776433944702, variance: 0.03764314576983452\n",
      "Train size: [400] hidden size: [22] trial: 43, train_loss: 1.894139, test loss: 0.997801, bias2: 0.9600077867507935, variance: 0.03779333829879761\n",
      "Train size: [400] hidden size: [22] trial: 44, train_loss: 1.892881, test loss: 0.997675, bias2: 0.9596902132034302, variance: 0.03798522800207138\n",
      "Train size: [400] hidden size: [22] trial: 45, train_loss: 1.894933, test loss: 0.998136, bias2: 0.9595794677734375, variance: 0.038556747138500214\n",
      "Train size: [400] hidden size: [22] trial: 46, train_loss: 1.897327, test loss: 0.997846, bias2: 0.9595626592636108, variance: 0.03828369081020355\n",
      "Train size: [400] hidden size: [22] trial: 47, train_loss: 1.896874, test loss: 0.998285, bias2: 0.9598979949951172, variance: 0.03838726505637169\n",
      "Train size: [400] hidden size: [22] trial: 48, train_loss: 1.895432, test loss: 0.998502, bias2: 0.960352897644043, variance: 0.03814862668514252\n",
      "Train size: [400] hidden size: [22] trial: 49, train_loss: 1.891012, test loss: 0.999160, bias2: 0.9612331986427307, variance: 0.0379272922873497\n",
      "##################################################\n",
      "Train size: [400] hidden size: [25] trial: 0, train_loss: 1.840087, test loss: 1.008352, bias2: 1.0083518028259277, variance: 4.865684938293313e-11\n",
      "Train size: [400] hidden size: [25] trial: 1, train_loss: 1.840185, test loss: 0.999301, bias2: 0.9710261225700378, variance: 0.028275128453969955\n",
      "Train size: [400] hidden size: [25] trial: 2, train_loss: 1.865368, test loss: 1.000424, bias2: 0.9657140970230103, variance: 0.03470979258418083\n",
      "Train size: [400] hidden size: [25] trial: 3, train_loss: 1.862164, test loss: 1.003142, bias2: 0.9639941453933716, variance: 0.03914783149957657\n",
      "Train size: [400] hidden size: [25] trial: 4, train_loss: 1.871215, test loss: 1.010097, bias2: 0.9656404852867126, variance: 0.044456884264945984\n",
      "Train size: [400] hidden size: [25] trial: 5, train_loss: 1.850548, test loss: 1.007160, bias2: 0.9599168300628662, variance: 0.04724324494600296\n",
      "Train size: [400] hidden size: [25] trial: 6, train_loss: 1.831587, test loss: 1.005002, bias2: 0.9591060280799866, variance: 0.04589636251330376\n",
      "Train size: [400] hidden size: [25] trial: 7, train_loss: 1.813403, test loss: 1.000686, bias2: 0.9542052745819092, variance: 0.04648063704371452\n",
      "Train size: [400] hidden size: [25] trial: 8, train_loss: 1.822808, test loss: 0.999118, bias2: 0.9543944001197815, variance: 0.04472362622618675\n",
      "Train size: [400] hidden size: [25] trial: 9, train_loss: 1.817026, test loss: 0.998514, bias2: 0.9545767307281494, variance: 0.04393724352121353\n",
      "Train size: [400] hidden size: [25] trial: 10, train_loss: 1.813162, test loss: 0.999279, bias2: 0.953305721282959, variance: 0.0459727942943573\n",
      "Train size: [400] hidden size: [25] trial: 11, train_loss: 1.824326, test loss: 0.998499, bias2: 0.9520015716552734, variance: 0.04649783670902252\n",
      "Train size: [400] hidden size: [25] trial: 12, train_loss: 1.833863, test loss: 0.997326, bias2: 0.9511690139770508, variance: 0.04615709185600281\n",
      "Train size: [400] hidden size: [25] trial: 13, train_loss: 1.826858, test loss: 0.995097, bias2: 0.9492595791816711, variance: 0.04583759605884552\n",
      "Train size: [400] hidden size: [25] trial: 14, train_loss: 1.861257, test loss: 0.996742, bias2: 0.9510591626167297, variance: 0.045683179050683975\n",
      "Train size: [400] hidden size: [25] trial: 15, train_loss: 1.865724, test loss: 0.996295, bias2: 0.9495183229446411, variance: 0.046776823699474335\n",
      "Train size: [400] hidden size: [25] trial: 16, train_loss: 1.863664, test loss: 0.997691, bias2: 0.9511178731918335, variance: 0.04657283425331116\n",
      "Train size: [400] hidden size: [25] trial: 17, train_loss: 1.866663, test loss: 0.998445, bias2: 0.9520654082298279, variance: 0.04638003185391426\n",
      "Train size: [400] hidden size: [25] trial: 18, train_loss: 1.873401, test loss: 0.998674, bias2: 0.9530128836631775, variance: 0.045661453157663345\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [25] trial: 19, train_loss: 1.884846, test loss: 0.999354, bias2: 0.9538995027542114, variance: 0.04545453190803528\n",
      "Train size: [400] hidden size: [25] trial: 20, train_loss: 1.879849, test loss: 0.999442, bias2: 0.9539440870285034, variance: 0.04549795761704445\n",
      "Train size: [400] hidden size: [25] trial: 21, train_loss: 1.877569, test loss: 0.999438, bias2: 0.9545893669128418, variance: 0.044848475605249405\n",
      "Train size: [400] hidden size: [25] trial: 22, train_loss: 1.879842, test loss: 0.999309, bias2: 0.9549222588539124, variance: 0.04438721761107445\n",
      "Train size: [400] hidden size: [25] trial: 23, train_loss: 1.867658, test loss: 1.000249, bias2: 0.9553016424179077, variance: 0.04494773969054222\n",
      "Train size: [400] hidden size: [25] trial: 24, train_loss: 1.863579, test loss: 1.000700, bias2: 0.9553266763687134, variance: 0.045372869819402695\n",
      "Train size: [400] hidden size: [25] trial: 25, train_loss: 1.855401, test loss: 1.000132, bias2: 0.9552908539772034, variance: 0.04484110325574875\n",
      "Train size: [400] hidden size: [25] trial: 26, train_loss: 1.857786, test loss: 1.000893, bias2: 0.9565338492393494, variance: 0.044359490275382996\n",
      "Train size: [400] hidden size: [25] trial: 27, train_loss: 1.859948, test loss: 1.001523, bias2: 0.9562785029411316, variance: 0.04524403065443039\n",
      "Train size: [400] hidden size: [25] trial: 28, train_loss: 1.859705, test loss: 1.001322, bias2: 0.9561702013015747, variance: 0.045152194797992706\n",
      "Train size: [400] hidden size: [25] trial: 29, train_loss: 1.860600, test loss: 1.000954, bias2: 0.9559470415115356, variance: 0.045006632804870605\n",
      "Train size: [400] hidden size: [25] trial: 30, train_loss: 1.861768, test loss: 1.001584, bias2: 0.9566702246665955, variance: 0.04491405561566353\n",
      "Train size: [400] hidden size: [25] trial: 31, train_loss: 1.867662, test loss: 1.002137, bias2: 0.957547128200531, variance: 0.04458970949053764\n",
      "Train size: [400] hidden size: [25] trial: 32, train_loss: 1.865019, test loss: 1.001587, bias2: 0.957103431224823, variance: 0.04448394477367401\n",
      "Train size: [400] hidden size: [25] trial: 33, train_loss: 1.861997, test loss: 1.001038, bias2: 0.9569011926651001, variance: 0.04413673281669617\n",
      "Train size: [400] hidden size: [25] trial: 34, train_loss: 1.861424, test loss: 1.001770, bias2: 0.9571846127510071, variance: 0.044585395604372025\n",
      "Train size: [400] hidden size: [25] trial: 35, train_loss: 1.857446, test loss: 1.001539, bias2: 0.9562785625457764, variance: 0.04526052623987198\n",
      "Train size: [400] hidden size: [25] trial: 36, train_loss: 1.859148, test loss: 1.001140, bias2: 0.9563904404640198, variance: 0.044749803841114044\n",
      "Train size: [400] hidden size: [25] trial: 37, train_loss: 1.861261, test loss: 1.001180, bias2: 0.9564676880836487, variance: 0.04471258074045181\n",
      "Train size: [400] hidden size: [25] trial: 38, train_loss: 1.860622, test loss: 1.000687, bias2: 0.9559852480888367, variance: 0.04470137134194374\n",
      "Train size: [400] hidden size: [25] trial: 39, train_loss: 1.856645, test loss: 1.000432, bias2: 0.9555127620697021, variance: 0.044919464737176895\n",
      "Train size: [400] hidden size: [25] trial: 40, train_loss: 1.855175, test loss: 1.000638, bias2: 0.9552705883979797, variance: 0.04536740854382515\n",
      "Train size: [400] hidden size: [25] trial: 41, train_loss: 1.857938, test loss: 1.001317, bias2: 0.9560865759849548, variance: 0.0452306903898716\n",
      "Train size: [400] hidden size: [25] trial: 42, train_loss: 1.856571, test loss: 1.001686, bias2: 0.9568724632263184, variance: 0.0448138602077961\n",
      "Train size: [400] hidden size: [25] trial: 43, train_loss: 1.855877, test loss: 1.002153, bias2: 0.9568237066268921, variance: 0.04532906413078308\n",
      "Train size: [400] hidden size: [25] trial: 44, train_loss: 1.855557, test loss: 1.002649, bias2: 0.9572013020515442, variance: 0.04544743523001671\n",
      "Train size: [400] hidden size: [25] trial: 45, train_loss: 1.864774, test loss: 1.002786, bias2: 0.9575273394584656, variance: 0.04525906220078468\n",
      "Train size: [400] hidden size: [25] trial: 46, train_loss: 1.867337, test loss: 1.002790, bias2: 0.9578300714492798, variance: 0.04496002197265625\n",
      "Train size: [400] hidden size: [25] trial: 47, train_loss: 1.867282, test loss: 1.002479, bias2: 0.9577133059501648, variance: 0.04476531222462654\n",
      "Train size: [400] hidden size: [25] trial: 48, train_loss: 1.870131, test loss: 1.002648, bias2: 0.9578869342803955, variance: 0.0447610467672348\n",
      "Train size: [400] hidden size: [25] trial: 49, train_loss: 1.870327, test loss: 1.002857, bias2: 0.9581774473190308, variance: 0.04467961564660072\n",
      "##################################################\n",
      "Train size: [400] hidden size: [29] trial: 0, train_loss: 2.024167, test loss: 0.960199, bias2: 0.9601985812187195, variance: -4.379116513852921e-10\n",
      "Train size: [400] hidden size: [29] trial: 1, train_loss: 1.932014, test loss: 0.982602, bias2: 0.9569432735443115, variance: 0.02565922401845455\n",
      "Train size: [400] hidden size: [29] trial: 2, train_loss: 1.871432, test loss: 0.980250, bias2: 0.9495516419410706, variance: 0.030698254704475403\n",
      "Train size: [400] hidden size: [29] trial: 3, train_loss: 1.889698, test loss: 0.986227, bias2: 0.9535720348358154, variance: 0.03265461325645447\n",
      "Train size: [400] hidden size: [29] trial: 4, train_loss: 1.919564, test loss: 0.985883, bias2: 0.9530389308929443, variance: 0.03284445405006409\n",
      "Train size: [400] hidden size: [29] trial: 5, train_loss: 1.891356, test loss: 0.983929, bias2: 0.9502865076065063, variance: 0.033642418682575226\n",
      "Train size: [400] hidden size: [29] trial: 6, train_loss: 1.897632, test loss: 0.984327, bias2: 0.9476000666618347, variance: 0.03672730177640915\n",
      "Train size: [400] hidden size: [29] trial: 7, train_loss: 1.899618, test loss: 0.990218, bias2: 0.9506810903549194, variance: 0.039536505937576294\n",
      "Train size: [400] hidden size: [29] trial: 8, train_loss: 1.935166, test loss: 0.988422, bias2: 0.9469150304794312, variance: 0.041506972163915634\n",
      "Train size: [400] hidden size: [29] trial: 9, train_loss: 1.914252, test loss: 0.985987, bias2: 0.9430862069129944, variance: 0.042900629341602325\n",
      "Train size: [400] hidden size: [29] trial: 10, train_loss: 1.929518, test loss: 0.987228, bias2: 0.9452701210975647, variance: 0.04195806756615639\n",
      "Train size: [400] hidden size: [29] trial: 11, train_loss: 1.914807, test loss: 0.988124, bias2: 0.9461828470230103, variance: 0.0419410765171051\n",
      "Train size: [400] hidden size: [29] trial: 12, train_loss: 1.901940, test loss: 0.987834, bias2: 0.9459423422813416, variance: 0.04189181327819824\n",
      "Train size: [400] hidden size: [29] trial: 13, train_loss: 1.905120, test loss: 0.987520, bias2: 0.9459912776947021, variance: 0.04152899608016014\n",
      "Train size: [400] hidden size: [29] trial: 14, train_loss: 1.904492, test loss: 0.990280, bias2: 0.9489631056785583, variance: 0.041317179799079895\n",
      "Train size: [400] hidden size: [29] trial: 15, train_loss: 1.891977, test loss: 0.991724, bias2: 0.9488697648048401, variance: 0.042854487895965576\n",
      "Train size: [400] hidden size: [29] trial: 16, train_loss: 1.888625, test loss: 0.992864, bias2: 0.9494422078132629, variance: 0.04342159256339073\n",
      "Train size: [400] hidden size: [29] trial: 17, train_loss: 1.889230, test loss: 0.993725, bias2: 0.9503989815711975, variance: 0.04332580417394638\n",
      "Train size: [400] hidden size: [29] trial: 18, train_loss: 1.876812, test loss: 0.994625, bias2: 0.9507019519805908, variance: 0.04392280802130699\n",
      "Train size: [400] hidden size: [29] trial: 19, train_loss: 1.872351, test loss: 0.994002, bias2: 0.9494154453277588, variance: 0.044586729258298874\n",
      "Train size: [400] hidden size: [29] trial: 20, train_loss: 1.886921, test loss: 0.994512, bias2: 0.9498409032821655, variance: 0.04467058181762695\n",
      "Train size: [400] hidden size: [29] trial: 21, train_loss: 1.891426, test loss: 0.994506, bias2: 0.9498562812805176, variance: 0.044649455696344376\n",
      "Train size: [400] hidden size: [29] trial: 22, train_loss: 1.894963, test loss: 0.995705, bias2: 0.9504863023757935, variance: 0.0452190600335598\n",
      "Train size: [400] hidden size: [29] trial: 23, train_loss: 1.880896, test loss: 0.995690, bias2: 0.95053631067276, variance: 0.0451536662876606\n",
      "Train size: [400] hidden size: [29] trial: 24, train_loss: 1.882474, test loss: 0.997152, bias2: 0.9515445828437805, variance: 0.045607611536979675\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [29] trial: 25, train_loss: 1.882111, test loss: 0.996815, bias2: 0.9519155025482178, variance: 0.04490001127123833\n",
      "Train size: [400] hidden size: [29] trial: 26, train_loss: 1.878143, test loss: 0.996258, bias2: 0.9516201615333557, variance: 0.04463758319616318\n",
      "Train size: [400] hidden size: [29] trial: 27, train_loss: 1.877694, test loss: 0.995642, bias2: 0.9516698718070984, variance: 0.043971896171569824\n",
      "Train size: [400] hidden size: [29] trial: 28, train_loss: 1.877849, test loss: 0.995355, bias2: 0.9507625102996826, variance: 0.04459289088845253\n",
      "Train size: [400] hidden size: [29] trial: 29, train_loss: 1.877701, test loss: 0.995480, bias2: 0.9513686299324036, variance: 0.04411159083247185\n",
      "Train size: [400] hidden size: [29] trial: 30, train_loss: 1.875550, test loss: 0.994925, bias2: 0.9506654739379883, variance: 0.044259410351514816\n",
      "Train size: [400] hidden size: [29] trial: 31, train_loss: 1.867583, test loss: 0.994081, bias2: 0.9500055313110352, variance: 0.04407575726509094\n",
      "Train size: [400] hidden size: [29] trial: 32, train_loss: 1.868558, test loss: 0.992824, bias2: 0.9480939507484436, variance: 0.04472995176911354\n",
      "Train size: [400] hidden size: [29] trial: 33, train_loss: 1.866572, test loss: 0.993243, bias2: 0.948532223701477, variance: 0.04471077024936676\n",
      "Train size: [400] hidden size: [29] trial: 34, train_loss: 1.870635, test loss: 0.993359, bias2: 0.9482108950614929, variance: 0.04514824599027634\n",
      "Train size: [400] hidden size: [29] trial: 35, train_loss: 1.872181, test loss: 0.993566, bias2: 0.9484658241271973, variance: 0.04510033130645752\n",
      "Train size: [400] hidden size: [29] trial: 36, train_loss: 1.867864, test loss: 0.993568, bias2: 0.9484304189682007, variance: 0.04513723403215408\n",
      "Train size: [400] hidden size: [29] trial: 37, train_loss: 1.872535, test loss: 0.994425, bias2: 0.9495628476142883, variance: 0.044862426817417145\n",
      "Train size: [400] hidden size: [29] trial: 38, train_loss: 1.874910, test loss: 0.994521, bias2: 0.949618935585022, variance: 0.04490223154425621\n",
      "Train size: [400] hidden size: [29] trial: 39, train_loss: 1.874076, test loss: 0.993973, bias2: 0.9488387107849121, variance: 0.04513459652662277\n",
      "Train size: [400] hidden size: [29] trial: 40, train_loss: 1.873455, test loss: 0.994408, bias2: 0.9489430785179138, variance: 0.04546523839235306\n",
      "Train size: [400] hidden size: [29] trial: 41, train_loss: 1.869769, test loss: 0.994504, bias2: 0.9488756656646729, variance: 0.04562831670045853\n",
      "Train size: [400] hidden size: [29] trial: 42, train_loss: 1.871554, test loss: 0.995240, bias2: 0.94950270652771, variance: 0.04573744535446167\n",
      "Train size: [400] hidden size: [29] trial: 43, train_loss: 1.868162, test loss: 0.995361, bias2: 0.949830949306488, variance: 0.04553001746535301\n",
      "Train size: [400] hidden size: [29] trial: 44, train_loss: 1.866880, test loss: 0.995652, bias2: 0.9499223828315735, variance: 0.045729778707027435\n",
      "Train size: [400] hidden size: [29] trial: 45, train_loss: 1.867139, test loss: 0.995164, bias2: 0.949238121509552, variance: 0.04592623934149742\n",
      "Train size: [400] hidden size: [29] trial: 46, train_loss: 1.863964, test loss: 0.995389, bias2: 0.9489482641220093, variance: 0.046440523117780685\n",
      "Train size: [400] hidden size: [29] trial: 47, train_loss: 1.861811, test loss: 0.995313, bias2: 0.9490781426429749, variance: 0.04623518884181976\n",
      "Train size: [400] hidden size: [29] trial: 48, train_loss: 1.858019, test loss: 0.995603, bias2: 0.9489455223083496, variance: 0.04665711522102356\n",
      "Train size: [400] hidden size: [29] trial: 49, train_loss: 1.854373, test loss: 0.995996, bias2: 0.949150800704956, variance: 0.04684542864561081\n",
      "##################################################\n",
      "Train size: [400] hidden size: [33] trial: 0, train_loss: 1.939384, test loss: 0.995593, bias2: 0.9955928921699524, variance: 1.9462739753173253e-10\n",
      "Train size: [400] hidden size: [33] trial: 1, train_loss: 1.907885, test loss: 1.018367, bias2: 0.9813730120658875, variance: 0.03699441999197006\n",
      "Train size: [400] hidden size: [33] trial: 2, train_loss: 1.904414, test loss: 1.010499, bias2: 0.9686071276664734, variance: 0.041891373693943024\n",
      "Train size: [400] hidden size: [33] trial: 3, train_loss: 1.938177, test loss: 1.004720, bias2: 0.9587112665176392, variance: 0.046008214354515076\n",
      "Train size: [400] hidden size: [33] trial: 4, train_loss: 1.950647, test loss: 1.012389, bias2: 0.9571855664253235, variance: 0.05520383641123772\n",
      "Train size: [400] hidden size: [33] trial: 5, train_loss: 1.923070, test loss: 1.011864, bias2: 0.9576006531715393, variance: 0.05426354706287384\n",
      "Train size: [400] hidden size: [33] trial: 6, train_loss: 1.929761, test loss: 1.009324, bias2: 0.9541847705841064, variance: 0.05513916537165642\n",
      "Train size: [400] hidden size: [33] trial: 7, train_loss: 1.926658, test loss: 1.003270, bias2: 0.9500263333320618, variance: 0.05324367806315422\n",
      "Train size: [400] hidden size: [33] trial: 8, train_loss: 1.892488, test loss: 1.002743, bias2: 0.9490662217140198, variance: 0.05367689207196236\n",
      "Train size: [400] hidden size: [33] trial: 9, train_loss: 1.889579, test loss: 1.006220, bias2: 0.9529212117195129, variance: 0.05329877883195877\n",
      "Train size: [400] hidden size: [33] trial: 10, train_loss: 1.904178, test loss: 1.005747, bias2: 0.9521515965461731, variance: 0.05359547957777977\n",
      "Train size: [400] hidden size: [33] trial: 11, train_loss: 1.909239, test loss: 1.004228, bias2: 0.9500959515571594, variance: 0.054132066667079926\n",
      "Train size: [400] hidden size: [33] trial: 12, train_loss: 1.905774, test loss: 1.005804, bias2: 0.951602578163147, variance: 0.05420173332095146\n",
      "Train size: [400] hidden size: [33] trial: 13, train_loss: 1.903046, test loss: 1.004190, bias2: 0.9488146305084229, variance: 0.05537530779838562\n",
      "Train size: [400] hidden size: [33] trial: 14, train_loss: 1.894966, test loss: 1.002876, bias2: 0.9484902024269104, variance: 0.054385360330343246\n",
      "Train size: [400] hidden size: [33] trial: 15, train_loss: 1.886750, test loss: 1.001203, bias2: 0.9470052123069763, variance: 0.05419807881116867\n",
      "Train size: [400] hidden size: [33] trial: 16, train_loss: 1.894692, test loss: 1.000875, bias2: 0.9461688995361328, variance: 0.05470624566078186\n",
      "Train size: [400] hidden size: [33] trial: 17, train_loss: 1.885060, test loss: 1.001789, bias2: 0.9455577731132507, variance: 0.0562313087284565\n",
      "Train size: [400] hidden size: [33] trial: 18, train_loss: 1.891145, test loss: 1.002259, bias2: 0.9454407095909119, variance: 0.05681877210736275\n",
      "Train size: [400] hidden size: [33] trial: 19, train_loss: 1.884057, test loss: 1.001300, bias2: 0.9448993802070618, variance: 0.056400809437036514\n",
      "Train size: [400] hidden size: [33] trial: 20, train_loss: 1.897245, test loss: 1.001152, bias2: 0.9453123807907104, variance: 0.055839672684669495\n",
      "Train size: [400] hidden size: [33] trial: 21, train_loss: 1.897044, test loss: 1.001796, bias2: 0.9449625611305237, variance: 0.05683354288339615\n",
      "Train size: [400] hidden size: [33] trial: 22, train_loss: 1.883433, test loss: 1.001955, bias2: 0.9449644088745117, variance: 0.056991107761859894\n",
      "Train size: [400] hidden size: [33] trial: 23, train_loss: 1.882457, test loss: 1.001382, bias2: 0.944850504398346, variance: 0.05653161182999611\n",
      "Train size: [400] hidden size: [33] trial: 24, train_loss: 1.879422, test loss: 1.001666, bias2: 0.9450052976608276, variance: 0.05666040629148483\n",
      "Train size: [400] hidden size: [33] trial: 25, train_loss: 1.887103, test loss: 1.001466, bias2: 0.9446395635604858, variance: 0.056826502084732056\n",
      "Train size: [400] hidden size: [33] trial: 26, train_loss: 1.882827, test loss: 1.002484, bias2: 0.9447980523109436, variance: 0.057686131447553635\n",
      "Train size: [400] hidden size: [33] trial: 27, train_loss: 1.887212, test loss: 1.002429, bias2: 0.9448319673538208, variance: 0.05759681761264801\n",
      "Train size: [400] hidden size: [33] trial: 28, train_loss: 1.883879, test loss: 1.001883, bias2: 0.9450910687446594, variance: 0.056791819632053375\n",
      "Train size: [400] hidden size: [33] trial: 29, train_loss: 1.881866, test loss: 1.001236, bias2: 0.9444515109062195, variance: 0.056784458458423615\n",
      "Train size: [400] hidden size: [33] trial: 30, train_loss: 1.879895, test loss: 0.999839, bias2: 0.9434006810188293, variance: 0.056437890976667404\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [33] trial: 31, train_loss: 1.885101, test loss: 0.999573, bias2: 0.9433795809745789, variance: 0.05619369447231293\n",
      "Train size: [400] hidden size: [33] trial: 32, train_loss: 1.881444, test loss: 0.998756, bias2: 0.9419907331466675, variance: 0.056765198707580566\n",
      "Train size: [400] hidden size: [33] trial: 33, train_loss: 1.885402, test loss: 0.998735, bias2: 0.9415179491043091, variance: 0.05721740797162056\n",
      "Train size: [400] hidden size: [33] trial: 34, train_loss: 1.884920, test loss: 0.997822, bias2: 0.9405924081802368, variance: 0.057229604572057724\n",
      "Train size: [400] hidden size: [33] trial: 35, train_loss: 1.887654, test loss: 0.997246, bias2: 0.9402982592582703, variance: 0.05694732815027237\n",
      "Train size: [400] hidden size: [33] trial: 36, train_loss: 1.884654, test loss: 0.996940, bias2: 0.9404189586639404, variance: 0.05652111768722534\n",
      "Train size: [400] hidden size: [33] trial: 37, train_loss: 1.881568, test loss: 0.997427, bias2: 0.9407507181167603, variance: 0.05667659640312195\n",
      "Train size: [400] hidden size: [33] trial: 38, train_loss: 1.882780, test loss: 0.997745, bias2: 0.9409661889076233, variance: 0.056778375059366226\n",
      "Train size: [400] hidden size: [33] trial: 39, train_loss: 1.883159, test loss: 0.998737, bias2: 0.9412463903427124, variance: 0.05749009922146797\n",
      "Train size: [400] hidden size: [33] trial: 40, train_loss: 1.880992, test loss: 0.999132, bias2: 0.9415112137794495, variance: 0.05762050300836563\n",
      "Train size: [400] hidden size: [33] trial: 41, train_loss: 1.880014, test loss: 0.999377, bias2: 0.9409658312797546, variance: 0.05841163545846939\n",
      "Train size: [400] hidden size: [33] trial: 42, train_loss: 1.877950, test loss: 0.998491, bias2: 0.9391961097717285, variance: 0.05929534137248993\n",
      "Train size: [400] hidden size: [33] trial: 43, train_loss: 1.874521, test loss: 0.999151, bias2: 0.9401220679283142, variance: 0.05902935564517975\n",
      "Train size: [400] hidden size: [33] trial: 44, train_loss: 1.873103, test loss: 0.999598, bias2: 0.9404956102371216, variance: 0.05910211428999901\n",
      "Train size: [400] hidden size: [33] trial: 45, train_loss: 1.872477, test loss: 1.000447, bias2: 0.9405993223190308, variance: 0.05984769016504288\n",
      "Train size: [400] hidden size: [33] trial: 46, train_loss: 1.871662, test loss: 1.000629, bias2: 0.9408572912216187, variance: 0.05977155268192291\n",
      "Train size: [400] hidden size: [33] trial: 47, train_loss: 1.871480, test loss: 1.001075, bias2: 0.9407421946525574, variance: 0.06033233180642128\n",
      "Train size: [400] hidden size: [33] trial: 48, train_loss: 1.874927, test loss: 1.000768, bias2: 0.9406790137290955, variance: 0.06008893623948097\n",
      "Train size: [400] hidden size: [33] trial: 49, train_loss: 1.875117, test loss: 1.001738, bias2: 0.9406729936599731, variance: 0.06106521561741829\n",
      "##################################################\n",
      "Train size: [400] hidden size: [38] trial: 0, train_loss: 1.791404, test loss: 1.005745, bias2: 1.0057448148727417, variance: -9.731369876586626e-11\n",
      "Train size: [400] hidden size: [38] trial: 1, train_loss: 1.735330, test loss: 1.000965, bias2: 0.9595437049865723, variance: 0.04142150655388832\n",
      "Train size: [400] hidden size: [38] trial: 2, train_loss: 1.811561, test loss: 0.984809, bias2: 0.9399619102478027, variance: 0.044847555458545685\n",
      "Train size: [400] hidden size: [38] trial: 3, train_loss: 1.901155, test loss: 0.990662, bias2: 0.9383894801139832, variance: 0.05227293074131012\n",
      "Train size: [400] hidden size: [38] trial: 4, train_loss: 1.880074, test loss: 0.994592, bias2: 0.9422460794448853, variance: 0.05234600603580475\n",
      "Train size: [400] hidden size: [38] trial: 5, train_loss: 1.871650, test loss: 0.994391, bias2: 0.9393026232719421, variance: 0.05508870258927345\n",
      "Train size: [400] hidden size: [38] trial: 6, train_loss: 1.854485, test loss: 0.996657, bias2: 0.9419554471969604, variance: 0.054701875895261765\n",
      "Train size: [400] hidden size: [38] trial: 7, train_loss: 1.846568, test loss: 1.000141, bias2: 0.9435895085334778, variance: 0.05655102804303169\n",
      "Train size: [400] hidden size: [38] trial: 8, train_loss: 1.871703, test loss: 0.997947, bias2: 0.9388706088066101, variance: 0.05907607451081276\n",
      "Train size: [400] hidden size: [38] trial: 9, train_loss: 1.876297, test loss: 0.999140, bias2: 0.9388101100921631, variance: 0.06032995134592056\n",
      "Train size: [400] hidden size: [38] trial: 10, train_loss: 1.855789, test loss: 1.001066, bias2: 0.9403504133224487, variance: 0.060715802013874054\n",
      "Train size: [400] hidden size: [38] trial: 11, train_loss: 1.843077, test loss: 1.000683, bias2: 0.9409467577934265, variance: 0.05973665416240692\n",
      "Train size: [400] hidden size: [38] trial: 12, train_loss: 1.832797, test loss: 0.999162, bias2: 0.9393163919448853, variance: 0.05984611436724663\n",
      "Train size: [400] hidden size: [38] trial: 13, train_loss: 1.837436, test loss: 0.998813, bias2: 0.9370052814483643, variance: 0.061808109283447266\n",
      "Train size: [400] hidden size: [38] trial: 14, train_loss: 1.852266, test loss: 0.997856, bias2: 0.9372769594192505, variance: 0.060579076409339905\n",
      "Train size: [400] hidden size: [38] trial: 15, train_loss: 1.834717, test loss: 0.998086, bias2: 0.937677264213562, variance: 0.06040824204683304\n",
      "Train size: [400] hidden size: [38] trial: 16, train_loss: 1.842481, test loss: 0.999054, bias2: 0.9369336366653442, variance: 0.06212043762207031\n",
      "Train size: [400] hidden size: [38] trial: 17, train_loss: 1.825502, test loss: 0.999124, bias2: 0.9365975260734558, variance: 0.06252653151750565\n",
      "Train size: [400] hidden size: [38] trial: 18, train_loss: 1.832106, test loss: 0.999949, bias2: 0.9366475939750671, variance: 0.06330161541700363\n",
      "Train size: [400] hidden size: [38] trial: 19, train_loss: 1.831909, test loss: 1.000769, bias2: 0.937866747379303, variance: 0.06290238350629807\n",
      "Train size: [400] hidden size: [38] trial: 20, train_loss: 1.831550, test loss: 1.002529, bias2: 0.93654865026474, variance: 0.06598059087991714\n",
      "Train size: [400] hidden size: [38] trial: 21, train_loss: 1.827766, test loss: 1.002683, bias2: 0.9360679984092712, variance: 0.06661529839038849\n",
      "Train size: [400] hidden size: [38] trial: 22, train_loss: 1.829518, test loss: 1.001419, bias2: 0.9353725910186768, variance: 0.06604611873626709\n",
      "Train size: [400] hidden size: [38] trial: 23, train_loss: 1.832856, test loss: 1.000431, bias2: 0.9347465634346008, variance: 0.06568460166454315\n",
      "Train size: [400] hidden size: [38] trial: 24, train_loss: 1.834025, test loss: 1.000188, bias2: 0.934985876083374, variance: 0.06520188599824905\n",
      "Train size: [400] hidden size: [38] trial: 25, train_loss: 1.835689, test loss: 1.000273, bias2: 0.9360281825065613, variance: 0.06424514204263687\n",
      "Train size: [400] hidden size: [38] trial: 26, train_loss: 1.842651, test loss: 0.999591, bias2: 0.9339804649353027, variance: 0.0656106173992157\n",
      "Train size: [400] hidden size: [38] trial: 27, train_loss: 1.839491, test loss: 0.999709, bias2: 0.9344646334648132, variance: 0.06524419784545898\n",
      "Train size: [400] hidden size: [38] trial: 28, train_loss: 1.847701, test loss: 1.000617, bias2: 0.9353436231613159, variance: 0.06527363508939743\n",
      "Train size: [400] hidden size: [38] trial: 29, train_loss: 1.842410, test loss: 1.000977, bias2: 0.9358245730400085, variance: 0.06515269726514816\n",
      "Train size: [400] hidden size: [38] trial: 30, train_loss: 1.844306, test loss: 1.000527, bias2: 0.9355576634407043, variance: 0.06496911495923996\n",
      "Train size: [400] hidden size: [38] trial: 31, train_loss: 1.833576, test loss: 1.000232, bias2: 0.935066282749176, variance: 0.06516595929861069\n",
      "Train size: [400] hidden size: [38] trial: 32, train_loss: 1.832740, test loss: 0.999905, bias2: 0.934187650680542, variance: 0.06571733206510544\n",
      "Train size: [400] hidden size: [38] trial: 33, train_loss: 1.828243, test loss: 0.999534, bias2: 0.9340172410011292, variance: 0.06551628559827805\n",
      "Train size: [400] hidden size: [38] trial: 34, train_loss: 1.827805, test loss: 0.999852, bias2: 0.9352911114692688, variance: 0.06456104665994644\n",
      "Train size: [400] hidden size: [38] trial: 35, train_loss: 1.823550, test loss: 0.999726, bias2: 0.9361321926116943, variance: 0.06359384953975677\n",
      "Train size: [400] hidden size: [38] trial: 36, train_loss: 1.823421, test loss: 1.000087, bias2: 0.936468780040741, variance: 0.0636182352900505\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [38] trial: 37, train_loss: 1.821894, test loss: 1.000307, bias2: 0.9363107681274414, variance: 0.06399597972631454\n",
      "Train size: [400] hidden size: [38] trial: 38, train_loss: 1.824534, test loss: 0.999883, bias2: 0.9347223043441772, variance: 0.0651608556509018\n",
      "Train size: [400] hidden size: [38] trial: 39, train_loss: 1.823906, test loss: 1.000050, bias2: 0.9351871609687805, variance: 0.06486255675554276\n",
      "Train size: [400] hidden size: [38] trial: 40, train_loss: 1.828473, test loss: 0.999723, bias2: 0.9348049163818359, variance: 0.06491799652576447\n",
      "Train size: [400] hidden size: [38] trial: 41, train_loss: 1.832753, test loss: 0.999059, bias2: 0.9344804883003235, variance: 0.06457889080047607\n",
      "Train size: [400] hidden size: [38] trial: 42, train_loss: 1.829340, test loss: 0.999399, bias2: 0.934782087802887, variance: 0.0646168664097786\n",
      "Train size: [400] hidden size: [38] trial: 43, train_loss: 1.827997, test loss: 1.000310, bias2: 0.9357658624649048, variance: 0.06454397737979889\n",
      "Train size: [400] hidden size: [38] trial: 44, train_loss: 1.825499, test loss: 1.000181, bias2: 0.9357180595397949, variance: 0.06446265429258347\n",
      "Train size: [400] hidden size: [38] trial: 45, train_loss: 1.827831, test loss: 0.999730, bias2: 0.9347207546234131, variance: 0.0650094598531723\n",
      "Train size: [400] hidden size: [38] trial: 46, train_loss: 1.830302, test loss: 0.999902, bias2: 0.9352274537086487, variance: 0.0646747574210167\n",
      "Train size: [400] hidden size: [38] trial: 47, train_loss: 1.827172, test loss: 1.000958, bias2: 0.9357488751411438, variance: 0.06520956009626389\n",
      "Train size: [400] hidden size: [38] trial: 48, train_loss: 1.829511, test loss: 1.000765, bias2: 0.9353781938552856, variance: 0.06538664549589157\n",
      "Train size: [400] hidden size: [38] trial: 49, train_loss: 1.828788, test loss: 1.000936, bias2: 0.9353500604629517, variance: 0.06558630615472794\n",
      "##################################################\n",
      "Train size: [400] hidden size: [44] trial: 0, train_loss: 1.804433, test loss: 0.978770, bias2: 0.9787696599960327, variance: -6.568674493223625e-10\n",
      "Train size: [400] hidden size: [44] trial: 1, train_loss: 1.844070, test loss: 0.992977, bias2: 0.9641833305358887, variance: 0.028793461620807648\n",
      "Train size: [400] hidden size: [44] trial: 2, train_loss: 1.836411, test loss: 0.990341, bias2: 0.9532650709152222, variance: 0.037076231092214584\n",
      "Train size: [400] hidden size: [44] trial: 3, train_loss: 1.829931, test loss: 0.990999, bias2: 0.9452109336853027, variance: 0.045788269490003586\n",
      "Train size: [400] hidden size: [44] trial: 4, train_loss: 1.795281, test loss: 0.991701, bias2: 0.942869246006012, variance: 0.04883192479610443\n",
      "Train size: [400] hidden size: [44] trial: 5, train_loss: 1.771751, test loss: 0.991895, bias2: 0.9413958191871643, variance: 0.05049882084131241\n",
      "Train size: [400] hidden size: [44] trial: 6, train_loss: 1.748161, test loss: 0.991840, bias2: 0.9346444010734558, variance: 0.0571959987282753\n",
      "Train size: [400] hidden size: [44] trial: 7, train_loss: 1.773057, test loss: 0.991524, bias2: 0.9311107993125916, variance: 0.0604131780564785\n",
      "Train size: [400] hidden size: [44] trial: 8, train_loss: 1.770487, test loss: 0.992165, bias2: 0.927403450012207, variance: 0.06476113200187683\n",
      "Train size: [400] hidden size: [44] trial: 9, train_loss: 1.779561, test loss: 0.997376, bias2: 0.9293383359909058, variance: 0.06803780794143677\n",
      "Train size: [400] hidden size: [44] trial: 10, train_loss: 1.807580, test loss: 0.997286, bias2: 0.9279212951660156, variance: 0.06936469674110413\n",
      "Train size: [400] hidden size: [44] trial: 11, train_loss: 1.815190, test loss: 0.997800, bias2: 0.9263773560523987, variance: 0.0714227482676506\n",
      "Train size: [400] hidden size: [44] trial: 12, train_loss: 1.832571, test loss: 1.003282, bias2: 0.9295780658721924, variance: 0.07370403409004211\n",
      "Train size: [400] hidden size: [44] trial: 13, train_loss: 1.832793, test loss: 1.001312, bias2: 0.9274547100067139, variance: 0.07385727763175964\n",
      "Train size: [400] hidden size: [44] trial: 14, train_loss: 1.842959, test loss: 0.998943, bias2: 0.9262677431106567, variance: 0.07267501205205917\n",
      "Train size: [400] hidden size: [44] trial: 15, train_loss: 1.830719, test loss: 0.999765, bias2: 0.9264862537384033, variance: 0.07327915728092194\n",
      "Train size: [400] hidden size: [44] trial: 16, train_loss: 1.839636, test loss: 1.001975, bias2: 0.9275548458099365, variance: 0.07442042976617813\n",
      "Train size: [400] hidden size: [44] trial: 17, train_loss: 1.844614, test loss: 1.002352, bias2: 0.9285289645195007, variance: 0.07382328808307648\n",
      "Train size: [400] hidden size: [44] trial: 18, train_loss: 1.835314, test loss: 1.000355, bias2: 0.9267955422401428, variance: 0.0735592320561409\n",
      "Train size: [400] hidden size: [44] trial: 19, train_loss: 1.830016, test loss: 0.998357, bias2: 0.9245147705078125, variance: 0.0738421380519867\n",
      "Train size: [400] hidden size: [44] trial: 20, train_loss: 1.833114, test loss: 0.998369, bias2: 0.9253517985343933, variance: 0.07301730662584305\n",
      "Train size: [400] hidden size: [44] trial: 21, train_loss: 1.825833, test loss: 0.998540, bias2: 0.9244670867919922, variance: 0.07407283782958984\n",
      "Train size: [400] hidden size: [44] trial: 22, train_loss: 1.818826, test loss: 0.997459, bias2: 0.923227846622467, variance: 0.07423160970211029\n",
      "Train size: [400] hidden size: [44] trial: 23, train_loss: 1.814887, test loss: 0.999440, bias2: 0.9226210713386536, variance: 0.07681866735219955\n",
      "Train size: [400] hidden size: [44] trial: 24, train_loss: 1.804094, test loss: 1.000510, bias2: 0.9237427115440369, variance: 0.07676760852336884\n",
      "Train size: [400] hidden size: [44] trial: 25, train_loss: 1.804938, test loss: 1.001114, bias2: 0.9223574995994568, variance: 0.07875672727823257\n",
      "Train size: [400] hidden size: [44] trial: 26, train_loss: 1.808126, test loss: 1.002278, bias2: 0.9227349162101746, variance: 0.07954280078411102\n",
      "Train size: [400] hidden size: [44] trial: 27, train_loss: 1.801659, test loss: 1.001440, bias2: 0.9217166900634766, variance: 0.07972286641597748\n",
      "Train size: [400] hidden size: [44] trial: 28, train_loss: 1.804485, test loss: 1.001784, bias2: 0.9219062328338623, variance: 0.07987747341394424\n",
      "Train size: [400] hidden size: [44] trial: 29, train_loss: 1.801161, test loss: 1.001717, bias2: 0.9223261475563049, variance: 0.07939080893993378\n",
      "Train size: [400] hidden size: [44] trial: 30, train_loss: 1.801807, test loss: 1.000715, bias2: 0.9218651652336121, variance: 0.07884982973337173\n",
      "Train size: [400] hidden size: [44] trial: 31, train_loss: 1.801105, test loss: 1.002168, bias2: 0.9229088425636292, variance: 0.0792594701051712\n",
      "Train size: [400] hidden size: [44] trial: 32, train_loss: 1.807127, test loss: 1.001739, bias2: 0.922265887260437, variance: 0.07947299629449844\n",
      "Train size: [400] hidden size: [44] trial: 33, train_loss: 1.801444, test loss: 1.000861, bias2: 0.9212495684623718, variance: 0.07961171120405197\n",
      "Train size: [400] hidden size: [44] trial: 34, train_loss: 1.799062, test loss: 1.000158, bias2: 0.920295000076294, variance: 0.0798632949590683\n",
      "Train size: [400] hidden size: [44] trial: 35, train_loss: 1.796103, test loss: 0.999418, bias2: 0.9199568033218384, variance: 0.0794617235660553\n",
      "Train size: [400] hidden size: [44] trial: 36, train_loss: 1.797071, test loss: 0.998614, bias2: 0.9181209802627563, variance: 0.08049345761537552\n",
      "Train size: [400] hidden size: [44] trial: 37, train_loss: 1.796824, test loss: 0.998538, bias2: 0.9181117415428162, variance: 0.08042597770690918\n",
      "Train size: [400] hidden size: [44] trial: 38, train_loss: 1.797463, test loss: 0.999025, bias2: 0.9184218645095825, variance: 0.08060362935066223\n",
      "Train size: [400] hidden size: [44] trial: 39, train_loss: 1.794111, test loss: 0.998873, bias2: 0.9178528189659119, variance: 0.0810205414891243\n",
      "Train size: [400] hidden size: [44] trial: 40, train_loss: 1.792252, test loss: 0.999438, bias2: 0.9185068011283875, variance: 0.08093104511499405\n",
      "Train size: [400] hidden size: [44] trial: 41, train_loss: 1.796361, test loss: 0.999934, bias2: 0.9192742705345154, variance: 0.08065957576036453\n",
      "Train size: [400] hidden size: [44] trial: 42, train_loss: 1.796943, test loss: 0.999584, bias2: 0.919347882270813, variance: 0.08023571968078613\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [44] trial: 43, train_loss: 1.797688, test loss: 1.001048, bias2: 0.9200174808502197, variance: 0.0810304805636406\n",
      "Train size: [400] hidden size: [44] trial: 44, train_loss: 1.798232, test loss: 1.001694, bias2: 0.9205273985862732, variance: 0.08116618543863297\n",
      "Train size: [400] hidden size: [44] trial: 45, train_loss: 1.798752, test loss: 1.000932, bias2: 0.9195311069488525, variance: 0.08140100538730621\n",
      "Train size: [400] hidden size: [44] trial: 46, train_loss: 1.803557, test loss: 1.000756, bias2: 0.919516921043396, variance: 0.08123920857906342\n",
      "Train size: [400] hidden size: [44] trial: 47, train_loss: 1.802525, test loss: 0.999654, bias2: 0.9179793000221252, variance: 0.08167470991611481\n",
      "Train size: [400] hidden size: [44] trial: 48, train_loss: 1.806076, test loss: 0.999024, bias2: 0.9176651239395142, variance: 0.08135928958654404\n",
      "Train size: [400] hidden size: [44] trial: 49, train_loss: 1.809418, test loss: 0.999619, bias2: 0.9175713062286377, variance: 0.08204805105924606\n",
      "##################################################\n",
      "Train size: [400] hidden size: [51] trial: 0, train_loss: 1.834463, test loss: 0.982843, bias2: 0.9828433990478516, variance: -5.838822203507732e-10\n",
      "Train size: [400] hidden size: [51] trial: 1, train_loss: 1.795978, test loss: 1.001970, bias2: 0.9575271606445312, variance: 0.044443003833293915\n",
      "Train size: [400] hidden size: [51] trial: 2, train_loss: 1.684627, test loss: 0.998760, bias2: 0.9411075711250305, variance: 0.05765235424041748\n",
      "Train size: [400] hidden size: [51] trial: 3, train_loss: 1.754207, test loss: 0.998305, bias2: 0.9386001825332642, variance: 0.05970435589551926\n",
      "Train size: [400] hidden size: [51] trial: 4, train_loss: 1.739928, test loss: 0.998832, bias2: 0.9327684640884399, variance: 0.06606344878673553\n",
      "Train size: [400] hidden size: [51] trial: 5, train_loss: 1.721089, test loss: 0.996930, bias2: 0.9269248843193054, variance: 0.07000499218702316\n",
      "Train size: [400] hidden size: [51] trial: 6, train_loss: 1.702906, test loss: 0.993965, bias2: 0.9205861687660217, variance: 0.07337839901447296\n",
      "Train size: [400] hidden size: [51] trial: 7, train_loss: 1.716628, test loss: 0.998697, bias2: 0.9203872084617615, variance: 0.07830946147441864\n",
      "Train size: [400] hidden size: [51] trial: 8, train_loss: 1.738461, test loss: 0.999601, bias2: 0.9188090562820435, variance: 0.08079194277524948\n",
      "Train size: [400] hidden size: [51] trial: 9, train_loss: 1.763360, test loss: 1.000599, bias2: 0.9204734563827515, variance: 0.08012579381465912\n",
      "Train size: [400] hidden size: [51] trial: 10, train_loss: 1.771405, test loss: 1.000893, bias2: 0.9220869541168213, variance: 0.07880604267120361\n",
      "Train size: [400] hidden size: [51] trial: 11, train_loss: 1.786738, test loss: 1.002338, bias2: 0.9211835265159607, variance: 0.08115466684103012\n",
      "Train size: [400] hidden size: [51] trial: 12, train_loss: 1.783824, test loss: 0.998985, bias2: 0.916092574596405, variance: 0.0828925296664238\n",
      "Train size: [400] hidden size: [51] trial: 13, train_loss: 1.787621, test loss: 1.000372, bias2: 0.9162296056747437, variance: 0.08414196968078613\n",
      "Train size: [400] hidden size: [51] trial: 14, train_loss: 1.797985, test loss: 1.001252, bias2: 0.9151732921600342, variance: 0.08607885241508484\n",
      "Train size: [400] hidden size: [51] trial: 15, train_loss: 1.803536, test loss: 1.001801, bias2: 0.9167041778564453, variance: 0.08509694784879684\n",
      "Train size: [400] hidden size: [51] trial: 16, train_loss: 1.803773, test loss: 1.004477, bias2: 0.9181345105171204, variance: 0.08634249120950699\n",
      "Train size: [400] hidden size: [51] trial: 17, train_loss: 1.790522, test loss: 1.004137, bias2: 0.9184828996658325, variance: 0.08565366268157959\n",
      "Train size: [400] hidden size: [51] trial: 18, train_loss: 1.800655, test loss: 1.002731, bias2: 0.9147467017173767, variance: 0.08798449486494064\n",
      "Train size: [400] hidden size: [51] trial: 19, train_loss: 1.793990, test loss: 1.000451, bias2: 0.9122410416603088, variance: 0.08821015059947968\n",
      "Train size: [400] hidden size: [51] trial: 20, train_loss: 1.785095, test loss: 1.001589, bias2: 0.9127594232559204, variance: 0.08883009105920792\n",
      "Train size: [400] hidden size: [51] trial: 21, train_loss: 1.783083, test loss: 1.000736, bias2: 0.9135202765464783, variance: 0.08721571415662766\n",
      "Train size: [400] hidden size: [51] trial: 22, train_loss: 1.778391, test loss: 1.002282, bias2: 0.9137553572654724, variance: 0.08852700889110565\n",
      "Train size: [400] hidden size: [51] trial: 23, train_loss: 1.770816, test loss: 1.002267, bias2: 0.9138801097869873, variance: 0.08838702738285065\n",
      "Train size: [400] hidden size: [51] trial: 24, train_loss: 1.775488, test loss: 1.002379, bias2: 0.9148428440093994, variance: 0.08753655850887299\n",
      "Train size: [400] hidden size: [51] trial: 25, train_loss: 1.774121, test loss: 1.002672, bias2: 0.9155541658401489, variance: 0.08711790293455124\n",
      "Train size: [400] hidden size: [51] trial: 26, train_loss: 1.770587, test loss: 1.001799, bias2: 0.9147781729698181, variance: 0.08702119439840317\n",
      "Train size: [400] hidden size: [51] trial: 27, train_loss: 1.768826, test loss: 1.001295, bias2: 0.9139048457145691, variance: 0.08738964051008224\n",
      "Train size: [400] hidden size: [51] trial: 28, train_loss: 1.768125, test loss: 0.999792, bias2: 0.911110520362854, variance: 0.08868095278739929\n",
      "Train size: [400] hidden size: [51] trial: 29, train_loss: 1.767819, test loss: 0.998701, bias2: 0.9091601371765137, variance: 0.08954065293073654\n",
      "Train size: [400] hidden size: [51] trial: 30, train_loss: 1.771175, test loss: 0.999261, bias2: 0.9099345207214355, variance: 0.08932613581418991\n",
      "Train size: [400] hidden size: [51] trial: 31, train_loss: 1.768556, test loss: 1.000261, bias2: 0.9114667773246765, variance: 0.0887937992811203\n",
      "Train size: [400] hidden size: [51] trial: 32, train_loss: 1.770632, test loss: 1.000814, bias2: 0.9122114777565002, variance: 0.0886027067899704\n",
      "Train size: [400] hidden size: [51] trial: 33, train_loss: 1.774299, test loss: 1.000641, bias2: 0.9108781218528748, variance: 0.089762844145298\n",
      "Train size: [400] hidden size: [51] trial: 34, train_loss: 1.770054, test loss: 1.000744, bias2: 0.9117109179496765, variance: 0.08903329819440842\n",
      "Train size: [400] hidden size: [51] trial: 35, train_loss: 1.768971, test loss: 1.001123, bias2: 0.9106016159057617, variance: 0.09052097052335739\n",
      "Train size: [400] hidden size: [51] trial: 36, train_loss: 1.768927, test loss: 1.000822, bias2: 0.9102892279624939, variance: 0.09053310006856918\n",
      "Train size: [400] hidden size: [51] trial: 37, train_loss: 1.771788, test loss: 0.999858, bias2: 0.9090835452079773, variance: 0.09077475965023041\n",
      "Train size: [400] hidden size: [51] trial: 38, train_loss: 1.770944, test loss: 0.999488, bias2: 0.9093624353408813, variance: 0.09012550115585327\n",
      "Train size: [400] hidden size: [51] trial: 39, train_loss: 1.773602, test loss: 1.000224, bias2: 0.9089472889900208, variance: 0.09127707034349442\n",
      "Train size: [400] hidden size: [51] trial: 40, train_loss: 1.769711, test loss: 0.999814, bias2: 0.9091769456863403, variance: 0.09063749760389328\n",
      "Train size: [400] hidden size: [51] trial: 41, train_loss: 1.772733, test loss: 0.999973, bias2: 0.9090188145637512, variance: 0.09095459431409836\n",
      "Train size: [400] hidden size: [51] trial: 42, train_loss: 1.774410, test loss: 0.999746, bias2: 0.908697247505188, variance: 0.09104884415864944\n",
      "Train size: [400] hidden size: [51] trial: 43, train_loss: 1.770276, test loss: 1.000319, bias2: 0.9092671871185303, variance: 0.09105196595191956\n",
      "Train size: [400] hidden size: [51] trial: 44, train_loss: 1.771458, test loss: 0.999051, bias2: 0.9070298075675964, variance: 0.09202124178409576\n",
      "Train size: [400] hidden size: [51] trial: 45, train_loss: 1.770113, test loss: 0.998565, bias2: 0.9065676331520081, variance: 0.09199695289134979\n",
      "Train size: [400] hidden size: [51] trial: 46, train_loss: 1.769057, test loss: 0.998065, bias2: 0.9060753583908081, variance: 0.09198923408985138\n",
      "Train size: [400] hidden size: [51] trial: 47, train_loss: 1.768563, test loss: 0.998112, bias2: 0.9060502648353577, variance: 0.09206167608499527\n",
      "Train size: [400] hidden size: [51] trial: 48, train_loss: 1.765436, test loss: 0.998069, bias2: 0.9060748815536499, variance: 0.0919937938451767\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [51] trial: 49, train_loss: 1.760990, test loss: 0.998614, bias2: 0.9062241911888123, variance: 0.09238991886377335\n",
      "##################################################\n",
      "Train size: [400] hidden size: [58] trial: 0, train_loss: 1.763337, test loss: 1.013872, bias2: 1.0138720273971558, variance: -2.4328425385355956e-10\n",
      "Train size: [400] hidden size: [58] trial: 1, train_loss: 1.739484, test loss: 1.015347, bias2: 0.9515475034713745, variance: 0.06379983574151993\n",
      "Train size: [400] hidden size: [58] trial: 2, train_loss: 1.746403, test loss: 1.001299, bias2: 0.9278337955474854, variance: 0.07346519827842712\n",
      "Train size: [400] hidden size: [58] trial: 3, train_loss: 1.722795, test loss: 1.001949, bias2: 0.9278119802474976, variance: 0.07413707673549652\n",
      "Train size: [400] hidden size: [58] trial: 4, train_loss: 1.700625, test loss: 0.995114, bias2: 0.9078158140182495, variance: 0.08729822933673859\n",
      "Train size: [400] hidden size: [58] trial: 5, train_loss: 1.715699, test loss: 0.998809, bias2: 0.9090582132339478, variance: 0.08975086361169815\n",
      "Train size: [400] hidden size: [58] trial: 6, train_loss: 1.731401, test loss: 0.996705, bias2: 0.9083597660064697, variance: 0.08834541589021683\n",
      "Train size: [400] hidden size: [58] trial: 7, train_loss: 1.702832, test loss: 0.998581, bias2: 0.9105624556541443, variance: 0.08801813423633575\n",
      "Train size: [400] hidden size: [58] trial: 8, train_loss: 1.705724, test loss: 0.998742, bias2: 0.9128761887550354, variance: 0.08586630970239639\n",
      "Train size: [400] hidden size: [58] trial: 9, train_loss: 1.705954, test loss: 1.006703, bias2: 0.915894091129303, variance: 0.09080878645181656\n",
      "Train size: [400] hidden size: [58] trial: 10, train_loss: 1.705823, test loss: 1.008889, bias2: 0.9140427112579346, variance: 0.09484637528657913\n",
      "Train size: [400] hidden size: [58] trial: 11, train_loss: 1.725772, test loss: 1.008799, bias2: 0.9124864935874939, variance: 0.09631272405385971\n",
      "Train size: [400] hidden size: [58] trial: 12, train_loss: 1.719303, test loss: 1.007470, bias2: 0.9107030034065247, variance: 0.09676691144704819\n",
      "Train size: [400] hidden size: [58] trial: 13, train_loss: 1.725382, test loss: 1.008866, bias2: 0.9120006561279297, variance: 0.09686552733182907\n",
      "Train size: [400] hidden size: [58] trial: 14, train_loss: 1.711223, test loss: 1.009700, bias2: 0.9132183790206909, variance: 0.09648200869560242\n",
      "Train size: [400] hidden size: [58] trial: 15, train_loss: 1.710146, test loss: 1.009977, bias2: 0.9129122495651245, variance: 0.09706472605466843\n",
      "Train size: [400] hidden size: [58] trial: 16, train_loss: 1.717737, test loss: 1.010729, bias2: 0.9110737442970276, variance: 0.09965567290782928\n",
      "Train size: [400] hidden size: [58] trial: 17, train_loss: 1.712954, test loss: 1.013741, bias2: 0.9131008982658386, variance: 0.10064002126455307\n",
      "Train size: [400] hidden size: [58] trial: 18, train_loss: 1.712780, test loss: 1.013596, bias2: 0.9143689274787903, variance: 0.09922714531421661\n",
      "Train size: [400] hidden size: [58] trial: 19, train_loss: 1.708966, test loss: 1.012371, bias2: 0.9131693243980408, variance: 0.09920139610767365\n",
      "Train size: [400] hidden size: [58] trial: 20, train_loss: 1.709986, test loss: 1.011118, bias2: 0.9118652939796448, variance: 0.09925226867198944\n",
      "Train size: [400] hidden size: [58] trial: 21, train_loss: 1.709799, test loss: 1.011796, bias2: 0.9116969108581543, variance: 0.1000993475317955\n",
      "Train size: [400] hidden size: [58] trial: 22, train_loss: 1.703020, test loss: 1.011850, bias2: 0.9112616777420044, variance: 0.10058809816837311\n",
      "Train size: [400] hidden size: [58] trial: 23, train_loss: 1.713059, test loss: 1.011238, bias2: 0.9105451107025146, variance: 0.10069336742162704\n",
      "Train size: [400] hidden size: [58] trial: 24, train_loss: 1.707986, test loss: 1.009573, bias2: 0.9093031883239746, variance: 0.10026934742927551\n",
      "Train size: [400] hidden size: [58] trial: 25, train_loss: 1.709547, test loss: 1.009923, bias2: 0.9107605814933777, variance: 0.09916266053915024\n",
      "Train size: [400] hidden size: [58] trial: 26, train_loss: 1.712938, test loss: 1.010517, bias2: 0.9101351499557495, variance: 0.10038158297538757\n",
      "Train size: [400] hidden size: [58] trial: 27, train_loss: 1.707201, test loss: 1.010627, bias2: 0.9105280637741089, variance: 0.1000993475317955\n",
      "Train size: [400] hidden size: [58] trial: 28, train_loss: 1.707396, test loss: 1.011100, bias2: 0.9113869667053223, variance: 0.09971346706151962\n",
      "Train size: [400] hidden size: [58] trial: 29, train_loss: 1.701709, test loss: 1.010447, bias2: 0.9097973704338074, variance: 0.10065014660358429\n",
      "Train size: [400] hidden size: [58] trial: 30, train_loss: 1.704818, test loss: 1.009744, bias2: 0.9078400135040283, variance: 0.10190436244010925\n",
      "Train size: [400] hidden size: [58] trial: 31, train_loss: 1.698138, test loss: 1.010221, bias2: 0.9084610939025879, variance: 0.10175954550504684\n",
      "Train size: [400] hidden size: [58] trial: 32, train_loss: 1.703435, test loss: 1.010491, bias2: 0.9080972671508789, variance: 0.10239376872777939\n",
      "Train size: [400] hidden size: [58] trial: 33, train_loss: 1.701516, test loss: 1.011355, bias2: 0.9085394144058228, variance: 0.10281576961278915\n",
      "Train size: [400] hidden size: [58] trial: 34, train_loss: 1.695958, test loss: 1.010779, bias2: 0.9085984826087952, variance: 0.10218039900064468\n",
      "Train size: [400] hidden size: [58] trial: 35, train_loss: 1.703536, test loss: 1.010903, bias2: 0.9094528555870056, variance: 0.10145038366317749\n",
      "Train size: [400] hidden size: [58] trial: 36, train_loss: 1.701221, test loss: 1.012785, bias2: 0.9099299907684326, variance: 0.10285531729459763\n",
      "Train size: [400] hidden size: [58] trial: 37, train_loss: 1.705628, test loss: 1.011370, bias2: 0.909389853477478, variance: 0.10198021680116653\n",
      "Train size: [400] hidden size: [58] trial: 38, train_loss: 1.704587, test loss: 1.011164, bias2: 0.9082036018371582, variance: 0.10296013951301575\n",
      "Train size: [400] hidden size: [58] trial: 39, train_loss: 1.709473, test loss: 1.012030, bias2: 0.9083606600761414, variance: 0.10366957634687424\n",
      "Train size: [400] hidden size: [58] trial: 40, train_loss: 1.715756, test loss: 1.012068, bias2: 0.9078316688537598, variance: 0.10423591732978821\n",
      "Train size: [400] hidden size: [58] trial: 41, train_loss: 1.717263, test loss: 1.012163, bias2: 0.9082882404327393, variance: 0.10387471318244934\n",
      "Train size: [400] hidden size: [58] trial: 42, train_loss: 1.717392, test loss: 1.011925, bias2: 0.9084348082542419, variance: 0.10348983108997345\n",
      "Train size: [400] hidden size: [58] trial: 43, train_loss: 1.721973, test loss: 1.012221, bias2: 0.9093916416168213, variance: 0.10282910615205765\n",
      "Train size: [400] hidden size: [58] trial: 44, train_loss: 1.722681, test loss: 1.012791, bias2: 0.91020667552948, variance: 0.10258391499519348\n",
      "Train size: [400] hidden size: [58] trial: 45, train_loss: 1.719206, test loss: 1.012827, bias2: 0.9102464914321899, variance: 0.10258080065250397\n",
      "Train size: [400] hidden size: [58] trial: 46, train_loss: 1.721159, test loss: 1.012660, bias2: 0.9100585579872131, variance: 0.10260144621133804\n",
      "Train size: [400] hidden size: [58] trial: 47, train_loss: 1.716642, test loss: 1.011622, bias2: 0.9085806608200073, variance: 0.10304166376590729\n",
      "Train size: [400] hidden size: [58] trial: 48, train_loss: 1.724258, test loss: 1.011383, bias2: 0.9083837270736694, variance: 0.10299921780824661\n",
      "Train size: [400] hidden size: [58] trial: 49, train_loss: 1.722801, test loss: 1.010401, bias2: 0.90757155418396, variance: 0.1028289794921875\n",
      "##################################################\n",
      "Train size: [400] hidden size: [67] trial: 0, train_loss: 1.649310, test loss: 1.010090, bias2: 1.010089635848999, variance: -8.271663909376059e-10\n",
      "Train size: [400] hidden size: [67] trial: 1, train_loss: 1.684225, test loss: 1.011018, bias2: 0.9663900136947632, variance: 0.04462805390357971\n",
      "Train size: [400] hidden size: [67] trial: 2, train_loss: 1.681222, test loss: 0.998701, bias2: 0.9322922229766846, variance: 0.0664084255695343\n",
      "Train size: [400] hidden size: [67] trial: 3, train_loss: 1.702227, test loss: 1.006518, bias2: 0.9174312353134155, variance: 0.08908678591251373\n",
      "Train size: [400] hidden size: [67] trial: 4, train_loss: 1.647965, test loss: 1.004531, bias2: 0.9111828804016113, variance: 0.09334787726402283\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [67] trial: 5, train_loss: 1.662602, test loss: 1.000904, bias2: 0.9033212065696716, variance: 0.09758275747299194\n",
      "Train size: [400] hidden size: [67] trial: 6, train_loss: 1.696867, test loss: 1.000985, bias2: 0.9012241959571838, variance: 0.09976081550121307\n",
      "Train size: [400] hidden size: [67] trial: 7, train_loss: 1.694199, test loss: 1.003174, bias2: 0.9018563628196716, variance: 0.10131783038377762\n",
      "Train size: [400] hidden size: [67] trial: 8, train_loss: 1.701566, test loss: 1.003750, bias2: 0.9009255766868591, variance: 0.10282405465841293\n",
      "Train size: [400] hidden size: [67] trial: 9, train_loss: 1.712943, test loss: 1.004069, bias2: 0.9001514315605164, variance: 0.10391788184642792\n",
      "Train size: [400] hidden size: [67] trial: 10, train_loss: 1.700729, test loss: 1.001840, bias2: 0.8949189186096191, variance: 0.10692146420478821\n",
      "Train size: [400] hidden size: [67] trial: 11, train_loss: 1.706792, test loss: 0.999889, bias2: 0.8946712017059326, variance: 0.10521823167800903\n",
      "Train size: [400] hidden size: [67] trial: 12, train_loss: 1.713199, test loss: 1.000579, bias2: 0.8961252570152283, variance: 0.10445398837327957\n",
      "Train size: [400] hidden size: [67] trial: 13, train_loss: 1.710169, test loss: 0.998673, bias2: 0.8958843350410461, variance: 0.10278894007205963\n",
      "Train size: [400] hidden size: [67] trial: 14, train_loss: 1.704779, test loss: 0.997644, bias2: 0.8950492739677429, variance: 0.102594755589962\n",
      "Train size: [400] hidden size: [67] trial: 15, train_loss: 1.711191, test loss: 0.997627, bias2: 0.8951223492622375, variance: 0.10250464826822281\n",
      "Train size: [400] hidden size: [67] trial: 16, train_loss: 1.691459, test loss: 0.999347, bias2: 0.8946956992149353, variance: 0.10465092211961746\n",
      "Train size: [400] hidden size: [67] trial: 17, train_loss: 1.698482, test loss: 0.997849, bias2: 0.8930041193962097, variance: 0.1048450618982315\n",
      "Train size: [400] hidden size: [67] trial: 18, train_loss: 1.709480, test loss: 0.999635, bias2: 0.8934226036071777, variance: 0.10621216893196106\n",
      "Train size: [400] hidden size: [67] trial: 19, train_loss: 1.712614, test loss: 1.000691, bias2: 0.8946471214294434, variance: 0.10604380071163177\n",
      "Train size: [400] hidden size: [67] trial: 20, train_loss: 1.712070, test loss: 1.000882, bias2: 0.8937718868255615, variance: 0.10710980743169785\n",
      "Train size: [400] hidden size: [67] trial: 21, train_loss: 1.718675, test loss: 1.001990, bias2: 0.895750880241394, variance: 0.1062394231557846\n",
      "Train size: [400] hidden size: [67] trial: 22, train_loss: 1.719954, test loss: 1.002081, bias2: 0.8947932720184326, variance: 0.10728789120912552\n",
      "Train size: [400] hidden size: [67] trial: 23, train_loss: 1.722130, test loss: 1.002778, bias2: 0.8944385051727295, variance: 0.10833980143070221\n",
      "Train size: [400] hidden size: [67] trial: 24, train_loss: 1.714674, test loss: 1.002949, bias2: 0.8928401470184326, variance: 0.11010897904634476\n",
      "Train size: [400] hidden size: [67] trial: 25, train_loss: 1.711574, test loss: 1.001795, bias2: 0.892883837223053, variance: 0.10891145467758179\n",
      "Train size: [400] hidden size: [67] trial: 26, train_loss: 1.701327, test loss: 1.002495, bias2: 0.8931723833084106, variance: 0.1093221977353096\n",
      "Train size: [400] hidden size: [67] trial: 27, train_loss: 1.697314, test loss: 1.003447, bias2: 0.8929272294044495, variance: 0.11051957309246063\n",
      "Train size: [400] hidden size: [67] trial: 28, train_loss: 1.692475, test loss: 1.003225, bias2: 0.8917053937911987, variance: 0.11151991039514542\n",
      "Train size: [400] hidden size: [67] trial: 29, train_loss: 1.693342, test loss: 1.003319, bias2: 0.891426146030426, variance: 0.11189288645982742\n",
      "Train size: [400] hidden size: [67] trial: 30, train_loss: 1.690314, test loss: 1.001075, bias2: 0.8902686238288879, variance: 0.1108066514134407\n",
      "Train size: [400] hidden size: [67] trial: 31, train_loss: 1.693252, test loss: 1.003163, bias2: 0.891328752040863, variance: 0.11183389276266098\n",
      "Train size: [400] hidden size: [67] trial: 32, train_loss: 1.691900, test loss: 1.002510, bias2: 0.8901964426040649, variance: 0.11231305450201035\n",
      "Train size: [400] hidden size: [67] trial: 33, train_loss: 1.692970, test loss: 1.003701, bias2: 0.8913120627403259, variance: 0.11238879710435867\n",
      "Train size: [400] hidden size: [67] trial: 34, train_loss: 1.689792, test loss: 1.004119, bias2: 0.8915663957595825, variance: 0.11255275458097458\n",
      "Train size: [400] hidden size: [67] trial: 35, train_loss: 1.691467, test loss: 1.003361, bias2: 0.8905985355377197, variance: 0.11276283115148544\n",
      "Train size: [400] hidden size: [67] trial: 36, train_loss: 1.694297, test loss: 1.003916, bias2: 0.8912841081619263, variance: 0.11263225227594376\n",
      "Train size: [400] hidden size: [67] trial: 37, train_loss: 1.698224, test loss: 1.004145, bias2: 0.891924262046814, variance: 0.11222051084041595\n",
      "Train size: [400] hidden size: [67] trial: 38, train_loss: 1.691654, test loss: 1.004152, bias2: 0.8927193284034729, variance: 0.11143322288990021\n",
      "Train size: [400] hidden size: [67] trial: 39, train_loss: 1.691416, test loss: 1.004520, bias2: 0.8926836252212524, variance: 0.11183679103851318\n",
      "Train size: [400] hidden size: [67] trial: 40, train_loss: 1.690036, test loss: 1.005823, bias2: 0.8930702209472656, variance: 0.11275270581245422\n",
      "Train size: [400] hidden size: [67] trial: 41, train_loss: 1.692307, test loss: 1.006070, bias2: 0.8926050066947937, variance: 0.11346525698900223\n",
      "Train size: [400] hidden size: [67] trial: 42, train_loss: 1.694162, test loss: 1.005614, bias2: 0.8916153907775879, variance: 0.11399915814399719\n",
      "Train size: [400] hidden size: [67] trial: 43, train_loss: 1.698598, test loss: 1.005414, bias2: 0.8913407921791077, variance: 0.11407322436571121\n",
      "Train size: [400] hidden size: [67] trial: 44, train_loss: 1.693717, test loss: 1.004916, bias2: 0.8904558420181274, variance: 0.11445962637662888\n",
      "Train size: [400] hidden size: [67] trial: 45, train_loss: 1.696517, test loss: 1.004917, bias2: 0.889786958694458, variance: 0.11512969434261322\n",
      "Train size: [400] hidden size: [67] trial: 46, train_loss: 1.698429, test loss: 1.005048, bias2: 0.8902215361595154, variance: 0.1148262619972229\n",
      "Train size: [400] hidden size: [67] trial: 47, train_loss: 1.695760, test loss: 1.005488, bias2: 0.8905248641967773, variance: 0.11496351659297943\n",
      "Train size: [400] hidden size: [67] trial: 48, train_loss: 1.693776, test loss: 1.005696, bias2: 0.8903229236602783, variance: 0.11537288874387741\n",
      "Train size: [400] hidden size: [67] trial: 49, train_loss: 1.693420, test loss: 1.005302, bias2: 0.8899893760681152, variance: 0.11531271040439606\n",
      "##################################################\n",
      "Train size: [400] hidden size: [77] trial: 0, train_loss: 1.417744, test loss: 1.047796, bias2: 1.0477955341339111, variance: -9.731369876586626e-11\n",
      "Train size: [400] hidden size: [77] trial: 1, train_loss: 1.449672, test loss: 1.013680, bias2: 0.9528644680976868, variance: 0.06081573665142059\n",
      "Train size: [400] hidden size: [77] trial: 2, train_loss: 1.470385, test loss: 1.012060, bias2: 0.9172791838645935, variance: 0.09478038549423218\n",
      "Train size: [400] hidden size: [77] trial: 3, train_loss: 1.489675, test loss: 1.001735, bias2: 0.9032906293869019, variance: 0.09844432026147842\n",
      "Train size: [400] hidden size: [77] trial: 4, train_loss: 1.529933, test loss: 0.999349, bias2: 0.8906133770942688, variance: 0.10873512923717499\n",
      "Train size: [400] hidden size: [77] trial: 5, train_loss: 1.542822, test loss: 0.997537, bias2: 0.8815019130706787, variance: 0.11603555828332901\n",
      "Train size: [400] hidden size: [77] trial: 6, train_loss: 1.547635, test loss: 1.001430, bias2: 0.8777157068252563, variance: 0.12371382117271423\n",
      "Train size: [400] hidden size: [77] trial: 7, train_loss: 1.566265, test loss: 1.007752, bias2: 0.8781805038452148, variance: 0.12957146763801575\n",
      "Train size: [400] hidden size: [77] trial: 8, train_loss: 1.581723, test loss: 1.007610, bias2: 0.8748530149459839, variance: 0.13275669515132904\n",
      "Train size: [400] hidden size: [77] trial: 9, train_loss: 1.582389, test loss: 1.006875, bias2: 0.877839207649231, variance: 0.1290355622768402\n",
      "Train size: [400] hidden size: [77] trial: 10, train_loss: 1.593241, test loss: 1.005464, bias2: 0.8770782351493835, variance: 0.12838619947433472\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [77] trial: 11, train_loss: 1.594618, test loss: 1.011371, bias2: 0.8796281218528748, variance: 0.13174264132976532\n",
      "Train size: [400] hidden size: [77] trial: 12, train_loss: 1.603773, test loss: 1.010276, bias2: 0.8766332864761353, variance: 0.13364265859127045\n",
      "Train size: [400] hidden size: [77] trial: 13, train_loss: 1.607279, test loss: 1.009628, bias2: 0.8741843700408936, variance: 0.1354435533285141\n",
      "Train size: [400] hidden size: [77] trial: 14, train_loss: 1.606953, test loss: 1.009419, bias2: 0.8763864040374756, variance: 0.1330321878194809\n",
      "Train size: [400] hidden size: [77] trial: 15, train_loss: 1.594834, test loss: 1.008536, bias2: 0.8751466870307922, variance: 0.13338905572891235\n",
      "Train size: [400] hidden size: [77] trial: 16, train_loss: 1.599802, test loss: 1.009228, bias2: 0.8757063746452332, variance: 0.13352172076702118\n",
      "Train size: [400] hidden size: [77] trial: 17, train_loss: 1.600459, test loss: 1.006118, bias2: 0.8704095482826233, variance: 0.135708749294281\n",
      "Train size: [400] hidden size: [77] trial: 18, train_loss: 1.612639, test loss: 1.005787, bias2: 0.8689264059066772, variance: 0.13686075806617737\n",
      "Train size: [400] hidden size: [77] trial: 19, train_loss: 1.609327, test loss: 1.005828, bias2: 0.8692234754562378, variance: 0.13660502433776855\n",
      "Train size: [400] hidden size: [77] trial: 20, train_loss: 1.612298, test loss: 1.004545, bias2: 0.8666465282440186, variance: 0.13789881765842438\n",
      "Train size: [400] hidden size: [77] trial: 21, train_loss: 1.622855, test loss: 1.003315, bias2: 0.8667010068893433, variance: 0.13661430776119232\n",
      "Train size: [400] hidden size: [77] trial: 22, train_loss: 1.617739, test loss: 1.003058, bias2: 0.8655288815498352, variance: 0.13752955198287964\n",
      "Train size: [400] hidden size: [77] trial: 23, train_loss: 1.623224, test loss: 1.003076, bias2: 0.8652074337005615, variance: 0.13786843419075012\n",
      "Train size: [400] hidden size: [77] trial: 24, train_loss: 1.622444, test loss: 1.001840, bias2: 0.8633050918579102, variance: 0.1385350376367569\n",
      "Train size: [400] hidden size: [77] trial: 25, train_loss: 1.622396, test loss: 1.002916, bias2: 0.8615333437919617, variance: 0.14138226211071014\n",
      "Train size: [400] hidden size: [77] trial: 26, train_loss: 1.626457, test loss: 1.001818, bias2: 0.8616976737976074, variance: 0.1401207149028778\n",
      "Train size: [400] hidden size: [77] trial: 27, train_loss: 1.623747, test loss: 1.000700, bias2: 0.8616255521774292, variance: 0.13907477259635925\n",
      "Train size: [400] hidden size: [77] trial: 28, train_loss: 1.630031, test loss: 1.001973, bias2: 0.86313396692276, variance: 0.13883870840072632\n",
      "Train size: [400] hidden size: [77] trial: 29, train_loss: 1.630007, test loss: 1.000383, bias2: 0.8618582487106323, variance: 0.13852426409721375\n",
      "Train size: [400] hidden size: [77] trial: 30, train_loss: 1.625714, test loss: 1.000442, bias2: 0.8613484501838684, variance: 0.13909371197223663\n",
      "Train size: [400] hidden size: [77] trial: 31, train_loss: 1.628610, test loss: 1.000272, bias2: 0.8596029281616211, variance: 0.14066876471042633\n",
      "Train size: [400] hidden size: [77] trial: 32, train_loss: 1.628152, test loss: 0.999901, bias2: 0.8593350648880005, variance: 0.14056552946567535\n",
      "Train size: [400] hidden size: [77] trial: 33, train_loss: 1.628641, test loss: 0.999788, bias2: 0.858924150466919, variance: 0.1408640444278717\n",
      "Train size: [400] hidden size: [77] trial: 34, train_loss: 1.627505, test loss: 1.000114, bias2: 0.8598193526268005, variance: 0.14029471576213837\n",
      "Train size: [400] hidden size: [77] trial: 35, train_loss: 1.628205, test loss: 1.000575, bias2: 0.8597304224967957, variance: 0.1408441811800003\n",
      "Train size: [400] hidden size: [77] trial: 36, train_loss: 1.630888, test loss: 0.999603, bias2: 0.8596400618553162, variance: 0.13996249437332153\n",
      "Train size: [400] hidden size: [77] trial: 37, train_loss: 1.632291, test loss: 0.999777, bias2: 0.860518217086792, variance: 0.13925863802433014\n",
      "Train size: [400] hidden size: [77] trial: 38, train_loss: 1.629972, test loss: 0.999766, bias2: 0.8602867722511292, variance: 0.13947969675064087\n",
      "Train size: [400] hidden size: [77] trial: 39, train_loss: 1.628608, test loss: 0.999642, bias2: 0.8586129546165466, variance: 0.1410287767648697\n",
      "Train size: [400] hidden size: [77] trial: 40, train_loss: 1.630140, test loss: 0.999988, bias2: 0.8586156964302063, variance: 0.1413724273443222\n",
      "Train size: [400] hidden size: [77] trial: 41, train_loss: 1.635860, test loss: 0.999637, bias2: 0.8584238290786743, variance: 0.14121349155902863\n",
      "Train size: [400] hidden size: [77] trial: 42, train_loss: 1.637537, test loss: 1.000087, bias2: 0.8588173985481262, variance: 0.1412695199251175\n",
      "Train size: [400] hidden size: [77] trial: 43, train_loss: 1.635339, test loss: 1.000074, bias2: 0.8590545058250427, variance: 0.14101940393447876\n",
      "Train size: [400] hidden size: [77] trial: 44, train_loss: 1.632411, test loss: 0.998951, bias2: 0.8585066795349121, variance: 0.1404445320367813\n",
      "Train size: [400] hidden size: [77] trial: 45, train_loss: 1.628870, test loss: 0.998389, bias2: 0.857589066028595, variance: 0.14079970121383667\n",
      "Train size: [400] hidden size: [77] trial: 46, train_loss: 1.629786, test loss: 0.999097, bias2: 0.8578586578369141, variance: 0.14123813807964325\n",
      "Train size: [400] hidden size: [77] trial: 47, train_loss: 1.629665, test loss: 0.999918, bias2: 0.858553946018219, variance: 0.14136384427547455\n",
      "Train size: [400] hidden size: [77] trial: 48, train_loss: 1.628496, test loss: 1.000572, bias2: 0.859617292881012, variance: 0.14095433056354523\n",
      "Train size: [400] hidden size: [77] trial: 49, train_loss: 1.626833, test loss: 1.000604, bias2: 0.8597075939178467, variance: 0.14089635014533997\n",
      "##################################################\n",
      "Train size: [400] hidden size: [89] trial: 0, train_loss: 1.624701, test loss: 1.047385, bias2: 1.0473846197128296, variance: 4.865685077071191e-10\n",
      "Train size: [400] hidden size: [89] trial: 1, train_loss: 1.619918, test loss: 1.048744, bias2: 0.9719717502593994, variance: 0.07677186280488968\n",
      "Train size: [400] hidden size: [89] trial: 2, train_loss: 1.638617, test loss: 1.041528, bias2: 0.9229007363319397, variance: 0.11862723529338837\n",
      "Train size: [400] hidden size: [89] trial: 3, train_loss: 1.641366, test loss: 1.036412, bias2: 0.9077062010765076, variance: 0.12870603799819946\n",
      "Train size: [400] hidden size: [89] trial: 4, train_loss: 1.648924, test loss: 1.037222, bias2: 0.901809573173523, variance: 0.13541294634342194\n",
      "Train size: [400] hidden size: [89] trial: 5, train_loss: 1.678119, test loss: 1.036088, bias2: 0.8949260711669922, variance: 0.14116217195987701\n",
      "Train size: [400] hidden size: [89] trial: 6, train_loss: 1.673913, test loss: 1.035028, bias2: 0.8870543837547302, variance: 0.14797385036945343\n",
      "Train size: [400] hidden size: [89] trial: 7, train_loss: 1.658153, test loss: 1.028571, bias2: 0.8810604810714722, variance: 0.14751042425632477\n",
      "Train size: [400] hidden size: [89] trial: 8, train_loss: 1.656879, test loss: 1.031721, bias2: 0.8822623491287231, variance: 0.1494583934545517\n",
      "Train size: [400] hidden size: [89] trial: 9, train_loss: 1.666158, test loss: 1.025236, bias2: 0.8748866319656372, variance: 0.15034911036491394\n",
      "Train size: [400] hidden size: [89] trial: 10, train_loss: 1.669374, test loss: 1.024486, bias2: 0.8720390200614929, variance: 0.15244753658771515\n",
      "Train size: [400] hidden size: [89] trial: 11, train_loss: 1.669177, test loss: 1.022873, bias2: 0.8665889501571655, variance: 0.15628430247306824\n",
      "Train size: [400] hidden size: [89] trial: 12, train_loss: 1.661721, test loss: 1.022508, bias2: 0.8637179732322693, variance: 0.15879029035568237\n",
      "Train size: [400] hidden size: [89] trial: 13, train_loss: 1.660804, test loss: 1.026802, bias2: 0.8647390007972717, variance: 0.16206331551074982\n",
      "Train size: [400] hidden size: [89] trial: 14, train_loss: 1.646129, test loss: 1.027732, bias2: 0.8615056276321411, variance: 0.16622671484947205\n",
      "Train size: [400] hidden size: [89] trial: 15, train_loss: 1.647773, test loss: 1.026109, bias2: 0.8619997501373291, variance: 0.16410909593105316\n",
      "Train size: [400] hidden size: [89] trial: 16, train_loss: 1.643937, test loss: 1.026165, bias2: 0.857011079788208, variance: 0.16915372014045715\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [89] trial: 17, train_loss: 1.653144, test loss: 1.026144, bias2: 0.8579217195510864, variance: 0.16822181642055511\n",
      "Train size: [400] hidden size: [89] trial: 18, train_loss: 1.640344, test loss: 1.026590, bias2: 0.8585328459739685, variance: 0.16805702447891235\n",
      "Train size: [400] hidden size: [89] trial: 19, train_loss: 1.635681, test loss: 1.027841, bias2: 0.8572221994400024, variance: 0.17061926424503326\n",
      "Train size: [400] hidden size: [89] trial: 20, train_loss: 1.632196, test loss: 1.025835, bias2: 0.8547733426094055, variance: 0.1710614413022995\n",
      "Train size: [400] hidden size: [89] trial: 21, train_loss: 1.631382, test loss: 1.025011, bias2: 0.8539956212043762, variance: 0.17101579904556274\n",
      "Train size: [400] hidden size: [89] trial: 22, train_loss: 1.621791, test loss: 1.026014, bias2: 0.8559760451316833, variance: 0.1700381487607956\n",
      "Train size: [400] hidden size: [89] trial: 23, train_loss: 1.621731, test loss: 1.024753, bias2: 0.8547491431236267, variance: 0.1700039505958557\n",
      "Train size: [400] hidden size: [89] trial: 24, train_loss: 1.625207, test loss: 1.028346, bias2: 0.8568772077560425, variance: 0.17146888375282288\n",
      "Train size: [400] hidden size: [89] trial: 25, train_loss: 1.624941, test loss: 1.027217, bias2: 0.8565898537635803, variance: 0.170626699924469\n",
      "Train size: [400] hidden size: [89] trial: 26, train_loss: 1.630738, test loss: 1.025972, bias2: 0.8571122288703918, variance: 0.16885967552661896\n",
      "Train size: [400] hidden size: [89] trial: 27, train_loss: 1.628135, test loss: 1.026309, bias2: 0.8554849028587341, variance: 0.17082388699054718\n",
      "Train size: [400] hidden size: [89] trial: 28, train_loss: 1.625264, test loss: 1.026961, bias2: 0.8565162420272827, variance: 0.17044486105442047\n",
      "Train size: [400] hidden size: [89] trial: 29, train_loss: 1.623222, test loss: 1.026371, bias2: 0.855748176574707, variance: 0.1706232726573944\n",
      "Train size: [400] hidden size: [89] trial: 30, train_loss: 1.626114, test loss: 1.025843, bias2: 0.8535500764846802, variance: 0.17229317128658295\n",
      "Train size: [400] hidden size: [89] trial: 31, train_loss: 1.628669, test loss: 1.024774, bias2: 0.8526116609573364, variance: 0.17216192185878754\n",
      "Train size: [400] hidden size: [89] trial: 32, train_loss: 1.629352, test loss: 1.024413, bias2: 0.8517233729362488, variance: 0.17268984019756317\n",
      "Train size: [400] hidden size: [89] trial: 33, train_loss: 1.631327, test loss: 1.025996, bias2: 0.853076159954071, variance: 0.17291980981826782\n",
      "Train size: [400] hidden size: [89] trial: 34, train_loss: 1.631756, test loss: 1.025944, bias2: 0.8538773059844971, variance: 0.17206630110740662\n",
      "Train size: [400] hidden size: [89] trial: 35, train_loss: 1.628462, test loss: 1.024560, bias2: 0.8533637523651123, variance: 0.17119655013084412\n",
      "Train size: [400] hidden size: [89] trial: 36, train_loss: 1.627975, test loss: 1.025222, bias2: 0.8542641997337341, variance: 0.17095738649368286\n",
      "Train size: [400] hidden size: [89] trial: 37, train_loss: 1.628439, test loss: 1.026098, bias2: 0.854568600654602, variance: 0.17152941226959229\n",
      "Train size: [400] hidden size: [89] trial: 38, train_loss: 1.623217, test loss: 1.024383, bias2: 0.8527264595031738, variance: 0.17165672779083252\n",
      "Train size: [400] hidden size: [89] trial: 39, train_loss: 1.621930, test loss: 1.024542, bias2: 0.8528213500976562, variance: 0.17172077298164368\n",
      "Train size: [400] hidden size: [89] trial: 40, train_loss: 1.618502, test loss: 1.026084, bias2: 0.8540359735488892, variance: 0.1720479428768158\n",
      "Train size: [400] hidden size: [89] trial: 41, train_loss: 1.618632, test loss: 1.024669, bias2: 0.8541566133499146, variance: 0.17051242291927338\n",
      "Train size: [400] hidden size: [89] trial: 42, train_loss: 1.614535, test loss: 1.024924, bias2: 0.854200005531311, variance: 0.17072413861751556\n",
      "Train size: [400] hidden size: [89] trial: 43, train_loss: 1.618586, test loss: 1.025079, bias2: 0.8535960912704468, variance: 0.17148281633853912\n",
      "Train size: [400] hidden size: [89] trial: 44, train_loss: 1.618396, test loss: 1.024255, bias2: 0.8537561893463135, variance: 0.17049899697303772\n",
      "Train size: [400] hidden size: [89] trial: 45, train_loss: 1.616506, test loss: 1.025261, bias2: 0.8542850017547607, variance: 0.17097601294517517\n",
      "Train size: [400] hidden size: [89] trial: 46, train_loss: 1.615203, test loss: 1.023904, bias2: 0.8533819913864136, variance: 0.17052245140075684\n",
      "Train size: [400] hidden size: [89] trial: 47, train_loss: 1.614938, test loss: 1.023933, bias2: 0.8540457487106323, variance: 0.16988703608512878\n",
      "Train size: [400] hidden size: [89] trial: 48, train_loss: 1.611709, test loss: 1.024117, bias2: 0.8541427254676819, variance: 0.16997404396533966\n",
      "Train size: [400] hidden size: [89] trial: 49, train_loss: 1.606148, test loss: 1.023792, bias2: 0.8530766367912292, variance: 0.17071527242660522\n",
      "##################################################\n",
      "Train size: [400] hidden size: [102] trial: 0, train_loss: 1.610978, test loss: 1.048276, bias2: 1.048276424407959, variance: 9.731369876586626e-11\n",
      "Train size: [400] hidden size: [102] trial: 1, train_loss: 1.583599, test loss: 1.015361, bias2: 0.9040435552597046, variance: 0.11131764948368073\n",
      "Train size: [400] hidden size: [102] trial: 2, train_loss: 1.589792, test loss: 1.015956, bias2: 0.8664337396621704, variance: 0.14952205121517181\n",
      "Train size: [400] hidden size: [102] trial: 3, train_loss: 1.540803, test loss: 1.028184, bias2: 0.870384931564331, variance: 0.15779946744441986\n",
      "Train size: [400] hidden size: [102] trial: 4, train_loss: 1.575335, test loss: 1.043608, bias2: 0.8788861036300659, variance: 0.16472138464450836\n",
      "Train size: [400] hidden size: [102] trial: 5, train_loss: 1.575983, test loss: 1.035003, bias2: 0.8602372407913208, variance: 0.1747651994228363\n",
      "Train size: [400] hidden size: [102] trial: 6, train_loss: 1.566925, test loss: 1.035378, bias2: 0.8581560850143433, variance: 0.1772213876247406\n",
      "Train size: [400] hidden size: [102] trial: 7, train_loss: 1.570199, test loss: 1.033457, bias2: 0.8558425307273865, variance: 0.1776140183210373\n",
      "Train size: [400] hidden size: [102] trial: 8, train_loss: 1.563540, test loss: 1.035474, bias2: 0.8545738458633423, variance: 0.18090009689331055\n",
      "Train size: [400] hidden size: [102] trial: 9, train_loss: 1.553654, test loss: 1.032422, bias2: 0.8540712594985962, variance: 0.17835034430027008\n",
      "Train size: [400] hidden size: [102] trial: 10, train_loss: 1.550426, test loss: 1.027847, bias2: 0.8499922752380371, variance: 0.17785516381263733\n",
      "Train size: [400] hidden size: [102] trial: 11, train_loss: 1.544598, test loss: 1.025216, bias2: 0.850297212600708, variance: 0.17491842806339264\n",
      "Train size: [400] hidden size: [102] trial: 12, train_loss: 1.545450, test loss: 1.022471, bias2: 0.8506227135658264, variance: 0.17184847593307495\n",
      "Train size: [400] hidden size: [102] trial: 13, train_loss: 1.537321, test loss: 1.023795, bias2: 0.8492298126220703, variance: 0.17456495761871338\n",
      "Train size: [400] hidden size: [102] trial: 14, train_loss: 1.544709, test loss: 1.026136, bias2: 0.8483377695083618, variance: 0.17779794335365295\n",
      "Train size: [400] hidden size: [102] trial: 15, train_loss: 1.533352, test loss: 1.026296, bias2: 0.8499170541763306, variance: 0.17637857794761658\n",
      "Train size: [400] hidden size: [102] trial: 16, train_loss: 1.524678, test loss: 1.021643, bias2: 0.8470458984375, variance: 0.17459715902805328\n",
      "Train size: [400] hidden size: [102] trial: 17, train_loss: 1.522984, test loss: 1.022016, bias2: 0.8461530208587646, variance: 0.1758626401424408\n",
      "Train size: [400] hidden size: [102] trial: 18, train_loss: 1.526055, test loss: 1.018640, bias2: 0.8436019420623779, variance: 0.17503847181797028\n",
      "Train size: [400] hidden size: [102] trial: 19, train_loss: 1.525694, test loss: 1.016263, bias2: 0.8420940041542053, variance: 0.17416876554489136\n",
      "Train size: [400] hidden size: [102] trial: 20, train_loss: 1.524742, test loss: 1.014802, bias2: 0.838483989238739, variance: 0.1763184517621994\n",
      "Train size: [400] hidden size: [102] trial: 21, train_loss: 1.515823, test loss: 1.014176, bias2: 0.837378740310669, variance: 0.1767970472574234\n",
      "Train size: [400] hidden size: [102] trial: 22, train_loss: 1.525419, test loss: 1.014321, bias2: 0.836076021194458, variance: 0.17824456095695496\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [102] trial: 23, train_loss: 1.524975, test loss: 1.013748, bias2: 0.8335801362991333, variance: 0.180168017745018\n",
      "Train size: [400] hidden size: [102] trial: 24, train_loss: 1.520207, test loss: 1.016013, bias2: 0.8355437517166138, variance: 0.18046900629997253\n",
      "Train size: [400] hidden size: [102] trial: 25, train_loss: 1.524197, test loss: 1.017585, bias2: 0.8370496034622192, variance: 0.18053558468818665\n",
      "Train size: [400] hidden size: [102] trial: 26, train_loss: 1.521582, test loss: 1.017221, bias2: 0.8351723551750183, variance: 0.1820485144853592\n",
      "Train size: [400] hidden size: [102] trial: 27, train_loss: 1.530129, test loss: 1.017185, bias2: 0.8344802856445312, variance: 0.18270482122898102\n",
      "Train size: [400] hidden size: [102] trial: 28, train_loss: 1.533507, test loss: 1.016921, bias2: 0.832848846912384, variance: 0.18407195806503296\n",
      "Train size: [400] hidden size: [102] trial: 29, train_loss: 1.534361, test loss: 1.018676, bias2: 0.8344976902008057, variance: 0.18417836725711823\n",
      "Train size: [400] hidden size: [102] trial: 30, train_loss: 1.534275, test loss: 1.019932, bias2: 0.8350682258605957, variance: 0.18486346304416656\n",
      "Train size: [400] hidden size: [102] trial: 31, train_loss: 1.534637, test loss: 1.021993, bias2: 0.8365304470062256, variance: 0.18546262383460999\n",
      "Train size: [400] hidden size: [102] trial: 32, train_loss: 1.531949, test loss: 1.021011, bias2: 0.8371338248252869, variance: 0.1838769167661667\n",
      "Train size: [400] hidden size: [102] trial: 33, train_loss: 1.532907, test loss: 1.020516, bias2: 0.8350318074226379, variance: 0.18548376858234406\n",
      "Train size: [400] hidden size: [102] trial: 34, train_loss: 1.525339, test loss: 1.022227, bias2: 0.8364654779434204, variance: 0.1857612282037735\n",
      "Train size: [400] hidden size: [102] trial: 35, train_loss: 1.523740, test loss: 1.021405, bias2: 0.8362892866134644, variance: 0.18511593341827393\n",
      "Train size: [400] hidden size: [102] trial: 36, train_loss: 1.521514, test loss: 1.019203, bias2: 0.8355749249458313, variance: 0.18362800776958466\n",
      "Train size: [400] hidden size: [102] trial: 37, train_loss: 1.518943, test loss: 1.019442, bias2: 0.8345566987991333, variance: 0.18488536775112152\n",
      "Train size: [400] hidden size: [102] trial: 38, train_loss: 1.525262, test loss: 1.019642, bias2: 0.8353339433670044, variance: 0.1843085139989853\n",
      "Train size: [400] hidden size: [102] trial: 39, train_loss: 1.527914, test loss: 1.017966, bias2: 0.8340909481048584, variance: 0.18387471139431\n",
      "Train size: [400] hidden size: [102] trial: 40, train_loss: 1.529927, test loss: 1.018791, bias2: 0.8348117470741272, variance: 0.1839793175458908\n",
      "Train size: [400] hidden size: [102] trial: 41, train_loss: 1.530548, test loss: 1.017708, bias2: 0.8337957262992859, variance: 0.18391184508800507\n",
      "Train size: [400] hidden size: [102] trial: 42, train_loss: 1.529241, test loss: 1.015872, bias2: 0.8315669298171997, variance: 0.18430480360984802\n",
      "Train size: [400] hidden size: [102] trial: 43, train_loss: 1.529835, test loss: 1.017523, bias2: 0.8323673605918884, variance: 0.18515580892562866\n",
      "Train size: [400] hidden size: [102] trial: 44, train_loss: 1.530746, test loss: 1.018898, bias2: 0.8330902457237244, variance: 0.18580764532089233\n",
      "Train size: [400] hidden size: [102] trial: 45, train_loss: 1.530360, test loss: 1.017745, bias2: 0.8319789171218872, variance: 0.18576647341251373\n",
      "Train size: [400] hidden size: [102] trial: 46, train_loss: 1.530588, test loss: 1.018007, bias2: 0.8309347629547119, variance: 0.18707230687141418\n",
      "Train size: [400] hidden size: [102] trial: 47, train_loss: 1.534240, test loss: 1.016349, bias2: 0.8298157453536987, variance: 0.1865330934524536\n",
      "Train size: [400] hidden size: [102] trial: 48, train_loss: 1.536323, test loss: 1.016987, bias2: 0.8289052844047546, variance: 0.18808166682720184\n",
      "Train size: [400] hidden size: [102] trial: 49, train_loss: 1.539501, test loss: 1.017592, bias2: 0.829292893409729, variance: 0.18829956650733948\n",
      "##################################################\n",
      "Train size: [400] hidden size: [118] trial: 0, train_loss: 1.353873, test loss: 1.001481, bias2: 1.0014805793762207, variance: 1.8489603181848224e-09\n",
      "Train size: [400] hidden size: [118] trial: 1, train_loss: 1.376651, test loss: 1.013948, bias2: 0.9077631831169128, variance: 0.10618463903665543\n",
      "Train size: [400] hidden size: [118] trial: 2, train_loss: 1.368075, test loss: 1.029030, bias2: 0.8673801422119141, variance: 0.16164979338645935\n",
      "Train size: [400] hidden size: [118] trial: 3, train_loss: 1.441907, test loss: 1.038414, bias2: 0.8559511303901672, variance: 0.18246252834796906\n",
      "Train size: [400] hidden size: [118] trial: 4, train_loss: 1.445151, test loss: 1.027226, bias2: 0.8387101888656616, variance: 0.18851543962955475\n",
      "Train size: [400] hidden size: [118] trial: 5, train_loss: 1.461036, test loss: 1.034987, bias2: 0.8354669809341431, variance: 0.19951961934566498\n",
      "Train size: [400] hidden size: [118] trial: 6, train_loss: 1.437947, test loss: 1.039292, bias2: 0.8346868753433228, variance: 0.2046051025390625\n",
      "Train size: [400] hidden size: [118] trial: 7, train_loss: 1.442639, test loss: 1.038234, bias2: 0.8303718566894531, variance: 0.20786166191101074\n",
      "Train size: [400] hidden size: [118] trial: 8, train_loss: 1.445384, test loss: 1.036266, bias2: 0.8285507559776306, variance: 0.2077152281999588\n",
      "Train size: [400] hidden size: [118] trial: 9, train_loss: 1.438071, test loss: 1.039619, bias2: 0.8277530670166016, variance: 0.21186567842960358\n",
      "Train size: [400] hidden size: [118] trial: 10, train_loss: 1.439147, test loss: 1.039562, bias2: 0.8279516100883484, variance: 0.21160989999771118\n",
      "Train size: [400] hidden size: [118] trial: 11, train_loss: 1.446964, test loss: 1.035912, bias2: 0.8258615136146545, variance: 0.21005065739154816\n",
      "Train size: [400] hidden size: [118] trial: 12, train_loss: 1.453646, test loss: 1.035363, bias2: 0.8248250484466553, variance: 0.21053758263587952\n",
      "Train size: [400] hidden size: [118] trial: 13, train_loss: 1.473991, test loss: 1.041215, bias2: 0.8235054612159729, variance: 0.2177092581987381\n",
      "Train size: [400] hidden size: [118] trial: 14, train_loss: 1.482877, test loss: 1.040652, bias2: 0.8223943710327148, variance: 0.21825799345970154\n",
      "Train size: [400] hidden size: [118] trial: 15, train_loss: 1.489629, test loss: 1.036278, bias2: 0.8200992345809937, variance: 0.21617886424064636\n",
      "Train size: [400] hidden size: [118] trial: 16, train_loss: 1.485913, test loss: 1.035172, bias2: 0.8186683654785156, variance: 0.21650364995002747\n",
      "Train size: [400] hidden size: [118] trial: 17, train_loss: 1.487078, test loss: 1.035026, bias2: 0.8201659321784973, variance: 0.21486012637615204\n",
      "Train size: [400] hidden size: [118] trial: 18, train_loss: 1.491402, test loss: 1.034079, bias2: 0.8157848715782166, variance: 0.21829409897327423\n",
      "Train size: [400] hidden size: [118] trial: 19, train_loss: 1.496000, test loss: 1.033331, bias2: 0.815380871295929, variance: 0.21794968843460083\n",
      "Train size: [400] hidden size: [118] trial: 20, train_loss: 1.483843, test loss: 1.032110, bias2: 0.8135511875152588, variance: 0.21855928003787994\n",
      "Train size: [400] hidden size: [118] trial: 21, train_loss: 1.480266, test loss: 1.032102, bias2: 0.8146065473556519, variance: 0.21749581396579742\n",
      "Train size: [400] hidden size: [118] trial: 22, train_loss: 1.467989, test loss: 1.034532, bias2: 0.8180299997329712, variance: 0.21650215983390808\n",
      "Train size: [400] hidden size: [118] trial: 23, train_loss: 1.466975, test loss: 1.032344, bias2: 0.8149696588516235, variance: 0.21737441420555115\n",
      "Train size: [400] hidden size: [118] trial: 24, train_loss: 1.474605, test loss: 1.031494, bias2: 0.8149818778038025, variance: 0.21651214361190796\n",
      "Train size: [400] hidden size: [118] trial: 25, train_loss: 1.473269, test loss: 1.030521, bias2: 0.8137672543525696, variance: 0.21675366163253784\n",
      "Train size: [400] hidden size: [118] trial: 26, train_loss: 1.479880, test loss: 1.033785, bias2: 0.8156190514564514, variance: 0.21816547214984894\n",
      "Train size: [400] hidden size: [118] trial: 27, train_loss: 1.478097, test loss: 1.034552, bias2: 0.8143435120582581, variance: 0.22020882368087769\n",
      "Train size: [400] hidden size: [118] trial: 28, train_loss: 1.479095, test loss: 1.034280, bias2: 0.8128703832626343, variance: 0.22140942513942719\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [118] trial: 29, train_loss: 1.487659, test loss: 1.033706, bias2: 0.8130506873130798, variance: 0.2206553816795349\n",
      "Train size: [400] hidden size: [118] trial: 30, train_loss: 1.484407, test loss: 1.033599, bias2: 0.8116828799247742, variance: 0.22191566228866577\n",
      "Train size: [400] hidden size: [118] trial: 31, train_loss: 1.476022, test loss: 1.031979, bias2: 0.8115252256393433, variance: 0.2204533815383911\n",
      "Train size: [400] hidden size: [118] trial: 32, train_loss: 1.470593, test loss: 1.030719, bias2: 0.8111621737480164, variance: 0.21955721080303192\n",
      "Train size: [400] hidden size: [118] trial: 33, train_loss: 1.475238, test loss: 1.030362, bias2: 0.8105267286300659, variance: 0.2198352813720703\n",
      "Train size: [400] hidden size: [118] trial: 34, train_loss: 1.480807, test loss: 1.030692, bias2: 0.8106937408447266, variance: 0.2199985682964325\n",
      "Train size: [400] hidden size: [118] trial: 35, train_loss: 1.474180, test loss: 1.030361, bias2: 0.8111344575881958, variance: 0.21922644972801208\n",
      "Train size: [400] hidden size: [118] trial: 36, train_loss: 1.476109, test loss: 1.028992, bias2: 0.8090137243270874, variance: 0.21997788548469543\n",
      "Train size: [400] hidden size: [118] trial: 37, train_loss: 1.474315, test loss: 1.027235, bias2: 0.8051019906997681, variance: 0.22213327884674072\n",
      "Train size: [400] hidden size: [118] trial: 38, train_loss: 1.478642, test loss: 1.027953, bias2: 0.8050308227539062, variance: 0.22292254865169525\n",
      "Train size: [400] hidden size: [118] trial: 39, train_loss: 1.484141, test loss: 1.027905, bias2: 0.8050038814544678, variance: 0.22290155291557312\n",
      "Train size: [400] hidden size: [118] trial: 40, train_loss: 1.480984, test loss: 1.028906, bias2: 0.8046449422836304, variance: 0.22426141798496246\n",
      "Train size: [400] hidden size: [118] trial: 41, train_loss: 1.484239, test loss: 1.029394, bias2: 0.8048151731491089, variance: 0.2245790660381317\n",
      "Train size: [400] hidden size: [118] trial: 42, train_loss: 1.481743, test loss: 1.028430, bias2: 0.8038061261177063, variance: 0.22462373971939087\n",
      "Train size: [400] hidden size: [118] trial: 43, train_loss: 1.480322, test loss: 1.028186, bias2: 0.8035165071487427, variance: 0.2246694713830948\n",
      "Train size: [400] hidden size: [118] trial: 44, train_loss: 1.481070, test loss: 1.028416, bias2: 0.8041892051696777, variance: 0.22422660887241364\n",
      "Train size: [400] hidden size: [118] trial: 45, train_loss: 1.482573, test loss: 1.027006, bias2: 0.8028163313865662, variance: 0.22418932616710663\n",
      "Train size: [400] hidden size: [118] trial: 46, train_loss: 1.480974, test loss: 1.026092, bias2: 0.8021536469459534, variance: 0.22393862903118134\n",
      "Train size: [400] hidden size: [118] trial: 47, train_loss: 1.480499, test loss: 1.026055, bias2: 0.8030061721801758, variance: 0.22304846346378326\n",
      "Train size: [400] hidden size: [118] trial: 48, train_loss: 1.480487, test loss: 1.025940, bias2: 0.8032599687576294, variance: 0.2226797491312027\n",
      "Train size: [400] hidden size: [118] trial: 49, train_loss: 1.482384, test loss: 1.025897, bias2: 0.8043915629386902, variance: 0.22150568664073944\n",
      "##################################################\n",
      "Train size: [400] hidden size: [136] trial: 0, train_loss: 1.567108, test loss: 1.067033, bias2: 1.067032814025879, variance: -1.9462740308284765e-09\n",
      "Train size: [400] hidden size: [136] trial: 1, train_loss: 1.442030, test loss: 1.036851, bias2: 0.8926567435264587, variance: 0.14419452846050262\n",
      "Train size: [400] hidden size: [136] trial: 2, train_loss: 1.420453, test loss: 1.056091, bias2: 0.8724970817565918, variance: 0.18359383940696716\n",
      "Train size: [400] hidden size: [136] trial: 3, train_loss: 1.458180, test loss: 1.070619, bias2: 0.8668403625488281, variance: 0.20377865433692932\n",
      "Train size: [400] hidden size: [136] trial: 4, train_loss: 1.450704, test loss: 1.066500, bias2: 0.8484458327293396, variance: 0.21805377304553986\n",
      "Train size: [400] hidden size: [136] trial: 5, train_loss: 1.437903, test loss: 1.069358, bias2: 0.8483678698539734, variance: 0.22099025547504425\n",
      "Train size: [400] hidden size: [136] trial: 6, train_loss: 1.440700, test loss: 1.064884, bias2: 0.8396841287612915, variance: 0.22520016133785248\n",
      "Train size: [400] hidden size: [136] trial: 7, train_loss: 1.449870, test loss: 1.063371, bias2: 0.8356670141220093, variance: 0.22770380973815918\n",
      "Train size: [400] hidden size: [136] trial: 8, train_loss: 1.457657, test loss: 1.059718, bias2: 0.8232295513153076, variance: 0.2364887297153473\n",
      "Train size: [400] hidden size: [136] trial: 9, train_loss: 1.437794, test loss: 1.060433, bias2: 0.8252350091934204, variance: 0.23519767820835114\n",
      "Train size: [400] hidden size: [136] trial: 10, train_loss: 1.439742, test loss: 1.059043, bias2: 0.8221073150634766, variance: 0.2369358390569687\n",
      "Train size: [400] hidden size: [136] trial: 11, train_loss: 1.435295, test loss: 1.064694, bias2: 0.8188474774360657, variance: 0.24584607779979706\n",
      "Train size: [400] hidden size: [136] trial: 12, train_loss: 1.452552, test loss: 1.063543, bias2: 0.8184022903442383, variance: 0.2451404333114624\n",
      "Train size: [400] hidden size: [136] trial: 13, train_loss: 1.448193, test loss: 1.058961, bias2: 0.8090733885765076, variance: 0.24988813698291779\n",
      "Train size: [400] hidden size: [136] trial: 14, train_loss: 1.441325, test loss: 1.055275, bias2: 0.805382251739502, variance: 0.2498929649591446\n",
      "Train size: [400] hidden size: [136] trial: 15, train_loss: 1.429966, test loss: 1.053175, bias2: 0.8024789094924927, variance: 0.2506960332393646\n",
      "Train size: [400] hidden size: [136] trial: 16, train_loss: 1.436799, test loss: 1.054379, bias2: 0.8019555807113647, variance: 0.25242361426353455\n",
      "Train size: [400] hidden size: [136] trial: 17, train_loss: 1.442973, test loss: 1.051717, bias2: 0.7980930805206299, variance: 0.2536240518093109\n",
      "Train size: [400] hidden size: [136] trial: 18, train_loss: 1.437963, test loss: 1.049895, bias2: 0.7969452142715454, variance: 0.2529495656490326\n",
      "Train size: [400] hidden size: [136] trial: 19, train_loss: 1.432046, test loss: 1.045614, bias2: 0.7964111566543579, variance: 0.24920237064361572\n",
      "Train size: [400] hidden size: [136] trial: 20, train_loss: 1.422212, test loss: 1.044885, bias2: 0.7955145835876465, variance: 0.2493705451488495\n",
      "Train size: [400] hidden size: [136] trial: 21, train_loss: 1.416700, test loss: 1.046238, bias2: 0.794273316860199, variance: 0.2519649863243103\n",
      "Train size: [400] hidden size: [136] trial: 22, train_loss: 1.415923, test loss: 1.044159, bias2: 0.7913818359375, variance: 0.252777099609375\n",
      "Train size: [400] hidden size: [136] trial: 23, train_loss: 1.419411, test loss: 1.043073, bias2: 0.7896134257316589, variance: 0.2534591555595398\n",
      "Train size: [400] hidden size: [136] trial: 24, train_loss: 1.424546, test loss: 1.043955, bias2: 0.7909971475601196, variance: 0.2529582977294922\n",
      "Train size: [400] hidden size: [136] trial: 25, train_loss: 1.426698, test loss: 1.043933, bias2: 0.78855961561203, variance: 0.2553732991218567\n",
      "Train size: [400] hidden size: [136] trial: 26, train_loss: 1.430495, test loss: 1.045549, bias2: 0.7914550304412842, variance: 0.2540943920612335\n",
      "Train size: [400] hidden size: [136] trial: 27, train_loss: 1.428078, test loss: 1.044425, bias2: 0.7902103662490845, variance: 0.2542145550251007\n",
      "Train size: [400] hidden size: [136] trial: 28, train_loss: 1.434073, test loss: 1.041790, bias2: 0.7890608310699463, variance: 0.25272905826568604\n",
      "Train size: [400] hidden size: [136] trial: 29, train_loss: 1.430032, test loss: 1.041230, bias2: 0.7899916172027588, variance: 0.2512385845184326\n",
      "Train size: [400] hidden size: [136] trial: 30, train_loss: 1.428513, test loss: 1.043722, bias2: 0.7925204038619995, variance: 0.25120165944099426\n",
      "Train size: [400] hidden size: [136] trial: 31, train_loss: 1.424789, test loss: 1.042412, bias2: 0.7924449443817139, variance: 0.2499673217535019\n",
      "Train size: [400] hidden size: [136] trial: 32, train_loss: 1.420172, test loss: 1.040545, bias2: 0.7911208868026733, variance: 0.24942395091056824\n",
      "Train size: [400] hidden size: [136] trial: 33, train_loss: 1.420270, test loss: 1.039891, bias2: 0.7907649278640747, variance: 0.24912630021572113\n",
      "Train size: [400] hidden size: [136] trial: 34, train_loss: 1.417961, test loss: 1.038617, bias2: 0.7903156876564026, variance: 0.24830158054828644\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [136] trial: 35, train_loss: 1.415001, test loss: 1.037870, bias2: 0.7906618714332581, variance: 0.24720843136310577\n",
      "Train size: [400] hidden size: [136] trial: 36, train_loss: 1.417734, test loss: 1.038535, bias2: 0.7905232906341553, variance: 0.2480112463235855\n",
      "Train size: [400] hidden size: [136] trial: 37, train_loss: 1.418414, test loss: 1.037479, bias2: 0.7879750728607178, variance: 0.24950386583805084\n",
      "Train size: [400] hidden size: [136] trial: 38, train_loss: 1.418973, test loss: 1.037353, bias2: 0.7875440716743469, variance: 0.24980920553207397\n",
      "Train size: [400] hidden size: [136] trial: 39, train_loss: 1.415004, test loss: 1.035972, bias2: 0.7855360507965088, variance: 0.25043585896492004\n",
      "Train size: [400] hidden size: [136] trial: 40, train_loss: 1.415382, test loss: 1.036466, bias2: 0.7860133647918701, variance: 0.2504526376724243\n",
      "Train size: [400] hidden size: [136] trial: 41, train_loss: 1.415051, test loss: 1.035878, bias2: 0.78514564037323, variance: 0.2507326304912567\n",
      "Train size: [400] hidden size: [136] trial: 42, train_loss: 1.413958, test loss: 1.036652, bias2: 0.7856458425521851, variance: 0.25100603699684143\n",
      "Train size: [400] hidden size: [136] trial: 43, train_loss: 1.411442, test loss: 1.037108, bias2: 0.7853566408157349, variance: 0.2517518103122711\n",
      "Train size: [400] hidden size: [136] trial: 44, train_loss: 1.414152, test loss: 1.035557, bias2: 0.7838113903999329, variance: 0.2517457604408264\n",
      "Train size: [400] hidden size: [136] trial: 45, train_loss: 1.411047, test loss: 1.036671, bias2: 0.7851013541221619, variance: 0.25156933069229126\n",
      "Train size: [400] hidden size: [136] trial: 46, train_loss: 1.413145, test loss: 1.035958, bias2: 0.7835748791694641, variance: 0.2523830533027649\n",
      "Train size: [400] hidden size: [136] trial: 47, train_loss: 1.416473, test loss: 1.035795, bias2: 0.7836434841156006, variance: 0.25215110182762146\n",
      "Train size: [400] hidden size: [136] trial: 48, train_loss: 1.416070, test loss: 1.035285, bias2: 0.7828981280326843, variance: 0.25238651037216187\n",
      "Train size: [400] hidden size: [136] trial: 49, train_loss: 1.413720, test loss: 1.035839, bias2: 0.7835358381271362, variance: 0.2523029148578644\n",
      "##################################################\n",
      "Train size: [400] hidden size: [156] trial: 0, train_loss: 1.285129, test loss: 1.010254, bias2: 1.0102535486221313, variance: 5.838822203507732e-10\n",
      "Train size: [400] hidden size: [156] trial: 1, train_loss: 1.329236, test loss: 1.039160, bias2: 0.9043419361114502, variance: 0.13481858372688293\n",
      "Train size: [400] hidden size: [156] trial: 2, train_loss: 1.331302, test loss: 1.036428, bias2: 0.8457522988319397, variance: 0.1906755417585373\n",
      "Train size: [400] hidden size: [156] trial: 3, train_loss: 1.316639, test loss: 1.031419, bias2: 0.8082675933837891, variance: 0.22315166890621185\n",
      "Train size: [400] hidden size: [156] trial: 4, train_loss: 1.294537, test loss: 1.025228, bias2: 0.7892341017723083, variance: 0.23599404096603394\n",
      "Train size: [400] hidden size: [156] trial: 5, train_loss: 1.312911, test loss: 1.038165, bias2: 0.7907259464263916, variance: 0.24743928015232086\n",
      "Train size: [400] hidden size: [156] trial: 6, train_loss: 1.322528, test loss: 1.044605, bias2: 0.7873462438583374, variance: 0.2572583258152008\n",
      "Train size: [400] hidden size: [156] trial: 7, train_loss: 1.322914, test loss: 1.043956, bias2: 0.777613639831543, variance: 0.26634225249290466\n",
      "Train size: [400] hidden size: [156] trial: 8, train_loss: 1.314227, test loss: 1.039933, bias2: 0.7684333324432373, variance: 0.27149930596351624\n",
      "Train size: [400] hidden size: [156] trial: 9, train_loss: 1.315491, test loss: 1.047893, bias2: 0.772275447845459, variance: 0.2756172716617584\n",
      "Train size: [400] hidden size: [156] trial: 10, train_loss: 1.328031, test loss: 1.048831, bias2: 0.7701554298400879, variance: 0.2786750793457031\n",
      "Train size: [400] hidden size: [156] trial: 11, train_loss: 1.341001, test loss: 1.046667, bias2: 0.7625412940979004, variance: 0.2841254472732544\n",
      "Train size: [400] hidden size: [156] trial: 12, train_loss: 1.333815, test loss: 1.045334, bias2: 0.7625324726104736, variance: 0.2828013002872467\n",
      "Train size: [400] hidden size: [156] trial: 13, train_loss: 1.346338, test loss: 1.047603, bias2: 0.7618669271469116, variance: 0.28573569655418396\n",
      "Train size: [400] hidden size: [156] trial: 14, train_loss: 1.360198, test loss: 1.054662, bias2: 0.7624592185020447, variance: 0.29220300912857056\n",
      "Train size: [400] hidden size: [156] trial: 15, train_loss: 1.359816, test loss: 1.053597, bias2: 0.758047342300415, variance: 0.2955498993396759\n",
      "Train size: [400] hidden size: [156] trial: 16, train_loss: 1.351152, test loss: 1.056405, bias2: 0.7611479163169861, variance: 0.29525691270828247\n",
      "Train size: [400] hidden size: [156] trial: 17, train_loss: 1.347352, test loss: 1.051506, bias2: 0.7558420896530151, variance: 0.2956638038158417\n",
      "Train size: [400] hidden size: [156] trial: 18, train_loss: 1.346713, test loss: 1.051941, bias2: 0.75873863697052, variance: 0.2932027578353882\n",
      "Train size: [400] hidden size: [156] trial: 19, train_loss: 1.347982, test loss: 1.054415, bias2: 0.7589380145072937, variance: 0.29547709226608276\n",
      "Train size: [400] hidden size: [156] trial: 20, train_loss: 1.337227, test loss: 1.054859, bias2: 0.7587616443634033, variance: 0.29609742760658264\n",
      "Train size: [400] hidden size: [156] trial: 21, train_loss: 1.333425, test loss: 1.054157, bias2: 0.7597881555557251, variance: 0.2943686544895172\n",
      "Train size: [400] hidden size: [156] trial: 22, train_loss: 1.331434, test loss: 1.050106, bias2: 0.7561308145523071, variance: 0.29397544264793396\n",
      "Train size: [400] hidden size: [156] trial: 23, train_loss: 1.336910, test loss: 1.050009, bias2: 0.756047785282135, variance: 0.2939611077308655\n",
      "Train size: [400] hidden size: [156] trial: 24, train_loss: 1.338024, test loss: 1.050896, bias2: 0.7583107948303223, variance: 0.2925852835178375\n",
      "Train size: [400] hidden size: [156] trial: 25, train_loss: 1.339388, test loss: 1.050100, bias2: 0.7531611323356628, variance: 0.296938955783844\n",
      "Train size: [400] hidden size: [156] trial: 26, train_loss: 1.338229, test loss: 1.048358, bias2: 0.7483958005905151, variance: 0.2999626100063324\n",
      "Train size: [400] hidden size: [156] trial: 27, train_loss: 1.344938, test loss: 1.050344, bias2: 0.7487373352050781, variance: 0.3016066253185272\n",
      "Train size: [400] hidden size: [156] trial: 28, train_loss: 1.343134, test loss: 1.050626, bias2: 0.749407172203064, variance: 0.30121922492980957\n",
      "Train size: [400] hidden size: [156] trial: 29, train_loss: 1.338026, test loss: 1.050252, bias2: 0.7455918788909912, variance: 0.3046603202819824\n",
      "Train size: [400] hidden size: [156] trial: 30, train_loss: 1.336875, test loss: 1.049717, bias2: 0.7457780241966248, variance: 0.3039394021034241\n",
      "Train size: [400] hidden size: [156] trial: 31, train_loss: 1.343874, test loss: 1.050253, bias2: 0.7459583878517151, variance: 0.3042951226234436\n",
      "Train size: [400] hidden size: [156] trial: 32, train_loss: 1.341427, test loss: 1.049101, bias2: 0.7457253932952881, variance: 0.30337515473365784\n",
      "Train size: [400] hidden size: [156] trial: 33, train_loss: 1.341975, test loss: 1.048826, bias2: 0.7442425489425659, variance: 0.3045835494995117\n",
      "Train size: [400] hidden size: [156] trial: 34, train_loss: 1.340854, test loss: 1.047856, bias2: 0.7453388571739197, variance: 0.30251699686050415\n",
      "Train size: [400] hidden size: [156] trial: 35, train_loss: 1.338329, test loss: 1.047225, bias2: 0.7440177202224731, variance: 0.30320778489112854\n",
      "Train size: [400] hidden size: [156] trial: 36, train_loss: 1.337365, test loss: 1.046886, bias2: 0.7453016638755798, variance: 0.30158454179763794\n",
      "Train size: [400] hidden size: [156] trial: 37, train_loss: 1.334636, test loss: 1.045589, bias2: 0.7445173859596252, variance: 0.3010713458061218\n",
      "Train size: [400] hidden size: [156] trial: 38, train_loss: 1.337842, test loss: 1.044688, bias2: 0.7438350915908813, variance: 0.3008524477481842\n",
      "Train size: [400] hidden size: [156] trial: 39, train_loss: 1.336879, test loss: 1.045274, bias2: 0.7451242804527283, variance: 0.3001496195793152\n",
      "Train size: [400] hidden size: [156] trial: 40, train_loss: 1.338902, test loss: 1.044531, bias2: 0.7459786534309387, variance: 0.2985526919364929\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [156] trial: 41, train_loss: 1.340113, test loss: 1.043760, bias2: 0.7450811266899109, variance: 0.298678457736969\n",
      "Train size: [400] hidden size: [156] trial: 42, train_loss: 1.338657, test loss: 1.043302, bias2: 0.7462334632873535, variance: 0.29706844687461853\n",
      "Train size: [400] hidden size: [156] trial: 43, train_loss: 1.340077, test loss: 1.042907, bias2: 0.7463436722755432, variance: 0.2965635657310486\n",
      "Train size: [400] hidden size: [156] trial: 44, train_loss: 1.340955, test loss: 1.043533, bias2: 0.7460528612136841, variance: 0.2974800765514374\n",
      "Train size: [400] hidden size: [156] trial: 45, train_loss: 1.337373, test loss: 1.042913, bias2: 0.7465000152587891, variance: 0.29641303420066833\n",
      "Train size: [400] hidden size: [156] trial: 46, train_loss: 1.339533, test loss: 1.043603, bias2: 0.746741771697998, variance: 0.2968612015247345\n",
      "Train size: [400] hidden size: [156] trial: 47, train_loss: 1.341050, test loss: 1.043323, bias2: 0.7459248304367065, variance: 0.29739829897880554\n",
      "Train size: [400] hidden size: [156] trial: 48, train_loss: 1.340056, test loss: 1.043305, bias2: 0.7451307773590088, variance: 0.298174649477005\n",
      "Train size: [400] hidden size: [156] trial: 49, train_loss: 1.339541, test loss: 1.043662, bias2: 0.7449299097061157, variance: 0.29873183369636536\n",
      "##################################################\n",
      "Train size: [400] hidden size: [180] trial: 0, train_loss: 1.543682, test loss: 1.082831, bias2: 1.0828306674957275, variance: 3.8925479506346505e-10\n",
      "Train size: [400] hidden size: [180] trial: 1, train_loss: 1.494295, test loss: 1.067805, bias2: 0.8681578040122986, variance: 0.19964666664600372\n",
      "Train size: [400] hidden size: [180] trial: 2, train_loss: 1.449891, test loss: 1.068292, bias2: 0.8173681497573853, variance: 0.25092384219169617\n",
      "Train size: [400] hidden size: [180] trial: 3, train_loss: 1.426620, test loss: 1.083770, bias2: 0.8034555912017822, variance: 0.28031444549560547\n",
      "Train size: [400] hidden size: [180] trial: 4, train_loss: 1.368791, test loss: 1.074041, bias2: 0.7751524448394775, variance: 0.2988888919353485\n",
      "Train size: [400] hidden size: [180] trial: 5, train_loss: 1.359340, test loss: 1.066345, bias2: 0.7577801942825317, variance: 0.30856433510780334\n",
      "Train size: [400] hidden size: [180] trial: 6, train_loss: 1.351976, test loss: 1.056784, bias2: 0.7466989159584045, variance: 0.3100854754447937\n",
      "Train size: [400] hidden size: [180] trial: 7, train_loss: 1.350610, test loss: 1.062628, bias2: 0.748296320438385, variance: 0.314331591129303\n",
      "Train size: [400] hidden size: [180] trial: 8, train_loss: 1.335057, test loss: 1.060226, bias2: 0.7373719215393066, variance: 0.32285377383232117\n",
      "Train size: [400] hidden size: [180] trial: 9, train_loss: 1.326394, test loss: 1.062241, bias2: 0.7335292100906372, variance: 0.3287116289138794\n",
      "Train size: [400] hidden size: [180] trial: 10, train_loss: 1.329482, test loss: 1.061654, bias2: 0.7276692986488342, variance: 0.33398503065109253\n",
      "Train size: [400] hidden size: [180] trial: 11, train_loss: 1.334423, test loss: 1.061390, bias2: 0.7264175415039062, variance: 0.3349727690219879\n",
      "Train size: [400] hidden size: [180] trial: 12, train_loss: 1.322475, test loss: 1.053666, bias2: 0.719224214553833, variance: 0.3344416320323944\n",
      "Train size: [400] hidden size: [180] trial: 13, train_loss: 1.316491, test loss: 1.059280, bias2: 0.7238674163818359, variance: 0.3354123830795288\n",
      "Train size: [400] hidden size: [180] trial: 14, train_loss: 1.309134, test loss: 1.051887, bias2: 0.7142608761787415, variance: 0.3376263976097107\n",
      "Train size: [400] hidden size: [180] trial: 15, train_loss: 1.300062, test loss: 1.049602, bias2: 0.7159425020217896, variance: 0.3336595594882965\n",
      "Train size: [400] hidden size: [180] trial: 16, train_loss: 1.296674, test loss: 1.056773, bias2: 0.7211391925811768, variance: 0.33563360571861267\n",
      "Train size: [400] hidden size: [180] trial: 17, train_loss: 1.300752, test loss: 1.058614, bias2: 0.7213088274002075, variance: 0.33730533719062805\n",
      "Train size: [400] hidden size: [180] trial: 18, train_loss: 1.307129, test loss: 1.060123, bias2: 0.7248491048812866, variance: 0.33527377247810364\n",
      "Train size: [400] hidden size: [180] trial: 19, train_loss: 1.306939, test loss: 1.058669, bias2: 0.725690484046936, variance: 0.3329789340496063\n",
      "Train size: [400] hidden size: [180] trial: 20, train_loss: 1.307318, test loss: 1.059821, bias2: 0.7271682024002075, variance: 0.33265307545661926\n",
      "Train size: [400] hidden size: [180] trial: 21, train_loss: 1.299550, test loss: 1.061349, bias2: 0.7274874448776245, variance: 0.3338618576526642\n",
      "Train size: [400] hidden size: [180] trial: 22, train_loss: 1.298489, test loss: 1.060964, bias2: 0.725814700126648, variance: 0.3351494073867798\n",
      "Train size: [400] hidden size: [180] trial: 23, train_loss: 1.296806, test loss: 1.058919, bias2: 0.7214910387992859, variance: 0.33742755651474\n",
      "Train size: [400] hidden size: [180] trial: 24, train_loss: 1.298953, test loss: 1.054861, bias2: 0.7201308012008667, variance: 0.3347298204898834\n",
      "Train size: [400] hidden size: [180] trial: 25, train_loss: 1.290119, test loss: 1.052166, bias2: 0.715804934501648, variance: 0.3363606929779053\n",
      "Train size: [400] hidden size: [180] trial: 26, train_loss: 1.290051, test loss: 1.053239, bias2: 0.7167946100234985, variance: 0.3364444971084595\n",
      "Train size: [400] hidden size: [180] trial: 27, train_loss: 1.290878, test loss: 1.054149, bias2: 0.7159556746482849, variance: 0.3381938338279724\n",
      "Train size: [400] hidden size: [180] trial: 28, train_loss: 1.291762, test loss: 1.053454, bias2: 0.7166869640350342, variance: 0.33676669001579285\n",
      "Train size: [400] hidden size: [180] trial: 29, train_loss: 1.295562, test loss: 1.055494, bias2: 0.7169437408447266, variance: 0.33855023980140686\n",
      "Train size: [400] hidden size: [180] trial: 30, train_loss: 1.297189, test loss: 1.052551, bias2: 0.713904619216919, variance: 0.3386462926864624\n",
      "Train size: [400] hidden size: [180] trial: 31, train_loss: 1.296426, test loss: 1.054797, bias2: 0.7158888578414917, variance: 0.3389084041118622\n",
      "Train size: [400] hidden size: [180] trial: 32, train_loss: 1.292692, test loss: 1.056271, bias2: 0.7177022099494934, variance: 0.3385687470436096\n",
      "Train size: [400] hidden size: [180] trial: 33, train_loss: 1.290160, test loss: 1.055120, bias2: 0.7175103425979614, variance: 0.3376096189022064\n",
      "Train size: [400] hidden size: [180] trial: 34, train_loss: 1.287706, test loss: 1.056355, bias2: 0.7174586653709412, variance: 0.3388959765434265\n",
      "Train size: [400] hidden size: [180] trial: 35, train_loss: 1.286331, test loss: 1.055768, bias2: 0.7163517475128174, variance: 0.33941638469696045\n",
      "Train size: [400] hidden size: [180] trial: 36, train_loss: 1.284525, test loss: 1.057509, bias2: 0.7186925411224365, variance: 0.33881649374961853\n",
      "Train size: [400] hidden size: [180] trial: 37, train_loss: 1.283573, test loss: 1.056622, bias2: 0.7184443473815918, variance: 0.3381774127483368\n",
      "Train size: [400] hidden size: [180] trial: 38, train_loss: 1.283579, test loss: 1.057176, bias2: 0.7186976671218872, variance: 0.3384786546230316\n",
      "Train size: [400] hidden size: [180] trial: 39, train_loss: 1.286469, test loss: 1.057244, bias2: 0.718574583530426, variance: 0.3386690020561218\n",
      "Train size: [400] hidden size: [180] trial: 40, train_loss: 1.285601, test loss: 1.056673, bias2: 0.7175530195236206, variance: 0.33911970257759094\n",
      "Train size: [400] hidden size: [180] trial: 41, train_loss: 1.287715, test loss: 1.056164, bias2: 0.7144560813903809, variance: 0.34170815348625183\n",
      "Train size: [400] hidden size: [180] trial: 42, train_loss: 1.287339, test loss: 1.059616, bias2: 0.7159572839736938, variance: 0.3436586856842041\n",
      "Train size: [400] hidden size: [180] trial: 43, train_loss: 1.286445, test loss: 1.059454, bias2: 0.7161272764205933, variance: 0.34332719445228577\n",
      "Train size: [400] hidden size: [180] trial: 44, train_loss: 1.289555, test loss: 1.059183, bias2: 0.7157838940620422, variance: 0.3433991074562073\n",
      "Train size: [400] hidden size: [180] trial: 45, train_loss: 1.287704, test loss: 1.057985, bias2: 0.7152074575424194, variance: 0.34277787804603577\n",
      "Train size: [400] hidden size: [180] trial: 46, train_loss: 1.282284, test loss: 1.058171, bias2: 0.7136330604553223, variance: 0.344537615776062\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [180] trial: 47, train_loss: 1.281358, test loss: 1.056912, bias2: 0.7127363681793213, variance: 0.34417518973350525\n",
      "Train size: [400] hidden size: [180] trial: 48, train_loss: 1.280164, test loss: 1.057398, bias2: 0.7128413915634155, variance: 0.34455621242523193\n",
      "Train size: [400] hidden size: [180] trial: 49, train_loss: 1.278024, test loss: 1.059212, bias2: 0.713491678237915, variance: 0.34572073817253113\n",
      "##################################################\n",
      "Train size: [400] hidden size: [207] trial: 0, train_loss: 1.265883, test loss: 1.112370, bias2: 1.1123701333999634, variance: 3.8925479506346505e-10\n",
      "Train size: [400] hidden size: [207] trial: 1, train_loss: 1.207269, test loss: 1.108002, bias2: 0.8907641172409058, variance: 0.21723772585391998\n",
      "Train size: [400] hidden size: [207] trial: 2, train_loss: 1.213192, test loss: 1.087356, bias2: 0.8105186223983765, variance: 0.27683696150779724\n",
      "Train size: [400] hidden size: [207] trial: 3, train_loss: 1.231529, test loss: 1.073524, bias2: 0.7695514559745789, variance: 0.30397242307662964\n",
      "Train size: [400] hidden size: [207] trial: 4, train_loss: 1.203813, test loss: 1.048778, bias2: 0.7396481037139893, variance: 0.3091299533843994\n",
      "Train size: [400] hidden size: [207] trial: 5, train_loss: 1.194229, test loss: 1.064744, bias2: 0.7279441356658936, variance: 0.33679986000061035\n",
      "Train size: [400] hidden size: [207] trial: 6, train_loss: 1.230698, test loss: 1.079267, bias2: 0.7322996258735657, variance: 0.3469669222831726\n",
      "Train size: [400] hidden size: [207] trial: 7, train_loss: 1.232804, test loss: 1.079961, bias2: 0.7185491323471069, variance: 0.36141204833984375\n",
      "Train size: [400] hidden size: [207] trial: 8, train_loss: 1.229025, test loss: 1.075222, bias2: 0.7096806764602661, variance: 0.36554157733917236\n",
      "Train size: [400] hidden size: [207] trial: 9, train_loss: 1.223487, test loss: 1.077902, bias2: 0.7123416066169739, variance: 0.36556047201156616\n",
      "Train size: [400] hidden size: [207] trial: 10, train_loss: 1.233719, test loss: 1.080380, bias2: 0.7098588347434998, variance: 0.3705208897590637\n",
      "Train size: [400] hidden size: [207] trial: 11, train_loss: 1.242059, test loss: 1.087001, bias2: 0.7093914747238159, variance: 0.3776092529296875\n",
      "Train size: [400] hidden size: [207] trial: 12, train_loss: 1.241395, test loss: 1.082547, bias2: 0.7051278352737427, variance: 0.37741944193840027\n",
      "Train size: [400] hidden size: [207] trial: 13, train_loss: 1.237544, test loss: 1.082223, bias2: 0.6992675065994263, variance: 0.3829551935195923\n",
      "Train size: [400] hidden size: [207] trial: 14, train_loss: 1.231866, test loss: 1.081339, bias2: 0.6965627670288086, variance: 0.38477611541748047\n",
      "Train size: [400] hidden size: [207] trial: 15, train_loss: 1.233774, test loss: 1.082611, bias2: 0.6967381834983826, variance: 0.385873019695282\n",
      "Train size: [400] hidden size: [207] trial: 16, train_loss: 1.225322, test loss: 1.087160, bias2: 0.6971440315246582, variance: 0.3900162875652313\n",
      "Train size: [400] hidden size: [207] trial: 17, train_loss: 1.216404, test loss: 1.091019, bias2: 0.7011874914169312, variance: 0.3898310363292694\n",
      "Train size: [400] hidden size: [207] trial: 18, train_loss: 1.217990, test loss: 1.090685, bias2: 0.698824405670166, variance: 0.39186111092567444\n",
      "Train size: [400] hidden size: [207] trial: 19, train_loss: 1.209444, test loss: 1.091254, bias2: 0.7027879357337952, variance: 0.38846641778945923\n",
      "Train size: [400] hidden size: [207] trial: 20, train_loss: 1.201301, test loss: 1.095050, bias2: 0.7028195858001709, variance: 0.3922308385372162\n",
      "Train size: [400] hidden size: [207] trial: 21, train_loss: 1.202002, test loss: 1.092989, bias2: 0.7038352489471436, variance: 0.38915327191352844\n",
      "Train size: [400] hidden size: [207] trial: 22, train_loss: 1.199366, test loss: 1.094131, bias2: 0.7047356963157654, variance: 0.38939541578292847\n",
      "Train size: [400] hidden size: [207] trial: 23, train_loss: 1.202399, test loss: 1.095051, bias2: 0.7041046619415283, variance: 0.3909459412097931\n",
      "Train size: [400] hidden size: [207] trial: 24, train_loss: 1.198344, test loss: 1.094354, bias2: 0.7022013068199158, variance: 0.39215320348739624\n",
      "Train size: [400] hidden size: [207] trial: 25, train_loss: 1.196070, test loss: 1.094827, bias2: 0.700143575668335, variance: 0.39468297362327576\n",
      "Train size: [400] hidden size: [207] trial: 26, train_loss: 1.196766, test loss: 1.097457, bias2: 0.7028664946556091, variance: 0.39459091424942017\n",
      "Train size: [400] hidden size: [207] trial: 27, train_loss: 1.195096, test loss: 1.096095, bias2: 0.7009637951850891, variance: 0.3951314091682434\n",
      "Train size: [400] hidden size: [207] trial: 28, train_loss: 1.200013, test loss: 1.096524, bias2: 0.6993528604507446, variance: 0.39717069268226624\n",
      "Train size: [400] hidden size: [207] trial: 29, train_loss: 1.198687, test loss: 1.095886, bias2: 0.6966598033905029, variance: 0.3992266356945038\n",
      "Train size: [400] hidden size: [207] trial: 30, train_loss: 1.197200, test loss: 1.096255, bias2: 0.695042073726654, variance: 0.4012126326560974\n",
      "Train size: [400] hidden size: [207] trial: 31, train_loss: 1.196938, test loss: 1.095689, bias2: 0.698641836643219, variance: 0.3970469832420349\n",
      "Train size: [400] hidden size: [207] trial: 32, train_loss: 1.191645, test loss: 1.095053, bias2: 0.6957771182060242, variance: 0.39927607774734497\n",
      "Train size: [400] hidden size: [207] trial: 33, train_loss: 1.197042, test loss: 1.093872, bias2: 0.6964254379272461, variance: 0.39744699001312256\n",
      "Train size: [400] hidden size: [207] trial: 34, train_loss: 1.198983, test loss: 1.093576, bias2: 0.6957180500030518, variance: 0.39785823225975037\n",
      "Train size: [400] hidden size: [207] trial: 35, train_loss: 1.194317, test loss: 1.092926, bias2: 0.6953452825546265, variance: 0.3975805342197418\n",
      "Train size: [400] hidden size: [207] trial: 36, train_loss: 1.193921, test loss: 1.093539, bias2: 0.6949446201324463, variance: 0.398594468832016\n",
      "Train size: [400] hidden size: [207] trial: 37, train_loss: 1.195182, test loss: 1.094088, bias2: 0.6940834522247314, variance: 0.40000471472740173\n",
      "Train size: [400] hidden size: [207] trial: 38, train_loss: 1.192636, test loss: 1.096099, bias2: 0.6931087970733643, variance: 0.4029906094074249\n",
      "Train size: [400] hidden size: [207] trial: 39, train_loss: 1.190631, test loss: 1.096496, bias2: 0.6917039752006531, variance: 0.4047916531562805\n",
      "Train size: [400] hidden size: [207] trial: 40, train_loss: 1.191093, test loss: 1.094186, bias2: 0.6891930103302002, variance: 0.40499284863471985\n",
      "Train size: [400] hidden size: [207] trial: 41, train_loss: 1.188112, test loss: 1.094904, bias2: 0.6870770454406738, variance: 0.40782663226127625\n",
      "Train size: [400] hidden size: [207] trial: 42, train_loss: 1.187660, test loss: 1.094392, bias2: 0.6838515400886536, variance: 0.4105401635169983\n",
      "Train size: [400] hidden size: [207] trial: 43, train_loss: 1.183703, test loss: 1.094209, bias2: 0.6816478371620178, variance: 0.41256123781204224\n",
      "Train size: [400] hidden size: [207] trial: 44, train_loss: 1.181920, test loss: 1.095410, bias2: 0.6805546879768372, variance: 0.4148557782173157\n",
      "Train size: [400] hidden size: [207] trial: 45, train_loss: 1.185217, test loss: 1.095766, bias2: 0.6798712611198425, variance: 0.4158943295478821\n",
      "Train size: [400] hidden size: [207] trial: 46, train_loss: 1.185474, test loss: 1.097084, bias2: 0.6793431043624878, variance: 0.4177406132221222\n",
      "Train size: [400] hidden size: [207] trial: 47, train_loss: 1.184889, test loss: 1.097930, bias2: 0.6801602840423584, variance: 0.4177699387073517\n",
      "Train size: [400] hidden size: [207] trial: 48, train_loss: 1.182173, test loss: 1.097178, bias2: 0.6784778833389282, variance: 0.41870033740997314\n",
      "Train size: [400] hidden size: [207] trial: 49, train_loss: 1.181150, test loss: 1.097777, bias2: 0.6777575612068176, variance: 0.42001956701278687\n",
      "##################################################\n",
      "Train size: [400] hidden size: [239] trial: 0, train_loss: 1.099984, test loss: 1.133149, bias2: 1.1331490278244019, variance: 3.8925479506346505e-10\n",
      "Train size: [400] hidden size: [239] trial: 1, train_loss: 1.109343, test loss: 1.058056, bias2: 0.8190303444862366, variance: 0.23902539908885956\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [239] trial: 2, train_loss: 1.104234, test loss: 1.099775, bias2: 0.7638051509857178, variance: 0.33596980571746826\n",
      "Train size: [400] hidden size: [239] trial: 3, train_loss: 1.104258, test loss: 1.096153, bias2: 0.715939998626709, variance: 0.3802126348018646\n",
      "Train size: [400] hidden size: [239] trial: 4, train_loss: 1.107339, test loss: 1.104861, bias2: 0.6947673559188843, variance: 0.41009414196014404\n",
      "Train size: [400] hidden size: [239] trial: 5, train_loss: 1.088713, test loss: 1.105579, bias2: 0.6900549530982971, variance: 0.4155239462852478\n",
      "Train size: [400] hidden size: [239] trial: 6, train_loss: 1.084690, test loss: 1.103697, bias2: 0.6803259253501892, variance: 0.4233711361885071\n",
      "Train size: [400] hidden size: [239] trial: 7, train_loss: 1.079035, test loss: 1.105574, bias2: 0.6735286712646484, variance: 0.4320451319217682\n",
      "Train size: [400] hidden size: [239] trial: 8, train_loss: 1.077290, test loss: 1.111354, bias2: 0.6676305532455444, variance: 0.44372329115867615\n",
      "Train size: [400] hidden size: [239] trial: 9, train_loss: 1.080425, test loss: 1.107602, bias2: 0.6656845808029175, variance: 0.44191718101501465\n",
      "Train size: [400] hidden size: [239] trial: 10, train_loss: 1.086114, test loss: 1.104643, bias2: 0.662001371383667, variance: 0.4426412284374237\n",
      "Train size: [400] hidden size: [239] trial: 11, train_loss: 1.085327, test loss: 1.097529, bias2: 0.6581586599349976, variance: 0.4393702447414398\n",
      "Train size: [400] hidden size: [239] trial: 12, train_loss: 1.070829, test loss: 1.098980, bias2: 0.6626788377761841, variance: 0.4363013207912445\n",
      "Train size: [400] hidden size: [239] trial: 13, train_loss: 1.064798, test loss: 1.099966, bias2: 0.6564576029777527, variance: 0.4435088038444519\n",
      "Train size: [400] hidden size: [239] trial: 14, train_loss: 1.067367, test loss: 1.095824, bias2: 0.6504690647125244, variance: 0.44535502791404724\n",
      "Train size: [400] hidden size: [239] trial: 15, train_loss: 1.059428, test loss: 1.091296, bias2: 0.651703417301178, variance: 0.4395928978919983\n",
      "Train size: [400] hidden size: [239] trial: 16, train_loss: 1.067734, test loss: 1.088592, bias2: 0.64593905210495, variance: 0.44265347719192505\n",
      "Train size: [400] hidden size: [239] trial: 17, train_loss: 1.066283, test loss: 1.088671, bias2: 0.6459764242172241, variance: 0.442694753408432\n",
      "Train size: [400] hidden size: [239] trial: 18, train_loss: 1.058469, test loss: 1.093831, bias2: 0.6478956937789917, variance: 0.44593533873558044\n",
      "Train size: [400] hidden size: [239] trial: 19, train_loss: 1.069127, test loss: 1.092574, bias2: 0.6437027454376221, variance: 0.44887086749076843\n",
      "Train size: [400] hidden size: [239] trial: 20, train_loss: 1.066432, test loss: 1.092800, bias2: 0.6469265222549438, variance: 0.44587329030036926\n",
      "Train size: [400] hidden size: [239] trial: 21, train_loss: 1.066567, test loss: 1.094716, bias2: 0.6483367085456848, variance: 0.44637924432754517\n",
      "Train size: [400] hidden size: [239] trial: 22, train_loss: 1.066607, test loss: 1.092473, bias2: 0.6488913297653198, variance: 0.4435814321041107\n",
      "Train size: [400] hidden size: [239] trial: 23, train_loss: 1.068396, test loss: 1.090362, bias2: 0.6456743478775024, variance: 0.44468793272972107\n",
      "Train size: [400] hidden size: [239] trial: 24, train_loss: 1.067946, test loss: 1.093396, bias2: 0.6475483179092407, variance: 0.44584736227989197\n",
      "Train size: [400] hidden size: [239] trial: 25, train_loss: 1.065282, test loss: 1.094332, bias2: 0.6465891003608704, variance: 0.44774264097213745\n",
      "Train size: [400] hidden size: [239] trial: 26, train_loss: 1.063870, test loss: 1.096058, bias2: 0.6491094827651978, variance: 0.44694817066192627\n",
      "Train size: [400] hidden size: [239] trial: 27, train_loss: 1.062452, test loss: 1.091752, bias2: 0.6432873010635376, variance: 0.4484647214412689\n",
      "Train size: [400] hidden size: [239] trial: 28, train_loss: 1.064524, test loss: 1.092260, bias2: 0.6430483460426331, variance: 0.4492112994194031\n",
      "Train size: [400] hidden size: [239] trial: 29, train_loss: 1.069936, test loss: 1.095422, bias2: 0.6425290703773499, variance: 0.45289283990859985\n",
      "Train size: [400] hidden size: [239] trial: 30, train_loss: 1.069781, test loss: 1.099675, bias2: 0.6436861753463745, variance: 0.4559883773326874\n",
      "Train size: [400] hidden size: [239] trial: 31, train_loss: 1.065885, test loss: 1.099674, bias2: 0.6429762840270996, variance: 0.4566977322101593\n",
      "Train size: [400] hidden size: [239] trial: 32, train_loss: 1.069088, test loss: 1.101443, bias2: 0.6433526277542114, variance: 0.458090215921402\n",
      "Train size: [400] hidden size: [239] trial: 33, train_loss: 1.070431, test loss: 1.101300, bias2: 0.6410161256790161, variance: 0.46028396487236023\n",
      "Train size: [400] hidden size: [239] trial: 34, train_loss: 1.068627, test loss: 1.103051, bias2: 0.643203616142273, variance: 0.45984694361686707\n",
      "Train size: [400] hidden size: [239] trial: 35, train_loss: 1.070519, test loss: 1.101350, bias2: 0.641722559928894, variance: 0.45962727069854736\n",
      "Train size: [400] hidden size: [239] trial: 36, train_loss: 1.070449, test loss: 1.100927, bias2: 0.6411916017532349, variance: 0.45973536372184753\n",
      "Train size: [400] hidden size: [239] trial: 37, train_loss: 1.067299, test loss: 1.104587, bias2: 0.6424152851104736, variance: 0.46217143535614014\n",
      "Train size: [400] hidden size: [239] trial: 38, train_loss: 1.068152, test loss: 1.109550, bias2: 0.6415225863456726, variance: 0.4680270552635193\n",
      "Train size: [400] hidden size: [239] trial: 39, train_loss: 1.065537, test loss: 1.112261, bias2: 0.6410715579986572, variance: 0.4711894094944\n",
      "Train size: [400] hidden size: [239] trial: 40, train_loss: 1.066224, test loss: 1.112159, bias2: 0.6428821086883545, variance: 0.46927666664123535\n",
      "Train size: [400] hidden size: [239] trial: 41, train_loss: 1.063677, test loss: 1.114258, bias2: 0.6440916061401367, variance: 0.4701665937900543\n",
      "Train size: [400] hidden size: [239] trial: 42, train_loss: 1.061931, test loss: 1.116654, bias2: 0.6450080871582031, variance: 0.4716460704803467\n",
      "Train size: [400] hidden size: [239] trial: 43, train_loss: 1.063327, test loss: 1.119988, bias2: 0.6454203128814697, variance: 0.47456732392311096\n",
      "Train size: [400] hidden size: [239] trial: 44, train_loss: 1.065295, test loss: 1.120194, bias2: 0.6454224586486816, variance: 0.47477099299430847\n",
      "Train size: [400] hidden size: [239] trial: 45, train_loss: 1.066520, test loss: 1.120129, bias2: 0.6438043117523193, variance: 0.47632476687431335\n",
      "Train size: [400] hidden size: [239] trial: 46, train_loss: 1.068187, test loss: 1.118006, bias2: 0.6434675455093384, variance: 0.4745385944843292\n",
      "Train size: [400] hidden size: [239] trial: 47, train_loss: 1.068788, test loss: 1.117220, bias2: 0.6417152881622314, variance: 0.47550442814826965\n",
      "Train size: [400] hidden size: [239] trial: 48, train_loss: 1.067968, test loss: 1.118275, bias2: 0.6428848505020142, variance: 0.47538986802101135\n",
      "Train size: [400] hidden size: [239] trial: 49, train_loss: 1.068851, test loss: 1.118403, bias2: 0.6430894732475281, variance: 0.4753134846687317\n",
      "##################################################\n",
      "Train size: [400] hidden size: [275] trial: 0, train_loss: 0.952005, test loss: 1.107305, bias2: 1.1073054075241089, variance: -1.9462740308284765e-09\n",
      "Train size: [400] hidden size: [275] trial: 1, train_loss: 0.934074, test loss: 1.154406, bias2: 0.8447149991989136, variance: 0.3096904754638672\n",
      "Train size: [400] hidden size: [275] trial: 2, train_loss: 0.915217, test loss: 1.142878, bias2: 0.7632725238800049, variance: 0.37960565090179443\n",
      "Train size: [400] hidden size: [275] trial: 3, train_loss: 0.917156, test loss: 1.131800, bias2: 0.7146073579788208, variance: 0.4171924889087677\n",
      "Train size: [400] hidden size: [275] trial: 4, train_loss: 0.916505, test loss: 1.140804, bias2: 0.6921764612197876, variance: 0.4486274719238281\n",
      "Train size: [400] hidden size: [275] trial: 5, train_loss: 0.914472, test loss: 1.138818, bias2: 0.6760866641998291, variance: 0.4627317488193512\n",
      "Train size: [400] hidden size: [275] trial: 6, train_loss: 0.928595, test loss: 1.135706, bias2: 0.6499667167663574, variance: 0.48573970794677734\n",
      "Train size: [400] hidden size: [275] trial: 7, train_loss: 0.914404, test loss: 1.145539, bias2: 0.6426476240158081, variance: 0.5028915405273438\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [275] trial: 8, train_loss: 0.909972, test loss: 1.142734, bias2: 0.6210699081420898, variance: 0.521664023399353\n",
      "Train size: [400] hidden size: [275] trial: 9, train_loss: 0.909426, test loss: 1.147528, bias2: 0.6158017516136169, variance: 0.5317259430885315\n",
      "Train size: [400] hidden size: [275] trial: 10, train_loss: 0.898744, test loss: 1.145994, bias2: 0.6121448278427124, variance: 0.5338493585586548\n",
      "Train size: [400] hidden size: [275] trial: 11, train_loss: 0.906821, test loss: 1.145245, bias2: 0.611025869846344, variance: 0.5342192053794861\n",
      "Train size: [400] hidden size: [275] trial: 12, train_loss: 0.898862, test loss: 1.147055, bias2: 0.6113146543502808, variance: 0.5357407331466675\n",
      "Train size: [400] hidden size: [275] trial: 13, train_loss: 0.903308, test loss: 1.150197, bias2: 0.6058738827705383, variance: 0.5443230271339417\n",
      "Train size: [400] hidden size: [275] trial: 14, train_loss: 0.908212, test loss: 1.146761, bias2: 0.6073748469352722, variance: 0.5393857359886169\n",
      "Train size: [400] hidden size: [275] trial: 15, train_loss: 0.917914, test loss: 1.146957, bias2: 0.6067148447036743, variance: 0.540242075920105\n",
      "Train size: [400] hidden size: [275] trial: 16, train_loss: 0.920417, test loss: 1.143185, bias2: 0.6001959443092346, variance: 0.5429888367652893\n",
      "Train size: [400] hidden size: [275] trial: 17, train_loss: 0.921886, test loss: 1.149586, bias2: 0.6043301820755005, variance: 0.5452557802200317\n",
      "Train size: [400] hidden size: [275] trial: 18, train_loss: 0.919441, test loss: 1.155626, bias2: 0.6071113348007202, variance: 0.5485146045684814\n",
      "Train size: [400] hidden size: [275] trial: 19, train_loss: 0.916690, test loss: 1.157376, bias2: 0.605331301689148, variance: 0.5520445108413696\n",
      "Train size: [400] hidden size: [275] trial: 20, train_loss: 0.924101, test loss: 1.158262, bias2: 0.6064963340759277, variance: 0.5517659187316895\n",
      "Train size: [400] hidden size: [275] trial: 21, train_loss: 0.927860, test loss: 1.151866, bias2: 0.6028489470481873, variance: 0.5490166544914246\n",
      "Train size: [400] hidden size: [275] trial: 22, train_loss: 0.931414, test loss: 1.152740, bias2: 0.6027854681015015, variance: 0.5499544143676758\n",
      "Train size: [400] hidden size: [275] trial: 23, train_loss: 0.934477, test loss: 1.160751, bias2: 0.6049249172210693, variance: 0.5558258295059204\n",
      "Train size: [400] hidden size: [275] trial: 24, train_loss: 0.931238, test loss: 1.159921, bias2: 0.6038411259651184, variance: 0.5560798048973083\n",
      "Train size: [400] hidden size: [275] trial: 25, train_loss: 0.935183, test loss: 1.156610, bias2: 0.5999706983566284, variance: 0.5566388368606567\n",
      "Train size: [400] hidden size: [275] trial: 26, train_loss: 0.933736, test loss: 1.153706, bias2: 0.5979971885681152, variance: 0.5557085275650024\n",
      "Train size: [400] hidden size: [275] trial: 27, train_loss: 0.936866, test loss: 1.150879, bias2: 0.6007691025733948, variance: 0.5501098036766052\n",
      "Train size: [400] hidden size: [275] trial: 28, train_loss: 0.936327, test loss: 1.155564, bias2: 0.6023491024971008, variance: 0.5532152056694031\n",
      "Train size: [400] hidden size: [275] trial: 29, train_loss: 0.937965, test loss: 1.154334, bias2: 0.6032043099403381, variance: 0.5511301159858704\n",
      "Train size: [400] hidden size: [275] trial: 30, train_loss: 0.935692, test loss: 1.157810, bias2: 0.6017137169837952, variance: 0.5560962557792664\n",
      "Train size: [400] hidden size: [275] trial: 31, train_loss: 0.936092, test loss: 1.156721, bias2: 0.6015779376029968, variance: 0.5551431775093079\n",
      "Train size: [400] hidden size: [275] trial: 32, train_loss: 0.935846, test loss: 1.156504, bias2: 0.601972222328186, variance: 0.5545322895050049\n",
      "Train size: [400] hidden size: [275] trial: 33, train_loss: 0.933321, test loss: 1.157902, bias2: 0.6002549529075623, variance: 0.557647168636322\n",
      "Train size: [400] hidden size: [275] trial: 34, train_loss: 0.935967, test loss: 1.154835, bias2: 0.60066157579422, variance: 0.5541738867759705\n",
      "Train size: [400] hidden size: [275] trial: 35, train_loss: 0.934511, test loss: 1.153792, bias2: 0.5999001264572144, variance: 0.553891658782959\n",
      "Train size: [400] hidden size: [275] trial: 36, train_loss: 0.934983, test loss: 1.155247, bias2: 0.5988719463348389, variance: 0.5563749074935913\n",
      "Train size: [400] hidden size: [275] trial: 37, train_loss: 0.936580, test loss: 1.157108, bias2: 0.5999190807342529, variance: 0.5571889877319336\n",
      "Train size: [400] hidden size: [275] trial: 38, train_loss: 0.939526, test loss: 1.159173, bias2: 0.6014653444290161, variance: 0.5577074289321899\n",
      "Train size: [400] hidden size: [275] trial: 39, train_loss: 0.938054, test loss: 1.158619, bias2: 0.6031971573829651, variance: 0.5554214119911194\n",
      "Train size: [400] hidden size: [275] trial: 40, train_loss: 0.936756, test loss: 1.158746, bias2: 0.6018945574760437, variance: 0.5568519234657288\n",
      "Train size: [400] hidden size: [275] trial: 41, train_loss: 0.936109, test loss: 1.158347, bias2: 0.6028684973716736, variance: 0.5554783940315247\n",
      "Train size: [400] hidden size: [275] trial: 42, train_loss: 0.936693, test loss: 1.157770, bias2: 0.6000567078590393, variance: 0.5577130913734436\n",
      "Train size: [400] hidden size: [275] trial: 43, train_loss: 0.937294, test loss: 1.156620, bias2: 0.6000426411628723, variance: 0.5565770268440247\n",
      "Train size: [400] hidden size: [275] trial: 44, train_loss: 0.934620, test loss: 1.158544, bias2: 0.6015294790267944, variance: 0.5570148229598999\n",
      "Train size: [400] hidden size: [275] trial: 45, train_loss: 0.935567, test loss: 1.161416, bias2: 0.6014358997344971, variance: 0.559980034828186\n",
      "Train size: [400] hidden size: [275] trial: 46, train_loss: 0.936158, test loss: 1.162376, bias2: 0.6004816293716431, variance: 0.5618941783905029\n",
      "Train size: [400] hidden size: [275] trial: 47, train_loss: 0.937204, test loss: 1.161686, bias2: 0.5994377732276917, variance: 0.5622479319572449\n",
      "Train size: [400] hidden size: [275] trial: 48, train_loss: 0.937872, test loss: 1.161586, bias2: 0.5990875363349915, variance: 0.5624982714653015\n",
      "Train size: [400] hidden size: [275] trial: 49, train_loss: 0.938570, test loss: 1.161965, bias2: 0.5988315343856812, variance: 0.5631335973739624\n",
      "##################################################\n",
      "Train size: [400] hidden size: [316] trial: 0, train_loss: 0.832030, test loss: 1.220329, bias2: 1.220328688621521, variance: 8.563605824463139e-09\n",
      "Train size: [400] hidden size: [316] trial: 1, train_loss: 0.928031, test loss: 1.245492, bias2: 0.9098693132400513, variance: 0.3356228172779083\n",
      "Train size: [400] hidden size: [316] trial: 2, train_loss: 0.897385, test loss: 1.209602, bias2: 0.7672630548477173, variance: 0.44233909249305725\n",
      "Train size: [400] hidden size: [316] trial: 3, train_loss: 0.914900, test loss: 1.192770, bias2: 0.7142856121063232, variance: 0.47848454117774963\n",
      "Train size: [400] hidden size: [316] trial: 4, train_loss: 0.887336, test loss: 1.222472, bias2: 0.693455696105957, variance: 0.5290168523788452\n",
      "Train size: [400] hidden size: [316] trial: 5, train_loss: 0.886683, test loss: 1.250851, bias2: 0.6788487434387207, variance: 0.5720021724700928\n",
      "Train size: [400] hidden size: [316] trial: 6, train_loss: 0.889177, test loss: 1.226554, bias2: 0.6476499438285828, variance: 0.5789039731025696\n",
      "Train size: [400] hidden size: [316] trial: 7, train_loss: 0.881293, test loss: 1.233417, bias2: 0.637516975402832, variance: 0.5958998203277588\n",
      "Train size: [400] hidden size: [316] trial: 8, train_loss: 0.883958, test loss: 1.241016, bias2: 0.6324079036712646, variance: 0.6086084842681885\n",
      "Train size: [400] hidden size: [316] trial: 9, train_loss: 0.879292, test loss: 1.247269, bias2: 0.6230717897415161, variance: 0.6241973638534546\n",
      "Train size: [400] hidden size: [316] trial: 10, train_loss: 0.865551, test loss: 1.241947, bias2: 0.6164458990097046, variance: 0.625501275062561\n",
      "Train size: [400] hidden size: [316] trial: 11, train_loss: 0.861989, test loss: 1.242989, bias2: 0.6135309934616089, variance: 0.6294577121734619\n",
      "Train size: [400] hidden size: [316] trial: 12, train_loss: 0.860320, test loss: 1.229610, bias2: 0.604945957660675, variance: 0.6246636509895325\n",
      "Train size: [400] hidden size: [316] trial: 13, train_loss: 0.855125, test loss: 1.234999, bias2: 0.604544997215271, variance: 0.6304540634155273\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [316] trial: 14, train_loss: 0.846617, test loss: 1.245396, bias2: 0.603145956993103, variance: 0.6422501802444458\n",
      "Train size: [400] hidden size: [316] trial: 15, train_loss: 0.839619, test loss: 1.239787, bias2: 0.5968936681747437, variance: 0.6428930759429932\n",
      "Train size: [400] hidden size: [316] trial: 16, train_loss: 0.830784, test loss: 1.242536, bias2: 0.5978442430496216, variance: 0.6446913480758667\n",
      "Train size: [400] hidden size: [316] trial: 17, train_loss: 0.827350, test loss: 1.251104, bias2: 0.5996108651161194, variance: 0.6514928936958313\n",
      "Train size: [400] hidden size: [316] trial: 18, train_loss: 0.821394, test loss: 1.259583, bias2: 0.6020899415016174, variance: 0.6574934124946594\n",
      "Train size: [400] hidden size: [316] trial: 19, train_loss: 0.825031, test loss: 1.256743, bias2: 0.5990332961082458, variance: 0.657709538936615\n",
      "Train size: [400] hidden size: [316] trial: 20, train_loss: 0.826074, test loss: 1.250154, bias2: 0.5974178314208984, variance: 0.6527365446090698\n",
      "Train size: [400] hidden size: [316] trial: 21, train_loss: 0.833333, test loss: 1.245926, bias2: 0.5884153842926025, variance: 0.6575107574462891\n",
      "Train size: [400] hidden size: [316] trial: 22, train_loss: 0.829405, test loss: 1.245140, bias2: 0.5840692520141602, variance: 0.6610703468322754\n",
      "Train size: [400] hidden size: [316] trial: 23, train_loss: 0.830186, test loss: 1.246315, bias2: 0.5813923478126526, variance: 0.6649226546287537\n",
      "Train size: [400] hidden size: [316] trial: 24, train_loss: 0.831150, test loss: 1.245818, bias2: 0.5818843841552734, variance: 0.6639331579208374\n",
      "Train size: [400] hidden size: [316] trial: 25, train_loss: 0.829578, test loss: 1.243129, bias2: 0.5802844166755676, variance: 0.662844717502594\n",
      "Train size: [400] hidden size: [316] trial: 26, train_loss: 0.830635, test loss: 1.239568, bias2: 0.5827446579933167, variance: 0.6568230986595154\n",
      "Train size: [400] hidden size: [316] trial: 27, train_loss: 0.829490, test loss: 1.236628, bias2: 0.5815629363059998, variance: 0.65506511926651\n",
      "Train size: [400] hidden size: [316] trial: 28, train_loss: 0.827924, test loss: 1.232040, bias2: 0.5776528120040894, variance: 0.6543867588043213\n",
      "Train size: [400] hidden size: [316] trial: 29, train_loss: 0.828664, test loss: 1.230680, bias2: 0.578797459602356, variance: 0.6518827676773071\n",
      "Train size: [400] hidden size: [316] trial: 30, train_loss: 0.827051, test loss: 1.228000, bias2: 0.5764743089675903, variance: 0.6515257358551025\n",
      "Train size: [400] hidden size: [316] trial: 31, train_loss: 0.825708, test loss: 1.227100, bias2: 0.5733367204666138, variance: 0.6537631750106812\n",
      "Train size: [400] hidden size: [316] trial: 32, train_loss: 0.825857, test loss: 1.227083, bias2: 0.572622537612915, variance: 0.6544606685638428\n",
      "Train size: [400] hidden size: [316] trial: 33, train_loss: 0.826586, test loss: 1.231280, bias2: 0.569530725479126, variance: 0.6617493629455566\n",
      "Train size: [400] hidden size: [316] trial: 34, train_loss: 0.827715, test loss: 1.229271, bias2: 0.5672990083694458, variance: 0.6619724035263062\n",
      "Train size: [400] hidden size: [316] trial: 35, train_loss: 0.833810, test loss: 1.228228, bias2: 0.5663388967514038, variance: 0.6618891954421997\n",
      "Train size: [400] hidden size: [316] trial: 36, train_loss: 0.835369, test loss: 1.231157, bias2: 0.5662724375724792, variance: 0.6648845076560974\n",
      "Train size: [400] hidden size: [316] trial: 37, train_loss: 0.835670, test loss: 1.227269, bias2: 0.5625196695327759, variance: 0.6647496223449707\n",
      "Train size: [400] hidden size: [316] trial: 38, train_loss: 0.831020, test loss: 1.228568, bias2: 0.5601994395256042, variance: 0.6683687567710876\n",
      "Train size: [400] hidden size: [316] trial: 39, train_loss: 0.832515, test loss: 1.225929, bias2: 0.5579016804695129, variance: 0.6680278182029724\n",
      "Train size: [400] hidden size: [316] trial: 40, train_loss: 0.830808, test loss: 1.225614, bias2: 0.5579695701599121, variance: 0.667644739151001\n",
      "Train size: [400] hidden size: [316] trial: 41, train_loss: 0.830848, test loss: 1.227425, bias2: 0.556962788105011, variance: 0.670462429523468\n",
      "Train size: [400] hidden size: [316] trial: 42, train_loss: 0.832238, test loss: 1.228311, bias2: 0.5578359961509705, variance: 0.6704753041267395\n",
      "Train size: [400] hidden size: [316] trial: 43, train_loss: 0.833397, test loss: 1.227179, bias2: 0.5566381216049194, variance: 0.6705414056777954\n",
      "Train size: [400] hidden size: [316] trial: 44, train_loss: 0.836139, test loss: 1.227420, bias2: 0.5544678568840027, variance: 0.6729523539543152\n",
      "Train size: [400] hidden size: [316] trial: 45, train_loss: 0.837723, test loss: 1.228510, bias2: 0.5550108551979065, variance: 0.6734990477561951\n",
      "Train size: [400] hidden size: [316] trial: 46, train_loss: 0.839511, test loss: 1.225694, bias2: 0.5528913736343384, variance: 0.6728023290634155\n",
      "Train size: [400] hidden size: [316] trial: 47, train_loss: 0.841262, test loss: 1.225244, bias2: 0.5522040128707886, variance: 0.6730395555496216\n",
      "Train size: [400] hidden size: [316] trial: 48, train_loss: 0.841164, test loss: 1.225104, bias2: 0.5523541569709778, variance: 0.6727500557899475\n",
      "Train size: [400] hidden size: [316] trial: 49, train_loss: 0.840131, test loss: 1.225925, bias2: 0.5529561042785645, variance: 0.672968864440918\n",
      "##################################################\n",
      "Train size: [400] hidden size: [364] trial: 0, train_loss: 0.688110, test loss: 1.395437, bias2: 1.3954370021820068, variance: 5.060312613380802e-09\n",
      "Train size: [400] hidden size: [364] trial: 1, train_loss: 0.730989, test loss: 1.316627, bias2: 0.9074878096580505, variance: 0.4091389775276184\n",
      "Train size: [400] hidden size: [364] trial: 2, train_loss: 0.703499, test loss: 1.299259, bias2: 0.7369521260261536, variance: 0.5623070597648621\n",
      "Train size: [400] hidden size: [364] trial: 3, train_loss: 0.704626, test loss: 1.289357, bias2: 0.6784650683403015, variance: 0.6108917593955994\n",
      "Train size: [400] hidden size: [364] trial: 4, train_loss: 0.685971, test loss: 1.272324, bias2: 0.6493488550186157, variance: 0.6229748725891113\n",
      "Train size: [400] hidden size: [364] trial: 5, train_loss: 0.702933, test loss: 1.283341, bias2: 0.6239199638366699, variance: 0.6594208478927612\n",
      "Train size: [400] hidden size: [364] trial: 6, train_loss: 0.702481, test loss: 1.287326, bias2: 0.6176323294639587, variance: 0.6696937680244446\n",
      "Train size: [400] hidden size: [364] trial: 7, train_loss: 0.706513, test loss: 1.269944, bias2: 0.5814990401268005, variance: 0.6884450316429138\n",
      "Train size: [400] hidden size: [364] trial: 8, train_loss: 0.701287, test loss: 1.277847, bias2: 0.5625485777854919, variance: 0.7152987122535706\n",
      "Train size: [400] hidden size: [364] trial: 9, train_loss: 0.703894, test loss: 1.281442, bias2: 0.5597756505012512, variance: 0.7216660380363464\n",
      "Train size: [400] hidden size: [364] trial: 10, train_loss: 0.703757, test loss: 1.290031, bias2: 0.5590007305145264, variance: 0.7310302257537842\n",
      "Train size: [400] hidden size: [364] trial: 11, train_loss: 0.709240, test loss: 1.289166, bias2: 0.5543156862258911, variance: 0.7348500490188599\n",
      "Train size: [400] hidden size: [364] trial: 12, train_loss: 0.715495, test loss: 1.286915, bias2: 0.5450140237808228, variance: 0.7419013977050781\n",
      "Train size: [400] hidden size: [364] trial: 13, train_loss: 0.716969, test loss: 1.290343, bias2: 0.5439615249633789, variance: 0.7463819980621338\n",
      "Train size: [400] hidden size: [364] trial: 14, train_loss: 0.718955, test loss: 1.303375, bias2: 0.5374873280525208, variance: 0.7658872008323669\n",
      "Train size: [400] hidden size: [364] trial: 15, train_loss: 0.720463, test loss: 1.299454, bias2: 0.5291222929954529, variance: 0.7703316807746887\n",
      "Train size: [400] hidden size: [364] trial: 16, train_loss: 0.723387, test loss: 1.295634, bias2: 0.5227361917495728, variance: 0.7728979587554932\n",
      "Train size: [400] hidden size: [364] trial: 17, train_loss: 0.716737, test loss: 1.294696, bias2: 0.5212258696556091, variance: 0.7734696269035339\n",
      "Train size: [400] hidden size: [364] trial: 18, train_loss: 0.715178, test loss: 1.298868, bias2: 0.5232073068618774, variance: 0.775660514831543\n",
      "Train size: [400] hidden size: [364] trial: 19, train_loss: 0.717464, test loss: 1.299693, bias2: 0.5195564031600952, variance: 0.780136227607727\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [364] trial: 20, train_loss: 0.720037, test loss: 1.306230, bias2: 0.5173969864845276, variance: 0.7888328433036804\n",
      "Train size: [400] hidden size: [364] trial: 21, train_loss: 0.721453, test loss: 1.304388, bias2: 0.5163071751594543, variance: 0.788080632686615\n",
      "Train size: [400] hidden size: [364] trial: 22, train_loss: 0.720848, test loss: 1.302193, bias2: 0.5151182413101196, variance: 0.7870748043060303\n",
      "Train size: [400] hidden size: [364] trial: 23, train_loss: 0.721103, test loss: 1.316443, bias2: 0.5189452171325684, variance: 0.7974978685379028\n",
      "Train size: [400] hidden size: [364] trial: 24, train_loss: 0.718343, test loss: 1.314004, bias2: 0.5174923539161682, variance: 0.7965111136436462\n",
      "Train size: [400] hidden size: [364] trial: 25, train_loss: 0.717204, test loss: 1.316123, bias2: 0.5182843208312988, variance: 0.7978388071060181\n",
      "Train size: [400] hidden size: [364] trial: 26, train_loss: 0.715693, test loss: 1.317410, bias2: 0.5206514596939087, variance: 0.796758770942688\n",
      "Train size: [400] hidden size: [364] trial: 27, train_loss: 0.712575, test loss: 1.312001, bias2: 0.5200905203819275, variance: 0.7919101119041443\n",
      "Train size: [400] hidden size: [364] trial: 28, train_loss: 0.712362, test loss: 1.313495, bias2: 0.5158657431602478, variance: 0.7976294159889221\n",
      "Train size: [400] hidden size: [364] trial: 29, train_loss: 0.712893, test loss: 1.313714, bias2: 0.5150551795959473, variance: 0.7986587285995483\n",
      "Train size: [400] hidden size: [364] trial: 30, train_loss: 0.713900, test loss: 1.310399, bias2: 0.5134186744689941, variance: 0.7969801425933838\n",
      "Train size: [400] hidden size: [364] trial: 31, train_loss: 0.716070, test loss: 1.310190, bias2: 0.5130132436752319, variance: 0.7971764802932739\n",
      "Train size: [400] hidden size: [364] trial: 32, train_loss: 0.716941, test loss: 1.310187, bias2: 0.5142590403556824, variance: 0.795928418636322\n",
      "Train size: [400] hidden size: [364] trial: 33, train_loss: 0.715765, test loss: 1.313721, bias2: 0.513009250164032, variance: 0.8007121682167053\n",
      "Train size: [400] hidden size: [364] trial: 34, train_loss: 0.713717, test loss: 1.314241, bias2: 0.5103879570960999, variance: 0.8038527369499207\n",
      "Train size: [400] hidden size: [364] trial: 35, train_loss: 0.713095, test loss: 1.314157, bias2: 0.5104636549949646, variance: 0.8036933541297913\n",
      "Train size: [400] hidden size: [364] trial: 36, train_loss: 0.713317, test loss: 1.313199, bias2: 0.5087870955467224, variance: 0.8044124245643616\n",
      "Train size: [400] hidden size: [364] trial: 37, train_loss: 0.714897, test loss: 1.313139, bias2: 0.5082404017448425, variance: 0.804898202419281\n",
      "Train size: [400] hidden size: [364] trial: 38, train_loss: 0.711126, test loss: 1.314969, bias2: 0.5100268721580505, variance: 0.8049425482749939\n",
      "Train size: [400] hidden size: [364] trial: 39, train_loss: 0.711962, test loss: 1.314431, bias2: 0.5108844041824341, variance: 0.8035470247268677\n",
      "Train size: [400] hidden size: [364] trial: 40, train_loss: 0.710574, test loss: 1.314142, bias2: 0.5108122229576111, variance: 0.8033302426338196\n",
      "Train size: [400] hidden size: [364] trial: 41, train_loss: 0.710124, test loss: 1.315222, bias2: 0.5119045376777649, variance: 0.8033174872398376\n",
      "Train size: [400] hidden size: [364] trial: 42, train_loss: 0.709533, test loss: 1.312908, bias2: 0.5079989433288574, variance: 0.8049086332321167\n",
      "Train size: [400] hidden size: [364] trial: 43, train_loss: 0.709358, test loss: 1.312302, bias2: 0.5075342655181885, variance: 0.8047680854797363\n",
      "Train size: [400] hidden size: [364] trial: 44, train_loss: 0.710389, test loss: 1.312165, bias2: 0.5058446526527405, variance: 0.80632084608078\n",
      "Train size: [400] hidden size: [364] trial: 45, train_loss: 0.713685, test loss: 1.315968, bias2: 0.5055763125419617, variance: 0.8103917241096497\n",
      "Train size: [400] hidden size: [364] trial: 46, train_loss: 0.712558, test loss: 1.317596, bias2: 0.5075907707214355, variance: 0.8100049495697021\n",
      "Train size: [400] hidden size: [364] trial: 47, train_loss: 0.712522, test loss: 1.317235, bias2: 0.5047202706336975, variance: 0.8125150799751282\n",
      "Train size: [400] hidden size: [364] trial: 48, train_loss: 0.712068, test loss: 1.321861, bias2: 0.5030351281166077, variance: 0.8188256621360779\n",
      "Train size: [400] hidden size: [364] trial: 49, train_loss: 0.714025, test loss: 1.322365, bias2: 0.5032281875610352, variance: 0.8191370964050293\n",
      "##################################################\n",
      "Train size: [400] hidden size: [419] trial: 0, train_loss: 0.551062, test loss: 1.473461, bias2: 1.4734605550765991, variance: 8.563605824463139e-09\n",
      "Train size: [400] hidden size: [419] trial: 1, train_loss: 0.609569, test loss: 1.481386, bias2: 0.975082516670227, variance: 0.5063035488128662\n",
      "Train size: [400] hidden size: [419] trial: 2, train_loss: 0.586773, test loss: 1.451821, bias2: 0.8175883889198303, variance: 0.6342328190803528\n",
      "Train size: [400] hidden size: [419] trial: 3, train_loss: 0.578983, test loss: 1.454421, bias2: 0.7278155088424683, variance: 0.7266050577163696\n",
      "Train size: [400] hidden size: [419] trial: 4, train_loss: 0.577747, test loss: 1.420776, bias2: 0.6420530676841736, variance: 0.778723418712616\n",
      "Train size: [400] hidden size: [419] trial: 5, train_loss: 0.574770, test loss: 1.456581, bias2: 0.6239213943481445, variance: 0.8326592445373535\n",
      "Train size: [400] hidden size: [419] trial: 6, train_loss: 0.600514, test loss: 1.459177, bias2: 0.6044191122055054, variance: 0.8547574281692505\n",
      "Train size: [400] hidden size: [419] trial: 7, train_loss: 0.599567, test loss: 1.443330, bias2: 0.5849704742431641, variance: 0.8583599328994751\n",
      "Train size: [400] hidden size: [419] trial: 8, train_loss: 0.600704, test loss: 1.443960, bias2: 0.5632921457290649, variance: 0.8806682825088501\n",
      "Train size: [400] hidden size: [419] trial: 9, train_loss: 0.595238, test loss: 1.440427, bias2: 0.5573771595954895, variance: 0.8830499053001404\n",
      "Train size: [400] hidden size: [419] trial: 10, train_loss: 0.603008, test loss: 1.448100, bias2: 0.5382589101791382, variance: 0.9098414182662964\n",
      "Train size: [400] hidden size: [419] trial: 11, train_loss: 0.597343, test loss: 1.441768, bias2: 0.5305555462837219, variance: 0.9112120270729065\n",
      "Train size: [400] hidden size: [419] trial: 12, train_loss: 0.592477, test loss: 1.439309, bias2: 0.5309665203094482, variance: 0.9083421230316162\n",
      "Train size: [400] hidden size: [419] trial: 13, train_loss: 0.588465, test loss: 1.435219, bias2: 0.5208272337913513, variance: 0.9143919348716736\n",
      "Train size: [400] hidden size: [419] trial: 14, train_loss: 0.589721, test loss: 1.435858, bias2: 0.51072758436203, variance: 0.9251301884651184\n",
      "Train size: [400] hidden size: [419] trial: 15, train_loss: 0.582818, test loss: 1.446844, bias2: 0.5101997256278992, variance: 0.9366444945335388\n",
      "Train size: [400] hidden size: [419] trial: 16, train_loss: 0.583438, test loss: 1.438113, bias2: 0.5063868165016174, variance: 0.9317266345024109\n",
      "Train size: [400] hidden size: [419] trial: 17, train_loss: 0.580213, test loss: 1.434932, bias2: 0.4977409839630127, variance: 0.9371914863586426\n",
      "Train size: [400] hidden size: [419] trial: 18, train_loss: 0.586076, test loss: 1.439143, bias2: 0.49384796619415283, variance: 0.9452950954437256\n",
      "Train size: [400] hidden size: [419] trial: 19, train_loss: 0.585884, test loss: 1.440323, bias2: 0.4935501217842102, variance: 0.9467726349830627\n",
      "Train size: [400] hidden size: [419] trial: 20, train_loss: 0.585107, test loss: 1.444099, bias2: 0.4935120940208435, variance: 0.9505873322486877\n",
      "Train size: [400] hidden size: [419] trial: 21, train_loss: 0.591772, test loss: 1.452603, bias2: 0.4981737732887268, variance: 0.9544294476509094\n",
      "Train size: [400] hidden size: [419] trial: 22, train_loss: 0.593486, test loss: 1.456514, bias2: 0.49696922302246094, variance: 0.9595448970794678\n",
      "Train size: [400] hidden size: [419] trial: 23, train_loss: 0.589712, test loss: 1.460228, bias2: 0.4956422448158264, variance: 0.9645861983299255\n",
      "Train size: [400] hidden size: [419] trial: 24, train_loss: 0.587218, test loss: 1.459124, bias2: 0.49470221996307373, variance: 0.9644213914871216\n",
      "Train size: [400] hidden size: [419] trial: 25, train_loss: 0.585090, test loss: 1.454554, bias2: 0.49199384450912476, variance: 0.9625599980354309\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [419] trial: 26, train_loss: 0.584477, test loss: 1.446044, bias2: 0.4856979250907898, variance: 0.9603458046913147\n",
      "Train size: [400] hidden size: [419] trial: 27, train_loss: 0.586620, test loss: 1.443428, bias2: 0.4841121435165405, variance: 0.9593157768249512\n",
      "Train size: [400] hidden size: [419] trial: 28, train_loss: 0.586347, test loss: 1.442702, bias2: 0.4840463399887085, variance: 0.9586559534072876\n",
      "Train size: [400] hidden size: [419] trial: 29, train_loss: 0.585710, test loss: 1.441218, bias2: 0.48082447052001953, variance: 0.9603935480117798\n",
      "Train size: [400] hidden size: [419] trial: 30, train_loss: 0.584809, test loss: 1.437001, bias2: 0.48195070028305054, variance: 0.955050528049469\n",
      "Train size: [400] hidden size: [419] trial: 31, train_loss: 0.583849, test loss: 1.437696, bias2: 0.48377370834350586, variance: 0.9539222717285156\n",
      "Train size: [400] hidden size: [419] trial: 32, train_loss: 0.583877, test loss: 1.437928, bias2: 0.483224093914032, variance: 0.9547037482261658\n",
      "Train size: [400] hidden size: [419] trial: 33, train_loss: 0.584400, test loss: 1.442650, bias2: 0.48327112197875977, variance: 0.9593791961669922\n",
      "Train size: [400] hidden size: [419] trial: 34, train_loss: 0.587393, test loss: 1.442233, bias2: 0.4790591597557068, variance: 0.963174045085907\n",
      "Train size: [400] hidden size: [419] trial: 35, train_loss: 0.587009, test loss: 1.440230, bias2: 0.4755048155784607, variance: 0.9647248387336731\n",
      "Train size: [400] hidden size: [419] trial: 36, train_loss: 0.586050, test loss: 1.436487, bias2: 0.4757310152053833, variance: 0.9607560634613037\n",
      "Train size: [400] hidden size: [419] trial: 37, train_loss: 0.583466, test loss: 1.434109, bias2: 0.47527337074279785, variance: 0.9588359594345093\n",
      "Train size: [400] hidden size: [419] trial: 38, train_loss: 0.583089, test loss: 1.436255, bias2: 0.4758526682853699, variance: 0.96040278673172\n",
      "Train size: [400] hidden size: [419] trial: 39, train_loss: 0.582717, test loss: 1.433960, bias2: 0.4759839177131653, variance: 0.9579759240150452\n",
      "Train size: [400] hidden size: [419] trial: 40, train_loss: 0.582035, test loss: 1.434758, bias2: 0.47402268648147583, variance: 0.9607349038124084\n",
      "Train size: [400] hidden size: [419] trial: 41, train_loss: 0.581680, test loss: 1.437017, bias2: 0.47133421897888184, variance: 0.9656832218170166\n",
      "Train size: [400] hidden size: [419] trial: 42, train_loss: 0.581288, test loss: 1.437371, bias2: 0.4709034562110901, variance: 0.9664670825004578\n",
      "Train size: [400] hidden size: [419] trial: 43, train_loss: 0.581919, test loss: 1.437815, bias2: 0.4706094264984131, variance: 0.9672054052352905\n",
      "Train size: [400] hidden size: [419] trial: 44, train_loss: 0.583817, test loss: 1.438775, bias2: 0.46887457370758057, variance: 0.9699002504348755\n",
      "Train size: [400] hidden size: [419] trial: 45, train_loss: 0.584436, test loss: 1.439947, bias2: 0.4687767028808594, variance: 0.97117018699646\n",
      "Train size: [400] hidden size: [419] trial: 46, train_loss: 0.584480, test loss: 1.438488, bias2: 0.46626824140548706, variance: 0.9722198843955994\n",
      "Train size: [400] hidden size: [419] trial: 47, train_loss: 0.582621, test loss: 1.434481, bias2: 0.46612387895584106, variance: 0.9683571457862854\n",
      "Train size: [400] hidden size: [419] trial: 48, train_loss: 0.583919, test loss: 1.432913, bias2: 0.46588289737701416, variance: 0.9670298099517822\n",
      "Train size: [400] hidden size: [419] trial: 49, train_loss: 0.582655, test loss: 1.434041, bias2: 0.4656204581260681, variance: 0.9684209227561951\n",
      "##################################################\n",
      "Train size: [400] hidden size: [483] trial: 0, train_loss: 0.457528, test loss: 1.581322, bias2: 1.581322431564331, variance: -4.6710577628061856e-09\n",
      "Train size: [400] hidden size: [483] trial: 1, train_loss: 0.477954, test loss: 1.568345, bias2: 1.0046894550323486, variance: 0.5636553168296814\n",
      "Train size: [400] hidden size: [483] trial: 2, train_loss: 0.490670, test loss: 1.579272, bias2: 0.798491358757019, variance: 0.7807807922363281\n",
      "Train size: [400] hidden size: [483] trial: 3, train_loss: 0.511248, test loss: 1.641633, bias2: 0.7212479114532471, variance: 0.9203852415084839\n",
      "Train size: [400] hidden size: [483] trial: 4, train_loss: 0.501028, test loss: 1.644624, bias2: 0.657717764377594, variance: 0.9869065880775452\n",
      "Train size: [400] hidden size: [483] trial: 5, train_loss: 0.501991, test loss: 1.669523, bias2: 0.6035259962081909, variance: 1.065996527671814\n",
      "Train size: [400] hidden size: [483] trial: 6, train_loss: 0.497064, test loss: 1.664765, bias2: 0.5536679029464722, variance: 1.111096739768982\n",
      "Train size: [400] hidden size: [483] trial: 7, train_loss: 0.489551, test loss: 1.661728, bias2: 0.5406523942947388, variance: 1.1210753917694092\n",
      "Train size: [400] hidden size: [483] trial: 8, train_loss: 0.492988, test loss: 1.646711, bias2: 0.5231074094772339, variance: 1.1236032247543335\n",
      "Train size: [400] hidden size: [483] trial: 9, train_loss: 0.486273, test loss: 1.624145, bias2: 0.5003262758255005, variance: 1.1238188743591309\n",
      "Train size: [400] hidden size: [483] trial: 10, train_loss: 0.483429, test loss: 1.610100, bias2: 0.48610448837280273, variance: 1.123995065689087\n",
      "Train size: [400] hidden size: [483] trial: 11, train_loss: 0.481992, test loss: 1.624813, bias2: 0.48753952980041504, variance: 1.1372736692428589\n",
      "Train size: [400] hidden size: [483] trial: 12, train_loss: 0.491118, test loss: 1.620643, bias2: 0.4787522554397583, variance: 1.1418912410736084\n",
      "Train size: [400] hidden size: [483] trial: 13, train_loss: 0.487274, test loss: 1.619455, bias2: 0.4734222888946533, variance: 1.146032691001892\n",
      "Train size: [400] hidden size: [483] trial: 14, train_loss: 0.485461, test loss: 1.616199, bias2: 0.47401463985443115, variance: 1.1421841382980347\n",
      "Train size: [400] hidden size: [483] trial: 15, train_loss: 0.482781, test loss: 1.609530, bias2: 0.465570330619812, variance: 1.1439592838287354\n",
      "Train size: [400] hidden size: [483] trial: 16, train_loss: 0.485448, test loss: 1.601420, bias2: 0.4650309085845947, variance: 1.136389136314392\n",
      "Train size: [400] hidden size: [483] trial: 17, train_loss: 0.487054, test loss: 1.599522, bias2: 0.463647723197937, variance: 1.135874629020691\n",
      "Train size: [400] hidden size: [483] trial: 18, train_loss: 0.488742, test loss: 1.606282, bias2: 0.455666184425354, variance: 1.1506153345108032\n",
      "Train size: [400] hidden size: [483] trial: 19, train_loss: 0.486633, test loss: 1.610801, bias2: 0.4480264186859131, variance: 1.162774920463562\n",
      "Train size: [400] hidden size: [483] trial: 20, train_loss: 0.482617, test loss: 1.608341, bias2: 0.4512009620666504, variance: 1.1571400165557861\n",
      "Train size: [400] hidden size: [483] trial: 21, train_loss: 0.479794, test loss: 1.599361, bias2: 0.4495044946670532, variance: 1.1498569250106812\n",
      "Train size: [400] hidden size: [483] trial: 22, train_loss: 0.480115, test loss: 1.600591, bias2: 0.44358551502227783, variance: 1.1570055484771729\n",
      "Train size: [400] hidden size: [483] trial: 23, train_loss: 0.481071, test loss: 1.603509, bias2: 0.43789243698120117, variance: 1.1656161546707153\n",
      "Train size: [400] hidden size: [483] trial: 24, train_loss: 0.478230, test loss: 1.600021, bias2: 0.4325375556945801, variance: 1.1674829721450806\n",
      "Train size: [400] hidden size: [483] trial: 25, train_loss: 0.477172, test loss: 1.604369, bias2: 0.4292926788330078, variance: 1.1750767230987549\n",
      "Train size: [400] hidden size: [483] trial: 26, train_loss: 0.477340, test loss: 1.600174, bias2: 0.4263017177581787, variance: 1.1738722324371338\n",
      "Train size: [400] hidden size: [483] trial: 27, train_loss: 0.475568, test loss: 1.593581, bias2: 0.42123687267303467, variance: 1.1723442077636719\n",
      "Train size: [400] hidden size: [483] trial: 28, train_loss: 0.474342, test loss: 1.597121, bias2: 0.4181995391845703, variance: 1.178921103477478\n",
      "Train size: [400] hidden size: [483] trial: 29, train_loss: 0.473921, test loss: 1.602762, bias2: 0.41349470615386963, variance: 1.1892669200897217\n",
      "Train size: [400] hidden size: [483] trial: 30, train_loss: 0.472594, test loss: 1.596682, bias2: 0.41210663318634033, variance: 1.184575080871582\n",
      "Train size: [400] hidden size: [483] trial: 31, train_loss: 0.472015, test loss: 1.590075, bias2: 0.4110368490219116, variance: 1.1790379285812378\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [483] trial: 32, train_loss: 0.471596, test loss: 1.590023, bias2: 0.41168665885925293, variance: 1.1783361434936523\n",
      "Train size: [400] hidden size: [483] trial: 33, train_loss: 0.471023, test loss: 1.588508, bias2: 0.4119246006011963, variance: 1.1765830516815186\n",
      "Train size: [400] hidden size: [483] trial: 34, train_loss: 0.468952, test loss: 1.587197, bias2: 0.41118335723876953, variance: 1.176013708114624\n",
      "Train size: [400] hidden size: [483] trial: 35, train_loss: 0.468934, test loss: 1.585404, bias2: 0.41001224517822266, variance: 1.1753920316696167\n",
      "Train size: [400] hidden size: [483] trial: 36, train_loss: 0.468486, test loss: 1.579926, bias2: 0.40933310985565186, variance: 1.170593023300171\n",
      "Train size: [400] hidden size: [483] trial: 37, train_loss: 0.470521, test loss: 1.578665, bias2: 0.40850067138671875, variance: 1.1701648235321045\n",
      "Train size: [400] hidden size: [483] trial: 38, train_loss: 0.469258, test loss: 1.577331, bias2: 0.40887272357940674, variance: 1.1684579849243164\n",
      "Train size: [400] hidden size: [483] trial: 39, train_loss: 0.469279, test loss: 1.579617, bias2: 0.40859925746917725, variance: 1.1710175275802612\n",
      "Train size: [400] hidden size: [483] trial: 40, train_loss: 0.468170, test loss: 1.574436, bias2: 0.4092116355895996, variance: 1.1652247905731201\n",
      "Train size: [400] hidden size: [483] trial: 41, train_loss: 0.468626, test loss: 1.570813, bias2: 0.4079453945159912, variance: 1.1628674268722534\n",
      "Train size: [400] hidden size: [483] trial: 42, train_loss: 0.468250, test loss: 1.571009, bias2: 0.407647967338562, variance: 1.1633607149124146\n",
      "Train size: [400] hidden size: [483] trial: 43, train_loss: 0.467535, test loss: 1.571323, bias2: 0.4101799726486206, variance: 1.1611428260803223\n",
      "Train size: [400] hidden size: [483] trial: 44, train_loss: 0.466567, test loss: 1.569490, bias2: 0.40987181663513184, variance: 1.1596181392669678\n",
      "Train size: [400] hidden size: [483] trial: 45, train_loss: 0.466378, test loss: 1.574418, bias2: 0.40861940383911133, variance: 1.165798544883728\n",
      "Train size: [400] hidden size: [483] trial: 46, train_loss: 0.465359, test loss: 1.574698, bias2: 0.4098721742630005, variance: 1.1648260354995728\n",
      "Train size: [400] hidden size: [483] trial: 47, train_loss: 0.464912, test loss: 1.572389, bias2: 0.4108220338821411, variance: 1.1615674495697021\n",
      "Train size: [400] hidden size: [483] trial: 48, train_loss: 0.465735, test loss: 1.571204, bias2: 0.40982961654663086, variance: 1.1613744497299194\n",
      "Train size: [400] hidden size: [483] trial: 49, train_loss: 0.465926, test loss: 1.572339, bias2: 0.4082510471343994, variance: 1.1640883684158325\n",
      "##################################################\n",
      "Train size: [400] hidden size: [556] trial: 0, train_loss: 0.351906, test loss: 1.673405, bias2: 1.673405408859253, variance: -7.785096123313906e-09\n",
      "Train size: [400] hidden size: [556] trial: 1, train_loss: 0.369981, test loss: 1.940439, bias2: 1.1855897903442383, variance: 0.7548487782478333\n",
      "Train size: [400] hidden size: [556] trial: 2, train_loss: 0.387547, test loss: 1.890856, bias2: 0.925098180770874, variance: 0.9657576084136963\n",
      "Train size: [400] hidden size: [556] trial: 3, train_loss: 0.386661, test loss: 1.891221, bias2: 0.810492992401123, variance: 1.0807284116744995\n",
      "Train size: [400] hidden size: [556] trial: 4, train_loss: 0.380839, test loss: 1.860940, bias2: 0.7005757093429565, variance: 1.160364031791687\n",
      "Train size: [400] hidden size: [556] trial: 5, train_loss: 0.372078, test loss: 1.864818, bias2: 0.6309562921524048, variance: 1.2338618040084839\n",
      "Train size: [400] hidden size: [556] trial: 6, train_loss: 0.366222, test loss: 1.846348, bias2: 0.588767409324646, variance: 1.2575803995132446\n",
      "Train size: [400] hidden size: [556] trial: 7, train_loss: 0.356100, test loss: 1.814875, bias2: 0.5604027509689331, variance: 1.254472017288208\n",
      "Train size: [400] hidden size: [556] trial: 8, train_loss: 0.362709, test loss: 1.828628, bias2: 0.542258620262146, variance: 1.2863690853118896\n",
      "Train size: [400] hidden size: [556] trial: 9, train_loss: 0.360428, test loss: 1.823506, bias2: 0.5115253925323486, variance: 1.3119803667068481\n",
      "Train size: [400] hidden size: [556] trial: 10, train_loss: 0.354029, test loss: 1.811075, bias2: 0.4939143657684326, variance: 1.3171602487564087\n",
      "Train size: [400] hidden size: [556] trial: 11, train_loss: 0.348186, test loss: 1.817326, bias2: 0.4859846830368042, variance: 1.3313417434692383\n",
      "Train size: [400] hidden size: [556] trial: 12, train_loss: 0.350732, test loss: 1.804410, bias2: 0.4631514549255371, variance: 1.3412586450576782\n",
      "Train size: [400] hidden size: [556] trial: 13, train_loss: 0.349553, test loss: 1.812384, bias2: 0.4546804428100586, variance: 1.3577038049697876\n",
      "Train size: [400] hidden size: [556] trial: 14, train_loss: 0.348623, test loss: 1.816141, bias2: 0.45004212856292725, variance: 1.3660985231399536\n",
      "Train size: [400] hidden size: [556] trial: 15, train_loss: 0.350733, test loss: 1.816412, bias2: 0.43562185764312744, variance: 1.3807902336120605\n",
      "Train size: [400] hidden size: [556] trial: 16, train_loss: 0.354479, test loss: 1.807049, bias2: 0.43352437019348145, variance: 1.3735249042510986\n",
      "Train size: [400] hidden size: [556] trial: 17, train_loss: 0.352219, test loss: 1.808901, bias2: 0.4349360466003418, variance: 1.3739650249481201\n",
      "Train size: [400] hidden size: [556] trial: 18, train_loss: 0.355021, test loss: 1.805665, bias2: 0.42749524116516113, variance: 1.3781700134277344\n",
      "Train size: [400] hidden size: [556] trial: 19, train_loss: 0.354125, test loss: 1.805615, bias2: 0.4172813892364502, variance: 1.3883332014083862\n",
      "Train size: [400] hidden size: [556] trial: 20, train_loss: 0.354524, test loss: 1.810514, bias2: 0.41635560989379883, variance: 1.394158124923706\n",
      "Train size: [400] hidden size: [556] trial: 21, train_loss: 0.358080, test loss: 1.816109, bias2: 0.4184185266494751, variance: 1.3976908922195435\n",
      "Train size: [400] hidden size: [556] trial: 22, train_loss: 0.356919, test loss: 1.811464, bias2: 0.4150207042694092, variance: 1.396443247795105\n",
      "Train size: [400] hidden size: [556] trial: 23, train_loss: 0.358252, test loss: 1.817383, bias2: 0.41429829597473145, variance: 1.4030842781066895\n",
      "Train size: [400] hidden size: [556] trial: 24, train_loss: 0.359708, test loss: 1.824252, bias2: 0.41263914108276367, variance: 1.4116131067276\n",
      "Train size: [400] hidden size: [556] trial: 25, train_loss: 0.359563, test loss: 1.816722, bias2: 0.4023933410644531, variance: 1.414328694343567\n",
      "Train size: [400] hidden size: [556] trial: 26, train_loss: 0.358505, test loss: 1.820812, bias2: 0.4050774574279785, variance: 1.415734887123108\n",
      "Train size: [400] hidden size: [556] trial: 27, train_loss: 0.358941, test loss: 1.822498, bias2: 0.4026362895965576, variance: 1.4198617935180664\n",
      "Train size: [400] hidden size: [556] trial: 28, train_loss: 0.357214, test loss: 1.821381, bias2: 0.39786624908447266, variance: 1.4235150814056396\n",
      "Train size: [400] hidden size: [556] trial: 29, train_loss: 0.356090, test loss: 1.816628, bias2: 0.39635658264160156, variance: 1.4202710390090942\n",
      "Train size: [400] hidden size: [556] trial: 30, train_loss: 0.354008, test loss: 1.821013, bias2: 0.3973886966705322, variance: 1.4236239194869995\n",
      "Train size: [400] hidden size: [556] trial: 31, train_loss: 0.354985, test loss: 1.820089, bias2: 0.395158052444458, variance: 1.4249305725097656\n",
      "Train size: [400] hidden size: [556] trial: 32, train_loss: 0.355251, test loss: 1.817813, bias2: 0.3938940763473511, variance: 1.423919439315796\n",
      "Train size: [400] hidden size: [556] trial: 33, train_loss: 0.356207, test loss: 1.813936, bias2: 0.3926316499710083, variance: 1.4213045835494995\n",
      "Train size: [400] hidden size: [556] trial: 34, train_loss: 0.354918, test loss: 1.810688, bias2: 0.3887603282928467, variance: 1.421927571296692\n",
      "Train size: [400] hidden size: [556] trial: 35, train_loss: 0.354576, test loss: 1.813230, bias2: 0.38851213455200195, variance: 1.4247174263000488\n",
      "Train size: [400] hidden size: [556] trial: 36, train_loss: 0.354368, test loss: 1.818596, bias2: 0.38674473762512207, variance: 1.4318512678146362\n",
      "Train size: [400] hidden size: [556] trial: 37, train_loss: 0.354438, test loss: 1.816581, bias2: 0.38343775272369385, variance: 1.4331430196762085\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [556] trial: 38, train_loss: 0.353751, test loss: 1.822251, bias2: 0.3818650245666504, variance: 1.440386176109314\n",
      "Train size: [400] hidden size: [556] trial: 39, train_loss: 0.356246, test loss: 1.818649, bias2: 0.3806040287017822, variance: 1.4380446672439575\n",
      "Train size: [400] hidden size: [556] trial: 40, train_loss: 0.356273, test loss: 1.817785, bias2: 0.3814697265625, variance: 1.4363149404525757\n",
      "Train size: [400] hidden size: [556] trial: 41, train_loss: 0.355361, test loss: 1.812653, bias2: 0.3806864023208618, variance: 1.4319669008255005\n",
      "Train size: [400] hidden size: [556] trial: 42, train_loss: 0.356168, test loss: 1.802250, bias2: 0.37710726261138916, variance: 1.4251428842544556\n",
      "Train size: [400] hidden size: [556] trial: 43, train_loss: 0.355752, test loss: 1.802796, bias2: 0.37708520889282227, variance: 1.4257111549377441\n",
      "Train size: [400] hidden size: [556] trial: 44, train_loss: 0.354889, test loss: 1.797219, bias2: 0.37464988231658936, variance: 1.4225693941116333\n",
      "Train size: [400] hidden size: [556] trial: 45, train_loss: 0.354369, test loss: 1.795824, bias2: 0.3751331567764282, variance: 1.4206910133361816\n",
      "Train size: [400] hidden size: [556] trial: 46, train_loss: 0.354475, test loss: 1.795061, bias2: 0.3738548755645752, variance: 1.4212063550949097\n",
      "Train size: [400] hidden size: [556] trial: 47, train_loss: 0.355120, test loss: 1.794621, bias2: 0.37230610847473145, variance: 1.4223146438598633\n",
      "Train size: [400] hidden size: [556] trial: 48, train_loss: 0.354247, test loss: 1.791211, bias2: 0.3697298765182495, variance: 1.4214807748794556\n",
      "Train size: [400] hidden size: [556] trial: 49, train_loss: 0.353702, test loss: 1.790406, bias2: 0.3682734966278076, variance: 1.4221326112747192\n",
      "##################################################\n",
      "Train size: [400] hidden size: [640] trial: 0, train_loss: 0.275436, test loss: 2.063219, bias2: 2.0632193088531494, variance: 2.8026345688658694e-08\n",
      "Train size: [400] hidden size: [640] trial: 1, train_loss: 0.234717, test loss: 1.931657, bias2: 1.085892677307129, variance: 0.8457647562026978\n",
      "Train size: [400] hidden size: [640] trial: 2, train_loss: 0.243622, test loss: 1.883165, bias2: 0.7815533876419067, variance: 1.1016114950180054\n",
      "Train size: [400] hidden size: [640] trial: 3, train_loss: 0.242304, test loss: 1.930508, bias2: 0.671184778213501, variance: 1.2593234777450562\n",
      "Train size: [400] hidden size: [640] trial: 4, train_loss: 0.242161, test loss: 1.930712, bias2: 0.5862618684768677, variance: 1.3444501161575317\n",
      "Train size: [400] hidden size: [640] trial: 5, train_loss: 0.238422, test loss: 1.923751, bias2: 0.5216320753097534, variance: 1.4021193981170654\n",
      "Train size: [400] hidden size: [640] trial: 6, train_loss: 0.235145, test loss: 1.923585, bias2: 0.4844970703125, variance: 1.4390876293182373\n",
      "Train size: [400] hidden size: [640] trial: 7, train_loss: 0.238647, test loss: 1.952237, bias2: 0.44635868072509766, variance: 1.50587797164917\n",
      "Train size: [400] hidden size: [640] trial: 8, train_loss: 0.247766, test loss: 1.967378, bias2: 0.43479669094085693, variance: 1.532581090927124\n",
      "Train size: [400] hidden size: [640] trial: 9, train_loss: 0.243627, test loss: 1.963983, bias2: 0.411112904548645, variance: 1.5528701543807983\n",
      "Train size: [400] hidden size: [640] trial: 10, train_loss: 0.244222, test loss: 1.940936, bias2: 0.3931213617324829, variance: 1.547814130783081\n",
      "Train size: [400] hidden size: [640] trial: 11, train_loss: 0.241126, test loss: 1.936338, bias2: 0.38619744777679443, variance: 1.5501408576965332\n",
      "Train size: [400] hidden size: [640] trial: 12, train_loss: 0.240467, test loss: 1.950683, bias2: 0.3887917995452881, variance: 1.5618916749954224\n",
      "Train size: [400] hidden size: [640] trial: 13, train_loss: 0.236631, test loss: 1.935616, bias2: 0.3796199560165405, variance: 1.555996298789978\n",
      "Train size: [400] hidden size: [640] trial: 14, train_loss: 0.235059, test loss: 1.937039, bias2: 0.37471330165863037, variance: 1.5623252391815186\n",
      "Train size: [400] hidden size: [640] trial: 15, train_loss: 0.236955, test loss: 1.918462, bias2: 0.3697190284729004, variance: 1.5487433671951294\n",
      "Train size: [400] hidden size: [640] trial: 16, train_loss: 0.236613, test loss: 1.921660, bias2: 0.3674795627593994, variance: 1.5541808605194092\n",
      "Train size: [400] hidden size: [640] trial: 17, train_loss: 0.239159, test loss: 1.935020, bias2: 0.3628871440887451, variance: 1.5721325874328613\n",
      "Train size: [400] hidden size: [640] trial: 18, train_loss: 0.239946, test loss: 1.931476, bias2: 0.3569098711013794, variance: 1.5745657682418823\n",
      "Train size: [400] hidden size: [640] trial: 19, train_loss: 0.239403, test loss: 1.943783, bias2: 0.3589200973510742, variance: 1.5848629474639893\n",
      "Train size: [400] hidden size: [640] trial: 20, train_loss: 0.238517, test loss: 1.957205, bias2: 0.36233627796173096, variance: 1.594868540763855\n",
      "Train size: [400] hidden size: [640] trial: 21, train_loss: 0.239000, test loss: 1.960673, bias2: 0.35931265354156494, variance: 1.601360559463501\n",
      "Train size: [400] hidden size: [640] trial: 22, train_loss: 0.239728, test loss: 1.956381, bias2: 0.35683369636535645, variance: 1.599547028541565\n",
      "Train size: [400] hidden size: [640] trial: 23, train_loss: 0.238379, test loss: 1.963865, bias2: 0.3550536632537842, variance: 1.6088110208511353\n",
      "Train size: [400] hidden size: [640] trial: 24, train_loss: 0.238332, test loss: 1.964451, bias2: 0.3518177270889282, variance: 1.6126328706741333\n",
      "Train size: [400] hidden size: [640] trial: 25, train_loss: 0.238747, test loss: 1.963737, bias2: 0.34992659091949463, variance: 1.613810658454895\n",
      "Train size: [400] hidden size: [640] trial: 26, train_loss: 0.238591, test loss: 1.961400, bias2: 0.3455181121826172, variance: 1.6158819198608398\n",
      "Train size: [400] hidden size: [640] trial: 27, train_loss: 0.240508, test loss: 1.967211, bias2: 0.33835864067077637, variance: 1.6288520097732544\n",
      "Train size: [400] hidden size: [640] trial: 28, train_loss: 0.241702, test loss: 1.970892, bias2: 0.33643078804016113, variance: 1.6344611644744873\n",
      "Train size: [400] hidden size: [640] trial: 29, train_loss: 0.240997, test loss: 1.965377, bias2: 0.33498072624206543, variance: 1.6303960084915161\n",
      "Train size: [400] hidden size: [640] trial: 30, train_loss: 0.239293, test loss: 1.963574, bias2: 0.3338674306869507, variance: 1.629706859588623\n",
      "Train size: [400] hidden size: [640] trial: 31, train_loss: 0.237274, test loss: 1.963990, bias2: 0.3303184509277344, variance: 1.6336711645126343\n",
      "Train size: [400] hidden size: [640] trial: 32, train_loss: 0.238132, test loss: 1.975573, bias2: 0.328959584236145, variance: 1.646613597869873\n",
      "Train size: [400] hidden size: [640] trial: 33, train_loss: 0.238345, test loss: 1.967392, bias2: 0.3268674612045288, variance: 1.6405242681503296\n",
      "Train size: [400] hidden size: [640] trial: 34, train_loss: 0.237855, test loss: 1.968355, bias2: 0.3272594213485718, variance: 1.641095519065857\n",
      "Train size: [400] hidden size: [640] trial: 35, train_loss: 0.237471, test loss: 1.967035, bias2: 0.3233335018157959, variance: 1.6437016725540161\n",
      "Train size: [400] hidden size: [640] trial: 36, train_loss: 0.237764, test loss: 1.961891, bias2: 0.3215430974960327, variance: 1.6403478384017944\n",
      "Train size: [400] hidden size: [640] trial: 37, train_loss: 0.237564, test loss: 1.964990, bias2: 0.31984198093414307, variance: 1.645148515701294\n",
      "Train size: [400] hidden size: [640] trial: 38, train_loss: 0.237519, test loss: 1.963709, bias2: 0.3191647529602051, variance: 1.6445447206497192\n",
      "Train size: [400] hidden size: [640] trial: 39, train_loss: 0.238559, test loss: 1.961721, bias2: 0.31437766551971436, variance: 1.6473429203033447\n",
      "Train size: [400] hidden size: [640] trial: 40, train_loss: 0.239053, test loss: 1.962114, bias2: 0.3141065835952759, variance: 1.6480071544647217\n",
      "Train size: [400] hidden size: [640] trial: 41, train_loss: 0.238436, test loss: 1.958594, bias2: 0.3108944892883301, variance: 1.647699236869812\n",
      "Train size: [400] hidden size: [640] trial: 42, train_loss: 0.238434, test loss: 1.957861, bias2: 0.3108789920806885, variance: 1.6469824314117432\n",
      "Train size: [400] hidden size: [640] trial: 43, train_loss: 0.237855, test loss: 1.952035, bias2: 0.31020212173461914, variance: 1.6418330669403076\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [640] trial: 44, train_loss: 0.237583, test loss: 1.951844, bias2: 0.30982816219329834, variance: 1.6420155763626099\n",
      "Train size: [400] hidden size: [640] trial: 45, train_loss: 0.238072, test loss: 1.953245, bias2: 0.30938780307769775, variance: 1.6438568830490112\n",
      "Train size: [400] hidden size: [640] trial: 46, train_loss: 0.238036, test loss: 1.961050, bias2: 0.30864250659942627, variance: 1.6524077653884888\n",
      "Train size: [400] hidden size: [640] trial: 47, train_loss: 0.237651, test loss: 1.962094, bias2: 0.3087151050567627, variance: 1.6533793210983276\n",
      "Train size: [400] hidden size: [640] trial: 48, train_loss: 0.239096, test loss: 1.963922, bias2: 0.30590736865997314, variance: 1.6580148935317993\n",
      "Train size: [400] hidden size: [640] trial: 49, train_loss: 0.239600, test loss: 1.962050, bias2: 0.306351900100708, variance: 1.6556984186172485\n",
      "##################################################\n",
      "Train size: [400] hidden size: [737] trial: 0, train_loss: 0.162002, test loss: 2.054400, bias2: 2.0543999671936035, variance: 6.228076721015441e-09\n",
      "Train size: [400] hidden size: [737] trial: 1, train_loss: 0.158375, test loss: 2.094907, bias2: 1.1650898456573486, variance: 0.929816722869873\n",
      "Train size: [400] hidden size: [737] trial: 2, train_loss: 0.155624, test loss: 2.118242, bias2: 0.8886816501617432, variance: 1.229560375213623\n",
      "Train size: [400] hidden size: [737] trial: 3, train_loss: 0.153758, test loss: 2.040557, bias2: 0.7339698076248169, variance: 1.3065873384475708\n",
      "Train size: [400] hidden size: [737] trial: 4, train_loss: 0.159884, test loss: 2.054676, bias2: 0.6678695678710938, variance: 1.3868064880371094\n",
      "Train size: [400] hidden size: [737] trial: 5, train_loss: 0.159464, test loss: 2.054013, bias2: 0.5972322225570679, variance: 1.4567805528640747\n",
      "Train size: [400] hidden size: [737] trial: 6, train_loss: 0.159546, test loss: 2.060258, bias2: 0.5740852355957031, variance: 1.4861729145050049\n",
      "Train size: [400] hidden size: [737] trial: 7, train_loss: 0.161588, test loss: 2.068221, bias2: 0.5181643962860107, variance: 1.5500562191009521\n",
      "Train size: [400] hidden size: [737] trial: 8, train_loss: 0.164731, test loss: 2.077645, bias2: 0.5055780410766602, variance: 1.5720670223236084\n",
      "Train size: [400] hidden size: [737] trial: 9, train_loss: 0.161552, test loss: 2.077317, bias2: 0.48642849922180176, variance: 1.5908880233764648\n",
      "Train size: [400] hidden size: [737] trial: 10, train_loss: 0.163422, test loss: 2.066047, bias2: 0.46660315990448, variance: 1.5994435548782349\n",
      "Train size: [400] hidden size: [737] trial: 11, train_loss: 0.160775, test loss: 2.045559, bias2: 0.4512057304382324, variance: 1.594353199005127\n",
      "Train size: [400] hidden size: [737] trial: 12, train_loss: 0.161990, test loss: 2.037629, bias2: 0.43710756301879883, variance: 1.6005213260650635\n",
      "Train size: [400] hidden size: [737] trial: 13, train_loss: 0.158968, test loss: 2.014256, bias2: 0.4157416820526123, variance: 1.5985138416290283\n",
      "Train size: [400] hidden size: [737] trial: 14, train_loss: 0.158103, test loss: 2.000215, bias2: 0.40604472160339355, variance: 1.594170093536377\n",
      "Train size: [400] hidden size: [737] trial: 15, train_loss: 0.157210, test loss: 2.007815, bias2: 0.4010261297225952, variance: 1.6067882776260376\n",
      "Train size: [400] hidden size: [737] trial: 16, train_loss: 0.157092, test loss: 1.996938, bias2: 0.3884601593017578, variance: 1.6084779500961304\n",
      "Train size: [400] hidden size: [737] trial: 17, train_loss: 0.158655, test loss: 1.999609, bias2: 0.38102638721466064, variance: 1.6185829639434814\n",
      "Train size: [400] hidden size: [737] trial: 18, train_loss: 0.158892, test loss: 1.997678, bias2: 0.376700758934021, variance: 1.6209768056869507\n",
      "Train size: [400] hidden size: [737] trial: 19, train_loss: 0.159869, test loss: 1.991811, bias2: 0.3705660104751587, variance: 1.6212449073791504\n",
      "Train size: [400] hidden size: [737] trial: 20, train_loss: 0.159384, test loss: 1.999620, bias2: 0.3688035011291504, variance: 1.6308166980743408\n",
      "Train size: [400] hidden size: [737] trial: 21, train_loss: 0.161136, test loss: 1.991290, bias2: 0.365604043006897, variance: 1.6256864070892334\n",
      "Train size: [400] hidden size: [737] trial: 22, train_loss: 0.161105, test loss: 1.988709, bias2: 0.3627811670303345, variance: 1.6259276866912842\n",
      "Train size: [400] hidden size: [737] trial: 23, train_loss: 0.160470, test loss: 1.992690, bias2: 0.359516978263855, variance: 1.6331733465194702\n",
      "Train size: [400] hidden size: [737] trial: 24, train_loss: 0.160555, test loss: 1.991674, bias2: 0.35448360443115234, variance: 1.6371902227401733\n",
      "Train size: [400] hidden size: [737] trial: 25, train_loss: 0.160368, test loss: 1.985756, bias2: 0.35158658027648926, variance: 1.6341694593429565\n",
      "Train size: [400] hidden size: [737] trial: 26, train_loss: 0.161112, test loss: 1.985044, bias2: 0.34391355514526367, variance: 1.6411302089691162\n",
      "Train size: [400] hidden size: [737] trial: 27, train_loss: 0.161186, test loss: 1.990134, bias2: 0.33959341049194336, variance: 1.650540828704834\n",
      "Train size: [400] hidden size: [737] trial: 28, train_loss: 0.159887, test loss: 1.979767, bias2: 0.33461666107177734, variance: 1.6451507806777954\n",
      "Train size: [400] hidden size: [737] trial: 29, train_loss: 0.160574, test loss: 1.989812, bias2: 0.32893288135528564, variance: 1.6608792543411255\n",
      "Train size: [400] hidden size: [737] trial: 30, train_loss: 0.159807, test loss: 1.987886, bias2: 0.32447028160095215, variance: 1.663415789604187\n",
      "Train size: [400] hidden size: [737] trial: 31, train_loss: 0.158747, test loss: 1.991557, bias2: 0.32526302337646484, variance: 1.666293978691101\n",
      "Train size: [400] hidden size: [737] trial: 32, train_loss: 0.158281, test loss: 2.002787, bias2: 0.32563769817352295, variance: 1.6771491765975952\n",
      "Train size: [400] hidden size: [737] trial: 33, train_loss: 0.159052, test loss: 2.003296, bias2: 0.3243594169616699, variance: 1.6789369583129883\n",
      "Train size: [400] hidden size: [737] trial: 34, train_loss: 0.157971, test loss: 2.008565, bias2: 0.32142555713653564, variance: 1.6871391534805298\n",
      "Train size: [400] hidden size: [737] trial: 35, train_loss: 0.157950, test loss: 2.012983, bias2: 0.3215228319168091, variance: 1.6914597749710083\n",
      "Train size: [400] hidden size: [737] trial: 36, train_loss: 0.156725, test loss: 2.009874, bias2: 0.3199782371520996, variance: 1.6898961067199707\n",
      "Train size: [400] hidden size: [737] trial: 37, train_loss: 0.156299, test loss: 2.011765, bias2: 0.31667113304138184, variance: 1.6950938701629639\n",
      "Train size: [400] hidden size: [737] trial: 38, train_loss: 0.155320, test loss: 2.006134, bias2: 0.31616127490997314, variance: 1.689972996711731\n",
      "Train size: [400] hidden size: [737] trial: 39, train_loss: 0.155158, test loss: 2.005077, bias2: 0.3140590190887451, variance: 1.6910178661346436\n",
      "Train size: [400] hidden size: [737] trial: 40, train_loss: 0.155809, test loss: 2.004678, bias2: 0.3145010471343994, variance: 1.6901769638061523\n",
      "Train size: [400] hidden size: [737] trial: 41, train_loss: 0.155489, test loss: 2.005456, bias2: 0.31179583072662354, variance: 1.6936601400375366\n",
      "Train size: [400] hidden size: [737] trial: 42, train_loss: 0.154833, test loss: 2.006312, bias2: 0.3109397888183594, variance: 1.6953725814819336\n",
      "Train size: [400] hidden size: [737] trial: 43, train_loss: 0.154650, test loss: 2.002681, bias2: 0.30889201164245605, variance: 1.693788766860962\n",
      "Train size: [400] hidden size: [737] trial: 44, train_loss: 0.154609, test loss: 2.006132, bias2: 0.3048403263092041, variance: 1.7012913227081299\n",
      "Train size: [400] hidden size: [737] trial: 45, train_loss: 0.154055, test loss: 2.006258, bias2: 0.3026310205459595, variance: 1.7036267518997192\n",
      "Train size: [400] hidden size: [737] trial: 46, train_loss: 0.154348, test loss: 2.008404, bias2: 0.30085599422454834, variance: 1.7075482606887817\n",
      "Train size: [400] hidden size: [737] trial: 47, train_loss: 0.154956, test loss: 2.010085, bias2: 0.3001711368560791, variance: 1.709914207458496\n",
      "Train size: [400] hidden size: [737] trial: 48, train_loss: 0.154230, test loss: 2.003749, bias2: 0.2992020845413208, variance: 1.7045472860336304\n",
      "Train size: [400] hidden size: [737] trial: 49, train_loss: 0.153762, test loss: 2.002468, bias2: 0.2978576421737671, variance: 1.7046107053756714\n",
      "##################################################\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [848] trial: 0, train_loss: 0.082874, test loss: 1.955279, bias2: 1.955278754234314, variance: 1.4013172844329347e-08\n",
      "Train size: [400] hidden size: [848] trial: 1, train_loss: 0.085394, test loss: 2.011183, bias2: 1.1275330781936646, variance: 0.8836499452590942\n",
      "Train size: [400] hidden size: [848] trial: 2, train_loss: 0.086794, test loss: 2.018721, bias2: 0.8270601034164429, variance: 1.1916612386703491\n",
      "Train size: [400] hidden size: [848] trial: 3, train_loss: 0.083768, test loss: 1.921634, bias2: 0.639741063117981, variance: 1.281893253326416\n",
      "Train size: [400] hidden size: [848] trial: 4, train_loss: 0.083041, test loss: 1.974468, bias2: 0.5901226997375488, variance: 1.3843450546264648\n",
      "Train size: [400] hidden size: [848] trial: 5, train_loss: 0.082113, test loss: 1.976936, bias2: 0.5319104194641113, variance: 1.4450253248214722\n",
      "Train size: [400] hidden size: [848] trial: 6, train_loss: 0.080556, test loss: 1.943380, bias2: 0.48289942741394043, variance: 1.4604809284210205\n",
      "Train size: [400] hidden size: [848] trial: 7, train_loss: 0.080424, test loss: 1.924791, bias2: 0.44836997985839844, variance: 1.4764211177825928\n",
      "Train size: [400] hidden size: [848] trial: 8, train_loss: 0.081194, test loss: 1.927939, bias2: 0.4206843376159668, variance: 1.5072541236877441\n",
      "Train size: [400] hidden size: [848] trial: 9, train_loss: 0.081962, test loss: 1.946926, bias2: 0.4072084426879883, variance: 1.539717674255371\n",
      "Train size: [400] hidden size: [848] trial: 10, train_loss: 0.082796, test loss: 1.953975, bias2: 0.38664066791534424, variance: 1.567334771156311\n",
      "Train size: [400] hidden size: [848] trial: 11, train_loss: 0.083022, test loss: 1.956983, bias2: 0.3757743835449219, variance: 1.5812084674835205\n",
      "Train size: [400] hidden size: [848] trial: 12, train_loss: 0.082315, test loss: 1.953820, bias2: 0.3704049587249756, variance: 1.5834152698516846\n",
      "Train size: [400] hidden size: [848] trial: 13, train_loss: 0.084106, test loss: 1.963815, bias2: 0.3596949577331543, variance: 1.6041200160980225\n",
      "Train size: [400] hidden size: [848] trial: 14, train_loss: 0.084272, test loss: 1.977312, bias2: 0.3533303737640381, variance: 1.6239819526672363\n",
      "Train size: [400] hidden size: [848] trial: 15, train_loss: 0.083925, test loss: 1.971256, bias2: 0.3444406986236572, variance: 1.6268155574798584\n",
      "Train size: [400] hidden size: [848] trial: 16, train_loss: 0.084169, test loss: 1.972370, bias2: 0.33739233016967773, variance: 1.634978175163269\n",
      "Train size: [400] hidden size: [848] trial: 17, train_loss: 0.084119, test loss: 1.979459, bias2: 0.33527469635009766, variance: 1.6441848278045654\n",
      "Train size: [400] hidden size: [848] trial: 18, train_loss: 0.084783, test loss: 1.988336, bias2: 0.3313843011856079, variance: 1.656951904296875\n",
      "Train size: [400] hidden size: [848] trial: 19, train_loss: 0.085072, test loss: 1.987220, bias2: 0.3274097442626953, variance: 1.659809947013855\n",
      "Train size: [400] hidden size: [848] trial: 20, train_loss: 0.085448, test loss: 1.981492, bias2: 0.31894612312316895, variance: 1.6625454425811768\n",
      "Train size: [400] hidden size: [848] trial: 21, train_loss: 0.085408, test loss: 1.972823, bias2: 0.30844151973724365, variance: 1.6643813848495483\n",
      "Train size: [400] hidden size: [848] trial: 22, train_loss: 0.085123, test loss: 1.978617, bias2: 0.30973970890045166, variance: 1.668877363204956\n",
      "Train size: [400] hidden size: [848] trial: 23, train_loss: 0.085037, test loss: 1.987584, bias2: 0.3050386905670166, variance: 1.6825454235076904\n",
      "Train size: [400] hidden size: [848] trial: 24, train_loss: 0.084622, test loss: 1.983946, bias2: 0.30475521087646484, variance: 1.6791905164718628\n",
      "Train size: [400] hidden size: [848] trial: 25, train_loss: 0.084454, test loss: 1.978325, bias2: 0.3002042770385742, variance: 1.6781210899353027\n",
      "Train size: [400] hidden size: [848] trial: 26, train_loss: 0.084273, test loss: 1.982310, bias2: 0.30179333686828613, variance: 1.6805167198181152\n",
      "Train size: [400] hidden size: [848] trial: 27, train_loss: 0.084505, test loss: 1.985949, bias2: 0.29621922969818115, variance: 1.6897293329238892\n",
      "Train size: [400] hidden size: [848] trial: 28, train_loss: 0.084635, test loss: 1.976740, bias2: 0.29089486598968506, variance: 1.685845136642456\n",
      "Train size: [400] hidden size: [848] trial: 29, train_loss: 0.085709, test loss: 1.982529, bias2: 0.28705883026123047, variance: 1.695469856262207\n",
      "Train size: [400] hidden size: [848] trial: 30, train_loss: 0.085930, test loss: 1.982738, bias2: 0.28622210025787354, variance: 1.696515440940857\n",
      "Train size: [400] hidden size: [848] trial: 31, train_loss: 0.086596, test loss: 1.986314, bias2: 0.2827247381210327, variance: 1.7035895586013794\n",
      "Train size: [400] hidden size: [848] trial: 32, train_loss: 0.087057, test loss: 1.988640, bias2: 0.27795135974884033, variance: 1.7106884717941284\n",
      "Train size: [400] hidden size: [848] trial: 33, train_loss: 0.087250, test loss: 1.989687, bias2: 0.27621781826019287, variance: 1.7134696245193481\n",
      "Train size: [400] hidden size: [848] trial: 34, train_loss: 0.087093, test loss: 1.991906, bias2: 0.2764192819595337, variance: 1.7154862880706787\n",
      "Train size: [400] hidden size: [848] trial: 35, train_loss: 0.086939, test loss: 1.987076, bias2: 0.2745933532714844, variance: 1.7124823331832886\n",
      "Train size: [400] hidden size: [848] trial: 36, train_loss: 0.087365, test loss: 1.989338, bias2: 0.2713881731033325, variance: 1.7179501056671143\n",
      "Train size: [400] hidden size: [848] trial: 37, train_loss: 0.087901, test loss: 1.991325, bias2: 0.2685244083404541, variance: 1.722800850868225\n",
      "Train size: [400] hidden size: [848] trial: 38, train_loss: 0.088007, test loss: 1.989648, bias2: 0.2702447175979614, variance: 1.7194035053253174\n",
      "Train size: [400] hidden size: [848] trial: 39, train_loss: 0.088269, test loss: 1.997069, bias2: 0.27158093452453613, variance: 1.7254879474639893\n",
      "Train size: [400] hidden size: [848] trial: 40, train_loss: 0.088743, test loss: 2.007962, bias2: 0.2721654176712036, variance: 1.7357970476150513\n",
      "Train size: [400] hidden size: [848] trial: 41, train_loss: 0.088470, test loss: 2.004301, bias2: 0.27196013927459717, variance: 1.732340693473816\n",
      "Train size: [400] hidden size: [848] trial: 42, train_loss: 0.088446, test loss: 2.004474, bias2: 0.2723919153213501, variance: 1.7320822477340698\n",
      "Train size: [400] hidden size: [848] trial: 43, train_loss: 0.088802, test loss: 2.000663, bias2: 0.2727919816970825, variance: 1.727871298789978\n",
      "Train size: [400] hidden size: [848] trial: 44, train_loss: 0.088904, test loss: 2.000255, bias2: 0.27097034454345703, variance: 1.7292847633361816\n",
      "Train size: [400] hidden size: [848] trial: 45, train_loss: 0.088928, test loss: 1.999353, bias2: 0.2707608938217163, variance: 1.7285925149917603\n",
      "Train size: [400] hidden size: [848] trial: 46, train_loss: 0.088326, test loss: 1.995020, bias2: 0.2713449001312256, variance: 1.7236754894256592\n",
      "Train size: [400] hidden size: [848] trial: 47, train_loss: 0.088196, test loss: 1.987845, bias2: 0.27058959007263184, variance: 1.7172553539276123\n",
      "Train size: [400] hidden size: [848] trial: 48, train_loss: 0.088759, test loss: 1.987625, bias2: 0.2686246633529663, variance: 1.7190008163452148\n",
      "Train size: [400] hidden size: [848] trial: 49, train_loss: 0.088803, test loss: 1.987954, bias2: 0.26785385608673096, variance: 1.7201006412506104\n",
      "##################################################\n",
      "Train size: [400] hidden size: [977] trial: 0, train_loss: 0.063613, test loss: 1.961224, bias2: 1.9612236022949219, variance: -6.228076721015441e-09\n",
      "Train size: [400] hidden size: [977] trial: 1, train_loss: 0.061226, test loss: 1.922736, bias2: 1.1284995079040527, variance: 0.7942363023757935\n",
      "Train size: [400] hidden size: [977] trial: 2, train_loss: 0.060237, test loss: 1.875553, bias2: 0.8047870397567749, variance: 1.0707663297653198\n",
      "Train size: [400] hidden size: [977] trial: 3, train_loss: 0.061102, test loss: 1.911072, bias2: 0.6940193176269531, variance: 1.2170528173446655\n",
      "Train size: [400] hidden size: [977] trial: 4, train_loss: 0.058143, test loss: 1.847140, bias2: 0.5878981351852417, variance: 1.2592417001724243\n",
      "Train size: [400] hidden size: [977] trial: 5, train_loss: 0.056814, test loss: 1.873390, bias2: 0.549167275428772, variance: 1.3242230415344238\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [977] trial: 6, train_loss: 0.054127, test loss: 1.860452, bias2: 0.49344730377197266, variance: 1.3670051097869873\n",
      "Train size: [400] hidden size: [977] trial: 7, train_loss: 0.052690, test loss: 1.872113, bias2: 0.45432567596435547, variance: 1.4177874326705933\n",
      "Train size: [400] hidden size: [977] trial: 8, train_loss: 0.051965, test loss: 1.849225, bias2: 0.41752004623413086, variance: 1.4317049980163574\n",
      "Train size: [400] hidden size: [977] trial: 9, train_loss: 0.051228, test loss: 1.844055, bias2: 0.4085201025009155, variance: 1.4355347156524658\n",
      "Train size: [400] hidden size: [977] trial: 10, train_loss: 0.052078, test loss: 1.833594, bias2: 0.39720118045806885, variance: 1.4363927841186523\n",
      "Train size: [400] hidden size: [977] trial: 11, train_loss: 0.051575, test loss: 1.837395, bias2: 0.3795076608657837, variance: 1.4578869342803955\n",
      "Train size: [400] hidden size: [977] trial: 12, train_loss: 0.051883, test loss: 1.832696, bias2: 0.37001335620880127, variance: 1.4626826047897339\n",
      "Train size: [400] hidden size: [977] trial: 13, train_loss: 0.051649, test loss: 1.838001, bias2: 0.36037611961364746, variance: 1.4776251316070557\n",
      "Train size: [400] hidden size: [977] trial: 14, train_loss: 0.051884, test loss: 1.823258, bias2: 0.34222984313964844, variance: 1.4810279607772827\n",
      "Train size: [400] hidden size: [977] trial: 15, train_loss: 0.052029, test loss: 1.832274, bias2: 0.3400859832763672, variance: 1.4921880960464478\n",
      "Train size: [400] hidden size: [977] trial: 16, train_loss: 0.052932, test loss: 1.833762, bias2: 0.33859753608703613, variance: 1.4951647520065308\n",
      "Train size: [400] hidden size: [977] trial: 17, train_loss: 0.053041, test loss: 1.833408, bias2: 0.33223557472229004, variance: 1.5011720657348633\n",
      "Train size: [400] hidden size: [977] trial: 18, train_loss: 0.052859, test loss: 1.829478, bias2: 0.3265336751937866, variance: 1.5029443502426147\n",
      "Train size: [400] hidden size: [977] trial: 19, train_loss: 0.053633, test loss: 1.835395, bias2: 0.31549715995788574, variance: 1.519897699356079\n",
      "Train size: [400] hidden size: [977] trial: 20, train_loss: 0.053422, test loss: 1.825204, bias2: 0.307428240776062, variance: 1.5177760124206543\n",
      "Train size: [400] hidden size: [977] trial: 21, train_loss: 0.053991, test loss: 1.822084, bias2: 0.3005249500274658, variance: 1.5215593576431274\n",
      "Train size: [400] hidden size: [977] trial: 22, train_loss: 0.054670, test loss: 1.832275, bias2: 0.30051517486572266, variance: 1.531760334968567\n",
      "Train size: [400] hidden size: [977] trial: 23, train_loss: 0.055086, test loss: 1.831823, bias2: 0.29598772525787354, variance: 1.5358357429504395\n",
      "Train size: [400] hidden size: [977] trial: 24, train_loss: 0.054871, test loss: 1.835325, bias2: 0.2964683771133423, variance: 1.5388565063476562\n",
      "Train size: [400] hidden size: [977] trial: 25, train_loss: 0.054975, test loss: 1.832531, bias2: 0.2958441972732544, variance: 1.5366872549057007\n",
      "Train size: [400] hidden size: [977] trial: 26, train_loss: 0.054645, test loss: 1.829224, bias2: 0.2956176996231079, variance: 1.5336065292358398\n",
      "Train size: [400] hidden size: [977] trial: 27, train_loss: 0.054319, test loss: 1.834553, bias2: 0.2972075939178467, variance: 1.5373456478118896\n",
      "Train size: [400] hidden size: [977] trial: 28, train_loss: 0.054255, test loss: 1.829539, bias2: 0.29453396797180176, variance: 1.5350054502487183\n",
      "Train size: [400] hidden size: [977] trial: 29, train_loss: 0.054219, test loss: 1.824988, bias2: 0.2923234701156616, variance: 1.5326647758483887\n",
      "Train size: [400] hidden size: [977] trial: 30, train_loss: 0.054200, test loss: 1.820675, bias2: 0.2903745174407959, variance: 1.5303009748458862\n",
      "Train size: [400] hidden size: [977] trial: 31, train_loss: 0.054293, test loss: 1.821761, bias2: 0.28855741024017334, variance: 1.5332040786743164\n",
      "Train size: [400] hidden size: [977] trial: 32, train_loss: 0.054372, test loss: 1.825837, bias2: 0.28667962551116943, variance: 1.539157748222351\n",
      "Train size: [400] hidden size: [977] trial: 33, train_loss: 0.054055, test loss: 1.822823, bias2: 0.28432631492614746, variance: 1.5384966135025024\n",
      "Train size: [400] hidden size: [977] trial: 34, train_loss: 0.053643, test loss: 1.819944, bias2: 0.28259778022766113, variance: 1.537346601486206\n",
      "Train size: [400] hidden size: [977] trial: 35, train_loss: 0.053297, test loss: 1.811829, bias2: 0.2805311679840088, variance: 1.5312974452972412\n",
      "Train size: [400] hidden size: [977] trial: 36, train_loss: 0.053278, test loss: 1.811181, bias2: 0.27924013137817383, variance: 1.5319404602050781\n",
      "Train size: [400] hidden size: [977] trial: 37, train_loss: 0.053360, test loss: 1.814568, bias2: 0.2771008014678955, variance: 1.537467122077942\n",
      "Train size: [400] hidden size: [977] trial: 38, train_loss: 0.053313, test loss: 1.814757, bias2: 0.27860915660858154, variance: 1.536148190498352\n",
      "Train size: [400] hidden size: [977] trial: 39, train_loss: 0.053420, test loss: 1.818801, bias2: 0.27689898014068604, variance: 1.5419018268585205\n",
      "Train size: [400] hidden size: [977] trial: 40, train_loss: 0.053508, test loss: 1.818348, bias2: 0.27692878246307373, variance: 1.541419506072998\n",
      "Train size: [400] hidden size: [977] trial: 41, train_loss: 0.053579, test loss: 1.818753, bias2: 0.27500927448272705, variance: 1.5437440872192383\n",
      "Train size: [400] hidden size: [977] trial: 42, train_loss: 0.053656, test loss: 1.815713, bias2: 0.2723809480667114, variance: 1.5433324575424194\n",
      "Train size: [400] hidden size: [977] trial: 43, train_loss: 0.053465, test loss: 1.808487, bias2: 0.26751387119293213, variance: 1.5409730672836304\n",
      "Train size: [400] hidden size: [977] trial: 44, train_loss: 0.053603, test loss: 1.809023, bias2: 0.2668994665145874, variance: 1.5421239137649536\n",
      "Train size: [400] hidden size: [977] trial: 45, train_loss: 0.053672, test loss: 1.803247, bias2: 0.264379620552063, variance: 1.5388672351837158\n",
      "Train size: [400] hidden size: [977] trial: 46, train_loss: 0.053666, test loss: 1.803683, bias2: 0.2638481855392456, variance: 1.5398350954055786\n",
      "Train size: [400] hidden size: [977] trial: 47, train_loss: 0.053626, test loss: 1.804495, bias2: 0.2662848234176636, variance: 1.5382105112075806\n",
      "Train size: [400] hidden size: [977] trial: 48, train_loss: 0.053562, test loss: 1.803535, bias2: 0.26523423194885254, variance: 1.53830087184906\n",
      "Train size: [400] hidden size: [977] trial: 49, train_loss: 0.053673, test loss: 1.801558, bias2: 0.2649519443511963, variance: 1.536605954170227\n",
      "##################################################\n",
      "Train size: [400] hidden size: [1125] trial: 0, train_loss: 0.031436, test loss: 1.545967, bias2: 1.5459671020507812, variance: -7.785096123313906e-09\n",
      "Train size: [400] hidden size: [1125] trial: 1, train_loss: 0.034237, test loss: 1.574721, bias2: 0.9063495397567749, variance: 0.6683717966079712\n",
      "Train size: [400] hidden size: [1125] trial: 2, train_loss: 0.033293, test loss: 1.582422, bias2: 0.6854881048202515, variance: 0.8969335556030273\n",
      "Train size: [400] hidden size: [1125] trial: 3, train_loss: 0.034219, test loss: 1.605300, bias2: 0.5923569202423096, variance: 1.012942910194397\n",
      "Train size: [400] hidden size: [1125] trial: 4, train_loss: 0.032703, test loss: 1.590440, bias2: 0.5072023868560791, variance: 1.083237886428833\n",
      "Train size: [400] hidden size: [1125] trial: 5, train_loss: 0.032926, test loss: 1.588920, bias2: 0.4706380367279053, variance: 1.1182814836502075\n",
      "Train size: [400] hidden size: [1125] trial: 6, train_loss: 0.032774, test loss: 1.581636, bias2: 0.44988179206848145, variance: 1.1317542791366577\n",
      "Train size: [400] hidden size: [1125] trial: 7, train_loss: 0.032705, test loss: 1.570647, bias2: 0.40906333923339844, variance: 1.1615839004516602\n",
      "Train size: [400] hidden size: [1125] trial: 8, train_loss: 0.031973, test loss: 1.562537, bias2: 0.38744354248046875, variance: 1.1750930547714233\n",
      "Train size: [400] hidden size: [1125] trial: 9, train_loss: 0.032327, test loss: 1.589508, bias2: 0.38381826877593994, variance: 1.2056896686553955\n",
      "Train size: [400] hidden size: [1125] trial: 10, train_loss: 0.031794, test loss: 1.572839, bias2: 0.3641672134399414, variance: 1.2086715698242188\n",
      "Train size: [400] hidden size: [1125] trial: 11, train_loss: 0.031598, test loss: 1.577959, bias2: 0.3480997085571289, variance: 1.2298589944839478\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [1125] trial: 12, train_loss: 0.031747, test loss: 1.582133, bias2: 0.3406490087509155, variance: 1.2414841651916504\n",
      "Train size: [400] hidden size: [1125] trial: 13, train_loss: 0.031869, test loss: 1.583298, bias2: 0.3293648958206177, variance: 1.2539334297180176\n",
      "Train size: [400] hidden size: [1125] trial: 14, train_loss: 0.031673, test loss: 1.575648, bias2: 0.31865131855010986, variance: 1.2569963932037354\n",
      "Train size: [400] hidden size: [1125] trial: 15, train_loss: 0.031388, test loss: 1.571191, bias2: 0.31679749488830566, variance: 1.2543938159942627\n",
      "Train size: [400] hidden size: [1125] trial: 16, train_loss: 0.031053, test loss: 1.570106, bias2: 0.31156837940216064, variance: 1.258538007736206\n",
      "Train size: [400] hidden size: [1125] trial: 17, train_loss: 0.031070, test loss: 1.566944, bias2: 0.3065609931945801, variance: 1.2603826522827148\n",
      "Train size: [400] hidden size: [1125] trial: 18, train_loss: 0.030820, test loss: 1.568140, bias2: 0.3049778938293457, variance: 1.2631621360778809\n",
      "Train size: [400] hidden size: [1125] trial: 19, train_loss: 0.031132, test loss: 1.580134, bias2: 0.3025904893875122, variance: 1.277543306350708\n",
      "Train size: [400] hidden size: [1125] trial: 20, train_loss: 0.031267, test loss: 1.582984, bias2: 0.29648518562316895, variance: 1.2864984273910522\n",
      "Train size: [400] hidden size: [1125] trial: 21, train_loss: 0.031178, test loss: 1.585024, bias2: 0.2961721420288086, variance: 1.2888514995574951\n",
      "Train size: [400] hidden size: [1125] trial: 22, train_loss: 0.031175, test loss: 1.578573, bias2: 0.2916957139968872, variance: 1.2868775129318237\n",
      "Train size: [400] hidden size: [1125] trial: 23, train_loss: 0.031376, test loss: 1.578045, bias2: 0.28797852993011475, variance: 1.2900663614273071\n",
      "Train size: [400] hidden size: [1125] trial: 24, train_loss: 0.031568, test loss: 1.583656, bias2: 0.28592216968536377, variance: 1.2977337837219238\n",
      "Train size: [400] hidden size: [1125] trial: 25, train_loss: 0.031334, test loss: 1.579930, bias2: 0.28158605098724365, variance: 1.2983442544937134\n",
      "Train size: [400] hidden size: [1125] trial: 26, train_loss: 0.031395, test loss: 1.575310, bias2: 0.2753854990005493, variance: 1.2999247312545776\n",
      "Train size: [400] hidden size: [1125] trial: 27, train_loss: 0.031638, test loss: 1.573391, bias2: 0.27081239223480225, variance: 1.3025786876678467\n",
      "Train size: [400] hidden size: [1125] trial: 28, train_loss: 0.031438, test loss: 1.567355, bias2: 0.2693626880645752, variance: 1.2979923486709595\n",
      "Train size: [400] hidden size: [1125] trial: 29, train_loss: 0.031337, test loss: 1.563019, bias2: 0.26563405990600586, variance: 1.29738450050354\n",
      "Train size: [400] hidden size: [1125] trial: 30, train_loss: 0.031381, test loss: 1.565719, bias2: 0.2674722671508789, variance: 1.2982465028762817\n",
      "Train size: [400] hidden size: [1125] trial: 31, train_loss: 0.031700, test loss: 1.568455, bias2: 0.26473212242126465, variance: 1.303722858428955\n",
      "Train size: [400] hidden size: [1125] trial: 32, train_loss: 0.031742, test loss: 1.566178, bias2: 0.25961148738861084, variance: 1.306566834449768\n",
      "Train size: [400] hidden size: [1125] trial: 33, train_loss: 0.031737, test loss: 1.567904, bias2: 0.2603428363800049, variance: 1.3075608015060425\n",
      "Train size: [400] hidden size: [1125] trial: 34, train_loss: 0.031798, test loss: 1.577398, bias2: 0.26245272159576416, variance: 1.3149455785751343\n",
      "Train size: [400] hidden size: [1125] trial: 35, train_loss: 0.031672, test loss: 1.574588, bias2: 0.26313865184783936, variance: 1.3114492893218994\n",
      "Train size: [400] hidden size: [1125] trial: 36, train_loss: 0.032051, test loss: 1.583670, bias2: 0.2626103162765503, variance: 1.321059226989746\n",
      "Train size: [400] hidden size: [1125] trial: 37, train_loss: 0.032100, test loss: 1.588215, bias2: 0.26456010341644287, variance: 1.3236552476882935\n",
      "Train size: [400] hidden size: [1125] trial: 38, train_loss: 0.032133, test loss: 1.586869, bias2: 0.264068603515625, variance: 1.3228007555007935\n",
      "Train size: [400] hidden size: [1125] trial: 39, train_loss: 0.032306, test loss: 1.586821, bias2: 0.2624633312225342, variance: 1.3243581056594849\n",
      "Train size: [400] hidden size: [1125] trial: 40, train_loss: 0.032306, test loss: 1.582797, bias2: 0.2592567205429077, variance: 1.3235403299331665\n",
      "Train size: [400] hidden size: [1125] trial: 41, train_loss: 0.032250, test loss: 1.580311, bias2: 0.2582052946090698, variance: 1.3221055269241333\n",
      "Train size: [400] hidden size: [1125] trial: 42, train_loss: 0.032326, test loss: 1.577148, bias2: 0.25913166999816895, variance: 1.3180160522460938\n",
      "Train size: [400] hidden size: [1125] trial: 43, train_loss: 0.032319, test loss: 1.575649, bias2: 0.25737321376800537, variance: 1.3182756900787354\n",
      "Train size: [400] hidden size: [1125] trial: 44, train_loss: 0.032482, test loss: 1.573094, bias2: 0.2558788061141968, variance: 1.3172152042388916\n",
      "Train size: [400] hidden size: [1125] trial: 45, train_loss: 0.032568, test loss: 1.577863, bias2: 0.2567664384841919, variance: 1.3210960626602173\n",
      "Train size: [400] hidden size: [1125] trial: 46, train_loss: 0.032499, test loss: 1.580456, bias2: 0.2580002546310425, variance: 1.3224557638168335\n",
      "Train size: [400] hidden size: [1125] trial: 47, train_loss: 0.032594, test loss: 1.578558, bias2: 0.25629496574401855, variance: 1.3222630023956299\n",
      "Train size: [400] hidden size: [1125] trial: 48, train_loss: 0.032748, test loss: 1.579955, bias2: 0.2554032802581787, variance: 1.3245521783828735\n",
      "Train size: [400] hidden size: [1125] trial: 49, train_loss: 0.032776, test loss: 1.577558, bias2: 0.25343525409698486, variance: 1.3241223096847534\n",
      "##################################################\n",
      "Train size: [400] hidden size: [1295] trial: 0, train_loss: 0.018531, test loss: 1.376362, bias2: 1.3763624429702759, variance: 7.785095901269301e-10\n",
      "Train size: [400] hidden size: [1295] trial: 1, train_loss: 0.022535, test loss: 1.365813, bias2: 0.7628054022789001, variance: 0.603007972240448\n",
      "Train size: [400] hidden size: [1295] trial: 2, train_loss: 0.021007, test loss: 1.347359, bias2: 0.5794491767883301, variance: 0.7679095268249512\n",
      "Train size: [400] hidden size: [1295] trial: 3, train_loss: 0.022202, test loss: 1.432420, bias2: 0.49990397691726685, variance: 0.9325162768363953\n",
      "Train size: [400] hidden size: [1295] trial: 4, train_loss: 0.022327, test loss: 1.415024, bias2: 0.4334968328475952, variance: 0.9815268516540527\n",
      "Train size: [400] hidden size: [1295] trial: 5, train_loss: 0.021633, test loss: 1.405305, bias2: 0.40295660495758057, variance: 1.00234854221344\n",
      "Train size: [400] hidden size: [1295] trial: 6, train_loss: 0.021776, test loss: 1.393953, bias2: 0.372073769569397, variance: 1.0218793153762817\n",
      "Train size: [400] hidden size: [1295] trial: 7, train_loss: 0.022096, test loss: 1.411145, bias2: 0.3563896417617798, variance: 1.0547550916671753\n",
      "Train size: [400] hidden size: [1295] trial: 8, train_loss: 0.021977, test loss: 1.406849, bias2: 0.35063111782073975, variance: 1.056218147277832\n",
      "Train size: [400] hidden size: [1295] trial: 9, train_loss: 0.021886, test loss: 1.398974, bias2: 0.3280903100967407, variance: 1.0708831548690796\n",
      "Train size: [400] hidden size: [1295] trial: 10, train_loss: 0.022325, test loss: 1.420059, bias2: 0.3180125951766968, variance: 1.1020461320877075\n",
      "Train size: [400] hidden size: [1295] trial: 11, train_loss: 0.022307, test loss: 1.413275, bias2: 0.310505747795105, variance: 1.102769136428833\n",
      "Train size: [400] hidden size: [1295] trial: 12, train_loss: 0.022301, test loss: 1.413174, bias2: 0.30665504932403564, variance: 1.1065187454223633\n",
      "Train size: [400] hidden size: [1295] trial: 13, train_loss: 0.022470, test loss: 1.420975, bias2: 0.3042799234390259, variance: 1.116694688796997\n",
      "Train size: [400] hidden size: [1295] trial: 14, train_loss: 0.022360, test loss: 1.410651, bias2: 0.2989683151245117, variance: 1.1116822957992554\n",
      "Train size: [400] hidden size: [1295] trial: 15, train_loss: 0.022158, test loss: 1.405021, bias2: 0.29076504707336426, variance: 1.1142560243606567\n",
      "Train size: [400] hidden size: [1295] trial: 16, train_loss: 0.022329, test loss: 1.415871, bias2: 0.284396767616272, variance: 1.1314737796783447\n",
      "Train size: [400] hidden size: [1295] trial: 17, train_loss: 0.022656, test loss: 1.413681, bias2: 0.27574002742767334, variance: 1.1379412412643433\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [1295] trial: 18, train_loss: 0.022869, test loss: 1.423539, bias2: 0.2751268148422241, variance: 1.1484119892120361\n",
      "Train size: [400] hidden size: [1295] trial: 19, train_loss: 0.022932, test loss: 1.426352, bias2: 0.2719155550003052, variance: 1.1544361114501953\n",
      "Train size: [400] hidden size: [1295] trial: 20, train_loss: 0.022813, test loss: 1.422804, bias2: 0.2703012228012085, variance: 1.1525026559829712\n",
      "Train size: [400] hidden size: [1295] trial: 21, train_loss: 0.023077, test loss: 1.424971, bias2: 0.2676384449005127, variance: 1.1573323011398315\n",
      "Train size: [400] hidden size: [1295] trial: 22, train_loss: 0.023226, test loss: 1.427248, bias2: 0.26461517810821533, variance: 1.1626331806182861\n",
      "Train size: [400] hidden size: [1295] trial: 23, train_loss: 0.022991, test loss: 1.425603, bias2: 0.26566267013549805, variance: 1.159940481185913\n",
      "Train size: [400] hidden size: [1295] trial: 24, train_loss: 0.023135, test loss: 1.427406, bias2: 0.2645484209060669, variance: 1.1628572940826416\n",
      "Train size: [400] hidden size: [1295] trial: 25, train_loss: 0.022965, test loss: 1.420371, bias2: 0.2633718252182007, variance: 1.1569992303848267\n",
      "Train size: [400] hidden size: [1295] trial: 26, train_loss: 0.023204, test loss: 1.417701, bias2: 0.2618604898452759, variance: 1.1558400392532349\n",
      "Train size: [400] hidden size: [1295] trial: 27, train_loss: 0.023277, test loss: 1.415048, bias2: 0.2572420835494995, variance: 1.1578058004379272\n",
      "Train size: [400] hidden size: [1295] trial: 28, train_loss: 0.023290, test loss: 1.414419, bias2: 0.2579667568206787, variance: 1.1564521789550781\n",
      "Train size: [400] hidden size: [1295] trial: 29, train_loss: 0.023317, test loss: 1.411958, bias2: 0.25537753105163574, variance: 1.1565804481506348\n",
      "Train size: [400] hidden size: [1295] trial: 30, train_loss: 0.023161, test loss: 1.407452, bias2: 0.25352394580841064, variance: 1.1539278030395508\n",
      "Train size: [400] hidden size: [1295] trial: 31, train_loss: 0.023305, test loss: 1.408906, bias2: 0.25197935104370117, variance: 1.156926155090332\n",
      "Train size: [400] hidden size: [1295] trial: 32, train_loss: 0.023273, test loss: 1.411777, bias2: 0.25283849239349365, variance: 1.1589382886886597\n",
      "Train size: [400] hidden size: [1295] trial: 33, train_loss: 0.023334, test loss: 1.415409, bias2: 0.2507714033126831, variance: 1.1646374464035034\n",
      "Train size: [400] hidden size: [1295] trial: 34, train_loss: 0.023264, test loss: 1.415662, bias2: 0.2520231008529663, variance: 1.1636393070220947\n",
      "Train size: [400] hidden size: [1295] trial: 35, train_loss: 0.023391, test loss: 1.415517, bias2: 0.2520461082458496, variance: 1.1634708642959595\n",
      "Train size: [400] hidden size: [1295] trial: 36, train_loss: 0.023287, test loss: 1.414807, bias2: 0.2512831687927246, variance: 1.1635240316390991\n",
      "Train size: [400] hidden size: [1295] trial: 37, train_loss: 0.023367, test loss: 1.420354, bias2: 0.2518414258956909, variance: 1.1685127019882202\n",
      "Train size: [400] hidden size: [1295] trial: 38, train_loss: 0.023298, test loss: 1.420546, bias2: 0.25143373012542725, variance: 1.1691125631332397\n",
      "Train size: [400] hidden size: [1295] trial: 39, train_loss: 0.023213, test loss: 1.417436, bias2: 0.2508145570755005, variance: 1.1666218042373657\n",
      "Train size: [400] hidden size: [1295] trial: 40, train_loss: 0.023206, test loss: 1.414850, bias2: 0.2486402988433838, variance: 1.1662095785140991\n",
      "Train size: [400] hidden size: [1295] trial: 41, train_loss: 0.023160, test loss: 1.413877, bias2: 0.2483755350112915, variance: 1.1655018329620361\n",
      "Train size: [400] hidden size: [1295] trial: 42, train_loss: 0.023135, test loss: 1.416178, bias2: 0.24864470958709717, variance: 1.167533040046692\n",
      "Train size: [400] hidden size: [1295] trial: 43, train_loss: 0.023133, test loss: 1.415559, bias2: 0.2475641965866089, variance: 1.1679946184158325\n",
      "Train size: [400] hidden size: [1295] trial: 44, train_loss: 0.023213, test loss: 1.417254, bias2: 0.24577665328979492, variance: 1.1714775562286377\n",
      "Train size: [400] hidden size: [1295] trial: 45, train_loss: 0.023216, test loss: 1.423084, bias2: 0.24707484245300293, variance: 1.1760090589523315\n",
      "Train size: [400] hidden size: [1295] trial: 46, train_loss: 0.023156, test loss: 1.424094, bias2: 0.24782276153564453, variance: 1.1762715578079224\n",
      "Train size: [400] hidden size: [1295] trial: 47, train_loss: 0.023181, test loss: 1.422525, bias2: 0.24548864364624023, variance: 1.1770360469818115\n",
      "Train size: [400] hidden size: [1295] trial: 48, train_loss: 0.023250, test loss: 1.421228, bias2: 0.2440626621246338, variance: 1.177164912223816\n",
      "Train size: [400] hidden size: [1295] trial: 49, train_loss: 0.023289, test loss: 1.422557, bias2: 0.24319899082183838, variance: 1.1793575286865234\n",
      "##################################################\n",
      "Train size: [400] hidden size: [1491] trial: 0, train_loss: 0.018128, test loss: 1.327391, bias2: 1.3273911476135254, variance: 2.3355288814030928e-09\n",
      "Train size: [400] hidden size: [1491] trial: 1, train_loss: 0.017322, test loss: 1.258079, bias2: 0.7314647436141968, variance: 0.5266138315200806\n",
      "Train size: [400] hidden size: [1491] trial: 2, train_loss: 0.016813, test loss: 1.281819, bias2: 0.5762431621551514, variance: 0.7055760622024536\n",
      "Train size: [400] hidden size: [1491] trial: 3, train_loss: 0.016804, test loss: 1.267377, bias2: 0.4785425066947937, variance: 0.7888345122337341\n",
      "Train size: [400] hidden size: [1491] trial: 4, train_loss: 0.016933, test loss: 1.280005, bias2: 0.4201453924179077, variance: 0.8598599433898926\n",
      "Train size: [400] hidden size: [1491] trial: 5, train_loss: 0.016847, test loss: 1.277985, bias2: 0.38809800148010254, variance: 0.8898869752883911\n",
      "Train size: [400] hidden size: [1491] trial: 6, train_loss: 0.016549, test loss: 1.266115, bias2: 0.35402101278305054, variance: 0.9120941758155823\n",
      "Train size: [400] hidden size: [1491] trial: 7, train_loss: 0.016447, test loss: 1.269176, bias2: 0.3404155969619751, variance: 0.9287607669830322\n",
      "Train size: [400] hidden size: [1491] trial: 8, train_loss: 0.016254, test loss: 1.254424, bias2: 0.3176434636116028, variance: 0.9367808699607849\n",
      "Train size: [400] hidden size: [1491] trial: 9, train_loss: 0.016122, test loss: 1.242899, bias2: 0.30222129821777344, variance: 0.9406780004501343\n",
      "Train size: [400] hidden size: [1491] trial: 10, train_loss: 0.016293, test loss: 1.251575, bias2: 0.3014611005783081, variance: 0.9501136541366577\n",
      "Train size: [400] hidden size: [1491] trial: 11, train_loss: 0.016296, test loss: 1.254153, bias2: 0.29398661851882935, variance: 0.9601662755012512\n",
      "Train size: [400] hidden size: [1491] trial: 12, train_loss: 0.016400, test loss: 1.252084, bias2: 0.29190170764923096, variance: 0.9601824283599854\n",
      "Train size: [400] hidden size: [1491] trial: 13, train_loss: 0.016351, test loss: 1.250476, bias2: 0.2865719199180603, variance: 0.9639042019844055\n",
      "Train size: [400] hidden size: [1491] trial: 14, train_loss: 0.016001, test loss: 1.250892, bias2: 0.2852768898010254, variance: 0.9656151533126831\n",
      "Train size: [400] hidden size: [1491] trial: 15, train_loss: 0.015959, test loss: 1.245013, bias2: 0.27863484621047974, variance: 0.9663780331611633\n",
      "Train size: [400] hidden size: [1491] trial: 16, train_loss: 0.016245, test loss: 1.247603, bias2: 0.27197402715682983, variance: 0.9756291508674622\n",
      "Train size: [400] hidden size: [1491] trial: 17, train_loss: 0.016364, test loss: 1.259277, bias2: 0.2713860869407654, variance: 0.9878913760185242\n",
      "Train size: [400] hidden size: [1491] trial: 18, train_loss: 0.016497, test loss: 1.263420, bias2: 0.2702312469482422, variance: 0.9931885004043579\n",
      "Train size: [400] hidden size: [1491] trial: 19, train_loss: 0.016547, test loss: 1.262277, bias2: 0.26452046632766724, variance: 0.9977570176124573\n",
      "Train size: [400] hidden size: [1491] trial: 20, train_loss: 0.016570, test loss: 1.262647, bias2: 0.2637253403663635, variance: 0.998921811580658\n",
      "Train size: [400] hidden size: [1491] trial: 21, train_loss: 0.016487, test loss: 1.267473, bias2: 0.2634345293045044, variance: 1.0040388107299805\n",
      "Train size: [400] hidden size: [1491] trial: 22, train_loss: 0.016486, test loss: 1.267425, bias2: 0.26231610774993896, variance: 1.0051085948944092\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [1491] trial: 23, train_loss: 0.016542, test loss: 1.268908, bias2: 0.2633044719696045, variance: 1.0056037902832031\n",
      "Train size: [400] hidden size: [1491] trial: 24, train_loss: 0.016531, test loss: 1.268124, bias2: 0.25671589374542236, variance: 1.0114082098007202\n",
      "Train size: [400] hidden size: [1491] trial: 25, train_loss: 0.016484, test loss: 1.265050, bias2: 0.25378942489624023, variance: 1.0112602710723877\n",
      "Train size: [400] hidden size: [1491] trial: 26, train_loss: 0.016466, test loss: 1.270159, bias2: 0.2537727355957031, variance: 1.0163860321044922\n",
      "Train size: [400] hidden size: [1491] trial: 27, train_loss: 0.016520, test loss: 1.271029, bias2: 0.250302791595459, variance: 1.0207257270812988\n",
      "Train size: [400] hidden size: [1491] trial: 28, train_loss: 0.016549, test loss: 1.267915, bias2: 0.24492335319519043, variance: 1.0229918956756592\n",
      "Train size: [400] hidden size: [1491] trial: 29, train_loss: 0.016594, test loss: 1.270207, bias2: 0.24236583709716797, variance: 1.0278414487838745\n",
      "Train size: [400] hidden size: [1491] trial: 30, train_loss: 0.016570, test loss: 1.269610, bias2: 0.24242007732391357, variance: 1.0271896123886108\n",
      "Train size: [400] hidden size: [1491] trial: 31, train_loss: 0.016543, test loss: 1.267710, bias2: 0.2424253225326538, variance: 1.0252844095230103\n",
      "Train size: [400] hidden size: [1491] trial: 32, train_loss: 0.016642, test loss: 1.270661, bias2: 0.24110770225524902, variance: 1.0295536518096924\n",
      "Train size: [400] hidden size: [1491] trial: 33, train_loss: 0.016643, test loss: 1.267609, bias2: 0.23859238624572754, variance: 1.0290162563323975\n",
      "Train size: [400] hidden size: [1491] trial: 34, train_loss: 0.016702, test loss: 1.267583, bias2: 0.23730874061584473, variance: 1.0302746295928955\n",
      "Train size: [400] hidden size: [1491] trial: 35, train_loss: 0.016642, test loss: 1.265753, bias2: 0.23413431644439697, variance: 1.0316184759140015\n",
      "Train size: [400] hidden size: [1491] trial: 36, train_loss: 0.016568, test loss: 1.263822, bias2: 0.23412632942199707, variance: 1.029695749282837\n",
      "Train size: [400] hidden size: [1491] trial: 37, train_loss: 0.016641, test loss: 1.263846, bias2: 0.23268795013427734, variance: 1.0311578512191772\n",
      "Train size: [400] hidden size: [1491] trial: 38, train_loss: 0.016740, test loss: 1.264432, bias2: 0.2311800718307495, variance: 1.0332516431808472\n",
      "Train size: [400] hidden size: [1491] trial: 39, train_loss: 0.016654, test loss: 1.263406, bias2: 0.23091256618499756, variance: 1.032492995262146\n",
      "Train size: [400] hidden size: [1491] trial: 40, train_loss: 0.016665, test loss: 1.264296, bias2: 0.23183798789978027, variance: 1.032457709312439\n",
      "Train size: [400] hidden size: [1491] trial: 41, train_loss: 0.016676, test loss: 1.267581, bias2: 0.2334221601486206, variance: 1.0341588258743286\n",
      "Train size: [400] hidden size: [1491] trial: 42, train_loss: 0.016706, test loss: 1.267590, bias2: 0.23218786716461182, variance: 1.0354024171829224\n",
      "Train size: [400] hidden size: [1491] trial: 43, train_loss: 0.016737, test loss: 1.266611, bias2: 0.2303624153137207, variance: 1.036249041557312\n",
      "Train size: [400] hidden size: [1491] trial: 44, train_loss: 0.016749, test loss: 1.265116, bias2: 0.229242205619812, variance: 1.0358734130859375\n",
      "Train size: [400] hidden size: [1491] trial: 45, train_loss: 0.016811, test loss: 1.266680, bias2: 0.2274787425994873, variance: 1.0392011404037476\n",
      "Train size: [400] hidden size: [1491] trial: 46, train_loss: 0.016784, test loss: 1.266147, bias2: 0.22684860229492188, variance: 1.0392988920211792\n",
      "Train size: [400] hidden size: [1491] trial: 47, train_loss: 0.016907, test loss: 1.270761, bias2: 0.22792935371398926, variance: 1.0428321361541748\n",
      "Train size: [400] hidden size: [1491] trial: 48, train_loss: 0.016892, test loss: 1.269232, bias2: 0.2274487018585205, variance: 1.0417828559875488\n",
      "Train size: [400] hidden size: [1491] trial: 49, train_loss: 0.016889, test loss: 1.271501, bias2: 0.22799551486968994, variance: 1.0435055494308472\n",
      "##################################################\n",
      "Train size: [400] hidden size: [1717] trial: 0, train_loss: 0.012194, test loss: 1.167748, bias2: 1.1677484512329102, variance: 7.785095901269301e-10\n",
      "Train size: [400] hidden size: [1717] trial: 1, train_loss: 0.012350, test loss: 1.114172, bias2: 0.6561778783798218, variance: 0.4579942226409912\n",
      "Train size: [400] hidden size: [1717] trial: 2, train_loss: 0.012811, test loss: 1.118540, bias2: 0.5214447975158691, variance: 0.5970953702926636\n",
      "Train size: [400] hidden size: [1717] trial: 3, train_loss: 0.012543, test loss: 1.095999, bias2: 0.4118505120277405, variance: 0.6841481328010559\n",
      "Train size: [400] hidden size: [1717] trial: 4, train_loss: 0.012764, test loss: 1.103116, bias2: 0.3707788586616516, variance: 0.7323369383811951\n",
      "Train size: [400] hidden size: [1717] trial: 5, train_loss: 0.012866, test loss: 1.117809, bias2: 0.3509121537208557, variance: 0.7668965458869934\n",
      "Train size: [400] hidden size: [1717] trial: 6, train_loss: 0.013077, test loss: 1.112566, bias2: 0.32363879680633545, variance: 0.7889273166656494\n",
      "Train size: [400] hidden size: [1717] trial: 7, train_loss: 0.013052, test loss: 1.117097, bias2: 0.31220299005508423, variance: 0.8048941493034363\n",
      "Train size: [400] hidden size: [1717] trial: 8, train_loss: 0.013231, test loss: 1.114816, bias2: 0.29123228788375854, variance: 0.8235835433006287\n",
      "Train size: [400] hidden size: [1717] trial: 9, train_loss: 0.013268, test loss: 1.126506, bias2: 0.27826642990112305, variance: 0.8482398986816406\n",
      "Train size: [400] hidden size: [1717] trial: 10, train_loss: 0.013381, test loss: 1.136973, bias2: 0.28188222646713257, variance: 0.8550906777381897\n",
      "Train size: [400] hidden size: [1717] trial: 11, train_loss: 0.013442, test loss: 1.147074, bias2: 0.28357213735580444, variance: 0.8635017275810242\n",
      "Train size: [400] hidden size: [1717] trial: 12, train_loss: 0.013353, test loss: 1.157180, bias2: 0.2746652364730835, variance: 0.8825149536132812\n",
      "Train size: [400] hidden size: [1717] trial: 13, train_loss: 0.013290, test loss: 1.159985, bias2: 0.27078133821487427, variance: 0.8892033696174622\n",
      "Train size: [400] hidden size: [1717] trial: 14, train_loss: 0.013176, test loss: 1.167092, bias2: 0.27208709716796875, variance: 0.8950045108795166\n",
      "Train size: [400] hidden size: [1717] trial: 15, train_loss: 0.013068, test loss: 1.160047, bias2: 0.2651180624961853, variance: 0.8949292302131653\n",
      "Train size: [400] hidden size: [1717] trial: 16, train_loss: 0.013078, test loss: 1.162664, bias2: 0.26231706142425537, variance: 0.900347113609314\n",
      "Train size: [400] hidden size: [1717] trial: 17, train_loss: 0.012992, test loss: 1.164400, bias2: 0.26048582792282104, variance: 0.9039143919944763\n",
      "Train size: [400] hidden size: [1717] trial: 18, train_loss: 0.013008, test loss: 1.162294, bias2: 0.25727784633636475, variance: 0.9050159454345703\n",
      "Train size: [400] hidden size: [1717] trial: 19, train_loss: 0.013101, test loss: 1.162276, bias2: 0.25181567668914795, variance: 0.9104598760604858\n",
      "Train size: [400] hidden size: [1717] trial: 20, train_loss: 0.013094, test loss: 1.163948, bias2: 0.24735206365585327, variance: 0.9165962338447571\n",
      "Train size: [400] hidden size: [1717] trial: 21, train_loss: 0.013110, test loss: 1.160004, bias2: 0.24606835842132568, variance: 0.9139351844787598\n",
      "Train size: [400] hidden size: [1717] trial: 22, train_loss: 0.013190, test loss: 1.159247, bias2: 0.24033695459365845, variance: 0.9189103245735168\n",
      "Train size: [400] hidden size: [1717] trial: 23, train_loss: 0.013225, test loss: 1.159111, bias2: 0.23453736305236816, variance: 0.9245736598968506\n",
      "Train size: [400] hidden size: [1717] trial: 24, train_loss: 0.013181, test loss: 1.156070, bias2: 0.23295843601226807, variance: 0.9231117963790894\n",
      "Train size: [400] hidden size: [1717] trial: 25, train_loss: 0.013065, test loss: 1.153844, bias2: 0.2320689558982849, variance: 0.921774685382843\n",
      "Train size: [400] hidden size: [1717] trial: 26, train_loss: 0.013021, test loss: 1.151976, bias2: 0.23114728927612305, variance: 0.9208290576934814\n",
      "Train size: [400] hidden size: [1717] trial: 27, train_loss: 0.013127, test loss: 1.154240, bias2: 0.2279646396636963, variance: 0.926275372505188\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [1717] trial: 28, train_loss: 0.013089, test loss: 1.154654, bias2: 0.2281840443611145, variance: 0.9264702200889587\n",
      "Train size: [400] hidden size: [1717] trial: 29, train_loss: 0.013126, test loss: 1.152879, bias2: 0.22742348909378052, variance: 0.9254550337791443\n",
      "Train size: [400] hidden size: [1717] trial: 30, train_loss: 0.013175, test loss: 1.155596, bias2: 0.2276170253753662, variance: 0.9279788732528687\n",
      "Train size: [400] hidden size: [1717] trial: 31, train_loss: 0.013140, test loss: 1.153860, bias2: 0.22634583711624146, variance: 0.9275144934654236\n",
      "Train size: [400] hidden size: [1717] trial: 32, train_loss: 0.013073, test loss: 1.157573, bias2: 0.22750896215438843, variance: 0.9300639033317566\n",
      "Train size: [400] hidden size: [1717] trial: 33, train_loss: 0.013035, test loss: 1.158512, bias2: 0.2284976840019226, variance: 0.930014431476593\n",
      "Train size: [400] hidden size: [1717] trial: 34, train_loss: 0.013113, test loss: 1.161241, bias2: 0.22758084535598755, variance: 0.9336598515510559\n",
      "Train size: [400] hidden size: [1717] trial: 35, train_loss: 0.013095, test loss: 1.160809, bias2: 0.2261764407157898, variance: 0.9346323609352112\n",
      "Train size: [400] hidden size: [1717] trial: 36, train_loss: 0.013085, test loss: 1.159135, bias2: 0.22452247142791748, variance: 0.9346127510070801\n",
      "Train size: [400] hidden size: [1717] trial: 37, train_loss: 0.013034, test loss: 1.160302, bias2: 0.22445088624954224, variance: 0.9358512759208679\n",
      "Train size: [400] hidden size: [1717] trial: 38, train_loss: 0.012987, test loss: 1.159328, bias2: 0.2243935465812683, variance: 0.9349347949028015\n",
      "Train size: [400] hidden size: [1717] trial: 39, train_loss: 0.012972, test loss: 1.160438, bias2: 0.22506815195083618, variance: 0.9353700280189514\n",
      "Train size: [400] hidden size: [1717] trial: 40, train_loss: 0.012957, test loss: 1.161899, bias2: 0.2248343825340271, variance: 0.9370649456977844\n",
      "Train size: [400] hidden size: [1717] trial: 41, train_loss: 0.012954, test loss: 1.162119, bias2: 0.22463834285736084, variance: 0.9374802112579346\n",
      "Train size: [400] hidden size: [1717] trial: 42, train_loss: 0.012925, test loss: 1.159532, bias2: 0.22359490394592285, variance: 0.9359370470046997\n",
      "Train size: [400] hidden size: [1717] trial: 43, train_loss: 0.012897, test loss: 1.154563, bias2: 0.22272098064422607, variance: 0.9318418502807617\n",
      "Train size: [400] hidden size: [1717] trial: 44, train_loss: 0.012917, test loss: 1.152356, bias2: 0.221257746219635, variance: 0.9310984015464783\n",
      "Train size: [400] hidden size: [1717] trial: 45, train_loss: 0.012942, test loss: 1.150169, bias2: 0.22090023756027222, variance: 0.9292691349983215\n",
      "Train size: [400] hidden size: [1717] trial: 46, train_loss: 0.012954, test loss: 1.153298, bias2: 0.22230184078216553, variance: 0.9309961795806885\n",
      "Train size: [400] hidden size: [1717] trial: 47, train_loss: 0.012932, test loss: 1.153755, bias2: 0.22199887037277222, variance: 0.9317560791969299\n",
      "Train size: [400] hidden size: [1717] trial: 48, train_loss: 0.012930, test loss: 1.153669, bias2: 0.2225865125656128, variance: 0.9310822486877441\n",
      "Train size: [400] hidden size: [1717] trial: 49, train_loss: 0.013011, test loss: 1.154993, bias2: 0.2225703001022339, variance: 0.9324231147766113\n",
      "##################################################\n",
      "Train size: [400] hidden size: [1977] trial: 0, train_loss: 0.010254, test loss: 1.080397, bias2: 1.0803972482681274, variance: -2.3355288814030928e-09\n",
      "Train size: [400] hidden size: [1977] trial: 1, train_loss: 0.010272, test loss: 1.065802, bias2: 0.6173678636550903, variance: 0.4484339654445648\n",
      "Train size: [400] hidden size: [1977] trial: 2, train_loss: 0.010576, test loss: 1.066321, bias2: 0.481802761554718, variance: 0.5845178961753845\n",
      "Train size: [400] hidden size: [1977] trial: 3, train_loss: 0.010630, test loss: 1.073918, bias2: 0.41187387704849243, variance: 0.6620442271232605\n",
      "Train size: [400] hidden size: [1977] trial: 4, train_loss: 0.010373, test loss: 1.061848, bias2: 0.3707544803619385, variance: 0.6910934448242188\n",
      "Train size: [400] hidden size: [1977] trial: 5, train_loss: 0.010201, test loss: 1.054321, bias2: 0.3497976064682007, variance: 0.7045232057571411\n",
      "Train size: [400] hidden size: [1977] trial: 6, train_loss: 0.010415, test loss: 1.085067, bias2: 0.34453946352005005, variance: 0.740527331829071\n",
      "Train size: [400] hidden size: [1977] trial: 7, train_loss: 0.010471, test loss: 1.092923, bias2: 0.3357946276664734, variance: 0.7571285367012024\n",
      "Train size: [400] hidden size: [1977] trial: 8, train_loss: 0.010469, test loss: 1.083531, bias2: 0.31521522998809814, variance: 0.7683159112930298\n",
      "Train size: [400] hidden size: [1977] trial: 9, train_loss: 0.010556, test loss: 1.089749, bias2: 0.3011789917945862, variance: 0.7885701060295105\n",
      "Train size: [400] hidden size: [1977] trial: 10, train_loss: 0.010644, test loss: 1.089222, bias2: 0.29244911670684814, variance: 0.7967733144760132\n",
      "Train size: [400] hidden size: [1977] trial: 11, train_loss: 0.010742, test loss: 1.089863, bias2: 0.2907262444496155, variance: 0.7991369366645813\n",
      "Train size: [400] hidden size: [1977] trial: 12, train_loss: 0.010705, test loss: 1.085382, bias2: 0.28133952617645264, variance: 0.8040425777435303\n",
      "Train size: [400] hidden size: [1977] trial: 13, train_loss: 0.010606, test loss: 1.086266, bias2: 0.27767831087112427, variance: 0.8085874915122986\n",
      "Train size: [400] hidden size: [1977] trial: 14, train_loss: 0.010564, test loss: 1.076973, bias2: 0.26832491159439087, variance: 0.8086480498313904\n",
      "Train size: [400] hidden size: [1977] trial: 15, train_loss: 0.010689, test loss: 1.079453, bias2: 0.26613354682922363, variance: 0.8133194446563721\n",
      "Train size: [400] hidden size: [1977] trial: 16, train_loss: 0.010642, test loss: 1.081947, bias2: 0.2629368305206299, variance: 0.8190103769302368\n",
      "Train size: [400] hidden size: [1977] trial: 17, train_loss: 0.010759, test loss: 1.090952, bias2: 0.2602294087409973, variance: 0.8307231068611145\n",
      "Train size: [400] hidden size: [1977] trial: 18, train_loss: 0.010763, test loss: 1.087493, bias2: 0.2597696781158447, variance: 0.8277230262756348\n",
      "Train size: [400] hidden size: [1977] trial: 19, train_loss: 0.010765, test loss: 1.085195, bias2: 0.2570391893386841, variance: 0.8281552791595459\n",
      "Train size: [400] hidden size: [1977] trial: 20, train_loss: 0.010782, test loss: 1.075852, bias2: 0.2502397894859314, variance: 0.8256117701530457\n",
      "Train size: [400] hidden size: [1977] trial: 21, train_loss: 0.010784, test loss: 1.073837, bias2: 0.24627578258514404, variance: 0.8275614976882935\n",
      "Train size: [400] hidden size: [1977] trial: 22, train_loss: 0.010759, test loss: 1.080611, bias2: 0.24685317277908325, variance: 0.8337580561637878\n",
      "Train size: [400] hidden size: [1977] trial: 23, train_loss: 0.010848, test loss: 1.088166, bias2: 0.248393714427948, variance: 0.8397718071937561\n",
      "Train size: [400] hidden size: [1977] trial: 24, train_loss: 0.010934, test loss: 1.089735, bias2: 0.24593663215637207, variance: 0.8437986373901367\n",
      "Train size: [400] hidden size: [1977] trial: 25, train_loss: 0.010968, test loss: 1.091850, bias2: 0.24548566341400146, variance: 0.8463648557662964\n",
      "Train size: [400] hidden size: [1977] trial: 26, train_loss: 0.010986, test loss: 1.095544, bias2: 0.24456244707107544, variance: 0.8509818911552429\n",
      "Train size: [400] hidden size: [1977] trial: 27, train_loss: 0.010929, test loss: 1.092228, bias2: 0.2422424554824829, variance: 0.8499857187271118\n",
      "Train size: [400] hidden size: [1977] trial: 28, train_loss: 0.010925, test loss: 1.092041, bias2: 0.24026209115982056, variance: 0.8517789244651794\n",
      "Train size: [400] hidden size: [1977] trial: 29, train_loss: 0.010906, test loss: 1.089705, bias2: 0.23922014236450195, variance: 0.8504846096038818\n",
      "Train size: [400] hidden size: [1977] trial: 30, train_loss: 0.010925, test loss: 1.089296, bias2: 0.2401266098022461, variance: 0.849169135093689\n",
      "Train size: [400] hidden size: [1977] trial: 31, train_loss: 0.010905, test loss: 1.089230, bias2: 0.24082481861114502, variance: 0.8484052419662476\n",
      "Train size: [400] hidden size: [1977] trial: 32, train_loss: 0.010882, test loss: 1.087048, bias2: 0.2392481565475464, variance: 0.8477994203567505\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [1977] trial: 33, train_loss: 0.010881, test loss: 1.086831, bias2: 0.2384893298149109, variance: 0.8483420014381409\n",
      "Train size: [400] hidden size: [1977] trial: 34, train_loss: 0.010853, test loss: 1.085150, bias2: 0.2369917631149292, variance: 0.848158597946167\n",
      "Train size: [400] hidden size: [1977] trial: 35, train_loss: 0.010829, test loss: 1.084341, bias2: 0.2359209656715393, variance: 0.848419725894928\n",
      "Train size: [400] hidden size: [1977] trial: 36, train_loss: 0.010813, test loss: 1.082489, bias2: 0.2364053726196289, variance: 0.8460838794708252\n",
      "Train size: [400] hidden size: [1977] trial: 37, train_loss: 0.010786, test loss: 1.083519, bias2: 0.23483961820602417, variance: 0.8486791253089905\n",
      "Train size: [400] hidden size: [1977] trial: 38, train_loss: 0.010785, test loss: 1.079813, bias2: 0.23334604501724243, variance: 0.8464667201042175\n",
      "Train size: [400] hidden size: [1977] trial: 39, train_loss: 0.010779, test loss: 1.081008, bias2: 0.23352909088134766, variance: 0.8474785089492798\n",
      "Train size: [400] hidden size: [1977] trial: 40, train_loss: 0.010771, test loss: 1.080583, bias2: 0.23245197534561157, variance: 0.8481313586235046\n",
      "Train size: [400] hidden size: [1977] trial: 41, train_loss: 0.010751, test loss: 1.077498, bias2: 0.23017793893814087, variance: 0.847320020198822\n",
      "Train size: [400] hidden size: [1977] trial: 42, train_loss: 0.010746, test loss: 1.076505, bias2: 0.22860854864120483, variance: 0.8478968739509583\n",
      "Train size: [400] hidden size: [1977] trial: 43, train_loss: 0.010776, test loss: 1.074885, bias2: 0.227685809135437, variance: 0.8471990823745728\n",
      "Train size: [400] hidden size: [1977] trial: 44, train_loss: 0.010757, test loss: 1.072629, bias2: 0.22731685638427734, variance: 0.8453119993209839\n",
      "Train size: [400] hidden size: [1977] trial: 45, train_loss: 0.010755, test loss: 1.072265, bias2: 0.22726118564605713, variance: 0.8450034856796265\n",
      "Train size: [400] hidden size: [1977] trial: 46, train_loss: 0.010775, test loss: 1.070778, bias2: 0.22514009475708008, variance: 0.8456375598907471\n",
      "Train size: [400] hidden size: [1977] trial: 47, train_loss: 0.010755, test loss: 1.068683, bias2: 0.22423291206359863, variance: 0.8444497585296631\n",
      "Train size: [400] hidden size: [1977] trial: 48, train_loss: 0.010776, test loss: 1.068543, bias2: 0.22299861907958984, variance: 0.8455444574356079\n",
      "Train size: [400] hidden size: [1977] trial: 49, train_loss: 0.010804, test loss: 1.071795, bias2: 0.2237377166748047, variance: 0.8480576276779175\n",
      "##################################################\n",
      "Train size: [400] hidden size: [2276] trial: 0, train_loss: 0.010415, test loss: 1.130439, bias2: 1.1304389238357544, variance: 5.449567463955418e-09\n",
      "Train size: [400] hidden size: [2276] trial: 1, train_loss: 0.009418, test loss: 1.065555, bias2: 0.6661876440048218, variance: 0.39936771988868713\n",
      "Train size: [400] hidden size: [2276] trial: 2, train_loss: 0.009878, test loss: 1.056686, bias2: 0.47249549627304077, variance: 0.5841900706291199\n",
      "Train size: [400] hidden size: [2276] trial: 3, train_loss: 0.009951, test loss: 1.073810, bias2: 0.3998836874961853, variance: 0.6739261746406555\n",
      "Train size: [400] hidden size: [2276] trial: 4, train_loss: 0.010050, test loss: 1.086489, bias2: 0.3602970242500305, variance: 0.726192057132721\n",
      "Train size: [400] hidden size: [2276] trial: 5, train_loss: 0.009795, test loss: 1.084004, bias2: 0.33089834451675415, variance: 0.7531059384346008\n",
      "Train size: [400] hidden size: [2276] trial: 6, train_loss: 0.009677, test loss: 1.068417, bias2: 0.3142629861831665, variance: 0.7541540861129761\n",
      "Train size: [400] hidden size: [2276] trial: 7, train_loss: 0.009746, test loss: 1.062054, bias2: 0.2982322573661804, variance: 0.7638216614723206\n",
      "Train size: [400] hidden size: [2276] trial: 8, train_loss: 0.009519, test loss: 1.056991, bias2: 0.28670865297317505, variance: 0.7702823281288147\n",
      "Train size: [400] hidden size: [2276] trial: 9, train_loss: 0.009426, test loss: 1.055433, bias2: 0.2846216559410095, variance: 0.7708117365837097\n",
      "Train size: [400] hidden size: [2276] trial: 10, train_loss: 0.009460, test loss: 1.055021, bias2: 0.2702159285545349, variance: 0.7848051190376282\n",
      "Train size: [400] hidden size: [2276] trial: 11, train_loss: 0.009403, test loss: 1.061440, bias2: 0.2638867497444153, variance: 0.7975532412528992\n",
      "Train size: [400] hidden size: [2276] trial: 12, train_loss: 0.009418, test loss: 1.060909, bias2: 0.2577245235443115, variance: 0.8031842708587646\n",
      "Train size: [400] hidden size: [2276] trial: 13, train_loss: 0.009341, test loss: 1.055389, bias2: 0.25008243322372437, variance: 0.8053063750267029\n",
      "Train size: [400] hidden size: [2276] trial: 14, train_loss: 0.009382, test loss: 1.048571, bias2: 0.24750006198883057, variance: 0.8010704517364502\n",
      "Train size: [400] hidden size: [2276] trial: 15, train_loss: 0.009318, test loss: 1.047755, bias2: 0.24463927745819092, variance: 0.8031154870986938\n",
      "Train size: [400] hidden size: [2276] trial: 16, train_loss: 0.009282, test loss: 1.047488, bias2: 0.2466365098953247, variance: 0.800851583480835\n",
      "Train size: [400] hidden size: [2276] trial: 17, train_loss: 0.009255, test loss: 1.052042, bias2: 0.24573957920074463, variance: 0.8063027858734131\n",
      "Train size: [400] hidden size: [2276] trial: 18, train_loss: 0.009238, test loss: 1.051494, bias2: 0.24221277236938477, variance: 0.8092817068099976\n",
      "Train size: [400] hidden size: [2276] trial: 19, train_loss: 0.009196, test loss: 1.049090, bias2: 0.23986661434173584, variance: 0.8092234134674072\n",
      "Train size: [400] hidden size: [2276] trial: 20, train_loss: 0.009144, test loss: 1.049194, bias2: 0.23983138799667358, variance: 0.8093623518943787\n",
      "Train size: [400] hidden size: [2276] trial: 21, train_loss: 0.009167, test loss: 1.047251, bias2: 0.2395889163017273, variance: 0.8076617121696472\n",
      "Train size: [400] hidden size: [2276] trial: 22, train_loss: 0.009224, test loss: 1.049729, bias2: 0.2346029281616211, variance: 0.8151260614395142\n",
      "Train size: [400] hidden size: [2276] trial: 23, train_loss: 0.009241, test loss: 1.049595, bias2: 0.23225802183151245, variance: 0.8173370957374573\n",
      "Train size: [400] hidden size: [2276] trial: 24, train_loss: 0.009242, test loss: 1.048869, bias2: 0.23090451955795288, variance: 0.8179641366004944\n",
      "Train size: [400] hidden size: [2276] trial: 25, train_loss: 0.009254, test loss: 1.052628, bias2: 0.23327815532684326, variance: 0.8193496465682983\n",
      "Train size: [400] hidden size: [2276] trial: 26, train_loss: 0.009244, test loss: 1.051307, bias2: 0.2328106164932251, variance: 0.8184967041015625\n",
      "Train size: [400] hidden size: [2276] trial: 27, train_loss: 0.009263, test loss: 1.048005, bias2: 0.23238849639892578, variance: 0.8156166076660156\n",
      "Train size: [400] hidden size: [2276] trial: 28, train_loss: 0.009302, test loss: 1.047403, bias2: 0.22978556156158447, variance: 0.8176170587539673\n",
      "Train size: [400] hidden size: [2276] trial: 29, train_loss: 0.009323, test loss: 1.047434, bias2: 0.23040497303009033, variance: 0.8170293569564819\n",
      "Train size: [400] hidden size: [2276] trial: 30, train_loss: 0.009328, test loss: 1.045550, bias2: 0.22997015714645386, variance: 0.8155795931816101\n",
      "Train size: [400] hidden size: [2276] trial: 31, train_loss: 0.009371, test loss: 1.047759, bias2: 0.22962462902069092, variance: 0.8181341886520386\n",
      "Train size: [400] hidden size: [2276] trial: 32, train_loss: 0.009338, test loss: 1.048156, bias2: 0.22937482595443726, variance: 0.8187815546989441\n",
      "Train size: [400] hidden size: [2276] trial: 33, train_loss: 0.009324, test loss: 1.049399, bias2: 0.23030847311019897, variance: 0.8190905451774597\n",
      "Train size: [400] hidden size: [2276] trial: 34, train_loss: 0.009283, test loss: 1.045572, bias2: 0.23021680116653442, variance: 0.8153552412986755\n",
      "Train size: [400] hidden size: [2276] trial: 35, train_loss: 0.009244, test loss: 1.044463, bias2: 0.23144054412841797, variance: 0.8130226135253906\n",
      "Train size: [400] hidden size: [2276] trial: 36, train_loss: 0.009238, test loss: 1.041239, bias2: 0.2287846803665161, variance: 0.8124545812606812\n",
      "Train size: [400] hidden size: [2276] trial: 37, train_loss: 0.009243, test loss: 1.042513, bias2: 0.22598445415496826, variance: 0.8165283203125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [2276] trial: 38, train_loss: 0.009181, test loss: 1.042508, bias2: 0.2259342074394226, variance: 0.816573441028595\n",
      "Train size: [400] hidden size: [2276] trial: 39, train_loss: 0.009187, test loss: 1.042370, bias2: 0.2264581322669983, variance: 0.8159119486808777\n",
      "Train size: [400] hidden size: [2276] trial: 40, train_loss: 0.009209, test loss: 1.046673, bias2: 0.2286386489868164, variance: 0.8180347681045532\n",
      "Train size: [400] hidden size: [2276] trial: 41, train_loss: 0.009192, test loss: 1.046674, bias2: 0.23066657781600952, variance: 0.8160070776939392\n",
      "Train size: [400] hidden size: [2276] trial: 42, train_loss: 0.009179, test loss: 1.048074, bias2: 0.2303624153137207, variance: 0.8177112340927124\n",
      "Train size: [400] hidden size: [2276] trial: 43, train_loss: 0.009141, test loss: 1.047417, bias2: 0.22976231575012207, variance: 0.8176542520523071\n",
      "Train size: [400] hidden size: [2276] trial: 44, train_loss: 0.009158, test loss: 1.048070, bias2: 0.22978967428207397, variance: 0.8182802796363831\n",
      "Train size: [400] hidden size: [2276] trial: 45, train_loss: 0.009153, test loss: 1.045871, bias2: 0.22823947668075562, variance: 0.8176314234733582\n",
      "Train size: [400] hidden size: [2276] trial: 46, train_loss: 0.009193, test loss: 1.044933, bias2: 0.2266625165939331, variance: 0.8182704448699951\n",
      "Train size: [400] hidden size: [2276] trial: 47, train_loss: 0.009163, test loss: 1.046253, bias2: 0.22683387994766235, variance: 0.8194193243980408\n",
      "Train size: [400] hidden size: [2276] trial: 48, train_loss: 0.009140, test loss: 1.046419, bias2: 0.2271442413330078, variance: 0.8192744255065918\n",
      "Train size: [400] hidden size: [2276] trial: 49, train_loss: 0.009138, test loss: 1.044392, bias2: 0.2264748215675354, variance: 0.8179171681404114\n",
      "##################################################\n",
      "Train size: [400] hidden size: [2621] trial: 0, train_loss: 0.007778, test loss: 0.944369, bias2: 0.9443694353103638, variance: 1.0120625226761604e-08\n",
      "Train size: [400] hidden size: [2621] trial: 1, train_loss: 0.007474, test loss: 0.880349, bias2: 0.5157496333122253, variance: 0.36459946632385254\n",
      "Train size: [400] hidden size: [2621] trial: 2, train_loss: 0.007595, test loss: 0.895122, bias2: 0.40191853046417236, variance: 0.49320393800735474\n",
      "Train size: [400] hidden size: [2621] trial: 3, train_loss: 0.007820, test loss: 0.907295, bias2: 0.3460221290588379, variance: 0.5612726807594299\n",
      "Train size: [400] hidden size: [2621] trial: 4, train_loss: 0.008045, test loss: 0.922103, bias2: 0.3134053945541382, variance: 0.608697235584259\n",
      "Train size: [400] hidden size: [2621] trial: 5, train_loss: 0.007704, test loss: 0.934291, bias2: 0.30162936449050903, variance: 0.632661759853363\n",
      "Train size: [400] hidden size: [2621] trial: 6, train_loss: 0.007523, test loss: 0.939652, bias2: 0.287827730178833, variance: 0.6518238186836243\n",
      "Train size: [400] hidden size: [2621] trial: 7, train_loss: 0.007629, test loss: 0.941695, bias2: 0.2750927209854126, variance: 0.666601836681366\n",
      "Train size: [400] hidden size: [2621] trial: 8, train_loss: 0.007762, test loss: 0.945143, bias2: 0.27331072092056274, variance: 0.6718327403068542\n",
      "Train size: [400] hidden size: [2621] trial: 9, train_loss: 0.007689, test loss: 0.938301, bias2: 0.2669209837913513, variance: 0.6713796854019165\n",
      "Train size: [400] hidden size: [2621] trial: 10, train_loss: 0.007729, test loss: 0.943954, bias2: 0.2645788788795471, variance: 0.6793754696846008\n",
      "Train size: [400] hidden size: [2621] trial: 11, train_loss: 0.007715, test loss: 0.940038, bias2: 0.2591997981071472, variance: 0.6808386445045471\n",
      "Train size: [400] hidden size: [2621] trial: 12, train_loss: 0.007717, test loss: 0.940072, bias2: 0.24975234270095825, variance: 0.6903195381164551\n",
      "Train size: [400] hidden size: [2621] trial: 13, train_loss: 0.007740, test loss: 0.943409, bias2: 0.24160194396972656, variance: 0.7018066048622131\n",
      "Train size: [400] hidden size: [2621] trial: 14, train_loss: 0.007735, test loss: 0.944609, bias2: 0.23955613374710083, variance: 0.7050530910491943\n",
      "Train size: [400] hidden size: [2621] trial: 15, train_loss: 0.007661, test loss: 0.945427, bias2: 0.23627996444702148, variance: 0.7091473937034607\n",
      "Train size: [400] hidden size: [2621] trial: 16, train_loss: 0.007699, test loss: 0.946660, bias2: 0.23384231328964233, variance: 0.7128180265426636\n",
      "Train size: [400] hidden size: [2621] trial: 17, train_loss: 0.007708, test loss: 0.943807, bias2: 0.23001277446746826, variance: 0.7137941718101501\n",
      "Train size: [400] hidden size: [2621] trial: 18, train_loss: 0.007704, test loss: 0.940731, bias2: 0.2284882664680481, variance: 0.7122424840927124\n",
      "Train size: [400] hidden size: [2621] trial: 19, train_loss: 0.007662, test loss: 0.940303, bias2: 0.22799253463745117, variance: 0.712310791015625\n",
      "Train size: [400] hidden size: [2621] trial: 20, train_loss: 0.007661, test loss: 0.946900, bias2: 0.2273818850517273, variance: 0.7195176482200623\n",
      "Train size: [400] hidden size: [2621] trial: 21, train_loss: 0.007739, test loss: 0.948768, bias2: 0.2255789041519165, variance: 0.7231895923614502\n",
      "Train size: [400] hidden size: [2621] trial: 22, train_loss: 0.007747, test loss: 0.952066, bias2: 0.22352981567382812, variance: 0.7285364866256714\n",
      "Train size: [400] hidden size: [2621] trial: 23, train_loss: 0.007757, test loss: 0.950220, bias2: 0.22026044130325317, variance: 0.7299599051475525\n",
      "Train size: [400] hidden size: [2621] trial: 24, train_loss: 0.007762, test loss: 0.947177, bias2: 0.2187291383743286, variance: 0.7284477353096008\n",
      "Train size: [400] hidden size: [2621] trial: 25, train_loss: 0.007756, test loss: 0.944493, bias2: 0.21661752462387085, variance: 0.7278749942779541\n",
      "Train size: [400] hidden size: [2621] trial: 26, train_loss: 0.007798, test loss: 0.948180, bias2: 0.21595394611358643, variance: 0.7322263121604919\n",
      "Train size: [400] hidden size: [2621] trial: 27, train_loss: 0.007797, test loss: 0.952390, bias2: 0.2160971760749817, variance: 0.736292839050293\n",
      "Train size: [400] hidden size: [2621] trial: 28, train_loss: 0.007789, test loss: 0.954514, bias2: 0.21688973903656006, variance: 0.7376239895820618\n",
      "Train size: [400] hidden size: [2621] trial: 29, train_loss: 0.007778, test loss: 0.953811, bias2: 0.21760547161102295, variance: 0.7362056374549866\n",
      "Train size: [400] hidden size: [2621] trial: 30, train_loss: 0.007823, test loss: 0.955329, bias2: 0.21763908863067627, variance: 0.7376899719238281\n",
      "Train size: [400] hidden size: [2621] trial: 31, train_loss: 0.007823, test loss: 0.958008, bias2: 0.21702945232391357, variance: 0.7409785985946655\n",
      "Train size: [400] hidden size: [2621] trial: 32, train_loss: 0.007824, test loss: 0.958077, bias2: 0.2163878083229065, variance: 0.7416887879371643\n",
      "Train size: [400] hidden size: [2621] trial: 33, train_loss: 0.007819, test loss: 0.957342, bias2: 0.2167971134185791, variance: 0.7405449151992798\n",
      "Train size: [400] hidden size: [2621] trial: 34, train_loss: 0.007820, test loss: 0.960116, bias2: 0.21560627222061157, variance: 0.7445099949836731\n",
      "Train size: [400] hidden size: [2621] trial: 35, train_loss: 0.007807, test loss: 0.960755, bias2: 0.21679270267486572, variance: 0.7439619898796082\n",
      "Train size: [400] hidden size: [2621] trial: 36, train_loss: 0.007795, test loss: 0.958904, bias2: 0.21513116359710693, variance: 0.7437725067138672\n",
      "Train size: [400] hidden size: [2621] trial: 37, train_loss: 0.007788, test loss: 0.959458, bias2: 0.21481776237487793, variance: 0.7446404695510864\n",
      "Train size: [400] hidden size: [2621] trial: 38, train_loss: 0.007801, test loss: 0.962684, bias2: 0.21646004915237427, variance: 0.7462234497070312\n",
      "Train size: [400] hidden size: [2621] trial: 39, train_loss: 0.007822, test loss: 0.962877, bias2: 0.21608304977416992, variance: 0.7467944025993347\n",
      "Train size: [400] hidden size: [2621] trial: 40, train_loss: 0.007795, test loss: 0.963374, bias2: 0.21635454893112183, variance: 0.7470192909240723\n",
      "Train size: [400] hidden size: [2621] trial: 41, train_loss: 0.007751, test loss: 0.960593, bias2: 0.21635687351226807, variance: 0.7442356944084167\n",
      "Train size: [400] hidden size: [2621] trial: 42, train_loss: 0.007774, test loss: 0.961774, bias2: 0.21555280685424805, variance: 0.7462208867073059\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [2621] trial: 43, train_loss: 0.007781, test loss: 0.962795, bias2: 0.21560508012771606, variance: 0.7471903562545776\n",
      "Train size: [400] hidden size: [2621] trial: 44, train_loss: 0.007762, test loss: 0.961304, bias2: 0.21487104892730713, variance: 0.7464331388473511\n",
      "Train size: [400] hidden size: [2621] trial: 45, train_loss: 0.007765, test loss: 0.961144, bias2: 0.21427035331726074, variance: 0.7468734979629517\n",
      "Train size: [400] hidden size: [2621] trial: 46, train_loss: 0.007781, test loss: 0.961396, bias2: 0.2132854461669922, variance: 0.7481107115745544\n",
      "Train size: [400] hidden size: [2621] trial: 47, train_loss: 0.007782, test loss: 0.962821, bias2: 0.21376872062683105, variance: 0.7490526437759399\n",
      "Train size: [400] hidden size: [2621] trial: 48, train_loss: 0.007810, test loss: 0.962067, bias2: 0.21323955059051514, variance: 0.7488273978233337\n",
      "Train size: [400] hidden size: [2621] trial: 49, train_loss: 0.007779, test loss: 0.960860, bias2: 0.2121732234954834, variance: 0.7486863136291504\n",
      "##################################################\n",
      "Train size: [400] hidden size: [3017] trial: 0, train_loss: 0.006752, test loss: 0.888846, bias2: 0.8888458609580994, variance: -2.3355288814030928e-09\n",
      "Train size: [400] hidden size: [3017] trial: 1, train_loss: 0.006988, test loss: 0.924031, bias2: 0.5832234621047974, variance: 0.3408075273036957\n",
      "Train size: [400] hidden size: [3017] trial: 2, train_loss: 0.006807, test loss: 0.894955, bias2: 0.4373025596141815, variance: 0.4576524794101715\n",
      "Train size: [400] hidden size: [3017] trial: 3, train_loss: 0.006918, test loss: 0.879671, bias2: 0.3734830617904663, variance: 0.5061876773834229\n",
      "Train size: [400] hidden size: [3017] trial: 4, train_loss: 0.006866, test loss: 0.903416, bias2: 0.35170215368270874, variance: 0.551713764667511\n",
      "Train size: [400] hidden size: [3017] trial: 5, train_loss: 0.006951, test loss: 0.900476, bias2: 0.33106279373168945, variance: 0.5694133043289185\n",
      "Train size: [400] hidden size: [3017] trial: 6, train_loss: 0.006780, test loss: 0.909736, bias2: 0.3253582715988159, variance: 0.5843780636787415\n",
      "Train size: [400] hidden size: [3017] trial: 7, train_loss: 0.006767, test loss: 0.911946, bias2: 0.31368327140808105, variance: 0.5982629060745239\n",
      "Train size: [400] hidden size: [3017] trial: 8, train_loss: 0.006904, test loss: 0.911301, bias2: 0.29978805780410767, variance: 0.6115133762359619\n",
      "Train size: [400] hidden size: [3017] trial: 9, train_loss: 0.006882, test loss: 0.916028, bias2: 0.2901118993759155, variance: 0.6259155869483948\n",
      "Train size: [400] hidden size: [3017] trial: 10, train_loss: 0.006881, test loss: 0.921605, bias2: 0.2839025855064392, variance: 0.637702226638794\n",
      "Train size: [400] hidden size: [3017] trial: 11, train_loss: 0.007002, test loss: 0.919505, bias2: 0.28098177909851074, variance: 0.6385236978530884\n",
      "Train size: [400] hidden size: [3017] trial: 12, train_loss: 0.007040, test loss: 0.919621, bias2: 0.27498483657836914, variance: 0.6446360349655151\n",
      "Train size: [400] hidden size: [3017] trial: 13, train_loss: 0.007049, test loss: 0.915765, bias2: 0.26480740308761597, variance: 0.6509578824043274\n",
      "Train size: [400] hidden size: [3017] trial: 14, train_loss: 0.007077, test loss: 0.919696, bias2: 0.26112133264541626, variance: 0.6585744023323059\n",
      "Train size: [400] hidden size: [3017] trial: 15, train_loss: 0.007042, test loss: 0.923485, bias2: 0.26150578260421753, variance: 0.6619787812232971\n",
      "Train size: [400] hidden size: [3017] trial: 16, train_loss: 0.006983, test loss: 0.920480, bias2: 0.2591961622238159, variance: 0.6612837314605713\n",
      "Train size: [400] hidden size: [3017] trial: 17, train_loss: 0.007040, test loss: 0.919820, bias2: 0.2531578540802002, variance: 0.66666179895401\n",
      "Train size: [400] hidden size: [3017] trial: 18, train_loss: 0.007009, test loss: 0.922618, bias2: 0.2501479983329773, variance: 0.672469973564148\n",
      "Train size: [400] hidden size: [3017] trial: 19, train_loss: 0.007005, test loss: 0.917862, bias2: 0.24591243267059326, variance: 0.6719493865966797\n",
      "Train size: [400] hidden size: [3017] trial: 20, train_loss: 0.006967, test loss: 0.916195, bias2: 0.24377858638763428, variance: 0.6724167466163635\n",
      "Train size: [400] hidden size: [3017] trial: 21, train_loss: 0.006942, test loss: 0.914553, bias2: 0.2430812120437622, variance: 0.6714721918106079\n",
      "Train size: [400] hidden size: [3017] trial: 22, train_loss: 0.006961, test loss: 0.915394, bias2: 0.240692138671875, variance: 0.6747015118598938\n",
      "Train size: [400] hidden size: [3017] trial: 23, train_loss: 0.006952, test loss: 0.915802, bias2: 0.240561842918396, variance: 0.6752400994300842\n",
      "Train size: [400] hidden size: [3017] trial: 24, train_loss: 0.007002, test loss: 0.918622, bias2: 0.23835915327072144, variance: 0.6802625060081482\n",
      "Train size: [400] hidden size: [3017] trial: 25, train_loss: 0.006974, test loss: 0.922720, bias2: 0.24042397737503052, variance: 0.6822957992553711\n",
      "Train size: [400] hidden size: [3017] trial: 26, train_loss: 0.006973, test loss: 0.920744, bias2: 0.2390860915184021, variance: 0.6816580295562744\n",
      "Train size: [400] hidden size: [3017] trial: 27, train_loss: 0.006939, test loss: 0.921012, bias2: 0.23867028951644897, variance: 0.6823418736457825\n",
      "Train size: [400] hidden size: [3017] trial: 28, train_loss: 0.006938, test loss: 0.920461, bias2: 0.2353793978691101, variance: 0.685081958770752\n",
      "Train size: [400] hidden size: [3017] trial: 29, train_loss: 0.006899, test loss: 0.919508, bias2: 0.23423099517822266, variance: 0.6852773427963257\n",
      "Train size: [400] hidden size: [3017] trial: 30, train_loss: 0.006883, test loss: 0.918102, bias2: 0.23393690586090088, variance: 0.6841650009155273\n",
      "Train size: [400] hidden size: [3017] trial: 31, train_loss: 0.006884, test loss: 0.919517, bias2: 0.23368096351623535, variance: 0.6858356595039368\n",
      "Train size: [400] hidden size: [3017] trial: 32, train_loss: 0.006862, test loss: 0.920000, bias2: 0.23380333185195923, variance: 0.6861971616744995\n",
      "Train size: [400] hidden size: [3017] trial: 33, train_loss: 0.006843, test loss: 0.918083, bias2: 0.2330591082572937, variance: 0.6850240230560303\n",
      "Train size: [400] hidden size: [3017] trial: 34, train_loss: 0.006873, test loss: 0.918246, bias2: 0.23098456859588623, variance: 0.6872615218162537\n",
      "Train size: [400] hidden size: [3017] trial: 35, train_loss: 0.006862, test loss: 0.921912, bias2: 0.2312195897102356, variance: 0.6906929016113281\n",
      "Train size: [400] hidden size: [3017] trial: 36, train_loss: 0.006873, test loss: 0.918789, bias2: 0.22927802801132202, variance: 0.6895108819007874\n",
      "Train size: [400] hidden size: [3017] trial: 37, train_loss: 0.006924, test loss: 0.920938, bias2: 0.2278692126274109, variance: 0.6930689811706543\n",
      "Train size: [400] hidden size: [3017] trial: 38, train_loss: 0.006916, test loss: 0.920222, bias2: 0.22676515579223633, variance: 0.6934564113616943\n",
      "Train size: [400] hidden size: [3017] trial: 39, train_loss: 0.006905, test loss: 0.922522, bias2: 0.2268039584159851, variance: 0.6957176923751831\n",
      "Train size: [400] hidden size: [3017] trial: 40, train_loss: 0.006917, test loss: 0.924453, bias2: 0.22617971897125244, variance: 0.698273241519928\n",
      "Train size: [400] hidden size: [3017] trial: 41, train_loss: 0.006901, test loss: 0.926517, bias2: 0.22628796100616455, variance: 0.7002293467521667\n",
      "Train size: [400] hidden size: [3017] trial: 42, train_loss: 0.006935, test loss: 0.928056, bias2: 0.22612440586090088, variance: 0.7019320726394653\n",
      "Train size: [400] hidden size: [3017] trial: 43, train_loss: 0.006920, test loss: 0.926594, bias2: 0.22609829902648926, variance: 0.700495719909668\n",
      "Train size: [400] hidden size: [3017] trial: 44, train_loss: 0.006910, test loss: 0.925051, bias2: 0.22364526987075806, variance: 0.7014060616493225\n",
      "Train size: [400] hidden size: [3017] trial: 45, train_loss: 0.006896, test loss: 0.923802, bias2: 0.22239631414413452, variance: 0.70140540599823\n",
      "Train size: [400] hidden size: [3017] trial: 46, train_loss: 0.006890, test loss: 0.926121, bias2: 0.22289395332336426, variance: 0.7032274603843689\n",
      "Train size: [400] hidden size: [3017] trial: 47, train_loss: 0.006907, test loss: 0.925876, bias2: 0.22129952907562256, variance: 0.7045767307281494\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [3017] trial: 48, train_loss: 0.006938, test loss: 0.924589, bias2: 0.21973109245300293, variance: 0.7048574090003967\n",
      "Train size: [400] hidden size: [3017] trial: 49, train_loss: 0.006965, test loss: 0.926133, bias2: 0.21981525421142578, variance: 0.7063173651695251\n",
      "##################################################\n",
      "Train size: [400] hidden size: [3474] trial: 0, train_loss: 0.006669, test loss: 0.829952, bias2: 0.8299523591995239, variance: -7.785096123313906e-09\n",
      "Train size: [400] hidden size: [3474] trial: 1, train_loss: 0.006168, test loss: 0.870671, bias2: 0.5267138481140137, variance: 0.3439570367336273\n",
      "Train size: [400] hidden size: [3474] trial: 2, train_loss: 0.005794, test loss: 0.857872, bias2: 0.42177173495292664, variance: 0.4360997974872589\n",
      "Train size: [400] hidden size: [3474] trial: 3, train_loss: 0.005922, test loss: 0.878682, bias2: 0.37116527557373047, variance: 0.507516622543335\n",
      "Train size: [400] hidden size: [3474] trial: 4, train_loss: 0.006047, test loss: 0.880271, bias2: 0.34438568353652954, variance: 0.5358852744102478\n",
      "Train size: [400] hidden size: [3474] trial: 5, train_loss: 0.006157, test loss: 0.884741, bias2: 0.3166354298591614, variance: 0.5681051015853882\n",
      "Train size: [400] hidden size: [3474] trial: 6, train_loss: 0.006265, test loss: 0.876544, bias2: 0.2930770516395569, variance: 0.5834670662879944\n",
      "Train size: [400] hidden size: [3474] trial: 7, train_loss: 0.006273, test loss: 0.874968, bias2: 0.28033459186553955, variance: 0.5946333408355713\n",
      "Train size: [400] hidden size: [3474] trial: 8, train_loss: 0.006310, test loss: 0.880363, bias2: 0.2758029103279114, variance: 0.6045600771903992\n",
      "Train size: [400] hidden size: [3474] trial: 9, train_loss: 0.006368, test loss: 0.881638, bias2: 0.26828521490097046, variance: 0.6133530139923096\n",
      "Train size: [400] hidden size: [3474] trial: 10, train_loss: 0.006399, test loss: 0.881218, bias2: 0.2582796812057495, variance: 0.6229383945465088\n",
      "Train size: [400] hidden size: [3474] trial: 11, train_loss: 0.006416, test loss: 0.884582, bias2: 0.2535313367843628, variance: 0.6310511231422424\n",
      "Train size: [400] hidden size: [3474] trial: 12, train_loss: 0.006500, test loss: 0.876982, bias2: 0.2461482286453247, variance: 0.6308342218399048\n",
      "Train size: [400] hidden size: [3474] trial: 13, train_loss: 0.006509, test loss: 0.879534, bias2: 0.2456931471824646, variance: 0.6338412761688232\n",
      "Train size: [400] hidden size: [3474] trial: 14, train_loss: 0.006477, test loss: 0.878803, bias2: 0.24310076236724854, variance: 0.6357020139694214\n",
      "Train size: [400] hidden size: [3474] trial: 15, train_loss: 0.006498, test loss: 0.879268, bias2: 0.23951661586761475, variance: 0.6397516131401062\n",
      "Train size: [400] hidden size: [3474] trial: 16, train_loss: 0.006511, test loss: 0.879298, bias2: 0.2340087890625, variance: 0.6452891826629639\n",
      "Train size: [400] hidden size: [3474] trial: 17, train_loss: 0.006496, test loss: 0.878515, bias2: 0.23120743036270142, variance: 0.647307276725769\n",
      "Train size: [400] hidden size: [3474] trial: 18, train_loss: 0.006428, test loss: 0.880489, bias2: 0.23173582553863525, variance: 0.6487531661987305\n",
      "Train size: [400] hidden size: [3474] trial: 19, train_loss: 0.006454, test loss: 0.878223, bias2: 0.22908198833465576, variance: 0.6491408944129944\n",
      "Train size: [400] hidden size: [3474] trial: 20, train_loss: 0.006456, test loss: 0.883902, bias2: 0.23161262273788452, variance: 0.6522897481918335\n",
      "Train size: [400] hidden size: [3474] trial: 21, train_loss: 0.006429, test loss: 0.883059, bias2: 0.23001062870025635, variance: 0.6530482769012451\n",
      "Train size: [400] hidden size: [3474] trial: 22, train_loss: 0.006383, test loss: 0.882035, bias2: 0.2288035750389099, variance: 0.6532314419746399\n",
      "Train size: [400] hidden size: [3474] trial: 23, train_loss: 0.006426, test loss: 0.882520, bias2: 0.22756439447402954, variance: 0.6549558043479919\n",
      "Train size: [400] hidden size: [3474] trial: 24, train_loss: 0.006425, test loss: 0.887202, bias2: 0.22633177042007446, variance: 0.660869836807251\n",
      "Train size: [400] hidden size: [3474] trial: 25, train_loss: 0.006422, test loss: 0.884751, bias2: 0.22313743829727173, variance: 0.6616132855415344\n",
      "Train size: [400] hidden size: [3474] trial: 26, train_loss: 0.006436, test loss: 0.885391, bias2: 0.2215791940689087, variance: 0.663811981678009\n",
      "Train size: [400] hidden size: [3474] trial: 27, train_loss: 0.006437, test loss: 0.891329, bias2: 0.22292888164520264, variance: 0.6684004068374634\n",
      "Train size: [400] hidden size: [3474] trial: 28, train_loss: 0.006460, test loss: 0.893151, bias2: 0.22347933053970337, variance: 0.6696712374687195\n",
      "Train size: [400] hidden size: [3474] trial: 29, train_loss: 0.006490, test loss: 0.894489, bias2: 0.22087126970291138, variance: 0.6736180186271667\n",
      "Train size: [400] hidden size: [3474] trial: 30, train_loss: 0.006500, test loss: 0.895216, bias2: 0.21903115510940552, variance: 0.6761851906776428\n",
      "Train size: [400] hidden size: [3474] trial: 31, train_loss: 0.006506, test loss: 0.892471, bias2: 0.21827924251556396, variance: 0.6741916537284851\n",
      "Train size: [400] hidden size: [3474] trial: 32, train_loss: 0.006526, test loss: 0.892690, bias2: 0.2178133726119995, variance: 0.6748767495155334\n",
      "Train size: [400] hidden size: [3474] trial: 33, train_loss: 0.006542, test loss: 0.893164, bias2: 0.2174454927444458, variance: 0.6757183074951172\n",
      "Train size: [400] hidden size: [3474] trial: 34, train_loss: 0.006519, test loss: 0.893313, bias2: 0.21782124042510986, variance: 0.6754913330078125\n",
      "Train size: [400] hidden size: [3474] trial: 35, train_loss: 0.006527, test loss: 0.894067, bias2: 0.21758806705474854, variance: 0.676478922367096\n",
      "Train size: [400] hidden size: [3474] trial: 36, train_loss: 0.006522, test loss: 0.892247, bias2: 0.21743178367614746, variance: 0.6748154759407043\n",
      "Train size: [400] hidden size: [3474] trial: 37, train_loss: 0.006513, test loss: 0.889607, bias2: 0.21513348817825317, variance: 0.6744736433029175\n",
      "Train size: [400] hidden size: [3474] trial: 38, train_loss: 0.006496, test loss: 0.888966, bias2: 0.21555358171463013, variance: 0.6734126806259155\n",
      "Train size: [400] hidden size: [3474] trial: 39, train_loss: 0.006485, test loss: 0.890041, bias2: 0.21503162384033203, variance: 0.6750097274780273\n",
      "Train size: [400] hidden size: [3474] trial: 40, train_loss: 0.006474, test loss: 0.890708, bias2: 0.21594268083572388, variance: 0.6747658252716064\n",
      "Train size: [400] hidden size: [3474] trial: 41, train_loss: 0.006473, test loss: 0.891970, bias2: 0.2147769331932068, variance: 0.6771934628486633\n",
      "Train size: [400] hidden size: [3474] trial: 42, train_loss: 0.006471, test loss: 0.891915, bias2: 0.21524852514266968, variance: 0.6766665577888489\n",
      "Train size: [400] hidden size: [3474] trial: 43, train_loss: 0.006461, test loss: 0.889780, bias2: 0.21422016620635986, variance: 0.6755602359771729\n",
      "Train size: [400] hidden size: [3474] trial: 44, train_loss: 0.006470, test loss: 0.892028, bias2: 0.21382880210876465, variance: 0.678199052810669\n",
      "Train size: [400] hidden size: [3474] trial: 45, train_loss: 0.006457, test loss: 0.892189, bias2: 0.21406275033950806, variance: 0.6781261563301086\n",
      "Train size: [400] hidden size: [3474] trial: 46, train_loss: 0.006455, test loss: 0.892209, bias2: 0.21347695589065552, variance: 0.6787315607070923\n",
      "Train size: [400] hidden size: [3474] trial: 47, train_loss: 0.006481, test loss: 0.893283, bias2: 0.21326106786727905, variance: 0.6800217032432556\n",
      "Train size: [400] hidden size: [3474] trial: 48, train_loss: 0.006471, test loss: 0.896601, bias2: 0.21422511339187622, variance: 0.682375967502594\n",
      "Train size: [400] hidden size: [3474] trial: 49, train_loss: 0.006480, test loss: 0.898446, bias2: 0.21435558795928955, variance: 0.6840909123420715\n",
      "##################################################\n",
      "Train size: [400] hidden size: [4000] trial: 0, train_loss: 0.005690, test loss: 0.834493, bias2: 0.8344929814338684, variance: -2.3355288814030928e-09\n",
      "Train size: [400] hidden size: [4000] trial: 1, train_loss: 0.005754, test loss: 0.848284, bias2: 0.5170114040374756, variance: 0.3312724828720093\n",
      "Train size: [400] hidden size: [4000] trial: 2, train_loss: 0.005962, test loss: 0.861737, bias2: 0.45280951261520386, variance: 0.40892714262008667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: [400] hidden size: [4000] trial: 3, train_loss: 0.006007, test loss: 0.852553, bias2: 0.37854793667793274, variance: 0.4740053117275238\n",
      "Train size: [400] hidden size: [4000] trial: 4, train_loss: 0.006251, test loss: 0.882990, bias2: 0.3470625877380371, variance: 0.5359275341033936\n",
      "Train size: [400] hidden size: [4000] trial: 5, train_loss: 0.006366, test loss: 0.880252, bias2: 0.31952160596847534, variance: 0.56072998046875\n",
      "Train size: [400] hidden size: [4000] trial: 6, train_loss: 0.006151, test loss: 0.872916, bias2: 0.3053128123283386, variance: 0.5676036477088928\n",
      "Train size: [400] hidden size: [4000] trial: 7, train_loss: 0.006121, test loss: 0.862683, bias2: 0.28916025161743164, variance: 0.5735225081443787\n",
      "Train size: [400] hidden size: [4000] trial: 8, train_loss: 0.006057, test loss: 0.860973, bias2: 0.281630277633667, variance: 0.579342246055603\n",
      "Train size: [400] hidden size: [4000] trial: 9, train_loss: 0.006133, test loss: 0.862886, bias2: 0.2727122902870178, variance: 0.5901735424995422\n",
      "Train size: [400] hidden size: [4000] trial: 10, train_loss: 0.006097, test loss: 0.859986, bias2: 0.25859546661376953, variance: 0.6013908982276917\n",
      "Train size: [400] hidden size: [4000] trial: 11, train_loss: 0.006136, test loss: 0.852367, bias2: 0.25131523609161377, variance: 0.601051390171051\n",
      "Train size: [400] hidden size: [4000] trial: 12, train_loss: 0.006072, test loss: 0.848437, bias2: 0.24418580532073975, variance: 0.6042516231536865\n",
      "Train size: [400] hidden size: [4000] trial: 13, train_loss: 0.006028, test loss: 0.841681, bias2: 0.24007314443588257, variance: 0.6016083359718323\n",
      "Train size: [400] hidden size: [4000] trial: 14, train_loss: 0.005955, test loss: 0.840891, bias2: 0.23829329013824463, variance: 0.6025975346565247\n",
      "Train size: [400] hidden size: [4000] trial: 15, train_loss: 0.005947, test loss: 0.840279, bias2: 0.23650753498077393, variance: 0.603771448135376\n",
      "Train size: [400] hidden size: [4000] trial: 16, train_loss: 0.005876, test loss: 0.842903, bias2: 0.23657560348510742, variance: 0.6063277125358582\n",
      "Train size: [400] hidden size: [4000] trial: 17, train_loss: 0.005865, test loss: 0.845541, bias2: 0.2336614727973938, variance: 0.6118793487548828\n",
      "Train size: [400] hidden size: [4000] trial: 18, train_loss: 0.005843, test loss: 0.843202, bias2: 0.2307308316230774, variance: 0.6124714016914368\n",
      "Train size: [400] hidden size: [4000] trial: 19, train_loss: 0.005918, test loss: 0.845760, bias2: 0.2283332347869873, variance: 0.6174271106719971\n",
      "Train size: [400] hidden size: [4000] trial: 20, train_loss: 0.005931, test loss: 0.847841, bias2: 0.22860562801361084, variance: 0.6192356944084167\n",
      "Train size: [400] hidden size: [4000] trial: 21, train_loss: 0.005961, test loss: 0.847905, bias2: 0.22620081901550293, variance: 0.6217043995857239\n",
      "Train size: [400] hidden size: [4000] trial: 22, train_loss: 0.005975, test loss: 0.847289, bias2: 0.22606539726257324, variance: 0.6212232112884521\n",
      "Train size: [400] hidden size: [4000] trial: 23, train_loss: 0.005982, test loss: 0.849353, bias2: 0.22558683156967163, variance: 0.6237663626670837\n",
      "Train size: [400] hidden size: [4000] trial: 24, train_loss: 0.006016, test loss: 0.851064, bias2: 0.2253318428993225, variance: 0.6257323026657104\n",
      "Train size: [400] hidden size: [4000] trial: 25, train_loss: 0.006034, test loss: 0.855806, bias2: 0.22498148679733276, variance: 0.6308242082595825\n",
      "Train size: [400] hidden size: [4000] trial: 26, train_loss: 0.006056, test loss: 0.849899, bias2: 0.22077149152755737, variance: 0.6291276216506958\n",
      "Train size: [400] hidden size: [4000] trial: 27, train_loss: 0.006065, test loss: 0.853948, bias2: 0.22204989194869995, variance: 0.6318979859352112\n",
      "Train size: [400] hidden size: [4000] trial: 28, train_loss: 0.006046, test loss: 0.857221, bias2: 0.22430849075317383, variance: 0.6329123377799988\n",
      "Train size: [400] hidden size: [4000] trial: 29, train_loss: 0.006016, test loss: 0.855745, bias2: 0.2253383994102478, variance: 0.63040691614151\n",
      "Train size: [400] hidden size: [4000] trial: 30, train_loss: 0.006029, test loss: 0.853479, bias2: 0.2246553897857666, variance: 0.6288232803344727\n",
      "Train size: [400] hidden size: [4000] trial: 31, train_loss: 0.006022, test loss: 0.855140, bias2: 0.22526735067367554, variance: 0.6298725605010986\n",
      "Train size: [400] hidden size: [4000] trial: 32, train_loss: 0.006004, test loss: 0.853833, bias2: 0.2249184250831604, variance: 0.628915011882782\n",
      "Train size: [400] hidden size: [4000] trial: 33, train_loss: 0.005966, test loss: 0.850721, bias2: 0.22429639101028442, variance: 0.6264241337776184\n",
      "Train size: [400] hidden size: [4000] trial: 34, train_loss: 0.005962, test loss: 0.849365, bias2: 0.22140294313430786, variance: 0.6279617547988892\n",
      "Train size: [400] hidden size: [4000] trial: 35, train_loss: 0.005952, test loss: 0.846235, bias2: 0.2173459529876709, variance: 0.6288895010948181\n",
      "Train size: [400] hidden size: [4000] trial: 36, train_loss: 0.005914, test loss: 0.846966, bias2: 0.2181362509727478, variance: 0.6288297176361084\n",
      "Train size: [400] hidden size: [4000] trial: 37, train_loss: 0.005902, test loss: 0.847482, bias2: 0.21877437829971313, variance: 0.6287071704864502\n",
      "Train size: [400] hidden size: [4000] trial: 38, train_loss: 0.005907, test loss: 0.849797, bias2: 0.2193371057510376, variance: 0.630460262298584\n",
      "Train size: [400] hidden size: [4000] trial: 39, train_loss: 0.005907, test loss: 0.849268, bias2: 0.21746623516082764, variance: 0.6318016648292542\n",
      "Train size: [400] hidden size: [4000] trial: 40, train_loss: 0.005926, test loss: 0.850310, bias2: 0.21713966131210327, variance: 0.633169949054718\n",
      "Train size: [400] hidden size: [4000] trial: 41, train_loss: 0.005929, test loss: 0.851275, bias2: 0.21705007553100586, variance: 0.6342247128486633\n",
      "Train size: [400] hidden size: [4000] trial: 42, train_loss: 0.005959, test loss: 0.851750, bias2: 0.21696621179580688, variance: 0.6347838640213013\n",
      "Train size: [400] hidden size: [4000] trial: 43, train_loss: 0.005941, test loss: 0.849314, bias2: 0.21673893928527832, variance: 0.632575273513794\n",
      "Train size: [400] hidden size: [4000] trial: 44, train_loss: 0.005924, test loss: 0.848946, bias2: 0.21717506647109985, variance: 0.631770670413971\n",
      "Train size: [400] hidden size: [4000] trial: 45, train_loss: 0.005942, test loss: 0.851852, bias2: 0.21783792972564697, variance: 0.634013831615448\n",
      "Train size: [400] hidden size: [4000] trial: 46, train_loss: 0.005943, test loss: 0.852871, bias2: 0.21820497512817383, variance: 0.6346656084060669\n",
      "Train size: [400] hidden size: [4000] trial: 47, train_loss: 0.005938, test loss: 0.853617, bias2: 0.21794551610946655, variance: 0.6356713175773621\n",
      "Train size: [400] hidden size: [4000] trial: 48, train_loss: 0.005929, test loss: 0.852990, bias2: 0.2187531590461731, variance: 0.6342371702194214\n",
      "Train size: [400] hidden size: [4000] trial: 49, train_loss: 0.005942, test loss: 0.853013, bias2: 0.21718913316726685, variance: 0.6358239650726318\n",
      "##################################################\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x360 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x360 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "coef = 0.01\n",
    "outdir = 'synthetic_coef_{}'.format(coef)\n",
    "if not os.path.exists(outdir):\n",
    "    os.makedirs(outdir)\n",
    "run_exps_ridge(train_sizes, N_Ds, P_Ns, beta, test_size, feature_dim, num_classes, num_trials, coef,\n",
    "         outdir, 'singleNN_output.csv', SNR= SNR, K = 1, F_norm = 1)\n",
    "run_exps_ridge(train_sizes, N_Ds, P_Ns, beta, test_size, feature_dim, num_classes, num_trials, coef,\n",
    "             outdir, 'ensembleNNK=2_output.csv', SNR= SNR, K = 2, F_norm = 1)\n",
    "K2_df = pd.read_csv(os.path.join(outdir, 'ensembleNNK=2_output.csv'))\n",
    "K1_df = pd.read_csv(os.path.join(outdir, 'singleNN_output.csv'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x360 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x360 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_single_vs_ensemble([K1_df, K2_df], [1, 2], N_Ds[0], feature_dim, ymax=2.0)\n",
    "plot_single_vs_ensemble([K1_df, K2_df], [1, 2], N_Ds[0], feature_dim, ymax=2.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
